Julia Version 1.6.0-DEV.733
Commit 5da96913c2 (2020-08-26 17:46 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed TimerOutputs ───────────────── v0.5.6
  Installed OrderedCollections ─────────── v1.3.0
  Installed FileIO ─────────────────────── v1.4.1
  Installed DataStructures ─────────────── v0.17.20
  Installed NNlib ──────────────────────── v0.7.4
  Installed Knet ───────────────────────── v1.4.0
  Installed CUDA ───────────────────────── v1.3.3
  Installed MacroTools ─────────────────── v0.5.5
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed Reexport ───────────────────── v0.2.0
  Installed Zlib_jll ───────────────────── v1.2.11+16
  Installed LLVM ───────────────────────── v2.0.0
  Installed SpecialFunctions ───────────── v0.10.3
  Installed AutoGrad ───────────────────── v1.2.3
  Installed GPUArrays ──────────────────── v5.1.0
  Installed ExprTools ──────────────────── v0.1.1
  Installed JLD2 ───────────────────────── v0.1.14
  Installed Adapt ──────────────────────── v2.0.2
  Installed CodecZlib ──────────────────── v0.7.0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed Requires ───────────────────── v1.0.1
  Installed CEnum ──────────────────────── v0.4.1
  Installed GPUCompiler ────────────────── v0.6.0
  Installed TranscodingStreams ─────────── v0.9.5
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.4.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v2.0.2
  [6710c13c] + AutoGrad v1.2.3
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.4.1
  [052768ef] + CUDA v1.3.3
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] + DataStructures v0.17.20
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.4.1
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [033835bb] + JLD2 v0.1.14
  [1902f260] + Knet v1.4.0
  [929cbde3] + LLVM v2.0.0
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.7.4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+16
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing Knet
Status `/tmp/jl_ZEMXWf/Project.toml`
  [6710c13c] AutoGrad v1.2.3
  [052768ef] CUDA v1.3.3
  [5789e2e9] FileIO v1.4.1
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [872c559c] NNlib v0.7.4
  [276daf66] SpecialFunctions v0.10.3
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_ZEMXWf/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v2.0.2
  [6710c13c] AutoGrad v1.2.3
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.4.1
  [052768ef] CUDA v1.3.3
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] DataStructures v0.17.20
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.4.1
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [929cbde3] LLVM v2.0.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.7.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+16
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
kptr.jl	252.619232 seconds (18.75 M allocations: 1.103 GiB, 0.85% gc time)
gpu.jl	Knet.LibKnet8.libknet8 = "/home/pkgeval/.julia/artifacts/5e1e317677e88277f0ee67ab9e17587a8edc4f7a/libknet8"
readdir(artifact"libknet8") = ["libknet8.so"]
CuDevice(0): Tesla T4
length(CUDA.devices()) = 1
CUDA.capability(CUDA.device()) = v"7.5.0"
CUDA.warpsize(CUDA.device()) = 32
CUDA.find_toolkit() = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
CUDA.version() = v"11.0.0"
Mem.info() = (15638200320, 15843721216)
CUDA.synchronize() = nothing
NVML.driver_version() = v"450.36.6"
NVML.version() = v"11.0.0+450.36.6"
NVML.cuda_driver_version() = v"11.0.0"
NVML.memory_info(nvmldev) = (total = 15843721216, free = 15638200320, used = 205520896)
CUBLAS.handle() = Ptr{Nothing} @0x00000000097930d0
CUBLAS.version() = v"10.2.2"
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gpu.jl:3
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] top-level scope
      @ show.jl:891
   [14] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:39
   [15] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:8
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [18] macro expansion
      @ ./timing.jl:174 [inlined]
   [19] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [20] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [22] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [23] top-level scope
      @ none:6
   [24] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [25] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [26] _start()
      @ Base ./client.jl:484
  
  6.448927 seconds (3.09 M allocations: 173.916 MiB, 1.60% gc time)
distributions.jl	  2.587761 seconds (3.22 M allocations: 181.078 MiB, 3.48% gc time)
dropout.jl	 20.623410 seconds (6.28 M allocations: 391.815 MiB, 1.85% gc time)
gcnode.jl	gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gcnode.jl:8
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] (::RNN)(x::KnetArray{Float32,3})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328
   [15] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:18
   [16] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:11
   [18] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [19] macro expansion
      @ ./timing.jl:174 [inlined]
   [20] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [21] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [27] _start()
      @ Base ./client.jl:484
  
  2.783903 seconds (2.49 M allocations: 155.018 MiB, 2.68% gc time)
jld.jl	 33.484666 seconds (27.06 M allocations: 1.480 GiB, 4.37% gc time)
statistics.jl	 29.646664 seconds (23.29 M allocations: 1.367 GiB, 4.17% gc time)
bmm.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e024387f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e0242d33)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e0242b0c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e0242934)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e02423e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fd4e02418bb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fd4e02407d4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e024387f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e0242d33)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e0242b0c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e0242934)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e02423e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fd4e02418bb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fd4e02407d4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:8
  Got exception outside of a @test
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:41
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
   [33] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [34] macro expansion
      @ ./timing.jl:174 [inlined]
   [35] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [36] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [37] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [38] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [39] top-level scope
      @ none:6
   [40] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [41] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [42] _start()
      @ Base ./client.jl:484
  
 54.495854 seconds (43.47 M allocations: 2.487 GiB, 5.91% gc time)
serialize.jl	serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/serialize.jl:10
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] RNN
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328 [inlined]
   [15] (::var"#m1test#61")(M1::RNN, xgpu::KnetArray{Float32,3}, xcpu::Array{Float32,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:40
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:50
   [17] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:11
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [20] macro expansion
      @ ./timing.jl:174 [inlined]
   [21] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [22] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [28] _start()
      @ Base ./client.jl:484
  
  8.106295 seconds (6.84 M allocations: 391.771 MiB, 3.89% gc time)
loss.jl	
Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:17
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:18
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 1,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:19
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 2,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:20
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] #logsoftmax#46
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13 [inlined]
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:20
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:21
  Test threw exception
  Expression: isapprox(f(a, dims = 1), f(k, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:21
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:22
  Test threw exception
  Expression: isapprox(f(a, dims = 2), f(k, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:22
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{KnetArray{Float64,3}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:36
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{KnetArray{Float64,3}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:37
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [18] logsoftmax(x::KnetArray{Float64,3})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:37
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:39
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => d,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:40
  Test threw exception
  Expression: isapprox(f(a, dims = d), f(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:40
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:69
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 1,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:70
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 2,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:73
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 1), nll(a, indices, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:73
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:74
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 2), nll(a, indices, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:74
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:87
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:87
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:88
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:88
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:89
  Test threw exception
  Expression: isapprox(logsoftmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:89
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:90
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:90
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:91
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:91
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:92
  Test threw exception
  Expression: isapprox(∇logsoftmax(x, y2, dy, dims = 1), _cudnnSoftmaxBackward(y2, dy, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:92
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#70#80")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#70#80")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#71#81")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#71#81")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#72#82")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#72#82")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#73#83")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#73#83")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#74#84")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#74#84")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#75#85")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98 =# @gcheck _cudnnSoftmaxBackward(Param(y2), Param(dy), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#75#85")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:107
  Test threw exception
  Expression: isapprox(f(a, b, c), f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] nll
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38 [inlined]
   [20] (::var"#f#86")(w::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:107
   [22] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:108
  Test threw exception
  Expression: isapprox(∇f(a, b, c), ∇f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
 [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
 [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [33] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] macro expansion
    @ ./timing.jl:174 [inlined]
 [37] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [38] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [39] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [40] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [41] top-level scope
    @ none:6
 [42] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [43] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [44] _start()
    @ Base ./client.jl:484

Stacktrace:
  [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
  [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [4] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
  [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
  [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
  [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [10] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [11] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [12] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [13] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [14] macro expansion
    @ ./timing.jl:174 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [16] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [17] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [18] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [19] top-level scope
    @ none:6
 [20] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [21] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [22] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:110
  Test threw exception
  Expression: isapprox(∇∇fj(a, b, c, i), ∇∇fj(A, B, C, i))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
    [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [4] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
    [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
    [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
    [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [10] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [11] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [12] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
   [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
   [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
 82.366192 seconds (50.38 M allocations: 2.958 GiB, 4.04% gc time)
cuarray.jl	┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01c491f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01c4235)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01c3fdf)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01c3e21)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01c3830)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01bbdcc)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01bbcac)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01c491f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01c4235)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01c3fdf)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01c3e21)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01c3830)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01bbdcc)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01bbcac)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01cbb7f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01cb4b5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01cb26f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01cb0c1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01cad80)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01c938c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01c926c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01cbb7f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01cb4b5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01cb26f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01cb0c1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01cad80)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01c938c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01c926c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01dc4ff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01dbe43)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01dbc1c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01dba54)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01db797)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fd4e01db1cb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fd4e01da5a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01dc4ff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01dbe43)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01dbc1c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01dba54)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01db797)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fd4e01db1cb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fd4e01da5a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29 =# @gcheck permutedims(a3, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30 =# @gcheck permutedims(a3, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01ed78f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01ed085)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01ece2f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01ecc71)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01ec910)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01ea81c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01ea6fc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01ed78f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01ed085)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01ece2f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01ecc71)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01ec910)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fd4e01ea81c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fd4e01ea6fc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fd4e034db14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01fbedf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01fb7be)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01fb558)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01fb38b)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01fb058)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7fd4e01fa8f6)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e01fbedf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e01fb7be)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e01fb558)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e01fb38b)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e01fb058)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7fd4e01fa8f6)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
 [28] _unsafe_getindex!
    @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
 [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] getindex
    @ ./none:0 [inlined]
 [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16 =# @gcheck getindex(a3, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] getindex
      @ ./none:0 [inlined]
   [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34 =# @gcheck permutedims(a3, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e000d65f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e000cf15)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e000cc8f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e000caa1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e000c710)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e000d65f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e000cf15)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e000cc8f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e000caa1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e000c710)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [35] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(7, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(1, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(3, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(7, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(2, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(6, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(2, 1, 6) CartesianIndex(8, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(8, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(8, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(3, 8, 8)] == CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(7, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(3, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(7, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(2, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(6, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(2, 1, 6) CartesianIndex(8, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(8, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(8, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(3, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(6, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(5, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(7, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(7, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(3, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(4, 1, 8) CartesianIndex(6, 2, 8) … CartesianIndex(1, 7, 8) CartesianIndex(7, 8, 8)] == CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(6, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(5, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(7, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(7, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(3, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(4, 1, 8) CartesianIndex(6, 2, 8) … CartesianIndex(1, 7, 8) CartesianIndex(7, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.8971825807136722 0.9450281833998582 … 0.9791036734474439 0.9513855116821657]

[0.9253698196550153 0.7546854237057974 … 0.9942723471631816 0.9094018793756515]

[0.9016463000511816 0.8854980292059513 … 0.9600479713779235 0.7152994582155769]

[0.7497063586889201 0.8723861962361914 … 0.9551708917680659 0.9701694275358188]

[0.8374540042728753 0.945002476936575 … 0.9978669939566656 0.8595351787447907]

[0.7632817061946846 0.8500268922788998 … 0.9918248950102821 0.9006354269215457]

[0.790626644509614 0.6383648019782564 … 0.9311824239298419 0.7839933833852093]

[0.9643801091325752 0.8899861641317333 … 0.9708430913376049 0.8636299699248629], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(7, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(1, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(3, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(7, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(2, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(6, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(2, 1, 6) CartesianIndex(8, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(8, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(8, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(3, 8, 8)]) == ([0.8971825807136722 0.9450281833998582 … 0.9791036734474439 0.9513855116821657]

[0.9253698196550153 0.8685309142530628 … 0.9942723471631816 0.9094018793756515]

[0.9016463000511816 0.8854980292059513 … 0.9600479713779235 0.7152994582155769]

[0.7497063586889201 0.8723861962361914 … 0.9551708917680659 0.9701694275358188]

[0.8374540042728753 0.945002476936575 … 0.9978669939566656 0.8595351787447907]

[0.7632817061946846 0.8500268922788998 … 0.9918248950102821 0.9006354269215457]

[0.790626644509614 0.6383648019782564 … 0.9311824239298419 0.7839933833852093]

[0.9643801091325752 0.8899861641317333 … 0.9708430913376049 0.8636299699248629], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(7, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(3, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(7, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(2, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(6, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(2, 1, 6) CartesianIndex(8, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(8, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(8, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(3, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.09604787360040223 0.3707125702980525 … 0.026482724525160428 0.15026051387371075]

[0.2824517398381081 0.05854842280965844 … 0.07179180849239652 0.0054331138548899816]

[0.09233079278242329 0.04035805737332998 … 0.09538351857020655 0.16796072875899304]

[0.0019227506512073944 0.03574693433962084 … 0.02826660265135006 0.11244266757253207]

[0.21578039607178567 0.022186032724292426 … 0.19977746823446352 0.015427976549171607]

[0.018894476531450044 0.07866450062666797 … 0.09791646521125918 0.06453330478504493]

[0.033877092422178734 0.011081922493380691 … 0.05285698866197963 0.023415317080398124]

[0.07279449289918527 0.03217170164372152 … 0.010936969553554166 0.024217387078273145], CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(6, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(5, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(7, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(7, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(3, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(4, 1, 8) CartesianIndex(6, 2, 8) … CartesianIndex(1, 7, 8) CartesianIndex(7, 8, 8)]) == ([0.09604787360040223 0.3707125702980525 … 0.026482724525160428 0.15026051387371075]

[0.2824517398381081 0.05854842280965844 … 0.07179180849239652 0.0054331138548899816]

[0.09233079278242329 0.04035805737332998 … 0.09538351857020655 0.16796072875899304]

[0.0019227506512073944 0.03574693433962084 … 0.02826660265135006 0.11244266757253207]

[0.21578039607178567 0.022186032724292426 … 0.19977746823446352 0.015427976549171607]

[0.018894476531450044 0.07866450062666797 … 0.09791646521125918 0.06453330478504493]

[0.033877092422178734 0.011081922493380691 … 0.05285698866197963 0.023415317080398124]

[0.07279449289918527 0.03217170164372152 … 0.010936969553554166 0.024217387078273145], CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(6, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(5, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(7, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(7, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(3, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(4, 1, 8) CartesianIndex(6, 2, 8) … CartesianIndex(1, 7, 8) CartesianIndex(7, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 4, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 7, 6); CartesianIndex(2, 3, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 5, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 7, 8)] == CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 2, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 2, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 4, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 7, 6); CartesianIndex(2, 3, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 5, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 7, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 5, 1)]

CartesianIndex{3}[CartesianIndex(1, 1, 2); CartesianIndex(2, 8, 2); … ; CartesianIndex(7, 8, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 4, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 7, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 2, 5); CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 3, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 4, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 2, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8)] == CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 5, 1)]

CartesianIndex{3}[CartesianIndex(1, 1, 2); CartesianIndex(2, 8, 2); … ; CartesianIndex(7, 8, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 4, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 7, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 2, 5); CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 3, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 4, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 2, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9518973043488883; 0.9791036734474439; … ; 0.9513855116821657; 0.8971825807136722]

[0.9896158895729947; 0.8349159589230382; … ; 0.7748006162444034; 0.9253698196550153]

[0.8280029915185094; 0.6994274423817157; … ; 0.9600479713779235; 0.8854980292059513]

[0.9701694275358188; 0.9645585324447679; … ; 0.9901209311692714; 0.9810121732637724]

[0.8374540042728753; 0.8319794722330665; … ; 0.833447835828907; 0.8944312030560306]

[0.9202925962299462; 0.8756877496917939; … ; 0.9890591932044905; 0.955633934502099]

[0.9911614655817098; 0.7285969463960502; … ; 0.8831131381711574; 0.9128046166715218]

[0.9643801091325752; 0.9049837004435881; … ; 0.8058981291385683; 0.9678283624727231], CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 4, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 7, 6); CartesianIndex(2, 3, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 5, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 7, 8)]) == ([0.9518973043488883; 0.9791036734474439; … ; 0.9513855116821657; 0.8971825807136722]

[0.9896158895729947; 0.8685309142530628; … ; 0.7748006162444034; 0.9253698196550153]

[0.8280029915185094; 0.6315029306517563; … ; 0.9600479713779235; 0.8854980292059513]

[0.9701694275358188; 0.9645585324447679; … ; 0.9901209311692714; 0.9810121732637724]

[0.8374540042728753; 0.8319794722330665; … ; 0.833447835828907; 0.8944312030560306]

[0.9202925962299462; 0.8756877496917939; … ; 0.9890591932044905; 0.955633934502099]

[0.9911614655817098; 0.7285969463960502; … ; 0.8831131381711574; 0.9128046166715218]

[0.9643801091325752; 0.9049837004435881; … ; 0.8058981291385683; 0.9678283624727231], CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 2, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 2, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 4, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 7, 6); CartesianIndex(2, 3, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 5, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 7, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.041002551905847895; 0.3211107523109422; … ; 0.02353463000792999; 0.36599209305800606]

[0.3326179450800115; 0.10830565892395239; … ; 0.0054331138548899816; 0.05854842280965844]

[0.20957453670134663; 0.06481829580338427; … ; 0.04035805737332998; 0.09538351857020655]

[0.16808421398200135; 0.06626763471824693; … ; 0.02826660265135006; 0.11794387961763286]

[0.07404424658912045; 0.015427976549171607; … ; 0.19977746823446352; 0.21244826708304476]

[0.0299033132430222; 0.1114039037115433; … ; 0.09791646521125918; 0.18505818239863325]

[0.011081922493380691; 0.0702323997797829; … ; 0.023415317080398124; 0.18913324467620218]

[0.010936969553554166; 0.05892412955286508; … ; 0.024217387078273145; 0.13087256273225], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 5, 1)]

CartesianIndex{3}[CartesianIndex(1, 1, 2); CartesianIndex(2, 8, 2); … ; CartesianIndex(7, 8, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 4, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 7, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 2, 5); CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 3, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 4, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 2, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8)]) == ([0.041002551905847895; 0.3211107523109422; … ; 0.02353463000792999; 0.36599209305800606]

[0.3326179450800115; 0.10830565892395239; … ; 0.0054331138548899816; 0.05854842280965844]

[0.20957453670134663; 0.09890655189610964; … ; 0.04035805737332998; 0.09538351857020655]

[0.16808421398200135; 0.06626763471824693; … ; 0.02826660265135006; 0.11794387961763286]

[0.07404424658912045; 0.015427976549171607; … ; 0.19977746823446352; 0.21244826708304476]

[0.0299033132430222; 0.1114039037115433; … ; 0.09791646521125918; 0.18505818239863325]

[0.011081922493380691; 0.0702323997797829; … ; 0.023415317080398124; 0.18913324467620218]

[0.010936969553554166; 0.05892412955286508; … ; 0.024217387078273145; 0.13087256273225], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 5, 1)]

CartesianIndex{3}[CartesianIndex(1, 1, 2); CartesianIndex(2, 8, 2); … ; CartesianIndex(7, 8, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 4, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 7, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 2, 5); CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 3, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 4, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 2, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 2) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 3) CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 2)] == CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 2) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 2) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 3) CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 2)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 5); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 8) … CartesianIndex(2, 7, 4) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 7) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 2); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 3) CartesianIndex(8, 8, 8)] == CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 5); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 8) … CartesianIndex(2, 7, 4) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 7) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 2); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 3) CartesianIndex(8, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9643801091325752 0.7546854237057974 … 0.9896158895729947 0.9701694275358188; 0.9041755548994024 0.8319794722330665 … 0.9791036734474439 0.7285969463960502; … ; 0.8288313156076512 0.7405846508737928 … 0.9600479713779235 0.9513855116821657; 0.9253698196550153 0.8899861641317333 … 0.9678283624727231 0.9094018793756515], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 2) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 3) CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 2)]) == ([0.9643801091325752 0.7546854237057974 … 0.9896158895729947 0.9701694275358188; 0.9041755548994024 0.8685309142530628 … 0.9791036734474439 0.7285969463960502; … ; 0.8288313156076512 0.7405846508737928 … 0.9600479713779235 0.9513855116821657; 0.9253698196550153 0.8899861641317333 … 0.9678283624727231 0.9094018793756515], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 2) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 2) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 3) CartesianIndex(7, 8, 1); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 2)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.28584169491510414 0.011081922493380691 … 0.010936969553554166 0.33048020071746675; 0.207589938600391 0.05892412955286508 … 0.06626763471824693 0.015427976549171607; … ; 0.054192921383208636 0.03574693433962084 … 0.02826660265135006 0.0054331138548899816; 0.13087256273225 0.05854842280965844 … 0.09538351857020655 0.20471592219364232], CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 5); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 8) … CartesianIndex(2, 7, 4) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 7) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 2); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 3) CartesianIndex(8, 8, 8)]) == ([0.28584169491510414 0.011081922493380691 … 0.010936969553554166 0.33048020071746675; 0.207589938600391 0.05892412955286508 … 0.06626763471824693 0.015427976549171607; … ; 0.054192921383208636 0.03574693433962084 … 0.02826660265135006 0.0054331138548899816; 0.13087256273225 0.05854842280965844 … 0.09538351857020655 0.20471592219364232], CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 5); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 8) … CartesianIndex(2, 7, 4) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 7) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 2); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 3) CartesianIndex(8, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 46.105903 seconds (22.11 M allocations: 1.293 GiB, 2.87% gc time)
update.jl	┌ Warning: optimizers is deprecated, use sgd, adam etc. instead.
└ @ Knet.Train20 ~/.julia/packages/Knet/Mfd6L/src/train20/update.jl:598
 74.981001 seconds (58.80 M allocations: 2.995 GiB, 4.54% gc time)
linalg.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e00d6c4f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e00d6593)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e00d636c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e00d61a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e00d5ee7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7fd4e00d585f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e00d6c4f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e00d6593)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e00d636c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e00d61a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e00d5ee7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7fd4e00d585f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e00e64ef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e00e5e13)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e00e5bec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e00e5a14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e00e5757)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7fd4e00e50df)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fd4e00e64ef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7fd4e00e5e13)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7fd4e00e5bec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fd4e00e5a14)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fd4e00e5757)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7fd4e00e50df)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_33497.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
