Julia Version 1.6.0-DEV.680
Commit bcbb00004d (2020-08-20 17:48 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed Blosc ──────────────────────── v0.7.0
  Installed HDF5_jll ───────────────────── v1.10.5+5
  Installed Lz4_jll ────────────────────── v1.9.2+2
  Installed Blosc_jll ──────────────────── v1.14.3+1
  Installed MacroTools ─────────────────── v0.5.5
  Installed SpecialFunctions ───────────── v0.10.3
  Installed FFTW ───────────────────────── v1.2.4
  Installed URIParser ──────────────────── v0.4.1
  Installed CMake ──────────────────────── v1.2.0
  Installed Zstd_jll ───────────────────── v1.4.5+0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed PyCall ─────────────────────── v1.91.4
  Installed JSON ───────────────────────── v0.21.0
  Installed HDF5 ───────────────────────── v0.13.5
  Installed Compat ─────────────────────── v3.14.0
  Installed Reexport ───────────────────── v0.2.0
  Installed BinDeps ────────────────────── v1.0.1
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed CodecZlib ──────────────────── v0.7.0
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed Parsers ────────────────────── v1.0.10
  Installed VersionParsing ─────────────── v1.2.0
  Installed MAT ────────────────────────── v0.8.0
  Installed BufferedStreams ────────────── v1.0.0
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Conda ──────────────────────── v1.4.1
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed TranscodingStreams ─────────── v0.9.5
  Installed ADCME ──────────────────────── v0.5.9
Updating `~/.julia/environments/v1.6/Project.toml`
  [07b341a0] + ADCME v0.5.9
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [07b341a0] + ADCME v0.5.9
  [621f4979] + AbstractFFTs v0.5.0
  [9e28174c] + BinDeps v1.0.1
  [a74b3585] + Blosc v0.7.0
  [0b7ba130] + Blosc_jll v1.14.3+1
  [e1450e63] + BufferedStreams v1.0.0
  [631607c0] + CMake v1.2.0
  [944b1d66] + CodecZlib v0.7.0
  [34da2185] + Compat v3.14.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] + Conda v1.4.1
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+5
  [f67ccb44] + HDF5 v0.13.5
  [0234f1f7] + HDF5_jll v1.10.5+5
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [682c06a0] + JSON v0.21.0
  [5ced341a] + Lz4_jll v1.9.2+2
  [23992714] + MAT v0.8.0
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [69de0a69] + Parsers v1.0.10
  [438e738f] + PyCall v1.91.4
  [189a3867] + Reexport v0.2.0
  [276daf66] + SpecialFunctions v0.10.3
  [3bb67fe8] + TranscodingStreams v0.9.5
  [30578b45] + URIParser v0.4.1
  [81def892] + VersionParsing v1.2.0
  [83775a58] + Zlib_jll v1.2.11+15
  [3161d3a3] + Zstd_jll v1.4.5+0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building Conda ─→ `~/.julia/packages/Conda/3rPhK/deps/build.log`
   Building PyCall → `~/.julia/packages/PyCall/zqDXB/deps/build.log`
   Building CMake ─→ `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building HDF5 ──→ `~/.julia/packages/HDF5/hPEcL/deps/build.log`
   Building FFTW ──→ `~/.julia/packages/FFTW/DMUbN/deps/build.log`
   Building ADCME ─→ `~/.julia/packages/ADCME/DBZ10/deps/build.log`
    Testing ADCME
Status `/tmp/jl_mFfVWT/Project.toml`
  [07b341a0] ADCME v0.5.9
  [9e28174c] BinDeps v1.0.1
  [631607c0] CMake v1.2.0
  [7a1cc6ca] FFTW v1.2.4
  [23992714] MAT v0.8.0
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v0.22.0
  [438e738f] PyCall v1.91.4
  [276daf66] SpecialFunctions v0.10.3
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [9a3f8284] Random
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_mFfVWT/Manifest.toml`
  [07b341a0] ADCME v0.5.9
  [621f4979] AbstractFFTs v0.5.0
  [4fba245c] ArrayInterface v2.11.0
  [9e28174c] BinDeps v1.0.1
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [631607c0] CMake v1.2.0
  [944b1d66] CodecZlib v0.7.0
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.14.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] Conda v1.4.1
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.20
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.8.14
  [6a86dc24] FiniteDiff v2.6.0
  [f6369f11] ForwardDiff v0.10.12
  [f67ccb44] HDF5 v0.13.5
  [0234f1f7] HDF5_jll v1.10.5+5
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [682c06a0] JSON v0.21.0
  [d3d80556] LineSearches v7.1.0
  [5ced341a] Lz4_jll v1.9.2+2
  [23992714] MAT v0.8.0
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.7.0
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [77ba4419] NaNMath v0.3.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.22.0
  [bac558e1] OrderedCollections v1.3.0
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.10
  [85a6dd25] PositiveFactorizations v0.2.3
  [438e738f] PyCall v1.91.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.0
  [3bb67fe8] TranscodingStreams v0.9.5
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.2
  [81def892] VersionParsing v1.2.0
  [83775a58] Zlib_jll v1.2.11+15
  [3161d3a3] Zstd_jll v1.4.5+0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
WARNING: Method definition size(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:798 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:212.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition length(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:797 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:236.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition lastindex(PyCall.PyObject) in module PyCall at deprecated.jl:70 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:424.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition *(PyCall.PyObject, PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/pyoperators.jl:11 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/ops.jl:102.
  ** incremental compilation may be fatally broken for this module **

[ Info: You are using ADCME for the first time. Precompiling built-in custom operators may take some time...
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
┌ Warning: Cannot load /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/CustomOps/build/libadcme.so. Please recompile the shared library by `ADCME.precompile()` for using custom operators.
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ADCME.jl:95
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
MPI_INCLUDE_PATH and/or MPI_C_LIBRARIES is not set. MPI operators are not compiled.
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build
[1/17] Building CXX object CMakeFiles/adcme.dir/OT/src/sinkhorn.cpp.o
[2/17] Building CXX object CMakeFiles/adcme.dir/SparseScatterUpdate/SparseScatterUpdate.cpp.o
[3/17] Building CXX object CMakeFiles/adcme.dir/SparseToDense/SparseToDense.cpp.o
[4/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/SparseAccumulator.cpp.o
[5/17] Building CXX object CMakeFiles/adcme.dir/OT/SinkhornKnopp/SinkhornKnopp.cpp.o
[6/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/lru_cache.cpp.o
[7/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/Impl.cpp.o
[8/17] Building CXX object CMakeFiles/adcme.dir/TriLu/TriLu.cpp.o
[9/17] Building CXX object CMakeFiles/adcme.dir/SparseMatMul/SparseMatMul.cpp.o
[10/17] Building CXX object CMakeFiles/adcme.dir/SparseIndexing/SparseIndexing.cpp.o
[11/17] Building CXX object CMakeFiles/adcme.dir/SparseConcate/SparseConcate.cpp.o
[12/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Solve/Solve.cpp.o
[13/17] Building CXX object CMakeFiles/adcme.dir/SolveBatchedRhs/SolveBatchedRhs.cpp.o
[14/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Factorization/SparseFactorization.cpp.o
[15/17] Building CXX object CMakeFiles/adcme.dir/SparseLeastSquare/SparseLeastSquare.cpp.o
[16/17] Building CXX object CMakeFiles/adcme.dir/SparseSolver/SparseSolver.cpp.o
[17/17] Linking CXX shared library libadcme.so
2020-08-22 02:49:02.671468: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-22 02:49:02.714678: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-08-22 02:49:02.800809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15cd940 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-22 02:49:02.800874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✘] Julia path (Optional)

[Reason]
`julia` outputs nothing. This will break custom operator compilation.


[Instruction]
Add your julia binary path to your environment path, e.g. (Unix systems) 

export PATH=/opt/julia/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] Dynamic library path (Optional)

[Reason]
/home/pkgeval/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/pkgeval/.julia/conda/3/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/pkgeval/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/pkgeval/.julia/conda/3/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 10 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 12 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 5425 thread 0 bound to OS proc set 0
2020-08-22 02:49:03.412536: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
[ Info: Copy "/home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/AdeptCMakeLists.txt" to "/home/pkgeval/.julia/conda/3/lib/Adept-2/adept/CMakeLists.txt" ... 
[ Info: Remove /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Make /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Change directory into /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Cmake ... 
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
Use openblas library /home/pkgeval/.julia/conda/3/lib/libopenblas.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build
[ Info: Make ... 
[1/12] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o
[2/12] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o
[3/12] Building CXX object CMakeFiles/adept.dir/settings.cpp.o
[4/12] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o
[5/12] Building CXX object CMakeFiles/adept.dir/index.cpp.o
[6/12] Building CXX object CMakeFiles/adept.dir/Array.cpp.o
[7/12] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o
[8/12] Building CXX object CMakeFiles/adept.dir/inv.cpp.o
[9/12] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o
[10/12] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o
[11/12] Building CXX object CMakeFiles/adept.dir/solve.cpp.o
[12/12] Linking CXX shared library /home/pkgeval/.julia/conda/3/lib/libadept.so
∘ Add the following lines to CMakeLists.txt 

include_directories(${LIBDIR}/Adept-2/include)
find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR})
find_library(LIBOPENBLAS openblas HINTS ${LIBDIR})
message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}")
message("LIBOPENBLAS=${LIBOPENBLAS}")

∘ Add `${ADEPT_LIB_FILE}` and `${LIBOPENBLAS}` to `target_link_libraries`
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
ADEPT_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/libadept.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build
[1/2] Building CXX object CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o
[2/2] Linking CXX shared library libExtendedNn.so
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.7569805620321772, 0.19052749695567073, 0.27565057600661214, 0.5709964913354251, 0.6228050907142655, 0.9054896889254833, 0.4372300692833313, 0.8781510301328794, 0.7406488672649889, 0.4149371515524991]
2020-08-22 02:50:37.307394: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 20 rows and tolerance 0.

2020-08-22 02:50:37.307457: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 02:50:37.307470: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 02:50:37.307508: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-22 02:50:37.420114: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 1.

2020-08-22 02:50:37.420175: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 02:50:37.420188: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 02:50:37.420225: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-22 02:50:37.594383: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 0.

2020-08-22 02:50:37.594530: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 02:50:37.594576: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 02:50:37.594698: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
Test Summary:    | Pass  Total
sparse_assembler |    3      3
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = \(s::SparseTensor, o::PyObject, method::String) at sparse.jl:408
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/sparse.jl:408
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
2020-08-22 02:50:56.005896: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 1, maximum cache size = 999999

2020-08-22 02:50:56.070221: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 2, maximum cache size = 999999

Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
2020-08-22 02:50:56.233947: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
2020-08-22 02:50:56.234607: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_hhghOE" --port 0
tensorboard --logdir="/tmp/jl_AuWjxJ" --port 0
Test Summary: |
diary         | No tests
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = macro expansion at variable.jl:17 [inlined]
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:17
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:131
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:131
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:132
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:132
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6117 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6118 thread 2 bound to OS proc set 2
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = (::var"#45#46"{PyObject,Int64})() at core.jl:18
└ @ Main ~/.julia/packages/ADCME/DBZ10/test/core.jl:18
Test Summary:      | Pass  Total
control_dependency |    2      2
WARNING: Method definition body(Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:40 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:73.
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
2020-08-22 02:52:25.825974: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6346 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6348 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6347 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6345 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6355 thread 13 bound to OS proc set 13
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6352 thread 10 bound to OS proc set 10
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6358 thread 16 bound to OS proc set 16
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6354 thread 12 bound to OS proc set 12
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6351 thread 9 bound to OS proc set 9
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6357 thread 15 bound to OS proc set 15
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6350 thread 8 bound to OS proc set 8
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6353 thread 11 bound to OS proc set 11
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6363 thread 21 bound to OS proc set 21
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6361 thread 19 bound to OS proc set 19
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6362 thread 20 bound to OS proc set 20
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6360 thread 18 bound to OS proc set 18
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6359 thread 17 bound to OS proc set 17
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6349 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6356 thread 14 bound to OS proc set 14
┌ Info: Timeline information saved in test.json
│ - Open Chrome and navigate to chrome://tracing
└ - Load the timeline file
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
[ Info: (1/4)Intializing TensorArray...
[ Info: (2/4)Parsing Condition...
[ Info: (3/4)Parsing Main Loop...
[ Info: (4/4)Postprocessing Results...
Newton-Raphson with absolute tolerance = 1.0e-12 and relative tolerance = 1.0e-12
ITER  2 >>> Error = 15.652475842498529 | Relative Error = 15.652475842498529
ITER  3 >>> Error = 64.928788679993914 | Relative Error = 15.652475842498529
ITER  4 >>> Error = 15.489950495968388 | Relative Error = 64.928788679993914
ITER  5 >>> Error = 2.2725864326069174 | Relative Error = 15.489950495968388
ITER  6 >>> Error = 0.084320075161598992 | Relative Error = 2.2725864326069174
ITER  7 >>> Error = 0.00013179440739372649 | Relative Error = 0.084320075161598992
ITER  8 >>> Error = 3.2366684481841166e-10 | Relative Error = 0.00013179440739372649
ITER  9 >>> Error = 0 | Relative Error = 3.2366684481841166e-10
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 7, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 12, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 12, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390849360328797], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996034007038], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999998577], 43, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.4584075016314103], 24, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:50
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:50
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#468"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f8140201d40>), ADCME.var"#df#469"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f8140201d40>), ADCME.var"#c#470"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64}([0.7569805620321772, 0.19052749695567073], Any[], Any[], 0, 0), ADCME.var"#dc#473"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64,Int64,Int64}([0.7569805620321772, 0.19052749695567073], Any[], Any[], 0, 2, 0, 0), [0.7569805620321772, 0.19052749695567073])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
[ Info: Optimization starts...
iter 1, current loss = 10572.711324381025
[ Info: (0, 10572.711324381025)
================== STEP 0 ==================
iter 2, current loss = 8.675505946308887e11
iter 3, current loss = 4074.846140231297
[ Info: (1, 4074.846140231297)
================== STEP 1 ==================
iter 4, current loss = 3664.524347225892
iter 5, current loss = 2473.7333914643827
iter 6, current loss = 7331.687802899502
iter 7, current loss = 1995.4037867248812
[ Info: (2, 1995.4037867248812)
================== STEP 2 ==================
iter 8, current loss = 1988.9932016647451
iter 9, current loss = 1963.4540028218303
iter 10, current loss = 1838.233402150319
iter 11, current loss = 1274.0152373693732
iter 12, current loss = 0.04537787994035152
iter 13, current loss = 9.11878621053724e-20
[ Info: (3, 9.11878621053724e-20)
================== STEP 3 ==================
iter 14, current loss = 8.240224434505031e-18
iter 15, current loss = 8.986979944413185e-20
[ Info: (4, 8.986979944413185e-20)
================== STEP 4 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
[ Info: Optimization starts...
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
┌ Warning: θ is not a PyObject, no gradients is available
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/optim.jl:591
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
[ Info: Optimization starts...
iter 1, current loss = 0.7723660851612438
[ Info: (0, 0.7723660851612438)
================== STEP 0 ==================
iter 2, current loss = 38532.110875561215
iter 3, current loss = 0.7570438689673614
iter 4, current loss = 0.6659670644459369
[ Info: (1, 0.6659670644459369)
================== STEP 1 ==================
iter 5, current loss = 0.6551715540530829
iter 6, current loss = 0.6139200952249482
iter 7, current loss = 0.4490198881402906
iter 8, current loss = 29.210162136797017
iter 9, current loss = 0.4467590824850063
[ Info: (2, 0.4467590824850063)
================== STEP 2 ==================
iter 10, current loss = 0.4699543051068085
iter 11, current loss = 0.4023371505122077
[ Info: (3, 0.4023371505122077)
================== STEP 3 ==================
iter 12, current loss = 0.26851909954526176
iter 13, current loss = 11.386442395099383
iter 14, current loss = 0.2672758569135996
[ Info: (4, 0.2672758569135996)
================== STEP 4 ==================
iter 15, current loss = 0.1885805006376439
iter 16, current loss = 0.5155187217753804
iter 17, current loss = 0.19775951126376834
[ Info: (5, 0.19775951126376834)
================== STEP 5 ==================
iter 18, current loss = 0.370530961648342
iter 19, current loss = 0.14938046986252423
iter 20, current loss = 0.09881396003111155
iter 21, current loss = 0.09584133858075981
[ Info: (6, 0.09584133858075981)
================== STEP 6 ==================
iter 22, current loss = 0.1602898123007335
iter 23, current loss = 0.08980322488287262
[ Info: (7, 0.08980322488287262)
================== STEP 7 ==================
iter 24, current loss = 0.07583475003192908
iter 25, current loss = 0.349899011622751
iter 26, current loss = 0.07499165184075345
[ Info: (8, 0.07499165184075345)
================== STEP 8 ==================
iter 27, current loss = 0.05622497103868619
iter 28, current loss = 0.09098139993007036
iter 29, current loss = 0.0458810207978507
[ Info: (9, 0.0458810207978507)
================== STEP 9 ==================
iter 30, current loss = 0.022550597575268987
iter 31, current loss = 0.1311006067597793
iter 32, current loss = 0.023478280610120847
[ Info: (10, 0.023478280610120847)
================== STEP 10 ==================
iter 33, current loss = 0.010676634855025239
iter 34, current loss = 0.008279847476104345
[ Info: (11, 0.008279847476104345)
================== STEP 11 ==================
iter 35, current loss = 0.01760970351584143
iter 36, current loss = 0.005814245799839303
[ Info: (12, 0.005814245799839303)
================== STEP 12 ==================
iter 37, current loss = 0.003925248859339938
iter 38, current loss = 0.003917434217067361
[ Info: (13, 0.003917434217067361)
================== STEP 13 ==================
iter 39, current loss = 0.0024883063541898255
iter 40, current loss = 5.828205984729886e-5
iter 41, current loss = 0.058928294456163516
iter 42, current loss = 2.8490561808679202e-5
[ Info: (14, 2.8490561808679202e-5)
================== STEP 14 ==================
iter 43, current loss = 6.06928192947062e-6
iter 44, current loss = 7.766460050412392e-5
iter 45, current loss = 3.104701511581619e-7
[ Info: (15, 3.104701511581619e-7)
================== STEP 15 ==================
iter 46, current loss = 4.650056788707473e-7
iter 47, current loss = 5.336456817163418e-9
[ Info: (16, 5.336456817163418e-9)
================== STEP 16 ==================
iter 48, current loss = 8.107873830444617e-12
iter 49, current loss = 7.752184822528273e-8
iter 50, current loss = 1.173615487037898e-13
[ Info: (17, 1.173615487037898e-13)
================== STEP 17 ==================
iter 51, current loss = 1.8759541413454954e-18
iter 52, current loss = 1.8590568345403487e-12
iter 53, current loss = 1.4100274848926749e-21
[ Info: (18, 1.4100274848926749e-21)
================== STEP 18 ==================
iter 54, current loss = 8.756849086018994e-28
iter 55, current loss = 3.0814879110195774e-31
[ Info: (19, 3.0814879110195774e-31)
================== STEP 19 ==================
[ Info: Optimization starts...
iter 1, current loss = 0.7723660851612438
[ Info: (0, 0.7723660851612438)
================== STEP 0 ==================
iter 2, current loss = 345.51300863136237
iter 3, current loss = 0.7011864842223776
[ Info: (1, 0.7011864842223776)
================== STEP 1 ==================
iter 4, current loss = 0.694564272506328
iter 5, current loss = 0.661004656430182
[ Info: (2, 0.661004656430182)
================== STEP 2 ==================
iter 6, current loss = 0.6584491642000029
iter 7, current loss = 1.1425135659824255
iter 8, current loss = 0.5876954958680676
[ Info: (3, 0.5876954958680676)
================== STEP 3 ==================
iter 9, current loss = 0.5757898125387025
iter 10, current loss = 0.5411807163218406
[ Info: (4, 0.5411807163218406)
================== STEP 4 ==================
iter 11, current loss = 0.38501662488417715
iter 12, current loss = 115.34734945233308
iter 13, current loss = 0.536789384505396
iter 14, current loss = 6.367121937434212
iter 15, current loss = 0.5176391723029835
iter 16, current loss = 0.4847856498612042
iter 17, current loss = 0.4267883537297195
iter 18, current loss = 0.3155492010865811
iter 19, current loss = 0.3140883673361853
[ Info: (5, 0.3140883673361853)
================== STEP 5 ==================
iter 20, current loss = 0.30293332546194407
iter 21, current loss = 0.3004714667125831
[ Info: (6, 0.3004714667125831)
================== STEP 6 ==================
iter 22, current loss = 0.28948525729518076
iter 23, current loss = 0.17346899883735292
[ Info: (7, 0.17346899883735292)
================== STEP 7 ==================
iter 24, current loss = 0.16583939913414664
iter 25, current loss = 0.16459769405851568
[ Info: (8, 0.16459769405851568)
================== STEP 8 ==================
iter 26, current loss = 0.16448645975562298
iter 27, current loss = 0.1543113265216835
iter 28, current loss = 0.11860176487029461
[ Info: (9, 0.11860176487029461)
================== STEP 9 ==================
iter 29, current loss = 0.11170715165679077
iter 30, current loss = 0.11136995751933948
[ Info: (10, 0.11136995751933948)
================== STEP 10 ==================
iter 31, current loss = 0.060261385746320575
iter 32, current loss = 0.05800084473772929
[ Info: (11, 0.05800084473772929)
================== STEP 11 ==================
iter 33, current loss = 0.03119933518349397
iter 34, current loss = 0.02524904530889585
[ Info: (12, 0.02524904530889585)
================== STEP 12 ==================
iter 35, current loss = 0.024760597628199557
iter 36, current loss = 0.26112292287148753
iter 37, current loss = 0.020913292966781894
iter 38, current loss = 0.11294338103474376
iter 39, current loss = 0.014657684873818369
iter 40, current loss = 0.01205885604006237
[ Info: (13, 0.01205885604006237)
================== STEP 13 ==================
iter 41, current loss = 0.0144290041058909
iter 42, current loss = 0.00919392535609037
[ Info: (14, 0.00919392535609037)
================== STEP 14 ==================
iter 43, current loss = 0.008335110498222194
iter 44, current loss = 0.001893139175274062
[ Info: (15, 0.001893139175274062)
================== STEP 15 ==================
iter 45, current loss = 0.0017496323203151335
iter 46, current loss = 0.0017016878238523105
[ Info: (16, 0.0017016878238523105)
================== STEP 16 ==================
iter 47, current loss = 0.0017013781753635131
iter 48, current loss = 4.020043352586621e-5
[ Info: (17, 4.020043352586621e-5)
================== STEP 17 ==================
iter 49, current loss = 0.06623574692430462
iter 50, current loss = 3.956943884027998e-5
[ Info: (18, 3.956943884027998e-5)
================== STEP 18 ==================
iter 51, current loss = 3.9551160855237416e-5
iter 52, current loss = 3.742429174889666e-5
[ Info: (19, 3.742429174889666e-5)
================== STEP 19 ==================
iter 53, current loss = 2.8985527104041557e-6
iter 54, current loss = 7.832334570199253e-8
[ Info: (20, 7.832334570199253e-8)
================== STEP 20 ==================
iter 55, current loss = 3.148964545188401e-7
iter 56, current loss = 8.37805670616593e-9
[ Info: (21, 8.37805670616593e-9)
================== STEP 21 ==================
iter 57, current loss = 8.376676084381845e-9
iter 58, current loss = 3.954610224733449e-10
[ Info: (22, 3.954610224733449e-10)
================== STEP 22 ==================
iter 59, current loss = 7.627484551921589e-5
iter 60, current loss = 2.5135250280697666e-14
[ Info: (23, 2.5135250280697666e-14)
================== STEP 23 ==================
iter 61, current loss = 1.6457130190113868e-14
iter 62, current loss = 2.6398466008446017e-15
[ Info: (24, 2.6398466008446017e-15)
================== STEP 24 ==================
iter 63, current loss = 2.6394024335303567e-15
iter 64, current loss = 3.115338891382255e-18
[ Info: (25, 3.115338891382255e-18)
================== STEP 25 ==================
iter 65, current loss = 1.121623990186535e-14
iter 66, current loss = 3.0577895915202285e-18
[ Info: (26, 3.0577895915202285e-18)
================== STEP 26 ==================
iter 67, current loss = 3.0572908482911114e-18
iter 68, current loss = 3.614566758490685e-16
iter 69, current loss = 1.5120048110298816e-23
[ Info: (27, 1.5120048110298816e-23)
================== STEP 27 ==================
iter 70, current loss = 3.723346116060321e-18
iter 71, current loss = 0.0
[ Info: (28, 0.0)
================== STEP 28 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[ Info: 3.900395163047295e-8
[2.6873403110589567, 2.2848777584058286, 1.959485177894072, 1.695402405085309, 1.480263493197685, 1.304318508155104, 1.1598475045894157, 1.0407152651051803, 0.9420302552703156, 0.8598815076342153]
[2.6873403110589567, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.4802634543798443, 1.3043184684311486, 1.159847465406238, 1.0407152273674067, 0.9420302195019173, 0.8598814740954399]
[ Info: 1.74923517585932e-6
[2.6873403110589567, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722332, 1.7903868796137, 1.6665331065514706, 1.5498999348193685, 1.4403938823398208]
[2.6873403110589567, 2.519680372297153, 2.3591806721463433, 2.205949060790531, 2.0600593252906663, 1.9215446484117813, 1.7903894445161121, 1.666535679326616, 1.5499024452536934, 1.4403964019318742]
[ Info: 0.009280891261506044
[2.6873403110589567, 2.5196803348281445, 2.407655825231478, 2.3197815374114255, 2.2461502831672484, 2.1821637837734777, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.6873403110589567, 2.52894669594942, 2.420490642269895, 2.334573816587063, 2.262184980528145, 2.199051744362444, 2.142753602200173, 2.091763168313902, 2.0450438762274734, 2.001854279772373]
[ Info: 0.0002640108007748801
[2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567]
[2.6873403110589567, 2.6872637777504984, 2.6871862715585118, 2.687108108244675, 2.6870294441458276, 2.6869503723706374, 2.686870954600783, 2.6867912346415777, 2.686711245167153, 2.686631011454236]
ADCME.Optimizer.RMSProp: 
[2.6873403110589567, 2.1809229506849572, 1.876707980129773, 1.6546592408302836, 1.479244033062772, 1.334696176675614, 1.2124398515964887, 1.1071870862263171, 1.015408944687647, 0.9346163191023285]
ADCME.Optimizer.AMSGrad: 
[2.6873403110589567, 2.180931270734746, 1.6124928714759128, 1.108615178036389, 0.7379095523937292, 0.5260637392759812, 0.4585161239500093, 0.48774999629589677, 0.5512317022689825, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.6873403110589567, 2.4425702565335135, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870792, 1.3669096060903072]
ADCME.Optimizer.Momentum: 
[2.6873403110589567, 0.5561138694752268, 1.901919174485902, 1.5251751312785733, 0.0420157941282293, 1.107065572875359, 0.9972859136071747, 0.092505967405753, 0.8373703084967706, 0.9155307151492693]
ADCME.Optimizer.Nesterov: 
[2.6873403110589567, 1.959349802300281, 1.270153711798689, 0.7838060906690358, 0.5406336834135216, 0.48898653622901855, 0.5361697434507271, 0.593802848884102, 0.6052577936273842, 0.553136858054489]
ADCME.Optimizer.RADAM: 
[2.6873403110589567, 2.2848777584058286, 1.9432397781298896, 1.6552856125616948, 1.4144226819237642, 1.41260788266853, 1.409924914461023, 1.40654531582648, 1.4025672017224886, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.6873403110589567, 2.51968033219294, 2.3622082113112657, 2.2144819560814186, 2.076059233397677, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.6066663584779952, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
WARNING: Method definition f(Any, Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:2 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:13.
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
ActNorm: initializing s and t...
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = tril(o::PyObject, num::Int64) at ops.jl:1136
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1136
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = triu(o::PyObject, num::Int64) at ops.jl:1152
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1152
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Pass  Total
NeuralCouplingFlow |    2      2
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
    Testing ADCME tests passed 
