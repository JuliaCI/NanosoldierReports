Julia Version 1.6.0-DEV.699
Commit 87bf13b792 (2020-08-22 14:55 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed Lz4_jll ────────────────────── v1.9.2+2
  Installed Reexport ───────────────────── v0.2.0
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed Compat ─────────────────────── v3.14.0
  Installed Conda ──────────────────────── v1.4.1
  Installed TranscodingStreams ─────────── v0.9.5
  Installed HDF5 ───────────────────────── v0.13.5
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed MacroTools ─────────────────── v0.5.5
  Installed Blosc_jll ──────────────────── v1.14.3+1
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Blosc ──────────────────────── v0.7.0
  Installed SpecialFunctions ───────────── v0.10.3
  Installed MAT ────────────────────────── v0.8.0
  Installed Zstd_jll ───────────────────── v1.4.5+0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed VersionParsing ─────────────── v1.2.0
  Installed Parsers ────────────────────── v1.0.10
  Installed CMake ──────────────────────── v1.2.0
  Installed BinDeps ────────────────────── v1.0.1
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed FFTW ───────────────────────── v1.2.4
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed HDF5_jll ───────────────────── v1.10.5+5
  Installed PyCall ─────────────────────── v1.91.4
  Installed JSON ───────────────────────── v0.21.0
  Installed BufferedStreams ────────────── v1.0.0
  Installed URIParser ──────────────────── v0.4.1
  Installed ADCME ──────────────────────── v0.5.9
Updating `~/.julia/environments/v1.6/Project.toml`
  [07b341a0] + ADCME v0.5.9
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [07b341a0] + ADCME v0.5.9
  [621f4979] + AbstractFFTs v0.5.0
  [9e28174c] + BinDeps v1.0.1
  [a74b3585] + Blosc v0.7.0
  [0b7ba130] + Blosc_jll v1.14.3+1
  [e1450e63] + BufferedStreams v1.0.0
  [631607c0] + CMake v1.2.0
  [944b1d66] + CodecZlib v0.7.0
  [34da2185] + Compat v3.14.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] + Conda v1.4.1
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+5
  [f67ccb44] + HDF5 v0.13.5
  [0234f1f7] + HDF5_jll v1.10.5+5
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [682c06a0] + JSON v0.21.0
  [5ced341a] + Lz4_jll v1.9.2+2
  [23992714] + MAT v0.8.0
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [69de0a69] + Parsers v1.0.10
  [438e738f] + PyCall v1.91.4
  [189a3867] + Reexport v0.2.0
  [276daf66] + SpecialFunctions v0.10.3
  [3bb67fe8] + TranscodingStreams v0.9.5
  [30578b45] + URIParser v0.4.1
  [81def892] + VersionParsing v1.2.0
  [83775a58] + Zlib_jll v1.2.11+15
  [3161d3a3] + Zstd_jll v1.4.5+0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building Conda ─→ `~/.julia/packages/Conda/3rPhK/deps/build.log`
   Building PyCall → `~/.julia/packages/PyCall/zqDXB/deps/build.log`
   Building CMake ─→ `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building HDF5 ──→ `~/.julia/packages/HDF5/hPEcL/deps/build.log`
   Building FFTW ──→ `~/.julia/packages/FFTW/DMUbN/deps/build.log`
   Building ADCME ─→ `~/.julia/packages/ADCME/DBZ10/deps/build.log`
    Testing ADCME
Status `/tmp/jl_yt2q6H/Project.toml`
  [07b341a0] ADCME v0.5.9
  [9e28174c] BinDeps v1.0.1
  [631607c0] CMake v1.2.0
  [7a1cc6ca] FFTW v1.2.4
  [23992714] MAT v0.8.0
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v0.22.0
  [438e738f] PyCall v1.91.4
  [276daf66] SpecialFunctions v0.10.3
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [9a3f8284] Random
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_yt2q6H/Manifest.toml`
  [07b341a0] ADCME v0.5.9
  [621f4979] AbstractFFTs v0.5.0
  [4fba245c] ArrayInterface v2.11.0
  [9e28174c] BinDeps v1.0.1
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [631607c0] CMake v1.2.0
  [944b1d66] CodecZlib v0.7.0
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.14.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] Conda v1.4.1
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.20
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.8.14
  [6a86dc24] FiniteDiff v2.6.0
  [f6369f11] ForwardDiff v0.10.12
  [f67ccb44] HDF5 v0.13.5
  [0234f1f7] HDF5_jll v1.10.5+5
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [682c06a0] JSON v0.21.0
  [d3d80556] LineSearches v7.1.0
  [5ced341a] Lz4_jll v1.9.2+2
  [23992714] MAT v0.8.0
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.7.0
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [77ba4419] NaNMath v0.3.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.22.0
  [bac558e1] OrderedCollections v1.3.0
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.10
  [85a6dd25] PositiveFactorizations v0.2.3
  [438e738f] PyCall v1.91.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.0
  [3bb67fe8] TranscodingStreams v0.9.5
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.2
  [81def892] VersionParsing v1.2.0
  [83775a58] Zlib_jll v1.2.11+15
  [3161d3a3] Zstd_jll v1.4.5+0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
WARNING: Method definition size(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:798 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:212.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition length(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:797 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:236.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition lastindex(PyCall.PyObject) in module PyCall at deprecated.jl:70 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:424.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition *(PyCall.PyObject, PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/pyoperators.jl:11 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/ops.jl:102.
  ** incremental compilation may be fatally broken for this module **

[ Info: You are using ADCME for the first time. Precompiling built-in custom operators may take some time...
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
┌ Warning: Cannot load /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/CustomOps/build/libadcme.so. Please recompile the shared library by `ADCME.precompile()` for using custom operators.
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ADCME.jl:95
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
MPI_INCLUDE_PATH and/or MPI_C_LIBRARIES is not set. MPI operators are not compiled.
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build
[1/17] Building CXX object CMakeFiles/adcme.dir/SparseToDense/SparseToDense.cpp.o
[2/17] Building CXX object CMakeFiles/adcme.dir/OT/src/sinkhorn.cpp.o
[3/17] Building CXX object CMakeFiles/adcme.dir/TriLu/TriLu.cpp.o
[4/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/SparseAccumulator.cpp.o
[5/17] Building CXX object CMakeFiles/adcme.dir/SparseConcate/SparseConcate.cpp.o
[6/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/lru_cache.cpp.o
[7/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/Impl.cpp.o
[8/17] Building CXX object CMakeFiles/adcme.dir/SparseScatterUpdate/SparseScatterUpdate.cpp.o
[9/17] Building CXX object CMakeFiles/adcme.dir/OT/SinkhornKnopp/SinkhornKnopp.cpp.o
[10/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Solve/Solve.cpp.o
[11/17] Building CXX object CMakeFiles/adcme.dir/SparseIndexing/SparseIndexing.cpp.o
[12/17] Building CXX object CMakeFiles/adcme.dir/SparseMatMul/SparseMatMul.cpp.o
[13/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Factorization/SparseFactorization.cpp.o
[14/17] Building CXX object CMakeFiles/adcme.dir/SolveBatchedRhs/SolveBatchedRhs.cpp.o
[15/17] Building CXX object CMakeFiles/adcme.dir/SparseLeastSquare/SparseLeastSquare.cpp.o
[16/17] Building CXX object CMakeFiles/adcme.dir/SparseSolver/SparseSolver.cpp.o
[17/17] Linking CXX shared library libadcme.so
2020-08-22 18:33:45.836573: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-22 18:33:45.980475: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-08-22 18:33:46.052897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xcf7820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-22 18:33:46.053396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✘] Julia path (Optional)

[Reason]
`julia` outputs nothing. This will break custom operator compilation.


[Instruction]
Add your julia binary path to your environment path, e.g. (Unix systems) 

export PATH=/opt/julia/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] Dynamic library path (Optional)

[Reason]
/home/pkgeval/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/pkgeval/.julia/conda/3/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/pkgeval/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/pkgeval/.julia/conda/3/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 10 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 12 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 5425 thread 0 bound to OS proc set 0
2020-08-22 18:33:46.584630: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
[ Info: Copy "/home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/AdeptCMakeLists.txt" to "/home/pkgeval/.julia/conda/3/lib/Adept-2/adept/CMakeLists.txt" ... 
[ Info: Remove /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Make /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Change directory into /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Cmake ... 
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
Use openblas library /home/pkgeval/.julia/conda/3/lib/libopenblas.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build
[ Info: Make ... 
[1/12] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o
[2/12] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o
[3/12] Building CXX object CMakeFiles/adept.dir/settings.cpp.o
[4/12] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o
[5/12] Building CXX object CMakeFiles/adept.dir/index.cpp.o
[6/12] Building CXX object CMakeFiles/adept.dir/Array.cpp.o
[7/12] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o
[8/12] Building CXX object CMakeFiles/adept.dir/inv.cpp.o
[9/12] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o
[10/12] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o
[11/12] Building CXX object CMakeFiles/adept.dir/solve.cpp.o
[12/12] Linking CXX shared library /home/pkgeval/.julia/conda/3/lib/libadept.so
∘ Add the following lines to CMakeLists.txt 

include_directories(${LIBDIR}/Adept-2/include)
find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR})
find_library(LIBOPENBLAS openblas HINTS ${LIBDIR})
message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}")
message("LIBOPENBLAS=${LIBOPENBLAS}")

∘ Add `${ADEPT_LIB_FILE}` and `${LIBOPENBLAS}` to `target_link_libraries`
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
ADEPT_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/libadept.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build
[1/2] Building CXX object CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o
[2/2] Linking CXX shared library libExtendedNn.so
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.5001896295700765, 0.283233883229433, 0.8053591003913558, 0.4340554042666629, 0.8589819502350404, 0.7033414011045163, 0.7775417769534061, 0.4080478147811122, 0.15742919666664656, 0.028353735239857958]
2020-08-22 18:35:19.902828: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 20 rows and tolerance 0.

2020-08-22 18:35:19.902987: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 18:35:19.903014: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 18:35:19.903071: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-22 18:35:20.019529: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 1.

2020-08-22 18:35:20.019601: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 18:35:20.019617: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 18:35:20.019648: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-22 18:35:20.215340: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 0.

2020-08-22 18:35:20.215411: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-22 18:35:20.215426: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-22 18:35:20.215474: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
Test Summary:    | Pass  Total
sparse_assembler |    3      3
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = \(s::SparseTensor, o::PyObject, method::String) at sparse.jl:408
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/sparse.jl:408
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
2020-08-22 18:35:38.957305: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 1, maximum cache size = 999999

2020-08-22 18:35:39.094250: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 2, maximum cache size = 999999

Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
2020-08-22 18:35:39.318502: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
2020-08-22 18:35:39.319388: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_4hNuOp" --port 0
tensorboard --logdir="/tmp/jl_F1EAlP" --port 0
Test Summary: |
diary         | No tests
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = macro expansion at variable.jl:17 [inlined]
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:17
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:131
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:131
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:132
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:132
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6118 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6117 thread 2 bound to OS proc set 2
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = (::var"#45#46"{PyObject,Int64})() at core.jl:18
└ @ Main ~/.julia/packages/ADCME/DBZ10/test/core.jl:18
Test Summary:      | Pass  Total
control_dependency |    2      2
WARNING: Method definition body(Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:40 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:73.
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
2020-08-22 18:37:04.722729: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6345 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6348 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6346 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6347 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6349 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6351 thread 9 bound to OS proc set 9
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6350 thread 8 bound to OS proc set 8
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6352 thread 10 bound to OS proc set 10
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6355 thread 13 bound to OS proc set 13
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6356 thread 14 bound to OS proc set 14
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6353 thread 11 bound to OS proc set 11
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6354 thread 12 bound to OS proc set 12
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6359 thread 17 bound to OS proc set 17
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6357 thread 15 bound to OS proc set 15
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6358 thread 16 bound to OS proc set 16
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6360 thread 18 bound to OS proc set 18
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6361 thread 19 bound to OS proc set 19
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6362 thread 20 bound to OS proc set 20
OMP: Info #250: KMP_AFFINITY: pid 5425 tid 6363 thread 21 bound to OS proc set 21
┌ Info: Timeline information saved in test.json
│ - Open Chrome and navigate to chrome://tracing
└ - Load the timeline file
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
[ Info: (1/4)Intializing TensorArray...
[ Info: (2/4)Parsing Condition...
[ Info: (3/4)Parsing Main Loop...
[ Info: (4/4)Postprocessing Results...
Newton-Raphson with absolute tolerance = 1.0e-12 and relative tolerance = 1.0e-12
ITER  2 >>> Error = 15.652475842498529 | Relative Error = 15.652475842498529
ITER  3 >>> Error = 64.928788679993914 | Relative Error = 15.652475842498529
ITER  4 >>> Error = 15.489950495968388 | Relative Error = 64.928788679993914
ITER  5 >>> Error = 2.2725864326069174 | Relative Error = 15.489950495968388
ITER  6 >>> Error = 0.084320075161598992 | Relative Error = 2.2725864326069174
ITER  7 >>> Error = 0.00013179440739372649 | Relative Error = 0.084320075161598992
ITER  8 >>> Error = 3.2366684481841166e-10 | Relative Error = 0.00013179440739372649
ITER  9 >>> Error = 0 | Relative Error = 3.2366684481841166e-10
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 6, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 26, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 4, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390849781175229], 20, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996180613778], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999997995], 42, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.4584075016314099], 25, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:50
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:50
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#468"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7fa848413b90>), ADCME.var"#df#469"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7fa848413b90>), ADCME.var"#c#470"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64}([0.5001896295700765, 0.283233883229433], Any[], Any[], 0, 0), ADCME.var"#dc#473"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64,Int64,Int64}([0.5001896295700765, 0.283233883229433], Any[], Any[], 0, 2, 0, 0), [0.5001896295700765, 0.283233883229433])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
[ Info: Optimization starts...
iter 1, current loss = 9822.978321995284
[ Info: (0, 9822.978321995284)
================== STEP 0 ==================
iter 2, current loss = 8.665077758720916e11
iter 3, current loss = 3467.2515337579616
[ Info: (1, 3467.2515337579616)
================== STEP 1 ==================
iter 4, current loss = 3175.4049380570223
iter 5, current loss = 2324.3633799660106
iter 6, current loss = 5661.431382616659
iter 7, current loss = 1971.14618977944
[ Info: (2, 1971.14618977944)
================== STEP 2 ==================
iter 8, current loss = 1964.7431757127697
iter 9, current loss = 1939.2352855251056
iter 10, current loss = 1814.1958204831692
iter 11, current loss = 1251.4981426830789
iter 12, current loss = 0.5009389224111068
iter 13, current loss = 2.142843437588011e-21
[ Info: (3, 2.142843437588011e-21)
================== STEP 3 ==================
iter 14, current loss = 8.184591215277132e-18
iter 15, current loss = 2.1123022560656255e-21
[ Info: (4, 2.1123022560656255e-21)
================== STEP 4 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
[ Info: Optimization starts...
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
┌ Warning: θ is not a PyObject, no gradients is available
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/optim.jl:591
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
[ Info: Optimization starts...
iter 1, current loss = 14.868382182867341
[ Info: (0, 14.868382182867341)
================== STEP 0 ==================
iter 2, current loss = 1.1837576249369413e8
iter 3, current loss = 14.77003287602376
iter 4, current loss = 0.8561141604166598
[ Info: (1, 0.8561141604166598)
================== STEP 1 ==================
iter 5, current loss = 0.46947463166155373
iter 6, current loss = 0.45777993427774916
[ Info: (2, 0.45777993427774916)
================== STEP 2 ==================
iter 7, current loss = 0.45339640767939454
iter 8, current loss = 0.4362798370715126
iter 9, current loss = 0.36906723572210276
iter 10, current loss = 3.7593570799062386
iter 11, current loss = 0.36536740508206333
[ Info: (3, 0.36536740508206333)
================== STEP 3 ==================
iter 12, current loss = 0.3428982868531608
iter 13, current loss = 0.3232377330954458
[ Info: (4, 0.3232377330954458)
================== STEP 4 ==================
iter 14, current loss = 0.23671118209489708
iter 15, current loss = 1.3263610093965088
iter 16, current loss = 0.22447420377334332
[ Info: (5, 0.22447420377334332)
================== STEP 5 ==================
iter 17, current loss = 0.15093468391134288
iter 18, current loss = 0.12407930796401664
iter 19, current loss = 120.80501022121275
iter 20, current loss = 0.12270769003385013
[ Info: (6, 0.12270769003385013)
================== STEP 6 ==================
iter 21, current loss = 5189.411935426806
iter 22, current loss = 0.12164592286660478
iter 23, current loss = 358.2087735635081
iter 24, current loss = 0.11779495770942046
iter 25, current loss = 142.52454731784186
iter 26, current loss = 11.389770768310362
iter 27, current loss = 0.09947906042063565
iter 28, current loss = 10.673298503797998
iter 29, current loss = 0.8640812138970045
iter 30, current loss = 0.05587954160243695
[ Info: (7, 0.05587954160243695)
================== STEP 7 ==================
iter 31, current loss = 6.634535477873427
iter 32, current loss = 0.04546568612710486
iter 33, current loss = 0.19613821269905676
iter 34, current loss = 0.01850067573717187
[ Info: (8, 0.01850067573717187)
================== STEP 8 ==================
iter 35, current loss = 0.03343924646692387
iter 36, current loss = 0.0066916604083858055
[ Info: (9, 0.0066916604083858055)
================== STEP 9 ==================
iter 37, current loss = 0.005310198532633232
iter 38, current loss = 0.005140092828722325
[ Info: (10, 0.005140092828722325)
================== STEP 10 ==================
iter 39, current loss = 0.0049428129712270966
iter 40, current loss = 0.0042842383242564655
iter 41, current loss = 0.005456575064664338
iter 42, current loss = 0.00374722819335653
[ Info: (11, 0.00374722819335653)
================== STEP 11 ==================
iter 43, current loss = 0.0019748200201889186
iter 44, current loss = 0.001040084855005645
iter 45, current loss = 0.0003754441972634908
[ Info: (12, 0.0003754441972634908)
================== STEP 12 ==================
iter 46, current loss = 0.00022612356973768135
iter 47, current loss = 3.2669583549358244e-5
[ Info: (13, 3.2669583549358244e-5)
================== STEP 13 ==================
iter 48, current loss = 6.6968091595104795e-6
iter 49, current loss = 9.61231791589415e-5
iter 50, current loss = 2.1185911100944347e-8
[ Info: (14, 2.1185911100944347e-8)
================== STEP 14 ==================
iter 51, current loss = 6.041590542593389e-11
iter 52, current loss = 4.534426553563152e-11
[ Info: (15, 4.534426553563152e-11)
================== STEP 15 ==================
iter 53, current loss = 6.848593433918876e-14
iter 54, current loss = 6.566307970883354e-10
iter 55, current loss = 1.942185762223109e-17
[ Info: (16, 1.942185762223109e-17)
================== STEP 16 ==================
iter 56, current loss = 1.3147109500835201e-24
iter 57, current loss = 3.105510575423316e-16
iter 58, current loss = 4.3730701496153095e-26
[ Info: (17, 4.3730701496153095e-26)
================== STEP 17 ==================
iter 59, current loss = 0.0
[ Info: (18, 0.0)
================== STEP 18 ==================
[ Info: Optimization starts...
iter 1, current loss = 14.868382182867341
[ Info: (0, 14.868382182867341)
================== STEP 0 ==================
iter 2, current loss = 327696.807215325
iter 3, current loss = 13.308529920165181
iter 4, current loss = 0.8077527135848483
[ Info: (1, 0.8077527135848483)
================== STEP 1 ==================
iter 5, current loss = 0.6397928400292556
iter 6, current loss = 0.45841045112000717
[ Info: (2, 0.45841045112000717)
================== STEP 2 ==================
iter 7, current loss = 0.4574818508336603
iter 8, current loss = 0.4355450606538527
[ Info: (3, 0.4355450606538527)
================== STEP 3 ==================
iter 9, current loss = 0.36213078635290086
iter 10, current loss = 8.56043064129902
iter 11, current loss = 0.42157134103488586
iter 12, current loss = 0.580298959104901
iter 13, current loss = 0.3623895148894261
iter 14, current loss = 0.26096832252238356
iter 15, current loss = 0.2610860894516966
[ Info: (4, 0.2610860894516966)
================== STEP 4 ==================
iter 16, current loss = 0.25022735533543183
iter 17, current loss = 0.2431314040399222
[ Info: (5, 0.2431314040399222)
================== STEP 5 ==================
iter 18, current loss = 0.2287163892256244
iter 19, current loss = 0.13192646644482853
[ Info: (6, 0.13192646644482853)
================== STEP 6 ==================
iter 20, current loss = 0.12728950441800063
iter 21, current loss = 0.12528166226353663
[ Info: (7, 0.12528166226353663)
================== STEP 7 ==================
iter 22, current loss = 0.12507162497621485
iter 23, current loss = 1.4271621454004368
iter 24, current loss = 0.11541242781180897
iter 25, current loss = 1.2412299248979932
iter 26, current loss = 0.12398026135400546
iter 27, current loss = 0.08824534838932345
[ Info: (8, 0.08824534838932345)
================== STEP 8 ==================
iter 28, current loss = 5.726849963717744
iter 29, current loss = 0.08549373792761968
iter 30, current loss = 0.09744698932317297
iter 31, current loss = 0.07140603651342292
[ Info: (9, 0.07140603651342292)
================== STEP 9 ==================
iter 32, current loss = 0.06747008840534682
iter 33, current loss = 0.0518401326813184
[ Info: (10, 0.0518401326813184)
================== STEP 10 ==================
iter 34, current loss = 0.028395856444454616
iter 35, current loss = 0.013302257471603744
[ Info: (11, 0.013302257471603744)
================== STEP 11 ==================
iter 36, current loss = 0.012927941147393858
iter 37, current loss = 0.012267741091663748
[ Info: (12, 0.012267741091663748)
================== STEP 12 ==================
iter 38, current loss = 0.011561658815453547
iter 39, current loss = 0.2805343468711725
iter 40, current loss = 0.010203190096029104
iter 41, current loss = 0.19713756744677857
iter 42, current loss = 0.0110226428077997
iter 43, current loss = 0.004636528032139342
[ Info: (13, 0.004636528032139342)
================== STEP 13 ==================
iter 44, current loss = 0.002960022904954329
iter 45, current loss = 0.0029452534230050165
[ Info: (14, 0.0029452534230050165)
================== STEP 14 ==================
iter 46, current loss = 0.0025864021477469195
iter 47, current loss = 0.0003291464181674595
[ Info: (15, 0.0003291464181674595)
================== STEP 15 ==================
iter 48, current loss = 0.00027934765669285303
iter 49, current loss = 0.0002602453513726327
[ Info: (16, 0.0002602453513726327)
================== STEP 16 ==================
iter 50, current loss = 0.0002564729552447214
iter 51, current loss = 6.032575655958347e-6
[ Info: (17, 6.032575655958347e-6)
================== STEP 17 ==================
iter 52, current loss = 0.000224139883588693
iter 53, current loss = 1.3321901137454535e-6
[ Info: (18, 1.3321901137454535e-6)
================== STEP 18 ==================
iter 54, current loss = 1.3114920237047706e-6
iter 55, current loss = 1.2716828195172086e-6
[ Info: (19, 1.2716828195172086e-6)
================== STEP 19 ==================
iter 56, current loss = 1.2714309614931928e-6
iter 57, current loss = 2.8202081427418578e-11
[ Info: (20, 2.8202081427418578e-11)
================== STEP 20 ==================
iter 58, current loss = 4.628718980209147e-6
iter 59, current loss = 3.27597542634403e-12
[ Info: (21, 3.27597542634403e-12)
================== STEP 21 ==================
iter 60, current loss = 3.275260402627273e-12
iter 61, current loss = 1.4504376890372985e-12
[ Info: (22, 1.4504376890372985e-12)
================== STEP 22 ==================
iter 62, current loss = 1.9168740049011974e-8
iter 63, current loss = 2.423639144034724e-18
[ Info: (23, 2.423639144034724e-18)
================== STEP 23 ==================
iter 64, current loss = 1.7630595368246033e-18
iter 65, current loss = 1.2905972459299493e-18
[ Info: (24, 1.2905972459299493e-18)
================== STEP 24 ==================
iter 66, current loss = 1.2861332388123877e-18
iter 67, current loss = 1.2614664734309251e-20
[ Info: (25, 1.2614664734309251e-20)
================== STEP 25 ==================
iter 68, current loss = 6.982929167602485e-20
iter 69, current loss = 1.2499564359224641e-20
[ Info: (26, 1.2499564359224641e-20)
================== STEP 26 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[ Info: 3.900395163047295e-8
[2.6873403110589567, 2.2848777584058286, 1.959485177894072, 1.695402405085309, 1.480263493197685, 1.304318508155104, 1.1598475045894157, 1.0407152651051803, 0.9420302552703156, 0.8598815076342153]
[2.6873403110589567, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.4802634543798443, 1.3043184684311486, 1.159847465406238, 1.0407152273674067, 0.9420302195019173, 0.8598814740954399]
[ Info: 1.74923517585932e-6
[2.6873403110589567, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722332, 1.7903868796137, 1.6665331065514706, 1.5498999348193685, 1.4403938823398208]
[2.6873403110589567, 2.519680372297153, 2.3591806721463433, 2.205949060790531, 2.0600593252906663, 1.9215446484117813, 1.7903894445161121, 1.666535679326616, 1.5499024452536934, 1.4403964019318742]
[ Info: 0.009280891261506044
[2.6873403110589567, 2.5196803348281445, 2.407655825231478, 2.3197815374114255, 2.2461502831672484, 2.1821637837734777, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.6873403110589567, 2.52894669594942, 2.420490642269895, 2.334573816587063, 2.262184980528145, 2.199051744362444, 2.142753602200173, 2.091763168313902, 2.0450438762274734, 2.001854279772373]
[ Info: 0.0002640108007748801
[2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567]
[2.6873403110589567, 2.6872637777504984, 2.6871862715585118, 2.687108108244675, 2.6870294441458276, 2.6869503723706374, 2.686870954600783, 2.6867912346415777, 2.686711245167153, 2.686631011454236]
ADCME.Optimizer.RMSProp: 
[2.6873403110589567, 2.1809229506849572, 1.876707980129773, 1.6546592408302836, 1.479244033062772, 1.334696176675614, 1.2124398515964887, 1.1071870862263171, 1.015408944687647, 0.9346163191023285]
ADCME.Optimizer.AMSGrad: 
[2.6873403110589567, 2.180931270734746, 1.6124928714759128, 1.108615178036389, 0.7379095523937292, 0.5260637392759812, 0.4585161239500093, 0.48774999629589677, 0.5512317022689825, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.6873403110589567, 2.4425702565335135, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870792, 1.3669096060903072]
ADCME.Optimizer.Momentum: 
[2.6873403110589567, 0.5561138694752268, 1.901919174485902, 1.5251751312785733, 0.0420157941282293, 1.107065572875359, 0.9972859136071747, 0.092505967405753, 0.8373703084967706, 0.9155307151492693]
ADCME.Optimizer.Nesterov: 
[2.6873403110589567, 1.959349802300281, 1.270153711798689, 0.7838060906690358, 0.5406336834135216, 0.48898653622901855, 0.5361697434507271, 0.593802848884102, 0.6052577936273842, 0.553136858054489]
ADCME.Optimizer.RADAM: 
[2.6873403110589567, 2.2848777584058286, 1.9432397781298896, 1.6552856125616948, 1.4144226819237642, 1.41260788266853, 1.409924914461023, 1.40654531582648, 1.4025672017224886, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.6873403110589567, 2.51968033219294, 2.3622082113112657, 2.2144819560814186, 2.076059233397677, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.6066663584779952, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
WARNING: Method definition f(Any, Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:2 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:13.
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
ActNorm: initializing s and t...
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = tril(o::PyObject, num::Int64) at ops.jl:1136
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1136
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = triu(o::PyObject, num::Int64) at ops.jl:1152
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1152
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Pass  Total
NeuralCouplingFlow |    2      2
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
    Testing ADCME tests passed 
