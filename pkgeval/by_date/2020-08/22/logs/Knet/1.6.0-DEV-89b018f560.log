Julia Version 1.6.0-DEV.689
Commit 89b018f560 (2020-08-21 13:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed Adapt ──────────────────────── v2.0.2
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed JLD2 ───────────────────────── v0.1.14
  Installed CEnum ──────────────────────── v0.4.1
  Installed OrderedCollections ─────────── v1.3.0
  Installed FileIO ─────────────────────── v1.4.1
  Installed DataStructures ─────────────── v0.17.20
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed GPUCompiler ────────────────── v0.6.0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed NNlib ──────────────────────── v0.7.4
  Installed CodecZlib ──────────────────── v0.7.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed Knet ───────────────────────── v1.4.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed SpecialFunctions ───────────── v0.10.3
  Installed TimerOutputs ───────────────── v0.5.6
  Installed Reexport ───────────────────── v0.2.0
  Installed ExprTools ──────────────────── v0.1.1
  Installed AutoGrad ───────────────────── v1.2.3
  Installed GPUArrays ──────────────────── v5.1.0
  Installed LLVM ───────────────────────── v2.0.0
  Installed CUDA ───────────────────────── v1.3.1
  Installed Requires ───────────────────── v1.0.1
  Installed TranscodingStreams ─────────── v0.9.5
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.4.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v2.0.2
  [6710c13c] + AutoGrad v1.2.3
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.4.1
  [052768ef] + CUDA v1.3.1
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] + DataStructures v0.17.20
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.4.1
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [033835bb] + JLD2 v0.1.14
  [1902f260] + Knet v1.4.0
  [929cbde3] + LLVM v2.0.0
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.7.4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+15
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing Knet
Status `/tmp/jl_3W2z3k/Project.toml`
  [6710c13c] AutoGrad v1.2.3
  [052768ef] CUDA v1.3.1
  [5789e2e9] FileIO v1.4.1
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [872c559c] NNlib v0.7.4
  [276daf66] SpecialFunctions v0.10.3
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_3W2z3k/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v2.0.2
  [6710c13c] AutoGrad v1.2.3
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.4.1
  [052768ef] CUDA v1.3.1
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] DataStructures v0.17.20
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.4.1
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [929cbde3] LLVM v2.0.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.7.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+15
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
kptr.jl	244.149936 seconds (18.83 M allocations: 1.107 GiB, 0.68% gc time)
gpu.jl	Knet.LibKnet8.libknet8 = "/home/pkgeval/.julia/artifacts/5e1e317677e88277f0ee67ab9e17587a8edc4f7a/libknet8"
readdir(artifact"libknet8") = ["libknet8.so"]
CuDevice(0): Tesla T4
length(CUDA.devices()) = 1
CUDA.capability(CUDA.device()) = v"7.5.0"
CUDA.warpsize(CUDA.device()) = 32
CUDA.find_toolkit() = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
CUDA.version() = v"11.0.0"
Mem.info() = (15646588928, 15843721216)
CUDA.synchronize() = nothing
NVML.driver_version() = v"450.36.6"
NVML.version() = v"11.0.0+450.36.6"
NVML.cuda_driver_version() = v"11.0.0"
NVML.memory_info(nvmldev) = (total = 15843721216, free = 15646588928, used = 197132288)
CUBLAS.handle() = Ptr{Nothing} @0x00000000096e1230
CUBLAS.version() = v"10.2.2"
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gpu.jl:3
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] top-level scope
      @ show.jl:891
   [14] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:39
   [15] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:8
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [18] macro expansion
      @ ./timing.jl:174 [inlined]
   [19] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [20] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [22] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [23] top-level scope
      @ none:6
   [24] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [25] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [26] _start()
      @ Base ./client.jl:484
  
  5.003282 seconds (3.03 M allocations: 169.595 MiB, 1.03% gc time)
distributions.jl	  2.498356 seconds (3.22 M allocations: 180.755 MiB, 3.86% gc time)
dropout.jl	 17.295900 seconds (6.60 M allocations: 412.912 MiB, 0.98% gc time)
gcnode.jl	gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gcnode.jl:8
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] (::RNN)(x::KnetArray{Float32,3})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328
   [15] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:18
   [16] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:11
   [18] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [19] macro expansion
      @ ./timing.jl:174 [inlined]
   [20] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [21] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [27] _start()
      @ Base ./client.jl:484
  
  3.049889 seconds (4.48 M allocations: 245.304 MiB, 4.43% gc time)
jld.jl	 27.647658 seconds (32.02 M allocations: 1.701 GiB, 3.35% gc time)
statistics.jl	 28.435366 seconds (23.29 M allocations: 1.367 GiB, 3.74% gc time)
bmm.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01a00b222f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01a00b16e3)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01a00b14bc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01a00b12e4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01a00b0d97)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f01a00b026b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f01a00af184)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01a00b222f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01a00b16e3)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01a00b14bc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01a00b12e4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01a00b0d97)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f01a00b026b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f01a00af184)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:8
  Got exception outside of a @test
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:41
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
   [33] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [34] macro expansion
      @ ./timing.jl:174 [inlined]
   [35] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [36] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [37] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [38] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [39] top-level scope
      @ none:6
   [40] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [41] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [42] _start()
      @ Base ./client.jl:484
  
 48.114513 seconds (43.54 M allocations: 2.491 GiB, 4.65% gc time)
serialize.jl	serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/serialize.jl:10
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] RNN
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328 [inlined]
   [15] (::var"#m1test#61")(M1::RNN, xgpu::KnetArray{Float32,3}, xcpu::Array{Float32,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:40
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:50
   [17] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:11
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [20] macro expansion
      @ ./timing.jl:174 [inlined]
   [21] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [22] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [28] _start()
      @ Base ./client.jl:484
  
  8.015215 seconds (6.86 M allocations: 392.747 MiB, 2.49% gc time)
loss.jl	
Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:17
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:18
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 1,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:19
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 2,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:20
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] #logsoftmax#46
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13 [inlined]
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:20
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:21
  Test threw exception
  Expression: isapprox(f(a, dims = 1), f(k, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:21
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:22
  Test threw exception
  Expression: isapprox(f(a, dims = 2), f(k, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:22
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{KnetArray{Float64,3}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:36
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{KnetArray{Float64,3}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:37
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [18] logsoftmax(x::KnetArray{Float64,3})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:37
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:39
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => d,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:40
  Test threw exception
  Expression: isapprox(f(a, dims = d), f(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:40
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:69
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 1,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:70
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 2,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:73
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 1), nll(a, indices, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:73
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:74
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 2), nll(a, indices, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:74
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:87
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:87
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:88
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:88
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:89
  Test threw exception
  Expression: isapprox(logsoftmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:89
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:90
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:90
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:91
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:91
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:92
  Test threw exception
  Expression: isapprox(∇logsoftmax(x, y2, dy, dims = 1), _cudnnSoftmaxBackward(y2, dy, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:92
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#70#80")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#70#80")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#71#81")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#71#81")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#72#82")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#72#82")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#73#83")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#73#83")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#74#84")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#74#84")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#75#85")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98 =# @gcheck _cudnnSoftmaxBackward(Param(y2), Param(dy), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#75#85")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:107
  Test threw exception
  Expression: isapprox(f(a, b, c), f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] nll
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38 [inlined]
   [20] (::var"#f#86")(w::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:107
   [22] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:108
  Test threw exception
  Expression: isapprox(∇f(a, b, c), ∇f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
 [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
 [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [33] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] macro expansion
    @ ./timing.jl:174 [inlined]
 [37] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [38] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [39] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [40] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [41] top-level scope
    @ none:6
 [42] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [43] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [44] _start()
    @ Base ./client.jl:484

Stacktrace:
  [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
  [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [4] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
  [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
  [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
  [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [10] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [11] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [12] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [13] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [14] macro expansion
    @ ./timing.jl:174 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [16] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [17] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [18] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [19] top-level scope
    @ none:6
 [20] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [21] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [22] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:110
  Test threw exception
  Expression: isapprox(∇∇fj(a, b, c, i), ∇∇fj(A, B, C, i))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
    [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [4] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
    [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
    [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
    [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [10] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [11] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [12] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
   [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
   [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
 69.136060 seconds (50.33 M allocations: 2.949 GiB, 3.14% gc time)
cuarray.jl	┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01780f1caf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01780f15c5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01780f136f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01780f11b1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01780f0bc0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f01780e908c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f01780e8f6c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01780f1caf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01780f15c5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01780f136f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01780f11b1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01780f0bc0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f01780e908c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f01780e8f6c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01780f904f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01780f8985)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01780f873f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01780f8581)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01780f8240)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f01780f684c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f01780f672c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01780f904f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f01780f8985)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01780f873f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01780f8581)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f01780f8240)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f01780f684c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f01780f672c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01781099cf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f0178109313)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01781090ec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f0178108f24)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178108c67)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f017810869b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f0178107a74)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f01781099cf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f0178109313)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f01781090ec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f0178108f24)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178108c67)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f017810869b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f0178107a74)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29 =# @gcheck permutedims(a3, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30 =# @gcheck permutedims(a3, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f017811acaf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f017811a5a5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f017811a34f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f017811a191)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178119e30)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f0178117d3c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f0178117c1c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f017811acaf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f017811a5a5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f017811a34f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f017811a191)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178119e30)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f0178117d3c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f0178117c1c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f01a01bbcc4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f017812941f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f0178128cfe)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f0178128a98)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01781288cb)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178128598)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7f0178127e36)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f017812941f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f0178128cfe)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f0178128a98)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f01781288cb)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f0178128598)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7f0178127e36)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
 [28] _unsafe_getindex!
    @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
 [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] getindex
    @ ./none:0 [inlined]
 [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16 =# @gcheck getindex(a3, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] getindex
      @ ./none:0 [inlined]
   [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34 =# @gcheck permutedims(a3, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d00cbbf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d00c475)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d00c1ef)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d00c001)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d00bc70)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d00cbbf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d00c475)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d00c1ef)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d00c001)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d00bc70)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [35] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:50
  Expression: argmax(a0) == argmax(a1)
   Evaluated: CartesianIndex(3, 4, 4) == CartesianIndex(4, 3, 3)
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:50
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:51
  Expression: argmin(a0) == argmin(a1)
   Evaluated: CartesianIndex(1, 5, 5) == CartesianIndex(4, 2, 4)
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:51
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:52
  Expression: findmax(a0) == findmax(a1)
   Evaluated: (0.9980764873119856, CartesianIndex(3, 4, 4)) == (0.9979308302709338, CartesianIndex(4, 3, 3))
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:52
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:53
  Expression: findmin(a0) == findmin(a1)
   Evaluated: (0.0022058069673227543, CartesianIndex(1, 5, 5)) == (0.001000821147479014, CartesianIndex(4, 2, 4))
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:53
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(2, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(6, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(6, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(1, 8, 8)] == CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(2, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(6, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(6, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(1, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(6, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(2, 8, 4)]

CartesianIndex{3}[CartesianIndex(8, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(7, 8, 5)]

CartesianIndex{3}[CartesianIndex(8, 1, 6) CartesianIndex(4, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(8, 7, 7) CartesianIndex(3, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(5, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)] == CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(6, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(4, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(2, 8, 4)]

CartesianIndex{3}[CartesianIndex(8, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(7, 8, 5)]

CartesianIndex{3}[CartesianIndex(8, 1, 6) CartesianIndex(4, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(8, 7, 7) CartesianIndex(3, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(5, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9645347066720291 0.9025081592226605 … 0.8742567147072013 0.8989683946399016]

[0.9456476703855101 0.9037263568244485 … 0.8601780232347871 0.7564948918321328]

[0.8642153986384999 0.7383762333286867 … 0.9074523456477919 0.8649312512420961]

[0.9153421490718139 0.9234607346394053 … 0.8795996935140971 0.9510437221062134]

[0.7599635277087444 0.8464100959338492 … 0.9569140119417332 0.8343812365707004]

[0.9697200199396838 0.9287874993147034 … 0.9841284859195079 0.8494907943633754]

[0.8102647565585299 0.9749751902365686 … 0.9254505295048123 0.7815139777828717]

[0.8421441078103644 0.9271873274195619 … 0.9945956633981152 0.8484035616336083], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(2, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(6, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(6, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(1, 8, 8)]) == ([0.9645347066720291 0.9025081592226605 … 0.8742567147072013 0.8989683946399016]

[0.9456476703855101 0.9786193405363004 … 0.8601780232347871 0.7564948918321328]

[0.8642153986384999 0.7383762333286867 … 0.9074523456477919 0.8649312512420961]

[0.9153421490718139 0.8810201113623162 … 0.8795996935140971 0.9510437221062134]

[0.7599635277087444 0.8464100959338492 … 0.9569140119417332 0.8343812365707004]

[0.9697200199396838 0.9287874993147034 … 0.9841284859195079 0.8494907943633754]

[0.8102647565585299 0.9749751902365686 … 0.9254505295048123 0.7815139777828717]

[0.8421441078103644 0.9271873274195619 … 0.9945956633981152 0.8484035616336083], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(4, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(2, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(6, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(2, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(6, 1, 7) CartesianIndex(5, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(1, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.08761485150754234 0.0726829778933249 … 0.23425568333811686 0.008975511553798832]

[0.05202607275886395 0.14834892230052033 … 0.09657425830522626 0.13776507763895562]

[0.2682180431626773 0.20371331820427652 … 0.16561035106288502 0.03290525060280958]

[0.11822798861547135 0.09533115405656489 … 0.07253534666051187 0.14191316451453106]

[0.11157828460982921 0.028970486751724422 … 0.14677398713592082 0.12270237581297128]

[0.2564754035561474 0.02152708211951504 … 0.11096165471245456 0.2647144923272646]

[0.11446422244243615 0.11899463519418818 … 0.05015256892984388 0.044259496148855826]

[0.14169968341879846 0.0816057515235451 … 0.5368915866800759 0.05868446660941773], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(6, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(2, 8, 4)]

CartesianIndex{3}[CartesianIndex(8, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(7, 8, 5)]

CartesianIndex{3}[CartesianIndex(8, 1, 6) CartesianIndex(4, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(8, 7, 7) CartesianIndex(3, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(5, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)]) == ([0.08761485150754234 0.0726829778933249 … 0.23425568333811686 0.008975511553798832]

[0.05202607275886395 0.14834892230052033 … 0.09657425830522626 0.13776507763895562]

[0.2682180431626773 0.20371331820427652 … 0.16561035106288502 0.03290525060280958]

[0.11822798861547135 0.001000821147479014 … 0.07253534666051187 0.14191316451453106]

[0.11157828460982921 0.028970486751724422 … 0.14677398713592082 0.12270237581297128]

[0.2564754035561474 0.02152708211951504 … 0.11096165471245456 0.2647144923272646]

[0.11446422244243615 0.11899463519418818 … 0.05015256892984388 0.044259496148855826]

[0.14169968341879846 0.0816057515235451 … 0.5368915866800759 0.05868446660941773], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(2, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(8, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(5, 1, 3) CartesianIndex(7, 2, 3) … CartesianIndex(8, 7, 3) CartesianIndex(6, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(4, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(2, 8, 4)]

CartesianIndex{3}[CartesianIndex(8, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(7, 8, 5)]

CartesianIndex{3}[CartesianIndex(8, 1, 6) CartesianIndex(4, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(8, 7, 7) CartesianIndex(3, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(5, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 4, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 3, 3); CartesianIndex(2, 6, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 3, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 6, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 3, 7); CartesianIndex(2, 5, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 2, 8); CartesianIndex(8, 6, 8)] == CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 2, 2); … ; CartesianIndex(7, 4, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 3, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 3, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 6, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 3, 7); CartesianIndex(2, 5, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 2, 8); CartesianIndex(8, 6, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 3, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 2, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 4, 4); CartesianIndex(8, 7, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 2, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 2, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 2, 8)] == CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 3, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 2, 2); CartesianIndex(2, 4, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 4, 4); CartesianIndex(8, 7, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 2, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 2, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 2, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9942868097248334; 0.8989683946399016; … ; 0.9116852069776828; 0.9645347066720291]

[0.9529130664215526; 0.7698129874005695; … ; 0.9882814328056748; 0.9459511080384877]

[0.9924207822241762; 0.7446799931437105; … ; 0.9845286515604512; 0.7859343640995953]

[0.7833066777504758; 0.975607584583293; … ; 0.9531791481859779; 0.893880587126914]

[0.5708534800839338; 0.866659231581713; … ; 0.9338099147705059; 0.9217019588915323]

[0.8413003991014594; 0.8903649654906469; … ; 0.9841284859195079; 0.9327886634717883]

[0.843951771066231; 0.6220701829929607; … ; 0.9541187448366044; 0.8601379287063176]

[0.9089255676861296; 0.876904645972856; … ; 0.9271873274195619; 0.8778832554529401], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 4, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 3, 3); CartesianIndex(2, 6, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 3, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 6, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 3, 7); CartesianIndex(2, 5, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 2, 8); CartesianIndex(8, 6, 8)]) == ([0.9942868097248334; 0.8989683946399016; … ; 0.9116852069776828; 0.9645347066720291]

[0.9529130664215526; 0.9786193405363004; … ; 0.9882814328056748; 0.9459511080384877]

[0.9924207822241762; 0.8343073362364963; … ; 0.9845286515604512; 0.7859343640995953]

[0.7833066777504758; 0.8580814363590912; … ; 0.9531791481859779; 0.893880587126914]

[0.5708534800839338; 0.866659231581713; … ; 0.9338099147705059; 0.9217019588915323]

[0.8413003991014594; 0.8903649654906469; … ; 0.9841284859195079; 0.9327886634717883]

[0.843951771066231; 0.6220701829929607; … ; 0.9541187448366044; 0.8601379287063176]

[0.9089255676861296; 0.876904645972856; … ; 0.9271873274195619; 0.8778832554529401], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 4, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 2, 2); … ; CartesianIndex(7, 4, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 3, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 3, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 1, 5); CartesianIndex(2, 6, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 4, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 3, 7); CartesianIndex(2, 5, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 7, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 2, 8); CartesianIndex(8, 6, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.06443787722746164; 0.0668397135879939; … ; 0.32436480863065853; 0.0726829778933249]

[0.21561387518095532; 0.2343532658749392; … ; 0.04183147108051832; 0.05202607275886395]

[0.2866469796528168; 0.2400927065977212; … ; 0.19657943851257875; 0.1605700127513705]

[0.07253534666051187; 0.14191316451453106; … ; 0.02670401533196709; 0.09296793435719675]

[0.0022058069673227543; 0.11199026374911547; … ; 0.12270237581297128; 0.09997333245598083]

[0.08489041873803616; 0.17041572250445935; … ; 0.18803332258241645; 0.12619903407040245]

[0.15963930428209072; 0.15333819698674533; … ; 0.07041978969397555; 0.05015256892984388]

[0.011108547627289855; 0.32889533128886694; … ; 0.18735698594189687; 0.09883980515560609], CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 3, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 2, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 4, 4); CartesianIndex(8, 7, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 2, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 2, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 2, 8)]) == ([0.06443787722746164; 0.0668397135879939; … ; 0.32436480863065853; 0.0726829778933249]

[0.21561387518095532; 0.039995474978888224; … ; 0.04183147108051832; 0.05202607275886395]

[0.2866469796528168; 0.29987389536566766; … ; 0.19657943851257875; 0.1605700127513705]

[0.07253534666051187; 0.14191316451453106; … ; 0.02670401533196709; 0.09296793435719675]

[0.0022058069673227543; 0.11199026374911547; … ; 0.12270237581297128; 0.09997333245598083]

[0.08489041873803616; 0.17041572250445935; … ; 0.18803332258241645; 0.12619903407040245]

[0.15963930428209072; 0.15333819698674533; … ; 0.07041978969397555; 0.05015256892984388]

[0.011108547627289855; 0.32889533128886694; … ; 0.18735698594189687; 0.09883980515560609], CartesianIndex{3}[CartesianIndex(1, 4, 1); CartesianIndex(2, 3, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 2, 2); CartesianIndex(2, 4, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 7, 3); CartesianIndex(8, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 4, 4); CartesianIndex(8, 7, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 2, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 2, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 8, 7); CartesianIndex(8, 7, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 5, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 2, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 4) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 1, 6) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 5)] == CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 1, 6) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 5)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 1) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 7); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 3)] == CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 1) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 7); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 3)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.8388949804539325 0.7383762333286867 … 0.9089255676861296 0.8484035616336083; 0.7698129874005695 0.9234607346394053 … 0.876904645972856 0.8989683946399016; … ; 0.9697200199396838 0.9271873274195619 … 0.9841284859195079 0.8473416997815488; 0.9645347066720291 0.9037263568244485 … 0.8742567147072013 0.6514470442489755], CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 4) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 1, 6) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 5)]) == ([0.8388949804539325 0.7383762333286867 … 0.9089255676861296 0.8484035616336083; 0.7698129874005695 0.9786193405363004 … 0.876904645972856 0.8989683946399016; … ; 0.9697200199396838 0.9271873274195619 … 0.9841284859195079 0.8473416997815488; 0.9645347066720291 0.9037263568244485 … 0.8742567147072013 0.6514470442489755], CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 8) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 2) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 1); … ; CartesianIndex(7, 1, 6) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 5)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.08761485150754234 0.08489041873803616 … 0.07253534666051187 0.15963930428209072; 0.11199026374911547 0.16671369200107122 … 0.19170663107227282 0.14191316451453106; … ; 0.3757474856006011 0.20371331820427652 … 0.13098031256677367 0.07041978969397555; 0.05202607275886395 0.0726829778933249 … 0.05015256892984388 0.1605700127513705], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 1) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 7); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 3)]) == ([0.08761485150754234 0.08489041873803616 … 0.07253534666051187 0.15963930428209072; 0.11199026374911547 0.16671369200107122 … 0.19170663107227282 0.14191316451453106; … ; 0.3757474856006011 0.20371331820427652 … 0.13098031256677367 0.07041978969397555; 0.05202607275886395 0.0726829778933249 … 0.05015256892984388 0.1605700127513705], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 1) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 7); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 3)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 41.118076 seconds (22.26 M allocations: 1.299 GiB, 1.90% gc time)
update.jl	┌ Warning: optimizers is deprecated, use sgd, adam etc. instead.
└ @ Knet.Train20 ~/.julia/packages/Knet/Mfd6L/src/train20/update.jl:598
 73.939917 seconds (63.75 M allocations: 3.071 GiB, 4.45% gc time)
linalg.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d0d6f4f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d0d6893)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d0d666c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d0d64a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d0d61e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7f015d0d5b8f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d0d6f4f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d0d6893)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d0d666c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d0d64a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d0d61e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7f015d0d5b8f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d0e680f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d0e6133)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d0e5f0c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d0e5d34)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d0e5a77)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7f015d0e541f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f015d0e680f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7f015d0e6133)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7f015d0e5f0c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f015d0e5d34)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f015d0e5a77)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7f015d0e541f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1752 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_21857.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1752 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260

signal (15): Terminated
in expression starting at none:16
pthread_cond_wait at /lib/x86_64-linux-gnu/libpthread.so.0 (unknown line)
