Julia Version 1.6.0-DEV.699
Commit 87bf13b792 (2020-08-22 14:55 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed Reexport ───────────────────── v0.2.0
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed TranscodingStreams ─────────── v0.9.5
  Installed SpecialFunctions ───────────── v0.10.3
  Installed AutoGrad ───────────────────── v1.2.3
  Installed BinaryProvider ─────────────── v0.5.10
  Installed GPUArrays ──────────────────── v5.1.0
  Installed CEnum ──────────────────────── v0.4.1
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Knet ───────────────────────── v1.4.0
  Installed NNlib ──────────────────────── v0.7.4
  Installed MacroTools ─────────────────── v0.5.5
  Installed JLD2 ───────────────────────── v0.1.14
  Installed OrderedCollections ─────────── v1.3.0
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed TimerOutputs ───────────────── v0.5.6
  Installed DataStructures ─────────────── v0.17.20
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed LLVM ───────────────────────── v2.0.0
  Installed ExprTools ──────────────────── v0.1.1
  Installed Adapt ──────────────────────── v2.0.2
  Installed CUDA ───────────────────────── v1.3.1
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Requires ───────────────────── v1.0.1
  Installed FileIO ─────────────────────── v1.4.1
  Installed GPUCompiler ────────────────── v0.6.0
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.4.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v2.0.2
  [6710c13c] + AutoGrad v1.2.3
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.4.1
  [052768ef] + CUDA v1.3.1
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] + DataStructures v0.17.20
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.4.1
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [033835bb] + JLD2 v0.1.14
  [1902f260] + Knet v1.4.0
  [929cbde3] + LLVM v2.0.0
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.7.4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+15
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing Knet
Status `/tmp/jl_cFLBUT/Project.toml`
  [6710c13c] AutoGrad v1.2.3
  [052768ef] CUDA v1.3.1
  [5789e2e9] FileIO v1.4.1
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [872c559c] NNlib v0.7.4
  [276daf66] SpecialFunctions v0.10.3
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_cFLBUT/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v2.0.2
  [6710c13c] AutoGrad v1.2.3
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.4.1
  [052768ef] CUDA v1.3.1
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] DataStructures v0.17.20
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.4.1
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [929cbde3] LLVM v2.0.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.7.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+15
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
kptr.jl	240.984656 seconds (18.79 M allocations: 1.104 GiB, 0.69% gc time)
gpu.jl	Knet.LibKnet8.libknet8 = "/home/pkgeval/.julia/artifacts/5e1e317677e88277f0ee67ab9e17587a8edc4f7a/libknet8"
readdir(artifact"libknet8") = ["libknet8.so"]
CuDevice(0): Tesla T4
length(CUDA.devices()) = 1
CUDA.capability(CUDA.device()) = v"7.5.0"
CUDA.warpsize(CUDA.device()) = 32
CUDA.find_toolkit() = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
CUDA.version() = v"11.0.0"
Mem.info() = (15634006016, 15843721216)
CUDA.synchronize() = nothing
NVML.driver_version() = v"450.36.6"
NVML.version() = v"11.0.0+450.36.6"
NVML.cuda_driver_version() = v"11.0.0"
NVML.memory_info(nvmldev) = (total = 15843721216, free = 15634006016, used = 209715200)
CUBLAS.handle() = Ptr{Nothing} @0x0000000009b009e0
CUBLAS.version() = v"10.2.2"
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gpu.jl:3
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] top-level scope
      @ show.jl:891
   [14] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:39
   [15] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:8
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [18] macro expansion
      @ ./timing.jl:174 [inlined]
   [19] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [20] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [22] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [23] top-level scope
      @ none:6
   [24] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [25] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [26] _start()
      @ Base ./client.jl:484
  
  5.279173 seconds (3.00 M allocations: 168.559 MiB, 1.08% gc time)
distributions.jl	  2.499075 seconds (3.22 M allocations: 181.237 MiB, 4.19% gc time)
dropout.jl	 18.243942 seconds (6.58 M allocations: 411.219 MiB, 1.01% gc time)
gcnode.jl	gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gcnode.jl:8
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] (::RNN)(x::KnetArray{Float32,3})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328
   [15] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:18
   [16] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:11
   [18] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [19] macro expansion
      @ ./timing.jl:174 [inlined]
   [20] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [21] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [27] _start()
      @ Base ./client.jl:484
  
  2.420932 seconds (2.52 M allocations: 157.337 MiB, 3.38% gc time)
jld.jl	 26.378325 seconds (24.53 M allocations: 1.346 GiB, 3.56% gc time)
statistics.jl	 28.727260 seconds (23.31 M allocations: 1.367 GiB, 2.94% gc time)
bmm.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b69b403f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b69b34f3)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b69b32cc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b69b30f4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b69b2ba7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fe7b69b207b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fe7b69b0f94)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b69b403f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b69b34f3)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b69b32cc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b69b30f4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b69b2ba7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fe7b69b207b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fe7b69b0f94)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:8
  Got exception outside of a @test
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:41
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
   [33] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [34] macro expansion
      @ ./timing.jl:174 [inlined]
   [35] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [36] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [37] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [38] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [39] top-level scope
      @ none:6
   [40] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [41] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [42] _start()
      @ Base ./client.jl:484
  
 48.410620 seconds (43.32 M allocations: 2.478 GiB, 4.49% gc time)
serialize.jl	serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/serialize.jl:10
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] RNN
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328 [inlined]
   [15] (::var"#m1test#61")(M1::RNN, xgpu::KnetArray{Float32,3}, xcpu::Array{Float32,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:40
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:50
   [17] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:11
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [20] macro expansion
      @ ./timing.jl:174 [inlined]
   [21] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [22] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [28] _start()
      @ Base ./client.jl:484
  
  7.843768 seconds (6.85 M allocations: 392.606 MiB, 3.77% gc time)
loss.jl	
Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:17
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:18
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 1,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:19
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 2,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:20
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] #logsoftmax#46
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13 [inlined]
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:20
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:21
  Test threw exception
  Expression: isapprox(f(a, dims = 1), f(k, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:21
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:22
  Test threw exception
  Expression: isapprox(f(a, dims = 2), f(k, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:22
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{KnetArray{Float64,3}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
 [29] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:36
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{KnetArray{Float64,3}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [29] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:37
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [18] logsoftmax(x::KnetArray{Float64,3})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:37
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
 [26] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:39
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => d,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [26] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:40
  Test threw exception
  Expression: isapprox(f(a, dims = d), f(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:40
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
 [27] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:69
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 1,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [27] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:70
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 2,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [5] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:73
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 1), nll(a, indices, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:73
   [20] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:74
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 2), nll(a, indices, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:74
   [21] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:87
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:87
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:88
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:88
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:89
  Test threw exception
  Expression: isapprox(logsoftmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:89
   [19] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:90
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:90
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:91
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:91
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:92
  Test threw exception
  Expression: isapprox(∇logsoftmax(x, y2, dy, dims = 1), _cudnnSoftmaxBackward(y2, dy, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:92
   [18] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#70#80")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#70#80")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#71#81")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#71#81")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#72#82")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#72#82")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#73#83")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#73#83")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#74#84")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#74#84")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#75#85")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98 =# @gcheck _cudnnSoftmaxBackward(Param(y2), Param(dy), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#75#85")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:107
  Test threw exception
  Expression: isapprox(f(a, b, c), f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] nll
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38 [inlined]
   [20] (::var"#f#86")(w::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:107
   [22] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
 [28] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:108
  Test threw exception
  Expression: isapprox(∇f(a, b, c), ∇f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [28] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
 [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
 [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [33] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] macro expansion
    @ ./timing.jl:174 [inlined]
 [37] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [38] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [39] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [40] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [41] top-level scope
    @ none:6
 [42] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [43] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [44] _start()
    @ Base ./client.jl:484

Stacktrace:
  [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
  [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [4] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
  [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
  [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
  [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [10] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [11] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [12] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [13] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [14] macro expansion
    @ ./timing.jl:174 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [16] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [17] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [18] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [19] top-level scope
    @ none:6
 [20] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [21] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [22] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:110
  Test threw exception
  Expression: isapprox(∇∇fj(a, b, c, i), ∇∇fj(A, B, C, i))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
    [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [4] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
    [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
    [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
    [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [10] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [11] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [12] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/xGgiY/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19161#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/xGgiY/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/xGgiY/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
   [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
   [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
 71.064872 seconds (50.22 M allocations: 2.943 GiB, 2.68% gc time)
cuarray.jl	┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b61359af)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b61352c5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b613506f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b6134eb1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b61348c0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b612ce5c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b612cd3c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b61359af)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b61352c5)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b613506f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b6134eb1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b61348c0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b612ce5c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b612cd3c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b613cc4f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b613c585)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b613c33f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b613c181)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b613be40)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b613a44c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b613a32c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b613cc4f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b613c585)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b613c33f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b613c181)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b613be40)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b613a44c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b613a32c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b614d5cf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b614cf13)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b614ccec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b614cb24)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b614c867)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fe7b614c29b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fe7b614b674)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b614d5cf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b614cf13)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b614ccec)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b614cb24)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b614c867)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7fe7b614c29b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7fe7b614b674)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29 =# @gcheck permutedims(a3, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30 =# @gcheck permutedims(a3, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b615e85f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b615e155)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b615deff)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b615dd41)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b615d9e0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b615b8ec)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b615b7cc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b615e85f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b615e155)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b615deff)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b615dd41)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b615d9e0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7fe7b615b8ec)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7fe7b615b7cc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7fe7bc0fd7a4)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:436
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b616cfaf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b616c88e)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b616c628)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b616c45b)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b616c128)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7fe7b616b9c6)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b616cfaf)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b616c88e)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b616c628)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b616c45b)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b616c128)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7fe7b616b9c6)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
 [28] _unsafe_getindex!
    @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
 [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] getindex
    @ ./none:0 [inlined]
 [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16 =# @gcheck getindex(a3, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] getindex
      @ ./none:0 [inlined]
   [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34 =# @gcheck permutedims(a3, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b007377f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b0073035)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b0072daf)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b0072bc1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b0072830)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b007377f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b0073035)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b0072daf)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b0072bc1)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b0072830)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
   [34] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [35] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
   [31] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(5, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(2, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(2, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(7, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(4, 8, 8)] == CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(5, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(2, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(2, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(7, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(4, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(3, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(4, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(1, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 8)] == CartesianIndex{3}[CartesianIndex(3, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(4, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(3, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(1, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.8521879751031218 0.9917683879225412 … 0.9272088764027118 0.9861269412191964]

[0.8362760470947743 0.9118789003075534 … 0.6510847442101659 0.8773514534437143]

[0.9722245265993812 0.9442231117379385 … 0.8935206020515722 0.9797838792516069]

[0.6653226252428937 0.9267377711086238 … 0.9497572287047373 0.810062414432855]

[0.99869158807497 0.8934002282419304 … 0.968451341456039 0.985259077417989]

[0.745410360740151 0.9675338420756163 … 0.9741425658770884 0.8507674752745804]

[0.9435951344041704 0.9611148716297067 … 0.8433067463844499 0.6916265678435156]

[0.8696053321959112 0.9869023271530188 … 0.963154443461874 0.9151416994595345], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(5, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(2, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(2, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(7, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(4, 8, 8)]) == ([0.8521879751031218 0.9917683879225412 … 0.9272088764027118 0.9861269412191964]

[0.8362760470947743 0.9118789003075534 … 0.6510847442101659 0.8773514534437143]

[0.9722245265993812 0.9442231117379385 … 0.8935206020515722 0.9797838792516069]

[0.6653226252428937 0.9267377711086238 … 0.9497572287047373 0.810062414432855]

[0.99869158807497 0.8934002282419304 … 0.968451341456039 0.985259077417989]

[0.745410360740151 0.9675338420756163 … 0.9741425658770884 0.8507674752745804]

[0.9435951344041704 0.9611148716297067 … 0.8433067463844499 0.6916265678435156]

[0.8696053321959112 0.9869023271530188 … 0.963154443461874 0.9151416994595345], CartesianIndex{3}[CartesianIndex(1, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(5, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(2, 1, 2) CartesianIndex(6, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(8, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(3, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(4, 7, 6) CartesianIndex(2, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(7, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(6, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(8, 7, 8) CartesianIndex(4, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.00143320488044818 0.09073864373781682 … 0.38481394544008096 0.29651059757649745]

[0.09470460899747102 0.009952989447539418 … 0.011556329169881474 0.09424493329545136]

[0.06501979002266411 0.10766672653165044 … 0.027319529587812363 0.004698468387966281]

[0.04554095964906013 0.013489398243243356 … 0.14033928492405345 0.046472377931976006]

[0.043013954442538305 0.13887630675634033 … 0.2239220307287113 0.10727406857208943]

[0.07465034818933458 0.011573543942051678 … 0.22154570985998112 0.0835805219604846]

[0.006623891499666357 0.19550913183874497 … 0.01817909964598563 0.20504985648265017]

[0.13306790235322175 0.16258881405527625 … 0.380027674451642 0.009451764660207695], CartesianIndex{3}[CartesianIndex(3, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(4, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(1, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 8)]) == ([0.00143320488044818 0.09073864373781682 … 0.38481394544008096 0.29651059757649745]

[0.09470460899747102 0.009952989447539418 … 0.011556329169881474 0.09424493329545136]

[0.06501979002266411 0.017219289624142764 … 0.027319529587812363 0.004698468387966281]

[0.04554095964906013 0.013489398243243356 … 0.14033928492405345 0.046472377931976006]

[0.043013954442538305 0.13887630675634033 … 0.2239220307287113 0.10727406857208943]

[0.07465034818933458 0.011573543942051678 … 0.22154570985998112 0.0835805219604846]

[0.006623891499666357 0.19550913183874497 … 0.01817909964598563 0.20504985648265017]

[0.13306790235322175 0.16258881405527625 … 0.380027674451642 0.009451764660207695], CartesianIndex{3}[CartesianIndex(3, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(4, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(3, 7, 2) CartesianIndex(8, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(3, 2, 3) … CartesianIndex(4, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(5, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(3, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(1, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(7, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 1, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 3, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 4, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 2, 7)]

CartesianIndex{3}[CartesianIndex(1, 4, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 7, 8)] == CartesianIndex{3}[CartesianIndex(1, 1, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 2, 3); … ; CartesianIndex(7, 1, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 4, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 2, 7)]

CartesianIndex{3}[CartesianIndex(1, 4, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 7, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 1, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 8, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)] == CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 1, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 8, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.8521879751031218; 0.9731674655960332; … ; 0.8144318996270599; 0.9917683879225412]

[0.8773514534437143; 0.8362760470947743; … ; 0.926291541828191; 0.8154340618891858]

[0.86159714198296; 0.9933488488428448; … ; 0.9722245265993812; 0.955455037716086]

[0.9970379688203808; 0.9158250232776952; … ; 0.9267377711086238; 0.9630997367538554]

[0.8639887014170591; 0.9920108488941097; … ; 0.9465141790556537; 0.968451341456039]

[0.9571585570026007; 0.8937588995255163; … ; 0.9073188377858867; 0.9031712164116104]

[0.9555990256588136; 0.8094162431301428; … ; 0.845329377395845; 0.9560391936227353]

[0.9896680335846582; 0.8810690493020836; … ; 0.6079263171888631; 0.963154443461874], CartesianIndex{3}[CartesianIndex(1, 1, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 4, 3); … ; CartesianIndex(7, 1, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 3, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 4, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 2, 7)]

CartesianIndex{3}[CartesianIndex(1, 4, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 7, 8)]) == ([0.8521879751031218; 0.9731674655960332; … ; 0.8144318996270599; 0.9917683879225412]

[0.8773514534437143; 0.8362760470947743; … ; 0.926291541828191; 0.8154340618891858]

[0.86159714198296; 0.9024802263765188; … ; 0.9722245265993812; 0.955455037716086]

[0.9970379688203808; 0.7758287291104069; … ; 0.9267377711086238; 0.9630997367538554]

[0.8639887014170591; 0.9920108488941097; … ; 0.9465141790556537; 0.968451341456039]

[0.9571585570026007; 0.8937588995255163; … ; 0.9073188377858867; 0.9031712164116104]

[0.9555990256588136; 0.8094162431301428; … ; 0.845329377395845; 0.9560391936227353]

[0.9896680335846582; 0.8810690493020836; … ; 0.6079263171888631; 0.963154443461874], CartesianIndex{3}[CartesianIndex(1, 1, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 1, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 2, 3); … ; CartesianIndex(7, 1, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 6, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 3, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 4, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 2, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 2, 7)]

CartesianIndex{3}[CartesianIndex(1, 4, 8); CartesianIndex(2, 7, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 7, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.05108764711636926; 0.09073864373781682; … ; 0.355846037761238; 0.12586527233282907]

[0.11919117293913728; 0.03842195446298691; … ; 0.009952989447539418; 0.00858542651382499]

[0.06501979002266411; 0.004698468387966281; … ; 0.036401470378491396; 0.0901624873052631]

[0.12462720228712532; 0.12214570256561963; … ; 0.04554095964906013; 0.046472377931976006]

[0.2239220307287113; 0.18388447828827514; … ; 0.16843933854883697; 0.2283493046391547]

[0.07112506362647686; 0.1923351373433917; … ; 0.36422698711266777; 0.12707516211847802]

[0.01817909964598563; 0.10014475732370354; … ; 0.17910783980503875; 0.36015380956327436]

[0.05659377549392519; 0.08050194635987862; … ; 0.009451764660207695; 0.012642343326075833], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 1, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 8, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)]) == ([0.05108764711636926; 0.09073864373781682; … ; 0.355846037761238; 0.12586527233282907]

[0.11919117293913728; 0.02327944639712909; … ; 0.009952989447539418; 0.00858542651382499]

[0.06501979002266411; 0.004698468387966281; … ; 0.036401470378491396; 0.0901624873052631]

[0.12462720228712532; 0.029368093899380998; … ; 0.04554095964906013; 0.046472377931976006]

[0.2239220307287113; 0.18388447828827514; … ; 0.16843933854883697; 0.2283493046391547]

[0.07112506362647686; 0.1923351373433917; … ; 0.36422698711266777; 0.12707516211847802]

[0.01817909964598563; 0.10014475732370354; … ; 0.17910783980503875; 0.36015380956327436]

[0.05659377549392519; 0.08050194635987862; … ; 0.009451764660207695; 0.012642343326075833], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 8, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 8, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 1, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 8, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 7) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 7) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 3)] == CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 7) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 7) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 3)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 4)] == CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 4)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9435951344041704 0.9555990256588136 … 0.9497572287047373 0.8773514534437143; 0.8362760470947743 0.8094162431301428 … 0.8935206020515722 0.8507674752745804; … ; 0.9722245265993812 0.9267377711086238 … 0.8433067463844499 0.761828358336528; 0.9134586229125934 0.9917683879225412 … 0.968451341456039 0.8436212408189383], CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 7) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 7) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 7) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 3)]) == ([0.9435951344041704 0.9555990256588136 … 0.9497572287047373 0.8773514534437143; 0.8362760470947743 0.9024802263765188 … 0.8935206020515722 0.8507674752745804; … ; 0.9722245265993812 0.9267377711086238 … 0.8433067463844499 0.761828358336528; 0.9134586229125934 0.9917683879225412 … 0.968451341456039 0.8436212408189383], CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 4) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 2) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 7) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 7) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 3)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.06501979002266411 0.10766672653165044 … 0.01817909964598563 0.05659377549392519; 0.13471971464430532 0.09073864373781682 … 0.10014475732370354 0.004698468387966281; … ; 0.04554095964906013 0.009952989447539418 … 0.15755685832182942 0.009451764660207695; 0.0901624873052631 0.21666847099734654 … 0.31837855634492995 0.046472377931976006], CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 4)]) == ([0.06501979002266411 0.10766672653165044 … 0.01817909964598563 0.05659377549392519; 0.13471971464430532 0.09073864373781682 … 0.10014475732370354 0.004698468387966281; … ; 0.04554095964906013 0.009952989447539418 … 0.15755685832182942 0.009451764660207695; 0.0901624873052631 0.21666847099734654 … 0.31837855634492995 0.046472377931976006], CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 8); CartesianIndex(2, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 4) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 4)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 42.619759 seconds (22.10 M allocations: 1.290 GiB, 1.90% gc time)
update.jl	┌ Warning: optimizers is deprecated, use sgd, adam etc. instead.
└ @ Knet.Train20 ~/.julia/packages/Knet/Mfd6L/src/train20/update.jl:598
 73.474183 seconds (63.72 M allocations: 3.068 GiB, 4.70% gc time)
linalg.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b013cb3f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b013c483)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b013c25c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b013c094)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b013bdd7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7fe7b013b77f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b013cb3f)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b013c483)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b013c25c)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b013c094)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b013bdd7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7fe7b013b77f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:313
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1888
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b014c3ff)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b014bd23)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b014bafc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b014b924)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b014b667)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7fe7b014b00f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /buildworker/worker/package_linux64/build/src/rtutils.c:77
emit_expr at /buildworker/worker/package_linux64/build/src/codegen.cpp:4466
emit_ssaval_assign at /buildworker/worker/package_linux64/build/src/codegen.cpp:3948
emit_stmtpos at /buildworker/worker/package_linux64/build/src/codegen.cpp:4147 [inlined]
emit_function at /buildworker/worker/package_linux64/build/src/codegen.cpp:6718
jl_emit_code at /buildworker/worker/package_linux64/build/src/codegen.cpp:7078
jl_emit_codeinst at /buildworker/worker/package_linux64/build/src/codegen.cpp:7112
_jl_compile_codeinst at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /buildworker/worker/package_linux64/build/src/jitlayers.cpp:350
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1894
jl_compile_method_internal at /buildworker/worker/package_linux64/build/src/gf.c:1839 [inlined]
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2143 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7fe7b014c3ff)
#cufunction#766 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
#launch_heuristic#826 at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
unknown function (ip: 0x7fe7b014bd23)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
unknown function (ip: 0x7fe7b014bafc)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7fe7b014b924)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_apply at /buildworker/worker/package_linux64/build/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7fe7b014b667)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7fe7b014b00f)
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:491
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:832
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1753 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:117
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:206
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:157 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:551
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:838
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:788
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_30062.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /buildworker/worker/package_linux64/build/ui/../src/julia.h:1753 [inlined]
true_main at /buildworker/worker/package_linux64/build/ui/repl.c:106
main at /buildworker/worker/package_linux64/build/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
_start at /opt/julia/bin/julia (unknown line)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/xGgiY/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

signal (15): Terminated
in expression starting at none:16
pthread_cond_wait at /lib/x86_64-linux-gnu/libpthread.so.0 (unknown line)
