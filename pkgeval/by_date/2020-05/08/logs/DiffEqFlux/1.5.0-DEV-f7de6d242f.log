Julia Version 1.5.0-DEV.875
Commit f7de6d242f (2020-05-07 14:36 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed PDMats ─────────────────────── v0.9.12
  Installed PositiveFactorizations ─────── v0.2.3
  Installed DiffEqFlux ─────────────────── v1.9.0
  Installed GenericSVD ─────────────────── v0.3.0
  Installed Rmath ──────────────────────── v0.6.1
  Installed QuadGK ─────────────────────── v2.3.1
  Installed FFTW ───────────────────────── v1.2.1
  Installed Media ──────────────────────── v0.5.0
  Installed IRTools ────────────────────── v0.3.2
  Installed RecursiveFactorization ─────── v0.1.0
  Installed DataAPI ────────────────────── v1.3.0
  Installed MuladdMacro ────────────────── v0.2.2
  Installed CodecZlib ──────────────────── v0.7.0
  Installed MKL_jll ────────────────────── v2019.0.117+2
  Installed CodeTracking ───────────────── v0.5.11
  Installed DiffEqSensitivity ──────────── v6.13.0
  Installed OrderedCollections ─────────── v1.2.0
  Installed TranscodingStreams ─────────── v0.9.5
  Installed GPUCompiler ────────────────── v0.2.0
  Installed SimpleTraits ───────────────── v0.9.2
  Installed DiffRules ──────────────────── v1.0.1
  Installed AbstractTrees ──────────────── v0.3.3
  Installed ProgressMeter ──────────────── v1.2.0
  Installed LeftChildRightSiblingTrees ─── v0.1.2
  Installed ZipFile ────────────────────── v0.9.1
  Installed RecipesBase ────────────────── v1.0.1
  Installed ArrayLayouts ───────────────── v0.2.6
  Installed Roots ──────────────────────── v1.0.1
  Installed IterativeSolvers ───────────── v0.8.4
  Installed CUDAdrv ────────────────────── v6.3.0
  Installed Distributions ──────────────── v0.23.2
  Installed CPUTime ────────────────────── v1.0.0
  Installed NaNMath ────────────────────── v0.3.3
  Installed Requires ───────────────────── v1.0.1
  Installed LineSearches ───────────────── v7.0.1
  Installed RecursiveArrayTools ────────── v2.3.1
  Installed StaticArrays ───────────────── v0.12.3
  Installed TableTraits ────────────────── v1.0.0
  Installed NLsolve ────────────────────── v4.3.0
  Installed GPUArrays ──────────────────── v3.3.0
  Installed Flux ───────────────────────── v0.10.4
  Installed Adapt ──────────────────────── v1.0.1
  Installed Zlib_jll ───────────────────── v1.2.11+9
  Installed Distances ──────────────────── v0.8.2
  Installed SpatialIndexing ────────────── v0.1.2
  Installed Inflate ────────────────────── v0.1.2
  Installed NLSolversBase ──────────────── v7.6.1
  Installed LatinHypercubeSampling ─────── v1.6.4
  Installed SpecialFunctions ───────────── v0.10.0
  Installed OpenBLAS_jll ───────────────── v0.3.9+4
  Installed Missings ───────────────────── v0.4.3
  Installed StatsBase ──────────────────── v0.33.0
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed Zygote ─────────────────────── v0.4.20
  Installed Compat ─────────────────────── v3.9.0
  Installed SparseDiffTools ────────────── v1.7.1
  Installed LLVM ───────────────────────── v1.4.1
  Installed ColorTypes ─────────────────── v0.10.3
  Installed ArnoldiMethod ──────────────── v0.0.4
  Installed FiniteDiff ─────────────────── v2.3.1
  Installed Parameters ─────────────────── v0.12.1
  Installed Reexport ───────────────────── v0.2.0
  Installed StatsFuns ──────────────────── v0.9.4
  Installed QuasiMonteCarlo ────────────── v0.2.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed SortingAlgorithms ──────────── v0.3.1
  Installed Arpack ─────────────────────── v0.4.0
  Installed Juno ───────────────────────── v0.8.1
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed ReverseDiff ────────────────── v1.2.0
  Installed DiffEqBase ─────────────────── v6.32.1
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed TimerOutputs ───────────────── v0.5.5
  Installed DiffResults ────────────────── v1.0.2
  Installed ConsoleProgressMonitor ─────── v0.1.2
  Installed LightGraphs ────────────────── v1.3.2
  Installed UnPack ─────────────────────── v1.0.0
  Installed ProgressLogging ────────────── v0.1.2
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed ExprTools ──────────────────── v0.1.1
  Installed CuArrays ───────────────────── v2.2.0
  Installed NNlib ──────────────────────── v0.6.6
  Installed CUDAnative ─────────────────── v3.1.0
  Installed CommonSubexpressions ───────── v0.2.0
  Installed FixedPointNumbers ──────────── v0.8.0
  Installed CUDAapi ────────────────────── v4.0.0
  Installed FillArrays ─────────────────── v0.8.8
  Installed Arpack_jll ─────────────────── v3.5.0+3
  Installed IteratorInterfaceExtensions ── v1.0.0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed DiffEqCallbacks ────────────── v2.13.1
  Installed LoggingExtras ──────────────── v0.4.0
  Installed Rmath_jll ──────────────────── v0.2.2+0
  Installed ExponentialUtilities ───────── v1.6.0
  Installed ForwardDiff ────────────────── v0.10.10
  Installed BlackBoxOptim ──────────────── v0.5.0
  Installed FunctionWrappers ───────────── v1.1.1
  Installed ZygoteRules ────────────────── v0.2.0
  Installed CEnum ──────────────────────── v0.3.0
  Installed LabelledArrays ─────────────── v1.2.0
  Installed Colors ─────────────────────── v0.12.0
  Installed Optim ──────────────────────── v0.20.6
  Installed Tracker ────────────────────── v0.2.6
  Installed TreeViews ──────────────────── v0.3.0
  Installed ArrayInterface ─────────────── v2.8.7
  Installed Cthulhu ────────────────────── v1.0.2
  Installed Sobol ──────────────────────── v1.3.0
  Installed VertexSafeGraphs ───────────── v0.1.2
  Installed BinaryProvider ─────────────── v0.5.9
  Installed TerminalLoggers ────────────── v0.1.1
  Installed DataStructures ─────────────── v0.17.15
  Installed DocStringExtensions ────────── v0.8.1
  Installed ChainRulesCore ─────────────── v0.7.5
  Installed OrdinaryDiffEq ─────────────── v5.36.0
Updating `~/.julia/environments/v1.5/Project.toml`
  [aae7a2af] + DiffEqFlux v1.9.0
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [1520ce14] + AbstractTrees v0.3.3
  [79e6a3ab] + Adapt v1.0.1
  [ec485272] + ArnoldiMethod v0.0.4
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+3
  [4fba245c] + ArrayInterface v2.8.7
  [4c555306] + ArrayLayouts v0.2.6
  [b99e7846] + BinaryProvider v0.5.9
  [a134a8b2] + BlackBoxOptim v0.5.0
  [fa961155] + CEnum v0.3.0
  [a9c8d775] + CPUTime v1.0.0
  [3895d2a7] + CUDAapi v4.0.0
  [c5f51814] + CUDAdrv v6.3.0
  [be33ccc6] + CUDAnative v3.1.0
  [d360d2e6] + ChainRulesCore v0.7.5
  [da1fd8a2] + CodeTracking v0.5.11
  [944b1d66] + CodecZlib v0.7.0
  [3da002f7] + ColorTypes v0.10.3
  [5ae59095] + Colors v0.12.0
  [bbf7d656] + CommonSubexpressions v0.2.0
  [34da2185] + Compat v3.9.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [88cd18e8] + ConsoleProgressMonitor v0.1.2
  [f68482b8] + Cthulhu v1.0.2
  [3a865a2d] + CuArrays v2.2.0
  [9a962f9c] + DataAPI v1.3.0
  [864edb3b] + DataStructures v0.17.15
  [2b5f629d] + DiffEqBase v6.32.1
  [459566f4] + DiffEqCallbacks v2.13.1
  [aae7a2af] + DiffEqFlux v1.9.0
  [41bf760c] + DiffEqSensitivity v6.13.0
  [163ba53b] + DiffResults v1.0.2
  [b552c78f] + DiffRules v1.0.1
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.23.2
  [ffbed154] + DocStringExtensions v0.8.1
  [d4d017d3] + ExponentialUtilities v1.6.0
  [e2ba6199] + ExprTools v0.1.1
  [7a1cc6ca] + FFTW v1.2.1
  [f5851436] + FFTW_jll v3.3.9+5
  [1a297f60] + FillArrays v0.8.8
  [6a86dc24] + FiniteDiff v2.3.1
  [53c48c17] + FixedPointNumbers v0.8.0
  [587475ba] + Flux v0.10.4
  [f6369f11] + ForwardDiff v0.10.10
  [069b7b12] + FunctionWrappers v1.1.1
  [0c68f7d7] + GPUArrays v3.3.0
  [61eb1bfa] + GPUCompiler v0.2.0
  [01680d73] + GenericSVD v0.3.0
  [7869d1d1] + IRTools v0.3.2
  [d25df0c9] + Inflate v0.1.2
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [42fd0dbc] + IterativeSolvers v0.8.4
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [e5e0dc1b] + Juno v0.8.1
  [929cbde3] + LLVM v1.4.1
  [2ee39098] + LabelledArrays v1.2.0
  [a5e1c1ea] + LatinHypercubeSampling v1.6.4
  [1d6d02ad] + LeftChildRightSiblingTrees v0.1.2
  [093fc24a] + LightGraphs v1.3.2
  [d3d80556] + LineSearches v7.0.1
  [e6f89c97] + LoggingExtras v0.4.0
  [856f044c] + MKL_jll v2019.0.117+2
  [1914dd2f] + MacroTools v0.5.5
  [e89f7d12] + Media v0.5.0
  [e1d29d7a] + Missings v0.4.3
  [46d2c3a1] + MuladdMacro v0.2.2
  [d41bc354] + NLSolversBase v7.6.1
  [2774e3e8] + NLsolve v4.3.0
  [872c559c] + NNlib v0.6.6
  [77ba4419] + NaNMath v0.3.3
  [4536629a] + OpenBLAS_jll v0.3.9+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [429524aa] + Optim v0.20.6
  [bac558e1] + OrderedCollections v1.2.0
  [1dea7af3] + OrdinaryDiffEq v5.36.0
  [90014a1f] + PDMats v0.9.12
  [d96e819e] + Parameters v0.12.1
  [85a6dd25] + PositiveFactorizations v0.2.3
  [33c8b6b6] + ProgressLogging v0.1.2
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.3.1
  [8a4e6c94] + QuasiMonteCarlo v0.2.0
  [3cdcf5f2] + RecipesBase v1.0.1
  [731186ca] + RecursiveArrayTools v2.3.1
  [f2c3362d] + RecursiveFactorization v0.1.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [37e2e3b7] + ReverseDiff v1.2.0
  [79098fc4] + Rmath v0.6.1
  [f50d1b31] + Rmath_jll v0.2.2+0
  [f2b01f46] + Roots v1.0.1
  [699a6c99] + SimpleTraits v0.9.2
  [ed01d8cd] + Sobol v1.3.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [47a9eef4] + SparseDiffTools v1.7.1
  [d4ead438] + SpatialIndexing v0.1.2
  [276daf66] + SpecialFunctions v0.10.0
  [90137ffa] + StaticArrays v0.12.3
  [2913bbd2] + StatsBase v0.33.0
  [4c63d2b9] + StatsFuns v0.9.4
  [3783bdb8] + TableTraits v1.0.0
  [5d786b92] + TerminalLoggers v0.1.1
  [a759f4b9] + TimerOutputs v0.5.5
  [9f7883ad] + Tracker v0.2.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [a2a6695c] + TreeViews v0.3.0
  [3a884ed6] + UnPack v1.0.0
  [19fa3120] + VertexSafeGraphs v0.1.2
  [a5390f91] + ZipFile v0.9.1
  [83775a58] + Zlib_jll v1.2.11+9
  [e88e6eb3] + Zygote v0.4.20
  [700de1a5] + ZygoteRules v0.2.0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [9fa8497b] + Future
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [9abbd945] + Profile
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [4607b0f0] + SuiteSparse
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building FFTW ─→ `~/.julia/packages/FFTW/5DZuu/deps/build.log`
   Building NNlib → `~/.julia/packages/NNlib/FAI3o/deps/build.log`
    Testing DiffEqFlux
Status `/tmp/jl_T4KZeo/Project.toml`
  [79e6a3ab] Adapt v1.0.1
  [a134a8b2] BlackBoxOptim v0.5.0
  [bcd4f6db] DelayDiffEq v5.24.1
  [2b5f629d] DiffEqBase v6.32.1
  [aae7a2af] DiffEqFlux v1.9.0
  [41bf760c] DiffEqSensitivity v6.13.0
  [163ba53b] DiffResults v1.0.2
  [587475ba] Flux v0.10.4
  [f6369f11] ForwardDiff v0.10.10
  [3933049c] MultistartOptimization v0.1.0
  [76087f3c] NLopt v0.5.1
  [429524aa] Optim v0.20.6
  [1dea7af3] OrdinaryDiffEq v5.36.0
  [33c8b6b6] ProgressLogging v0.1.2
  [731186ca] RecursiveArrayTools v2.3.1
  [ae029012] Requires v1.0.1
  [37e2e3b7] ReverseDiff v1.2.0
  [1bc83da4] SafeTestsets v0.0.1
  [90137ffa] StaticArrays v0.12.3
  [789caeaf] StochasticDiffEq v6.20.0
  [9f7883ad] Tracker v0.2.6
  [e88e6eb3] Zygote v0.4.20
  [700de1a5] ZygoteRules v0.2.0
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [de0858da] Printf
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_T4KZeo/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [1520ce14] AbstractTrees v0.3.3
  [79e6a3ab] Adapt v1.0.1
  [dce04be8] ArgCheck v1.1.0
  [ec485272] ArnoldiMethod v0.0.4
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+3
  [4fba245c] ArrayInterface v2.8.7
  [4c555306] ArrayLayouts v0.2.6
  [9e28174c] BinDeps v1.0.1
  [b99e7846] BinaryProvider v0.5.9
  [a134a8b2] BlackBoxOptim v0.5.0
  [fa961155] CEnum v0.3.0
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [a9c8d775] CPUTime v1.0.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.3.0
  [be33ccc6] CUDAnative v3.1.0
  [d360d2e6] ChainRulesCore v0.7.5
  [da1fd8a2] CodeTracking v0.5.11
  [944b1d66] CodecZlib v0.7.0
  [3da002f7] ColorTypes v0.10.3
  [5ae59095] Colors v0.12.0
  [bbf7d656] CommonSubexpressions v0.2.0
  [34da2185] Compat v3.9.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [f68482b8] Cthulhu v1.0.2
  [3a865a2d] CuArrays v2.2.0
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.15
  [bcd4f6db] DelayDiffEq v5.24.1
  [2b5f629d] DiffEqBase v6.32.1
  [459566f4] DiffEqCallbacks v2.13.1
  [aae7a2af] DiffEqFlux v1.9.0
  [77a26b50] DiffEqNoiseProcess v3.10.0
  [41bf760c] DiffEqSensitivity v6.13.0
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.23.2
  [ffbed154] DocStringExtensions v0.8.1
  [d4d017d3] ExponentialUtilities v1.6.0
  [e2ba6199] ExprTools v0.1.1
  [7a1cc6ca] FFTW v1.2.1
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.8.8
  [6a86dc24] FiniteDiff v2.3.1
  [53c48c17] FixedPointNumbers v0.8.0
  [587475ba] Flux v0.10.4
  [f6369f11] ForwardDiff v0.10.10
  [069b7b12] FunctionWrappers v1.1.1
  [0c68f7d7] GPUArrays v3.3.0
  [61eb1bfa] GPUCompiler v0.2.0
  [01680d73] GenericSVD v0.3.0
  [7869d1d1] IRTools v0.3.2
  [d25df0c9] Inflate v0.1.2
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [42fd0dbc] IterativeSolvers v0.8.4
  [82899510] IteratorInterfaceExtensions v1.0.0
  [e5e0dc1b] Juno v0.8.1
  [929cbde3] LLVM v1.4.1
  [2ee39098] LabelledArrays v1.2.0
  [a5e1c1ea] LatinHypercubeSampling v1.6.4
  [1d6d02ad] LeftChildRightSiblingTrees v0.1.2
  [093fc24a] LightGraphs v1.3.2
  [d3d80556] LineSearches v7.0.1
  [e6f89c97] LoggingExtras v0.4.0
  [856f044c] MKL_jll v2019.0.117+2
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e89f7d12] Media v0.5.0
  [e1d29d7a] Missings v0.4.3
  [46d2c3a1] MuladdMacro v0.2.2
  [3933049c] MultistartOptimization v0.1.0
  [d41bc354] NLSolversBase v7.6.1
  [76087f3c] NLopt v0.5.1
  [2774e3e8] NLsolve v4.3.0
  [872c559c] NNlib v0.6.6
  [77ba4419] NaNMath v0.3.3
  [4536629a] OpenBLAS_jll v0.3.9+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.20.6
  [bac558e1] OrderedCollections v1.2.0
  [1dea7af3] OrdinaryDiffEq v5.36.0
  [90014a1f] PDMats v0.9.12
  [d96e819e] Parameters v0.12.1
  [85a6dd25] PositiveFactorizations v0.2.3
  [33c8b6b6] ProgressLogging v0.1.2
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.3.1
  [8a4e6c94] QuasiMonteCarlo v0.2.0
  [e6cf234a] RandomNumbers v1.4.0
  [3cdcf5f2] RecipesBase v1.0.1
  [731186ca] RecursiveArrayTools v2.3.1
  [f2c3362d] RecursiveFactorization v0.1.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [ae5879a3] ResettableStacks v1.0.0
  [37e2e3b7] ReverseDiff v1.2.0
  [79098fc4] Rmath v0.6.1
  [f50d1b31] Rmath_jll v0.2.2+0
  [f2b01f46] Roots v1.0.1
  [1bc83da4] SafeTestsets v0.0.1
  [699a6c99] SimpleTraits v0.9.2
  [ed01d8cd] Sobol v1.3.0
  [a2af1166] SortingAlgorithms v0.3.1
  [47a9eef4] SparseDiffTools v1.7.1
  [d4ead438] SpatialIndexing v0.1.2
  [276daf66] SpecialFunctions v0.10.0
  [90137ffa] StaticArrays v0.12.3
  [2913bbd2] StatsBase v0.33.0
  [4c63d2b9] StatsFuns v0.9.4
  [789caeaf] StochasticDiffEq v6.20.0
  [3783bdb8] TableTraits v1.0.0
  [5d786b92] TerminalLoggers v0.1.1
  [a759f4b9] TimerOutputs v0.5.5
  [9f7883ad] Tracker v0.2.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [a2a6695c] TreeViews v0.3.0
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.0
  [19fa3120] VertexSafeGraphs v0.1.2
  [a5390f91] ZipFile v0.9.1
  [83775a58] Zlib_jll v1.2.11+9
  [e88e6eb3] Zygote v0.4.20
  [700de1a5] ZygoteRules v0.2.0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [9abbd945] Profile
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [4607b0f0] SuiteSparse
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
WARNING: could not import Compiler.just_construct_ssa into Wrap
416.7086995514811301.86465432569827213.21697213391016149.3929796071194115.2247517913104296.3438136311290279.3936123278511765.5625775751988754.73408970504229446.2626159904189439.55562467607837434.29338639796445430.54262397471921328.93102825992030330.78230280655101637.5616921386252547.3899178101139352.31771747076819448.8559023431533241.1409918445188933.4998573173513127.7136171838481823.8213532431337521.2574969683678819.43364473086034417.9080234863235616.40169427585258414.75827680393393112.9155083938401710.8813206837866058.7182734287630626.5317427624672214.45717155975515762.6440088213855261.23592071815229730.34657206429314730.032376452495214510.26367482940779230.905567097641851.72975726545156162.4738072183786732.93352765725007243.03618679634409672.84498125290393672.49864919108605132.1348949032518721.84171784634708581.64735382952383951.53548374223780541.46787860302471571.40348733006078131.31057624087927451.1723646987133380.98792068128521930.77000396330597080.54099857867771020.327773302321376360.156017818275280080.0445653704883056740.00091322139101779030.0190239786206280320.080410475436539270.159197271761418070.229589835455646730.27324885152407110.28364198270243850.26573545746272670.231707259387955280.195075966066423880.16585180213779310.148215404734272720.140797690163480650.13867239213660060.135911948945067140.127791420961522520.112133203758811030.089657382441687130.063454110359997350.037871264121909730.017167018654110830.0042911560636956050.000132331621225468740.0034254726393664930.0112719546828020260.020185633126746330.027176635651557520.0305475552150724330.0301433293399415230.027042574606087690.0228944748810245740.0192068480124802340.0168492892211720180.0158974341901012840.0157962049318957630.0157121461393411320.0149121397453862370.013034469259305310.0101844853779321530.0068527418229991870.00371107376408517140.4165147233362722.05749907210333312.0370229088210226.5135197460485113.4493268314854941.75595334745193780.84094112859804390.37442848437232390.168534450628907680.113993987252263160.146123478717827850.226085226249190860.330333604729165340.444534373326884170.55998839915566550.67148736086149520.77600647672168410.87189532854251120.95837015434837681.03519180224068191.10245973190405681.1604782310606711.20967136813183121.2505271011940631.28356141199421251.30929540278075081.32824101618583621.34089244428137851.34772122926775031.34917388070383741.34567112361001651.33760820437140931.32535586876996651.30926175199351081.2896520048541721.26683303750284851.2410933007046591.21270505766819881.18192610099156161.14900136156496921.11416445784295411.077639125372521.03964052899088681.00037646561251430.96004837917381170.9188522812487860.87697958751648160.83461759464484320.79194990569877520.74915676965992480.70641524364564860.6638991331799460.6217785606913130.58021964301761350.53938387483431670.499427333461248070.460499739708821740.42274337822788430.386291899150562330.35126903336119110.317787254515817130.28594642748894370.2558324889077440.22751621015976570.201052096409242430.17647747594999640.153811832936124440.13305643256661220.114194281298790780.097190454764755960.081992813256698670.068533108927257250.0567284800940232450.046483294056760050.037691293225716780.0302379803044163580.0240031626280547870.018863561059381280.0146954113248494580.0113769316606047150.0087905797423000960.0068250187158452330.0053767511287227460.0043513374548950640.0036642088220860870.0032410697523287770.0030179127204255330.00294069263292744520.002964718794096250.0030538328905185820.00317944571738445650.00331950398506860.00345745205301092220.00358124310142483430.00368244138331800960.00375544316037069530.0037968299933879190.003804855491655320.0037790561592185770.0037199694116348114416.70869955148316301.87186997430365213.22801705361297149.40648614478837115.2240412249364696.3454391345538679.3977976779125865.5678714713974554.73969630607274446.2681431647925939.5608383606454234.2980229596167530.54633410011867428.9332381463373130.78208250143966437.5587566610162847.3870414634704752.3184906512701248.8589544323429841.14383255919601433.5012140860317727.71329342894746323.81952936942857221.2543767187669819.4294856183711817.90303100693667616.39608500849614714.75230897079328312.90945584534311610.8754625577971288.712882525457966.5270686024001344.4534149599774862.6412962392444671.2342795663056390.3459158046638280.032506748634095760.264310414146053160.90639787468961761.7305156642179892.4743407762289472.9338239544033673.0363286740031682.84506488225275162.49872238818174442.13494430274363721.8416920826943291.6471951659831451.53515198186780831.46736343542057451.40280885504569251.30977827422533061.1715059590677530.98706641658549010.76921762520158130.54033333964074280.32726603243509670.155685347538229820.044402053227207340.00089265358725995560.0191039242369983630.080534769824929170.159307303717266780.229641600525029880.273224851436197740.283552996888048250.26561206968046450.23158584804701470.194985613398158870.165806707487119760.14821387238102470.140826097601411540.13871147379454670.135943057155115480.12780127946737040.112116466759106760.089616889144780110.063399129505176940.037814459743258160.017120978004210560.00426522788223897450.00013060182132885350.00344585479851722280.011306698777051870.0202248123961467770.02721155913652230.0305730930624841660.030158440940405340.027049241017987240.022895782224433470.0192051454721658860.016845112348903880.0158894783750984330.015782221974403340.015690315650227170.0148822708785586060.0129985681020147110.0101464819170533940.0068175358724189420.003683289147449469Test Summary: | Pass  Total
Layers Tests  |    6      6
Test Summary: | Pass  Total
Fast Layers   |    9      9
Training   0%|                                          |  ETA: N/A
494.2089032199091loss: 494   1%|▍                                        |  ETA: 0:07:58
416.7086995514831loss: 417   2%|▉                                        |  ETA: 0:04:03
301.87186997430365loss: 302   3%|█▎                                       |  ETA: 0:02:41
213.22801705361297loss: 213   4%|█▋                                       |  ETA: 0:02:00
149.40648614478843loss: 149   5%|██                                       |  ETA: 0:01:35
115.22404122493646loss: 115   6%|██▌                                      |  ETA: 0:01:19
96.34543913455384loss: 96.3   7%|██▊                                     |  ETA: 0:01:07
79.39779767791259loss: 79.4   8%|███▎                                    |  ETA: 0:00:58
65.56787147139745loss: 65.6   9%|███▋                                    |  ETA: 0:00:51
54.739696306072744loss: 54.7  10%|████                                    |  ETA: 0:00:46
46.26814316479258loss: 46.3  11%|████▍                                   |  ETA: 0:00:42
39.560838360645405loss: 39.6  12%|████▊                                   |  ETA: 0:00:38
34.298022959616745loss: 34.3  13%|█████▎                                  |  ETA: 0:00:35
30.54633410011867loss: 30.5  14%|█████▋                                  |  ETA: 0:00:32
28.933238146337313loss: 28.9  15%|██████                                  |  ETA: 0:00:29
30.78208250143967loss: 30.8  16%|██████▍                                 |  ETA: 0:00:27
37.55875666101628loss: 37.6  17%|██████▊                                 |  ETA: 0:00:26
47.38704146347047loss: 47.4  18%|███████▎                                |  ETA: 0:00:24
52.318490651270146loss: 52.3  19%|███████▋                                |  ETA: 0:00:22
48.85895443234298loss: 48.9  20%|████████                                |  ETA: 0:00:21
41.143832559196loss: 41.1  21%|████████▍                               |  ETA: 0:00:20
33.50121408603177loss: 33.5  22%|████████▊                               |  ETA: 0:00:19
27.713293428947466loss: 27.7  23%|█████████▎                              |  ETA: 0:00:18
23.819529369428558loss: 23.8  24%|█████████▋                              |  ETA: 0:00:17
21.254376718766984loss: 21.3  25%|██████████                              |  ETA: 0:00:16
19.42948561837119loss: 19.4  26%|██████████▍                             |  ETA: 0:00:15
17.90303100693668loss: 17.9  27%|██████████▊                             |  ETA: 0:00:15
16.396085008496147loss: 16.4  28%|███████████▎                            |  ETA: 0:00:14
14.752308970793283loss: 14.8  29%|███████████▋                            |  ETA: 0:00:13
12.909455845343116loss: 12.9  30%|████████████                            |  ETA: 0:00:13
10.875462557797128loss: 10.9  31%|████████████▍                           |  ETA: 0:00:12
8.71288252545796loss: 8.71  32%|████████████▊                           |  ETA: 0:00:12
6.527068602400136loss: 6.53  33%|█████████████▎                          |  ETA: 0:00:11
4.4534149599774855loss: 4.45  34%|█████████████▋                          |  ETA: 0:00:11
2.6412962392444665loss: 2.64  35%|██████████████                          |  ETA: 0:00:10
1.2342795663056394loss: 1.23  36%|██████████████▍                         |  ETA: 0:00:10
0.34591580466382804loss: 0.346  37%|██████████████▍                        |  ETA: 0:00:09
0.03250674863409575loss: 0.0325  38%|██████████████▌                       |  ETA: 0:00:09
0.2643104141460533loss: 0.264  39%|███████████████▎                       |  ETA: 0:00:09
0.9063978746896175loss: 0.906  40%|███████████████▋                       |  ETA: 0:00:08
1.7305156642179889loss: 1.73  41%|████████████████▍                       |  ETA: 0:00:08
2.474340776228947loss: 2.47  42%|████████████████▊                       |  ETA: 0:00:08
2.933823954403367loss: 2.93  43%|█████████████████▎                      |  ETA: 0:00:07
3.036328674003168loss: 3.04  44%|█████████████████▋                      |  ETA: 0:00:07
2.845064882252751loss: 2.85  45%|██████████████████                      |  ETA: 0:00:07
2.498722388181745loss: 2.5  46%|██████████████████▉                      |  ETA: 0:00:07
2.1349443027436377loss: 2.13  47%|██████████████████▊                     |  ETA: 0:00:06
1.8416920826943293loss: 1.84  48%|███████████████████▎                    |  ETA: 0:00:06
1.647195165983145loss: 1.65  49%|███████████████████▋                    |  ETA: 0:00:06
1.5351519818678083loss: 1.54  50%|████████████████████                    |  ETA: 0:00:06
1.467363435420574loss: 1.47  51%|████████████████████▍                   |  ETA: 0:00:05
1.402808855045693loss: 1.4  52%|█████████████████████▍                   |  ETA: 0:00:05
1.3097782742253306loss: 1.31  53%|█████████████████████▎                  |  ETA: 0:00:05
1.171505959067753loss: 1.17  54%|█████████████████████▋                  |  ETA: 0:00:05
0.9870664165854897loss: 0.987  55%|█████████████████████▌                 |  ETA: 0:00:05
0.7692176252015813loss: 0.769  56%|█████████████████████▉                 |  ETA: 0:00:05
0.5403333396407428loss: 0.54  57%|██████████████████████▊                 |  ETA: 0:00:04
0.3272660324350968loss: 0.327  58%|██████████████████████▋                |  ETA: 0:00:04
0.1556853475382298loss: 0.156  59%|███████████████████████                |  ETA: 0:00:04
0.04440205322720733loss: 0.0444  60%|██████████████████████▊               |  ETA: 0:00:04
0.0008926535872599556loss: 0.000893  61%|██████████████████████              |  ETA: 0:00:04
0.019103924236998377loss: 0.0191  62%|███████████████████████▌              |  ETA: 0:00:04
0.08053476982492919loss: 0.0805  63%|████████████████████████              |  ETA: 0:00:03
0.15930730371726676loss: 0.159  64%|█████████████████████████              |  ETA: 0:00:03
0.22964160052502988loss: 0.23  65%|██████████████████████████              |  ETA: 0:00:03
0.2732248514361978loss: 0.273  66%|█████████████████████████▊             |  ETA: 0:00:03
0.2835529968880482loss: 0.284  67%|██████████████████████████▏            |  ETA: 0:00:03
0.2656120696804645loss: 0.266  68%|██████████████████████████▌            |  ETA: 0:00:03
0.23158584804701468loss: 0.232  69%|██████████████████████████▉            |  ETA: 0:00:03
0.19498561339815892loss: 0.195  70%|███████████████████████████▎           |  ETA: 0:00:03
0.1658067074871198loss: 0.166  71%|███████████████████████████▊           |  ETA: 0:00:02
0.14821387238102476loss: 0.148  72%|████████████████████████████▏          |  ETA: 0:00:02
0.14082609760141152loss: 0.141  73%|████████████████████████████▌          |  ETA: 0:00:02
0.13871147379454676loss: 0.139  74%|████████████████████████████▉          |  ETA: 0:00:02
0.13594305715511545loss: 0.136  75%|█████████████████████████████▎         |  ETA: 0:00:02
0.1278012794673704loss: 0.128  76%|█████████████████████████████▋         |  ETA: 0:00:02
0.11211646675910676loss: 0.112  77%|██████████████████████████████         |  ETA: 0:00:02
0.0896168891447801loss: 0.0896  78%|█████████████████████████████▋        |  ETA: 0:00:02
0.06339912950517693loss: 0.0634  79%|██████████████████████████████        |  ETA: 0:00:02
0.03781445974325816loss: 0.0378  80%|██████████████████████████████▍       |  ETA: 0:00:02
0.017120978004210557loss: 0.0171  81%|██████████████████████████████▊       |  ETA: 0:00:01
0.004265227882238975loss: 0.00427  82%|██████████████████████████████▍      |  ETA: 0:00:01
0.00013060182132885353loss: 0.000131  83%|█████████████████████████████▉      |  ETA: 0:00:01
0.0034458547985172228loss: 0.00345  84%|███████████████████████████████▏     |  ETA: 0:00:01
0.01130669877705187loss: 0.0113  85%|████████████████████████████████▎     |  ETA: 0:00:01
0.020224812396146763loss: 0.0202  86%|████████████████████████████████▋     |  ETA: 0:00:01
0.0272115591365223loss: 0.0272  87%|█████████████████████████████████     |  ETA: 0:00:01
0.030573093062484166loss: 0.0306  88%|█████████████████████████████████▌    |  ETA: 0:00:01
0.03015844094040534loss: 0.0302  89%|█████████████████████████████████▉    |  ETA: 0:00:01
0.027049241017987252loss: 0.027  90%|███████████████████████████████████▏   |  ETA: 0:00:01
0.02289578222443347loss: 0.0229  91%|██████████████████████████████████▋   |  ETA: 0:00:01
0.019205145472165897loss: 0.0192  92%|███████████████████████████████████   |  ETA: 0:00:01
0.01684511234890388loss: 0.0168  93%|███████████████████████████████████▍  |  ETA: 0:00:00
0.01588947837509843loss: 0.0159  94%|███████████████████████████████████▊  |  ETA: 0:00:00
0.015782221974403335loss: 0.0158  95%|████████████████████████████████████▏ |  ETA: 0:00:00
0.01569031565022717loss: 0.0157  96%|████████████████████████████████████▌ |  ETA: 0:00:00
0.014882270878558595loss: 0.0149  97%|████████████████████████████████████▉ |  ETA: 0:00:00
0.01299856810201471loss: 0.013  98%|██████████████████████████████████████▎|  ETA: 0:00:00
0.010146481917053394loss: 0.0101  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.0068175358724189405loss: 0.00682 100%|█████████████████████████████████████| Time: 0:00:06
0.00013060182132885353Training 100%|██████████████████████████████████████████| Time: 0:00:07
494.2089032199091473.8759825703607567.1074818633421318.3855315564830028.9648899689183876.117368644930780.16955330167694750.00127452976279778434.4571905150957083e-72.8044413366351072e-82.7293451721924503e-82.729347900600587e-8494.2089032199091473.8237904460742767.225842645127621.36751439899320811.4350691360731788.0109706995672490.32915359623862510.0036303407653235878.934029714091469e-56.246060306129264e-50.00031047251577495510.0058696171661135780.000109832425486265727.733918863503838e-64.2537266437804656e-78.726103760581099e-74.2537266437804656e-72.72458808565546e-72.766701471525958e-72.72458808565546e-72.6483736867625894e-72.648412606822959e-72.6483736867625894e-72.5881397656192965e-72.588142311285918e-72.5881397656192965e-72.508740247077843e-72.508742514801445e-72.508740247077843e-72.508742104639958e-7Starting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},BlackBoxOptim.SimpleSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}
0.00 secs, 0 evals, 0 steps
1783.03107278064751256.82550285638674526.81538225096560.82504517323327107.1049551812449517.445233583252207138.17204843645334316.08960584981133174.99986589268548170.08221266820533269.2421688127938119.79759135119544113.80871132805319100695.61465761672164.576703873347658.267609063849484965.05042716195540548.33505004597113.80871132805319366.4046601432361379.7043246739513217.44523358325220742.28451160100808107.705711657595230.28754456516592314536.9121297606382137.03221713622276112.64604563229604106.560854651295862.32445628373067635.888583606317274965.05042716195552.76380862522166540.147959207378217.445233583252207673737.61385894970.2875445651659231417.445233583252207127.355309150417197.1288405441901317.44523358325220788363.119083470261862.66683652926969.62187485443664119.7915056514134281.02970656230237127.355309150417998.6460562610347107.08506169183512601.1960047745465157.477764524521741.7555314871639972.40916364456416465.68859044653317123.749731811004998.776485542615443107.70571165759523406.685719032634951305.7964766749253187.7619228197289750516.449092982617829.7205808976760.30635645915572129.010826328614196.769341072961770.28754456516592314107.085061691835124526.815382250965982.16792620057440.49901691580846168.79355345220160.825045173233272376.39170356732101479.48883735128110.2554217392659682.5447674295912732.1048274193652861.5677251802900494e65572.771076039995982.167926200574138.1720484364533471.742464016613463.8841701267679960.6932881524416316.08960584981133418.7032786911779625.80144222632051872.40916364456416434.046907788988967829.72058089767163.2860096316430561.09922622424265150.0646768966640560.8250451732332716.879988856645614998.64605626103471086.4420616132393107.7057116575952358.26760906384948736.1050774855572316.08960584981133
Optimization stopped after 101 steps and 0.29 seconds
Termination reason: Max number of steps (100) reached
Steps per second = 351.44
Function evals per second = 574.14
Improvements/step = 0.41000
Total function evaluations = 165


Best candidate found: [4.94558, 4.84665, 4.63731, 4.65602]

Fitness: 0.090658979

Training   0%|                                          |  ETA: N/A
74.23333058147179loss: 74.2   1%|▍                                       |  ETA: 0:00:32
40.41651472333627loss: 40.4   2%|▊                                       |  ETA: 0:00:16
22.057499072103333loss: 22.1   3%|█▎                                      |  ETA: 0:00:10
12.037022908821022loss: 12   4%|█▋                                        |  ETA: 0:00:08
6.513519746048511loss: 6.51   5%|██                                      |  ETA: 0:00:06
3.449326831485494loss: 3.45   6%|██▍                                     |  ETA: 0:00:05
1.7559533474519378loss: 1.76   7%|██▊                                     |  ETA: 0:00:04
0.8409411285980439loss: 0.841   8%|███▏                                   |  ETA: 0:00:04
0.3744284843723239loss: 0.374   9%|███▌                                   |  ETA: 0:00:03
0.16853445062890768loss: 0.169  10%|███▉                                   |  ETA: 0:00:03
0.11399398725226316loss: 0.114  11%|████▎                                  |  ETA: 0:00:03
0.14612347871782785loss: 0.146  12%|████▋                                  |  ETA: 0:00:02
0.22608522624919086loss: 0.226  13%|█████▏                                 |  ETA: 0:00:02
0.33033360472916534loss: 0.33  14%|█████▋                                  |  ETA: 0:00:02
0.44453437332688417loss: 0.445  15%|█████▉                                 |  ETA: 0:00:02
0.5599883991556655loss: 0.56  16%|██████▍                                 |  ETA: 0:00:02
0.6714873608614952loss: 0.671  17%|██████▋                                |  ETA: 0:00:02
0.7760064767216841loss: 0.776  18%|███████                                |  ETA: 0:00:02
0.8718953285425112loss: 0.872  19%|███████▍                               |  ETA: 0:00:01
0.9583701543483768loss: 0.958  20%|███████▊                               |  ETA: 0:00:01
1.0351918022406819loss: 1.04  21%|████████▍                               |  ETA: 0:00:01
1.1024597319040568loss: 1.1  22%|█████████                                |  ETA: 0:00:01
1.160478231060671loss: 1.16  23%|█████████▎                              |  ETA: 0:00:01
1.2096713681318312loss: 1.21  24%|█████████▋                              |  ETA: 0:00:01
1.250527101194063loss: 1.25  25%|██████████                              |  ETA: 0:00:01
1.2835614119942125loss: 1.28  26%|██████████▍                             |  ETA: 0:00:01
1.3092954027807508loss: 1.31  27%|██████████▊                             |  ETA: 0:00:01
1.3282410161858362loss: 1.33  28%|███████████▎                            |  ETA: 0:00:01
1.3408924442813785loss: 1.34  29%|███████████▋                            |  ETA: 0:00:01
1.3477212292677503loss: 1.35  30%|████████████                            |  ETA: 0:00:01
1.3491738807038374loss: 1.35  31%|████████████▍                           |  ETA: 0:00:01
1.3456711236100165loss: 1.35  32%|████████████▊                           |  ETA: 0:00:01
1.3376082043714093loss: 1.34  33%|█████████████▎                          |  ETA: 0:00:01
1.3253558687699665loss: 1.33  34%|█████████████▋                          |  ETA: 0:00:01
1.3092617519935108loss: 1.31  35%|██████████████                          |  ETA: 0:00:01
1.289652004854172loss: 1.29  36%|██████████████▍                         |  ETA: 0:00:01
1.2668330375028485loss: 1.27  37%|██████████████▊                         |  ETA: 0:00:01
1.241093300704659loss: 1.24  38%|███████████████▎                        |  ETA: 0:00:01
1.2127050576681988loss: 1.21  39%|███████████████▋                        |  ETA: 0:00:01
1.1819261009915616loss: 1.18  40%|████████████████                        |  ETA: 0:00:01
1.1490013615649692loss: 1.15  41%|████████████████▍                       |  ETA: 0:00:01
1.1141644578429541loss: 1.11  42%|████████████████▊                       |  ETA: 0:00:01
1.07763912537252loss: 1.08  43%|█████████████████▎                      |  ETA: 0:00:00
1.0396405289908868loss: 1.04  44%|█████████████████▋                      |  ETA: 0:00:00
1.0003764656125143loss: 1  45%|███████████████████▍                       |  ETA: 0:00:00
0.9600483791738117loss: 0.96  46%|██████████████████▍                     |  ETA: 0:00:00
0.918852281248786loss: 0.919  47%|██████████████████▍                    |  ETA: 0:00:00
0.8769795875164816loss: 0.877  48%|██████████████████▊                    |  ETA: 0:00:00
0.8346175946448432loss: 0.835  49%|███████████████████▏                   |  ETA: 0:00:00
0.7919499056987752loss: 0.792  50%|███████████████████▌                   |  ETA: 0:00:00
0.7491567696599248loss: 0.749  51%|███████████████████▉                   |  ETA: 0:00:00
0.7064152436456486loss: 0.706  52%|████████████████████▎                  |  ETA: 0:00:00
0.663899133179946loss: 0.664  53%|████████████████████▋                  |  ETA: 0:00:00
0.621778560691313loss: 0.622  54%|█████████████████████                  |  ETA: 0:00:00
0.5802196430176135loss: 0.58  55%|██████████████████████                  |  ETA: 0:00:00
0.5393838748343167loss: 0.539  56%|█████████████████████▉                 |  ETA: 0:00:00
0.49942733346124807loss: 0.499  57%|██████████████████████▎                |  ETA: 0:00:00
0.46049973970882174loss: 0.46  58%|███████████████████████▎                |  ETA: 0:00:00
0.4227433782278843loss: 0.423  59%|███████████████████████                |  ETA: 0:00:00
0.38629189915056233loss: 0.386  60%|███████████████████████▍               |  ETA: 0:00:00
0.3512690333611911loss: 0.351  61%|███████████████████████▊               |  ETA: 0:00:00
0.31778725451581713loss: 0.318  62%|████████████████████████▏              |  ETA: 0:00:00
0.2859464274889437loss: 0.286  63%|████████████████████████▋              |  ETA: 0:00:00
0.255832488907744loss: 0.256  64%|█████████████████████████              |  ETA: 0:00:00
0.2275162101597657loss: 0.228  65%|█████████████████████████▍             |  ETA: 0:00:00
0.20105209640924243loss: 0.201  66%|█████████████████████████▊             |  ETA: 0:00:00
0.1764774759499964loss: 0.176  67%|██████████████████████████▏            |  ETA: 0:00:00
0.15381183293612444loss: 0.154  68%|██████████████████████████▌            |  ETA: 0:00:00
0.1330564325666122loss: 0.133  69%|██████████████████████████▉            |  ETA: 0:00:00
0.11419428129879078loss: 0.114  70%|███████████████████████████▎           |  ETA: 0:00:00
0.09719045476475596loss: 0.0972  71%|███████████████████████████           |  ETA: 0:00:00
0.08199281325669867loss: 0.082  72%|████████████████████████████▏          |  ETA: 0:00:00
0.06853310892725725loss: 0.0685  73%|███████████████████████████▊          |  ETA: 0:00:00
0.056728480094023245loss: 0.0567  74%|████████████████████████████▏         |  ETA: 0:00:00
0.04648329405676005loss: 0.0465  75%|████████████████████████████▌         |  ETA: 0:00:00
0.03769129322571678loss: 0.0377  76%|████████████████████████████▉         |  ETA: 0:00:00
0.030237980304416358loss: 0.0302  77%|█████████████████████████████▎        |  ETA: 0:00:00
0.024003162628054787loss: 0.024  78%|██████████████████████████████▍        |  ETA: 0:00:00
0.01886356105938128loss: 0.0189  79%|██████████████████████████████        |  ETA: 0:00:00
0.014695411324849458loss: 0.0147  80%|██████████████████████████████▍       |  ETA: 0:00:00
0.011376931660604715loss: 0.0114  81%|██████████████████████████████▊       |  ETA: 0:00:00
0.008790579742300096loss: 0.00879  82%|██████████████████████████████▍      |  ETA: 0:00:00
0.006825018715845233loss: 0.00683  83%|██████████████████████████████▊      |  ETA: 0:00:00
0.005376751128722746loss: 0.00538  84%|███████████████████████████████▏     |  ETA: 0:00:00
0.004351337454895064loss: 0.00435  85%|███████████████████████████████▌     |  ETA: 0:00:00
0.003664208822086087loss: 0.00366  86%|███████████████████████████████▉     |  ETA: 0:00:00
0.003241069752328777loss: 0.00324  87%|████████████████████████████████▎    |  ETA: 0:00:00
0.003017912720425533loss: 0.00302  88%|████████████████████████████████▌    |  ETA: 0:00:00
0.0029406926329274452loss: 0.00294  89%|████████████████████████████████▉    |  ETA: 0:00:00
0.00296471879409625loss: 0.00296  90%|█████████████████████████████████▎   |  ETA: 0:00:00
0.003053832890518582loss: 0.00305  91%|█████████████████████████████████▋   |  ETA: 0:00:00
0.0031794457173844565loss: 0.00318  92%|██████████████████████████████████   |  ETA: 0:00:00
0.0033195039850686loss: 0.00332  93%|██████████████████████████████████▍  |  ETA: 0:00:00
0.0034574520530109222loss: 0.00346  94%|██████████████████████████████████▊  |  ETA: 0:00:00
0.0035812431014248343loss: 0.00358  95%|███████████████████████████████████▏ |  ETA: 0:00:00
0.0036824413833180096loss: 0.00368  96%|███████████████████████████████████▌ |  ETA: 0:00:00
0.0037554431603706953loss: 0.00376  97%|███████████████████████████████████▉ |  ETA: 0:00:00
0.003796829993387919loss: 0.0038  98%|█████████████████████████████████████▎|  ETA: 0:00:00
0.00380485549165532loss: 0.0038  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.003779056159218577loss: 0.00378 100%|█████████████████████████████████████| Time: 0:00:00
0.0029406926329274452Training 100%|██████████████████████████████████████████| Time: 0:00:00
74.233330581471791.56135771993787721.51943291733128061.51473100623542180.68242629663728870.191372695910355050.00019358396316548111.7955751251456144e-61.0477433167206356e-107.924036678678786e-177.924038666328425e-17Layers SciML Tests: Error During Test at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:25
  Got exception outside of a @test
  LoadError: TypeError: in typeassert, expected NLopt.Callback_Data, got a value of type Tuple{Int64,Int64}
  Stacktrace:
   [1] nlopt_callback_wrapper(::UInt32, ::Ptr{Float64}, ::Ptr{Float64}, ::Ptr{Nothing}) at /home/pkgeval/.julia/packages/NLopt/eqN9a/src/NLopt.jl:411
   [2] optimize! at /home/pkgeval/.julia/packages/NLopt/eqN9a/src/NLopt.jl:604 [inlined]
   [3] optimize at /home/pkgeval/.julia/packages/NLopt/eqN9a/src/NLopt.jl:611 [inlined]
   [4] local_minimization(::MultistartOptimization.NLoptLocalMethod, ::MultistartOptimization.MinimizationProblem{DiffEqFlux.var"#171#172"{typeof(Main.##373.loss_fd),DiffEqFlux.NullData},Array{Float64,1}}, ::Array{Float64,1}) at /home/pkgeval/.julia/packages/MultistartOptimization/BXoN7/src/MultistartOptimization.jl:126
   [5] (::MultistartOptimization.var"#_step#11"{MultistartOptimization.TikTak,MultistartOptimization.NLoptLocalMethod,MultistartOptimization.MinimizationProblem{DiffEqFlux.var"#171#172"{typeof(Main.##373.loss_fd),DiffEqFlux.NullData},Array{Float64,1}}})(::MultistartOptimization.LocationValue{Array{Float64,1},Float64}, ::Tuple{Int64,MultistartOptimization.LocationValue{Array{Float64,1},Float64}}) at /home/pkgeval/.julia/packages/MultistartOptimization/BXoN7/src/MultistartOptimization.jl:188
   [6] BottomRF at ./reduce.jl:81 [inlined]
   [7] _foldl_impl(::Base.BottomRF{MultistartOptimization.var"#_step#11"{MultistartOptimization.TikTak,MultistartOptimization.NLoptLocalMethod,MultistartOptimization.MinimizationProblem{DiffEqFlux.var"#171#172"{typeof(Main.##373.loss_fd),DiffEqFlux.NullData},Array{Float64,1}}}}, ::MultistartOptimization.LocationValue{Array{Float64,1},Float64}, ::Base.Iterators.Enumerate{SubArray{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1,Array{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1},Tuple{UnitRange{Int64}},true}}) at ./reduce.jl:62
   [8] foldl_impl at ./reduce.jl:48 [inlined]
   [9] mapfoldl_impl(::typeof(identity), ::MultistartOptimization.var"#_step#11"{MultistartOptimization.TikTak,MultistartOptimization.NLoptLocalMethod,MultistartOptimization.MinimizationProblem{DiffEqFlux.var"#171#172"{typeof(Main.##373.loss_fd),DiffEqFlux.NullData},Array{Float64,1}}}, ::NamedTuple{(:init,),Tuple{MultistartOptimization.LocationValue{Array{Float64,1},Float64}}}, ::Base.Iterators.Enumerate{SubArray{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1,Array{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1},Tuple{UnitRange{Int64}},true}}) at ./reduce.jl:44
   [10] mapfoldl(::Function, ::Function, ::Base.Iterators.Enumerate{SubArray{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1,Array{MultistartOptimization.LocationValue{Array{Float64,1},Float64},1},Tuple{UnitRange{Int64}},true}}; kw::Base.Iterators.Pairs{Symbol,MultistartOptimization.LocationValue{Array{Float64,1},Float64},Tuple{Symbol},NamedTuple{(:init,),Tuple{MultistartOptimization.LocationValue{Array{Float64,1},Float64}}}}) at ./reduce.jl:160
   [11] #foldl#202 at ./reduce.jl:178 [inlined]
   [12] multistart_minimization(::MultistartOptimization.TikTak, ::MultistartOptimization.NLoptLocalMethod, ::MultistartOptimization.MinimizationProblem{DiffEqFlux.var"#171#172"{typeof(Main.##373.loss_fd),DiffEqFlux.NullData},Array{Float64,1}}) at /home/pkgeval/.julia/packages/MultistartOptimization/BXoN7/src/MultistartOptimization.jl:191
   [13] sciml_train(::Function, ::Array{Float64,1}, ::MultistartOptimization.TikTak, ::Base.Iterators.Cycle{Tuple{DiffEqFlux.NullData}}; lower_bounds::Array{Float64,1}, upper_bounds::Array{Float64,1}, local_method::NLopt.Algorithm, maxiters::Int64, kwargs::Base.Iterators.Pairs{Symbol,Main.##373.var"#19#20",Tuple{Symbol},NamedTuple{(:cb,),Tuple{Main.##373.var"#19#20"}}}) at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/src/require.jl:138
   [14] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/layers_sciml.jl:96
   [15] include(::Function, ::Module, ::String) at ./Base.jl:380
   [16] include at ./Base.jl:368 [inlined]
   [17] include(::String) at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:23
   [18] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/runtests.jl:11
   [19] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/runtests.jl:11
   [21] eval(::Module, ::Any) at ./boot.jl:331
   [22] top-level scope at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:23
   [23] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/runtests.jl:11
   [24] top-level scope at timing.jl:174
   [25] include(::String) at ./client.jl:457
   [26] top-level scope at none:6
   [27] eval(::Module, ::Any) at ./boot.jl:331
   [28] exec_options(::Base.JLOptions) at ./client.jl:272
   [29] _start() at ./client.jl:506
  in expression starting at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/layers_sciml.jl:96
  
Test Summary:      | Pass  Error  Total
Layers SciML Tests |    9      1     10
ERROR: LoadError: Some tests did not pass: 9 passed, 0 failed, 1 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/DiffEqFlux/gMXy7/test/runtests.jl:7
ERROR: Package DiffEqFlux errored during testing
Stacktrace:
 [1] pkgerror(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1557
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:327
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:314
 [5] #test#61 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]
 [7] #test#60 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65
 [11] top-level scope at none:16
