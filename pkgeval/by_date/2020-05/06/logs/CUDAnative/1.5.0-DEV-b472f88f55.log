Julia Version 1.5.0-DEV.862
Commit b472f88f55 (2020-05-06 01:04 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Adapt ────────────── v1.0.1
  Installed CEnum ────────────── v0.2.0
  Installed CUDAapi ──────────── v4.0.0
  Installed TimerOutputs ─────── v0.5.5
  Installed ExprTools ────────── v0.1.1
  Installed BinaryProvider ───── v0.5.9
  Installed LLVM ─────────────── v1.4.1
  Installed CUDAnative ───────── v3.0.4
  Installed Cthulhu ──────────── v1.0.2
  Installed CodeTracking ─────── v0.5.11
  Installed OrderedCollections ─ v1.2.0
  Installed DataStructures ───── v0.17.15
  Installed CUDAdrv ──────────── v6.3.0
Updating `~/.julia/environments/v1.5/Project.toml`
  [be33ccc6] + CUDAnative v3.0.4
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [79e6a3ab] + Adapt v1.0.1
  [b99e7846] + BinaryProvider v0.5.9
  [fa961155] + CEnum v0.2.0
  [3895d2a7] + CUDAapi v4.0.0
  [c5f51814] + CUDAdrv v6.3.0
  [be33ccc6] + CUDAnative v3.0.4
  [da1fd8a2] + CodeTracking v0.5.11
  [f68482b8] + Cthulhu v1.0.2
  [864edb3b] + DataStructures v0.17.15
  [e2ba6199] + ExprTools v0.1.1
  [929cbde3] + LLVM v1.4.1
  [bac558e1] + OrderedCollections v1.2.0
  [a759f4b9] + TimerOutputs v0.5.5
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing CUDAnative
Status `/tmp/jl_mUMy0R/Project.toml`
  [79e6a3ab] Adapt v1.0.1
  [b99e7846] BinaryProvider v0.5.9
  [fa961155] CEnum v0.2.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.3.0
  [be33ccc6] CUDAnative v3.0.4
  [f68482b8] Cthulhu v1.0.2
  [864edb3b] DataStructures v0.17.15
  [e2ba6199] ExprTools v0.1.1
  [929cbde3] LLVM v1.4.1
  [a759f4b9] TimerOutputs v0.5.5
  [b77e0a4c] InteractiveUtils
  [8f399da3] Libdl
  [44cfe95a] Pkg
  [de0858da] Printf
  [8dfed614] Test
Status `/tmp/jl_mUMy0R/Manifest.toml`
  [79e6a3ab] Adapt v1.0.1
  [b99e7846] BinaryProvider v0.5.9
  [fa961155] CEnum v0.2.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.3.0
  [be33ccc6] CUDAnative v3.0.4
  [da1fd8a2] CodeTracking v0.5.11
  [f68482b8] Cthulhu v1.0.2
  [864edb3b] DataStructures v0.17.15
  [e2ba6199] ExprTools v0.1.1
  [929cbde3] LLVM v1.4.1
  [bac558e1] OrderedCollections v1.2.0
  [a759f4b9] TimerOutputs v0.5.5
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
[ Info: Testing using device Tesla T4 (compute capability 7.5.0, 14.535 GiB available memory) on CUDA driver 10.2.0 and toolkit 10.2.89
non-isbits arguments: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:353
  Got exception outside of a @test
  GPU compilation of kernel1(Type{Int64}, Int64) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#kernel1#304",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#kernel1#304", ::Type{Tuple{Type{Int64},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157 [inlined]
   [16] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:358 [inlined]
   [17] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [18] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:354 [inlined]
   [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:169 [inlined]
   [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [23] include(::String) at ./client.jl:457
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [25] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [26] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [27] include(::String) at ./client.jl:457
   [28] top-level scope at none:6
   [29] eval(::Module, ::Any) at ./boot.jl:331
   [30] exec_options(::Base.JLOptions) at ./client.jl:272
   [31] _start() at ./client.jl:506
  
stack traces at different debug levels: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558
  Got exception outside of a @test
  TypeError: non-boolean (Nothing) used in boolean context
  Stacktrace:
   [1] julia_script(::String, ::Cmd) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:80
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:573 [inlined]
   [3] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:560 [inlined]
   [5] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558 [inlined]
   [7] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [8] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [9] include(::String) at ./client.jl:457
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [11] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [12] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [13] include(::String) at ./client.jl:457
   [14] top-level scope at none:6
   [15] eval(::Module, ::Any) at ./boot.jl:331
   [16] exec_options(::Base.JLOptions) at ./client.jl:272
   [17] _start() at ./client.jl:506
  
#329: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:600
  Got exception outside of a @test
  TypeError: non-boolean (Nothing) used in boolean context
  Stacktrace:
   [1] julia_script(::String, ::Cmd) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:80
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:613 [inlined]
   [3] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:602 [inlined]
   [5] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:558 [inlined]
   [7] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [8] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/execution.jl:5
   [9] include(::String) at ./client.jl:457
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:164 [inlined]
   [11] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [12] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [13] include(::String) at ./client.jl:457
   [14] top-level scope at none:6
   [15] eval(::Module, ::Any) at ./boot.jl:331
   [16] exec_options(::Base.JLOptions) at ./client.jl:272
   [17] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2473#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2473#kernel#611", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2473#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2473#kernel#611", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2473#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2473#kernel#611", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2473#kernel#611",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2473#kernel#611", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:994
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:980
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2477#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2477#kernel#612", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2477#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2477#kernel#612", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2477#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2477#kernel#612", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2477#kernel#612",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2477#kernel#612", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1014
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1000
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2481#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2481#kernel#613", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2481#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2481#kernel#613", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2481#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2481#kernel#613", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2481#kernel#613",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2481#kernel#613", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1034
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1020
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Type{Float32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2489#kernel#615",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2489#kernel#615", ::Type{Tuple{CuDeviceArray{Float64,1,CUDAnative.AS.Global},Type{Float64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1070
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1061
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1058
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Type{Int32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Type{Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{UInt32,1,CUDAnative.AS.Global},Type{UInt32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{UInt64,1,CUDAnative.AS.Global},Type{UInt64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Type{Float32}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
  Got exception outside of a @test
  BoundsError: attempt to access LLVM.FunctionParameterSet
    at index [2]
  Stacktrace:
   [1] getindex at /home/pkgeval/.julia/packages/LLVM/5PewI/src/core/function.jl:88 [inlined]
   [2] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:64
   [3] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [5] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [6] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [7] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [8] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [9] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [10] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2493#kernel#616",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [11] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [12] macro expansion at ./lock.jl:183 [inlined]
   [13] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [14] cufunction(::var"#2493#kernel#616", ::Type{Tuple{CuDeviceArray{Float64,1,CUDAnative.AS.Global},Type{Float64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [17] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1088
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [19] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1079
   [20] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [21] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1076
   [22] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [23] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:903
   [24] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [25] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [26] include(::String) at ./client.jl:457
   [27] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [28] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [30] include(::String) at ./client.jl:457
   [31] top-level scope at none:6
   [32] eval(::Module, ::Any) at ./boot.jl:331
   [33] exec_options(::Base.JLOptions) at ./client.jl:272
   [34] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{Float32}, CuDeviceArray{Float32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Float32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{Float32},CuDeviceArray{Float32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Float64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
  Got exception outside of a @test
  GPU compilation of #2503#kernel(Type{Float64}, CuDeviceArray{Float64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Float64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2503#kernel#619",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2503#kernel#619", ::Type{Tuple{Type{Float64},CuDeviceArray{Float64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1142
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1133
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1130
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2506#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2506#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2506#kernel#620", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2506#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2506#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2506#kernel#620", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2506#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2506#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2506#kernel#620", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
  Got exception outside of a @test
  GPU compilation of #2506#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2506#kernel#620",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2506#kernel#620", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1157
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1148
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2509#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2509#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2509#kernel#621", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2509#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2509#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2509#kernel#621", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2509#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2509#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2509#kernel#621", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
  Got exception outside of a @test
  GPU compilation of #2509#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2509#kernel#621",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2509#kernel#621", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1174
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1163
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2512#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2512#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2512#kernel#622", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2512#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2512#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2512#kernel#622", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2512#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2512#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2512#kernel#622", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
  Got exception outside of a @test
  GPU compilation of #2512#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2512#kernel#622",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2512#kernel#622", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1192
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1181
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2515#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2515#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2515#kernel#623", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2515#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2515#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2515#kernel#623", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2515#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2515#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2515#kernel#623", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
  Got exception outside of a @test
  GPU compilation of #2515#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2515#kernel#623",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2515#kernel#623", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1211
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1199
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2518#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2518#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2518#kernel#624", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2518#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2518#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2518#kernel#624", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2518#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2518#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2518#kernel#624", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
  Got exception outside of a @test
  GPU compilation of #2518#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2518#kernel#624",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2518#kernel#624", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1227
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1218
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2521#kernel(Type{Int32}, CuDeviceArray{Int32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2521#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2521#kernel#625", ::Type{Tuple{Type{Int32},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = Int64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2521#kernel(Type{Int64}, CuDeviceArray{Int64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{Int64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2521#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2521#kernel#625", ::Type{Tuple{Type{Int64},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2521#kernel(Type{UInt32}, CuDeviceArray{UInt32,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt32}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2521#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2521#kernel#625", ::Type{Tuple{Type{UInt32},CuDeviceArray{UInt32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
T = UInt64: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
  Got exception outside of a @test
  GPU compilation of #2521#kernel(Type{UInt64}, CuDeviceArray{UInt64,1,CUDAnative.AS.Global}) failed
  KernelError: passing and using non-bitstype argument
  
  Argument 2 to your kernel function is of type Type{UInt64}.
  That type is not isbits, and such arguments are only allowed when they are unused by the kernel.
  
  Stacktrace:
   [1] check_invocation(::CUDAnative.CompilerJob, ::LLVM.Function) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/validation.jl:72
   [2] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:185 [inlined]
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:229 [inlined]
   [4] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:184
   [5] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:45
   [6] #compile#171 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/compiler/driver.jl:33 [inlined]
   [7] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:326
   [8] #219 at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:393 [inlined]
   [9] get!(::CUDAnative.var"#219#220"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},var"#2521#kernel#625",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:454
   [10] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:392 [inlined]
   [11] macro expansion at ./lock.jl:183 [inlined]
   [12] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:391
   [13] cufunction(::var"#2521#kernel#625", ::Type{Tuple{Type{UInt64},CuDeviceArray{UInt64,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [14] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:419
   [15] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/src/execution.jl:157
   [16] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1242
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188
   [18] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [20] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1233
   [21] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [22] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:1129
   [23] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [24] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/cuda.jl:5
   [25] include(::String) at ./client.jl:457
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:167 [inlined]
   [27] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [28] top-level scope at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:14
   [29] include(::String) at ./client.jl:457
   [30] top-level scope at none:6
   [31] eval(::Module, ::Any) at ./boot.jl:331
   [32] exec_options(::Base.JLOptions) at ./client.jl:272
   [33] _start() at ./client.jl:506
  
MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32: Error During Test at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/util.jl:109
 Unexpected Pass
 Expression: $(Expr(:escape, quote
    #= /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/device/wmma.jl:235 =# @cuda threads = 32 kernel(a_dev, b_dev, c_dev, d_dev, alpha, beta)
    d = Array(d_dev)
    new_a = if a_layout == ColMajor
            a
        else
            transpose(a)
        end
    new_b = if b_layout == ColMajor
            b
        else
            transpose(b)
        end
    new_c = if c_layout == ColMajor
            c
        else
            transpose(c)
        end
    new_d = if d_layout == ColMajor
            d
        else
            transpose(d)
        end
    if do_mac
        all(isapprox.(alpha * new_a * new_b + beta * new_c, new_d; rtol = sqrt(eps(Float16))))
    else
        all(isapprox.(alpha * new_a * new_b, new_d; rtol = sqrt(eps(Float16))))
    end
end))
 Got correct result, please change to @test if no longer broken.

 ──────────────────────────────────────────────────────────────────────────────
                                       Time                   Allocations      
                               ──────────────────────   ───────────────────────
       Tot / % measured:             591s / 8.36%           14.1GiB / 15.3%    

 Section               ncalls     time   %tot     avg     alloc   %tot      avg
 ──────────────────────────────────────────────────────────────────────────────
 LLVM middle-end          631    28.8s  58.3%  45.6ms    783MiB  35.4%  1.24MiB
   IR generation          631    16.4s  33.3%  26.0ms    744MiB  33.7%  1.18MiB
     emission             631    7.98s  16.2%  12.7ms    507MiB  22.9%   823KiB
     rewrite              631    5.68s  11.5%  9.01ms    162MiB  7.32%   263KiB
       hide unreach...  3.26k    2.55s  5.17%   784μs   26.3MiB  1.19%  8.28KiB
         find           3.26k    1.99s  4.03%   612μs   1.40MiB  0.06%     451B
         predecessors   3.26k    391ms  0.79%   120μs   11.5MiB  0.52%  3.62KiB
         replace        3.26k    132ms  0.27%  40.7μs   2.39MiB  0.11%     771B
       lower throw        631    1.17s  2.37%  1.85ms   52.7MiB  2.39%  85.6KiB
       hide trap          631    117ms  0.24%   186μs   3.40MiB  0.15%  5.51KiB
     clean-up             631    114ms  0.23%   180μs   6.68MiB  0.30%  10.8KiB
   optimization           625    7.08s  14.3%  11.3ms   29.6MiB  1.34%  48.4KiB
   device library          37    4.84s  9.81%   131ms    505KiB  0.02%  13.6KiB
   runtime library        120    265ms  0.54%  2.21ms    173KiB  0.01%  1.44KiB
 validation             1.16k    16.0s  32.4%  13.8ms   1.38GiB  63.8%  1.21MiB
 LLVM back-end            489    3.70s  7.49%  7.56ms   7.51MiB  0.34%  15.7KiB
   machine-code gen...    489    3.48s  7.05%  7.11ms   4.40MiB  0.20%  9.22KiB
   preparation            489    218ms  0.44%   445μs   3.10MiB  0.14%  6.50KiB
 device runtime lib...      9    796ms  1.61%  88.5ms   9.01MiB  0.41%  1.00MiB
 Julia front-end          632   77.4ms  0.16%   122μs    208KiB  0.01%     338B
 strip debug info          30    203μs  0.00%  6.77μs     0.00B  0.00%    0.00B
 ──────────────────────────────────────────────────────────────────────────────
Test Summary:                                                                                   | Pass  Error  Total
CUDAnative                                                                                      |  539    185    724
  base interface                                                                                |              No tests
  pointer                                                                                       |   20            20
  code generation                                                                               |   84            84
  code generation (relying on a device)                                                         |    8             8
  execution                                                                                     |   73      3     76
    @cuda                                                                                       |   14            14
    argument passing                                                                            |   30      1     31
      manually allocated                                                                        |    1             1
      scalar through single-value array                                                         |    1             1
      scalar through single-value array, using device function                                  |    1             1
      tuples                                                                                    |    1             1
      ghost function parameters                                                                 |    2             2
      immutables                                                                                |    1             1
      automatic recompilation                                                                   |    2             2
      automatic recompilation (bis)                                                             |    2             2
      non-isbits arguments                                                                      |           1      1
      splatting                                                                                 |    3             3
      object invoke                                                                             |    1             1
      closures                                                                                  |    1             1
      conversions                                                                               |    8             8
      argument count                                                                            |    4             4
      keyword arguments                                                                         |              No tests
      captured values                                                                           |    2             2
    exceptions                                                                                  |           2      2
      stack traces at different debug levels                                                    |           1      1
      #329                                                                                      |           1      1
    shmem divergence bug                                                                        |    7             7
    dynamic parallelism                                                                         |   11            11
    cooperative groups                                                                          |    1             1
    threading                                                                                   |   10            10
  pointer                                                                                       |   37            37
  device arrays                                                                                 |   20            20
  CUDA functionality                                                                            |  198     54    252
    indexing                                                                                    |    1             1
    math                                                                                        |   71            71
    formatted output                                                                            |    6             6
    @cuprint                                                                                    |   27            27
    assertion                                                                                   |              No tests
    shared memory                                                                               |   14            14
    data movement and conversion                                                                |   17            17
    clock and nanosleep                                                                         |              No tests
    parallel synchronization and communication                                                  |   16            16
    libcudadevrt                                                                                |              No tests
    atomics (low-level)                                                                         |   26     24     50
      atomic_add                                                                                |    6             6
      atomic_sub                                                                                |    6             6
      atomic_inc                                                                                |    1             1
      atomic_dec                                                                                |    1             1
      atomic_xchg                                                                               |    4             4
      atomic_and                                                                                |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      atomic_or                                                                                 |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      atomic_xor                                                                                |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      atomic_cas                                                                                |    4             4
      atomic_max                                                                                |           6      6
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
        T = Float32                                                                             |           1      1
        T = Float64                                                                             |           1      1
      atomic_min                                                                                |           6      6
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
        T = Float32                                                                             |           1      1
        T = Float64                                                                             |           1      1
      atomic_mul                                                                                |    2             2
      atomic_div                                                                                |    2             2
    atomics (high-level)                                                                        |   20     30     50
      add                                                                                       |           6      6
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
        T = Float32                                                                             |           1      1
        T = Float64                                                                             |           1      1
      sub                                                                                       |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      and                                                                                       |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      or                                                                                        |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      xor                                                                                       |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      max                                                                                       |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      min                                                                                       |           4      4
        T = Int32                                                                               |           1      1
        T = Int64                                                                               |           1      1
        T = UInt32                                                                              |           1      1
        T = UInt64                                                                              |           1      1
      macro                                                                                     |   20            20
  WMMA                                                                                          |   82    128    210
    LLVM intrinsics                                                                             |   52            52
    Flattening/unflattening                                                                     |   14            14
    Broadcasting over fragments: size=1, type=Float16                                           |    2             2
    Broadcasting over fragments: size=1, type=Float32                                           |    2             2
    Broadcasting over fragments: size=2, type=Float16                                           |    2             2
    Broadcasting over fragments: size=2, type=Float32                                           |    2             2
    Broadcasting over fragments: size=5, type=Float16                                           |    2             2
    Broadcasting over fragments: size=5, type=Float32                                           |    2             2
    CUDA C-style API                                                                            |         128    128
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: ColMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: ColMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: ColMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: ColMajor, C type: Float32, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float16, D type: Float32 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float16 |           1      1
      MAC: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
      MUL: A: RowMajor, B: RowMajor, C: RowMajor, D: RowMajor, C type: Float32, D type: Float32 |           1      1
    Codegen addressing                                                                          |    4             4
  NVTX                                                                                          |              No tests
  examples                                                                                      |    6             6
ERROR: LoadError: Some tests did not pass: 539 passed, 0 failed, 185 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/CUDAnative/ierw8/test/runtests.jl:12
ERROR: Package CUDAnative errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1515
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:316
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:303
 [5] #test#68 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [6] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:297 [inlined]
 [7] #test#67 at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [8] test at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:296 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [10] test(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:295
 [11] top-level scope at none:16
