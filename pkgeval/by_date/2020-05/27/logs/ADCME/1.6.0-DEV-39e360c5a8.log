Julia Version 1.6.0-DEV.106
Commit 39e360c5a8 (2020-05-26 17:21 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed VersionParsing ─────────────── v1.2.0
  Installed CodecZlib ──────────────────── v0.7.0
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed Blosc ──────────────────────── v0.7.0
  Installed CMake ──────────────────────── v1.2.0
  Installed Parsers ────────────────────── v1.0.4
  Installed BinDeps ────────────────────── v1.0.1
  Installed TranscodingStreams ─────────── v0.9.5
  Installed Compat ─────────────────────── v3.10.0
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed HDF5 ───────────────────────── v0.13.2
  Installed Reexport ───────────────────── v0.2.0
  Installed Blosc_jll ──────────────────── v1.14.3+1
  Installed HDF5_jll ───────────────────── v1.10.5+5
  Installed URIParser ──────────────────── v0.4.1
  Installed SpecialFunctions ───────────── v0.10.3
  Installed PyCall ─────────────────────── v1.91.4
  Installed BufferedStreams ────────────── v1.0.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed Lz4_jll ────────────────────── v1.9.2+0
  Installed ADCME ──────────────────────── v0.5.4
  Installed MAT ────────────────────────── v0.8.0
  Installed Conda ──────────────────────── v1.4.1
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed Zlib_jll ───────────────────── v1.2.11+10
  Installed FFTW ───────────────────────── v1.2.1
  Installed MKL_jll ────────────────────── v2019.0.117+2
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed Zstd_jll ───────────────────── v1.4.5+0
  Installed JSON ───────────────────────── v0.21.0
Updating `~/.julia/environments/v1.6/Project.toml`
  [07b341a0] + ADCME v0.5.4
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [07b341a0] + ADCME v0.5.4
  [621f4979] + AbstractFFTs v0.5.0
  [9e28174c] + BinDeps v1.0.1
  [a74b3585] + Blosc v0.7.0
  [0b7ba130] + Blosc_jll v1.14.3+1
  [e1450e63] + BufferedStreams v1.0.0
  [631607c0] + CMake v1.2.0
  [944b1d66] + CodecZlib v0.7.0
  [34da2185] + Compat v3.10.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] + Conda v1.4.1
  [7a1cc6ca] + FFTW v1.2.1
  [f5851436] + FFTW_jll v3.3.9+5
  [f67ccb44] + HDF5 v0.13.2
  [0234f1f7] + HDF5_jll v1.10.5+5
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [682c06a0] + JSON v0.21.0
  [5ced341a] + Lz4_jll v1.9.2+0
  [23992714] + MAT v0.8.0
  [856f044c] + MKL_jll v2019.0.117+2
  [1914dd2f] + MacroTools v0.5.5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [69de0a69] + Parsers v1.0.4
  [438e738f] + PyCall v1.91.4
  [189a3867] + Reexport v0.2.0
  [276daf66] + SpecialFunctions v0.10.3
  [3bb67fe8] + TranscodingStreams v0.9.5
  [30578b45] + URIParser v0.4.1
  [81def892] + VersionParsing v1.2.0
  [83775a58] + Zlib_jll v1.2.11+10
  [3161d3a3] + Zstd_jll v1.4.5+0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building Conda ─→ `~/.julia/packages/Conda/3rPhK/deps/build.log`
   Building PyCall → `~/.julia/packages/PyCall/zqDXB/deps/build.log`
   Building CMake ─→ `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building HDF5 ──→ `~/.julia/packages/HDF5/pAi1D/deps/build.log`
   Building FFTW ──→ `~/.julia/packages/FFTW/5DZuu/deps/build.log`
   Building ADCME ─→ `~/.julia/packages/ADCME/kFusn/deps/build.log`
    Testing ADCME
Status `/tmp/jl_XDyG6C/Project.toml`
  [07b341a0] ADCME v0.5.4
  [631607c0] CMake v1.2.0
  [8f4d0f93] Conda v1.4.1
  [7a1cc6ca] FFTW v1.2.1
  [23992714] MAT v0.8.0
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v0.21.0
  [438e738f] PyCall v1.91.4
  [276daf66] SpecialFunctions v0.10.3
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [9a3f8284] Random
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_XDyG6C/Manifest.toml`
  [07b341a0] ADCME v0.5.4
  [621f4979] AbstractFFTs v0.5.0
  [4fba245c] ArrayInterface v2.8.7
  [9e28174c] BinDeps v1.0.1
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [631607c0] CMake v1.2.0
  [944b1d66] CodecZlib v0.7.0
  [bbf7d656] CommonSubexpressions v0.2.0
  [34da2185] Compat v3.10.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] Conda v1.4.1
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.17
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [7a1cc6ca] FFTW v1.2.1
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.8.10
  [6a86dc24] FiniteDiff v2.3.2
  [f6369f11] ForwardDiff v0.10.10
  [f67ccb44] HDF5 v0.13.2
  [0234f1f7] HDF5_jll v1.10.5+5
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [682c06a0] JSON v0.21.0
  [d3d80556] LineSearches v7.0.1
  [5ced341a] Lz4_jll v1.9.2+0
  [23992714] MAT v0.8.0
  [856f044c] MKL_jll v2019.0.117+2
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.6.1
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [77ba4419] NaNMath v0.3.3
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.21.0
  [bac558e1] OrderedCollections v1.2.0
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.4
  [85a6dd25] PositiveFactorizations v0.2.3
  [438e738f] PyCall v1.91.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.3
  [2913bbd2] StatsBase v0.33.0
  [3bb67fe8] TranscodingStreams v0.9.5
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.1
  [81def892] VersionParsing v1.2.0
  [83775a58] Zlib_jll v1.2.11+10
  [3161d3a3] Zstd_jll v1.4.5+0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
WARNING: Method definition size(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:798 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/kFusn/src/variable.jl:208.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition length(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:797 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/kFusn/src/variable.jl:232.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition lastindex(PyCall.PyObject) in module PyCall at deprecated.jl:70 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/kFusn/src/variable.jl:395.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition *(PyCall.PyObject, PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/pyoperators.jl:11 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/kFusn/src/ops.jl:100.
  ** incremental compilation may be fatally broken for this module **

2020-05-27 22:36:31.073711: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-27 22:36:31.144570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-05-27 22:36:31.154229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46c2850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-27 22:36:31.154299: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✘] Julia path

[Reason]
`julia` outputs nothing. This will break custom operator compilation.


[Instruction]
(Optional) Add your julia binary path to your environment path, e.g. (Unix systems) 

export PATH=/opt/julia/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] Dynamic library path

[Reason]
/home/pkgeval/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
(Optional) Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/pkgeval/.julia/conda/3/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length
[✘] Binaries path

[Reason]
/home/pkgeval/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/pkgeval/.julia/conda/3/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/pkgeval/.julia/packages/ADCME/kFusn/src/../deps/deps.jl
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 10 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 12 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 4756 tid 4756 thread 0 bound to OS proc set 0
2020-05-27 22:36:32.578914: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[ Info: Copy "/home/pkgeval/.julia/packages/ADCME/kFusn/src/../deps/AdeptCMakeLists.txt" to "/home/pkgeval/.julia/conda/3/lib/Adept-2/adept/CMakeLists.txt" ... 
[ Info: Remove /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Make /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Change directory into /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Cmake ... 
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
EIGEN_INC=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
Use openblas library /home/pkgeval/.julia/conda/3/lib/libopenblas.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build
[ Info: Make ... 
Scanning dependencies of target adept
[  8%] Building CXX object CMakeFiles/adept.dir/Array.cpp.o
[ 16%] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o
[ 25%] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o
[ 33%] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o
[ 41%] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o
[ 50%] Building CXX object CMakeFiles/adept.dir/index.cpp.o
[ 58%] Building CXX object CMakeFiles/adept.dir/inv.cpp.o
[ 66%] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o
[ 75%] Building CXX object CMakeFiles/adept.dir/settings.cpp.o
[ 83%] Building CXX object CMakeFiles/adept.dir/solve.cpp.o
[ 91%] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o
[100%] Linking CXX shared library /home/pkgeval/.julia/conda/3/lib/libadept.so
[100%] Built target adept
∘ Add the following lines to CMakeLists.txt 

include_directories(${LIBDIR}/Adept-2/include)
find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR})
message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}")

∘ Add `${ADEPT_LIB_FILE}` to `target_link_libraries`
[ Info: Add formula "extended_nn" => ("ExtendedNN", "libExtendedNn", "extended_nn", true)
[ Info: Lib ExtendedNN exists in registery but was not initialized. Compiling...
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
BINDIR=/home/pkgeval/.julia/conda/3/bin
LIBDIR=/home/pkgeval/.julia/conda/3/lib
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
EIGEN_INC=/home/pkgeval/.julia/conda/3/lib/Libraries
Python path=/home/pkgeval/.julia/conda/3/bin/python
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
ADEPT_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/libadept.so
Total number of libraries to make: 12
Compiling 0th library: SparseAccumulate
Compiling 1th library: SolveBatchedRhs
Compiling 2th library: SparseMatMul
Compiling 3th library: ExtendedNN
Compiling 4th library: SparseFactorizationSolve
Compiling 5th library: OT/SinkhornKnopp
Compiling 6th library: TriLu
Compiling 7th library: SparseLeastSquare
Compiling 8th library: SparseConcate
Compiling 9th library: SparseScatterUpdate
Compiling 10th library: SparseIndexing
Compiling 11th library: SparseSolver
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/build
Scanning dependencies of target SparseAccumulator
Scanning dependencies of target SparseMatMul
Scanning dependencies of target lru
[  3%] Building CXX object SparseAccumulate/CMakeFiles/SparseAccumulator.dir/SparseAccumulator.cpp.o
Scanning dependencies of target SparseLeastSquare
[  6%] Building CXX object SparseAccumulate/CMakeFiles/SparseAccumulator.dir/Impl.cpp.o
Scanning dependencies of target TriLu
Scanning dependencies of target ExtendedNn
Scanning dependencies of target SparseIndexing
Scanning dependencies of target SparseConcate
Scanning dependencies of target SolveBatchedRhs
Scanning dependencies of target SparseScatterUpdate
[ 10%] Building CXX object SparseMatMul/CMakeFiles/SparseMatMul.dir/SparseMatMul.cpp.o
[ 13%] Building CXX object SparseFactorizationSolve/CMakeFiles/lru.dir/lru_cache.cpp.o
Scanning dependencies of target SparseSolver
[ 16%] Building CXX object TriLu/CMakeFiles/TriLu.dir/TriLu.cpp.o
[ 20%] Building CXX object SparseLeastSquare/CMakeFiles/SparseLeastSquare.dir/SparseLeastSquare.cpp.o
[ 23%] Building CXX object ExtendedNN/CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o
Scanning dependencies of target SinkhornKnopp
[ 26%] Building CXX object SparseConcate/CMakeFiles/SparseConcate.dir/SparseConcate.cpp.o
[ 30%] Building CXX object SparseIndexing/CMakeFiles/SparseIndexing.dir/SparseIndexing.cpp.o
[ 33%] Building CXX object SolveBatchedRhs/CMakeFiles/SolveBatchedRhs.dir/SolveBatchedRhs.cpp.o
[ 36%] Building CXX object SparseScatterUpdate/CMakeFiles/SparseScatterUpdate.dir/SparseScatterUpdate.cpp.o
[ 40%] Building CXX object SparseSolver/CMakeFiles/SparseSolver.dir/SparseSolver.cpp.o
[ 43%] Building CXX object OT/SinkhornKnopp/CMakeFiles/SinkhornKnopp.dir/__/src/sinkhorn.cpp.o
[ 46%] Building CXX object OT/SinkhornKnopp/CMakeFiles/SinkhornKnopp.dir/SinkhornKnopp.cpp.o
[ 50%] Linking CXX shared library ../../TriLu/build/libTriLu.so
[ 53%] Linking CXX shared library ../../SparseAccumulate/build/libSparseAccumulator.so
[ 56%] Linking CXX shared library liblru.so
[ 56%] Built target TriLu
[ 56%] Built target SparseAccumulator
[ 56%] Built target lru
[ 60%] Linking CXX shared library ../../SparseConcate/build/libSparseConcate.so
Scanning dependencies of target Solve
Scanning dependencies of target factorization
[ 63%] Building CXX object SparseFactorizationSolve/CMakeFiles/Solve.dir/Solve/Solve.cpp.o
[ 66%] Building CXX object SparseFactorizationSolve/CMakeFiles/factorization.dir/Factorization/SparseFactorization.cpp.o
[ 70%] Linking CXX shared library ../../../OT/SinkhornKnopp/build/libSinkhornKnopp.so
[ 73%] Linking CXX shared library ../../SparseScatterUpdate/build/libSparseScatterUpdate.so
[ 73%] Built target SparseConcate
[ 73%] Built target SinkhornKnopp
[ 73%] Built target SparseScatterUpdate
[ 76%] Linking CXX shared library ../../SparseIndexing/build/libSparseIndexing.so
[ 76%] Built target SparseIndexing
[ 80%] Linking CXX shared library ../../SparseMatMul/build/libSparseMatMul.so
[ 80%] Built target SparseMatMul
[ 83%] Linking CXX shared library ../../ExtendedNN/build/libExtendedNn.so
[ 83%] Built target ExtendedNn
[ 86%] Linking CXX shared library ../../SolveBatchedRhs/build/libSolveBatchedRhs.so
[ 86%] Built target SolveBatchedRhs
[ 90%] Linking CXX shared library ../../SparseFactorizationSolve/build/libSolve.so
[ 90%] Built target Solve
[ 93%] Linking CXX shared library ../../SparseLeastSquare/build/libSparseLeastSquare.so
[ 93%] Built target SparseLeastSquare
[ 96%] Linking CXX shared library ../../SparseFactorizationSolve/build/libfactorization.so
[100%] Linking CXX shared library ../../SparseSolver/build/libSparseSolver.so
[100%] Built target factorization
[100%] Built target SparseSolver
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
WARNING:tensorflow:Large dropout rate: 0.999 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Test Summary: | Pass  Total
dropout       |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = size(::SparseTensor) at sparse.jl:154
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:154
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = size(::SparseTensor) at sparse.jl:154
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:154
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = size(::SparseTensor, ::Int64) at sparse.jl:158
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:158
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseConcate/build/libSparseConcate.so ==> sparse_concate
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::UnitRange{Int64}, ::UnitRange{Int64}) at sparse.jl:276
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:276
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::UnitRange{Int64}, ::UnitRange{Int64}) at sparse.jl:277
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:277
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseIndexing/build/libSparseIndexing.so ==> sparse_indexing
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::UnitRange{Int64}, ::Colon) at sparse.jl:276
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:276
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::UnitRange{Int64}, ::Colon) at sparse.jl:277
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:277
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Colon, ::UnitRange{Int64}) at sparse.jl:276
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:276
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Colon, ::UnitRange{Int64}) at sparse.jl:277
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:277
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseSolver/build/libSparseSolver.so ==> sparse_solver
Test Summary: | Pass  Total
sparse_solve  |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseAccumulate/build/libSparseAccumulator.so ==> sparse_accumulator
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.20446763406089974, 0.6788077905732142, 0.3110563754197897, 0.7919663312457494, 0.20922965821462047, 0.7846396415567087, 0.5759892680734566, 0.059013780135029004, 0.5610700600476493, 0.6469118505004283]
Load library operator: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseAccumulate/build/libSparseAccumulator.so ==> sparse_accumulator_add
Load library operator: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseAccumulate/build/libSparseAccumulator.so ==> sparse_accumulator_copy
Test Summary:    | Pass  Total
sparse_assembler |    3      3
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseLeastSquare/build/libSparseLeastSquare.so ==> sparse_least_square
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = \(::SparseTensor, ::PyObject, ::String) at sparse.jl:382
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:382
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseMatMul/build/libSparseMatMul.so ==> sparse_sparse_mat_mul
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Array{Int64,1}, ::Array{Int64,1}) at sparse.jl:276
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:276
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Array{Int64,1}, ::Array{Int64,1}) at sparse.jl:277
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:277
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
WARNING:tensorflow:From /home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:320: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = rows(::SparseTensor) at sparse.jl:31
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:31
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = cols(::SparseTensor) at sparse.jl:35
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:35
Test Summary: | Pass  Total
find          |    6      6
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseScatterUpdate/build/libSparseScatterUpdate.so ==> sparse_scatter_update
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Array{Bool,1}, ::Array{Bool,1}) at sparse.jl:276
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:276
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = getindex(::SparseTensor, ::Array{Bool,1}, ::Array{Bool,1}) at sparse.jl:277
└ @ ADCME ~/.julia/packages/ADCME/kFusn/src/sparse.jl:277
Test Summary: | Pass  Total
get index     |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseFactorizationSolve/build/libfactorization.so ==> sparse_factorization
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/kFusn/deps/CustomOps/SparseFactorizationSolve/build/libSolve.so ==> solve
sparse_factorization_and_solve: Test Failed at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:331
  Expression: norm(run(sess, v1) - A \ rhs1) < 1.0e-10
   Evaluated: 2.7125255582933374e-9 < 1.0e-10
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:331
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:324
sparse_factorization_and_solve: Test Failed at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:332
  Expression: norm(run(sess, v2) - A \ rhs2) < 1.0e-10
   Evaluated: 3.3414281997915613e-10 < 1.0e-10
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:332
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:324
Test Summary:                  | Fail  Total
sparse_factorization_and_solve |    2      2
ERROR: LoadError: LoadError: Some tests did not pass: 0 passed, 2 failed, 0 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/ADCME/kFusn/test/sparse.jl:323
in expression starting at /home/pkgeval/.julia/packages/ADCME/kFusn/test/runtests.jl:19
Create a new sparse assembler [Handle ID = 100] with 20 rows and tolerance 0.
Current sparse assembler:
 100 |
destroy_sparse_assembler
Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 1.
Current sparse assembler:
 100 |
destroy_sparse_assembler
Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 0.
Current sparse assembler:
 100 |
destroy_sparse_assembler
Factorization: current matrix id= 1, maximum cache size = 999999
Factorization: current matrix id= 2, maximum cache size = 999999
ERROR: Package ADCME errored during testing
Stacktrace:
 [1] pkgerror(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1557
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:327
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:314
 [5] #test#61 at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
 [6] test at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
 [7] #test#60 at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
 [8] test at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [10] test(::String) at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [11] top-level scope at none:16
