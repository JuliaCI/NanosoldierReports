Julia Version 1.3.2-pre.0
Commit 2e6715c045 (2019-12-31 00:49 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Distances ────────── v0.8.2
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataStructures ───── v0.17.9
 Installed HDF5 ─────────────── v0.12.5
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed LegacyStrings ────── v0.4.1
 Installed Rmath ────────────── v0.6.0
 Installed BinaryProvider ───── v0.5.8
 Installed Clustering ───────── v0.13.3
 Installed CMake ────────────── v1.1.2
 Installed PDMats ───────────── v0.9.11
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed FileIO ───────────── v1.2.1
 Installed JLD ──────────────── v0.9.2
 Installed OrderedCollections ─ v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Blosc ────────────── v0.5.1
 Installed BinDeps ──────────── v1.0.0
 Installed Distributions ────── v0.22.4
 Installed FillArrays ───────── v0.8.4
 Installed Compat ───────────── v2.2.0
 Installed StatsBase ────────── v0.32.0
 Installed Arpack ───────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed SortingAlgorithms ── v0.3.1
 Installed StatsFuns ────────── v0.9.3
 Installed NearestNeighbors ─── v0.4.4
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_YogRkm/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -4.075342699146988e7, [46052.240259115344, 53947.75974088466], [4382.877371282963 -39171.57213680894 6903.300798143459; -4125.546031936943 38659.12484776499 -7021.17421709632], Array{Float64,2}[[46768.114622951834 -353.7727951400838 -403.6523762175509; -353.77279514008376 50416.28084601374 -899.0156704488583; -403.65237621755085 -899.0156704488583 46241.10911342253], [53816.186245675526 666.6079757647399 -133.42814205366756; 666.6079757647399 50143.06697346722 590.7595458509144; -133.42814205366747 590.7595458509144 53796.03353246594]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.242757e+03
      1       9.377859e+02      -3.049708e+02 |        6
      2       8.999889e+02      -3.779706e+01 |        4
      3       8.864354e+02      -1.355352e+01 |        0
      4       8.864354e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 886.4353637369754)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078870
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.861881
[ Info: iteration 2, lowerbound -3.755273
[ Info: iteration 3, lowerbound -3.642634
[ Info: iteration 4, lowerbound -3.504382
[ Info: iteration 5, lowerbound -3.343729
[ Info: iteration 6, lowerbound -3.169052
[ Info: iteration 7, lowerbound -3.000598
[ Info: iteration 8, lowerbound -2.865465
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.753696
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.661137
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.582859
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.506500
[ Info: iteration 13, lowerbound -2.439856
[ Info: iteration 14, lowerbound -2.389524
[ Info: iteration 15, lowerbound -2.351790
[ Info: iteration 16, lowerbound -2.324762
[ Info: iteration 17, lowerbound -2.309700
[ Info: iteration 18, lowerbound -2.308467
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb  6 19:07:14 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb  6 19:07:21 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Feb  6 19:07:23 2020: EM with 272 data points 0 iterations avll -2.078870
5.8 data points per parameter
, Thu Feb  6 19:07:24 2020: GMM converted to Variational GMM
, Thu Feb  6 19:07:33 2020: iteration 1, lowerbound -3.861881
, Thu Feb  6 19:07:33 2020: iteration 2, lowerbound -3.755273
, Thu Feb  6 19:07:33 2020: iteration 3, lowerbound -3.642634
, Thu Feb  6 19:07:33 2020: iteration 4, lowerbound -3.504382
, Thu Feb  6 19:07:33 2020: iteration 5, lowerbound -3.343729
, Thu Feb  6 19:07:33 2020: iteration 6, lowerbound -3.169052
, Thu Feb  6 19:07:33 2020: iteration 7, lowerbound -3.000598
, Thu Feb  6 19:07:33 2020: iteration 8, lowerbound -2.865465
, Thu Feb  6 19:07:34 2020: dropping number of Gaussions to 6
, Thu Feb  6 19:07:34 2020: iteration 9, lowerbound -2.753696
, Thu Feb  6 19:07:34 2020: dropping number of Gaussions to 5
, Thu Feb  6 19:07:34 2020: iteration 10, lowerbound -2.661137
, Thu Feb  6 19:07:34 2020: dropping number of Gaussions to 4
, Thu Feb  6 19:07:34 2020: iteration 11, lowerbound -2.582859
, Thu Feb  6 19:07:34 2020: dropping number of Gaussions to 3
, Thu Feb  6 19:07:34 2020: iteration 12, lowerbound -2.506500
, Thu Feb  6 19:07:34 2020: iteration 13, lowerbound -2.439856
, Thu Feb  6 19:07:34 2020: iteration 14, lowerbound -2.389524
, Thu Feb  6 19:07:34 2020: iteration 15, lowerbound -2.351790
, Thu Feb  6 19:07:34 2020: iteration 16, lowerbound -2.324762
, Thu Feb  6 19:07:34 2020: iteration 17, lowerbound -2.309700
, Thu Feb  6 19:07:34 2020: iteration 18, lowerbound -2.308467
, Thu Feb  6 19:07:34 2020: dropping number of Gaussions to 2
, Thu Feb  6 19:07:34 2020: iteration 19, lowerbound -2.302915
, Thu Feb  6 19:07:34 2020: iteration 20, lowerbound -2.299259
, Thu Feb  6 19:07:34 2020: iteration 21, lowerbound -2.299256
, Thu Feb  6 19:07:34 2020: iteration 22, lowerbound -2.299254
, Thu Feb  6 19:07:34 2020: iteration 23, lowerbound -2.299254
, Thu Feb  6 19:07:34 2020: iteration 24, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 25, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 26, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 27, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 28, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 29, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 30, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 31, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 32, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 33, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 34, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 35, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 36, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 37, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 38, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 39, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 40, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 41, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 42, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 43, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 44, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 45, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 46, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 47, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 48, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 49, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: iteration 50, lowerbound -2.299253
, Thu Feb  6 19:07:34 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601405, 95.95490777398594]
β = [178.04509222601405, 95.95490777398594]
m = [4.250300733269908 79.28686694436183; 2.0002292577753686 53.851987172461286]
ν = [180.04509222601405, 97.95490777398594]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484854 -0.007644049042327895; 0.0 0.00858170516633361], [0.37587636119484297 -0.008953123827346197; 0.0 0.012748664777409345]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9726850577632993
avll from llpg:  -0.9726850577633137
avll direct:     -0.9726850577633137
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9639589351540102
avll from llpg:  -0.9639589351540102
avll direct:     -0.9639589351540102
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.232495      0.160276     0.043001     0.0624263     0.13218     -0.0792295  -0.03065      0.0843467   -0.0375594    0.0273491    -0.0486559   -0.0419762    0.0723037     0.0343824   -0.196921    -0.145228    -0.174753    -0.0412831     0.125066     0.114598      0.179014     0.113611    -0.0331679    -0.152231     0.0606749    0.0782119 
 -0.111555     -0.0307982   -0.122451     0.0925071    -0.0386313    0.251131   -0.112586     0.0895622    0.00843666   0.0699778    -0.0534025    0.0800115    0.174846     -0.0725837   -0.122723     0.0843439    0.0256775   -0.0312891     0.0580671    0.0320983     0.120872    -0.0671119   -0.0938829    -0.0335259   -0.0131786    0.0448987 
  0.0333494    -0.0263067   -0.100984     0.102004      0.0582758    0.0300383   0.0738356   -0.096388     0.107187    -0.0264672    -0.285291    -0.0474122   -0.122365     -0.0569392    0.00381368  -0.0252695    0.0500992    0.176547     -0.25232     -0.0264584    -0.109033     0.0667293    0.173914     -0.00351981   0.00436458  -0.0227874 
  0.0759192     0.0211298    0.0970758   -0.143827      0.0293491    0.0980856   0.0502413    0.0172567    0.025175     0.0568123    -0.0139862    0.031797     0.251701     -0.15221      0.0389652    0.0718634    0.0193018    0.056321      0.0291796    0.0893509    -0.0205731    0.224854    -0.275297      0.131766    -0.00656439  -0.100154  
 -0.0519908     0.0702497    0.180037    -0.105809     -0.109271     0.144265   -0.037328    -0.199133     0.0460258    0.0952634    -0.101132    -0.0162258    0.0901141    -0.0659117    0.220826     0.0613763   -0.0626382   -0.113347     -0.183187    -0.10504       0.0821131    0.0899137   -0.000188396   0.0933606    0.068377     0.192838  
 -0.00161722   -0.095009     0.111623    -0.0559257     0.138328    -0.0153729   0.0902911   -0.0038038    0.0621391    0.0522081     0.178235     0.102143    -0.0736761     0.0385462    0.043352    -0.149311    -0.086364     0.000110655   0.219814     0.14459       0.130909    -0.0111579   -0.0169641     0.0514161   -0.0385009    0.0524285 
  0.047921     -0.0306789   -0.038008    -0.105318     -0.0333942    0.105749    0.0517966    0.0900043   -0.0420041    0.0464344    -0.0703653    0.0289185   -0.168297      0.0530145   -0.0021017   -0.185885     0.0935211    0.0537945    -0.0678056   -0.000253303   0.042752    -0.146786    -0.0826073     0.0775308   -0.00263468   0.0467894 
  0.000334866   0.0579363    0.0464159    0.180961      0.079607    -0.129437    0.0453597    0.140985     0.0312903    0.0499534     0.0490138   -0.0433234    0.0162842    -0.161573     0.0525531   -0.0436782    0.114613    -0.241781      0.104477    -0.159211      0.0120106    0.164414     0.0131384     0.0445945    0.0363238   -0.0713281 
  0.123248     -0.0278701    0.131082    -0.0103112    -0.120386     0.0962731  -0.0563191   -0.116126    -0.0934829   -0.0324081     0.0590619   -0.0542615   -0.124919     -0.0944151    0.247979     0.0566702   -0.0548521    0.0203044     0.0997545    0.158019     -0.0621509   -0.0804679   -0.0716749     0.0074296    0.120027    -0.172586  
  0.0931107    -0.00457254  -0.0203298   -0.142111     -0.0464448    0.0284346   0.0320341    0.129949     0.00695073   0.0275162     0.0622218    0.0345978   -0.180641      0.0349792    0.160912     0.0343289   -0.0839594   -0.254216      0.0083757    0.100816      0.0594969    0.216719     0.0279083     0.0509281   -0.0638971    0.00933054
 -0.146832      0.00456077  -0.0105472   -0.0916017    -0.106755     0.183893   -0.0255703    0.00640762  -0.163906     0.119228     -0.0214149   -0.126818     0.0138233    -0.00703288   0.0877814   -0.0575022   -0.0435078   -0.145048     -0.149564     0.150853      0.00744092   0.123443    -0.159728     -0.021569     0.0282876    0.0899344 
  0.171033      0.0967155    0.108066    -0.103651      0.0669984   -0.0272646  -0.0467502    0.0369183    0.082228     0.0256549     0.0343895    0.0576986   -0.0250043    -0.0131719    0.0216868   -0.0324581    0.0118619    0.0575231    -0.0747808   -0.105481     -0.0157938    0.111525    -0.0931479     0.0509741    0.0229293   -0.0036807 
  0.0615918     0.102635    -0.0438334   -0.11651      -0.0181949    0.0150681   0.0282262   -0.151168    -0.00368848   0.0473654     0.00714478  -0.0553479   -0.0666293    -0.0687611   -0.0301167   -0.090096     0.190102     0.0554468     0.0204996   -0.102239     -0.0227348   -0.173035     0.0623779    -0.0501186   -0.0476526    0.107344  
  0.0127144    -0.0504661    0.0431328    0.223091      0.00197192   0.0647779  -0.161431    -0.0214973    0.221575    -0.100711      0.0761323   -0.0739441   -0.0329156     0.0153518   -0.0146894   -0.0921809    0.0339284   -0.0337034    -0.00715774  -0.0235658     0.05201      0.0408028    0.0683372    -0.0925616    0.0483698    0.282124  
 -0.141454     -0.0900018   -0.0508572    0.191823      0.0205797   -0.14819     0.0489948    0.0713852    0.12743     -0.109394     -0.0520615   -0.00301039   0.0284358    -0.0381517    0.015102    -0.0167538    0.0101193    0.0860364    -0.0228704    0.0974309    -0.179872    -0.241577     0.0539521    -0.0348684    0.127485    -0.0210605 
  0.141963     -0.124149     0.0567993    0.178817     -0.0357275    0.0324663   0.0809935    0.04266     -0.155285     0.0763352    -0.0614796   -0.0693816    0.0461467    -0.184077    -0.0548127   -0.0375339    0.0764051    0.216123     -0.103369     0.117338     -0.0943677   -0.0958023   -0.0417302    -0.0407136    0.17609     -0.136387  
  0.0859358    -0.0441913   -0.135086    -0.0318347    -0.128489     0.0295983   0.030392    -0.0930753   -0.117181     0.051629     -0.0501074   -0.145987    -0.114955     -0.0404432    0.0591651    0.0624583   -0.207043    -0.0457048    -0.156057    -0.0542703     0.0620744   -0.00910642   0.163883      0.0161061    0.0384824    0.0238046 
 -0.18791      -0.0338241    0.16509     -0.0232706     0.0298997   -0.0897282   0.013175     0.0579634    0.0322854    0.11379      -0.0749303   -0.0427922    0.185003      0.147412     0.0275447    0.0171728   -0.171505     0.0542392     0.129331    -0.0307308     0.0234504    0.203072     0.149205      0.00862778   0.00828236   0.0169597 
 -0.127519     -0.0480366   -0.0795441    0.116864      0.217782    -0.0160063   0.154018     0.146464     0.188755    -0.12374      -0.0726451   -0.124953     0.029421     -0.0533624    0.0922425   -0.177656    -0.00781452   0.0615227    -0.0819126    0.0942998     0.0178048    0.128548     0.0825225     0.0701873   -0.0208339    0.107968  
  0.0881951     0.00695957  -0.00243915   0.223985      0.0980727    0.0398712  -0.053086     0.0353968   -0.0810617   -0.0165377    -0.112084    -0.262114     0.10712       0.137515    -0.213812     0.00863387  -0.0671474   -0.0433567    -0.0810978   -0.0576619     0.0924826   -0.0833304    0.0301187    -0.155255    -0.0517091   -0.137694  
  0.00231603    0.067134    -0.15732      0.161205      0.212105    -0.177388   -0.0116547    0.00160343   0.273519    -0.073242      0.0361318    0.0125439    0.000117112  -0.105558     0.0170654   -0.0173187   -0.0232943    0.0333916     0.0556336    0.0176819     0.0340814   -0.0249342    0.193932     -0.0557556   -0.11737      0.109521  
  0.10923      -0.0493659   -0.0418292   -0.0575519    -0.0908327    0.0385081   0.024756     0.0426662    0.0872325   -0.0399642     0.0975007    0.0554279   -0.101062     -0.116516     0.124779    -0.0119308   -0.0957674    0.146236     -0.0992385    0.00021196   -0.0490923   -0.115268     0.0291       -0.0724608    0.218419    -0.0790737 
  0.0588168    -0.0179631   -0.0255755    0.00718941   -0.217312    -0.0649718  -0.00730264   0.0834448    0.0484287    0.0280177    -0.0443762    0.135517     0.172883      0.056761     0.0114185   -0.103327     0.0291436   -0.188938      0.12479      0.0235716    -0.121344     0.265696    -0.0546817    -0.0967621    0.046658    -0.0614876 
 -0.266751      0.0697291    0.107313    -0.100206     -0.0350259    0.0543761   0.206929    -0.131363    -0.125855     0.0899873    -0.0904845   -0.0254545   -0.0609342    -0.0411345    0.0539389   -0.0464702   -0.00712645  -0.161025     -0.082296    -0.134728     -0.0245523    0.108083     0.242499     -0.0532069   -0.218497    -0.043621  
  0.0605823    -0.0668144    0.105879    -0.0026721     0.0429742   -0.147444   -0.0510639    0.12785      0.0714151   -0.0677328    -0.222601    -0.0865703   -0.0765605    -0.0740364    0.0129515   -0.0503077    0.0762519    0.0776956    -0.0980923   -0.00350556   -0.169772    -0.0287744   -0.0417709     0.00440468   0.122153     0.195279  
 -0.137728      0.060011    -0.0747587   -0.0210054    -0.143444     0.0552678  -0.0849336    0.161869    -0.0525675    0.0420545    -0.174826    -0.141926    -0.124787     -0.141753    -0.126911     0.0391269   -0.0569144    0.143829     -0.17315     -0.0209731     0.0894732   -0.00507193  -0.120075      0.00749332  -0.00445386   0.163013  
 -0.0672388     0.312256     0.105196     0.000822026   0.0908548   -0.082644    0.0657274    0.23951     -0.0047933   -0.0267123    -0.0223743   -0.012764    -0.0858385     0.0232447   -0.0537734    0.152875     0.0424979   -0.00509651    0.0522189   -0.0647692    -0.138941    -0.00654575   0.041729     -0.0514724    0.143973    -0.0757103 
  0.0945911    -0.0922565   -0.163783    -0.133725     -0.166902     0.092046    0.0568958   -0.025482    -0.0480778    0.0782669    -0.00857801  -0.0136278    0.183476     -0.139616     0.172224    -0.037108     0.146168    -0.0699435    -0.0466768    0.0842557     0.0142615   -0.0903539    0.20695      -0.0343227   -0.0105026   -0.0840835 
  0.0737564     0.159518    -0.113386    -0.042008      0.0659289   -0.14971     0.090267     0.111566    -0.0725758    0.197102      0.133513    -0.0262875    0.125282      0.0277628    0.0951827    0.108027    -0.04906     -0.0703381     0.0167721   -0.0159925     0.0131577    0.0570329    0.0647072     0.10063      0.0832663    0.106195  
 -0.00291571    0.0399276   -0.139112    -0.194531      0.204047    -0.0529746  -0.222709     0.209395     0.0387029    0.0400871    -0.184991     0.071036     0.0396355     0.0666646   -0.11742      0.0729037    0.0222023   -0.145121      0.0230666    0.0205352     0.118412    -0.0058724   -0.0836084     0.272542     0.165633     0.0564029 
  0.0183839    -0.102785    -0.0657907    0.0493653    -0.241016    -0.127166   -0.255954     0.0498714    0.0176575   -0.0226551     0.108606    -0.00479113   0.0254743     0.0427229   -0.0710874   -0.136966    -0.145723    -0.0420844     0.023457    -0.0306215     0.0066545    0.0304864    0.10212       0.0187598    0.00125603   0.00485777
  0.000535531  -0.047083    -0.0557564    0.0404009    -0.0949663    0.104028    0.0479389    0.102511     0.222282    -0.000830211   0.186762    -0.111283     0.0204214     0.0576102    0.165261     0.0949355    0.0540355   -0.185745      0.130019    -0.0155211     0.108465    -0.141821     0.058854      0.107432    -0.0282109    0.0826273 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.411316278258557
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411380
[ Info: iteration 2, average log likelihood -1.411322
[ Info: iteration 3, average log likelihood -1.411129
[ Info: iteration 4, average log likelihood -1.409148
[ Info: iteration 5, average log likelihood -1.399985
[ Info: iteration 6, average log likelihood -1.389315
[ Info: iteration 7, average log likelihood -1.385241
[ Info: iteration 8, average log likelihood -1.382977
[ Info: iteration 9, average log likelihood -1.381456
[ Info: iteration 10, average log likelihood -1.380495
[ Info: iteration 11, average log likelihood -1.379893
[ Info: iteration 12, average log likelihood -1.379463
[ Info: iteration 13, average log likelihood -1.379095
[ Info: iteration 14, average log likelihood -1.378788
[ Info: iteration 15, average log likelihood -1.378550
[ Info: iteration 16, average log likelihood -1.378376
[ Info: iteration 17, average log likelihood -1.378257
[ Info: iteration 18, average log likelihood -1.378181
[ Info: iteration 19, average log likelihood -1.378133
[ Info: iteration 20, average log likelihood -1.378101
[ Info: iteration 21, average log likelihood -1.378078
[ Info: iteration 22, average log likelihood -1.378063
[ Info: iteration 23, average log likelihood -1.378051
[ Info: iteration 24, average log likelihood -1.378043
[ Info: iteration 25, average log likelihood -1.378036
[ Info: iteration 26, average log likelihood -1.378031
[ Info: iteration 27, average log likelihood -1.378027
[ Info: iteration 28, average log likelihood -1.378024
[ Info: iteration 29, average log likelihood -1.378022
[ Info: iteration 30, average log likelihood -1.378019
[ Info: iteration 31, average log likelihood -1.378018
[ Info: iteration 32, average log likelihood -1.378016
[ Info: iteration 33, average log likelihood -1.378015
[ Info: iteration 34, average log likelihood -1.378014
[ Info: iteration 35, average log likelihood -1.378013
[ Info: iteration 36, average log likelihood -1.378012
[ Info: iteration 37, average log likelihood -1.378011
[ Info: iteration 38, average log likelihood -1.378011
[ Info: iteration 39, average log likelihood -1.378010
[ Info: iteration 40, average log likelihood -1.378010
[ Info: iteration 41, average log likelihood -1.378010
[ Info: iteration 42, average log likelihood -1.378009
[ Info: iteration 43, average log likelihood -1.378009
[ Info: iteration 44, average log likelihood -1.378009
[ Info: iteration 45, average log likelihood -1.378009
[ Info: iteration 46, average log likelihood -1.378009
[ Info: iteration 47, average log likelihood -1.378008
[ Info: iteration 48, average log likelihood -1.378008
[ Info: iteration 49, average log likelihood -1.378008
[ Info: iteration 50, average log likelihood -1.378008
┌ Info: EM with 100000 data points 50 iterations avll -1.378008
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4113801247552642
│     -1.4113224084797373
│      ⋮                 
└     -1.3780082196929926
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.378129
[ Info: iteration 2, average log likelihood -1.378019
[ Info: iteration 3, average log likelihood -1.377647
[ Info: iteration 4, average log likelihood -1.373779
[ Info: iteration 5, average log likelihood -1.359607
[ Info: iteration 6, average log likelihood -1.346490
[ Info: iteration 7, average log likelihood -1.341274
[ Info: iteration 8, average log likelihood -1.338844
[ Info: iteration 9, average log likelihood -1.337432
[ Info: iteration 10, average log likelihood -1.336624
[ Info: iteration 11, average log likelihood -1.336132
[ Info: iteration 12, average log likelihood -1.335779
[ Info: iteration 13, average log likelihood -1.335492
[ Info: iteration 14, average log likelihood -1.335246
[ Info: iteration 15, average log likelihood -1.335027
[ Info: iteration 16, average log likelihood -1.334841
[ Info: iteration 17, average log likelihood -1.334693
[ Info: iteration 18, average log likelihood -1.334583
[ Info: iteration 19, average log likelihood -1.334511
[ Info: iteration 20, average log likelihood -1.334469
[ Info: iteration 21, average log likelihood -1.334444
[ Info: iteration 22, average log likelihood -1.334429
[ Info: iteration 23, average log likelihood -1.334421
[ Info: iteration 24, average log likelihood -1.334416
[ Info: iteration 25, average log likelihood -1.334412
[ Info: iteration 26, average log likelihood -1.334410
[ Info: iteration 27, average log likelihood -1.334409
[ Info: iteration 28, average log likelihood -1.334408
[ Info: iteration 29, average log likelihood -1.334407
[ Info: iteration 30, average log likelihood -1.334406
[ Info: iteration 31, average log likelihood -1.334405
[ Info: iteration 32, average log likelihood -1.334404
[ Info: iteration 33, average log likelihood -1.334403
[ Info: iteration 34, average log likelihood -1.334402
[ Info: iteration 35, average log likelihood -1.334401
[ Info: iteration 36, average log likelihood -1.334400
[ Info: iteration 37, average log likelihood -1.334399
[ Info: iteration 38, average log likelihood -1.334397
[ Info: iteration 39, average log likelihood -1.334396
[ Info: iteration 40, average log likelihood -1.334394
[ Info: iteration 41, average log likelihood -1.334392
[ Info: iteration 42, average log likelihood -1.334389
[ Info: iteration 43, average log likelihood -1.334387
[ Info: iteration 44, average log likelihood -1.334384
[ Info: iteration 45, average log likelihood -1.334381
[ Info: iteration 46, average log likelihood -1.334379
[ Info: iteration 47, average log likelihood -1.334376
[ Info: iteration 48, average log likelihood -1.334372
[ Info: iteration 49, average log likelihood -1.334369
[ Info: iteration 50, average log likelihood -1.334366
┌ Info: EM with 100000 data points 50 iterations avll -1.334366
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3781289585880812
│     -1.378019282233713 
│      ⋮                 
└     -1.3343660374989947
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.334561
[ Info: iteration 2, average log likelihood -1.334366
[ Info: iteration 3, average log likelihood -1.333937
[ Info: iteration 4, average log likelihood -1.330170
[ Info: iteration 5, average log likelihood -1.317534
[ Info: iteration 6, average log likelihood -1.304609
[ Info: iteration 7, average log likelihood -1.295047
[ Info: iteration 8, average log likelihood -1.289971
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.287548
[ Info: iteration 10, average log likelihood -1.301017
[ Info: iteration 11, average log likelihood -1.293330
[ Info: iteration 12, average log likelihood -1.288537
[ Info: iteration 13, average log likelihood -1.285819
[ Info: iteration 14, average log likelihood -1.284690
[ Info: iteration 15, average log likelihood -1.284005
[ Info: iteration 16, average log likelihood -1.283411
[ Info: iteration 17, average log likelihood -1.282882
[ Info: iteration 18, average log likelihood -1.282420
[ Info: iteration 19, average log likelihood -1.282025
[ Info: iteration 20, average log likelihood -1.281681
[ Info: iteration 21, average log likelihood -1.281365
[ Info: iteration 22, average log likelihood -1.281061
[ Info: iteration 23, average log likelihood -1.280752
[ Info: iteration 24, average log likelihood -1.280418
[ Info: iteration 25, average log likelihood -1.280014
[ Info: iteration 26, average log likelihood -1.279490
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.278869
[ Info: iteration 28, average log likelihood -1.292745
[ Info: iteration 29, average log likelihood -1.284848
[ Info: iteration 30, average log likelihood -1.281059
[ Info: iteration 31, average log likelihood -1.279252
[ Info: iteration 32, average log likelihood -1.278608
[ Info: iteration 33, average log likelihood -1.278291
[ Info: iteration 34, average log likelihood -1.277964
[ Info: iteration 35, average log likelihood -1.277617
[ Info: iteration 36, average log likelihood -1.277262
[ Info: iteration 37, average log likelihood -1.276911
[ Info: iteration 38, average log likelihood -1.276582
[ Info: iteration 39, average log likelihood -1.276306
[ Info: iteration 40, average log likelihood -1.276097
[ Info: iteration 41, average log likelihood -1.275962
[ Info: iteration 42, average log likelihood -1.275884
[ Info: iteration 43, average log likelihood -1.275841
[ Info: iteration 44, average log likelihood -1.275817
[ Info: iteration 45, average log likelihood -1.275802
[ Info: iteration 46, average log likelihood -1.275793
[ Info: iteration 47, average log likelihood -1.275787
[ Info: iteration 48, average log likelihood -1.275781
[ Info: iteration 49, average log likelihood -1.275777
[ Info: iteration 50, average log likelihood -1.275772
┌ Info: EM with 100000 data points 50 iterations avll -1.275772
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3345614877105967
│     -1.3343655281083475
│      ⋮                 
└     -1.2757723726799872
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.275987
[ Info: iteration 2, average log likelihood -1.275720
[ Info: iteration 3, average log likelihood -1.274063
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.257143
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.231500
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.209921
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.200360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.204037
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.196800
[ Info: iteration 10, average log likelihood -1.208600
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.191744
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.191534
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.201150
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.197041
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.195452
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.204095
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.188754
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.192698
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.199983
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194911
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.190946
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.193337
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.194284
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.197836
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.199737
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.194651
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.183545
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.199077
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.194403
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.190850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.199996
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.187317
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.199930
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.195782
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.193240
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.189186
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.190617
[ Info: iteration 38, average log likelihood -1.204320
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.186920
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.190613
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.197786
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.182182
[ Info: iteration 43, average log likelihood -1.210422
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.191711
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.182001
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.194806
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.199886
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.196298
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.195382
[ Info: iteration 50, average log likelihood -1.197113
┌ Info: EM with 100000 data points 50 iterations avll -1.197113
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2759869284450194
│     -1.2757200009026406
│      ⋮                 
└     -1.1971134282426612
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.182670
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.174702
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.180697
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.160124
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.142560
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.119490
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.127347
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.111025
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113826
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.108289
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.117735
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.104115
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.115587
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.105611
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.116049
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.109324
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.110362
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.098670
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.120730
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104017
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.108213
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.104083
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.115189
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.106440
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.115877
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.100522
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.114878
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.108793
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.109970
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.098422
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.120640
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.103889
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.108048
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.103944
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.115142
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.106387
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115826
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.100504
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.114876
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.108731
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.109900
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.098341
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.120536
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.103762
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.107913
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.103783
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.114995
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.106386
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.115814
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.100499
┌ Info: EM with 100000 data points 50 iterations avll -1.100499
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1826697780322613
│     -1.174701930114108 
│      ⋮                 
└     -1.1004989559330984
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.411316278258557 
│     -1.4113801247552642
│     -1.4113224084797373
│     -1.4111292189126268
│      ⋮                 
│     -1.1063862423784265
│     -1.1158143354482357
└     -1.1004989559330984
32×26 Array{Float64,2}:
  0.0897847     0.0225434   -0.0212803    0.21933       0.106948    0.030628    -0.0560723    0.0409667    -0.0794255    -0.0154827   -0.116138   -0.258712      0.0951336   0.135397     -0.229693    -0.00471765  -0.0854494   -0.0234913   -0.0948714   -0.054316     0.0903885    -0.0996001     0.0155691  -0.151061    -0.0499297   -0.218742  
  0.019668     -0.108861    -0.0393162    0.0572975    -0.2528     -0.126847    -0.253824     0.0393192     0.0197562    -0.0209248    0.102585    0.00387774    0.0264382   0.024408     -0.070064    -0.123387    -0.135276    -0.0604403    0.0515125   -0.0304951    0.011107      0.0209726     0.0899497   0.0343987   -0.0856067   -0.046295  
  0.0401239     0.0296754    0.0748561   -0.136965      0.0291505   0.0842925    0.0215953   -0.0266569     0.053793      0.065767    -0.0281647   0.0117617     0.177986   -0.122562      0.0583664    0.0458388   -0.00592123   0.00631233   0.0065414    0.0596092   -0.00105154    0.184731     -0.210761    0.122304     0.0536431   -0.0339492 
 -0.0334313     0.00666407   0.042853    -0.050729     -0.0993592   0.130025    -0.0394356   -0.0320011    -0.0435796     0.0458808    0.0190929  -0.0742846    -0.0225026  -0.0333061     0.173585     0.0118396   -0.0361475   -0.100078    -0.0367967    0.083308     0.0108518    -0.0139526    -0.0688361   0.0386565    0.0507058    0.00632314
  0.0921401    -0.105263    -0.150151    -0.103542     -0.170184    0.101122     0.0543375   -0.0533584    -0.0425606     0.0812866   -0.0389173  -0.0164321     0.181872   -0.138898      0.177634    -0.0285777    0.146805    -0.0348351   -0.0400092    0.109067     0.0100883    -0.097108      0.190965   -0.0206811   -0.0152732   -0.0646202 
  0.041474     -0.00388491  -0.0423319   -0.101243     -0.0339993   0.113578     0.0825648    0.0516915    -0.0442752     0.0394777   -0.0721457  -0.00449172   -0.169116    0.0550881     1.63262e-5  -0.151961     0.0988127    0.0699564   -0.0563586   -0.00586747   0.0552021    -0.110808     -0.0784904   0.0829631   -0.00444743   0.0509719 
 -0.142209     -0.0283392    0.227113    -0.0531638     0.0306198  -0.0907329    0.0085347    0.0430494     0.024378      0.120888    -0.0744289  -0.0413535     0.217506    0.129603      0.0238181    0.0512917   -0.1812       0.00699053   0.11647     -0.0366924    0.0038839     0.204224      0.14749    -0.00987876   0.00431554   0.0187222 
 -0.000331539  -0.105693     0.00569122   0.183003     -0.0155108  -0.0523859    0.0368307    0.0634742    -0.00860746   -0.021062    -0.0691016  -0.0188787     0.0381349  -0.0928286    -0.0182286   -0.0287644    0.0458486    0.133141    -0.0624543    0.102611    -0.141492     -0.178842      0.0122237  -0.0320066    0.178914    -0.095717  
  0.0922185    -0.05639     -0.135696    -0.0313709    -0.110338   -0.0948158    0.0670109   -0.0933026    -0.0708843     0.0509156   -0.150731   -0.144811     -0.114433   -0.0387222     0.0542871    0.051166    -0.196162    -0.0405458   -0.130587    -0.0557328    0.0638027     0.00250761    0.175946    0.0241417    0.038883     0.0121477 
  0.0181042    -0.00891753  -0.0995645    0.108656      0.0691224   0.0360406    0.0761864   -0.0980165     0.075759     -0.0271137   -0.292131   -0.0451474    -0.123431   -0.0728402     0.00950452  -0.0404893    0.0340443    0.166939    -0.2499      -0.0109983   -0.0882815     0.119742      0.165603    0.00396653   0.00679751  -0.0216333 
  0.0657951    -0.0138804   -0.0820323   -0.115119      0.0350089  -0.02347     -0.0742548    0.121952      0.124801     -0.0229744   -0.0384415   0.0510968    -0.0277813  -0.0740044     0.0498711    0.0309576   -0.0435206    0.0393155   -0.0439174    0.004668    -0.000969258  -0.134497     -0.0027107   0.0552013    0.185543     0.00463046
  0.0131704     0.00805824   0.0441129    0.207655      0.0314378  -0.0087822   -0.0600316    0.0730748     0.128167     -0.0275568    0.109542   -0.0670195    -0.0341628  -0.0476044    -0.0095034   -0.052415     0.060781    -0.141546     0.0448466   -0.0854575    0.0388803     0.0857054     0.0488174   0.0106464    0.0405678    0.104667  
 -0.269583      0.074352     0.137757    -0.0968247     0.040701    0.0233218    0.230915    -0.151083     -0.0677296     0.0527429   -0.101595   -0.0893624    -0.126959    0.341692      0.0870946   -0.0397706    0.0180846   -0.135161    -0.258214    -0.114875    -0.0489591     0.0998999     0.051788   -0.0429723   -0.219142    -0.0526546 
 -0.26434       0.0357997    0.0495767   -0.103843     -0.087093    0.0539092    0.19252     -0.123394     -0.207128      0.144953    -0.0818143   0.022062     -0.0553826  -0.514738      0.0167625   -0.0454921   -0.0431933   -0.190193     0.0893053   -0.124653    -0.0306142     0.125729      0.62503    -0.059226    -0.218915    -0.0197133 
 -0.137711      0.0620699   -0.0589212   -0.374966     -0.197551    0.0493206   -0.139034     0.154245     -0.303377      0.062551    -0.0752595  -0.335007     -0.119814   -0.13883      -0.260792    -0.130929    -0.116718    -0.0645177   -0.172659    -0.0217072    0.0910277    -0.0513063    -0.111274    0.00711937  -0.0163994    0.233054  
 -0.13804       0.0318926   -0.0975755    0.184909      0.0660293   0.0394937   -0.00789807   0.214208      0.160161      0.0189164   -0.235605    0.0800565    -0.118996   -0.137027      0.0580611    0.241926     0.0521442    0.360202    -0.174145    -0.0199479    0.105692      0.011255     -0.137596    0.00714326   0.0162918    0.0801569 
  0.114727      0.103068    -0.0376748   -0.114199      0.049674   -0.0125609    0.0316187   -0.108622     -0.0609194     0.103675    -0.275483    0.00288631   -0.175272   -0.0696503     0.178586    -0.0939076    0.198988    -0.14147      0.0425563   -0.490706    -0.0262971    -0.177705      0.0621877  -0.0472901   -0.0154086    0.104155  
 -0.0566728     0.104597    -0.0447128   -0.119702     -0.0809675   0.227767     0.0348123   -0.235367      0.0545306    -0.0785425    0.366755   -0.160251      0.136513   -0.0697663    -0.22591     -0.0969261    0.162327     0.332607     0.00650356   0.260965    -0.0201304    -0.177576      0.0557912  -0.0497212   -0.08801      0.106787  
  0.104982     -0.0010955   -0.0529662   -0.29211      -0.0564734   0.0286527    0.0340568    0.14257      -0.0284128     0.0341763    0.0593321   0.0315331    -0.16881     0.0284569     0.160824     0.0261392   -0.0606134   -0.260262     0.00172845   0.0856263    0.0587591     0.217503      0.0269355   0.0462874   -0.0624098   -0.00430625
  0.0755636     0.0147717    0.0442493    0.193401     -0.030153    0.00754076   0.0124742    0.169896     -0.000769917  -0.00411246   0.0609678   0.0408739    -0.177622    0.0404437     0.160575     0.0513119   -0.0936232   -0.248693     0.0268075    0.170149     0.0587933     0.154083      0.0467785   0.0976245   -0.0650617    0.00375116
  0.174098      0.0593157    0.0489912   -0.0962363     0.11511    -0.0211601    0.00202535   0.174952      0.08444      -0.193713     0.0753858   0.0173313     0.0500346   0.00349867    0.0738797   -0.0371217    0.0175603    0.0556019   -0.0156453   -0.298937    -0.00147312    0.0514032    -0.0547589  -0.033962    -0.0437295    0.0284312 
  0.174357      0.0748011    0.105346    -0.115697      0.0537578  -0.0360272   -0.067089    -0.0659846     0.0901115     0.117182     0.0161403   0.0901644    -0.0872486  -0.0122442     0.00365432  -0.0260563    0.0100088    0.0550527   -0.155921     0.109784    -0.0255947     0.125573     -0.105845    0.111119     0.0582597   -0.0462275 
  0.0609859    -0.030993    -0.0551205   -0.017305     -0.217766   -0.0959301    0.0348529    0.0630014    -0.015747      0.0769519   -0.27085     0.125861      0.259939    0.0351889     0.00471347  -0.0899734   -0.0063971   -0.188894     0.021084     0.0270845   -0.143691      0.258253     -0.0288873  -0.0248164    0.0692751   -0.0188121 
  0.0544862     0.060598    -0.0374271    0.0248355    -0.213339   -0.027665    -0.0400212    0.0947315     0.142899      0.00745846   0.208908    0.153006      0.131062    0.0657844     0.0151043   -0.113402     0.0497839   -0.189842     0.18553      0.0240602   -0.0752363     0.271541     -0.0647129  -0.137271     0.0497476   -0.0818295 
 -0.0847506    -0.135883    -0.0757352    0.0947977     0.0680061   0.271588    -0.137664     0.150021     -0.220907      0.0652057   -0.0589082  -0.0681372     0.0696289  -0.522673     -0.0563627    0.083276    -0.0144597   -0.0379406    0.0783759   -0.0166077    0.187005     -0.0656038    -0.103923   -0.00679138  -0.0422201    0.0267191 
 -0.139922     -0.0247859   -0.156951     0.10508      -0.147664    0.214152    -0.0822676    0.000550085   0.166248      0.085941    -0.0361667   0.233447      0.239216    0.440596     -0.162865     0.0869342    0.0227287   -0.0321867    0.0451301    0.0329602    0.0484306    -0.0767169    -0.0734134  -0.0573008    0.0280542    0.046816  
  0.00892693    0.116515    -0.131791     0.0571884     0.137729   -0.165015     0.0442332    0.0796813     0.106661      0.0620725    0.0942119  -0.000863638   0.0712464  -0.0414966     0.0516823    0.0462195   -0.0349088   -0.0190696    0.0363303    0.00747372   0.0179094     0.0388471     0.115951    0.0220026   -0.0198412    0.0802351 
  0.0504044     0.0138534    0.0376844    0.0488978     0.108244   -0.0628581    0.0244198    0.109621      0.0981765    -0.0449331   -0.111659   -0.0856011     0.0121989  -0.0240246    -0.00335789  -0.108879    -0.0212676   -0.00178775  -0.0198307    0.0534564    0.00639092    0.0637307     0.0178964  -0.0135781    0.0578497    0.109561  
  0.0128754    -0.0215922    0.145686    -0.142295     -0.204147   -0.0207291    0.0902601    0.0299574     0.105339      0.0249124    0.177502    0.224188     -0.181375    0.053851      0.0405507   -0.165804    -0.0832723   -0.0496046    0.242124     0.208352     0.116998     -0.0111117    -0.0102921   0.0469757    0.0161669    0.0235387 
 -0.00788056   -0.217527     0.101349     0.000846383   0.569707   -0.0229846    0.0900106   -0.0103621    -0.0153532     0.0601468    0.173593   -0.0176191     0.0398523  -0.000781425   0.0442607   -0.145981    -0.0709319    0.0258204    0.208691     0.0661165    0.139527     -0.011176     -0.0213228   0.062541    -0.0486068    0.0287685 
  0.145278     -0.696856     0.111987    -0.113367      0.107547   -0.0232035    0.0519959    0.200074     -0.0119251    -0.0263619   -0.0204787  -0.0231218    -0.0860044   0.148985     -0.0158791    0.141971     0.0982073   -0.0170762    0.150316    -0.00400423  -0.14656      -0.000113186   0.0448406  -0.121916     0.196477    -0.0506431 
 -0.192094      1.00571      0.0298209    0.10338       0.0473727  -0.120871     0.0612257    0.287138      0.00253035   -0.0259069   -0.0294268  -0.00390276   -0.0862416  -0.0350105    -0.147647     0.155482     0.0095174    0.0121096    0.0107304   -0.0715028   -0.122725      0.000289162   0.0357149   0.0481065    0.219825    -0.0957092 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.114852
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.102564
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.108294
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.098257
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.114298
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.102088
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.107738
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      9
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097409
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.114762
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     15
│     16
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.101288
┌ Info: EM with 100000 data points 10 iterations avll -1.101288
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.612238e+05
      1       6.828943e+05      -1.783295e+05 |       32
      2       6.531422e+05      -2.975214e+04 |       32
      3       6.365801e+05      -1.656210e+04 |       32
      4       6.262773e+05      -1.030279e+04 |       32
      5       6.214356e+05      -4.841619e+03 |       32
      6       6.186978e+05      -2.737862e+03 |       32
      7       6.168043e+05      -1.893496e+03 |       32
      8       6.154925e+05      -1.311800e+03 |       32
      9       6.144916e+05      -1.000891e+03 |       32
     10       6.136616e+05      -8.299786e+02 |       32
     11       6.129342e+05      -7.274331e+02 |       32
     12       6.122573e+05      -6.768848e+02 |       32
     13       6.115250e+05      -7.323038e+02 |       32
     14       6.106992e+05      -8.258067e+02 |       32
     15       6.099760e+05      -7.231920e+02 |       32
     16       6.095235e+05      -4.525493e+02 |       32
     17       6.091976e+05      -3.258480e+02 |       32
     18       6.089626e+05      -2.350207e+02 |       32
     19       6.087405e+05      -2.221307e+02 |       32
     20       6.084548e+05      -2.856414e+02 |       32
     21       6.080872e+05      -3.676307e+02 |       32
     22       6.077191e+05      -3.680507e+02 |       32
     23       6.074135e+05      -3.056465e+02 |       32
     24       6.071826e+05      -2.309076e+02 |       32
     25       6.070288e+05      -1.537408e+02 |       32
     26       6.069444e+05      -8.443786e+01 |       32
     27       6.068891e+05      -5.530867e+01 |       32
     28       6.068521e+05      -3.698719e+01 |       32
     29       6.068274e+05      -2.470332e+01 |       32
     30       6.068083e+05      -1.912638e+01 |       30
     31       6.067944e+05      -1.391840e+01 |       32
     32       6.067843e+05      -1.003880e+01 |       28
     33       6.067761e+05      -8.253159e+00 |       28
     34       6.067696e+05      -6.442106e+00 |       27
     35       6.067655e+05      -4.133832e+00 |       25
     36       6.067613e+05      -4.204863e+00 |       24
     37       6.067558e+05      -5.505315e+00 |       27
     38       6.067497e+05      -6.111870e+00 |       29
     39       6.067435e+05      -6.131243e+00 |       29
     40       6.067379e+05      -5.641689e+00 |       26
     41       6.067331e+05      -4.768147e+00 |       28
     42       6.067295e+05      -3.644298e+00 |       22
     43       6.067265e+05      -2.930641e+00 |       25
     44       6.067230e+05      -3.593128e+00 |       26
     45       6.067203e+05      -2.669724e+00 |       22
     46       6.067180e+05      -2.236571e+00 |       20
     47       6.067161e+05      -1.994604e+00 |       21
     48       6.067135e+05      -2.561717e+00 |       24
     49       6.067103e+05      -3.165866e+00 |       22
     50       6.067080e+05      -2.293980e+00 |       24
K-means terminated without convergence after 50 iterations (objv = 606708.0298864086)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329820
[ Info: iteration 2, average log likelihood -1.302865
[ Info: iteration 3, average log likelihood -1.278282
[ Info: iteration 4, average log likelihood -1.253340
[ Info: iteration 5, average log likelihood -1.216397
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.159617
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.143851
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│      9
│     13
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.109113
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.176528
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.142746
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.108632
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     12
│     13
│     16
│     17
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.071438
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.152088
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.136589
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.109526
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     17
│     21
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.094762
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     16
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.114490
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.147161
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.089824
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      8
│     12
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.080558
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     16
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.104574
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.145270
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.092366
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.077907
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     12
│     13
│     16
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.084646
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.155205
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.104735
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.092039
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      6
│     12
│     13
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.071815
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.110640
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.104334
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     18
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.091163
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.082653
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      9
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.090502
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.117987
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.084199
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     17
│     21
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.073255
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.118216
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.096459
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.108088
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080509
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│      9
│     13
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.081893
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     18
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.103143
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     16
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.105083
[ Info: iteration 45, average log likelihood -1.142455
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.060692
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│     17
│     18
│     21
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065170
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.136948
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.105744
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.086097
┌ Info: EM with 100000 data points 50 iterations avll -1.086097
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0123953   -0.052849    -0.042047    0.0745436   -0.103935      0.0972915    0.0296575    0.108597     0.22224      0.00352296   0.196534   -0.104813     0.0445941    0.042175     0.185928     0.056956    0.0508837   -0.155666     0.123201   -0.00377492   0.102696    -0.141396     0.0439779    0.103483     -0.0395382     0.0466777 
  0.102199    -0.0466901   -0.0328489  -0.0568205   -0.0562135    -0.0191354    0.0157807    0.0550436    0.120418    -0.0454773    0.0755031   0.0504995   -0.0616885   -0.169741     0.122744    -0.029606   -0.093957     0.135665    -0.0600332  -0.00163809  -0.0460613   -0.192182     0.0289527   -0.0652609     0.211515     -0.0401377 
  0.087147     0.0161799    0.219765   -0.121411     0.000369969   0.0958872    0.0262389   -0.0206124    0.0310166    0.0252769    0.015839    0.0250957    0.180728    -0.121248     0.119091     0.0370914   0.021295     0.0561807    0.0651227   0.107078    -0.0617149    0.141343    -0.294713     0.0906045     0.00281932   -0.158943  
 -0.136353    -0.0879918   -0.043497    0.259219     0.0041539    -0.117246     0.0462131    0.0594909    0.11536     -0.108013    -0.060072    0.011109     0.0386696   -0.0214093    0.0207795   -0.0133179   0.0123851    0.057691    -0.0168592   0.0901646   -0.199615    -0.26584      0.0727719   -0.0125999     0.162376     -0.0296097 
  0.0963077    0.0266548   -0.0147181   0.21706      0.103857      0.0333828   -0.0557665    0.0353492   -0.0838465   -0.0115379   -0.114088   -0.260824     0.0949791    0.135497    -0.233868    -0.0044275  -0.0907688   -0.0263479   -0.0951529  -0.0537153    0.0891572   -0.100149     0.0154996   -0.152923     -0.0514327    -0.230697  
  0.0120785   -0.0435408    0.0416334   0.222711     0.00610504    0.0705011   -0.172192    -0.004299     0.20124     -0.102149     0.0850162  -0.0774762   -0.0499768    0.00539413  -0.0557732   -0.0671413   0.0246294   -0.0243161   -0.006281   -0.0153892    0.0472603    0.0398816    0.0917081   -0.0889337     0.0384266     0.281591  
 -0.0379602    0.225845     0.070121    0.00200275   0.0745673    -0.0753611    0.0570427    0.244984    -0.00496579  -0.0259193   -0.0242993  -0.0126668   -0.086062     0.0471186   -0.0869533    0.148472    0.0486713   -0.00143858   0.0774089  -0.0378289   -0.132446    -0.00080525   0.0383874   -0.0285816     0.205587     -0.0756634 
 -0.0996033   -0.0391838   -0.0538276   0.109846     0.207861     -0.00752326   0.156996     0.149179     0.177547    -0.13343     -0.0694784  -0.11564      0.0239361   -0.0422776    0.100156    -0.160737   -0.014561     0.0637705   -0.137495    0.0941111   -0.00496029   0.139856     0.0750917    0.069175      0.000435964   0.0949424 
  0.144568    -0.121753     0.0560891   0.168908    -0.024817      0.0255528    0.0350934    0.0543277   -0.148812     0.0772108   -0.061192   -0.0512892    0.0440232   -0.166925    -0.053306    -0.0420404   0.0687935    0.20104     -0.103388    0.114161    -0.090499    -0.0998231   -0.0529483   -0.0322042     0.212094     -0.17289   
 -0.112702    -0.0791614   -0.118701    0.0975801   -0.0394885     0.243618    -0.107533     0.0692879   -0.0213474    0.0747388   -0.0427565   0.0894015    0.155974    -0.0180901   -0.108028     0.0852638   0.00330819  -0.03295      0.0590202   0.0105762    0.116878    -0.0720317   -0.0901165   -0.0340862    -0.011872      0.0391426 
 -0.266376     0.0560127    0.0945428  -0.104487    -0.0209486     0.0406796    0.212715    -0.138116    -0.139531     0.0977971   -0.0913888  -0.0357523   -0.0948641   -0.081209     0.0524635   -0.0424099  -0.0114079   -0.163314    -0.0862086  -0.120419    -0.0399139    0.111478     0.332077    -0.0506026    -0.21894      -0.0363884 
 -0.147004    -0.00751823  -0.0177667  -0.0929891   -0.110343      0.179346    -0.0252682   -0.00173725  -0.166233     0.117412    -0.0200235  -0.139615     0.019488    -0.00961296   0.0900047   -0.0576575  -0.0473133   -0.165995    -0.157387    0.155088    -0.0383859    0.109045    -0.187147     0.000866982   0.0488929     0.080215  
 -0.0961232    0.0437758   -0.089892   -0.106222    -0.0784514     0.0525761   -0.0579391    0.153481    -0.10636      0.0378818   -0.157753   -0.154897    -0.109915    -0.132553    -0.112066     0.0592611  -0.0216478    0.177926    -0.144026    0.0125191    0.0891164   -0.00998348  -0.146517     0.0221577    -0.000281563   0.153243  
 -0.146669    -0.0260734    0.238735   -0.0607458    0.0318717    -0.0913672    0.00799719   0.0398047    0.0219614    0.12316     -0.080657   -0.0381091    0.220469     0.13401      0.0234515    0.0504303  -0.187014     0.0149783    0.116821   -0.0346667    0.00242326   0.204594     0.148293    -0.0144285     0.00484739    0.0204244 
  0.220184     0.14946      0.0809999   0.0730503    0.131491     -0.048417    -0.0333584    0.0854886    0.00675896   0.0267182   -0.0506547  -0.0469786    0.071131     0.02342     -0.170809    -0.146542   -0.161228    -0.0411681    0.156089    0.106002     0.225684     0.116616    -0.0213911   -0.150447      0.053422      0.00509495
  0.0385444    0.152512    -0.134603   -0.108855     0.0689963    -0.114277     0.0897106    0.0953368   -0.0401347    0.155096     0.11924    -0.00685862   0.151063    -0.0321752    0.07509      0.110226   -0.0456334   -0.0354067    0.028978    0.0121775    0.0072969    0.154306    -0.0332652    0.10618       0.0604143     0.0444972 
  0.0358438   -0.0725169    0.0808712  -0.0129895    0.0218792    -0.13356     -0.0366384    0.130987     0.072742    -0.0564595   -0.204243   -0.0863378   -0.0788804   -0.067103     0.0133604   -0.0553308   0.0846163    0.0569834   -0.0921827   0.0250616   -0.213569    -0.0209548   -0.0412716    0.013825      0.121402      0.185955  
  0.0279853   -0.105417    -0.0384337   0.0552567   -0.247174     -0.120499    -0.245161     0.0389892    0.0188607   -0.0215859    0.103683    0.00260208   0.0258526    0.0199045   -0.0688978   -0.119205   -0.127882    -0.0580603    0.057773   -0.0272916    0.00966974   0.0210067    0.0743096    0.0361239    -0.0957696    -0.0472187 
 -0.0517907    0.0603506    0.20106    -0.101795    -0.0942864     0.134878    -0.0365968   -0.194865     0.0486289    0.0848683   -0.107548    0.00795077   0.0896206   -0.073245     0.220807     0.0465781  -0.0630501   -0.120045    -0.177933   -0.0973706    0.0772535    0.0996189    3.18006e-5   0.0822444     0.140571      0.195803  
  0.0890755   -0.104563    -0.146853   -0.102563    -0.169845      0.10283      0.0528708   -0.0504887   -0.0469507    0.0831412   -0.0425391  -0.0143336    0.181392    -0.138943     0.17021     -0.0292229   0.145772    -0.0317533   -0.0423373   0.105212     0.0105812   -0.0976551    0.18589     -0.0235671    -0.0154184    -0.0611667 
  0.0131623   -0.114707     0.17045    -0.110868     0.212219     -0.0134236    0.0797405    0.00428881   0.0427303    0.0596108    0.163997    0.114599    -0.056994     0.0256253    0.0384857   -0.151517   -0.0769064   -0.0126263    0.21427     0.160817     0.110635    -0.007157    -0.020936     0.0588369    -0.0716131     0.0159752 
  0.00202448   0.0534003   -0.172626   -0.283577     0.190917     -0.0173698   -0.22043      0.20301      0.0888589    0.037788    -0.244703    0.101165     0.0421358    0.0409319   -0.125753     0.104218    0.0421434   -0.132322     0.0318696   0.0236926    0.0934416   -0.0193852   -0.102805     0.260402      0.170265      0.032078  
  0.0577687    0.0147169   -0.0475406   0.00421055  -0.2158       -0.0602792   -0.00360896   0.0802845    0.0620885    0.042559    -0.024427    0.140829     0.194023     0.0516354    0.00999017  -0.101782    0.0225179   -0.189474     0.10636     0.025818    -0.107572     0.266012    -0.0470543   -0.0840757     0.0575905    -0.0526773 
 -0.0162563    0.0660811   -0.153214    0.152531     0.207739     -0.163113    -0.00770876   0.0413859    0.266287    -0.0578904    0.0575901   0.0157676   -0.00190182  -0.107659     0.0352973   -0.0165929  -0.0213981    0.0383107    0.0538172   0.0321581    0.0206794   -0.0205878    0.194119    -0.0530273    -0.111456      0.0800019 
  0.0316394    0.103619    -0.0408664  -0.117136    -0.0149185     0.103038     0.0337659   -0.170677    -0.0059801    0.0142562    0.039554   -0.0750862   -0.025758    -0.0698335   -0.0204639   -0.0951262   0.179898     0.0889642    0.0254659  -0.124286    -0.0229242   -0.178112     0.0589336   -0.0482932    -0.0503638     0.10485   
  0.0421047   -0.00237763  -0.0430265  -0.103822    -0.034363      0.113411     0.0869446    0.0500086   -0.0447843    0.0406479   -0.0719503  -0.00322864  -0.177474     0.0562448    0.00122082  -0.155925    0.098349     0.070785    -0.0578741  -0.00768389   0.0539293   -0.112525    -0.0787032    0.0835743    -0.00485366    0.0500567 
  0.105004    -0.00798399   0.23141     0.0166097   -0.126991      0.101101    -0.0558047   -0.112745    -0.0619457   -0.0238497    0.0624306  -0.0442619   -0.155951    -0.104204     0.344615     0.0619204  -0.0580417    0.0408633    0.0885322   0.1277      -0.0662943   -0.0493651   -0.0821503    0.00935761    0.110544     -0.343485  
  0.0882423   -0.00332277  -0.0176229  -0.130045    -0.048684      0.0211695    0.0276059    0.144812    -0.0171129    0.0216781    0.0629145   0.0317518   -0.162316     0.029211     0.1591       0.0285897  -0.0705379   -0.248342     0.012536    0.113924     0.058247     0.183555     0.0305341    0.0608407    -0.0607015    -0.00345623
  0.00991237   0.0579494    0.0462017   0.19108      0.0643797    -0.12032      0.0566289    0.141754     0.03219      0.0469619    0.115331   -0.063563    -0.00641207  -0.139969     0.0426192   -0.0410049   0.0855471   -0.249419     0.0947074  -0.161834     0.0233139    0.156222     0.0149013    0.0810845     0.0407485    -0.0738325 
  0.174615     0.0734328    0.0929226  -0.116601     0.0763778    -0.0325128   -0.045977     0.00925948   0.0894472    0.024592     0.0398926   0.0766939   -0.0451033   -0.0102926    0.0253517   -0.0284318   0.011656     0.0540475   -0.107801   -0.0259792   -0.013995     0.102659    -0.092791     0.0626797     0.0314944    -0.035743  
  0.0173336   -0.0109957   -0.100821    0.110557     0.0673536     0.0375659    0.0764355   -0.0998193    0.0773258   -0.0270781   -0.292404   -0.0469055   -0.12257     -0.0769529    0.0100472   -0.0442969   0.034162     0.170881    -0.25079    -0.0135471   -0.0900407    0.122238     0.166229     0.00347265    0.00604253   -0.0226632 
  0.0930751   -0.0569218   -0.135825   -0.0327771   -0.103126     -0.0954525    0.0705048   -0.0925793   -0.0708865    0.0529565   -0.155725   -0.143127    -0.114857    -0.0392173    0.05446      0.0490648  -0.1971      -0.0406509   -0.134224   -0.0528948    0.061996     0.00314096   0.174333     0.0235629     0.0388172     0.0138981 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     18
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.097770
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      6
│     13
│      ⋮
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.035168
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.019904
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060492
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│     16
│     18
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.051689
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.012276
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     16
│     18
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.080440
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      6
│     13
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.023779
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.022757
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      6
│     13
│      ⋮
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.065999
┌ Info: EM with 100000 data points 10 iterations avll -1.065999
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0234388     0.02013       0.063092     0.0136638   -0.11393       0.00360864  -0.0460871   -0.00528022   0.0335897    0.0219396   0.0361099   -0.0125734   -0.0332647     0.12982    -0.13526      0.0811027    0.0115917    0.102243    -0.0285033    0.0390943    0.15189     -0.013059     0.13241      0.111504     0.0417388   -0.117242 
 -0.0195917    -0.0199335    -0.188092     0.137091    -0.114966      0.270057    -0.0504897   -0.200946    -0.0181863    0.133194   -0.0457036    0.0300198    0.138545      0.0135352  -0.0805454    0.199144     0.0815298    0.197679     0.123314    -0.183069     0.0496401    0.0535457    0.186816    -0.0563705    0.00254317  -0.035167 
  0.108701      0.0381714     0.0451863   -0.0663246   -0.146184      0.0486159    0.0365056    0.0141879    0.190191    -0.116543    0.0489228    0.0358324   -0.0539273     0.0461151   0.0910094    0.0589405   -0.133362     0.0708452    0.158662     0.0327967   -0.00175962   0.0833026    0.159606    -0.0520022    0.00447632  -0.104787 
  0.0545887     0.000470475  -0.029099    -0.0615619   -0.00839652    0.265229    -0.0045437   -0.0956068    0.0182619    0.127288   -0.0181841   -0.139726    -0.033247      0.0419244  -0.120007    -0.0255353   -0.0275148   -0.111099    -0.236676     0.0247392   -0.154737     0.0824703    0.031086     0.099492     0.109616     0.0287423
  0.00459709   -0.126954     -0.0954637   -0.100751     0.0467676    -0.0324195   -0.0917615   -0.0872433    0.0232788    0.0440583   0.0503208   -0.0391798   -0.00277272    0.266163   -0.00621831  -0.00186835   0.0246492    0.0951905   -0.148938    -0.155757     0.00901546  -0.0604204    0.108674     0.115876     0.0855913   -0.112491 
  0.151066     -0.0188844     0.158055    -0.079101     0.00237783    0.046862    -0.0875253    0.19343     -0.211874     0.0775946   0.0349386    0.0402762   -0.0605683     0.132979    0.210447     0.0227312   -0.127159    -0.0258978    0.0569695    0.018652     0.100507     0.0787078    0.0856016    0.0838512   -0.029075    -0.0807998
  0.0462104    -0.0484046     0.125716    -0.00513895   0.18222       0.119422     0.137949    -0.141501    -0.024485     0.0603207  -0.0188768    0.0715944   -0.0888435     0.124012    0.0531745   -0.0308206   -0.17526      0.0737469    0.0750724   -0.0146624   -0.0780629   -0.0827765   -0.0362097    0.0618234    0.0621614   -0.0152266
  0.0457273    -0.0604741     0.115537     0.0651386   -0.104198     -0.00898077  -0.0871201    0.0499897    0.0620829    0.10175     0.0432131   -0.163156    -0.0370791     0.0708106  -0.0179428   -0.173285     0.0983283   -0.0503316    0.00823515   0.0310802   -0.174867     0.19461      0.140485    -0.0501314   -0.0257055   -0.0364139
  0.117522     -0.0302565    -0.137481     0.121728     0.0951163    -0.00721744   0.102104    -0.162358     0.0348141    0.162719   -0.00220007  -0.0236481    0.172758     -0.120256    0.114901    -0.0181295   -0.0205836   -0.192007    -0.0176208   -0.0617214    0.0517121   -0.134747     0.153347    -0.136228     0.00265985  -0.0220276
  0.0182492    -0.0114831    -0.235119    -0.163202     0.110053     -0.089054    -0.159636    -0.085261     0.112113     0.0837934  -0.233642    -0.193963    -0.0319868    -0.14167    -0.00377453   0.102346     0.152978    -0.124951    -0.0741511    0.137523     0.144988    -0.127526     0.0753399    0.019011     0.0856065    0.0247853
 -0.154294      0.237914     -0.152681    -0.0296483    0.0955929     0.0552264   -0.0720248   -0.0452541    0.0396565    0.015215   -0.0137303    0.0058853    0.0189436    -0.0165034  -0.0697847    0.0436749   -0.00397433   0.0217196   -0.111796     0.0178592    0.0149842   -0.0202597    0.13944     -0.03305      0.0348384   -0.0761111
 -0.00231873   -0.0984408     0.102294    -0.0106113   -0.131733      0.0355037   -0.0534452   -0.0172109   -0.040688    -0.0445374  -0.0226012    0.0336847   -0.115702     -0.070599   -0.0754501    0.0611624   -0.160329    -0.235815     0.107515     0.144573     0.191208    -0.0792738    0.123692    -0.0211964   -0.0675904    0.18062  
  0.0104865     0.0839163     0.049843     0.0484884   -0.000658587   0.0731256    0.0247887   -0.0609439   -0.236916    -0.0472193   0.00483514  -0.0379983    0.000905177  -0.137584    0.0471396   -0.0591524    0.0501414   -0.00603716  -0.0380955    0.100109    -0.155014    -0.0568564    0.0430112   -0.0253198    0.0587745    0.0649196
  0.0237895    -0.048091      0.0161665   -0.0966423    0.0618505     0.0314539   -0.0859983    0.0903319   -0.172246    -0.0260247   0.202285     0.0730753    0.210991     -0.0480075  -0.116444     0.0449063   -0.0741887   -0.196017     0.0276026    0.0315606   -0.0421601    0.0759356    0.150298    -0.00539368   0.0211352   -0.154189 
  0.0207701     0.0594519     0.0837844    0.0163221   -0.0267878    -0.135897    -0.174603     0.176182     0.130321     0.0476747   0.104332     0.097119    -0.037418     -0.0408576  -0.0175812    0.0671308    0.0851446   -0.22333      0.140703     0.00421656   0.0121925    0.0835839   -0.0201982    0.0789679   -0.0808443    0.136183 
  0.146375     -0.083599     -0.175914    -0.0393303    0.0730147     0.0999458    0.0234135    0.0932695   -0.0261436    0.114295    0.135982     0.0548703    0.00935639    0.0766525   0.0355596    0.0614602    0.0967933   -0.127146    -0.00866831   0.0199377    0.0129162    0.0991732   -0.243079     0.0212702   -0.0090422   -0.0282756
 -0.0742156    -0.110732      0.0893766    0.14045      0.0674904     0.0697351    0.0203693    0.290887    -0.0281747   -0.143194   -0.0180058    0.0736652    0.193176     -0.122113   -0.126879     0.0321878   -0.14989     -0.0413647    0.118974    -0.0821654    0.109898     0.155975     0.0517344   -0.0453753   -0.0928033   -0.0531985
 -0.0158592     0.0277212     0.209606    -0.00804989  -0.0166096     0.0460682    0.0408525   -0.0193113   -0.0798573    0.0176089   0.0313029   -0.0323159   -0.062294     -0.0293365   0.0418574   -0.0700641    0.0309628    0.0713832    0.0776605   -0.0378844    0.0910792   -0.0661299    0.0689824   -0.0135127   -0.0713032   -0.0567584
  0.0565819    -0.00613098   -0.106422     0.0566579   -0.00171135   -0.178765    -0.146599     0.0158582   -0.0464268    0.0777545   0.133372    -0.173585    -0.00302149    0.0720608  -0.00278893  -0.114489    -0.163703     0.0037409   -0.106894    -0.152131    -0.010834    -0.19662     -0.0370392   -0.0617036   -0.0402707   -0.109372 
  0.0715112     0.0293084    -0.188743    -0.00439354   0.131498      0.059421     0.0394465    0.0881396   -0.181423    -0.0673055   0.0402889   -0.0263627   -0.0289463    -0.0398001   0.0994058   -0.0117182   -0.0803751    0.0738962    0.0335335    0.00124757   0.2036       0.115527    -0.107448     0.0862414    0.110885    -0.100281 
  0.121852      0.0538618    -0.017542    -0.0526018   -0.0360638     0.0204213   -0.0336774   -0.037596     0.0465028    0.193868   -0.131806     0.0604284    0.0154005    -0.0408946  -0.106063    -0.0775883   -0.0671856    0.0156239   -0.069798    -0.168418     0.00775024  -0.0959085   -0.0084419   -0.00421563  -0.00362049   0.0485056
 -0.244         0.066842     -0.0751171    0.246295    -0.068758     -0.0135039    0.101312    -0.0820641    0.12625      0.195872    0.0132302   -0.00164387  -0.0493168     0.0936593  -0.0619826    0.0952106   -0.0171512    0.00454008  -0.0380517    0.0759871    0.0793808   -0.158262     0.0268334   -0.121879    -0.0316469   -0.161512 
 -0.0959286    -0.104538     -0.0149363   -0.0197767   -0.12213       0.109283     0.00665337   0.111287    -0.072675     0.0328365  -0.147794    -0.0164574    0.142454      0.0634961   0.0554477   -0.0645994    0.0113989   -0.0512341   -0.0369789    0.139902     0.058668     0.174016     0.125705    -0.115214     0.0506911    0.10285  
  0.0200709     0.0520237     0.0538467    0.0495832   -0.0121803    -0.058312    -0.0269262    0.0435373    0.136565     0.103821    0.0210053   -0.00328741   0.0409858     0.0584001  -0.0500394   -0.158475    -0.00609158  -0.0217929    0.0345118    0.0224278    0.0920519   -0.0393014   -0.0213844    0.172042     0.0396764    0.149727 
 -0.0609469     0.0237778     0.00946648   0.102129    -0.189857      0.0949723   -0.104456    -0.145965    -0.00211572  -0.121921   -0.00278483   0.0116797    0.07917      -0.055663    0.151443    -0.0948326   -0.0645109    0.0772666    0.00403504  -0.178056     0.135024    -0.0298003    0.134238     0.089199    -0.00583737   0.0108479
 -0.00305857   -0.22496       0.00278985  -0.0088108    0.085317     -0.0496517    0.192761    -0.0343421    0.203042     0.027341   -0.0365077   -0.0663029    0.0281146    -0.0708045  -0.0869647   -0.0530407   -0.113154     0.0824151    0.0463743    0.0638834   -0.0569186   -0.0311222    0.0364368   -0.00841246  -0.128726     0.0754002
 -0.0525293     0.0104629    -0.1721      -0.107383    -0.149367     -0.0446574   -0.0647242   -0.10212     -0.114757     0.125591    0.0162266   -0.121192    -0.0920969     0.0984059  -0.143629     0.106312     0.0801144    0.0804502   -0.158962    -0.0203916    0.0990761    0.0204983   -0.0334202   -0.0770359    0.0187935   -0.0113454
 -0.125224      0.00941602   -0.0698075   -0.0821553   -0.0824532    -0.0458199   -0.0914214    0.0674841   -0.0483983   -0.120312    0.00511439  -0.0522526   -0.237143     -0.10059    -0.00681005   0.0784886    0.0293228   -0.0896405    0.0808613   -0.0955303    0.0295793   -0.00632494   0.0405101   -0.0432783    0.0630512    0.253125 
  0.0116227     0.0822204    -0.100788     0.0312323   -0.112181      0.0232461   -0.20548      0.0304239   -0.0557627   -0.0174728  -0.0596769   -0.0352488   -0.0933067    -0.121777   -0.0846116    0.0528205   -0.0171086   -0.0932114   -0.0587067   -0.0516444   -0.117414     0.114496    -0.0423052   -0.0296941   -0.0686197    0.0293472
 -0.000819489   0.178406     -0.0668117   -0.12586      0.0106783    -0.0932261   -0.276391     0.0761125   -0.0770028   -0.0700724   0.175937     0.0751098    0.0814451     0.135592   -0.0164823    0.0315409   -0.0217603    0.0158323   -0.0292228   -0.0945122    0.0749648   -0.20932     -0.00666915   0.168526    -0.0232631    0.123187 
 -0.19851      -0.118456      0.0651923   -0.0155044    0.125622     -0.0134514    0.078932     0.0530135   -0.0136428    0.10879    -0.0480383   -0.15708     -0.162216      0.087936   -0.0857694   -0.09613     -0.0188162    0.179256    -0.0176904    0.121608    -0.0755459   -0.00357537   0.00178079  -0.192103    -0.0477669    0.138982 
  0.0079936     0.0175584    -0.107532     0.056334     0.00488611    0.0157045   -0.0640778   -0.241436     0.0492298   -0.084885    0.165787    -0.135663    -0.159301     -0.0410106   0.112495     0.281924     0.0343231    0.03656      0.0539952   -0.0714978    0.081075    -0.0383053    0.203058     0.0799732   -0.0219843    0.200243 kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4191423180890121
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419160
[ Info: iteration 2, average log likelihood -1.419092
[ Info: iteration 3, average log likelihood -1.419037
[ Info: iteration 4, average log likelihood -1.418969
[ Info: iteration 5, average log likelihood -1.418882
[ Info: iteration 6, average log likelihood -1.418775
[ Info: iteration 7, average log likelihood -1.418654
[ Info: iteration 8, average log likelihood -1.418529
[ Info: iteration 9, average log likelihood -1.418416
[ Info: iteration 10, average log likelihood -1.418320
[ Info: iteration 11, average log likelihood -1.418240
[ Info: iteration 12, average log likelihood -1.418166
[ Info: iteration 13, average log likelihood -1.418082
[ Info: iteration 14, average log likelihood -1.417967
[ Info: iteration 15, average log likelihood -1.417789
[ Info: iteration 16, average log likelihood -1.417501
[ Info: iteration 17, average log likelihood -1.417045
[ Info: iteration 18, average log likelihood -1.416384
[ Info: iteration 19, average log likelihood -1.415572
[ Info: iteration 20, average log likelihood -1.414789
[ Info: iteration 21, average log likelihood -1.414213
[ Info: iteration 22, average log likelihood -1.413874
[ Info: iteration 23, average log likelihood -1.413701
[ Info: iteration 24, average log likelihood -1.413618
[ Info: iteration 25, average log likelihood -1.413580
[ Info: iteration 26, average log likelihood -1.413562
[ Info: iteration 27, average log likelihood -1.413554
[ Info: iteration 28, average log likelihood -1.413551
[ Info: iteration 29, average log likelihood -1.413549
[ Info: iteration 30, average log likelihood -1.413548
[ Info: iteration 31, average log likelihood -1.413547
[ Info: iteration 32, average log likelihood -1.413547
[ Info: iteration 33, average log likelihood -1.413546
[ Info: iteration 34, average log likelihood -1.413546
[ Info: iteration 35, average log likelihood -1.413546
[ Info: iteration 36, average log likelihood -1.413546
[ Info: iteration 37, average log likelihood -1.413546
[ Info: iteration 38, average log likelihood -1.413546
[ Info: iteration 39, average log likelihood -1.413545
[ Info: iteration 40, average log likelihood -1.413545
[ Info: iteration 41, average log likelihood -1.413545
[ Info: iteration 42, average log likelihood -1.413545
[ Info: iteration 43, average log likelihood -1.413545
[ Info: iteration 44, average log likelihood -1.413545
[ Info: iteration 45, average log likelihood -1.413545
[ Info: iteration 46, average log likelihood -1.413545
[ Info: iteration 47, average log likelihood -1.413545
[ Info: iteration 48, average log likelihood -1.413545
[ Info: iteration 49, average log likelihood -1.413545
[ Info: iteration 50, average log likelihood -1.413545
┌ Info: EM with 100000 data points 50 iterations avll -1.413545
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4191602161820498
│     -1.4190922134748867
│      ⋮                 
└     -1.4135447963744714
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413560
[ Info: iteration 2, average log likelihood -1.413492
[ Info: iteration 3, average log likelihood -1.413422
[ Info: iteration 4, average log likelihood -1.413328
[ Info: iteration 5, average log likelihood -1.413200
[ Info: iteration 6, average log likelihood -1.413045
[ Info: iteration 7, average log likelihood -1.412882
[ Info: iteration 8, average log likelihood -1.412737
[ Info: iteration 9, average log likelihood -1.412624
[ Info: iteration 10, average log likelihood -1.412539
[ Info: iteration 11, average log likelihood -1.412474
[ Info: iteration 12, average log likelihood -1.412422
[ Info: iteration 13, average log likelihood -1.412381
[ Info: iteration 14, average log likelihood -1.412348
[ Info: iteration 15, average log likelihood -1.412321
[ Info: iteration 16, average log likelihood -1.412300
[ Info: iteration 17, average log likelihood -1.412283
[ Info: iteration 18, average log likelihood -1.412270
[ Info: iteration 19, average log likelihood -1.412259
[ Info: iteration 20, average log likelihood -1.412250
[ Info: iteration 21, average log likelihood -1.412243
[ Info: iteration 22, average log likelihood -1.412236
[ Info: iteration 23, average log likelihood -1.412231
[ Info: iteration 24, average log likelihood -1.412227
[ Info: iteration 25, average log likelihood -1.412223
[ Info: iteration 26, average log likelihood -1.412219
[ Info: iteration 27, average log likelihood -1.412216
[ Info: iteration 28, average log likelihood -1.412213
[ Info: iteration 29, average log likelihood -1.412210
[ Info: iteration 30, average log likelihood -1.412207
[ Info: iteration 31, average log likelihood -1.412204
[ Info: iteration 32, average log likelihood -1.412202
[ Info: iteration 33, average log likelihood -1.412199
[ Info: iteration 34, average log likelihood -1.412197
[ Info: iteration 35, average log likelihood -1.412195
[ Info: iteration 36, average log likelihood -1.412192
[ Info: iteration 37, average log likelihood -1.412190
[ Info: iteration 38, average log likelihood -1.412188
[ Info: iteration 39, average log likelihood -1.412186
[ Info: iteration 40, average log likelihood -1.412184
[ Info: iteration 41, average log likelihood -1.412181
[ Info: iteration 42, average log likelihood -1.412179
[ Info: iteration 43, average log likelihood -1.412177
[ Info: iteration 44, average log likelihood -1.412175
[ Info: iteration 45, average log likelihood -1.412173
[ Info: iteration 46, average log likelihood -1.412171
[ Info: iteration 47, average log likelihood -1.412169
[ Info: iteration 48, average log likelihood -1.412167
[ Info: iteration 49, average log likelihood -1.412165
[ Info: iteration 50, average log likelihood -1.412163
┌ Info: EM with 100000 data points 50 iterations avll -1.412163
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4135595090657096
│     -1.413491515410726 
│      ⋮                 
└     -1.4121633784318384
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412173
[ Info: iteration 2, average log likelihood -1.412114
[ Info: iteration 3, average log likelihood -1.412060
[ Info: iteration 4, average log likelihood -1.411994
[ Info: iteration 5, average log likelihood -1.411910
[ Info: iteration 6, average log likelihood -1.411807
[ Info: iteration 7, average log likelihood -1.411690
[ Info: iteration 8, average log likelihood -1.411570
[ Info: iteration 9, average log likelihood -1.411457
[ Info: iteration 10, average log likelihood -1.411359
[ Info: iteration 11, average log likelihood -1.411278
[ Info: iteration 12, average log likelihood -1.411211
[ Info: iteration 13, average log likelihood -1.411155
[ Info: iteration 14, average log likelihood -1.411108
[ Info: iteration 15, average log likelihood -1.411067
[ Info: iteration 16, average log likelihood -1.411033
[ Info: iteration 17, average log likelihood -1.411004
[ Info: iteration 18, average log likelihood -1.410979
[ Info: iteration 19, average log likelihood -1.410957
[ Info: iteration 20, average log likelihood -1.410939
[ Info: iteration 21, average log likelihood -1.410922
[ Info: iteration 22, average log likelihood -1.410908
[ Info: iteration 23, average log likelihood -1.410895
[ Info: iteration 24, average log likelihood -1.410883
[ Info: iteration 25, average log likelihood -1.410873
[ Info: iteration 26, average log likelihood -1.410863
[ Info: iteration 27, average log likelihood -1.410854
[ Info: iteration 28, average log likelihood -1.410845
[ Info: iteration 29, average log likelihood -1.410837
[ Info: iteration 30, average log likelihood -1.410829
[ Info: iteration 31, average log likelihood -1.410822
[ Info: iteration 32, average log likelihood -1.410815
[ Info: iteration 33, average log likelihood -1.410808
[ Info: iteration 34, average log likelihood -1.410802
[ Info: iteration 35, average log likelihood -1.410795
[ Info: iteration 36, average log likelihood -1.410789
[ Info: iteration 37, average log likelihood -1.410783
[ Info: iteration 38, average log likelihood -1.410777
[ Info: iteration 39, average log likelihood -1.410771
[ Info: iteration 40, average log likelihood -1.410766
[ Info: iteration 41, average log likelihood -1.410760
[ Info: iteration 42, average log likelihood -1.410754
[ Info: iteration 43, average log likelihood -1.410749
[ Info: iteration 44, average log likelihood -1.410743
[ Info: iteration 45, average log likelihood -1.410738
[ Info: iteration 46, average log likelihood -1.410733
[ Info: iteration 47, average log likelihood -1.410727
[ Info: iteration 48, average log likelihood -1.410722
[ Info: iteration 49, average log likelihood -1.410717
[ Info: iteration 50, average log likelihood -1.410712
┌ Info: EM with 100000 data points 50 iterations avll -1.410712
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4121732745010183
│     -1.4121144796055667
│      ⋮                 
└     -1.4107122541844737
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410715
[ Info: iteration 2, average log likelihood -1.410658
[ Info: iteration 3, average log likelihood -1.410603
[ Info: iteration 4, average log likelihood -1.410537
[ Info: iteration 5, average log likelihood -1.410455
[ Info: iteration 6, average log likelihood -1.410354
[ Info: iteration 7, average log likelihood -1.410236
[ Info: iteration 8, average log likelihood -1.410107
[ Info: iteration 9, average log likelihood -1.409975
[ Info: iteration 10, average log likelihood -1.409850
[ Info: iteration 11, average log likelihood -1.409735
[ Info: iteration 12, average log likelihood -1.409634
[ Info: iteration 13, average log likelihood -1.409547
[ Info: iteration 14, average log likelihood -1.409471
[ Info: iteration 15, average log likelihood -1.409406
[ Info: iteration 16, average log likelihood -1.409349
[ Info: iteration 17, average log likelihood -1.409300
[ Info: iteration 18, average log likelihood -1.409258
[ Info: iteration 19, average log likelihood -1.409220
[ Info: iteration 20, average log likelihood -1.409187
[ Info: iteration 21, average log likelihood -1.409157
[ Info: iteration 22, average log likelihood -1.409130
[ Info: iteration 23, average log likelihood -1.409106
[ Info: iteration 24, average log likelihood -1.409084
[ Info: iteration 25, average log likelihood -1.409063
[ Info: iteration 26, average log likelihood -1.409044
[ Info: iteration 27, average log likelihood -1.409026
[ Info: iteration 28, average log likelihood -1.409010
[ Info: iteration 29, average log likelihood -1.408995
[ Info: iteration 30, average log likelihood -1.408980
[ Info: iteration 31, average log likelihood -1.408966
[ Info: iteration 32, average log likelihood -1.408953
[ Info: iteration 33, average log likelihood -1.408941
[ Info: iteration 34, average log likelihood -1.408929
[ Info: iteration 35, average log likelihood -1.408918
[ Info: iteration 36, average log likelihood -1.408907
[ Info: iteration 37, average log likelihood -1.408897
[ Info: iteration 38, average log likelihood -1.408886
[ Info: iteration 39, average log likelihood -1.408877
[ Info: iteration 40, average log likelihood -1.408867
[ Info: iteration 41, average log likelihood -1.408858
[ Info: iteration 42, average log likelihood -1.408849
[ Info: iteration 43, average log likelihood -1.408840
[ Info: iteration 44, average log likelihood -1.408831
[ Info: iteration 45, average log likelihood -1.408823
[ Info: iteration 46, average log likelihood -1.408815
[ Info: iteration 47, average log likelihood -1.408806
[ Info: iteration 48, average log likelihood -1.408798
[ Info: iteration 49, average log likelihood -1.408791
[ Info: iteration 50, average log likelihood -1.408783
┌ Info: EM with 100000 data points 50 iterations avll -1.408783
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107149977089324
│     -1.4106583655023055
│      ⋮                 
└     -1.4087830161825632
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408784
[ Info: iteration 2, average log likelihood -1.408712
[ Info: iteration 3, average log likelihood -1.408641
[ Info: iteration 4, average log likelihood -1.408553
[ Info: iteration 5, average log likelihood -1.408440
[ Info: iteration 6, average log likelihood -1.408297
[ Info: iteration 7, average log likelihood -1.408128
[ Info: iteration 8, average log likelihood -1.407944
[ Info: iteration 9, average log likelihood -1.407760
[ Info: iteration 10, average log likelihood -1.407586
[ Info: iteration 11, average log likelihood -1.407428
[ Info: iteration 12, average log likelihood -1.407285
[ Info: iteration 13, average log likelihood -1.407158
[ Info: iteration 14, average log likelihood -1.407046
[ Info: iteration 15, average log likelihood -1.406948
[ Info: iteration 16, average log likelihood -1.406861
[ Info: iteration 17, average log likelihood -1.406784
[ Info: iteration 18, average log likelihood -1.406716
[ Info: iteration 19, average log likelihood -1.406655
[ Info: iteration 20, average log likelihood -1.406601
[ Info: iteration 21, average log likelihood -1.406551
[ Info: iteration 22, average log likelihood -1.406506
[ Info: iteration 23, average log likelihood -1.406464
[ Info: iteration 24, average log likelihood -1.406425
[ Info: iteration 25, average log likelihood -1.406388
[ Info: iteration 26, average log likelihood -1.406353
[ Info: iteration 27, average log likelihood -1.406321
[ Info: iteration 28, average log likelihood -1.406289
[ Info: iteration 29, average log likelihood -1.406260
[ Info: iteration 30, average log likelihood -1.406231
[ Info: iteration 31, average log likelihood -1.406204
[ Info: iteration 32, average log likelihood -1.406178
[ Info: iteration 33, average log likelihood -1.406153
[ Info: iteration 34, average log likelihood -1.406128
[ Info: iteration 35, average log likelihood -1.406105
[ Info: iteration 36, average log likelihood -1.406082
[ Info: iteration 37, average log likelihood -1.406060
[ Info: iteration 38, average log likelihood -1.406038
[ Info: iteration 39, average log likelihood -1.406017
[ Info: iteration 40, average log likelihood -1.405996
[ Info: iteration 41, average log likelihood -1.405976
[ Info: iteration 42, average log likelihood -1.405957
[ Info: iteration 43, average log likelihood -1.405938
[ Info: iteration 44, average log likelihood -1.405919
[ Info: iteration 45, average log likelihood -1.405902
[ Info: iteration 46, average log likelihood -1.405885
[ Info: iteration 47, average log likelihood -1.405869
[ Info: iteration 48, average log likelihood -1.405854
[ Info: iteration 49, average log likelihood -1.405839
[ Info: iteration 50, average log likelihood -1.405825
┌ Info: EM with 100000 data points 50 iterations avll -1.405825
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4087835586746593
│     -1.4087122619591348
│      ⋮                 
└     -1.405825117076962 
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4191423180890121
│     -1.4191602161820498
│     -1.4190922134748867
│     -1.4190369277142512
│      ⋮                 
│     -1.405853505081129 
│     -1.405838929261485 
└     -1.405825117076962 
32×26 Array{Float64,2}:
 -0.00155308  -0.410299   -0.661526   -0.144252     0.0465067    0.295679   -0.0797308   -0.189554   -0.0559643    0.00929009  -0.45385       0.0460809    -0.0406005   -0.200291    0.320836    0.220936    -0.302785   -0.421137     0.316414     0.339572     0.19464    -0.382303   -0.144069    0.158127    -0.331002    -0.309092  
 -0.0517163   -0.146495    0.155545   -0.524703     0.0703505    0.134098    0.132269    -0.155476    0.352381     0.0356461   -0.164239     -0.085767     -0.0643155    0.168327   -0.0966659  -0.34487     -0.0810879  -0.0248728    0.347585     0.373667    -0.107999   -0.604407   -0.060449   -0.0308955    0.212132     0.0632822 
  0.0824148   -0.103693   -0.0212414  -0.0180132   -0.267366     0.0833586   0.00438724   0.0255868  -0.0329589   -0.0326791    0.129541      0.10767       0.287225     0.0312693   0.0504806   0.146366    -0.0542265  -0.0247357    0.102769    -0.204149     0.120649    0.0451762   0.0128533  -0.0573064    0.0314826    0.070247  
 -0.0329025    0.0925191   0.0111341   0.163818     0.194167    -0.0241169  -0.131776     0.0617851   0.0108433    0.110765     0.000819527  -0.0280657    -0.197211     0.0890138  -0.103252   -0.0342138   -0.0537909   0.028844    -0.0709025    0.0789005   -0.109228    0.0285722   0.0552844   0.0377994    0.00519333  -0.212563  
 -0.242916     0.439287    0.199535    0.158528    -0.0455011   -0.304863    0.0227606    0.212958    0.0481992    0.090711     0.334179      0.0593157     0.0257196   -0.636538   -0.0157338   0.661365    -0.236319    0.17959      0.212815     0.412912    -0.257198    0.543451    0.369079    0.149847     0.207027     0.51797   
  0.31443      0.204691    0.310832    0.00624485  -0.373724    -0.0686928  -0.201629    -0.160781    0.383254    -0.377389     0.427295      0.305466     -0.574902     0.0769446   0.327645    0.257633    -0.145739    0.192787     0.336242     0.462313     0.872281   -0.0302878   0.269594   -0.238617     0.0582952    0.203765  
  0.188744     0.0301486  -0.176224   -0.417047     0.522465    -0.145674   -0.117744    -0.0185263  -0.0787211    0.380174    -0.0907827     0.174937     -0.144372     0.419131    0.270755    0.284908    -0.618342   -0.117637     0.311253    -0.174025    -0.0972956   0.118653   -0.302435   -0.337864     0.767215     0.354184  
 -0.101482     0.208326    0.265695    0.0556427    0.408581    -0.164764   -0.366296     0.166657    0.67063      0.51254      0.170822     -0.174566     -0.112152    -0.228888    0.924711    0.582829    -0.134163   -0.421462    -0.343747    -0.226746     0.397502    0.387059   -0.196783   -0.181913    -0.317641     0.0662699 
  0.365058     0.0258416   0.909115    0.289212    -0.529341     0.0550107  -0.122865    -0.503438   -0.302748     0.074091    -0.228816     -0.367543     -0.44125     -0.921222    0.534252   -0.401838     0.412795   -0.588109     0.00281141   0.380159     0.0622733  -0.0105237   0.385386    0.319674    -0.314414    -0.192769  
  0.499456     0.112223    0.559238    0.501588    -0.547901     0.453083   -0.406074     0.0258702  -0.00333038  -0.112144    -0.297178     -0.221312      0.0549105    0.281293    0.378196   -0.213384    -0.0784556   0.213387    -0.0894541   -0.123821    -0.201313   -0.14225     0.407255    0.616071    -0.133179    -0.162341  
  0.283311     0.218863    0.0675561   0.0574509    0.118698    -0.411718   -0.19185      0.36043    -0.249046    -0.0236884    0.0521026    -0.634503     -0.129989     0.0708198  -0.250052   -0.309062     0.510006    0.416992    -0.273169    -0.644077    -0.0935585  -0.245428    0.051126   -0.683162     0.0298812    0.359313  
  0.00753064  -0.171872    0.120594   -0.15443     -0.268197    -0.0666923  -0.43174      0.122636   -0.161625    -0.0331595    0.904858     -0.322755      0.492378    -0.0551795  -0.693125   -0.304672     0.301828    0.00664666  -0.0962658   -0.00724064   0.117917    0.014073    0.135485    0.0759361    0.225795    -0.130978  
 -0.441785    -0.276004   -0.113706    0.0928964    0.136016    -0.0444637   0.310931    -0.124465   -0.214672     0.0943439   -0.682817     -0.000308272   0.134341    -0.558187   -0.161344   -0.316747    -0.0353996  -0.0300013   -0.208354    -0.256311    -0.135398    0.369635    0.26449     0.0995583   -0.239267     0.283835  
 -0.367462    -0.174055    0.0268918  -0.0515542   -0.00452631   0.291372    0.528657     0.258685    0.0251375    0.102245     0.208548     -0.0695053    -0.343757    -0.304797   -0.159002    0.195785     0.289579    0.0322469   -0.483229     0.0954693    0.130266    0.395952   -0.0571578   0.33803     -0.248589    -0.430217  
 -0.186863     0.731667    0.060916    0.0898778    0.124432    -0.0352128   0.282458    -0.233952   -0.472944     0.0460325   -0.0196817    -0.185978     -0.447018     0.379632    0.104484   -0.244117     0.159241    0.293381    -0.525674     0.00853246   0.389228    0.612895    0.094127    0.172376    -0.173635     0.295652  
  0.261852     0.640033   -0.129395   -0.144001     0.0343289    0.537181    0.499111    -0.199961   -0.774873     0.359338     0.187432     -0.0908861    -0.104623     0.119045    0.315721    0.275964     0.520012    0.441649     0.709272     0.191176    -0.143876    0.156513   -0.119197    0.0868824   -0.383646     0.0706647 
 -0.0018606   -0.228711   -0.614934   -0.746759    -0.0822205   -0.0844258  -0.148551    -0.666254    0.352061    -0.205769     0.416702      0.104987      0.699836     0.618781    0.290479    0.305476     0.145465   -0.456634    -0.259313    -0.430904     0.285312   -0.679614   -0.0472054  -0.27007     -0.249382     0.276704  
  0.279868     0.14492    -0.637777    0.522658    -0.238573    -0.282242   -0.534359    -0.68107     0.0297611    0.00836053   0.260028     -0.204439      0.393972     0.0870549   0.109936    0.26582      0.01416    -0.0716561    0.323857     0.0678493   -0.0262329  -0.651482    0.218497   -0.57616     -0.205757    -0.00154216
 -0.0333699   -0.354886    0.353894    0.176387     0.434927    -0.975747    0.103942    -0.877117    0.0642376    0.213547     0.16148       0.148225      0.1394       0.248119    0.397106   -0.0496907    0.489422   -0.766019     0.784411    -0.243979    -0.254732   -0.337702   -0.657945   -0.126165     0.276617    -0.10503   
  0.511148     0.0837857   0.646543   -0.0418309   -0.731248     0.18859    -0.409719    -0.378643    0.667689     0.846733     0.476172      0.498081      0.710577     0.0781794  -0.180726    0.00903393  -0.284635   -0.636661     0.541089     0.453857    -0.173637   -0.394244   -0.419209    0.660248    -0.378937    -0.229136  
 -0.285039    -0.414582   -0.314331   -0.246252     0.276326     0.219093   -0.0208318   -0.06751     0.303895     0.0388992   -0.381838     -0.248095     -0.00529052   0.509919   -0.234382   -1.0255       0.0686726  -0.418024    -0.282924    -0.127424     0.0416517  -0.855717   -0.110969    0.0533289    0.134991    -0.840561  
 -0.00283034   0.0414124   0.51173    -0.112437     0.098112     0.0159128  -0.0357482    0.192186   -0.34883     -0.195431    -0.501434      0.0251949    -0.59943      0.601105   -0.320078   -0.929907    -0.267167   -0.367479    -0.273482    -0.0104688   -0.0278123   0.0809557  -0.194913    0.184983     0.47837      0.461893  
 -0.994492    -0.433434   -0.410449   -0.0713372    0.175534    -0.370006    0.153493     0.198118    0.195232    -0.549094    -0.169092      0.496461      0.752686     0.43953    -0.068748    0.330071    -0.523275   -0.571975     0.18257     -0.271388    -0.323761   -0.404491    0.410761    0.315598     0.515775    -0.247182  
  0.320879    -0.948574   -0.0785612  -0.0209458   -0.211306     0.151725   -0.414155     0.671425    0.378821    -0.24575      0.0928254     0.140984      0.275703     0.104485   -0.24937     0.27296     -0.453038   -0.257598     0.0510252   -0.390869     0.120741   -0.453531    0.0705637  -0.327836     0.607027    -0.312344  
  0.17618      0.472174   -0.905208    0.00166473  -0.00361339  -0.0640312  -0.46013     -0.122411   -0.374032     0.405321     0.223711     -0.973416     -0.283643    -0.0990075  -0.46957     0.252283     0.148662    0.246821    -0.997873    -0.407874    -0.615361    0.782002   -0.257414   -0.0705852    0.0571946    0.02646   
  0.191718     0.480166    0.115171    0.393972    -0.240722    -0.0321576  -0.282246     0.53036     0.14018      0.106853     0.593222      0.328226      0.727334     0.745004   -0.191273   -0.244465    -0.460055    0.68768     -0.323635    -0.478982    -0.613413    0.523079    0.10453    -0.180999     0.580937     0.060856  
  0.0496753    0.472182    0.25769     0.460456    -0.376582    -0.215112   -0.347398    -0.514371    0.0460851   -0.0518761    0.693457     -0.220704     -0.16466      0.0491518  -0.0284743   0.0849137    0.449564   -0.0310125   -0.0502058    0.156217     0.469784    0.0788203   0.477888   -0.37207     -0.00538812  -0.150936  
 -0.0606656    0.260208    0.135615    0.0745752   -0.281541     0.26288    -0.255703     0.742233    0.0165763   -0.226001     0.116459     -0.320259     -0.196818    -0.417778   -0.486146   -0.254889    -0.0679933   1.07829     -0.446572     0.391011     0.204834    0.336008    0.506907    0.499236    -0.136278     0.0682326 
 -0.0474485   -0.292532   -0.634569   -0.195364     0.283536    -0.0538959   0.0489025   -0.018461   -0.140516     0.0119816   -0.329731     -0.147584      0.081274    -0.26635     0.153862    0.354954     0.0565819   0.00421066   0.34446      0.0345353    0.02451    -0.341748   -0.0959028  -0.0775821   -0.204159     0.309622  
 -0.373802     0.161254    0.460693   -0.149663     0.271467     0.14337     0.515451     0.236934    0.343513     0.349064    -0.333175      0.32275      -0.267837    -0.320625    0.256671    0.215132    -0.292671   -0.263188    -0.152747     0.123482    -0.154771    0.874514   -0.155027    0.386327     0.111861    -0.116168  
  0.210182    -0.384727   -0.347426   -0.0906082   -0.65585      0.576839    0.449307    -0.267081   -1.0751      -0.451921    -0.470236      0.508951      0.213029    -0.131885   -1.00039    -0.205736     0.0941782   0.523531     0.0150787   -0.377141     0.0117665  -0.15565     0.263513   -0.00227044  -0.38266     -0.0357335 
 -0.105056    -0.212739   -0.549298    0.359921     0.775551     0.151379    0.238165     0.576556    0.0144313    0.119075    -0.397848      0.56096      -0.346649     0.122516   -0.363424    0.476971    -0.269292    0.287551     0.102401    -0.163158    -0.114218    0.166141   -0.275972   -0.0227024   -0.462312    -0.183927  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405812
[ Info: iteration 2, average log likelihood -1.405800
[ Info: iteration 3, average log likelihood -1.405788
[ Info: iteration 4, average log likelihood -1.405777
[ Info: iteration 5, average log likelihood -1.405766
[ Info: iteration 6, average log likelihood -1.405756
[ Info: iteration 7, average log likelihood -1.405747
[ Info: iteration 8, average log likelihood -1.405738
[ Info: iteration 9, average log likelihood -1.405729
[ Info: iteration 10, average log likelihood -1.405721
┌ Info: EM with 100000 data points 10 iterations avll -1.405721
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.482146e+05
      1       7.008175e+05      -2.473971e+05 |       32
      2       6.862709e+05      -1.454656e+04 |       32
      3       6.810851e+05      -5.185799e+03 |       32
      4       6.783688e+05      -2.716393e+03 |       32
      5       6.767180e+05      -1.650786e+03 |       32
      6       6.755405e+05      -1.177504e+03 |       32
      7       6.746080e+05      -9.324489e+02 |       32
      8       6.738555e+05      -7.524708e+02 |       32
      9       6.732289e+05      -6.266890e+02 |       32
     10       6.727219e+05      -5.069049e+02 |       32
     11       6.722779e+05      -4.440480e+02 |       32
     12       6.718658e+05      -4.120994e+02 |       32
     13       6.714994e+05      -3.664172e+02 |       32
     14       6.711680e+05      -3.313739e+02 |       32
     15       6.708552e+05      -3.128303e+02 |       32
     16       6.705556e+05      -2.995786e+02 |       32
     17       6.702984e+05      -2.572364e+02 |       32
     18       6.700658e+05      -2.326003e+02 |       32
     19       6.698501e+05      -2.156824e+02 |       32
     20       6.696572e+05      -1.928925e+02 |       32
     21       6.694761e+05      -1.810855e+02 |       32
     22       6.693048e+05      -1.713122e+02 |       32
     23       6.691288e+05      -1.759728e+02 |       32
     24       6.689657e+05      -1.631314e+02 |       32
     25       6.688306e+05      -1.350851e+02 |       32
     26       6.687140e+05      -1.166489e+02 |       32
     27       6.686059e+05      -1.080540e+02 |       32
     28       6.685042e+05      -1.017142e+02 |       32
     29       6.684156e+05      -8.859181e+01 |       32
     30       6.683283e+05      -8.732502e+01 |       32
     31       6.682406e+05      -8.763206e+01 |       32
     32       6.681664e+05      -7.420766e+01 |       32
     33       6.681068e+05      -5.960697e+01 |       32
     34       6.680579e+05      -4.894455e+01 |       32
     35       6.680151e+05      -4.279599e+01 |       32
     36       6.679833e+05      -3.180996e+01 |       32
     37       6.679547e+05      -2.859272e+01 |       32
     38       6.679266e+05      -2.811378e+01 |       32
     39       6.678938e+05      -3.271768e+01 |       32
     40       6.678641e+05      -2.977167e+01 |       32
     41       6.678337e+05      -3.034163e+01 |       32
     42       6.678075e+05      -2.625405e+01 |       32
     43       6.677856e+05      -2.192373e+01 |       32
     44       6.677608e+05      -2.471089e+01 |       32
     45       6.677364e+05      -2.443719e+01 |       32
     46       6.677132e+05      -2.320564e+01 |       32
     47       6.676864e+05      -2.680980e+01 |       32
     48       6.676606e+05      -2.583255e+01 |       32
     49       6.676338e+05      -2.671283e+01 |       32
     50       6.676019e+05      -3.197714e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667601.8692555436)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417711
[ Info: iteration 2, average log likelihood -1.412549
[ Info: iteration 3, average log likelihood -1.411005
[ Info: iteration 4, average log likelihood -1.409804
[ Info: iteration 5, average log likelihood -1.408701
[ Info: iteration 6, average log likelihood -1.407877
[ Info: iteration 7, average log likelihood -1.407390
[ Info: iteration 8, average log likelihood -1.407123
[ Info: iteration 9, average log likelihood -1.406961
[ Info: iteration 10, average log likelihood -1.406847
[ Info: iteration 11, average log likelihood -1.406758
[ Info: iteration 12, average log likelihood -1.406685
[ Info: iteration 13, average log likelihood -1.406622
[ Info: iteration 14, average log likelihood -1.406566
[ Info: iteration 15, average log likelihood -1.406517
[ Info: iteration 16, average log likelihood -1.406471
[ Info: iteration 17, average log likelihood -1.406430
[ Info: iteration 18, average log likelihood -1.406392
[ Info: iteration 19, average log likelihood -1.406357
[ Info: iteration 20, average log likelihood -1.406324
[ Info: iteration 21, average log likelihood -1.406293
[ Info: iteration 22, average log likelihood -1.406263
[ Info: iteration 23, average log likelihood -1.406235
[ Info: iteration 24, average log likelihood -1.406209
[ Info: iteration 25, average log likelihood -1.406184
[ Info: iteration 26, average log likelihood -1.406161
[ Info: iteration 27, average log likelihood -1.406138
[ Info: iteration 28, average log likelihood -1.406116
[ Info: iteration 29, average log likelihood -1.406096
[ Info: iteration 30, average log likelihood -1.406076
[ Info: iteration 31, average log likelihood -1.406057
[ Info: iteration 32, average log likelihood -1.406038
[ Info: iteration 33, average log likelihood -1.406021
[ Info: iteration 34, average log likelihood -1.406004
[ Info: iteration 35, average log likelihood -1.405988
[ Info: iteration 36, average log likelihood -1.405972
[ Info: iteration 37, average log likelihood -1.405957
[ Info: iteration 38, average log likelihood -1.405942
[ Info: iteration 39, average log likelihood -1.405928
[ Info: iteration 40, average log likelihood -1.405914
[ Info: iteration 41, average log likelihood -1.405901
[ Info: iteration 42, average log likelihood -1.405888
[ Info: iteration 43, average log likelihood -1.405875
[ Info: iteration 44, average log likelihood -1.405863
[ Info: iteration 45, average log likelihood -1.405851
[ Info: iteration 46, average log likelihood -1.405840
[ Info: iteration 47, average log likelihood -1.405828
[ Info: iteration 48, average log likelihood -1.405818
[ Info: iteration 49, average log likelihood -1.405807
[ Info: iteration 50, average log likelihood -1.405797
┌ Info: EM with 100000 data points 50 iterations avll -1.405797
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0992511    0.185914     0.100661    -0.20434      0.485319    -0.122997     0.0636834   -0.27141     -0.530226    0.488774    -0.431039     0.217469   -0.370073      0.811211    0.234461    -0.287378   -0.561413     -0.258829     0.268524   -0.259621    -0.744425     0.18119    -0.325107    -0.547128     0.304459      0.0935753
 -0.282948     0.360186    -0.407583    -0.158273     0.078852     0.288114     0.708718    -0.188045    -1.11788    -0.00506285  -0.0698051   -0.317729   -0.55938       0.113751   -0.0118552    0.133904    0.507599      0.295354     0.123483    0.0474691    0.0593663    0.189237   -0.0107074   -0.0856233   -0.25263       0.113591 
  0.13349     -0.43975     -0.434617    -0.223347     0.398965     0.277295     0.394678    -0.114843    -0.335047    0.0389515   -0.610086     0.250299   -0.708921     -0.511714   -0.0493262    0.444048   -0.225407     -0.109754     0.730073    0.211342     0.293925    -0.175983   -0.544266     0.289031    -0.330666      0.015758 
  0.102222     0.751846    -0.176374     0.458098    -0.732377    -0.160634    -0.711785    -0.648281     0.0667831   0.0328465    0.798047    -0.437338    0.2865        0.233543   -0.146365     0.0784032   0.440482      0.137288    -0.351924   -0.0980321    0.00195323   0.12055     0.477598    -0.50008     -0.0444484    -0.285546 
  0.113959    -0.274786    -0.237921    -0.0583948   -0.120715    -0.135864    -0.340874    -0.143706     0.111931   -0.0613691    0.406114     0.0116118   0.410042      0.122866    0.00210315   0.240619    0.016997     -0.28536      0.272356   -0.11164      0.0278194   -0.312075   -0.150272    -0.229626     0.135417     -0.185481 
 -0.455329    -0.329708    -0.0819032    0.182039    -0.0150824    0.0501637    0.251154    -0.163513    -0.226271    0.116545    -0.706352     0.0289169   0.157964     -0.533663   -0.142646    -0.2314     -0.161222     -0.0356041   -0.0777326  -0.179014    -0.264884     0.286702    0.191409     0.208545    -0.314796      0.0213211
 -0.0555734    0.507945     0.630089     0.558589    -0.376906    -0.483661    -0.067789    -0.303542    -0.258671   -0.0710059    0.112068    -0.419445   -0.712009     -1.0966      0.158216     0.332566    0.0905268    -0.155605     0.176412    0.871166    -0.193082     0.642869    0.476839     0.222496     0.131956      0.318534 
 -0.150995    -0.441049    -0.222028     0.271291    -0.00927085  -0.168257    -0.182333     0.214786     0.591193   -0.388004     0.223667    -0.32781    -0.0240069    -1.08354    -0.175541     0.544952    0.924901     -0.201105     0.241769    0.411762     1.13616     -0.415159    0.413246     0.286831    -0.590637     -0.131596 
 -0.0936013    0.412102     0.0483267   -0.141061     0.18135     -0.355011    -0.187149    -0.432588     0.740175    0.436942     0.322326    -0.109784   -0.268853      0.0843223   0.704264     0.483024   -0.347968     -0.192187     0.187985    0.374867     0.267286    -0.180543   -0.00941831  -0.181836     0.0623109     0.220499 
  0.141698    -1.14925      0.622209     0.661268    -0.128689    -0.291132    -0.232698    -0.273041    -0.130721    0.698583     0.666114     0.739546    0.643054     -0.341918   -0.608705    -0.438762    0.477978     -0.93911      0.758611    0.204743    -0.0555692   -0.044818   -0.350087    -0.247097     0.184068     -0.328031 
 -0.227647    -0.291494     0.0294023    0.1711      -0.0950711   -0.119942    -0.0292652   -0.022168     0.0488229  -0.516384    -0.0955839   -0.0176081   0.0215758     0.506286   -0.821643    -0.883393   -0.0882593    -0.654699    -0.0869455  -0.0135794    0.018265    -0.715296    0.283585     0.129789     0.479269     -0.377912 
  0.166132    -0.298846    -0.117886    -0.203769    -0.028536    -0.251194    -0.270795    -0.298543     0.486705    0.0442922    0.10371      0.0674288   0.457911      0.330061    0.370397     0.119457    0.0700594    -0.440774     0.230549   -0.251001     0.0382605   -0.631422   -0.237375     0.0130193    0.0817767    -0.0606895
 -0.497968    -0.457513    -0.788962    -0.347397     0.0726303    0.211345     0.170953    -0.134234     0.244842   -0.414679    -0.34704      0.515805    0.661813      0.471539    0.629863     0.314484   -0.396726     -0.925893     0.0867659  -0.130468    -0.00874623  -0.712073    0.134865     0.165165     0.0971673    -0.307821 
  0.0314866    0.817634     0.881337     0.127098     0.200961     0.223921    -0.151979    -0.357899    -0.212843    0.233937     0.0600684   -0.0501119  -0.410594      0.614358   -0.0865154   -0.718568    0.0437862     0.161375    -0.109734    0.400291     0.298766     0.410005   -0.422083     0.535685    -0.0101697     0.493009 
  0.0646321    0.212825     0.349916     0.202934    -0.154768    -0.0217403   -0.193753     0.355821     0.150855   -0.0681254    0.355854     0.0257106   0.255965      0.0277     -0.00667191   0.0547608  -0.149459      0.253044    -0.156038   -0.138717    -0.135463     0.330178    0.261373     0.111183     0.238473      0.239812 
  0.0272144    0.00524484  -0.0697763   -0.0579073    0.0755195    0.0845917   -0.00599221  -0.0545627   -0.023145    0.0475851   -0.168372     0.01245    -0.164479      0.0645281  -0.0251573   -0.0941468  -0.0518694     0.00754954   0.0916804   0.101653     0.0483612   -0.149207    0.03713     -0.00161543  -0.0463979    -0.0356617
  0.00115209   0.21001     -0.00530083  -0.0369144   -0.279358     0.438086    -0.360654     0.952457    -0.184521   -0.142256     0.128133    -0.269415   -0.092678     -0.113718   -0.634683    -0.309598   -0.282632      1.06442     -0.493429    0.213699    -0.0967082    0.354171    0.456367     0.43279      0.000233453   0.0107606
 -0.277792     0.240758    -0.054855     0.0414689    0.00763561   0.0699657    0.317524     7.22179e-5  -0.328222    0.0892363    0.205557    -0.17051    -0.354283     -0.0490691  -0.0725837    0.123239    0.281326      0.168267    -0.436407    0.0160212    0.249235     0.524015    0.0637642    0.18921     -0.199158     -0.150602 
  0.398567     0.145137     0.355275     0.267502    -0.237102     0.144392    -0.161634    -0.141288     0.0688353  -0.464973     0.109595     0.321091   -0.885548      0.189287    0.343701     0.142194    0.0109287     0.239756     0.277456    0.0814495    1.10151      0.11292     0.475979    -0.394405    -0.0309182     0.125094 
  0.464271     0.0697397    0.596294     0.147567    -0.4746       0.483036    -0.128338    -0.389993    -0.167514    0.061514    -0.0694869   -0.279437   -0.000705453  -0.0636216   0.551391    -0.498956    0.519924     -0.103522     0.104378   -0.00268792   0.0517266   -0.295646    0.232957     0.391969    -0.347831     -0.181171 
 -0.143859     0.0276401   -0.20071      0.258709     0.68823     -0.123695    -0.065624     0.763372     0.206331   -0.0181818    0.269601     0.563274   -0.0682706     0.473497   -0.102907     0.752032   -0.302077     -0.218663    -0.0764145  -0.399263     0.219658     0.400165   -0.389528    -0.42726      0.0738042    -0.296135 
  0.575203    -0.941758    -0.32759      0.159654    -0.410324     0.377884    -0.0753633    0.356505    -0.503768   -0.495199    -0.249841     0.371852    0.452033      0.0308545  -0.534106     0.0767401   0.133296      0.181843    -0.330308   -1.20638     -0.0911526   -0.236143    0.357882    -0.36394     -0.194033     -0.110678 
 -0.328804     0.0834963    0.274303     0.0695217    0.373212    -0.00867949   0.169146     0.362889     0.424587    0.425732    -0.00192619   0.0227712  -0.126632     -0.623091    0.267043     0.327028   -0.273817     -0.188542    -0.572521   -0.187195    -0.166235     0.96898    -0.0230831    0.0902463   -0.00102356   -0.0547798
  0.260597    -0.369702    -0.784886    -0.0952949    0.0765777    0.0703623   -0.638359    -0.35149     -0.113742    0.111362    -0.0966623   -0.609388    0.167196      0.0807374  -0.10274     -0.210665   -0.296307     -0.0718386   -0.115064   -0.107436     0.280255    -0.894995    0.103077    -0.782206    -0.107432      0.0781161
  0.231092     0.295131     0.170889     0.00186202   0.0951432   -0.514748    -0.230755     0.405507    -0.314752    0.0358569    0.242779    -0.707727   -0.090926      0.0926832  -0.343362    -0.291763    0.513167      0.460904    -0.299372   -0.570064    -0.118285    -0.0819736  -0.0437748   -0.513922     0.16097       0.361765 
 -0.115343     0.0870812   -0.450069    -0.0619871   -0.0406351   -0.475431    -0.196881    -0.35485     -0.354853   -0.406579    -0.148851     0.358604    0.715683      0.192429   -0.235518     0.375441   -0.458516      0.403243     0.660468   -0.014024    -0.115235    -0.0805144   0.244643    -0.121129     0.255067      1.07647  
 -0.230811    -0.676107     0.161051    -0.886131     0.19796      0.265589     0.0101187    0.464846     0.466347    0.147527    -0.402725    -0.29686    -0.23671       0.301653   -0.256468    -0.274399   -0.393489     -0.333178    -0.135562    0.0494673    0.0924739   -0.0286237  -0.351282     0.237895     0.592248     -0.0977452
 -0.0813346    0.101398     0.00922234  -0.668825    -0.53845      0.151537     0.433789     0.00462396   0.02113    -0.207983     0.596982     0.121664    0.491256     -0.55765    -0.497788    -0.220859   -0.000509912   0.15096      0.0692941   0.15577      0.906865     0.347652    0.235337    -0.0196797   -0.0957277     0.343474 
  0.378824     0.248508    -0.617718    -0.0535085    0.175502     0.192421     0.200074     0.00214717  -0.429367    0.659892     0.162045    -0.300992    0.447767     -0.385439    0.262143     0.651477    0.36674       0.116162     0.200464    0.221323    -0.454568     0.162269   -0.191032     0.101376    -0.361746      0.309805 
 -0.295872     0.0723298   -0.0971119    0.234541     0.513391    -0.0912206    0.341879     0.400103    -0.0952834  -0.242841    -1.15337      0.200047   -0.565211      0.197678    0.345595    -0.091584    0.0634178     0.196745    -0.508147   -0.236071    -0.0297249    0.310834    0.179543     0.535739    -0.102948      0.070494 
  0.411805    -0.0424788    0.214512     0.333047    -0.506049     0.271373    -0.349109     0.340242     0.318414    0.147652     0.0690836    0.271277    0.115385     -0.0350063   0.112743     0.300452   -0.723766     -0.0365589    0.288618    0.33348     -0.256296    -0.174636    0.0516508    0.418796     0.131201     -0.526377 
 -0.444393    -0.107707    -0.420474    -0.309911     0.200517     0.138202     0.615291    -0.228181     0.373847    0.278702     0.273104     0.350225    0.354364     -0.0318734  -0.595062    -0.191409    0.393734      0.512731    -0.170592    0.240514    -0.691231    -0.404779    0.0831483   -0.127578    -0.188776     -0.237061 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405787
[ Info: iteration 2, average log likelihood -1.405777
[ Info: iteration 3, average log likelihood -1.405768
[ Info: iteration 4, average log likelihood -1.405759
[ Info: iteration 5, average log likelihood -1.405750
[ Info: iteration 6, average log likelihood -1.405741
[ Info: iteration 7, average log likelihood -1.405733
[ Info: iteration 8, average log likelihood -1.405724
[ Info: iteration 9, average log likelihood -1.405716
[ Info: iteration 10, average log likelihood -1.405709
┌ Info: EM with 100000 data points 10 iterations avll -1.405709
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
