Julia Version 1.4.0-rc1.21
Commit 113211dee6 (2020-02-06 08:37 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed DataAPI ──────────── v1.1.0
  Installed GaussianMixtures ─── v0.3.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed NearestNeighbors ─── v0.4.4
  Installed SpecialFunctions ─── v0.9.0
  Installed QuadGK ───────────── v2.3.1
  Installed URIParser ────────── v0.4.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed Blosc ────────────── v0.5.1
  Installed Parameters ───────── v0.12.0
  Installed LegacyStrings ────── v0.4.1
  Installed CMake ────────────── v1.1.2
  Installed Compat ───────────── v2.2.0
  Installed Clustering ───────── v0.13.3
  Installed Arpack_jll ───────── v3.5.0+2
  Installed FillArrays ───────── v0.8.4
  Installed PDMats ───────────── v0.9.11
  Installed Missings ─────────── v0.4.3
  Installed OrderedCollections ─ v1.1.0
  Installed BinDeps ──────────── v1.0.0
  Installed StatsFuns ────────── v0.9.3
  Installed StaticArrays ─────── v0.12.1
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed Distributions ────── v0.22.4
  Installed Rmath ────────────── v0.6.0
  Installed SortingAlgorithms ── v0.3.1
  Installed HDF5 ─────────────── v0.12.5
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Distances ────────── v0.8.2
  Installed DataStructures ───── v0.17.9
  Installed FileIO ───────────── v1.2.1
#=#=#                                                                         ##O#- #                                                                       ######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ################################################################          89.8%######################################################################## 100.0%
#=#=#                                                                                                                                                    0.1%#################                                                         24.9%###########################################################               83.0%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_Dvo4D8/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.1618325569233755e7, [46689.30337512948, 53310.69662487052], [26792.854166703015 11002.053068012208 26343.05429120467; -26902.005995883366 -11462.149002104843 -26302.864484699836], [[48657.14251373224 1010.1459595420689 2075.581376898242; 1010.145959542069 48087.27909349725 2035.3012643453203; 2075.581376898242 2035.3012643453203 47132.2465778372], [50946.91711593487 -571.9520918427829 -2237.614960375574; -571.9520918427829 52434.99754358507 -1358.172709150011; -2237.614960375574 -1358.172709150011 52879.45110014004]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.896805e+03
      1       1.476955e+03      -4.198494e+02 |        8
      2       1.188494e+03      -2.884608e+02 |        5
      3       1.005419e+03      -1.830749e+02 |        5
      4       9.739427e+02      -3.147670e+01 |        4
      5       9.427486e+02      -3.119403e+01 |        0
      6       9.427486e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 942.7486358108254)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075177
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.730440
[ Info: iteration 2, lowerbound -3.597565
[ Info: iteration 3, lowerbound -3.472374
[ Info: iteration 4, lowerbound -3.339289
[ Info: iteration 5, lowerbound -3.204934
[ Info: iteration 6, lowerbound -3.081454
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.974958
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.882434
[ Info: iteration 9, lowerbound -2.819369
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.786784
[ Info: iteration 11, lowerbound -2.770115
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.754163
[ Info: iteration 13, lowerbound -2.731528
[ Info: iteration 14, lowerbound -2.702144
[ Info: iteration 15, lowerbound -2.659150
[ Info: iteration 16, lowerbound -2.601658
[ Info: iteration 17, lowerbound -2.534269
[ Info: iteration 18, lowerbound -2.467313
[ Info: iteration 19, lowerbound -2.410667
[ Info: iteration 20, lowerbound -2.367356
[ Info: iteration 21, lowerbound -2.335528
[ Info: iteration 22, lowerbound -2.314743
[ Info: iteration 23, lowerbound -2.307397
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302946
[ Info: iteration 25, lowerbound -2.299261
[ Info: iteration 26, lowerbound -2.299257
[ Info: iteration 27, lowerbound -2.299255
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb  6 13:42:25 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb  6 13:42:33 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Thu Feb  6 13:42:36 2020: EM with 272 data points 0 iterations avll -2.075177
5.8 data points per parameter
, Thu Feb  6 13:42:37 2020: GMM converted to Variational GMM
, Thu Feb  6 13:42:46 2020: iteration 1, lowerbound -3.730440
, Thu Feb  6 13:42:46 2020: iteration 2, lowerbound -3.597565
, Thu Feb  6 13:42:46 2020: iteration 3, lowerbound -3.472374
, Thu Feb  6 13:42:46 2020: iteration 4, lowerbound -3.339289
, Thu Feb  6 13:42:46 2020: iteration 5, lowerbound -3.204934
, Thu Feb  6 13:42:46 2020: iteration 6, lowerbound -3.081454
, Thu Feb  6 13:42:46 2020: dropping number of Gaussions to 7
, Thu Feb  6 13:42:46 2020: iteration 7, lowerbound -2.974958
, Thu Feb  6 13:42:46 2020: dropping number of Gaussions to 5
, Thu Feb  6 13:42:46 2020: iteration 8, lowerbound -2.882434
, Thu Feb  6 13:42:46 2020: iteration 9, lowerbound -2.819369
, Thu Feb  6 13:42:46 2020: dropping number of Gaussions to 4
, Thu Feb  6 13:42:46 2020: iteration 10, lowerbound -2.786784
, Thu Feb  6 13:42:46 2020: iteration 11, lowerbound -2.770115
, Thu Feb  6 13:42:46 2020: dropping number of Gaussions to 3
, Thu Feb  6 13:42:46 2020: iteration 12, lowerbound -2.754163
, Thu Feb  6 13:42:46 2020: iteration 13, lowerbound -2.731528
, Thu Feb  6 13:42:46 2020: iteration 14, lowerbound -2.702144
, Thu Feb  6 13:42:46 2020: iteration 15, lowerbound -2.659150
, Thu Feb  6 13:42:46 2020: iteration 16, lowerbound -2.601658
, Thu Feb  6 13:42:46 2020: iteration 17, lowerbound -2.534269
, Thu Feb  6 13:42:46 2020: iteration 18, lowerbound -2.467313
, Thu Feb  6 13:42:46 2020: iteration 19, lowerbound -2.410667
, Thu Feb  6 13:42:46 2020: iteration 20, lowerbound -2.367356
, Thu Feb  6 13:42:46 2020: iteration 21, lowerbound -2.335528
, Thu Feb  6 13:42:46 2020: iteration 22, lowerbound -2.314743
, Thu Feb  6 13:42:46 2020: iteration 23, lowerbound -2.307397
, Thu Feb  6 13:42:46 2020: dropping number of Gaussions to 2
, Thu Feb  6 13:42:46 2020: iteration 24, lowerbound -2.302946
, Thu Feb  6 13:42:46 2020: iteration 25, lowerbound -2.299261
, Thu Feb  6 13:42:46 2020: iteration 26, lowerbound -2.299257
, Thu Feb  6 13:42:46 2020: iteration 27, lowerbound -2.299255
, Thu Feb  6 13:42:46 2020: iteration 28, lowerbound -2.299254
, Thu Feb  6 13:42:46 2020: iteration 29, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 30, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 31, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 32, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 33, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 34, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 35, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 36, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 37, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 38, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 39, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 40, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 41, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 42, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 43, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 44, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 45, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 46, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 47, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 48, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 49, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: iteration 50, lowerbound -2.299253
, Thu Feb  6 13:42:46 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222603053, 95.95490777396942]
β = [178.04509222603053, 95.95490777396942]
m = [4.250300733269775 79.28686694435984; 2.0002292577752314 53.85198717246056]
ν = [180.04509222603053, 97.95490777396942]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547482748 -0.007644049042328947; 0.0 0.008581705166331005], [0.3758763611950776 -0.008953123827348562; 0.0 0.012748664777410004]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -1.0033310699403346
avll from llpg:  -1.003331069940335
avll direct:     -1.003331069940335
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.989843118762948
avll from llpg:  -0.989843118762948
avll direct:     -0.989843118762948
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.099766      0.0556239    0.0856115    0.00926712   -0.0457942     0.00735976   0.0370641   -0.11057     -0.0947059    0.00518218    0.0309512   -0.00683255  -0.0414897    0.154588     0.046658    -0.0459239    0.192048    -0.0221222   -0.0132842    0.0328764     0.0178822    0.0223026    0.159331    -0.124337    -0.00771787   0.131182
 -0.0161146     0.141739    -0.0700464    0.095233     -0.0697287    -0.05733     -0.0395587    0.052865     0.14628     -0.0564768     0.140831     0.133658    -0.0107199    0.00576331   0.00609494  -0.0149233    0.0681576    0.100182    -0.063371    -0.0666159     0.0527392   -0.00124605  -0.0851856   -0.152438     0.0124592    0.0742359
 -0.0810204     0.0163488    0.256154    -0.15128      -0.0424195     0.0481148    0.221638    -0.0487421    0.0277814   -0.00777485    0.0888224   -0.311682    -0.0750487    0.00879142   0.0523479   -0.0253585   -0.0700916    0.0292982    0.173557     0.0388817    -0.0844296    0.0621305   -0.021886     0.135023     0.069185     0.105382
  0.134111     -0.210589    -0.0958349    0.0227078    -0.0368975     0.176277     0.109145    -0.261378    -0.0860513    0.166362      0.0700594    0.00951918  -0.0192811   -0.0466544   -0.144547     0.0152738    0.13831     -0.138119    -0.284701    -0.0761561    -0.0605416    0.123682     0.155087     0.0472404   -0.158598     0.0234838
  0.0898787    -0.096192     0.0807331   -0.0984408     0.0118058     0.00923869  -0.104366     0.054935     0.0411667   -0.0450874    -0.00329266   0.0390641   -0.0462294   -0.0594437   -0.0760897   -0.142375    -0.0402276    0.13363     -0.0352283   -0.046616      0.08762     -0.0253251   -0.120067     0.0182653    0.143003     0.0387743
 -0.0111334     0.148658     0.116001    -0.104329      0.0493335    -0.115593    -0.138222    -0.00608701  -0.0496069    0.0340561    -0.190546     0.108071    -0.0833904    0.0353163    0.128509     0.0493168   -0.0255178   -0.237107     0.0113878   -0.084592      0.0445647    0.0266764   -0.0390459   -0.0322924    0.233864    -0.107121
  0.14823      -0.0698407   -0.050112    -0.0299554    -0.00855894    0.0137831   -0.0549585    0.0838163   -0.0606372    0.12344       0.09975     -0.0589806    0.0852464    0.0688295   -0.102588     0.0627042    0.141714    -0.149497     0.0201387   -0.000338822  -0.0642408   -0.0972927    0.135906     0.0225946    0.0717777    0.136671
 -0.109644     -0.0242223   -0.00441842  -0.110637      0.000399252  -0.104836    -0.0480861    0.0828597   -0.0603752   -0.051781     -0.0676714   -0.0820148   -0.0328747    0.0746867    0.00957339  -0.00844635  -0.019747     0.156703    -0.0359963    0.0278486    -0.072211     0.028345    -0.148912     0.111129     0.0627835    0.0190875
 -0.11009       0.0968918   -0.0685054    0.0982962     0.0216135    -0.0356062    0.119211     0.0875887   -0.157541    -0.134574      0.0110336   -0.0676547    0.122721    -0.118538     0.162106     0.102325     0.0916217   -0.0818273    0.140778     0.027723     -0.0493731   -0.0248328   -0.127585     0.154084     0.036416    -0.00658426
 -0.034696      0.0358084   -0.0436239    0.0871797    -0.0615434    -0.0353388    0.121526    -0.0759554    0.100664    -0.0498402     0.0112222   -0.0166671    0.254145     0.0548222    0.13664      0.131937    -0.0715045   -0.0651472   -0.199149     0.0232236     0.0581995    0.0224124   -0.120849     0.0529274   -0.00627068  -0.00815396
 -0.000646814  -0.0617262    0.140729     0.0244107     0.0878244     0.104637    -0.0209635   -0.0387798    0.198397     0.0555662    -0.0353866   -0.0797301    0.00571553   0.0211307    0.0713271    0.0706884    0.167015     0.048849     0.0317693    0.0188528     0.135366    -0.100565    -0.021851    -0.0241331   -0.00298239  -0.039916
  0.147303      0.117331     0.058307    -0.107856      0.128435     -0.0732483   -0.0196301    0.0542163    0.313432     0.0207638    -0.151442    -0.0497665   -0.053637    -0.0627495    0.172998    -0.145477     0.00639826   0.138091    -0.0225688   -0.038723      0.153586    -0.0634055   -0.100698     0.0558144   -0.0367614   -0.135728
 -0.151361      0.0938462    0.164767     0.0151625     0.0545442     0.00640997   0.0920138    0.0485742    0.00955086  -0.0100309    -0.0539034    0.00963316   0.0987141    0.0102026    0.135581     0.148465    -0.0113675    0.0210672    0.0210264    0.1321       -0.0272925   -0.0527842   -0.0448387   -0.0693858    0.216281    -0.116424
 -0.0405217    -0.0174171    0.0121089    0.0346161    -0.261595     -0.00946384  -0.0627473    0.0945122   -0.0494296    0.00894032   -0.105053     0.081683     0.0880466   -0.0530234    0.0315999   -0.0627186   -0.252712     0.125733     0.0484611    0.102404      0.154119    -0.05845     -0.280031    -0.174014     0.00318928  -0.151102
  0.013682     -0.00376404   0.0136805    0.0959794    -0.0377003    -0.193421    -0.00274634   0.025071     0.0745966   -0.106668      0.00890159  -0.125766     0.173158     0.206531    -0.192558    -0.23185     -0.102513     0.0674915   -0.036152     0.0625799    -0.134089     0.160226     0.105311     0.0667493    0.0680119    0.131036
  0.105713     -0.243223    -0.0813699    0.0980394     0.120569      0.00054123   0.0552596   -0.135016    -0.0187016   -0.172792      0.0485305    0.218695    -0.102853    -0.042966    -0.069909    -0.0471438   -0.0280593   -0.00975556   0.00874529  -0.0421149     0.124381     0.190845     0.0564268   -0.019903     0.0227049   -0.0482096
  0.10394      -0.0165885   -0.0114229   -0.0719066    -0.0650836    -0.0733428   -0.0916948   -0.215162     0.031328     0.242696      0.0197504    0.127974    -0.136073     0.0320415   -0.139893     0.0690995    0.0138964    0.205126    -0.0075166    0.0631535     0.0398565    0.0146696   -0.0144733    0.209144    -0.0488048   -0.046161
  0.165966      0.179315    -0.0536221   -0.0227142    -0.218466     -0.0480387   -0.0194088    0.025732     0.200218     0.0476592     0.0169889   -0.0697937    0.186573     0.0471199   -0.00178254  -0.0977052   -0.0233648   -0.0344482   -0.0350455   -0.00303294   -0.0480122   -0.250498     0.104521    -0.0792671   -0.0539339   -0.0394069
  0.0299372     0.0926855   -0.165854    -0.0989558    -0.082232     -0.0549101   -0.00287782  -0.0309472   -0.0260988   -0.129128      0.208024    -0.0616988    0.121057     0.0299355    0.302268    -0.0258972   -0.100135     0.0751149    0.0474914   -0.0967183     0.0774581    0.0272286    0.099996    -0.171155    -0.0297742    0.0371249
 -0.0747979     0.199435    -0.0159249   -0.0863451     0.0160797    -0.0575298    0.0435041    0.0529914   -0.126868     0.000895176   0.093373    -0.11291      0.0638678   -0.192663     0.0589857   -0.0387894    0.0950747   -0.0858759   -0.0203741    0.0246996    -0.16581      0.0748088   -0.138639    -0.0404276    0.044922     0.091383
 -0.174229      0.0840347    0.135067    -0.00804341    0.0978706     0.0290032   -0.0684783    0.0240167   -0.207734    -0.0602546    -0.0216418   -0.052346    -0.00986973  -0.0630656   -0.0148931    0.0641413   -0.0283453    0.0616882   -0.0877278   -0.0312154    -0.00283101  -0.0379427    0.125098    -0.00746944   0.0874254    0.12965
 -0.095198      0.0189349   -0.0429105    0.000459584  -0.0562749    -0.0398788    0.0509975    0.112138    -0.0273408    0.189132      0.271729     0.0594768    0.0980427   -0.21596     -0.0735919    0.0435613   -0.108818     0.160153     0.0528343   -0.177029     -0.122066    -0.149136     0.00229513   0.137556     0.167601     0.153394
  0.164625     -0.108683    -0.134834     0.00998386    0.126136      0.0580177    0.109052     0.00993135   0.0246728   -0.0762994     0.144077     0.0290813   -0.0243623   -0.106644    -0.0227681    0.110625    -0.1432       0.00918903   0.0365884   -0.0399135    -0.0701527   -0.0256685    0.0467514   -0.013401     0.0547329    0.032351
 -0.184541     -0.0371027   -0.0149185    0.0314143    -0.165636      0.0513716    0.078743    -0.00102406  -0.0114818    0.139953      0.0116348    0.0898327    0.16442      0.0291066    0.0669477    0.0414103    0.0132104   -0.0661247   -0.133228    -0.109844      0.189518    -0.0394979    0.0473671    0.0427415   -0.0200461    0.0287939
  0.0750512    -0.00915656  -0.0987974   -0.0617656     0.0237212     0.100931     0.123182    -0.0245284   -0.0079465    0.252939      0.00681613   0.173578    -0.121051    -0.185954    -0.0821051    0.0172224    0.0121477    0.169377     0.122399     0.0165744    -0.076599     0.0597983   -0.0453301   -0.0380916   -2.79328e-5  -0.0830747
  0.031613      0.0439547   -0.00955878  -0.0910662    -0.0205839     0.0382261    0.154997    -0.016334    -0.0160178   -0.0500921    -0.0431628    0.0778905   -0.0902162   -0.0987045   -0.252519    -0.0528635   -0.0332416   -0.115703    -0.0567172    0.0462427     0.0927491    0.0334794    0.00680851  -0.0382212   -0.111814    -0.025628
 -0.0199509     0.136364     0.112947    -0.107502     -0.0170367     0.074622     0.0540868   -0.15788     -0.00359613   0.0308306    -0.106699    -0.0939415   -0.0295231    0.0607413    0.0254614   -0.0297877    0.0662825    0.0622523    0.0437906    0.0496605     0.0498928   -0.12496     -0.141034     0.151777    -0.074699     0.0136226
 -0.261671      0.227543     0.0194047   -0.0825645     0.150579      0.0118094    0.0238535    0.141548     0.0957741    0.0427701     0.0665475    0.140513     0.116894    -0.0363947   -0.0661092    0.0819538    0.0984945   -0.00572315   0.138999    -0.00062492   -0.0183411    0.11942     -0.0787976   -0.223059     0.143862    -0.210701
 -0.0453356    -0.0389523   -0.0510522    0.161614      0.0116304    -0.0964002    0.02844     -0.0553147   -0.0528053   -0.0362424    -0.0256566   -0.00137542   0.088244    -0.0927576    0.0136743    0.0767518    0.114987    -0.0716873   -0.119204     0.098469      0.0725559   -0.0308186   -0.039459    -0.0849682    0.0083512   -0.0258465
  0.220612     -0.159972    -0.0243151   -0.0193343    -0.00178101    0.0175504    0.0614833   -0.06524     -0.0936328    0.000471651   0.0478247   -0.0714898   -0.0350497    0.0622119    0.137002     0.146714     0.253671    -0.117836    -0.17569      0.141987     -0.0309584   -0.0106659    0.0838189   -0.00382616   0.132104     0.162143
 -0.0543453     0.0366914   -0.0554855   -0.0894579    -0.15228       0.0674852   -0.0328738    0.171979     0.136201    -0.0562864     0.0683888    0.00131374   0.00754004   0.0650529    0.0152098   -0.152352    -0.0420524   -0.0215813    0.0236198    0.0391834     0.0452792   -0.151439     0.0955075   -0.0711734    0.139644     0.242235
  0.166538     -0.0633702    0.145651    -0.0356324     0.0268089     0.0447914    0.0202792   -0.0119729   -0.127209    -0.060687     -0.085944     0.129354    -0.0491818   -0.00881863  -0.0927595    0.0130085    0.045556     0.221122    -0.259592     0.0400439    -0.0766354   -0.0508916   -0.119657     0.135301    -0.289119    -0.0350506kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4049625844822162
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405028
[ Info: iteration 2, average log likelihood -1.404972
[ Info: iteration 3, average log likelihood -1.404705
[ Info: iteration 4, average log likelihood -1.401595
[ Info: iteration 5, average log likelihood -1.389437
[ Info: iteration 6, average log likelihood -1.380244
[ Info: iteration 7, average log likelihood -1.378283
[ Info: iteration 8, average log likelihood -1.377515
[ Info: iteration 9, average log likelihood -1.376968
[ Info: iteration 10, average log likelihood -1.376542
[ Info: iteration 11, average log likelihood -1.376203
[ Info: iteration 12, average log likelihood -1.375936
[ Info: iteration 13, average log likelihood -1.375724
[ Info: iteration 14, average log likelihood -1.375553
[ Info: iteration 15, average log likelihood -1.375412
[ Info: iteration 16, average log likelihood -1.375289
[ Info: iteration 17, average log likelihood -1.375180
[ Info: iteration 18, average log likelihood -1.375080
[ Info: iteration 19, average log likelihood -1.374987
[ Info: iteration 20, average log likelihood -1.374899
[ Info: iteration 21, average log likelihood -1.374815
[ Info: iteration 22, average log likelihood -1.374733
[ Info: iteration 23, average log likelihood -1.374651
[ Info: iteration 24, average log likelihood -1.374567
[ Info: iteration 25, average log likelihood -1.374476
[ Info: iteration 26, average log likelihood -1.374366
[ Info: iteration 27, average log likelihood -1.374196
[ Info: iteration 28, average log likelihood -1.373872
[ Info: iteration 29, average log likelihood -1.373436
[ Info: iteration 30, average log likelihood -1.373060
[ Info: iteration 31, average log likelihood -1.372794
[ Info: iteration 32, average log likelihood -1.372597
[ Info: iteration 33, average log likelihood -1.372440
[ Info: iteration 34, average log likelihood -1.372312
[ Info: iteration 35, average log likelihood -1.372209
[ Info: iteration 36, average log likelihood -1.372125
[ Info: iteration 37, average log likelihood -1.372054
[ Info: iteration 38, average log likelihood -1.371989
[ Info: iteration 39, average log likelihood -1.371921
[ Info: iteration 40, average log likelihood -1.371836
[ Info: iteration 41, average log likelihood -1.371711
[ Info: iteration 42, average log likelihood -1.371525
[ Info: iteration 43, average log likelihood -1.371265
[ Info: iteration 44, average log likelihood -1.370901
[ Info: iteration 45, average log likelihood -1.370404
[ Info: iteration 46, average log likelihood -1.369863
[ Info: iteration 47, average log likelihood -1.369418
[ Info: iteration 48, average log likelihood -1.369065
[ Info: iteration 49, average log likelihood -1.368786
[ Info: iteration 50, average log likelihood -1.368565
┌ Info: EM with 100000 data points 50 iterations avll -1.368565
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4050277933513273
│     -1.4049722341931223
│      ⋮
└     -1.368565136591395
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368528
[ Info: iteration 2, average log likelihood -1.368244
[ Info: iteration 3, average log likelihood -1.367397
[ Info: iteration 4, average log likelihood -1.362029
[ Info: iteration 5, average log likelihood -1.349195
[ Info: iteration 6, average log likelihood -1.338839
[ Info: iteration 7, average log likelihood -1.332231
[ Info: iteration 8, average log likelihood -1.327500
[ Info: iteration 9, average log likelihood -1.324209
[ Info: iteration 10, average log likelihood -1.321906
[ Info: iteration 11, average log likelihood -1.320230
[ Info: iteration 12, average log likelihood -1.318996
[ Info: iteration 13, average log likelihood -1.318104
[ Info: iteration 14, average log likelihood -1.317463
[ Info: iteration 15, average log likelihood -1.317007
[ Info: iteration 16, average log likelihood -1.316683
[ Info: iteration 17, average log likelihood -1.316452
[ Info: iteration 18, average log likelihood -1.316282
[ Info: iteration 19, average log likelihood -1.316158
[ Info: iteration 20, average log likelihood -1.316067
[ Info: iteration 21, average log likelihood -1.316000
[ Info: iteration 22, average log likelihood -1.315950
[ Info: iteration 23, average log likelihood -1.315912
[ Info: iteration 24, average log likelihood -1.315884
[ Info: iteration 25, average log likelihood -1.315864
[ Info: iteration 26, average log likelihood -1.315851
[ Info: iteration 27, average log likelihood -1.315842
[ Info: iteration 28, average log likelihood -1.315836
[ Info: iteration 29, average log likelihood -1.315832
[ Info: iteration 30, average log likelihood -1.315829
[ Info: iteration 31, average log likelihood -1.315828
[ Info: iteration 32, average log likelihood -1.315826
[ Info: iteration 33, average log likelihood -1.315826
[ Info: iteration 34, average log likelihood -1.315825
[ Info: iteration 35, average log likelihood -1.315825
[ Info: iteration 36, average log likelihood -1.315824
[ Info: iteration 37, average log likelihood -1.315824
[ Info: iteration 38, average log likelihood -1.315824
[ Info: iteration 39, average log likelihood -1.315824
[ Info: iteration 40, average log likelihood -1.315824
[ Info: iteration 41, average log likelihood -1.315824
[ Info: iteration 42, average log likelihood -1.315824
[ Info: iteration 43, average log likelihood -1.315824
[ Info: iteration 44, average log likelihood -1.315824
[ Info: iteration 45, average log likelihood -1.315824
[ Info: iteration 46, average log likelihood -1.315824
[ Info: iteration 47, average log likelihood -1.315824
[ Info: iteration 48, average log likelihood -1.315824
[ Info: iteration 49, average log likelihood -1.315824
[ Info: iteration 50, average log likelihood -1.315824
┌ Info: EM with 100000 data points 50 iterations avll -1.315824
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3685284456675044
│     -1.368244465077595
│      ⋮
└     -1.3158237703999798
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.315978
[ Info: iteration 2, average log likelihood -1.315787
[ Info: iteration 3, average log likelihood -1.314915
[ Info: iteration 4, average log likelihood -1.308024
[ Info: iteration 5, average log likelihood -1.291394
[ Info: iteration 6, average log likelihood -1.280365
[ Info: iteration 7, average log likelihood -1.275721
[ Info: iteration 8, average log likelihood -1.272022
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.268106
[ Info: iteration 10, average log likelihood -1.278747
[ Info: iteration 11, average log likelihood -1.272887
[ Info: iteration 12, average log likelihood -1.269909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.266928
[ Info: iteration 14, average log likelihood -1.277157
[ Info: iteration 15, average log likelihood -1.271947
[ Info: iteration 16, average log likelihood -1.269305
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.266509
[ Info: iteration 18, average log likelihood -1.276794
[ Info: iteration 19, average log likelihood -1.271630
[ Info: iteration 20, average log likelihood -1.268980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.266157
[ Info: iteration 22, average log likelihood -1.276390
[ Info: iteration 23, average log likelihood -1.271123
[ Info: iteration 24, average log likelihood -1.268407
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.265519
[ Info: iteration 26, average log likelihood -1.275657
[ Info: iteration 27, average log likelihood -1.270284
[ Info: iteration 28, average log likelihood -1.267502
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.264568
[ Info: iteration 30, average log likelihood -1.274684
[ Info: iteration 31, average log likelihood -1.269183
[ Info: iteration 32, average log likelihood -1.266087
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.262813
[ Info: iteration 34, average log likelihood -1.272661
[ Info: iteration 35, average log likelihood -1.266678
[ Info: iteration 36, average log likelihood -1.263064
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.259596
[ Info: iteration 38, average log likelihood -1.269717
[ Info: iteration 39, average log likelihood -1.264554
[ Info: iteration 40, average log likelihood -1.261986
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.259303
[ Info: iteration 42, average log likelihood -1.269416
[ Info: iteration 43, average log likelihood -1.264514
[ Info: iteration 44, average log likelihood -1.262166
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.259587
[ Info: iteration 46, average log likelihood -1.269345
[ Info: iteration 47, average log likelihood -1.264530
[ Info: iteration 48, average log likelihood -1.262263
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.259718
[ Info: iteration 50, average log likelihood -1.269269
┌ Info: EM with 100000 data points 50 iterations avll -1.269269
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3159779233637015
│     -1.3157865835562477
│      ⋮
└     -1.2692686312925745
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.264658
[ Info: iteration 2, average log likelihood -1.262163
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.258635
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.248246
[ Info: iteration 5, average log likelihood -1.230142
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.207493
[ Info: iteration 7, average log likelihood -1.210020
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.192870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.202945
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.195236
[ Info: iteration 11, average log likelihood -1.198774
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.184506
[ Info: iteration 13, average log likelihood -1.202522
[ Info: iteration 14, average log likelihood -1.189831
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.172014
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.170939
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.168860
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.182550
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.174881
[ Info: iteration 20, average log likelihood -1.172863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.161277
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.177507
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.173125
[ Info: iteration 24, average log likelihood -1.168624
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.160125
[ Info: iteration 26, average log likelihood -1.181267
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.172870
[ Info: iteration 28, average log likelihood -1.167146
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.157537
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.166917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.168496
[ Info: iteration 32, average log likelihood -1.165094
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.156946
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.167494
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.168377
[ Info: iteration 36, average log likelihood -1.165006
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.156864
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.167474
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.168362
[ Info: iteration 40, average log likelihood -1.164948
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.156786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.167455
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.168355
[ Info: iteration 44, average log likelihood -1.164914
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.156737
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.167444
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.168352
[ Info: iteration 48, average log likelihood -1.164893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.156704
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.167437
┌ Info: EM with 100000 data points 50 iterations avll -1.167437
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2646584845791724
│     -1.2621628806178842
│      ⋮
└     -1.1674366503343565
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.168578
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.159994
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.154709
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.130405
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      6
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.086649
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.079796
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     14
│     20
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.068962
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068806
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     20
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070711
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     14
│     19
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.064260
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      6
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.064987
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     19
│     20
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.060349
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.074294
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.054829
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     19
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.063227
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     20
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.068242
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.057317
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.078530
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.054985
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066114
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      6
│     14
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.057334
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.061985
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.074900
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     14
│     19
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.054102
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.058692
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082312
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      6
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.058611
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.043194
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.088754
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      6
│     24
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.056908
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.052377
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.089455
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.055466
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.061317
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.073145
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      6
│     24
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.059739
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.055364
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.081528
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.061784
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.064372
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.076202
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048971
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.061678
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.084248
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      6
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.053078
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.070684
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078570
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      6
│     24
│     26
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051932
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.051396
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.090284
┌ Info: EM with 100000 data points 50 iterations avll -1.090284
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1685775155402451
│     -1.1599935585251453
│      ⋮
└     -1.090283657599291
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4049625844822162
│     -1.4050277933513273
│     -1.4049722341931223
│     -1.404704951122532
│      ⋮
│     -1.0519316184656293
│     -1.051396270353596
└     -1.090283657599291
32×26 Array{Float64,2}:
  0.0157398    0.0565704  -0.187463    -0.0670705    -0.337105     0.0777031   -0.0706555    0.248093      0.172088     -0.049767      0.0638032   -0.0642117   0.0145818    0.0674356    0.0528678   -0.228067    -0.0560172   -0.0559752   -0.0481498    0.0325301   0.060775    -0.22267      0.0742143   -0.0752772    0.134241     0.2206
 -0.205512     0.0684558   0.143156    -0.0146223     0.0959171    0.0478236   -0.0867087    0.0297878    -0.172406     -0.0495677    -0.0162321   -0.0413635  -0.00388081  -0.0439164   -0.0033493    0.0507681   -0.0275651    0.0751847   -0.0872679   -0.0355502  -0.0006063   -0.0561949    0.124567    -0.0181728    0.0986829    0.132378
  0.108292     0.052259    0.0973389    0.0273839    -0.0500288   -0.0010737   -0.00940688  -0.11012      -0.0933335     0.00898174    0.0337345    0.0143992  -0.0432421    0.191216     0.0250967   -0.0470945    0.219089     0.0264972   -0.00932313   0.0290663   0.0195054    0.0247589    0.185807    -0.106584    -0.041849     0.129663
  0.00299227   0.0398747  -0.077846    -0.0767246    -0.162279     0.0872237   -0.0632716    0.0728286     0.174785     -0.0425785     0.0650634    0.0203204   0.0102234    0.0628924   -0.0763337   -0.1283      -0.0811339   -0.0501042    0.0908327    0.0379953   0.0399819   -0.203953     0.109035    -0.123024     0.241403     0.255064
 -0.182395     0.0932848   0.164202     0.00761653    0.0830914    0.0217432    0.0833384    0.0450932     0.0127758    -0.0161553    -0.04496      0.0305235   0.108834     0.0100619    0.134738     0.14359     -0.009433     0.0325903    0.0201733    0.136043   -0.0349782   -0.0141297   -0.0404701   -0.0640211    0.214835    -0.120974
 -0.00549617   0.148583    0.112557    -0.110577      0.0580467   -0.120341    -0.118406    -0.000245625  -0.0399585     0.0337357    -0.193648     0.104889   -0.081284     0.0344502    0.121933     0.0401791   -0.0153535   -0.234479     0.0163498   -0.09836     0.040701     0.0264223   -0.0634261   -0.0328036    0.230279    -0.0940815
  0.144649     0.110345   -0.116259    -0.105702     -0.0268446   -0.159875    -0.179261    -0.0680962    -0.0274023    -0.121512      0.211471    -0.0609738   0.0887239    0.0297131    0.28277     -0.0299528   -0.191563     0.0258957   -0.0614218   -0.0718265   0.110217     0.0282303    0.191336    -0.149638    -0.0178779    0.0733505
 -0.164899     0.0977374  -0.20091     -0.0788008    -0.105299    -0.0420253    0.148553     0.01916      -0.0155489    -0.141273      0.171161    -0.0611374   0.131616     0.0297856    0.297832    -0.0149379   -0.0434902    0.115088     0.0896634   -0.0646653   0.0359557    0.0136395    0.0213677   -0.173191    -0.0404118   -0.00337748
 -0.03871      0.153587   -0.0774582    0.102169     -0.0885684   -0.0515543   -0.0527043    0.107982      0.177925     -0.0740716     0.106238     0.138154   -0.00363598   0.0122064   -0.013839    -0.0259814    0.0692128    0.0581199   -0.0707681   -0.0680944   0.0621126   -0.023179    -0.0841181   -0.167647     0.0241109    0.0791449
  0.0023808   -0.0462499   0.142737     0.0166046     0.0582803    0.093134    -0.0287233   -0.0298033     0.206329      0.0588149    -0.0464991   -0.0784367   0.00909311   0.0187595    0.0950257    0.0804652    0.159022     0.0405517    0.0314266    0.0236167   0.136307    -0.103612    -0.0186178   -0.0350711   -0.00317589  -0.0379161
 -0.0349869   -0.0422209  -0.0364737   -0.0142883    -0.0829208    0.0316856    0.0091598    0.0542716    -0.0311238     0.109664      0.0461663    0.0208348   0.139351     0.0462816   -0.0108626    0.0502094    0.0722327   -0.126083    -0.031457    -0.0245671   0.0573329   -0.06941      0.12321      0.0263681    0.01824      0.0879169
 -0.084761     0.0044875   0.252278    -0.160532     -0.061136     0.0510301    0.214915    -0.0589333     0.0111837    -0.00210758    0.0896825   -0.312268   -0.0915076   -0.00524024   0.0554384   -0.0346723   -0.0680079    0.0305641    0.171733     0.0175753  -0.0746244    0.0518426   -0.0292408    0.135256     0.0537756    0.102627
  0.0975594   -0.158963   -8.75928e-5   0.00620163    0.0803902   -0.00162053  -0.0391078   -0.0371241     0.00923281   -0.0903151     0.0183508    0.117782   -0.0794079   -0.0296493   -0.072801    -0.101063    -0.0611381    0.0631216    0.00208229  -0.0298812   0.116978     0.0792631   -0.0328477   -0.0026523    0.0711722    0.00248563
 -0.0802606   -0.0140006  -0.0421749    0.00410325   -0.0413814   -0.0525972    0.0383025    0.0687284    -0.0207504     0.13279       0.286371     0.047571    0.0790387   -0.196261    -0.0725796    0.023406    -0.133202     0.129145     0.0401398   -0.153337   -0.0996683   -0.0823089    0.0290084    0.133549     0.175583     0.112912
  0.0524545   -0.0184068  -0.0806707   -0.0614108    -0.0546599    0.140073     0.106305    -0.0323562     0.0401432     0.309546      0.149442     0.192758   -0.121061    -0.173336    -0.0619342    0.0183058    0.0510056    0.158233    -0.29266      0.0691303   0.0555135    0.0977771   -0.175347    -0.0843057   -0.0396059   -0.0634474
  0.113344     0.0151095  -0.115161    -0.0625747     0.0354062    0.0581693    0.149726     0.00613485   -0.0274784     0.171308     -0.163005     0.141489   -0.112058    -0.179653    -0.151197     0.00170168  -0.161135     0.137996     0.717571     0.0274637  -0.209381     0.102299     0.0728488    0.0164623    0.0159308   -0.0619293
  0.139167    -0.0230784  -0.0763035   -0.0040971    -0.100126     0.067883     0.0296979   -0.11777       0.0663874     0.0830544     0.0442355   -0.0436714   0.0757009    0.0104307   -0.0374407   -0.0686466    0.0580416   -0.0837646   -0.157565    -0.0315261  -0.0546016   -0.0672408    0.120501    -0.0195471   -0.105391    -0.0079286
 -0.0511037   -0.0680823  -0.0501943    0.137122      0.00723207  -0.087827     0.0273992   -0.0475403    -0.0548551    -0.0446876    -0.0425468    0.017001    0.122854    -0.154599    -0.00232728   0.0802989    0.122235    -0.0744707   -0.128056     0.0960572   0.0708748   -0.0289169   -0.0391044   -0.081156     0.0463678   -0.0239496
 -0.0307336    0.158475    0.137351    -0.0812664    -0.0128092    0.0642823    0.0568836   -0.181895      0.000719872   0.0274746    -0.113652    -0.0807105  -0.0309656    0.0566678    0.0350073   -0.030159     0.0677343    0.0666939    0.0391841    0.0579783   0.0542629   -0.136177    -0.114942     0.132711    -0.0629139    0.0179635
 -0.062206     0.166795   -0.0422697   -0.0995774     0.0122538   -0.0681982    0.0280751    0.0756202    -0.114324     -0.000567728   0.0925241   -0.170349    0.0660334   -0.190998     0.0726729   -0.0391647    0.0900463   -0.0778184   -0.0169758    0.0259534  -0.15716      0.0927857   -0.161668    -0.0218913    0.0669344    0.0663367
  0.0569322   -0.0880801  -0.00923022  -0.0898934     0.00132349  -0.046022    -0.00597099   0.00735931   -0.0802895    -0.0381777    -0.00370021  -0.0549902  -0.0290919    0.0677577    0.0647763    0.0547322    0.109137     0.0243379   -0.106788     0.0729879  -0.0792512   -0.0154365   -0.0357543    0.0504577    0.0663876    0.0564217
 -0.170139     0.161931   -0.0374544    0.0260495     0.0796281    0.00706576   0.0659358    0.112861     -0.0337582    -0.0616092     0.0293823    0.0629655   0.0688178   -0.0716315    0.0524029    0.0822866    0.0872111   -0.0418112    0.157653     0.0474209   0.00684103   0.0206144   -0.0943693   -0.0157245    0.11655     -0.100642
  0.14387      0.117996    0.0560863   -0.116515      0.140948    -0.0842971   -0.037216     0.0398921     0.316174      0.0152853    -0.150052    -0.0459517  -0.0496      -0.0485541    0.188668    -0.149443     0.00243308   0.135941    -0.0782022   -0.0388054   0.151699    -0.0561496   -0.0757786    0.0498518   -0.0145287   -0.143168
 -0.0287316   -0.0284825   0.00753552   0.0392998    -0.251944    -0.00241897  -0.0463517    0.0973694    -0.0515131     0.00179786   -0.0756233    0.0584328   0.0977539   -0.0517325    0.0382537   -0.0487328   -0.222576     0.113345     0.0429185    0.0903167   0.118191    -0.0629149   -0.260368    -0.165724     0.00984896  -0.126378
  0.0125884   -0.0235668   0.00209339   0.0830717    -0.0394475   -0.213683    -0.0238137   -0.000315762   0.0570209    -0.078922      0.00864186  -0.125136    0.174061     0.20027     -0.241439    -0.230648    -0.103573     0.0398192   -0.0316369    0.058971   -0.125543     0.161109     0.136581     0.0567665    0.0688278    0.121412
 -0.0354363    0.0329155  -0.0430912    0.0845691    -0.0572912   -0.033483     0.115267    -0.071285      0.0979881    -0.062112      0.00719557  -0.016927    0.227142     0.0677513    0.134866     0.129185    -0.0737763   -0.0834821   -0.156621     0.0264112   0.0576841    0.0222898   -0.109388     0.053587    -0.0179188   -0.0127352
  0.178397    -0.0347715  -0.224269    -0.000797634   0.125559    -0.0456223    0.115659     0.0388084     0.0100335    -0.0819741     0.147796     0.0444811  -0.0232427   -0.216048     0.0256703    0.0958267   -0.0638801    0.011223     0.029529    -0.0359216  -0.765071    -0.00982903  -0.0140188   -0.00808794   0.0511202    0.023232
  0.163485    -0.208583   -0.11999      0.0156348     0.127125     0.124924     0.0873867    0.00174327    0.0205644    -0.0818543     0.121081     0.0412511  -0.0128807    0.00976352  -0.0298367    0.114846    -0.208066     0.00837529   0.0302933   -0.0528584   0.772773    -0.0300908    0.00917031  -0.0101418    0.0483878    0.0330833
  0.0133735    0.0406406  -0.00590207  -0.0975384    -0.020112     0.0365848    0.149691    -0.00531831   -0.0241801    -0.0454425    -0.0112972    0.0553249  -0.0902255   -0.116995    -0.25191     -0.0337687   -0.0331076   -0.112705    -0.0671722    0.0570722   0.0779513    0.0326555   -0.00531248  -0.0387571   -0.11097     -0.0236682
  0.103761    -0.01854    -0.0100264   -0.0692529    -0.0685855   -0.0718397   -0.0929269   -0.294349      0.00738082    0.249399      0.0139828    0.111206   -0.136346     0.0377219   -0.167138     0.0502986    0.0232829    0.18506     -0.0219614    0.0536468   0.0618327    0.00250746  -0.0326421    0.238971    -0.0484781   -0.0355024
 -0.0318804   -0.0656644  -0.0754568   -0.0228025     0.0550416    0.272501     0.0171958   -0.467322     -0.147616     -0.0907642    -0.085508     0.135015   -0.0399015    0.0327518    0.0558449    0.0129091    0.0536213    0.496485    -0.259794     0.0505369  -0.0798303   -0.0424553   -0.136851     0.21649     -0.291996    -0.0399127
  0.371125    -0.0558842   0.385778    -0.0418039     0.0051462   -0.10602      0.00432738   0.453435     -0.165341     -0.00156293   -0.0856675    0.0771116  -0.042598    -0.0296404   -0.167494     0.0123998    0.0446442   -0.0729094   -0.259643     0.0388429  -0.0832921   -0.0701456   -0.134299    -0.043628    -0.290614    -0.0329503[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.055370
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.035796
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054186
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.035095
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.053968
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.034908
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.053906
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.034730
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      6
│     19
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053914
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034603
┌ Info: EM with 100000 data points 10 iterations avll -1.034603
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.906680e+05
      1       6.637532e+05      -2.269149e+05 |       32
      2       6.367944e+05      -2.695884e+04 |       32
      3       6.243087e+05      -1.248568e+04 |       32
      4       6.174210e+05      -6.887696e+03 |       32
      5       6.124869e+05      -4.934059e+03 |       32
      6       6.091382e+05      -3.348713e+03 |       32
      7       6.073234e+05      -1.814850e+03 |       32
      8       6.061688e+05      -1.154517e+03 |       32
      9       6.051594e+05      -1.009447e+03 |       32
     10       6.040384e+05      -1.121003e+03 |       32
     11       6.027524e+05      -1.285997e+03 |       32
     12       6.013762e+05      -1.376146e+03 |       32
     13       6.002593e+05      -1.116971e+03 |       32
     14       5.995349e+05      -7.243989e+02 |       32
     15       5.991545e+05      -3.803893e+02 |       32
     16       5.989446e+05      -2.099180e+02 |       32
     17       5.987872e+05      -1.573204e+02 |       32
     18       5.986421e+05      -1.451719e+02 |       32
     19       5.985324e+05      -1.097064e+02 |       31
     20       5.984421e+05      -9.023721e+01 |       31
     21       5.983583e+05      -8.380657e+01 |       31
     22       5.982874e+05      -7.091728e+01 |       30
     23       5.982405e+05      -4.695013e+01 |       31
     24       5.982166e+05      -2.385230e+01 |       30
     25       5.982020e+05      -1.465217e+01 |       29
     26       5.981918e+05      -1.017441e+01 |       27
     27       5.981853e+05      -6.494928e+00 |       24
     28       5.981794e+05      -5.882762e+00 |       25
     29       5.981746e+05      -4.820898e+00 |       24
     30       5.981712e+05      -3.336699e+00 |       25
     31       5.981680e+05      -3.200211e+00 |       21
     32       5.981657e+05      -2.323275e+00 |       20
     33       5.981636e+05      -2.167928e+00 |       21
     34       5.981613e+05      -2.255661e+00 |       21
     35       5.981586e+05      -2.685499e+00 |       21
     36       5.981540e+05      -4.564983e+00 |       23
     37       5.981472e+05      -6.840574e+00 |       26
     38       5.981365e+05      -1.067886e+01 |       27
     39       5.981199e+05      -1.658929e+01 |       27
     40       5.980905e+05      -2.943825e+01 |       30
     41       5.980389e+05      -5.163772e+01 |       31
     42       5.979666e+05      -7.227720e+01 |       30
     43       5.978598e+05      -1.068319e+02 |       31
     44       5.977044e+05      -1.553530e+02 |       32
     45       5.975153e+05      -1.891176e+02 |       31
     46       5.973275e+05      -1.878249e+02 |       32
     47       5.971582e+05      -1.692624e+02 |       31
     48       5.970129e+05      -1.452972e+02 |       32
     49       5.969355e+05      -7.740309e+01 |       32
     50       5.968843e+05      -5.123366e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 596884.2586085122)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.319592
[ Info: iteration 2, average log likelihood -1.289559
[ Info: iteration 3, average log likelihood -1.257837
[ Info: iteration 4, average log likelihood -1.221638
[ Info: iteration 5, average log likelihood -1.181040
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.137438
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.141897
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.101904
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      9
│     17
│     23
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076594
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.126866
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.069899
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     14
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.080977
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.108619
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.079149
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     13
│     21
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064918
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     14
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.100577
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.108777
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.069981
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     13
│     17
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.052663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     10
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.096921
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.084019
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091794
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.072356
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.066919
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     24
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080807
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.079221
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.090592
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.085748
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.068964
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     17
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.057495
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     21
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.102364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.101081
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.085752
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.074067
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     13
│     14
│     17
│     21
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.035397
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.107643
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.087593
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     11
│     14
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.056569
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.078706
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.055663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.091468
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.088525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.069238
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      6
│     10
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.052314
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     11
│     17
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.094017
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.096772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.046317
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│     10
│     11
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.039146
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.106787
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     14
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068631
┌ Info: EM with 100000 data points 50 iterations avll -1.068631
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0777997    0.0551159    0.0607795    0.00617109  -0.0593145     0.0154858    -0.0243492   -0.0564491    -0.0480824   -0.00533219    0.0421722    0.030325    -0.0226652    0.183467     0.0114182    -0.0658517   0.189252     0.0240065     0.0066866    0.0335527    0.0191504    0.0151039    0.174356     -0.120502    -0.00318849   0.143626
  0.155384     0.210158    -0.0598277   -0.0262188   -0.206243     -0.0443576    -0.0133967   -0.000786692   0.208262     0.0307213     0.0210329   -0.130556     0.191179     0.0407077    0.0596551    -0.113427   -0.0222093   -0.0344216    -0.0583482    0.00852505  -0.060056    -0.31507      0.0992268    -0.0714387   -0.0997078   -0.0425836
  0.149062    -0.0414352   -0.0445153   -0.0462367   -0.0368472     0.0261951    -0.0534594    0.105937     -0.0750038    0.166379      0.091029    -0.0697959    0.0516255    0.0333005   -0.132165      0.0429607   0.112183    -0.169548      0.211463     0.0240491   -0.0471345   -0.139641     0.197654      0.00357916   0.0872781    0.156125
 -0.0946087    0.09819     -0.0819993    0.123621     0.0226424    -0.0309825     0.101407     0.0874287    -0.14486     -0.136445     -0.00172397  -0.0149985    0.120426    -0.115218     0.163465      0.0831888   0.0831137   -0.0726749     0.158507     0.0318331   -0.00315622  -0.0699039   -0.133687      0.145596     0.0598661   -0.00823671
  0.222836    -0.169369    -0.0209419   -0.0234968    0.000677187   0.0194838     0.0442698   -0.0761052    -0.0984298   -0.0253853     0.0496516   -0.0409028   -0.0387152    0.0571331    0.133073      0.136933    0.252501    -0.112472     -0.175508     0.129854    -0.062782    -0.00794222   0.0753849    -0.012612     0.0873588    0.0437655
  0.100143    -0.228187    -0.0952472    0.0757972    0.103969     -0.0180046     0.0536813   -0.141053     -0.0282339   -0.197893      0.0482614    0.232896    -0.0964071   -0.0472269   -0.0697133    -0.0459214  -0.058658     0.000450801  -0.00274927  -0.0440305    0.120368     0.192036     0.0781367    -0.0102981    0.0236791   -0.0502561
  0.0890974   -0.0866429    0.0787864   -0.0538266    0.0343659     0.000709488  -0.10106      0.06788       0.0409732    0.000157467   0.00275096   0.0386252   -0.0460145   -0.0560354   -0.0746912    -0.129343   -0.10122      0.139877      0.00536056  -0.0264961    0.0707211   -0.0425463   -0.120818      0.0429705    0.120941     0.0493114
  0.144357     0.117994     0.0571366   -0.118609     0.139666     -0.0832176    -0.0371471    0.0386134     0.315652     0.0155984    -0.150365    -0.045076    -0.0505597   -0.049433     0.184955     -0.149976    0.00441843   0.136842     -0.0825006   -0.0390549    0.151423    -0.0562128   -0.0773809     0.0509178   -0.0159054   -0.147966
 -0.0887452    0.183642    -0.0249846   -0.0965474    0.0142098    -0.066447      0.028747     0.0565669    -0.135226     0.00498964    0.09548     -0.191825     0.0628677   -0.221419     0.0694222    -0.0281406   0.0983498   -0.0993943    -0.013104     0.0257      -0.146624     0.100514    -0.185885     -0.0389824    0.0634957    0.0571015
 -0.172732     0.0203324   -0.0311082   -0.00249194  -0.0532454    -0.0768652     0.0460342    0.104273     -0.00923247   0.203973      0.391057     0.0282404    0.0988881   -0.199565    -0.0748148     0.0240901  -0.161486     0.146138      0.0696702   -0.170328    -0.116977    -0.129001     0.0035187     0.163194     0.300973     0.149976
  0.0967599   -0.0486654   -0.0124577   -0.0591399   -0.0706286    -0.0708188    -0.08033     -0.29297       0.00829883   0.252422      0.00381947   0.105809    -0.126122     0.0381471   -0.155239      0.0547215   0.0152769    0.198883     -0.0167464    0.0538032    0.0576737    0.00285592  -0.0407707     0.234464    -0.0444757   -0.0281631
 -0.0998769   -0.00579999   0.002748    -0.160611     0.0108256    -0.112083     -0.0539915    0.0813072    -0.0629845   -0.0495908    -0.0589413   -0.0701457   -0.0199982    0.0830874    0.00628077   -0.0173507  -0.0183062    0.154443     -0.0448505    0.0279238   -0.0823385    0.0108807   -0.147375      0.108213     0.03111      0.0516127
 -0.0112668   -0.0226624    0.008655     0.0461151   -0.24925      -0.00734063   -0.0525367    0.0913762    -0.0450951    0.00371228   -0.0829531    0.0706366    0.101419    -0.0563292    0.03941      -0.0326884  -0.227584     0.111494      0.0385462    0.0871208    0.117303    -0.0609152   -0.273023     -0.171127     0.00820526  -0.142775
  0.1683      -0.0588347    0.15293     -0.0312527    0.0286035     0.079724      0.0119829   -0.00345603   -0.151869    -0.0429475    -0.085517     0.105323    -0.0368174    0.00290856  -0.0543128     0.013808    0.0489876    0.203116     -0.259512     0.044746    -0.0796491   -0.0563476   -0.136882      0.0845171   -0.291608    -0.0360896
  0.00355296  -0.0442168    0.141242     0.0179688    0.0574079     0.0912107    -0.0287535   -0.0311898     0.19916      0.0575631    -0.0427352   -0.08046      0.00546181   0.0235663    0.0922924     0.077691    0.160026     0.0480931     0.0310807    0.0239644    0.134639    -0.104581    -0.0179894    -0.0253526   -0.00138595  -0.0341623
  0.0772647   -0.00424203  -0.0966212   -0.0616064   -0.0110603     0.105936      0.12943     -0.020583      0.00857867   0.250769      0.0092364    0.167781    -0.11816     -0.177574    -0.10406       0.0123437  -0.04773      0.151337      0.140489     0.0461401   -0.0602075    0.0970255   -0.0706092    -0.0389259   -0.0135852   -0.0677434
 -0.0476054    0.0422761   -0.0252938    0.0659399   -0.0450848    -0.0844226     0.0868261   -0.05019      -0.029384    -0.120013      2.68207e-5  -0.0235545    0.092452    -0.0289853    0.129914      0.0865834  -0.0308992    0.10672      -0.0419838   -0.0085795    0.0639599   -0.00834492  -0.0637401     0.0489036   -0.0137084    0.0404164
 -0.197702    -0.0375461   -0.0205714    0.00885105  -0.126253      0.0494249     0.0691447    0.0193091    -0.0089434    0.122304      0.00274169   0.0862837    0.180371     0.0296857    0.0677283     0.0398715   0.00518965  -0.0798694    -0.133525    -0.0897501    0.175018    -0.0306198    0.0825238     0.0466317   -0.02858      0.0373572
 -0.0511308   -0.0690717   -0.0508069    0.140145     0.00729575   -0.0890057     0.026037    -0.0484142    -0.0544191   -0.0442134    -0.0413598    0.0170447    0.121346    -0.155608    -0.00155768    0.0792465   0.121736    -0.0734019    -0.128843     0.0964592    0.0707062   -0.0287188   -0.0392496    -0.0819972    0.0491236   -0.0237921
  0.0135134    0.0403998   -0.0058251   -0.098353    -0.0202567     0.0369067     0.149418    -0.00540108   -0.0241714   -0.0459473    -0.0106358    0.05458     -0.0902763   -0.116381    -0.252063     -0.0330161  -0.0330666   -0.112776     -0.0677502    0.0572314    0.078494     0.0326409   -0.00493842   -0.0386258   -0.110858    -0.0235683
  0.137078    -0.208654    -0.0955209    0.0194738    0.0125179     0.177227      0.0900908   -0.255472     -0.0860805    0.142957      0.0703561    0.0039897   -0.0187663   -0.0263461   -0.143218     -0.03487     0.14629     -0.141001     -0.266014    -0.0732272   -0.0628147    0.123012     0.147391      0.0471763   -0.150524    -0.0274069
 -0.0372812    0.157203    -0.0756404    0.106785    -0.0889586    -0.0569994    -0.0518968    0.107042      0.174061    -0.0715035     0.102941     0.139198    -0.0109139    0.0122548   -0.0206665    -0.0238163   0.0688197    0.0676058    -0.0737173   -0.0757931    0.0631564   -0.0158214   -0.0870441    -0.17661      0.0185302    0.0660766
 -0.185892     0.0709867    0.1346      -0.00501106   0.0921535     0.0295984    -0.0833686    0.019676     -0.209022    -0.0414382    -0.0264165   -0.0535085   -0.00674717  -0.0596149   -0.00430188    0.0657704  -0.0294726    0.0808745    -0.0836731   -0.0375168   -0.00204022  -0.0301598    0.118972     -0.00752205   0.0795663    0.132839
 -0.102502     0.0392387   -0.0944947   -0.104373    -0.176748      0.117151     -0.0319536    0.149254      0.16653     -0.0465011     0.0675994    0.0638947    0.0204423    0.073006    -0.00973      -0.125295   -0.0242156   -0.0286774     0.0300623    0.0519041    0.0206715   -0.167408     0.0983299    -0.0870378    0.159456     0.225025
  0.0112651   -0.0213195   -0.00495976   0.0818178   -0.041938     -0.188339     -0.00355283  -0.0141557     0.0646765   -0.0883326     0.00823626  -0.111361     0.200242     0.198371    -0.195924     -0.183667   -0.102703     0.0393574    -0.032498     0.0522507   -0.104315     0.148986     0.101197      0.0537454    0.0607883    0.111003
 -0.0830477    0.00358218   0.253022    -0.161285    -0.0616949     0.0502094     0.216107    -0.0600373     0.0135904   -0.00156556    0.0898482   -0.313368    -0.0922711   -0.00603812   0.055898     -0.0348649  -0.0672334    0.0280144     0.174451     0.0178304   -0.0769227    0.0525134   -0.0288948     0.137042     0.0530853    0.103926
 -0.0127381    0.146345     0.111032    -0.103447     0.0628227    -0.112568     -0.107828    -0.00198861   -0.0347932    0.0308887    -0.186182     0.112598    -0.0774988    0.035021     0.129009      0.0443647  -0.0158431   -0.236383      0.0155646   -0.0977092    0.0386382    0.02271     -0.0560496    -0.0356472    0.227196    -0.0884654
 -0.0254829    0.160136     0.142562    -0.0790081   -0.012661      0.064691      0.0556257   -0.175172     -0.00143542   0.0306527    -0.114225    -0.0650905   -0.046063     0.0593318    0.0340326    -0.0299588   0.0650373    0.071073      0.0386666    0.0571184    0.0439862   -0.135226    -0.126339      0.151669    -0.0603921    0.0143331
 -0.0892211    0.0985665   -0.00657031  -0.0507779   -0.00619792   -0.0412771     0.0276011    0.0223777     0.00135434  -0.0697259     0.0730178   -0.0238554    0.102109     0.0207631    0.231439      0.0465995  -0.0636794    0.0440601     0.0168809    0.0336086    0.0224117    0.0079911    0.0324629    -0.113881     0.0942736   -0.029352
 -0.0255985    0.0106329   -0.0449872    0.064293    -0.0594698    -0.0220541     0.0832232   -0.0375489     0.138839    -0.126596      0.0215312   -0.00938466   0.25189      0.0537038    0.118819      0.104384   -0.0530871   -0.100504     -0.341761     0.0184773    0.0300979    0.00676498  -0.0948543     0.0391569   -0.035696     0.027229
 -0.270461     0.236784     0.009214    -0.063032     0.144173      0.0452022     0.0246449    0.143559      0.0908       0.02292       0.0704552    0.137114     0.0243637   -0.0361158   -0.067456      0.0892268   0.100658    -0.0086464     0.187359     0.0613366    0.00500243   0.132593    -0.0912313    -0.208965     0.167623    -0.227281
  0.17329     -0.118133    -0.176515     0.00669546   0.126298      0.0379542     0.102679     0.0206177     0.0171243   -0.082244      0.135562     0.0439109   -0.0176648   -0.111297     0.000305097   0.106738   -0.130205     0.00984488    0.0283443   -0.0425246   -0.0457684   -0.0199669    0.000169921  -0.00863215   0.0495678    0.0277907[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.083124
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│     13
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025874
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.010089
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.031489
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│     11
│     13
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.030110
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.013447
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     13
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.047328
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│     13
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.013292
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.003202
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     13
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.051234
┌ Info: EM with 100000 data points 10 iterations avll -1.051234
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.165605     -0.0789945  -0.110564      0.0482864    -0.183602     0.0782918   -0.0786274   -0.0836905   -0.057463     0.0760426    0.0227103   -0.066418    0.100173    -0.0877056    -0.021051    0.0548009   -0.227643    0.0662941    -0.0764594     0.0283781   -0.175866      0.139976     -0.00152338    0.104954     0.009606     0.198432
 -0.0550931    -0.0802277  -0.133322      0.177387      0.0300623    0.154857    -0.00106119  -0.0819594    0.0947531    0.0685488    0.168078     0.0719702  -0.175231     0.139398     -0.0642154  -0.0110035    0.037531   -0.0752486    -0.255827     -0.0788748    0.0148592     0.13429       0.028121      0.0271613    0.0249863    0.00641636
  0.152115     -0.0641566  -0.00118391   -0.168138      0.0314691   -0.0546214   -0.154173     0.0122553    0.0157598   -0.0737919   -0.195285    -0.0877592  -0.284646    -0.074262      0.0704863  -0.215425     0.145228    0.0729293     0.0246069    -0.0871009    0.196079      0.0789882    -0.101444      0.00374943   0.0294535   -0.0631619
  0.189157      0.0951943   0.163636      0.0806737    -0.0892033    0.0645362   -0.159822     0.0376328    0.0787283   -0.0748803    0.047553     0.25105    -0.0737055    0.0764079    -0.0547774   0.0797145   -0.0221358  -0.0276298    -0.0266036     0.0867868   -0.0606894     0.159868     -0.0474131     0.0367344   -0.0175062    0.00612847
  0.0566069     0.025615   -0.000112904   0.122958      0.0169599    0.113897    -0.0935668   -0.212531     0.0746043    0.182263    -0.0222316   -0.0668058   0.220811     0.087155      0.0734885  -0.101136     0.278324    0.0663575     0.093893     -0.143377    -0.0724574     0.0461239     0.079519      0.0597089   -0.0636553   -0.0119475
 -0.0745723    -0.0241573  -0.00231219    0.0346627    -0.101374    -0.0949311   -0.020154    -0.242017     0.021587    -0.00698759   0.127358     0.0921564  -0.166251    -0.0167576    -0.0363899  -0.0296016    0.133408    0.000440121  -0.145102      0.00975563   0.0911171     0.00211779    0.0901327     0.111327     0.0934551   -0.00795017
  0.0277891    -0.0772777   0.00926506   -0.00670307    0.0375406    0.232595     0.215036     0.0616509    0.0465167    0.0395527   -0.105157     0.121619   -0.0610213   -0.000941256  -0.0535942   0.215895     0.0376926  -0.08943       0.00828182    0.0251494    0.0627965    -0.00407308    0.181527      0.072426     0.00280732   0.035716
  0.000825052   0.235744   -0.123672     -0.0402504    -0.105137    -0.115524    -0.116849    -0.236757    -0.067485     0.10327      0.0271489    0.0706183   0.0883728    0.0245029     0.154568    0.0323272   -0.114375    0.213018     -0.0512622     0.116076    -0.234419     -0.0880477     0.10301       0.0581426   -0.0166505    0.0123199
  0.13967       0.0504554   0.0115868    -0.0214122    -0.0451208    0.0555041    0.0700767   -0.0918391    0.087546     0.0118301   -0.00456243   0.130277   -0.127408     0.137592      0.159781    0.11306      0.111354    0.0144007    -0.000347134   0.0145693   -0.000291654   0.0919999     0.0158556     0.0842889    0.0935071   -0.0490882
 -0.0604283     0.103455    0.128008     -0.0500545    -0.0234912    0.0573948   -0.0454426   -0.0882779   -0.0497541    0.00267876  -0.00390227   0.0741542   0.0498131    0.110342     -0.0265977  -0.00403495  -0.0218598   0.190529      0.0690911    -0.119943     0.123574      0.026235     -0.180915     -0.0449999   -0.107239    -0.0923831
  0.210714     -0.0835099  -0.166162     -0.0686899     0.0281193   -0.0426671    0.24279     -0.109981     0.055083    -0.0303995   -0.010204    -0.0788506  -0.0687444   -0.0664827    -0.135021    0.00108021  -0.0148016   0.203103      0.00263729   -0.34454     -0.103516      0.0748055     0.0942507    -0.0400679    0.213839     0.0677326
  0.0941838    -0.069942   -0.011961      0.0940684    -0.0185      -0.0573504    0.111369     0.0224809    0.0173605   -0.0185308   -0.0159152   -0.0828842   0.169443     0.0242973    -0.0733968   0.105306    -0.0294573   0.0620407     0.0274547     0.127721     0.0402006     0.21756      -0.127393      0.0927062   -0.0325499   -0.0462586
  0.0361683    -0.0418141  -0.101337     -0.42748       0.00929263   0.0779187    0.033808     0.0147336   -0.00405433   0.11921     -0.0356683    0.0285602   0.00856744   0.063835      0.0639071  -0.0825806   -0.0848654  -0.0262782    -0.00434375    0.181529    -0.0301162     0.0028484    -0.0384781     0.0147543   -0.0924104    0.00313922
  0.090198     -0.05209     0.0671267    -0.049764      0.129616     0.0443952   -0.109516     0.0660044    0.0746884   -0.0471084   -0.0806539    0.127869   -0.0897597   -0.107992      0.0482481   0.08036     -0.0315662   0.126029     -0.0266819     0.0360219    0.0535354     0.101456     -0.0940235    -0.150304     0.00440956  -0.0269358
  0.135659     -0.0355324   0.270337     -0.158006      0.0290209    0.138341     0.0454432   -0.0116761   -0.00859687  -0.125559    -0.0830721   -0.217621   -0.0694075    0.117971      0.0869797  -0.0712345   -0.0982884   0.0822127     0.125283      0.0245669   -0.135829     -0.0747991     0.0281093    -0.0698512    0.0920343   -0.144189
  0.00694408    0.064805    0.141058      0.0686495    -0.111321    -0.123507    -0.0793439    0.0606704   -0.014835     0.030449     0.116726    -0.121091    0.0152008   -0.143318      0.120469   -0.0894294   -0.149661   -0.0492094    -0.0149991    -0.0408114   -0.0553661    -0.171189     -0.0374037     0.0223072   -0.216063    -0.0166221
 -0.115341      0.0562628   0.0225572     0.0075027    -0.0576519   -0.0631851   -0.0456002    0.147482    -0.0467252   -0.0522421    0.0619803   -0.086711    0.0136693    0.123187     -0.0524997  -0.0231547    0.0292235  -0.0342651    -0.106961     -0.134887     0.0179493    -0.112105      0.245706      0.0696566    0.178649     0.0667549
 -0.0473935    -0.0695216   0.0152069    -0.0511554     0.08118     -0.141596     0.00878202   0.00789389   0.0968872    0.0516821    0.0388777   -0.0756329  -0.128514    -0.0572349    -0.051774   -0.184061     0.0955384   0.085889     -0.151688     -0.0242057    0.0196569    -0.0145307    -0.0235124    -0.0993622   -0.157696    -0.157966
 -0.00821611    0.168841   -0.0250733    -0.0290634    -0.0320705    0.0198961   -0.064805     0.337799    -0.0513795    0.0273523   -0.0137434    0.0484427   0.217586    -0.0408535    -0.0280966  -0.159926     0.112413   -0.0313043    -0.0189522     0.0814624   -0.0342876     0.15366       0.0649354    -0.0454864   -0.118654     0.133844
 -0.0582982    -0.044565    0.0347386    -0.0233519     0.0201675   -0.116889     0.043939     0.186848    -0.0259828    0.051082     0.077207    -0.0737561   0.106415    -0.0110687    -0.0915016   0.013212     0.0650545  -0.114261     -0.0783281    -0.0022037   -0.0976252     0.0581525     0.129364     -0.0691878   -0.187181     0.0882959
  0.0232264     0.0908643   0.143099     -0.0285409    -0.120998    -0.111535     0.0667618   -0.21049     -0.00252077  -0.0934036   -0.0676632   -0.114314   -0.101281     0.140335     -0.21338    -0.190178    -0.024207    0.12742      -0.0382637     0.135705    -0.14467       0.0468979     0.152922      0.0467866    0.0363474    0.0291962
  0.0719222     0.0690379  -0.0352631    -0.11449      -0.139296    -0.0404249    0.00290394   0.0470182   -0.0827536    0.0688777    0.0843201   -0.0423698  -0.0632132    0.10297       0.0977099   0.0667607    0.070851   -0.0704873     0.0317701    -0.0877446    0.0479899    -0.0607693    -0.121571      0.239196     0.00423565   0.0697652
 -0.182664     -0.149164    0.201524      0.163385     -0.0456695    0.0343386   -0.0189052    0.0640566   -0.00072284  -0.15009      0.119399    -0.0630047  -0.0564137   -0.0174907    -0.0421054  -0.0203122    0.172876   -0.0319695    -0.0815254     0.0804728    0.090123      0.0735005     0.146134     -0.0775393    0.0911523   -0.0421416
 -0.125827     -0.136119    0.0530637    -0.000899894   0.19588     -0.141104     0.088678     0.202786     0.0779778    0.148692     0.0940907   -0.0581796   0.248291    -0.0281423    -0.0787955   0.00335769  -0.0817374  -0.0744236    -0.0784849     0.0587574   -0.00832695   -0.152401     -0.0277781     0.0807403   -0.257003     0.104789
  0.0927726    -0.0203974  -0.00891432   -0.043455      0.0280841   -0.0440962    0.0657425    0.0772489    0.0553546   -0.0493669    0.0931036   -0.0194218  -0.0125386    0.0625889     0.0130976  -0.0435095   -0.088166    0.0800164     0.0396937    -0.0534211   -0.0699114     0.0623119     0.106285      0.0891931    0.0064911    0.0592891
 -0.0105381    -0.0754172   0.197969      0.0228371    -0.112       -0.0880688    0.0178678    0.110792     0.0667043   -0.153752    -0.166086     0.0482431   0.0852183   -0.0358246    -0.29077    -0.0593209    0.109388   -0.0983147    -0.0505836    -0.0644962    0.0177839     0.0666493     0.050121      0.0408973   -0.143479    -0.186881
 -0.0448801     0.0870851   0.15064       0.0524841    -0.0361809   -0.0241603    0.0551449   -0.00363905  -0.115961     0.0121132    0.0162756    0.0309439   0.162431     0.0709692     0.056958    0.153686     0.0814828   0.109772     -0.00483482   -0.1642       0.0208266     0.0398908     0.0383835     0.0327792    0.0223742   -0.0663651
 -0.0516042    -0.186208    0.0468232     0.0245538     0.0336961   -0.00247081  -0.0237586    0.0567817    0.0469863   -0.0106386    0.0417327   -0.0658373  -0.114906    -0.0141354    -0.175346    0.0528453    0.0844722  -0.00510561   -0.131915      0.0266963   -0.196344      0.0142429    -0.138117      0.238429     0.0732112   -0.113432
  0.0168618    -0.146639    0.05916       0.0269326    -0.0627228    0.0833473   -0.20607      0.0654003    0.014806     0.084185    -0.0699101   -0.0218293   0.0769691    0.105921      0.108922    0.0768803    0.0697052  -0.124299     -0.0854567     0.0679131   -0.134614     -0.0066919    -0.000315301  -0.16142     -0.134635     0.0776948
  0.249448      0.0425437   0.143211      0.0113313     0.0943881    0.0428669   -0.263044    -0.0515392    0.06182     -0.178863    -0.0230634   -0.0506803  -0.0307639    0.130516     -0.0452509   0.00200825   0.0409037   0.0221196    -0.0626364     0.0526143   -0.056113     -0.184634      0.0173303    -0.0489784   -0.119726     0.0364103
 -0.0198975    -0.0210598   0.122835     -0.074064      0.0985045   -0.0724785    0.181961    -0.0341014    0.104727    -0.0553196    0.141217     0.136988   -0.0956514    0.036913      0.0548976   0.00607813  -0.0748855  -0.0841171     0.135926      0.151136     0.10906      -0.0525919    -0.164783     -0.0635152    0.105582     0.0518612
  0.0540328     0.0627399   0.0164828     0.0930993    -0.0791742   -0.036721    -0.0374246   -0.0530227   -0.0628592    0.0523152    0.257788    -0.213354   -0.0789799    0.026957      0.0344178   0.0352923   -0.0120435  -0.0750219    -0.059157     -0.0970914    0.0741705     0.000224563   0.110446     -0.180799     0.200349     0.0238681kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4284026023054592
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428422
[ Info: iteration 2, average log likelihood -1.428364
[ Info: iteration 3, average log likelihood -1.428326
[ Info: iteration 4, average log likelihood -1.428286
[ Info: iteration 5, average log likelihood -1.428241
[ Info: iteration 6, average log likelihood -1.428191
[ Info: iteration 7, average log likelihood -1.428137
[ Info: iteration 8, average log likelihood -1.428079
[ Info: iteration 9, average log likelihood -1.428017
[ Info: iteration 10, average log likelihood -1.427942
[ Info: iteration 11, average log likelihood -1.427829
[ Info: iteration 12, average log likelihood -1.427626
[ Info: iteration 13, average log likelihood -1.427234
[ Info: iteration 14, average log likelihood -1.426541
[ Info: iteration 15, average log likelihood -1.425550
[ Info: iteration 16, average log likelihood -1.424531
[ Info: iteration 17, average log likelihood -1.423817
[ Info: iteration 18, average log likelihood -1.423452
[ Info: iteration 19, average log likelihood -1.423295
[ Info: iteration 20, average log likelihood -1.423230
[ Info: iteration 21, average log likelihood -1.423204
[ Info: iteration 22, average log likelihood -1.423193
[ Info: iteration 23, average log likelihood -1.423188
[ Info: iteration 24, average log likelihood -1.423186
[ Info: iteration 25, average log likelihood -1.423185
[ Info: iteration 26, average log likelihood -1.423184
[ Info: iteration 27, average log likelihood -1.423183
[ Info: iteration 28, average log likelihood -1.423183
[ Info: iteration 29, average log likelihood -1.423183
[ Info: iteration 30, average log likelihood -1.423182
[ Info: iteration 31, average log likelihood -1.423182
[ Info: iteration 32, average log likelihood -1.423182
[ Info: iteration 33, average log likelihood -1.423182
[ Info: iteration 34, average log likelihood -1.423182
[ Info: iteration 35, average log likelihood -1.423182
[ Info: iteration 36, average log likelihood -1.423181
[ Info: iteration 37, average log likelihood -1.423181
[ Info: iteration 38, average log likelihood -1.423181
[ Info: iteration 39, average log likelihood -1.423181
[ Info: iteration 40, average log likelihood -1.423181
[ Info: iteration 41, average log likelihood -1.423181
[ Info: iteration 42, average log likelihood -1.423181
[ Info: iteration 43, average log likelihood -1.423181
[ Info: iteration 44, average log likelihood -1.423181
[ Info: iteration 45, average log likelihood -1.423181
[ Info: iteration 46, average log likelihood -1.423181
[ Info: iteration 47, average log likelihood -1.423181
[ Info: iteration 48, average log likelihood -1.423181
[ Info: iteration 49, average log likelihood -1.423181
[ Info: iteration 50, average log likelihood -1.423181
┌ Info: EM with 100000 data points 50 iterations avll -1.423181
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4284221927159981
│     -1.4283644798883839
│      ⋮
└     -1.4231805132900976
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423200
[ Info: iteration 2, average log likelihood -1.423140
[ Info: iteration 3, average log likelihood -1.423101
[ Info: iteration 4, average log likelihood -1.423059
[ Info: iteration 5, average log likelihood -1.423012
[ Info: iteration 6, average log likelihood -1.422961
[ Info: iteration 7, average log likelihood -1.422906
[ Info: iteration 8, average log likelihood -1.422851
[ Info: iteration 9, average log likelihood -1.422798
[ Info: iteration 10, average log likelihood -1.422750
[ Info: iteration 11, average log likelihood -1.422706
[ Info: iteration 12, average log likelihood -1.422667
[ Info: iteration 13, average log likelihood -1.422632
[ Info: iteration 14, average log likelihood -1.422597
[ Info: iteration 15, average log likelihood -1.422561
[ Info: iteration 16, average log likelihood -1.422522
[ Info: iteration 17, average log likelihood -1.422477
[ Info: iteration 18, average log likelihood -1.422424
[ Info: iteration 19, average log likelihood -1.422362
[ Info: iteration 20, average log likelihood -1.422291
[ Info: iteration 21, average log likelihood -1.422214
[ Info: iteration 22, average log likelihood -1.422134
[ Info: iteration 23, average log likelihood -1.422056
[ Info: iteration 24, average log likelihood -1.421987
[ Info: iteration 25, average log likelihood -1.421927
[ Info: iteration 26, average log likelihood -1.421879
[ Info: iteration 27, average log likelihood -1.421841
[ Info: iteration 28, average log likelihood -1.421811
[ Info: iteration 29, average log likelihood -1.421787
[ Info: iteration 30, average log likelihood -1.421768
[ Info: iteration 31, average log likelihood -1.421753
[ Info: iteration 32, average log likelihood -1.421740
[ Info: iteration 33, average log likelihood -1.421729
[ Info: iteration 34, average log likelihood -1.421720
[ Info: iteration 35, average log likelihood -1.421712
[ Info: iteration 36, average log likelihood -1.421704
[ Info: iteration 37, average log likelihood -1.421698
[ Info: iteration 38, average log likelihood -1.421692
[ Info: iteration 39, average log likelihood -1.421686
[ Info: iteration 40, average log likelihood -1.421681
[ Info: iteration 41, average log likelihood -1.421677
[ Info: iteration 42, average log likelihood -1.421672
[ Info: iteration 43, average log likelihood -1.421668
[ Info: iteration 44, average log likelihood -1.421664
[ Info: iteration 45, average log likelihood -1.421661
[ Info: iteration 46, average log likelihood -1.421657
[ Info: iteration 47, average log likelihood -1.421654
[ Info: iteration 48, average log likelihood -1.421651
[ Info: iteration 49, average log likelihood -1.421649
[ Info: iteration 50, average log likelihood -1.421646
┌ Info: EM with 100000 data points 50 iterations avll -1.421646
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4231999169339336
│     -1.4231404348378922
│      ⋮
└     -1.4216458627380306
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421657
[ Info: iteration 2, average log likelihood -1.421597
[ Info: iteration 3, average log likelihood -1.421548
[ Info: iteration 4, average log likelihood -1.421494
[ Info: iteration 5, average log likelihood -1.421431
[ Info: iteration 6, average log likelihood -1.421359
[ Info: iteration 7, average log likelihood -1.421279
[ Info: iteration 8, average log likelihood -1.421197
[ Info: iteration 9, average log likelihood -1.421117
[ Info: iteration 10, average log likelihood -1.421043
[ Info: iteration 11, average log likelihood -1.420979
[ Info: iteration 12, average log likelihood -1.420924
[ Info: iteration 13, average log likelihood -1.420878
[ Info: iteration 14, average log likelihood -1.420839
[ Info: iteration 15, average log likelihood -1.420806
[ Info: iteration 16, average log likelihood -1.420777
[ Info: iteration 17, average log likelihood -1.420750
[ Info: iteration 18, average log likelihood -1.420725
[ Info: iteration 19, average log likelihood -1.420702
[ Info: iteration 20, average log likelihood -1.420679
[ Info: iteration 21, average log likelihood -1.420657
[ Info: iteration 22, average log likelihood -1.420635
[ Info: iteration 23, average log likelihood -1.420612
[ Info: iteration 24, average log likelihood -1.420589
[ Info: iteration 25, average log likelihood -1.420566
[ Info: iteration 26, average log likelihood -1.420542
[ Info: iteration 27, average log likelihood -1.420518
[ Info: iteration 28, average log likelihood -1.420494
[ Info: iteration 29, average log likelihood -1.420470
[ Info: iteration 30, average log likelihood -1.420446
[ Info: iteration 31, average log likelihood -1.420423
[ Info: iteration 32, average log likelihood -1.420400
[ Info: iteration 33, average log likelihood -1.420378
[ Info: iteration 34, average log likelihood -1.420358
[ Info: iteration 35, average log likelihood -1.420338
[ Info: iteration 36, average log likelihood -1.420319
[ Info: iteration 37, average log likelihood -1.420302
[ Info: iteration 38, average log likelihood -1.420285
[ Info: iteration 39, average log likelihood -1.420269
[ Info: iteration 40, average log likelihood -1.420254
[ Info: iteration 41, average log likelihood -1.420240
[ Info: iteration 42, average log likelihood -1.420226
[ Info: iteration 43, average log likelihood -1.420213
[ Info: iteration 44, average log likelihood -1.420201
[ Info: iteration 45, average log likelihood -1.420189
[ Info: iteration 46, average log likelihood -1.420177
[ Info: iteration 47, average log likelihood -1.420166
[ Info: iteration 48, average log likelihood -1.420155
[ Info: iteration 49, average log likelihood -1.420144
[ Info: iteration 50, average log likelihood -1.420133
┌ Info: EM with 100000 data points 50 iterations avll -1.420133
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4216565204700573
│     -1.4215970107237375
│      ⋮
└     -1.4201333055500134
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420131
[ Info: iteration 2, average log likelihood -1.420063
[ Info: iteration 3, average log likelihood -1.419998
[ Info: iteration 4, average log likelihood -1.419923
[ Info: iteration 5, average log likelihood -1.419831
[ Info: iteration 6, average log likelihood -1.419718
[ Info: iteration 7, average log likelihood -1.419584
[ Info: iteration 8, average log likelihood -1.419435
[ Info: iteration 9, average log likelihood -1.419278
[ Info: iteration 10, average log likelihood -1.419120
[ Info: iteration 11, average log likelihood -1.418970
[ Info: iteration 12, average log likelihood -1.418833
[ Info: iteration 13, average log likelihood -1.418714
[ Info: iteration 14, average log likelihood -1.418612
[ Info: iteration 15, average log likelihood -1.418526
[ Info: iteration 16, average log likelihood -1.418453
[ Info: iteration 17, average log likelihood -1.418391
[ Info: iteration 18, average log likelihood -1.418337
[ Info: iteration 19, average log likelihood -1.418289
[ Info: iteration 20, average log likelihood -1.418247
[ Info: iteration 21, average log likelihood -1.418209
[ Info: iteration 22, average log likelihood -1.418175
[ Info: iteration 23, average log likelihood -1.418143
[ Info: iteration 24, average log likelihood -1.418115
[ Info: iteration 25, average log likelihood -1.418088
[ Info: iteration 26, average log likelihood -1.418063
[ Info: iteration 27, average log likelihood -1.418040
[ Info: iteration 28, average log likelihood -1.418019
[ Info: iteration 29, average log likelihood -1.417999
[ Info: iteration 30, average log likelihood -1.417980
[ Info: iteration 31, average log likelihood -1.417962
[ Info: iteration 32, average log likelihood -1.417945
[ Info: iteration 33, average log likelihood -1.417929
[ Info: iteration 34, average log likelihood -1.417914
[ Info: iteration 35, average log likelihood -1.417900
[ Info: iteration 36, average log likelihood -1.417887
[ Info: iteration 37, average log likelihood -1.417875
[ Info: iteration 38, average log likelihood -1.417863
[ Info: iteration 39, average log likelihood -1.417851
[ Info: iteration 40, average log likelihood -1.417841
[ Info: iteration 41, average log likelihood -1.417831
[ Info: iteration 42, average log likelihood -1.417821
[ Info: iteration 43, average log likelihood -1.417812
[ Info: iteration 44, average log likelihood -1.417803
[ Info: iteration 45, average log likelihood -1.417795
[ Info: iteration 46, average log likelihood -1.417786
[ Info: iteration 47, average log likelihood -1.417779
[ Info: iteration 48, average log likelihood -1.417771
[ Info: iteration 49, average log likelihood -1.417764
[ Info: iteration 50, average log likelihood -1.417757
┌ Info: EM with 100000 data points 50 iterations avll -1.417757
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201314849048006
│     -1.4200628528608812
│      ⋮
└     -1.4177568327287886
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417759
[ Info: iteration 2, average log likelihood -1.417685
[ Info: iteration 3, average log likelihood -1.417611
[ Info: iteration 4, average log likelihood -1.417521
[ Info: iteration 5, average log likelihood -1.417404
[ Info: iteration 6, average log likelihood -1.417256
[ Info: iteration 7, average log likelihood -1.417076
[ Info: iteration 8, average log likelihood -1.416876
[ Info: iteration 9, average log likelihood -1.416669
[ Info: iteration 10, average log likelihood -1.416471
[ Info: iteration 11, average log likelihood -1.416291
[ Info: iteration 12, average log likelihood -1.416133
[ Info: iteration 13, average log likelihood -1.415997
[ Info: iteration 14, average log likelihood -1.415880
[ Info: iteration 15, average log likelihood -1.415780
[ Info: iteration 16, average log likelihood -1.415693
[ Info: iteration 17, average log likelihood -1.415618
[ Info: iteration 18, average log likelihood -1.415553
[ Info: iteration 19, average log likelihood -1.415495
[ Info: iteration 20, average log likelihood -1.415444
[ Info: iteration 21, average log likelihood -1.415399
[ Info: iteration 22, average log likelihood -1.415358
[ Info: iteration 23, average log likelihood -1.415322
[ Info: iteration 24, average log likelihood -1.415289
[ Info: iteration 25, average log likelihood -1.415259
[ Info: iteration 26, average log likelihood -1.415231
[ Info: iteration 27, average log likelihood -1.415206
[ Info: iteration 28, average log likelihood -1.415182
[ Info: iteration 29, average log likelihood -1.415160
[ Info: iteration 30, average log likelihood -1.415139
[ Info: iteration 31, average log likelihood -1.415120
[ Info: iteration 32, average log likelihood -1.415102
[ Info: iteration 33, average log likelihood -1.415084
[ Info: iteration 34, average log likelihood -1.415068
[ Info: iteration 35, average log likelihood -1.415052
[ Info: iteration 36, average log likelihood -1.415037
[ Info: iteration 37, average log likelihood -1.415023
[ Info: iteration 38, average log likelihood -1.415009
[ Info: iteration 39, average log likelihood -1.414996
[ Info: iteration 40, average log likelihood -1.414984
[ Info: iteration 41, average log likelihood -1.414972
[ Info: iteration 42, average log likelihood -1.414960
[ Info: iteration 43, average log likelihood -1.414949
[ Info: iteration 44, average log likelihood -1.414939
[ Info: iteration 45, average log likelihood -1.414928
[ Info: iteration 46, average log likelihood -1.414919
[ Info: iteration 47, average log likelihood -1.414909
[ Info: iteration 48, average log likelihood -1.414900
[ Info: iteration 49, average log likelihood -1.414891
[ Info: iteration 50, average log likelihood -1.414882
┌ Info: EM with 100000 data points 50 iterations avll -1.414882
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4177586492339804
│     -1.417684846382156
│      ⋮
└     -1.4148818105575462
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4284026023054592
│     -1.4284221927159981
│     -1.4283644798883839
│     -1.428326373096131
│      ⋮
│     -1.4148996454042733
│     -1.414890610736674
└     -1.4148818105575462
32×26 Array{Float64,2}:
 -0.188459    -0.180714   -0.391597    -0.127921    0.161682     0.0866287    0.271303    -0.618663     -0.0549766   -0.227782     0.115351    0.486141    -0.0883356    0.0590723  -0.0010542   -0.311088    -0.173026     0.290937    0.00281738  -0.0348142   0.161259    0.348766    -0.280023   -0.197038     0.0839337   -0.427995
 -0.341006     0.227496   -0.176196     0.051386    0.256638    -0.444567     0.266828     0.309866     -0.0531264    0.250082    -0.191966    0.369941     0.277585     0.327466    0.132492    -0.245858    -0.0995741    0.339949   -0.0179562    0.275886   -0.39289    -0.458184    -0.210465    0.126567    -0.316055    -0.224566
 -0.00634358   0.179426    0.195361    -0.0937892  -0.0820543   -0.0277524   -0.00439268  -0.0454317     0.0235179   -0.0430288    0.0264143  -0.0352276    0.0517786    0.147288   -0.0635761    0.00942213  -0.132095    -0.0956693  -0.129016     0.0862409   0.0214505   0.0556717    0.190768   -0.316792     0.102874     0.0437683
  0.12912     -0.167894   -0.0770304    0.205462   -0.02231     -0.00807145   0.00751103   0.0438681     0.0604137    0.171391    -0.0478628  -0.204115    -0.183328    -0.0133718  -0.0354545    0.0534284    0.205988     0.141694    0.112553    -0.134191   -0.160897   -0.0150275   -0.0643002   0.308891    -0.0752109    0.07036
  0.113216     0.141834   -0.555191     0.78927     0.0423009    0.0439489   -0.584435    -0.190291      0.163077    -0.0670637   -0.538623   -0.331954    -0.550156    -0.556643    0.359911     0.0193387   -0.0206291    0.40594    -0.482943     0.207181    0.299829    0.0715581   -0.431264   -0.0223876    0.36371     -0.374927
 -0.242779     0.0255699   0.309433    -0.111484   -0.0125503   -0.240128    -0.159772     0.0209573     0.0643059    0.00546063  -0.0284819  -0.278494    -0.378897    -0.439374    0.00683485   0.733716     0.379339     0.176744   -0.907788     0.290387   -0.0789404  -0.121712     0.0250362  -0.172767     0.0140911    0.0516315
 -0.0401118   -0.451669    0.468842     0.0648262   0.122074     0.119085    -0.772181     0.127039     -0.21883     -0.566787     0.110419    0.228632    -0.029728    -0.463062    0.284947    -0.0478913    0.180933    -0.369957   -0.164826     0.0578895  -0.47994    -0.293122    -0.139667   -0.0940972    0.00945909   0.0404598
  0.136464    -0.0830528   0.209285    -0.183365   -0.075678     0.247252    -0.327783     0.326794     -0.100577    -0.539066     0.134011    0.256204     0.158545    -0.547399    0.0325177   -0.478653     0.00497975  -0.465054   -0.148851     0.134881    0.739923    0.357368     0.0955485   0.110403     0.127304     0.141224
  0.516891    -0.129655   -0.0821301    0.0328719  -0.145685    -0.103521     0.382816    -0.0687519    -0.121389    -0.0646729    0.704992   -0.0288397    0.257853    -0.209543   -0.626087     0.622834     0.366782    -0.140817   -0.0371311   -0.388508    0.0130904  -0.00809212  -0.387911    0.131167     0.17844     -0.368583
  0.238143    -0.442043    0.089911    -0.399993   -0.00444511  -0.0184273    0.613479     0.4616        0.0536691   -0.00557274   0.188582   -0.0499246    0.227594    -0.326512   -0.56842     -0.394298     0.650131    -0.220422    0.274717     0.164236   -0.366195    0.196836     0.702622    0.774277    -0.346757    -0.643168
  0.565147    -0.455105   -0.123868     0.31866     0.192798     0.289325     0.239515     0.497502     -0.105621     0.208185    -0.355808    0.081336    -0.626793    -0.234324    0.373432    -0.0564632   -0.276194     0.322857    0.251583    -0.0143185  -0.0569432  -0.179846     0.152886    0.208655    -0.836044     0.537583
  0.975433     0.16172    -0.0101194    0.154827    0.166141     0.323131     0.0641797    0.188627     -0.208968     0.086008     0.20421    -0.247461     0.552573     0.350687    0.0657819   -0.32164     -0.532499    -0.25292     0.982051    -0.0364564  -0.0465174  -0.51925     -0.0568791   0.344921    -0.215081     0.171903
 -0.507402     0.502103   -0.275195    -0.735421   -0.0445786   -0.0226359    0.373808    -0.111246      0.00503288   0.0989383   -0.132225    0.169341     0.56987      0.784481   -0.262616    -0.0144837    0.00787278   0.440693    0.205341    -0.037606    0.146131    0.369225     0.164517   -0.0586513    0.307559     0.188348
 -0.319529    -0.152821    0.899545    -0.738062   -0.474877    -0.139471     0.499475     0.0166442    -0.15323      0.0997612    0.466069    0.294616     0.497692     0.545202    0.0296921   -0.0713852   -0.101546    -0.363515    0.0480447    0.204994   -0.163537    0.26716      0.420501   -0.14007     -0.170835     0.280091
 -0.232966     0.227309    0.619926    -0.308934    0.300816    -0.144017     0.205253     0.297596      0.70813     -0.055534    -0.552441   -0.220295     0.0925917    0.153699    0.286601    -0.794372    -0.260049    -0.252761    0.297798     0.115888    0.25288     0.187062     0.969195    0.167775    -0.281355     0.166889
 -0.508901     0.37306     0.187767     0.581326   -0.0991646   -0.585635    -0.166699     0.209762      0.369878     0.283284    -0.172925   -0.261158    -0.179225     0.261905   -0.58668     -0.317202     0.894686    -0.170192   -0.0150446    0.423698   -0.245976    0.257288     0.206455    0.00974658   0.155856     0.014104
  0.0433894    0.142966    0.0770458    0.0841565   0.218257    -0.476398    -0.355468     1.07433       0.118856     0.186498     0.285528   -0.00441859   0.484884    -0.51384    -0.118166    -0.0107658    0.167655    -0.518157   -0.223253     0.0448559  -0.181998   -0.668482    -0.125945    0.147286    -1.08509      0.0818968
 -0.273551    -0.330237   -0.00381987   0.0561128   0.746119    -0.413575     0.43379      0.145529      0.372535     0.715181     0.152426    0.234563     0.376598     0.640176   -0.391499     1.00825     -0.499771     0.410679   -0.562193     0.0427123  -0.49106    -0.638108     0.199128   -0.843465    -1.22264      0.175517
 -0.284456    -0.142594    0.711182    -0.274467    0.648769     0.287345     0.122717     0.34969       0.214866    -0.606983     0.101701    0.143574    -0.221378     0.361123   -0.354783     0.131099     0.359793     0.99086    -0.0221121   -0.184004   -0.106306   -0.343371    -0.112426    0.559082    -0.106202     0.373481
 -0.0358446   -0.354185   -0.347036     0.0449864  -0.15163     -0.391988    -0.693378     0.000801375  -0.35965      0.845757     0.723784   -0.367161    -0.164683     0.570124   -0.247571     0.111728     0.191992     0.494024   -0.268357    -0.0866865  -0.138123   -0.392226    -0.792465    0.406713     0.192205     0.194297
  0.507369     0.201051   -0.311098     0.232543   -0.732644    -0.251284    -0.253836    -0.0833373    -0.253814     0.506597     0.10737    -0.22822     -5.59399e-5  -0.52112     0.201744    -0.155479    -0.086337    -1.13506     0.193734     0.137463    0.0280409   0.283982     0.257714   -0.373744    -0.116075    -0.0759699
  0.614497    -0.21199    -0.236954     0.773578    0.0154418   -0.0178199    0.393237    -0.512096      0.336253     0.694764     0.143406   -0.422416     0.119891     0.58445     0.0902795    0.533483     0.0672106   -0.314748    0.20888     -0.128196   -0.361886   -0.19459      0.0221288  -0.00185067  -0.497124    -0.685159
  0.0616143   -0.817548    0.667987     0.482734   -0.611783     0.111251     0.383758    -0.519032     -0.00452794   0.411752    -0.366944   -0.568176    -0.577118     0.186964    0.115263     0.508882     0.185831     0.522467   -0.0821536   -0.0243383  -0.799368    0.404335     0.382756    0.716099     0.154416    -0.185623
 -0.367571     0.536202   -0.192505     0.131883   -0.701285     0.237283     1.01882     -0.303233     -0.0307788    0.205728    -0.202297    0.239232    -0.413937     0.0719185   0.690138     0.558373     0.210352    -0.039611    0.219999    -0.468743   -0.986143    0.14782      0.522745    0.190091    -0.294705    -0.524033
  0.170373    -0.0895642   0.275678    -0.670337    0.199724     0.512242    -0.185255    -0.237296     -0.515409    -0.465858     0.0599759   0.614032     0.511388    -0.131749    0.459993     0.419431    -0.770335     0.617249   -0.417647    -0.527341    0.0666439   0.027124    -0.765276   -0.42317      0.0978578   -0.351692
 -0.297161     0.410957    0.214306     0.186381   -0.066143     0.0523172   -0.573953    -0.306595     -0.0393462   -0.122061    -0.294118   -0.148718    -0.386813     0.532875    0.555374     0.0992129   -0.741352     0.219118   -0.181128    -0.0997537   0.185654   -0.211454    -0.0896444  -0.775697     0.386382     0.474226
  0.142446     0.1936     -0.69685     -0.156731    0.130796     0.528828    -0.514153    -0.0248375    -0.0588202   -0.214184    -0.338054    0.0960088   -0.0239654    0.185887   -0.230591    -0.492373     0.0842087    0.0931378   0.335803    -0.657359    0.485122    0.374064     0.104954    0.0451161    0.482898     0.154698
  0.0745299   -0.197942    0.225771    -0.288194   -0.400708     0.416113    -0.0183659   -0.56498       0.234325    -0.162688     0.34467    -0.628297    -0.352887    -0.0635302  -0.218625     0.359654    -0.0347936   -0.191182    0.186218    -0.248219    0.520857    0.578105     0.10072     0.189173     0.660585     0.313494
 -0.124585     0.0165772   0.0191405   -0.532432   -0.04323     -0.0463104   -0.703731     0.0739131    -0.161614    -0.764935     0.0689746   0.255009     0.199113    -0.25597    -0.0343019   -1.17272     -0.145017    -0.193669   -0.293005     0.49839     0.780607    0.328367    -0.279452    0.00272613   0.574092     0.412179
 -0.535996    -0.238677    0.366165    -0.0934975  -0.192411    -0.0076275   -0.471952     0.107829     -0.152838    -0.114451     0.180944    0.192406    -0.46977     -0.553314    0.00583351   0.254428     0.257665     0.157031   -0.845082     0.0681642  -0.0875281   0.329569    -0.361075   -0.223212     0.251722    -0.010394
  0.401926     0.240723    0.342811    -0.0801513   0.21187      0.306328     0.330101    -0.252627      0.545515    -1.01928     -0.123266    0.199667     0.456653    -0.281749   -0.0405561    0.175221     0.0733124   -0.548661    0.296538    -0.166899   -0.0144186   0.105471     0.601793   -0.70314      0.0692582   -0.169841
 -0.00709735   0.173687   -0.305514    -0.007406   -0.0286376   -0.071435     0.334752    -0.191509      0.0798816    0.265039    -0.176947   -0.106023     0.0371823    0.339573   -0.00938222  -0.147361    -0.0198396    0.329326    0.267042    -0.0103179   0.0190883  -0.0452563    0.063988    0.306181     0.0873644   -0.00890761[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414873
[ Info: iteration 2, average log likelihood -1.414865
[ Info: iteration 3, average log likelihood -1.414857
[ Info: iteration 4, average log likelihood -1.414848
[ Info: iteration 5, average log likelihood -1.414840
[ Info: iteration 6, average log likelihood -1.414833
[ Info: iteration 7, average log likelihood -1.414825
[ Info: iteration 8, average log likelihood -1.414817
[ Info: iteration 9, average log likelihood -1.414809
[ Info: iteration 10, average log likelihood -1.414802
┌ Info: EM with 100000 data points 10 iterations avll -1.414802
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.294056e+05
      1       7.146290e+05      -2.147766e+05 |       32
      2       6.968107e+05      -1.781834e+04 |       32
      3       6.902365e+05      -6.574203e+03 |       32
      4       6.871114e+05      -3.125072e+03 |       32
      5       6.852963e+05      -1.815096e+03 |       32
      6       6.840252e+05      -1.271102e+03 |       32
      7       6.830739e+05      -9.512961e+02 |       32
      8       6.823238e+05      -7.500726e+02 |       32
      9       6.816822e+05      -6.416214e+02 |       32
     10       6.811400e+05      -5.421755e+02 |       32
     11       6.806795e+05      -4.604824e+02 |       32
     12       6.802760e+05      -4.035517e+02 |       32
     13       6.799315e+05      -3.445191e+02 |       32
     14       6.796356e+05      -2.959032e+02 |       32
     15       6.793745e+05      -2.610579e+02 |       32
     16       6.791558e+05      -2.187608e+02 |       32
     17       6.789508e+05      -2.049783e+02 |       32
     18       6.787635e+05      -1.872390e+02 |       32
     19       6.786116e+05      -1.519268e+02 |       32
     20       6.784799e+05      -1.316854e+02 |       32
     21       6.783537e+05      -1.262565e+02 |       32
     22       6.782511e+05      -1.025874e+02 |       32
     23       6.781687e+05      -8.238368e+01 |       32
     24       6.780958e+05      -7.292239e+01 |       32
     25       6.780206e+05      -7.518460e+01 |       32
     26       6.779581e+05      -6.248939e+01 |       32
     27       6.778923e+05      -6.576574e+01 |       32
     28       6.778245e+05      -6.787420e+01 |       32
     29       6.777617e+05      -6.272242e+01 |       32
     30       6.777012e+05      -6.054312e+01 |       32
     31       6.776425e+05      -5.867574e+01 |       32
     32       6.775881e+05      -5.446204e+01 |       32
     33       6.775351e+05      -5.292517e+01 |       32
     34       6.774841e+05      -5.098680e+01 |       32
     35       6.774324e+05      -5.174052e+01 |       32
     36       6.773786e+05      -5.379478e+01 |       32
     37       6.773309e+05      -4.769743e+01 |       32
     38       6.772911e+05      -3.980640e+01 |       32
     39       6.772526e+05      -3.853232e+01 |       32
     40       6.772160e+05      -3.662167e+01 |       32
     41       6.771780e+05      -3.798718e+01 |       32
     42       6.771441e+05      -3.386572e+01 |       32
     43       6.771124e+05      -3.168485e+01 |       32
     44       6.770803e+05      -3.215865e+01 |       32
     45       6.770442e+05      -3.601896e+01 |       32
     46       6.770093e+05      -3.488476e+01 |       32
     47       6.769789e+05      -3.048647e+01 |       32
     48       6.769524e+05      -2.645608e+01 |       32
     49       6.769271e+05      -2.525837e+01 |       32
     50       6.769038e+05      -2.332923e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 676903.819774382)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426355
[ Info: iteration 2, average log likelihood -1.421433
[ Info: iteration 3, average log likelihood -1.420153
[ Info: iteration 4, average log likelihood -1.419268
[ Info: iteration 5, average log likelihood -1.418391
[ Info: iteration 6, average log likelihood -1.417556
[ Info: iteration 7, average log likelihood -1.416905
[ Info: iteration 8, average log likelihood -1.416484
[ Info: iteration 9, average log likelihood -1.416230
[ Info: iteration 10, average log likelihood -1.416068
[ Info: iteration 11, average log likelihood -1.415950
[ Info: iteration 12, average log likelihood -1.415857
[ Info: iteration 13, average log likelihood -1.415778
[ Info: iteration 14, average log likelihood -1.415709
[ Info: iteration 15, average log likelihood -1.415647
[ Info: iteration 16, average log likelihood -1.415590
[ Info: iteration 17, average log likelihood -1.415539
[ Info: iteration 18, average log likelihood -1.415492
[ Info: iteration 19, average log likelihood -1.415449
[ Info: iteration 20, average log likelihood -1.415409
[ Info: iteration 21, average log likelihood -1.415373
[ Info: iteration 22, average log likelihood -1.415339
[ Info: iteration 23, average log likelihood -1.415307
[ Info: iteration 24, average log likelihood -1.415277
[ Info: iteration 25, average log likelihood -1.415250
[ Info: iteration 26, average log likelihood -1.415224
[ Info: iteration 27, average log likelihood -1.415199
[ Info: iteration 28, average log likelihood -1.415176
[ Info: iteration 29, average log likelihood -1.415155
[ Info: iteration 30, average log likelihood -1.415134
[ Info: iteration 31, average log likelihood -1.415114
[ Info: iteration 32, average log likelihood -1.415096
[ Info: iteration 33, average log likelihood -1.415078
[ Info: iteration 34, average log likelihood -1.415061
[ Info: iteration 35, average log likelihood -1.415045
[ Info: iteration 36, average log likelihood -1.415030
[ Info: iteration 37, average log likelihood -1.415016
[ Info: iteration 38, average log likelihood -1.415002
[ Info: iteration 39, average log likelihood -1.414989
[ Info: iteration 40, average log likelihood -1.414977
[ Info: iteration 41, average log likelihood -1.414966
[ Info: iteration 42, average log likelihood -1.414955
[ Info: iteration 43, average log likelihood -1.414944
[ Info: iteration 44, average log likelihood -1.414934
[ Info: iteration 45, average log likelihood -1.414925
[ Info: iteration 46, average log likelihood -1.414916
[ Info: iteration 47, average log likelihood -1.414908
[ Info: iteration 48, average log likelihood -1.414899
[ Info: iteration 49, average log likelihood -1.414892
[ Info: iteration 50, average log likelihood -1.414884
┌ Info: EM with 100000 data points 50 iterations avll -1.414884
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.449262    -0.103324    0.386927   -0.321707    0.67667     0.029458     0.371074    0.0841344   0.256265    -0.21779    -0.031392     0.133254   -0.153835    0.51248    -0.176067    0.187446     0.0587777    1.21451      0.0201729    -0.0776      -0.20245     -0.434646   -0.0530449   0.402113   -0.182381    0.198669
  0.35867     -0.098597   -0.0460923   0.847655   -0.215945   -0.147663     0.552833   -0.180711    0.234055     0.988756    0.0557308   -0.486476   -0.133599    0.458742    0.0214095   0.639707     0.295266    -0.165864     0.201156     -0.0079073   -0.654331    -0.179099    0.149236    0.196285   -0.544878   -0.434581
 -0.192042    -0.148915    0.573444   -0.69104    -0.230593   -0.244942     0.555026    0.218807   -0.193379     0.211785    0.602632     0.548098    0.619393    0.439014   -0.133966    0.00545836  -0.0844909   -0.44958      0.0025991     0.0698542   -0.260336     0.167784    0.345494   -0.0615362  -0.430231    0.290335
 -0.254916    -0.0679142  -0.2932      0.180927   -0.0232291  -0.652532     0.360143    0.0661316  -0.247875     0.229838   -0.0811416    0.643064   -0.119862    0.180183    0.491564   -0.768552    -0.296177     0.0547045   -0.0936254     0.632402    -0.0538776   -0.266782   -0.410535    0.355492   -0.47715    -0.078861
  0.124612    -0.191391    0.523662   -0.276692    0.229812    0.00820039  -0.339286    0.269649    0.0958901   -1.03514     0.0827026    0.285042    0.407472   -0.596077   -0.101538   -0.469245    -0.110563    -0.556099    -0.0148549     0.26314      0.444503     0.0561388   0.175009   -0.131949    0.0544711   0.216472
  0.100791     0.303257    0.24524    -0.148285    0.293468   -0.370434     0.0779363   0.662479    0.60331      0.180573   -0.366674    -0.371847    0.060141    0.160363   -0.237575   -0.827786     0.100954    -0.434709     0.507325     -0.0212086    0.225314     0.0463441   0.998366    0.345245   -0.232816    0.177278
 -0.173485     0.663103    0.235967   -0.214645   -0.445024    0.389257     1.05125    -0.549057    0.029175    -0.459615   -0.690257     0.422641   -0.12331    -0.133753    0.915489    0.0739558    0.0380444   -0.0862536    0.223944     -0.325041    -0.657372     0.31137     0.998839   -0.0686726   0.0607356  -0.667545
 -0.25839     -0.0130859   0.1605     -0.263046   -0.162606   -0.0289879   -0.621913    0.0230333  -0.0819347   -0.342522   -0.00965632   0.0444059  -0.168745   -0.40574    -0.0226583  -0.308228     0.127342    -0.0131226   -0.471517      0.146718     0.333219     0.312597   -0.245306   -0.0478713   0.394952    0.224614
 -0.304451    -0.0957516  -0.144052   -0.380506   -0.0501649   0.252436    -0.477278   -0.181286   -0.159197    -0.542144    0.0971284    0.335066   -0.0556318  -0.212921    0.122612   -0.349656    -0.126553     0.126615    -0.313985      0.024592     0.316332     0.292604   -0.307873   -0.175151    0.360058   -0.115117
  0.47548     -0.0518157  -0.120013   -0.07452    -0.523141    0.597521    -0.306133   -0.0131571  -0.0903924   -0.301288   -0.0159166   -0.29045     0.0640882  -0.334314    0.106823   -0.593365     0.384962    -0.667129     0.23427      -0.0017862    0.676782     0.874966    0.0863118   0.462208    0.536675   -0.0932762
 -0.405538     0.222907    0.0738583  -0.781215   -0.269478    0.584343    -0.0126281  -0.161056   -0.194432    -0.205972   -0.35969      0.027423    0.280935    0.523324   -0.0601963  -0.40507     -0.119035     0.694517     0.351244     -0.218397     0.412871     0.481679    0.199796    0.173584    0.429729    0.783491
  0.379581     0.365003   -0.20002     0.127836   -0.858078   -0.0943026   -0.324152   -0.0869562  -0.391352     0.387499    0.152022    -0.0103649   0.0282815  -0.370443    0.19386    -0.115252    -0.37422     -1.0807       0.371223     -0.0151364   -0.106644     0.175181    0.382482   -0.760416   -0.121187    0.127602
  0.470258    -0.12932    -0.0241256   0.154846   -0.0625116   0.189056     0.285      -1.01339     0.548148    -0.259125    0.537452    -0.451094    0.0207903   0.317104    0.0809261   0.317466    -0.299106    -0.679478     0.318802     -0.438695     0.27728      0.172799    0.237789   -0.206398    0.0265303  -0.170596
  0.106033    -0.325887   -0.232929    0.343971    0.0430646  -0.561516    -0.86359     0.0476038  -0.165896     0.667644    0.769005    -0.30657     0.118496    0.328215   -0.670435    0.0908617    0.203362     0.39455     -0.372836      0.00503977   0.113852    -0.438957   -0.97799     0.306038    0.0357375   0.394006
 -0.68186      0.498876    0.487331   -0.0192562  -0.232819   -0.45996     -0.0488134  -0.303217    0.607158    -0.0624999  -0.0208163   -0.266923    0.0858655   0.35295    -0.420914   -0.249656     0.506002    -0.0893747   -0.128935      0.554368    -0.212759     0.342762    0.0957142  -0.34969     0.421758   -0.363315
 -0.0812747    0.23566    -0.192129   -0.0287282  -0.0658399   0.026614    -0.821215   -0.069611   -0.512535    -0.205991   -0.0918696    0.239878   -0.232151    0.458993    0.664104    0.0127752   -0.716454     0.16943      0.0973103    -0.801032     0.166686    -0.468012   -0.965172   -0.74122     0.411308    0.383959
  0.221858    -0.530646    0.195896   -0.398322   -0.169449    0.0913225    0.707868    0.442015    0.0917216   -0.14234     0.315208    -0.0975949   0.2818     -0.446497   -0.710949   -0.137081     0.752599    -0.153404     0.240578      0.105202    -0.336254     0.144857    0.476777    0.937664   -0.454261   -0.659723
  0.227366     0.0265668   0.0604146   0.0437884  -0.150449   -0.101789     0.126303   -0.0629113   0.00731444  -0.0127453   0.249946    -0.248471   -0.0534973  -0.131395   -0.313137    0.28868      0.243318    -0.0244836   -0.126237     -0.100448    -0.0642611    0.0451103  -0.0523266   0.0430193   0.169004   -0.14564
  0.115698    -0.921234    0.683113    0.481753   -0.753414    0.454605     0.159277   -0.408165    0.204889     0.128791   -0.366506    -0.446951   -0.836473    0.0134264   0.143306    0.421276     0.118742     0.497483    -0.202006     -0.0483813   -0.466165     0.412874    0.361471    0.675199    0.16913    -0.0142481
  0.00912243  -0.189429    0.103899    0.063418    0.505376   -0.186728     0.252458    0.5606      0.226813     0.242891    0.0171807    0.127736    0.180729   -0.0275549   0.0960943   0.542829    -0.29182      0.155245    -0.348756     -0.0324565   -0.365621    -0.611839    0.254588   -0.376895   -1.11814     0.133705
  0.0829519    0.0347454  -0.254475   -0.0574566   0.562564   -0.0223103    0.467156   -0.23842    -0.0178011   -0.284179    0.0809915    0.633548   -0.182386   -0.299808   -0.715975   -0.159299    -0.0658112    0.193864     0.137649     -0.448074     0.38291      0.53278     0.194432   -0.441654    0.442099   -0.115134
 -0.0658395   -0.154713    0.712242   -0.362222   -0.212121    0.431938    -0.288241    0.0895147   0.106991    -0.308427    0.623415    -0.475164   -0.214722    0.0499816   0.0489758   0.832947     0.0428177   -0.16603      0.000923822   0.0613766   -0.015653    -0.257977    0.0367987   0.127759    0.553044    0.744585
  0.0121701   -0.186801    0.113184    0.078998    0.110714    0.121299    -0.15982     0.121082    0.0703849    0.0356507  -0.155378    -0.0169707  -0.08407     0.0304285   0.153247   -0.186482    -0.0502673    0.0461675    0.127733     -0.0059642    0.00825012  -0.0289184   0.0605181   0.117679   -0.14574     0.261319
 -0.0554486    0.221968   -0.296111   -0.0109717  -0.0852172  -0.110119     0.484281   -0.198918    0.0227813    0.280507   -0.165705     0.10819     0.138341    0.535291    0.0171957   0.00368707  -0.0183581    0.204903     0.21841      -0.0171088   -0.251875     0.0309165   0.0691245   0.0372439  -0.111948   -0.277312
 -0.373549     0.322491    0.370544   -0.11205    -0.0730247  -0.153063    -0.276422    0.0662406  -0.0260118    0.0882811  -0.285623    -0.137063   -0.127219    0.147661    0.249341    0.145693    -0.445808     0.0805161   -0.603738      0.21133      0.102231    -0.123855    0.308065   -0.619345   -0.0833748   0.292921
 -0.684593    -0.0547505   0.0518876   0.441848    0.319564   -0.338332    -0.447243    0.597626   -0.0934096    0.0581716  -0.415641     0.245146   -0.099826   -0.175557   -0.201805   -0.0126715    0.713206     0.281615    -0.272879      0.182403    -0.678212    -0.157162   -0.221761    0.222004   -0.116757    0.0668537
 -0.275694    -0.195944   -0.602332   -0.367588   -0.693538   -0.471011     0.0228805  -0.299731   -0.367972     0.835912    0.147257    -0.608318   -0.385       0.120004   -0.145917    0.209587     0.383694     0.274392    -0.0330869    -0.354344    -0.297427     0.415872   -0.122131    0.416992    0.34268    -0.0886821
  0.15245      0.198232   -0.369656    0.833298    0.21255     0.116525    -0.446461   -0.231122    0.306238    -0.113725   -0.669654    -0.527178   -0.725776   -0.211843    0.316467    0.0071203   -0.302199     0.530006    -0.219402      0.113893     0.402204     0.0723763  -0.164295   -0.213861    0.305789   -0.0998129
  0.118353     0.479408   -0.462474   -0.212215    0.566565    0.285657     0.256777    0.100552    0.284494    -0.229698    0.132377     0.378815    0.891806    0.803582   -0.219867   -0.299954     0.00843844   0.00825925   0.402183     -0.167836     0.33516     -0.0206678  -0.11859    -0.125466    0.358393   -0.299356
  0.317083    -0.11712    -0.0242715   0.395507    0.223176   -0.287289    -0.278489    0.403344    0.0744788    0.0579406   0.242611    -0.0249956  -0.0385273  -0.616568    0.042032    0.278942     0.546179    -0.471752    -0.533417      0.1037      -0.18153     -0.252912   -0.0755518   0.0465071  -0.354597   -0.366537
  0.999804    -0.210348   -0.158436    0.196286    0.229932    0.312272     0.0454899   0.269468   -0.281921     0.11329     0.0962383   -0.164788    0.155131   -0.0217804   0.0921825  -0.122187    -0.368456     0.0450818    0.730264     -0.127862    -0.0973939   -0.451213   -0.147167    0.428476   -0.487416    0.179131
  0.0972261   -0.229278    0.160518   -0.137587   -0.0928274   0.593809     0.100794   -0.733351   -0.383972    -0.221346    0.232692     0.470701    0.0562218  -0.175522    0.226136    0.719573    -0.0995864    0.61824     -0.571906     -0.1117      -0.227379     0.0437248  -0.839542   -0.260482    0.204536   -0.555689[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414877
[ Info: iteration 2, average log likelihood -1.414870
[ Info: iteration 3, average log likelihood -1.414864
[ Info: iteration 4, average log likelihood -1.414857
[ Info: iteration 5, average log likelihood -1.414851
[ Info: iteration 6, average log likelihood -1.414845
[ Info: iteration 7, average log likelihood -1.414839
[ Info: iteration 8, average log likelihood -1.414834
[ Info: iteration 9, average log likelihood -1.414829
[ Info: iteration 10, average log likelihood -1.414823
┌ Info: EM with 100000 data points 10 iterations avll -1.414823
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
