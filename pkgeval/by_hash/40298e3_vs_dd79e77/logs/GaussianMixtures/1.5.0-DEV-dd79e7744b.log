Julia Version 1.5.0-DEV.60
Commit dd79e7744b (2020-01-13 21:12 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed HDF5 ─────────────── v0.12.5
 Installed BinaryProvider ───── v0.5.8
 Installed Clustering ───────── v0.13.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed NearestNeighbors ─── v0.4.4
 Installed BinDeps ──────────── v1.0.0
 Installed Blosc ────────────── v0.5.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Arpack_jll ───────── v3.5.0+2
 Installed StatsBase ────────── v0.32.0
 Installed QuadGK ───────────── v2.3.1
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed Compat ───────────── v2.2.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
 Installed DataAPI ──────────── v1.1.0
 Installed StaticArrays ─────── v0.12.1
 Installed PDMats ───────────── v0.9.10
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed JLD ──────────────── v0.9.1
 Installed DataStructures ───── v0.17.7
 Installed SpecialFunctions ─── v0.9.0
 Installed SortingAlgorithms ── v0.3.1
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed Distributions ────── v0.22.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.1
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_Xx6iL4/Project.toml`
 [no changes]
  Updating `/tmp/jl_Xx6iL4/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_wHgaJw/Project.toml`
 [no changes]
  Updating `/tmp/jl_wHgaJw/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_lI2Gu6/Project.toml`
 [no changes]
  Updating `/tmp/jl_lI2Gu6/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_cG61F3/Project.toml`
 [no changes]
  Updating `/tmp/jl_cG61F3/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_lNlKLm/Project.toml`
 [no changes]
  Updating `/tmp/jl_lNlKLm/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_lNlKLm/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.1
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -824724.1011329025, [73080.42977604984, 26919.57022395017], [1497.9804263671283 -16485.63152236756 10214.578285914991; -1295.4986252988901 16163.989808006037 -10110.178460078083], [[77697.66848138336 -6397.7345895748995 -621.1145403943127; -6397.7345895748995 83868.45079547072 -739.28561939051; -621.1145403943127 -739.28561939051 70015.04389614132], [21821.49540283327 6445.590211058357 624.0036305839728; 6445.590211058357 16317.604955167553 450.56097912274026; 624.0036305839728 450.56097912274026 29570.93249365296]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.142169e+03
      1       1.278076e+03      -8.640926e+02 |        8
      2       9.218286e+02      -3.562476e+02 |        6
      3       8.903292e+02      -3.149941e+01 |        4
      4       8.623386e+02      -2.799056e+01 |        0
      5       8.623386e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 862.3386181567757)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.081917
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.910535
[ Info: iteration 2, lowerbound -3.788673
[ Info: iteration 3, lowerbound -3.634069
[ Info: iteration 4, lowerbound -3.424072
[ Info: iteration 5, lowerbound -3.180574
[ Info: iteration 6, lowerbound -2.946381
[ Info: iteration 7, lowerbound -2.761216
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.635400
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.544530
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.464988
[ Info: iteration 11, lowerbound -2.410864
[ Info: iteration 12, lowerbound -2.377368
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.343672
[ Info: iteration 14, lowerbound -2.317875
[ Info: iteration 15, lowerbound -2.307735
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.303012
[ Info: iteration 17, lowerbound -2.299262
[ Info: iteration 18, lowerbound -2.299257
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 14 11:13:21 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 14 11:13:29 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Jan 14 11:13:31 2020: EM with 272 data points 0 iterations avll -2.081917
5.8 data points per parameter
, Tue Jan 14 11:13:33 2020: GMM converted to Variational GMM
, Tue Jan 14 11:13:42 2020: iteration 1, lowerbound -3.910535
, Tue Jan 14 11:13:42 2020: iteration 2, lowerbound -3.788673
, Tue Jan 14 11:13:42 2020: iteration 3, lowerbound -3.634069
, Tue Jan 14 11:13:42 2020: iteration 4, lowerbound -3.424072
, Tue Jan 14 11:13:42 2020: iteration 5, lowerbound -3.180574
, Tue Jan 14 11:13:42 2020: iteration 6, lowerbound -2.946381
, Tue Jan 14 11:13:42 2020: iteration 7, lowerbound -2.761216
, Tue Jan 14 11:13:42 2020: dropping number of Gaussions to 7
, Tue Jan 14 11:13:42 2020: iteration 8, lowerbound -2.635400
, Tue Jan 14 11:13:42 2020: dropping number of Gaussions to 5
, Tue Jan 14 11:13:42 2020: iteration 9, lowerbound -2.544530
, Tue Jan 14 11:13:42 2020: dropping number of Gaussions to 4
, Tue Jan 14 11:13:42 2020: iteration 10, lowerbound -2.464988
, Tue Jan 14 11:13:42 2020: iteration 11, lowerbound -2.410864
, Tue Jan 14 11:13:42 2020: iteration 12, lowerbound -2.377368
, Tue Jan 14 11:13:42 2020: dropping number of Gaussions to 3
, Tue Jan 14 11:13:42 2020: iteration 13, lowerbound -2.343672
, Tue Jan 14 11:13:42 2020: iteration 14, lowerbound -2.317875
, Tue Jan 14 11:13:42 2020: iteration 15, lowerbound -2.307735
, Tue Jan 14 11:13:42 2020: dropping number of Gaussions to 2
, Tue Jan 14 11:13:42 2020: iteration 16, lowerbound -2.303012
, Tue Jan 14 11:13:42 2020: iteration 17, lowerbound -2.299262
, Tue Jan 14 11:13:42 2020: iteration 18, lowerbound -2.299257
, Tue Jan 14 11:13:42 2020: iteration 19, lowerbound -2.299255
, Tue Jan 14 11:13:42 2020: iteration 20, lowerbound -2.299254
, Tue Jan 14 11:13:42 2020: iteration 21, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 22, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 23, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 24, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 25, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 26, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 27, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 28, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 29, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 30, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 31, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 32, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 33, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 34, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 35, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 36, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 37, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 38, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 39, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 40, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 41, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 42, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 43, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 44, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 45, lowerbound -2.299253
, Tue Jan 14 11:13:42 2020: iteration 46, lowerbound -2.299253
, Tue Jan 14 11:13:43 2020: iteration 47, lowerbound -2.299253
, Tue Jan 14 11:13:43 2020: iteration 48, lowerbound -2.299253
, Tue Jan 14 11:13:43 2020: iteration 49, lowerbound -2.299253
, Tue Jan 14 11:13:43 2020: iteration 50, lowerbound -2.299253
, Tue Jan 14 11:13:43 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398624, 178.0450922260138]
β = [95.95490777398624, 178.0450922260138]
m = [2.0002292577753713 53.8519871724613; 4.250300733269911 79.28686694436185]
ν = [97.95490777398624, 180.0450922260138]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484036 -0.008953123827346102; 0.0 0.012748664777409421], [0.18404155547484669 -0.007644049042327279; 0.0 0.00858170516633346]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0023353327773492
avll from llpg:  -1.0023353327773366
avll direct:     -1.0023353327773366
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9806668182048486
avll from llpg:  -0.9806668182048488
avll direct:     -0.9806668182048488
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0464979   -0.0877683    0.158542    -0.0514269    0.108711    -0.0223903    0.0614169    0.0322852   -0.0911948    0.0220543   -0.0667348    -0.112212   -0.057445     0.0406737  -0.104989    0.0964531    0.00495829  -0.0747583    0.0709526   -0.169409    -0.162096     0.141106     0.0367531    0.14609      0.191756   -0.0375574
  0.062233     0.184871     0.052478    -0.0543824    0.00203582  -0.112826    -0.0465498   -0.0661265   -0.0590669   -0.00275299  -0.0212257     0.121467   -0.0240771   -0.0253973  -0.140634   -0.0959553    0.0832539    0.0871645   -0.0352277    0.199992     0.0414154    0.228936     0.00493234  -0.188056    -0.120555    0.163379
  0.0258146   -0.00664212  -0.00396341   0.2735      -0.198905     0.0360047   -0.0243112   -0.015208    -0.23212      0.109221    -0.095952      0.0093109  -0.153816    -0.137833   -0.0415389  -0.0405165   -0.021346    -0.10894      0.0144394    0.167342     0.00756367  -0.0751934    0.0618451    0.0741874   -0.0734362   0.0749895
  0.1551       0.104233    -0.0851979   -0.14137      0.068467    -0.00140588   0.0181075   -0.0491978   -0.159003    -0.0067381    0.0285079    -0.150607   -0.0649573    0.048416   -0.0337308   0.0841303   -0.142816    -0.0693791   -0.00350379  -0.0727085   -0.0166782    0.130326     0.0325265    0.0149263    0.0293053   0.135088
 -0.0288322    0.111189     0.112912     0.0166332    0.125055    -0.0114358    0.0198546    0.0620045    0.0749149   -0.0262735    0.0126139    -0.140404   -0.0149036    0.147266   -0.0464296  -0.14576     -0.103081     0.0301344   -0.0317555    0.0683622    0.0800551   -0.0314549   -0.016782    -0.00902841  -0.0841468  -0.0259216
  0.00621815   0.01868      0.117778     0.007766    -0.0988376   -0.243069    -0.0279543    0.00765165   0.0732474    0.223619     0.0157178    -0.0543241   0.0343891    0.0817977  -0.0496452   0.169114     0.061896    -0.00373494  -0.0344144    0.0674187   -0.0287983    0.0313604   -0.0397554   -0.017516    -0.015139   -0.00103067
 -0.0471444    0.12414      0.0680665   -0.146875    -0.0120286   -0.0347118   -0.233291     0.100198    -0.0491412    0.00569349   0.0671906    -0.0904319   0.0604522    0.145557   -0.0874212  -0.243689    -0.204485     0.0470487    0.0320863   -0.0303931   -0.108283    -0.124526     0.0448592    0.0457714   -0.0464669   0.00906441
 -0.122691    -0.0307521    0.0145159   -0.0183537    0.0528421    0.0047552   -0.119185     0.00391775  -0.0491317    0.0106177   -0.070887      0.105712   -0.259254     0.0425034   0.0822716  -0.0452199    0.169979     0.0974854   -0.139887    -0.060458    -0.114135     0.04167      0.046601    -0.0758903   -0.0270277  -0.0830015
 -0.0437903    0.137184    -0.0626293   -0.0614874   -0.240217    -0.0442206    0.0548308    0.0649648    0.116858    -0.0925249   -0.0926163    -0.22253    -0.0622732   -0.0639763   0.0853623  -0.0760442    0.032408    -0.190609    -0.00709268  -0.0303812   -0.152034    -0.0726211   -0.0046825    0.0440604   -0.03611     0.0377849
  0.18454     -0.0950227   -0.06327      0.149325     0.0668797   -0.107355     0.134154     0.0251607    0.131287     0.0905559    0.0276008     0.0990677   0.0603805    0.0978733   0.0901033   0.00730428   0.0734409   -0.188947    -0.0989448   -0.134415    -0.200296     0.0305226   -0.00762967   0.0157905    0.11389    -0.0537443
 -0.0693135    0.00594543   0.021222    -0.133756    -0.117044    -0.128298    -0.106986     0.0250641    0.0686741   -0.0623879   -0.123024      0.152483   -0.00115589   0.0410464   0.0564527  -0.055368    -0.0835743   -0.0668749   -0.0513006   -0.0707386    0.0318274    0.0846195    0.136601    -0.057462     0.11448     0.102853
  0.05192      0.00824696  -0.0546046    0.124435     0.0776134    0.197619    -0.0116826   -0.00582085  -0.0098706   -0.0722712   -0.0513518    -0.1316      0.0520332    0.0944097   0.0283953  -0.0876211   -0.118409    -0.00757421   0.0133145    0.142315    -0.0747678    0.0414851    0.0182758    0.0301175    0.0126576   0.200938
  0.0793556   -0.0899456    0.0566287    0.0304588    0.00468619   0.00245176   0.0230132    0.0120269   -0.184502    -0.0803173   -0.0734566     0.0151415  -0.155982    -0.0593887  -0.0454461   0.0637749   -0.0335022    0.0618612   -0.122933    -0.0447337    0.00133261  -0.171484     0.0327109   -0.00412657   0.0209168   0.0807198
  0.18443      0.0851782   -0.0946953   -0.0101738   -0.161115    -0.0332073   -0.0304726   -0.11416     -0.00160553  -0.0848648    0.0982344     0.0184577  -0.0462216   -0.0695413  -0.133695   -0.0279703   -0.0729452    0.21921      0.0133273    0.0890592    0.106468     0.037709     0.0415465   -0.0588305   -0.167665    0.0535586
  0.046427    -0.10154      0.24486     -0.0597992    0.0620262   -0.193164    -0.0762575    0.0800747    0.0604389   -0.00107221  -0.134766     -0.094761    0.0310833   -0.0372516   0.0700091  -0.0586987   -0.010039    -0.0567157   -0.0392016    0.0869423    0.0116339    0.0997907   -0.0760635   -0.125043    -0.0129837   0.0414756
 -0.0481266   -0.0323016    0.0574852    0.0598395   -0.17162      0.142936     0.0924663   -0.0327181   -0.0151852    0.0719082    0.0437554    -0.148314    0.0534562   -0.0215647   0.0959425  -0.122604    -0.212515     0.00917278  -0.0218237    0.067477     0.0942107   -0.109105     0.0381497   -0.293675     0.080257    0.0396087
  0.0075506    0.0185159    0.0198297   -0.0855051   -0.0960337   -0.166795     0.00277456   0.0838668   -0.0223867    0.105741    -0.0121643    -0.169023    0.0958654   -0.0761458   0.170497    0.00141077   0.048915    -0.0792625   -0.129992     0.0353444    0.00708611   0.19026      0.00457121   0.0167152   -0.0247949   0.0698012
  0.0786348    0.18575      0.0653333   -0.118233     0.122149    -0.0798085    0.109901     0.0210135    0.0560878    0.00360188  -0.000645638   0.0861848  -0.00975315   0.0602476  -0.006539   -0.0605487   -0.0342082   -0.10121      0.0165401    0.0311333    0.0242112   -0.118721     0.0358031   -0.0797898    0.0623922   0.0145948
  0.0600608   -0.0458449    0.0277247   -0.0651485   -0.113623    -0.029855     0.13903      0.106049    -0.162893    -0.0657749    0.0738308    -0.0356433  -0.123024     0.004611   -0.0364191   0.0441455    0.068949    -0.00810272  -0.0254836   -0.0203301   -0.111988     0.164958    -0.0313221    0.0635427    0.0167397  -0.0947802
  0.127984     0.0417704    0.109949    -0.0306563   -0.0978451    0.16725     -0.063148     0.13371     -0.140579     0.113135    -0.037496     -0.251777   -0.15661     -0.081307    0.0822568   0.109823     0.098334    -0.12632     -0.0100273    0.0596159    0.0591025    0.0296807   -0.0353754    0.129986    -0.188537    0.0126736
  0.119925     0.0100827    0.173715     0.157932    -0.0874511   -0.0974365    0.14747     -0.12761      0.0123175    0.0113851    0.064559      0.024015   -0.0124978   -0.0348994  -0.0281064   0.135463     0.233546     0.0078484    0.173148    -0.0919936   -0.0236933   -0.00441928   0.119594    -0.0533034   -0.0162127   0.0359334
 -0.0607521    0.122914     0.0292221   -0.150286     0.00500692   0.067493    -0.00592691  -0.147785     0.0579419   -0.0275561    0.00880508   -0.129274    0.0884385    0.0463051   0.040071    0.127714    -0.237279    -0.103247    -0.0943878    0.00306294  -0.0586395   -0.098521    -0.0547932    0.0627761   -0.016954   -0.130056
 -0.0127726   -0.0592916    0.171094     0.035032     0.0854989    0.0149801    0.0384465   -0.119664    -0.0783982   -0.0386382    0.0962629     0.0530267   0.108976    -0.0388359   0.115034   -0.0546518   -0.196407    -0.016565    -0.11058      0.0614126    0.226223     0.0332063   -0.0190841   -0.112471     0.151835   -0.012105
 -0.0275234    0.022972     0.11453      0.113593     0.0937991    0.080176     0.015181     0.0432078   -0.0553605    0.087652     0.117108      0.117487    0.0389912   -0.0241298  -0.0299328   0.0255905    0.0925857    0.139664    -0.112375     0.027615     0.375171     0.196087    -0.0156747   -0.0505594    0.131701    0.0348082
 -0.0521403    0.13103     -0.0176252   -0.0476936   -0.092897    -0.0144085    0.105218     0.0914619   -0.0618662    0.0847215    0.0136451     0.0313909   0.0751883    0.0764213  -0.110879   -0.111527     0.115603     0.122997     0.0251337    0.105628    -0.157444     0.0429953    0.104745    -0.0711563    0.018055   -0.106238
  0.0733073    0.0155453    0.00390784   0.0287293   -0.0141559   -0.0596619   -0.0539183   -0.0199595   -0.0381086   -0.101837     0.0587462    -0.123626   -0.263835     0.0764939  -0.257818   -0.0486887    0.0947198    0.00884016   0.043419     0.00532467   0.0392621   -0.121478     0.167985    -0.0822316    0.0280517   0.0551455
  0.0708389   -0.170721     0.0358652   -0.0842166    0.0522403   -0.0861902    0.237395    -0.0659314    0.0462112   -0.0868796    0.000412274  -0.052424   -0.162011    -0.0994152  -0.128239   -0.0150142   -0.0940832    0.0818572   -0.142357     0.0322653   -0.0172211   -0.0980959    0.0949985    0.155707     0.0166516  -0.0169203
 -0.030511     0.0405506    0.0860425    0.0586898   -0.0459805    0.0791128   -0.098978     0.0661276    0.08235      0.0754133   -0.0121508    -0.0893551   0.0993107    0.064334    0.0255562   0.0403478    0.0709633   -0.0873057    0.0443633    0.0360754   -0.0598736    0.166954     0.0816406    0.0648517    0.0113104  -0.0779535
 -0.196759     0.0970881   -0.0523252    0.00742379   0.00535501  -0.100072    -0.00400053   0.0847706    0.232899    -0.13427      0.00565945   -0.0396533   0.125006     0.0466916   0.0327253  -0.0493453   -0.16276     -0.103173     0.126771    -0.274968    -0.0293826    0.160365    -0.00562686  -0.0489126    0.0978292  -0.169659
  0.0379562    0.182742     0.0688821    0.100048    -0.139941     0.0186767   -0.00235266  -0.0689891    0.00759764   0.172178     0.0396854    -0.0421196   0.0370321    0.0689802  -0.154278   -0.0441696    0.0255643   -0.0995917    0.0342879    0.020246    -0.0326779   -0.0122538    0.110457     0.0224609   -0.118756   -0.0561574
  0.0369881    0.152666    -0.0157931    0.00362373   0.108177     0.121949     0.0561615    0.168191     0.163241     0.127625    -0.0814632    -0.0764376   0.0174486   -0.163849    0.103268    0.0641883    0.0422846   -0.0105935    0.0103327   -0.139675    -0.190906    -0.0996613    0.134881     0.0441508    0.0900838   0.0390707
 -0.0248697    0.0580805   -0.113381     0.0768235   -0.0291222    0.00487732  -0.0236539   -0.0132979   -0.00350209  -0.0266428    0.00849255   -0.0293984   0.0487648   -0.115893   -0.0766062  -0.086802    -0.0155805   -0.109795    -0.0632364    0.101886     0.0987405   -0.0653674   -0.149257    -0.0865782    0.0343269   0.148513kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4275335075782338
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427599
[ Info: iteration 2, average log likelihood -1.427534
[ Info: iteration 3, average log likelihood -1.427109
[ Info: iteration 4, average log likelihood -1.422764
[ Info: iteration 5, average log likelihood -1.411462
[ Info: iteration 6, average log likelihood -1.404584
[ Info: iteration 7, average log likelihood -1.401940
[ Info: iteration 8, average log likelihood -1.400213
[ Info: iteration 9, average log likelihood -1.398988
[ Info: iteration 10, average log likelihood -1.398037
[ Info: iteration 11, average log likelihood -1.397287
[ Info: iteration 12, average log likelihood -1.396735
[ Info: iteration 13, average log likelihood -1.396371
[ Info: iteration 14, average log likelihood -1.396134
[ Info: iteration 15, average log likelihood -1.395965
[ Info: iteration 16, average log likelihood -1.395830
[ Info: iteration 17, average log likelihood -1.395713
[ Info: iteration 18, average log likelihood -1.395604
[ Info: iteration 19, average log likelihood -1.395497
[ Info: iteration 20, average log likelihood -1.395392
[ Info: iteration 21, average log likelihood -1.395294
[ Info: iteration 22, average log likelihood -1.395205
[ Info: iteration 23, average log likelihood -1.395121
[ Info: iteration 24, average log likelihood -1.395037
[ Info: iteration 25, average log likelihood -1.394952
[ Info: iteration 26, average log likelihood -1.394861
[ Info: iteration 27, average log likelihood -1.394768
[ Info: iteration 28, average log likelihood -1.394671
[ Info: iteration 29, average log likelihood -1.394577
[ Info: iteration 30, average log likelihood -1.394491
[ Info: iteration 31, average log likelihood -1.394410
[ Info: iteration 32, average log likelihood -1.394333
[ Info: iteration 33, average log likelihood -1.394259
[ Info: iteration 34, average log likelihood -1.394189
[ Info: iteration 35, average log likelihood -1.394125
[ Info: iteration 36, average log likelihood -1.394071
[ Info: iteration 37, average log likelihood -1.394024
[ Info: iteration 38, average log likelihood -1.393983
[ Info: iteration 39, average log likelihood -1.393947
[ Info: iteration 40, average log likelihood -1.393915
[ Info: iteration 41, average log likelihood -1.393887
[ Info: iteration 42, average log likelihood -1.393864
[ Info: iteration 43, average log likelihood -1.393847
[ Info: iteration 44, average log likelihood -1.393834
[ Info: iteration 45, average log likelihood -1.393825
[ Info: iteration 46, average log likelihood -1.393818
[ Info: iteration 47, average log likelihood -1.393813
[ Info: iteration 48, average log likelihood -1.393809
[ Info: iteration 49, average log likelihood -1.393806
[ Info: iteration 50, average log likelihood -1.393803
┌ Info: EM with 100000 data points 50 iterations avll -1.393803
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4275987865267268
│     -1.4275344934347078
│      ⋮
└     -1.3938033343921319
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.393928
[ Info: iteration 2, average log likelihood -1.393808
[ Info: iteration 3, average log likelihood -1.393306
[ Info: iteration 4, average log likelihood -1.388397
[ Info: iteration 5, average log likelihood -1.373862
[ Info: iteration 6, average log likelihood -1.363523
[ Info: iteration 7, average log likelihood -1.360108
[ Info: iteration 8, average log likelihood -1.358471
[ Info: iteration 9, average log likelihood -1.357490
[ Info: iteration 10, average log likelihood -1.356984
[ Info: iteration 11, average log likelihood -1.356719
[ Info: iteration 12, average log likelihood -1.356538
[ Info: iteration 13, average log likelihood -1.356368
[ Info: iteration 14, average log likelihood -1.356196
[ Info: iteration 15, average log likelihood -1.356024
[ Info: iteration 16, average log likelihood -1.355858
[ Info: iteration 17, average log likelihood -1.355708
[ Info: iteration 18, average log likelihood -1.355575
[ Info: iteration 19, average log likelihood -1.355460
[ Info: iteration 20, average log likelihood -1.355363
[ Info: iteration 21, average log likelihood -1.355286
[ Info: iteration 22, average log likelihood -1.355226
[ Info: iteration 23, average log likelihood -1.355180
[ Info: iteration 24, average log likelihood -1.355143
[ Info: iteration 25, average log likelihood -1.355113
[ Info: iteration 26, average log likelihood -1.355089
[ Info: iteration 27, average log likelihood -1.355068
[ Info: iteration 28, average log likelihood -1.355050
[ Info: iteration 29, average log likelihood -1.355034
[ Info: iteration 30, average log likelihood -1.355020
[ Info: iteration 31, average log likelihood -1.355005
[ Info: iteration 32, average log likelihood -1.354991
[ Info: iteration 33, average log likelihood -1.354976
[ Info: iteration 34, average log likelihood -1.354959
[ Info: iteration 35, average log likelihood -1.354941
[ Info: iteration 36, average log likelihood -1.354923
[ Info: iteration 37, average log likelihood -1.354903
[ Info: iteration 38, average log likelihood -1.354883
[ Info: iteration 39, average log likelihood -1.354862
[ Info: iteration 40, average log likelihood -1.354839
[ Info: iteration 41, average log likelihood -1.354814
[ Info: iteration 42, average log likelihood -1.354789
[ Info: iteration 43, average log likelihood -1.354763
[ Info: iteration 44, average log likelihood -1.354737
[ Info: iteration 45, average log likelihood -1.354710
[ Info: iteration 46, average log likelihood -1.354682
[ Info: iteration 47, average log likelihood -1.354655
[ Info: iteration 48, average log likelihood -1.354628
[ Info: iteration 49, average log likelihood -1.354601
[ Info: iteration 50, average log likelihood -1.354574
┌ Info: EM with 100000 data points 50 iterations avll -1.354574
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3939275052870537
│     -1.393808041931867
│      ⋮
└     -1.3545740186196835
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.354701
[ Info: iteration 2, average log likelihood -1.354527
[ Info: iteration 3, average log likelihood -1.354036
[ Info: iteration 4, average log likelihood -1.349552
[ Info: iteration 5, average log likelihood -1.333809
[ Info: iteration 6, average log likelihood -1.319284
[ Info: iteration 7, average log likelihood -1.312912
[ Info: iteration 8, average log likelihood -1.309354
[ Info: iteration 9, average log likelihood -1.307048
[ Info: iteration 10, average log likelihood -1.305851
[ Info: iteration 11, average log likelihood -1.305125
[ Info: iteration 12, average log likelihood -1.304364
[ Info: iteration 13, average log likelihood -1.303397
[ Info: iteration 14, average log likelihood -1.302281
[ Info: iteration 15, average log likelihood -1.301127
[ Info: iteration 16, average log likelihood -1.300053
[ Info: iteration 17, average log likelihood -1.299035
[ Info: iteration 18, average log likelihood -1.298001
[ Info: iteration 19, average log likelihood -1.297083
[ Info: iteration 20, average log likelihood -1.296412
[ Info: iteration 21, average log likelihood -1.295999
[ Info: iteration 22, average log likelihood -1.295742
[ Info: iteration 23, average log likelihood -1.295573
[ Info: iteration 24, average log likelihood -1.295450
[ Info: iteration 25, average log likelihood -1.295354
[ Info: iteration 26, average log likelihood -1.295272
[ Info: iteration 27, average log likelihood -1.295194
[ Info: iteration 28, average log likelihood -1.295112
[ Info: iteration 29, average log likelihood -1.295027
[ Info: iteration 30, average log likelihood -1.294937
[ Info: iteration 31, average log likelihood -1.294851
[ Info: iteration 32, average log likelihood -1.294777
[ Info: iteration 33, average log likelihood -1.294716
[ Info: iteration 34, average log likelihood -1.294665
[ Info: iteration 35, average log likelihood -1.294619
[ Info: iteration 36, average log likelihood -1.294575
[ Info: iteration 37, average log likelihood -1.294529
[ Info: iteration 38, average log likelihood -1.294478
[ Info: iteration 39, average log likelihood -1.294418
[ Info: iteration 40, average log likelihood -1.294344
[ Info: iteration 41, average log likelihood -1.294248
[ Info: iteration 42, average log likelihood -1.294122
[ Info: iteration 43, average log likelihood -1.293959
[ Info: iteration 44, average log likelihood -1.293759
[ Info: iteration 45, average log likelihood -1.293540
[ Info: iteration 46, average log likelihood -1.293336
[ Info: iteration 47, average log likelihood -1.293161
[ Info: iteration 48, average log likelihood -1.293019
[ Info: iteration 49, average log likelihood -1.292913
[ Info: iteration 50, average log likelihood -1.292838
┌ Info: EM with 100000 data points 50 iterations avll -1.292838
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3547010703551319
│     -1.354527307029633
│      ⋮
└     -1.2928376848219711
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.292977
[ Info: iteration 2, average log likelihood -1.292673
[ Info: iteration 3, average log likelihood -1.290201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.266726
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.238224
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.229396
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.212753
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.209730
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.200474
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.224320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.219470
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.196886
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.215424
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.205996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.206279
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.186166
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.243815
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.224696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.201322
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.207137
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.198581
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.211572
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.214390
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.220669
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.207117
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.199887
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.205305
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.208636
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.219008
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.206471
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.217394
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.204963
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.186300
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.227665
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.217572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.214099
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.193364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.217021
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.215495
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.205116
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.207281
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.209617
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.208268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.201798
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.213112
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.221070
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.203690
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.207624
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.210767
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.209341
┌ Info: EM with 100000 data points 50 iterations avll -1.209341
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.292976876071551
│     -1.2926734312433148
│      ⋮
└     -1.209341073879014
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     21
│     22
│     23
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.201907
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     21
│     22
│     23
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.195550
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      9
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190394
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.172181
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.145391
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.133113
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.127165
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105530
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.119089
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.101884
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.106283
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.105904
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.108348
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.094783
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.114527
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.098532
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.104131
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.104747
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.107766
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.094117
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.114029
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.097596
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.103224
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.103776
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.106771
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.093170
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.113508
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.097045
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.102980
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.103730
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.106727
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.093142
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.113507
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.097030
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.102966
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.103727
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.106718
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.093134
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.113503
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.097025
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.102962
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.103723
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.106714
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.093131
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.113500
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097022
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.102959
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.103720
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.106712
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.093128
┌ Info: EM with 100000 data points 50 iterations avll -1.093128
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2019071163271984
│     -1.195549909620924
│      ⋮
└     -1.0931280398965988
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4275335075782338
│     -1.4275987865267268
│     -1.4275344934347078
│     -1.4271092769757898
│      ⋮
│     -1.1037200547605983
│     -1.1067116739929863
└     -1.0931280398965988
32×26 Array{Float64,2}:
 -0.0433254   0.114508      0.0784589   -0.14251     -0.0626771  -0.032477    -0.199516     0.0824893    -0.059124     0.0106035    0.0664181   -0.101264     0.0700417     0.145514   -0.0901082   -0.219677    -0.200141     0.0431218    0.0319358  -0.00990313   -0.0976183   -0.117314     0.00351416   0.0484411   -0.045918    -0.0317926
  0.0582237  -0.162984      0.0565906   -0.0829188    0.0232816  -0.0980301    0.2238      -0.0690515     0.053112    -0.0306162    0.00319449  -0.0580853   -0.144534     -0.102086   -0.143095    -0.0361088   -0.103334     0.0694231   -0.138982   -0.0048641    -0.0160268   -0.099244     0.0706547    0.15063      0.0178241   -0.0144697
  0.0807746  -0.289359      0.0581953    0.0294899   -0.0626998   0.0913715    0.0275234    0.12542      -0.146481    -0.0861857   -0.0712339    0.0647944   -0.236114     -0.662931   -0.0135834    0.192796    -0.0506115    0.0576741   -0.112315    0.135331     -0.00309255  -0.169591     0.0373784    0.113954     0.022272     0.0803086
  0.0828028   0.0973016     0.0592602    0.0302642    0.0307465  -0.0518473    0.0252515   -0.129728     -0.207983    -0.0726418   -0.0740666   -0.00858743  -0.124333      0.545701   -0.0777141    0.0241261   -0.0323848    0.0636747   -0.129208   -0.199147      0.0294704   -0.184729     0.0278357   -0.016876     0.0165644    0.0803717
 -0.112949   -0.0344032     0.0160221   -0.0174466    0.037404   -0.00217497  -0.120788     0.00842427   -0.0487491   -0.00250726  -0.0500268    0.0996479   -0.26717       0.0349111   0.0674298   -0.0603003    0.170158     0.0919814   -0.105551   -0.0462819    -0.118533     0.0346744    0.0556971   -0.150861    -0.0329746   -0.083204
  0.136755    0.0247997    -0.0425946   -0.0195913   -0.140626   -0.0574698    0.0457923    0.000305893  -0.10701     -0.0814818    0.0765459   -0.010853    -0.0460824    -0.03467    -0.0865291    0.0145567   -0.0156183    0.105703    -0.0112896   0.0553999    -0.00042558   0.0947377    0.00912206   0.00169818  -0.0768718   -0.009067
 -0.0225159   0.0633993    -0.108194     0.0552811   -0.0481857   0.00941328  -0.026686    -0.0134562     0.00274866  -0.0266159    0.0080438   -0.0288036    0.0272524    -0.179941   -0.123476    -0.0832349    0.0202706   -0.106267    -0.051431    0.0623573     0.0778298   -0.0789166   -0.154271    -0.0831265    0.048198     0.155406
  0.16312    -0.0973669    -0.0575577    0.173629     0.0612127  -0.12174      0.109773     0.0439005     0.123275     0.0977255    0.0381485    0.098364     0.0731935     0.109005    0.133045     0.00738998   0.0731943   -0.192697    -0.113332   -0.129996     -0.196345     0.0282716   -0.0109992    0.0736687    0.111253    -0.0505992
  0.126321    0.00540939    0.151551     0.132906    -0.0879921  -0.100068     0.15592     -0.125476     -0.0130351   -0.00742649   0.0643851    0.0163749   -0.0122147    -0.0385604  -0.0367939    0.127364     0.228221     0.0349923    0.184147   -0.131815     -0.0410399   -0.00677067   0.109147    -0.067346    -0.0171172    0.0335196
  0.128163    0.0581678     0.106704    -0.00931408  -0.0982706   0.160044    -0.0292427    0.132593     -0.139049     0.128494    -0.0478066   -0.25385     -0.190992     -0.0848223   0.0943967    0.125602     0.0977642   -0.151763     0.0106669   0.0311555     0.0378723    0.0236351    0.0237269    0.140078    -0.201722     0.0162753
  0.072741    0.0142911     0.0125339    0.00730991  -0.0143168  -0.0582909   -0.0655027   -0.0149961    -0.048499    -0.100669     0.060036    -0.122888    -0.280373      0.0637226  -0.16872     -0.0501479    0.0888823   -0.00556765   0.0474131  -0.000858906   0.0214921   -0.11519      0.178055    -0.0701179    0.039428    -0.016913
  0.0801108   0.196803      0.103886    -0.0848184    0.120524   -0.0801132    0.0946127    0.0568609     0.0375765   -0.00858365  -0.001239     0.10409     -0.00906107    0.0783302   0.0120671   -0.0468772   -0.0581627   -0.083451     0.0198029   0.0110974     0.0207353   -0.159229     0.0594609   -0.133241     0.0681906    0.000376848
 -0.0851071   0.00687196    0.0173915   -0.134087    -0.145883   -0.128648    -0.105246     0.0348677     0.0721885   -0.0606812   -0.114798     0.148253    -0.00385697    0.014003    0.0633878    0.0124425   -0.0838961   -0.0702675   -0.0645344  -0.104691      0.0211249    0.0965581    0.116965    -0.056387     0.0972011    0.127563
  0.065325    0.00239294   -0.0384393    0.126988     0.0961563   0.218329    -0.00420265   0.00437767    0.0433831   -0.0694102   -0.0469318   -0.0873258    0.0578082     0.0832385   0.0203422   -0.12712     -0.11333      0.027012     0.0040659   0.0997321    -0.0771653    0.0316253    0.00061344   0.0322474    0.0235347    0.228135
  0.05137     0.100638      0.0806835   -0.0238617   -0.0546568  -0.173972    -0.0385572   -0.0437715    -0.0118905    0.0912254   -0.0182523    0.0287887    0.000886589   0.0348208  -0.102935     0.0316512    0.0552654    0.0355317   -0.0236829   0.129286      0.0110781    0.158364    -0.0312124   -0.108845    -0.0569814    0.0665197
  0.0365935   0.109024      0.0228486    0.0132663   -0.0310456  -0.0042737    0.012547     0.0639504     0.0404042    0.123187    -0.0581963   -0.0921902    0.0423418    -0.0775129   0.045351    -0.003531     0.0438963   -0.0700586   -0.0196153  -0.0459865    -0.0846985    0.0257176    0.10641      0.039045    -0.0158366    0.0247474
 -0.0101613  -0.0517523     0.1602       0.0311132    0.128317   -0.00994309   0.0453694   -0.101866     -0.058293    -0.012731     0.0946359    0.0796201    0.108965     -0.0495243   0.105195    -0.0593617   -0.19129     -0.0096614   -0.13016     0.0642016     0.230416     0.0367279   -0.0376867   -0.106521     0.135511    -0.0373141
  0.0277681  -0.000988872  -0.00829761   0.270622    -0.213269    0.0366524   -0.0213226   -0.0166723    -0.219707     0.11277     -0.103736    -0.0165161   -0.153442     -0.13161    -0.0432974   -0.0605352   -0.00820893  -0.110388     0.0392792   0.169046      0.0327594   -0.0631314    0.0772329    0.0817707   -0.0574736    0.051845
 -0.0769609   0.124107      0.0380154   -0.148057    -0.0178684   0.0556763   -0.00306468  -0.157194      0.0583118   -0.0310814    0.0378787   -0.140173     0.0663053     0.0417748   0.0420804    0.106626    -0.222021    -0.106362    -0.109241    0.000467934  -0.0578152   -0.096828    -0.0480444    0.0359922   -0.0159721   -0.131039
 -0.123384    0.0832802    -0.047284    -0.00188273  -0.144346    0.00969641   0.0511014    0.0471844     0.116288    -0.0524885   -0.0214277   -0.152137     0.0284956    -0.0144617   0.0562053   -0.0651042   -0.112807    -0.120122     0.0396045  -0.0812844    -0.0185767   -0.0138447    0.0106415   -0.0758865    0.0524118   -0.0365492
 -0.112934    0.132627      0.00241156  -0.148111    -0.0344463   0.0271923    0.251217     0.0680402    -0.0127216    0.0844886    0.00572944   0.0166889    0.0569589     0.0866396  -0.270131    -0.163031     0.115748     0.302904     0.170958    0.124025     -0.119523    -0.429901     0.0309869   -0.0678848    0.20108     -0.0917331
  0.0177346   0.131239      0.0503574   -0.0234303   -0.152847   -0.0769852    0.0236354    0.126298     -0.129735     0.084363     0.0216921    0.0680526    0.079839      0.0664613   0.00430427  -0.0336827    0.115627    -0.0637208   -0.108042    0.088846     -0.166904     0.512478     0.150525    -0.0796924   -0.228328    -0.115264
  0.0433567  -0.0777447     0.311023    -0.241214     0.103052    0.0316525    0.16362      0.0325353    -0.0902623    0.0220249   -0.0664785    0.137491    -0.0566753     0.0478388  -0.102696     0.0848309   -0.0372847   -0.0842003    0.131595   -0.168911     -0.161167    -0.197731     0.142794     0.149603     0.193464     0.147309
  0.0487586  -0.0922273     0.0283708    0.142778     0.111581   -0.0347992    0.0432317    0.0323967    -0.0908241    0.0441378   -0.0666863   -0.215328    -0.0734559     0.0244681  -0.102626     0.10339      0.024131    -0.0755974    0.0169535  -0.16886      -0.159082     0.456939    -0.128613     0.14283      0.191679    -0.242245
  0.0462673  -0.0735466     0.243943    -0.0104172   -0.958768   -0.189767    -0.0729852    0.0672936     0.0660299   -0.0432234   -0.123103    -0.0961927    0.0207128    -0.0364878   0.0798221   -0.0313459   -8.64338e-6  -0.0324966   -0.0522086   0.0834505     0.0062641    0.215959    -0.0734621   -0.11289     -0.0148078    0.0416251
  0.0485488  -0.143816      0.24311     -0.117556     1.1859     -0.176338    -0.0871751    0.0935743     0.0392324   -0.0322603   -0.138696    -0.0932441    0.0359305    -0.03636     0.069489    -0.0577285    0.00492797  -0.100174    -0.0339952   0.0929734    -0.00387109  -0.0341604   -0.0753161   -0.102774    -0.0133386    0.0446681
  0.212635    0.110143     -0.106279    -0.133692     0.084075   -0.429602     0.0152911   -0.0415594    -0.136526     0.018357    -0.0535867   -0.102525    -0.062289      0.0487511  -0.0171883    0.10979     -0.285115    -0.0782043   -0.0520387  -0.0250049    -0.116178     0.0822442    0.0352055    0.245471     0.0133495    0.114565
  0.156772    0.110748     -0.0687363   -0.158224     0.0603995   0.396733     0.0198472   -0.0526618    -0.168391    -0.0342063   -0.0212588   -0.207228    -0.072918      0.0532141  -0.0797147   -0.00501607   0.0976953   -0.0471501    0.0165754  -0.0765298     0.0955514    0.196199     0.0316314   -0.208115     0.0499741    0.150748
 -0.0281536   0.0782248     0.109238     0.0140118    0.117782    0.0119385   -0.0119718    0.0662887     0.078145    -0.0266061    0.0272503   -0.139858    -0.015022      0.145438   -0.0412744   -0.138314    -0.121835     0.0225552   -0.0202896   0.078383      0.0939953   -0.0832127   -0.0303864   -0.0126069   -0.0863586   -0.0469408
 -0.0433023   0.0414996     0.0779944    0.0599391   -0.0132687   0.125607    -0.0915205    0.0383803     0.0750591    0.0742414   -0.00224964  -0.0895535    0.0977016     0.0595537   0.0266534    0.0311108    0.0587098   -0.108087     0.0426673   0.0328799    -0.0297607    0.128559     0.0954452    0.0820734    0.00706539  -0.0736381
  0.133127    0.0297935     0.0980974    0.307067     0.0842416   0.0615181   -0.00583033   0.0608933    -0.0846823   -0.308775     0.080529     0.177706     0.0168338    -0.0648609  -0.0271848    0.027486     0.0987363    0.136907    -0.0515802   0.0280817     0.325585     0.221115    -0.0341981    0.0441987    0.106079    -0.0976995
 -0.100078   -0.0141083     0.13975     -0.111806     0.0782538   0.0804155    0.0463639    0.0578936    -0.0115206    0.660646     0.144315     0.0613612    0.0647314     0.0327903  -0.0290434    0.0189884    0.0863403    0.138789    -0.125997    0.0267566     0.458059     0.153866    -0.0170968   -0.114557     0.216522     0.110072[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.113497
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.091844
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.102954
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.098536
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106710
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.087938
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     18
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.113495
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.091833
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102951
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.098534
┌ Info: EM with 100000 data points 10 iterations avll -1.098534
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.824004e+05
      1       7.024891e+05      -1.799113e+05 |       32
      2       6.745325e+05      -2.795664e+04 |       32
      3       6.594346e+05      -1.509781e+04 |       32
      4       6.495477e+05      -9.886919e+03 |       32
      5       6.434731e+05      -6.074594e+03 |       32
      6       6.400291e+05      -3.444035e+03 |       32
      7       6.376557e+05      -2.373436e+03 |       32
      8       6.358564e+05      -1.799307e+03 |       32
      9       6.347913e+05      -1.065039e+03 |       32
     10       6.340651e+05      -7.262012e+02 |       32
     11       6.334850e+05      -5.801557e+02 |       32
     12       6.330048e+05      -4.801595e+02 |       32
     13       6.325704e+05      -4.344494e+02 |       32
     14       6.321565e+05      -4.138360e+02 |       32
     15       6.318028e+05      -3.537604e+02 |       32
     16       6.314923e+05      -3.104531e+02 |       32
     17       6.312887e+05      -2.036441e+02 |       32
     18       6.311676e+05      -1.210196e+02 |       32
     19       6.310988e+05      -6.887620e+01 |       32
     20       6.310634e+05      -3.540265e+01 |       32
     21       6.310462e+05      -1.713958e+01 |       32
     22       6.310335e+05      -1.272363e+01 |       30
     23       6.310256e+05      -7.934835e+00 |       30
     24       6.310200e+05      -5.547706e+00 |       29
     25       6.310149e+05      -5.121562e+00 |       31
     26       6.310106e+05      -4.264866e+00 |       22
     27       6.310087e+05      -1.922382e+00 |       23
     28       6.310065e+05      -2.162572e+00 |       15
     29       6.310054e+05      -1.117336e+00 |       16
     30       6.310044e+05      -1.020542e+00 |       18
     31       6.310032e+05      -1.213416e+00 |       12
     32       6.310024e+05      -8.316121e-01 |        9
     33       6.310017e+05      -6.436728e-01 |       13
     34       6.310010e+05      -7.028583e-01 |       12
     35       6.310003e+05      -7.072062e-01 |       16
     36       6.309993e+05      -9.596034e-01 |       15
     37       6.309981e+05      -1.201365e+00 |       16
     38       6.309966e+05      -1.563581e+00 |       19
     39       6.309950e+05      -1.610719e+00 |       16
     40       6.309934e+05      -1.588467e+00 |       17
     41       6.309914e+05      -1.950525e+00 |       15
     42       6.309903e+05      -1.089032e+00 |       18
     43       6.309888e+05      -1.587348e+00 |       23
     44       6.309845e+05      -4.256300e+00 |       24
     45       6.309774e+05      -7.065176e+00 |       29
     46       6.309688e+05      -8.633419e+00 |       27
     47       6.309613e+05      -7.462619e+00 |       25
     48       6.309555e+05      -5.812128e+00 |       29
     49       6.309492e+05      -6.290211e+00 |       26
     50       6.309411e+05      -8.124098e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 630941.1096479024)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.354399
[ Info: iteration 2, average log likelihood -1.327500
[ Info: iteration 3, average log likelihood -1.300136
[ Info: iteration 4, average log likelihood -1.264714
[ Info: iteration 5, average log likelihood -1.222404
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.175902
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.159957
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.149187
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.153554
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.131166
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.101398
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.114057
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.077234
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.094932
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.121675
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.108252
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.073711
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.108862
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.119911
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.091276
[ Info: iteration 21, average log likelihood -1.124186
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.083573
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.097359
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.098590
[ Info: iteration 25, average log likelihood -1.123075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.077804
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.096620
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.109649
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.079517
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     14
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.088075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.115534
[ Info: iteration 32, average log likelihood -1.126351
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.075209
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     12
│      ⋮
│     18
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.042914
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.157720
[ Info: iteration 36, average log likelihood -1.127178
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.084690
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     12
│     14
│     16
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.052017
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.115220
[ Info: iteration 40, average log likelihood -1.129334
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086262
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     12
│     14
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.061941
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.127434
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.089624
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     12
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.078721
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.139612
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.116959
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.058032
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     10
│     12
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.089244
[ Info: iteration 50, average log likelihood -1.153782
┌ Info: EM with 100000 data points 50 iterations avll -1.153782
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0612701   -0.0487457    0.0197816   -0.0465593   -0.104681    -0.0567671    0.131936     0.130157    -0.164912     -0.0666324    0.0641395    -0.0329635  -0.0845953    0.000314484  -0.048707     0.0416062    0.0529335   -0.0145835   -0.0441183   -0.016699    -0.121924     0.147312    -0.0341976     0.0724694    0.0126287   -0.0558056
  0.061427     0.176345     0.0556352   -0.0528588   -0.00958238  -0.110147    -0.0528031   -0.0876206   -0.0958323    -0.0422423   -0.0499003     0.110939   -0.0233626   -0.0132748    -0.140193    -0.101592     0.0790526    0.0666637   -0.006382     0.189417     0.0419065    0.26774     -0.00273798   -0.185767    -0.123107     0.133162
  0.00201538  -0.127767     0.296385    -0.0258961    0.0750624   -0.165776    -0.013892     0.0472981    0.0394884    -0.0446154   -0.0602528    -0.149804    0.0512931   -0.0380155     0.0841628   -0.0683179   -0.0869566   -0.0467807   -0.0730535    0.058188     0.0429704    0.0777171   -0.063997     -0.196983     0.043144     0.0516095
  0.0725665    0.0130421    0.011666     0.00962228  -0.0145946   -0.0609715   -0.0645917   -0.0141418   -0.0436538    -0.0936332    0.0566379    -0.12376    -0.278138     0.0574552    -0.166645    -0.0481053    0.0851803   -0.0112298    0.0460864   -0.00440738   0.0242398   -0.115703     0.175317     -0.0655103    0.0408981   -0.0176153
 -0.0444843    0.0412395    0.0798924    0.0587745   -0.00579393   0.120635    -0.0898493    0.0414264    0.072972      0.0741181   -0.00406189   -0.0896534   0.0970794    0.0586108     0.0293911    0.0303264    0.0570759   -0.106453     0.0431717    0.0324141   -0.0308629    0.12455      0.0946082     0.0782948    0.00708033  -0.0797059
  0.0236502    0.00870366   0.117337     0.107208     0.0820824    0.0710643    0.0197055    0.0597925   -0.0502721     0.152771     0.111775      0.121436    0.0397971   -0.0183712    -0.028081     0.0236118    0.0925786    0.137757    -0.0855022    0.0273522    0.389227     0.189149    -0.0262815    -0.0317757    0.159433     0.0021531
 -0.0770044    0.123741     0.0411976   -0.147545    -0.0181947    0.0537492   -0.00291841  -0.156217     0.0585951    -0.031183     0.0358767    -0.140732    0.0665983    0.0421606     0.0421481    0.106471    -0.221421    -0.108938    -0.110058    -0.00111196  -0.0576058   -0.0958715   -0.0476548     0.0371549   -0.0129375   -0.130836
  0.122645     0.0670605    0.105795    -0.00838932  -0.0923327    0.15446     -0.0163214    0.129825    -0.128342      0.120744    -0.0417637    -0.243408   -0.17481     -0.0842247     0.097712     0.124761     0.0871202   -0.145399    -0.00465351   0.0198582    0.0499694    0.0255433    0.0270477     0.138456    -0.184852     0.0092204
 -0.028567    -0.0695527    0.162207     0.0457517    0.122289    -0.00325661   0.0442487   -0.104951    -0.0162852    -0.0275955    0.0633577     0.113132    0.0946678   -0.0580475     0.132683    -0.0676559   -0.182174    -0.0141983   -0.200917     0.0281697    0.211151     0.0159151   -0.0408869    -0.193828     0.134415     0.00321826
 -0.190931     0.169302    -0.0776172    0.0372984    0.00736184  -0.0664646    0.0186865    0.0597787    0.152676     -0.101386     0.0193772    -0.0475525   0.122737     0.0330905     0.0092117   -0.011127    -0.176048    -0.114625     0.238912    -0.223657     0.00762808   0.139829    -0.00390737   -0.0457206    0.102088    -0.281092
  0.0272028    0.00115028   0.0309264   -0.0833931   -0.098455    -0.166799    -0.00616794   0.0859615    0.00541369    0.0927395   -0.0486583    -0.155546    0.0616976   -0.110792      0.165786    -0.0197766    0.059374    -0.0787678   -0.141916     0.0357728    0.0127835    0.206172     0.00146365    0.0411086   -0.0283782    0.0786866
  0.142814    -0.0974397   -0.111884     0.149259     0.0373724   -0.108477     0.133208     0.0318369    0.111576      0.0794891    0.0424635     0.0731177   0.0805362    0.104671      0.174078     0.00498596   0.0364631   -0.168127    -0.116723    -0.112025    -0.152978     0.0130455   -0.000935418   0.0563617    0.116955    -0.0294604
  0.0705622    0.00719928  -0.0512578    0.137032     0.094444     0.22825     -0.00527751   0.0028916    0.0416678    -0.0697067   -0.0543838    -0.0913329   0.0514069    0.0823071     0.0174517   -0.131651    -0.115485     0.0388291   -0.00267086   0.10916     -0.0820608    0.0272342    0.0152988     0.0318712    0.0406279    0.238346
 -0.0561922    0.12473      0.042962    -0.114006    -0.106534    -0.0383966    0.116551     0.101896    -0.0627714     0.0709787    0.00444305    0.0125653   0.0689351    0.0648826    -0.156997    -0.103475     0.0870786    0.0981724    0.0114618    0.106503    -0.126176     0.037518     0.0844416    -0.0797368   -0.0280872   -0.0790594
 -0.120831    -0.0342512    0.0166611   -0.0169416    0.0373221    0.0042364   -0.120614     0.00645918  -0.049571     -0.00431628  -0.053921      0.0939734  -0.274034     0.0349661     0.0741499   -0.0677952    0.168757     0.0996122   -0.112954    -0.045285    -0.119478     0.031072     0.0553955    -0.152921    -0.0302522   -0.0826508
 -0.0347756    0.132975     0.0760859   -0.129651    -0.0650501   -0.0332582   -0.257258     0.111446    -0.0557681     0.00432443   0.0744883    -0.11891     0.0702893    0.291067     -0.0837901   -0.287528    -0.197479     0.042822     0.0180651   -0.0158961   -0.103849    -0.122178    -0.0145361     0.0397165   -0.0387417   -0.0467862
  0.0266255    0.0188451    0.110776     0.00739152  -0.0972441   -0.242375    -0.0207837    0.0100959    0.0635239     0.226391     0.014952     -0.0625174   0.032215     0.0821575    -0.0580317    0.159325     0.0326357   -0.00281466  -0.0337307    0.0634284   -0.0345103    0.039289    -0.0494923    -0.0233728    0.00823806   0.00209247
 -0.0679157    0.00038584   0.0628578    0.0442299   -0.239387     0.160037     0.0489296   -0.0119515    0.0126463     0.0556505    0.00592363   -0.175332    0.0419307   -0.0253395     0.0390422   -0.162754    -0.160008    -0.0196358   -0.00478126   0.0682252    0.0388853   -0.136288     0.0166293    -0.334009     0.0879701    0.0402629
  0.119989     0.00586855   0.151244     0.129129    -0.0880921   -0.0996241    0.156808    -0.123072    -0.00689547   -0.00980832   0.0631022     0.0149567  -0.0132858   -0.0422411    -0.0394197    0.126262     0.228158     0.0368996    0.186096    -0.127286    -0.0367507   -0.00689447   0.106716     -0.0688671   -0.016491     0.033859
  0.0617862   -0.13432      0.0600119    0.0114163   -0.0153811    0.03399      0.0584182   -0.0272633   -0.18297      -0.0651639   -0.0582091     0.0454774  -0.159261    -0.170355     -0.052842     0.1395      -0.0790418    0.0564031   -0.0963893   -0.0231663    0.0217639   -0.166923     0.0392705     0.0592013    0.0103348    0.0908651
 -0.0393982    0.0619044   -0.0228705    0.104718    -0.200096     0.0266603    0.013785     0.0223887   -0.0537702     0.00954833  -0.0863184    -0.103676   -0.0907638   -0.0841033     0.0335434   -0.0738086   -0.0116689   -0.127506     0.0259346    0.0715268   -0.00260452  -0.0701299    0.0374034     0.0539698   -0.02982      0.0467484
  0.204907     0.0857066   -0.119088     0.00763177  -0.154461    -0.0510314   -0.0480067   -0.121257    -0.0209536    -0.092274     0.0805873     0.013268   -0.0217971   -0.0730621    -0.138356    -0.0227556   -0.0844256    0.216488     0.01203      0.0994848    0.0961847    0.0343003    0.0450649    -0.0636416   -0.156324     0.0194044
  0.167044     0.0919983   -0.0808511   -0.144153     0.0762128   -0.0224125    0.0128147   -0.0390427   -0.137932     -0.00250554  -0.0510425    -0.14819    -0.0613808    0.043397     -0.0416272    0.0550182   -0.0774238   -0.0626547   -0.0111224   -0.0390407   -0.0140439    0.147539     0.0237147     0.00304942   0.0288788    0.124701
  0.0649539   -0.169476     0.0696587   -0.077671     0.0363906   -0.109147     0.207308    -0.069506     0.047054     -0.0446318   -0.000824765  -0.0568945  -0.135544    -0.108321     -0.140424    -0.0427967   -0.0920908    0.0613262   -0.140436     0.00143805  -0.0131837   -0.109342     0.0642049     0.153623     0.0162114   -0.00671453
 -0.0218645    0.0609793   -0.109593     0.0565438   -0.0454962    0.0130511   -0.0294749   -0.0124692    0.000936419  -0.0288743    0.00740234   -0.0287668   0.0291831   -0.177086     -0.124616    -0.0824699    0.0162772   -0.105213    -0.0524962    0.0570904    0.0733999   -0.078698    -0.15729      -0.0809792    0.0509348    0.154988
  0.0405755   -0.0763034    0.162596    -0.0376747    0.100002    -0.0139314    0.0845419    0.0384846   -0.0739861     0.0238023   -0.0647378    -0.0106922  -0.0517496    0.0367842    -0.0946903    0.091832    -0.00437546  -0.0804353    0.0816104   -0.144933    -0.147361     0.182461    -0.00827083    0.126002     0.177665    -0.0575012
  0.068262    -0.0278095    0.0657966    0.0341388    0.00594452   0.0668696    0.0352314   -0.0575429   -0.167972     -0.114296    -0.0751983     0.0281189  -0.176638    -0.0565846    -0.00327194   0.30169     -0.0308294    0.0337355   -0.124902    -0.0848044    0.017883    -0.161298     0.0229202    -0.0645927    0.0160799    0.0717138
  0.0784539    0.183761     0.114275    -0.0844356    0.118766    -0.0693127    0.0912381    0.0432298    0.0300237    -0.00731544  -0.0014314     0.118524   -0.00939793   0.0675207     0.00517864  -0.048914    -0.0644396   -0.0833027    0.019119     0.014698     0.0140673   -0.16665      0.0594901    -0.117305     0.0774555    0.00238004
  0.0236674    0.163798     0.0612815    0.112593    -0.12253      0.0215822   -0.00663226  -0.0707498    0.00168513    0.136288    -0.00639748   -0.0403902   0.049403     0.0715811    -0.140944    -0.0440394    0.00877019  -0.141096     0.0358565    0.0178623   -0.0284533   -0.0030673    0.141947      0.0410897   -0.137327    -0.0536899
 -0.0298749    0.0784574    0.109539     0.0120163    0.119348     0.00968543  -0.0100027    0.0668374    0.0763997    -0.0265174    0.0283686    -0.139861   -0.0145671    0.144903     -0.0406554   -0.13883     -0.120381     0.0221156   -0.0198021    0.0781181    0.0940635   -0.0815161   -0.0316617    -0.0130192   -0.0853357   -0.0457357
 -0.084121     0.00683591   0.0167592   -0.134331    -0.145845    -0.128969    -0.105515     0.0336978    0.0726725    -0.061401    -0.11605       0.152328   -0.00499545   0.0135314     0.0635615    0.0136293   -0.0840207   -0.0691475   -0.0672859   -0.106086     0.0226139    0.0962454    0.117002     -0.0561451    0.0974581    0.127866
  0.0865104    0.138238    -0.00460217   0.00246537   0.103254     0.121179     0.0393217    0.164406     0.121385      0.129114    -0.103168     -0.0749314   0.019844    -0.177766      0.0975862    0.0619997    0.0496279    0.0116781    0.0225367   -0.144805    -0.198904    -0.104573     0.153692      0.0458022    0.089772     0.0476059[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.100639
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     16
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.074783
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     12
│     14
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.047246
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      8
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.074312
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     14
│     16
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.075560
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.068953
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      8
│     12
│     14
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.066433
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     16
│     18
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.079585
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     12
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.059861
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      8
│     14
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.068761
┌ Info: EM with 100000 data points 10 iterations avll -1.068761
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0455456    0.1776      0.0143045   -0.0725886  -0.23897      0.154306   -0.19312     -0.0494675    -0.145293    -0.0911612   -0.053216    -0.0173841  -0.0196724    0.0810744    0.0261009    0.114391    -0.0598782    0.00168951   0.0064006    0.0209539    0.146635     -0.0938269    0.0252836   -0.134908      0.0445187   -0.0788424
  0.0887206   -0.090675    0.161089     0.0785788  -0.0936886   -0.176933    0.0712168   -0.184469      0.0278462    0.145442     0.216645     0.0399259  -0.0451689   -0.0234278   -0.109153     0.00994391  -0.131433    -0.0604983   -0.131782    -0.167895    -0.0395561    -0.0245631    0.0780973    0.189054      0.0528576    0.0159606
 -0.0580999    0.106975    0.0587416    0.161571   -0.0528714   -0.0922891   0.108563    -0.000305748  -0.110345    -0.0032893    0.144045     0.0170539  -0.137318     0.109403    -0.0357064    0.0158917    0.0425618    0.00224296  -0.0868228   -0.0337522   -0.0877563     0.145543    -0.0369697    0.0957422    -0.112953    -0.207613
 -0.0375555    0.161251   -0.0413128   -0.0918096  -0.0240041   -0.021437    0.00424715  -0.137656     -0.0629107   -0.0717058   -0.00587169  -0.0569481  -0.0259558   -0.11693      0.106075     0.0079808    0.0128392   -0.0269286    0.139096     0.122737     0.0330492    -0.0749677    0.00844886   0.0557208     0.0285512   -0.127607
  0.0849204    0.0711693  -0.0548857    0.134121   -0.0130755    0.0320066   0.125499     0.11328       0.0463319   -0.0534852    0.0604592   -0.0216573  -0.0255869   -0.0109462   -0.037077    -0.184125    -0.00264736   0.0946835   -0.0115686   -0.0468053    0.0161482     0.107152     0.0316117   -0.0114041    -0.228643    -0.148812
  0.14945     -0.0140083  -0.0472233   -0.148278   -0.155006     0.0649574  -0.05387     -0.0930035     0.0132422   -0.0427567    0.0527633    0.0295343   0.0215688    0.0378898    0.198049    -0.0228036   -0.0431669    0.0925343    0.0349894    0.0050335   -0.0509628     0.00356137   0.012083    -0.105661     -0.0483431    0.0821779
  0.159983    -0.0533774   0.144211    -0.0229409   0.0978547    0.0689762  -0.0777231   -0.043294      0.013037    -0.0530728   -0.0291851    0.153889   -0.00242019   0.0667987    0.00191413   0.0851026    0.0874283   -0.0514536   -0.198534    -0.0857791   -0.0538152     0.122651    -0.0653728   -0.0390805    -0.260472     0.113805
 -0.00609311   0.0550612   0.083201    -0.0635413   0.0889434   -0.1704     -0.151028     0.0442955     0.0258035    0.0173218    0.103481    -0.111563   -0.030601    -0.00924663  -0.0260198   -0.0669665   -0.0430347    0.230109     0.00848583  -0.094195     0.0618121    -0.0576192   -0.0232874   -0.00351994   -0.0344015   -0.0626158
 -0.0651147   -0.101021   -0.186028    -0.106772   -0.00133066   0.104572    0.149387    -0.0375632     0.0825495   -0.0887691   -0.047595    -0.127838   -0.116008     0.0156236    0.102359     0.130599    -0.0581664    0.0138304   -0.0580495    0.17035      0.0260987     0.283598    -0.0895457    0.102732     -0.0591354   -0.0227209
  0.0306845    0.211352    0.0890302   -0.0139943  -0.0611922   -0.0889424  -0.0460266   -0.0873316     0.116709    -0.0816861   -0.073676     0.111125    0.0521529   -0.141137     0.113413     0.09162      0.00605748  -0.206651    -0.0262333   -0.0703817    0.0038694    -0.0828852   -0.0604389   -0.158426      0.0419507   -0.130627
 -0.13203     -0.065807   -0.0832412    0.0877095  -0.0900012   -0.120606   -0.0171211   -0.106748     -0.027521     0.144902    -0.051432     0.0274219  -0.0471065   -0.113529    -0.25296     -0.079244    -0.0744445    0.10476      0.04809      0.112023    -0.0225412    -0.210507     0.0217969    0.0124288     0.0556887    0.216986
  0.0170931   -0.0228229  -0.0288692    0.0199643  -0.0807491   -0.164965   -0.121098     0.152502     -0.0295692    0.0365102    0.0578267   -0.0592078  -0.0373657    0.140723     0.111551    -0.087413     0.00616436   0.185772    -0.103415     0.168714     0.1533        0.00576861   0.0879169    0.0469141    -0.128171     0.105147
  0.0666047   -0.157016    0.227711     0.028207   -0.0150107    0.069895   -0.0252597    0.0202955    -0.0310171   -0.0902597    0.151579     0.121054    0.00701961  -0.0394355   -0.119863    -0.0592178    0.0468567    0.04409      0.0389912   -0.0302493   -0.0689372    -0.0363263    0.0580801    0.194762      0.131495     0.0622342
 -0.0791924   -0.0948945   0.0827142   -0.152651    0.0919194   -0.146347   -0.0694261   -0.0489572     0.116664    -0.165897     0.11782     -0.0612675   0.17304     -0.117155     0.0186609    0.0831773    0.0643474    0.0360902   -0.247334     0.0273494   -0.0471732     0.00440697   0.00420852  -0.0123036     0.092789    -0.0436653
 -0.23043      0.0331513  -0.0435721   -0.0171291  -0.134345    -0.0149255  -0.0781265    0.0827783     0.0801618   -0.0370237    0.0616208    0.0838886  -0.0345545   -0.139979    -0.0408123    0.0120195   -0.043527     0.0402191   -0.0741065    0.00622872  -0.0126761     0.0882732    0.126825     0.0787843     0.0874135   -0.121515
 -0.0969018    0.0835804   0.0938662    0.0817712   0.0929415    0.0882187   0.0908671    0.0146618     0.177607    -0.164236     0.220998    -0.0591258  -0.0190672   -0.152376     0.0427036   -0.0456655   -0.191118     0.0861184    0.0929539   -0.0404143   -0.000695647   0.0328224   -0.216455    -0.0323975    -0.0882661   -0.0816161
  0.149624     0.105732   -0.0452004   -0.105908   -0.00957487   0.0663768   0.0326105    0.00347389   -0.0133019    0.159444    -0.0887159   -0.0419728   0.0680014   -0.025562    -0.0488151   -0.0116916    0.0241361    0.19609      0.103137     0.0408196    0.0363147     0.119271    -0.0370186    0.0347685    -0.173519    -0.0215703
 -0.0311434   -0.0279256   0.189213    -0.0314387   0.0272558   -0.0514864   0.0424361    0.031213      0.0436469    0.0332498   -0.0588098    0.157955   -0.0204       0.115058     0.0743009   -0.096033    -0.0101711    0.0648505   -0.0466636   -0.0930019    0.058701      0.0364206    0.119306     0.119196     -0.0167372    0.108159
  0.0557126    0.0536365  -0.0923812    0.0219402   0.0561332   -0.0484177   0.0354786    0.1235       -0.0384606   -0.0440436    0.0902447    0.0848463  -0.0894808   -0.11282      0.0873404   -0.068329     0.0836979   -0.0325274   -0.0862436    0.119835     0.0367296     0.0295179   -0.103487     0.0830352     0.156585     0.165527
 -0.0128549    0.104709   -0.0742101    0.075001   -0.0641992   -0.0530909  -0.0355487    0.123875     -0.121219     0.0607988    0.146762     0.0380723   0.00970314  -0.0816979   -0.230949    -0.154558     0.0418134   -0.10794     -0.0453516    0.126142     0.0812408     0.107827     0.0916009    0.0228175    -0.036269    -0.171742
  0.0483676    0.167748   -0.00424172   0.0482853   0.131609     0.0131497   0.0534342    0.0762878    -0.0112442    0.0967708   -0.0773951   -0.206012   -0.0208642   -0.0362677    0.140064     0.120152     0.144055    -0.012514    -0.0468613   -0.146398     0.0652005     0.158103     0.0616142   -0.00763804    0.198746    -0.114983
  0.01065     -0.0490663  -0.124921     0.15892     0.0556377    0.0300404   0.00654327  -0.00696319   -0.0630013    0.00922692  -0.0585806   -0.0678628   0.115435     0.164997     0.00680493   0.116495    -0.00177563   0.0895364   -0.107789     0.0174064    0.0626512    -0.150141     0.0450875   -0.00593375   -0.0845888    0.0525374
 -0.152214    -0.109556    0.150575    -0.0988147   0.0223756   -0.0526694   0.0180486   -0.036777      0.0929499   -0.0931456    0.127364     0.0727177   0.162087    -0.0697831    0.0797043    0.0321777    0.101152     0.140588    -0.0150987   -0.0803245   -0.173146     -0.0912477    0.206553    -0.036289      0.0143246   -0.0178203
 -0.0138489    0.14735    -0.109876     0.10039     0.0770254    0.0410503  -0.00819772   0.158144     -0.0103103   -0.0203117    0.0287645   -0.0313114   0.0210032    0.136693     0.0398593    0.0139741   -0.00820779  -0.0269009   -0.0464557   -0.062353    -0.0237545     0.0377857   -0.0780614   -0.104514      0.143626     0.051727
  0.0466865    0.0586187   0.0593656    0.0738104   0.010872    -0.149467   -0.0391963   -0.023603     -0.00766595   0.0282882    0.0160021   -0.114977    0.130071     0.17826      0.0499792   -0.0925127   -0.0713472    0.106112    -0.33211     -0.26908     -0.00345986    0.115184    -0.169918    -0.0931875    -0.109413    -0.132818
  0.00350691  -0.0562307  -0.0466729    0.0205804   0.155355     0.109568   -0.109273    -0.0396135     0.173712    -0.0402502   -0.0936226   -0.0374006   0.122293     0.131468    -0.242892     0.105582    -0.0625307    0.0942542   -0.119245     0.177332    -0.0559258    -0.0122939   -0.0239199   -0.0835002    -0.129418    -0.0126964
  0.0493471   -0.0498896  -0.050966     0.088667   -0.0252596    0.0700754   0.0197946    0.102601      0.00715027   0.0643302    0.00711143  -0.100447   -0.0168894    0.0113944   -0.197232    -0.148731    -0.0365272   -0.0618866   -0.132092    -0.00901933   0.00498195   -0.0885809    0.0257556    0.0549509     0.0359286   -0.0782
  0.0597676   -0.126044   -0.0553208    0.0742629  -0.00466764   0.0175095   0.049654    -0.0365092    -0.00423386  -0.0355102   -0.122404     0.0214756   0.0470939   -0.0545762   -0.0531423    0.0703329    0.0794097   -0.0961312    0.188314     0.105948     0.0712864     0.131885     0.152924    -0.0137909    -0.0742076   -0.0114273
 -0.119899    -0.129923    0.106723    -0.0172757   0.120618     0.0858753   0.0500848    0.0214025    -0.0671763   -0.0842416   -0.157272    -0.0583196   0.0129559    0.129931    -0.202378     0.0472388    0.0792444    0.17692      0.0817276    0.0345497    0.0489443     0.0288294    0.0200701    0.0699024     0.116881    -0.0718095
  0.128909    -0.355577    0.060747    -0.0786863  -0.0395532    0.166789   -0.0390169   -0.0667967    -0.147932     0.111104     0.031057    -0.0389306  -0.0698832    0.086473    -0.0042961    0.0869334    0.143499    -0.0197492   -0.0180089    0.100597     0.100536      0.119871    -0.167207    -0.0104974    -0.0109861   -0.0843082
 -0.0145703    0.151166   -0.0404683   -0.0572753  -0.0067717   -0.0544854   0.101063     0.0687434    -0.0848944   -0.117886     0.0955501    0.109568    0.244245    -0.0321645    0.0656061    0.0697737   -0.044644    -0.11546     -0.145432    -0.125307    -0.00258396    0.0270729    0.00311048   0.000335872   0.0152694    0.0715328
  0.0974445   -0.211195   -0.0232342   -0.0941124  -0.026945    -0.0323864  -0.0443809   -0.103002      0.00684465  -0.0661867   -0.0163321    0.0190851  -0.0247024    0.0544432    0.0447023   -0.0439178    0.132074    -0.0644412    0.144436    -0.0582015   -0.148518      0.103675     0.0484514    0.0876778     0.00240922   0.0229574kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.419600235473276
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419620
[ Info: iteration 2, average log likelihood -1.419538
[ Info: iteration 3, average log likelihood -1.419473
[ Info: iteration 4, average log likelihood -1.419396
[ Info: iteration 5, average log likelihood -1.419303
[ Info: iteration 6, average log likelihood -1.419188
[ Info: iteration 7, average log likelihood -1.419043
[ Info: iteration 8, average log likelihood -1.418841
[ Info: iteration 9, average log likelihood -1.418520
[ Info: iteration 10, average log likelihood -1.417988
[ Info: iteration 11, average log likelihood -1.417177
[ Info: iteration 12, average log likelihood -1.416185
[ Info: iteration 13, average log likelihood -1.415298
[ Info: iteration 14, average log likelihood -1.414732
[ Info: iteration 15, average log likelihood -1.414455
[ Info: iteration 16, average log likelihood -1.414336
[ Info: iteration 17, average log likelihood -1.414287
[ Info: iteration 18, average log likelihood -1.414266
[ Info: iteration 19, average log likelihood -1.414257
[ Info: iteration 20, average log likelihood -1.414253
[ Info: iteration 21, average log likelihood -1.414251
[ Info: iteration 22, average log likelihood -1.414250
[ Info: iteration 23, average log likelihood -1.414249
[ Info: iteration 24, average log likelihood -1.414248
[ Info: iteration 25, average log likelihood -1.414248
[ Info: iteration 26, average log likelihood -1.414248
[ Info: iteration 27, average log likelihood -1.414247
[ Info: iteration 28, average log likelihood -1.414247
[ Info: iteration 29, average log likelihood -1.414247
[ Info: iteration 30, average log likelihood -1.414246
[ Info: iteration 31, average log likelihood -1.414246
[ Info: iteration 32, average log likelihood -1.414246
[ Info: iteration 33, average log likelihood -1.414246
[ Info: iteration 34, average log likelihood -1.414245
[ Info: iteration 35, average log likelihood -1.414245
[ Info: iteration 36, average log likelihood -1.414245
[ Info: iteration 37, average log likelihood -1.414245
[ Info: iteration 38, average log likelihood -1.414245
[ Info: iteration 39, average log likelihood -1.414245
[ Info: iteration 40, average log likelihood -1.414245
[ Info: iteration 41, average log likelihood -1.414245
[ Info: iteration 42, average log likelihood -1.414244
[ Info: iteration 43, average log likelihood -1.414244
[ Info: iteration 44, average log likelihood -1.414244
[ Info: iteration 45, average log likelihood -1.414244
[ Info: iteration 46, average log likelihood -1.414244
[ Info: iteration 47, average log likelihood -1.414244
[ Info: iteration 48, average log likelihood -1.414244
[ Info: iteration 49, average log likelihood -1.414244
[ Info: iteration 50, average log likelihood -1.414244
┌ Info: EM with 100000 data points 50 iterations avll -1.414244
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4196204642580201
│     -1.4195380676688056
│      ⋮
└     -1.4142440210256684
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414264
[ Info: iteration 2, average log likelihood -1.414179
[ Info: iteration 3, average log likelihood -1.414111
[ Info: iteration 4, average log likelihood -1.414032
[ Info: iteration 5, average log likelihood -1.413939
[ Info: iteration 6, average log likelihood -1.413838
[ Info: iteration 7, average log likelihood -1.413740
[ Info: iteration 8, average log likelihood -1.413655
[ Info: iteration 9, average log likelihood -1.413590
[ Info: iteration 10, average log likelihood -1.413544
[ Info: iteration 11, average log likelihood -1.413511
[ Info: iteration 12, average log likelihood -1.413488
[ Info: iteration 13, average log likelihood -1.413471
[ Info: iteration 14, average log likelihood -1.413458
[ Info: iteration 15, average log likelihood -1.413448
[ Info: iteration 16, average log likelihood -1.413440
[ Info: iteration 17, average log likelihood -1.413432
[ Info: iteration 18, average log likelihood -1.413426
[ Info: iteration 19, average log likelihood -1.413420
[ Info: iteration 20, average log likelihood -1.413415
[ Info: iteration 21, average log likelihood -1.413409
[ Info: iteration 22, average log likelihood -1.413404
[ Info: iteration 23, average log likelihood -1.413399
[ Info: iteration 24, average log likelihood -1.413394
[ Info: iteration 25, average log likelihood -1.413388
[ Info: iteration 26, average log likelihood -1.413382
[ Info: iteration 27, average log likelihood -1.413376
[ Info: iteration 28, average log likelihood -1.413370
[ Info: iteration 29, average log likelihood -1.413363
[ Info: iteration 30, average log likelihood -1.413355
[ Info: iteration 31, average log likelihood -1.413347
[ Info: iteration 32, average log likelihood -1.413338
[ Info: iteration 33, average log likelihood -1.413329
[ Info: iteration 34, average log likelihood -1.413319
[ Info: iteration 35, average log likelihood -1.413309
[ Info: iteration 36, average log likelihood -1.413299
[ Info: iteration 37, average log likelihood -1.413288
[ Info: iteration 38, average log likelihood -1.413277
[ Info: iteration 39, average log likelihood -1.413266
[ Info: iteration 40, average log likelihood -1.413254
[ Info: iteration 41, average log likelihood -1.413244
[ Info: iteration 42, average log likelihood -1.413233
[ Info: iteration 43, average log likelihood -1.413223
[ Info: iteration 44, average log likelihood -1.413213
[ Info: iteration 45, average log likelihood -1.413204
[ Info: iteration 46, average log likelihood -1.413196
[ Info: iteration 47, average log likelihood -1.413188
[ Info: iteration 48, average log likelihood -1.413180
[ Info: iteration 49, average log likelihood -1.413173
[ Info: iteration 50, average log likelihood -1.413167
┌ Info: EM with 100000 data points 50 iterations avll -1.413167
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414264009292105
│     -1.4141789954667228
│      ⋮
└     -1.4131665957573163
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413171
[ Info: iteration 2, average log likelihood -1.413117
[ Info: iteration 3, average log likelihood -1.413069
[ Info: iteration 4, average log likelihood -1.413014
[ Info: iteration 5, average log likelihood -1.412944
[ Info: iteration 6, average log likelihood -1.412857
[ Info: iteration 7, average log likelihood -1.412750
[ Info: iteration 8, average log likelihood -1.412627
[ Info: iteration 9, average log likelihood -1.412496
[ Info: iteration 10, average log likelihood -1.412365
[ Info: iteration 11, average log likelihood -1.412242
[ Info: iteration 12, average log likelihood -1.412132
[ Info: iteration 13, average log likelihood -1.412038
[ Info: iteration 14, average log likelihood -1.411958
[ Info: iteration 15, average log likelihood -1.411892
[ Info: iteration 16, average log likelihood -1.411837
[ Info: iteration 17, average log likelihood -1.411791
[ Info: iteration 18, average log likelihood -1.411753
[ Info: iteration 19, average log likelihood -1.411721
[ Info: iteration 20, average log likelihood -1.411693
[ Info: iteration 21, average log likelihood -1.411669
[ Info: iteration 22, average log likelihood -1.411648
[ Info: iteration 23, average log likelihood -1.411629
[ Info: iteration 24, average log likelihood -1.411612
[ Info: iteration 25, average log likelihood -1.411597
[ Info: iteration 26, average log likelihood -1.411583
[ Info: iteration 27, average log likelihood -1.411570
[ Info: iteration 28, average log likelihood -1.411558
[ Info: iteration 29, average log likelihood -1.411547
[ Info: iteration 30, average log likelihood -1.411537
[ Info: iteration 31, average log likelihood -1.411528
[ Info: iteration 32, average log likelihood -1.411519
[ Info: iteration 33, average log likelihood -1.411510
[ Info: iteration 34, average log likelihood -1.411502
[ Info: iteration 35, average log likelihood -1.411494
[ Info: iteration 36, average log likelihood -1.411487
[ Info: iteration 37, average log likelihood -1.411480
[ Info: iteration 38, average log likelihood -1.411473
[ Info: iteration 39, average log likelihood -1.411466
[ Info: iteration 40, average log likelihood -1.411460
[ Info: iteration 41, average log likelihood -1.411454
[ Info: iteration 42, average log likelihood -1.411448
[ Info: iteration 43, average log likelihood -1.411442
[ Info: iteration 44, average log likelihood -1.411437
[ Info: iteration 45, average log likelihood -1.411431
[ Info: iteration 46, average log likelihood -1.411426
[ Info: iteration 47, average log likelihood -1.411421
[ Info: iteration 48, average log likelihood -1.411415
[ Info: iteration 49, average log likelihood -1.411410
[ Info: iteration 50, average log likelihood -1.411405
┌ Info: EM with 100000 data points 50 iterations avll -1.411405
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4131710767574823
│     -1.4131165035697502
│      ⋮
└     -1.4114054438376862
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411409
[ Info: iteration 2, average log likelihood -1.411352
[ Info: iteration 3, average log likelihood -1.411299
[ Info: iteration 4, average log likelihood -1.411238
[ Info: iteration 5, average log likelihood -1.411164
[ Info: iteration 6, average log likelihood -1.411074
[ Info: iteration 7, average log likelihood -1.410971
[ Info: iteration 8, average log likelihood -1.410857
[ Info: iteration 9, average log likelihood -1.410738
[ Info: iteration 10, average log likelihood -1.410621
[ Info: iteration 11, average log likelihood -1.410509
[ Info: iteration 12, average log likelihood -1.410405
[ Info: iteration 13, average log likelihood -1.410311
[ Info: iteration 14, average log likelihood -1.410226
[ Info: iteration 15, average log likelihood -1.410151
[ Info: iteration 16, average log likelihood -1.410085
[ Info: iteration 17, average log likelihood -1.410028
[ Info: iteration 18, average log likelihood -1.409977
[ Info: iteration 19, average log likelihood -1.409934
[ Info: iteration 20, average log likelihood -1.409895
[ Info: iteration 21, average log likelihood -1.409861
[ Info: iteration 22, average log likelihood -1.409830
[ Info: iteration 23, average log likelihood -1.409802
[ Info: iteration 24, average log likelihood -1.409776
[ Info: iteration 25, average log likelihood -1.409751
[ Info: iteration 26, average log likelihood -1.409728
[ Info: iteration 27, average log likelihood -1.409707
[ Info: iteration 28, average log likelihood -1.409686
[ Info: iteration 29, average log likelihood -1.409665
[ Info: iteration 30, average log likelihood -1.409646
[ Info: iteration 31, average log likelihood -1.409627
[ Info: iteration 32, average log likelihood -1.409608
[ Info: iteration 33, average log likelihood -1.409590
[ Info: iteration 34, average log likelihood -1.409572
[ Info: iteration 35, average log likelihood -1.409555
[ Info: iteration 36, average log likelihood -1.409538
[ Info: iteration 37, average log likelihood -1.409522
[ Info: iteration 38, average log likelihood -1.409506
[ Info: iteration 39, average log likelihood -1.409491
[ Info: iteration 40, average log likelihood -1.409476
[ Info: iteration 41, average log likelihood -1.409461
[ Info: iteration 42, average log likelihood -1.409447
[ Info: iteration 43, average log likelihood -1.409434
[ Info: iteration 44, average log likelihood -1.409421
[ Info: iteration 45, average log likelihood -1.409409
[ Info: iteration 46, average log likelihood -1.409397
[ Info: iteration 47, average log likelihood -1.409386
[ Info: iteration 48, average log likelihood -1.409375
[ Info: iteration 49, average log likelihood -1.409365
[ Info: iteration 50, average log likelihood -1.409355
┌ Info: EM with 100000 data points 50 iterations avll -1.409355
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41140874163875
│     -1.4113520343882744
│      ⋮
└     -1.4093554555626293
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409354
[ Info: iteration 2, average log likelihood -1.409291
[ Info: iteration 3, average log likelihood -1.409231
[ Info: iteration 4, average log likelihood -1.409160
[ Info: iteration 5, average log likelihood -1.409069
[ Info: iteration 6, average log likelihood -1.408950
[ Info: iteration 7, average log likelihood -1.408801
[ Info: iteration 8, average log likelihood -1.408624
[ Info: iteration 9, average log likelihood -1.408428
[ Info: iteration 10, average log likelihood -1.408227
[ Info: iteration 11, average log likelihood -1.408032
[ Info: iteration 12, average log likelihood -1.407854
[ Info: iteration 13, average log likelihood -1.407696
[ Info: iteration 14, average log likelihood -1.407559
[ Info: iteration 15, average log likelihood -1.407442
[ Info: iteration 16, average log likelihood -1.407342
[ Info: iteration 17, average log likelihood -1.407257
[ Info: iteration 18, average log likelihood -1.407184
[ Info: iteration 19, average log likelihood -1.407123
[ Info: iteration 20, average log likelihood -1.407070
[ Info: iteration 21, average log likelihood -1.407025
[ Info: iteration 22, average log likelihood -1.406986
[ Info: iteration 23, average log likelihood -1.406951
[ Info: iteration 24, average log likelihood -1.406921
[ Info: iteration 25, average log likelihood -1.406894
[ Info: iteration 26, average log likelihood -1.406869
[ Info: iteration 27, average log likelihood -1.406846
[ Info: iteration 28, average log likelihood -1.406825
[ Info: iteration 29, average log likelihood -1.406806
[ Info: iteration 30, average log likelihood -1.406787
[ Info: iteration 31, average log likelihood -1.406770
[ Info: iteration 32, average log likelihood -1.406754
[ Info: iteration 33, average log likelihood -1.406738
[ Info: iteration 34, average log likelihood -1.406723
[ Info: iteration 35, average log likelihood -1.406709
[ Info: iteration 36, average log likelihood -1.406695
[ Info: iteration 37, average log likelihood -1.406682
[ Info: iteration 38, average log likelihood -1.406669
[ Info: iteration 39, average log likelihood -1.406657
[ Info: iteration 40, average log likelihood -1.406645
[ Info: iteration 41, average log likelihood -1.406633
[ Info: iteration 42, average log likelihood -1.406622
[ Info: iteration 43, average log likelihood -1.406611
[ Info: iteration 44, average log likelihood -1.406601
[ Info: iteration 45, average log likelihood -1.406590
[ Info: iteration 46, average log likelihood -1.406580
[ Info: iteration 47, average log likelihood -1.406570
[ Info: iteration 48, average log likelihood -1.406561
[ Info: iteration 49, average log likelihood -1.406551
[ Info: iteration 50, average log likelihood -1.406542
┌ Info: EM with 100000 data points 50 iterations avll -1.406542
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4093542190912276
│     -1.4092913666219824
│      ⋮
└     -1.4065420342315516
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.419600235473276
│     -1.4196204642580201
│     -1.4195380676688056
│     -1.419472851636105
│      ⋮
│     -1.4065608109411885
│     -1.4065513510364642
└     -1.4065420342315516
32×26 Array{Float64,2}:
  0.175657    -0.488055    -0.283325     -0.0750833  -0.374393    -0.250477     -0.0801815   0.080163    0.605008   -0.0324164   0.0418874   0.139926   -0.218658    -0.105187    -0.0815066  -0.513112    0.866798   -0.205555     0.605012     0.57555     0.124615     0.294413    0.0938538    0.244887     0.0679355   -0.596449
  0.0365945    0.147046    -0.483669      0.322917    0.172349     0.156116     -0.256657    0.384327   -0.0216664  -0.151287    0.435633    0.463292   -0.282224    -0.16819     -0.538579    0.0391386   0.128579    0.190175     0.586863     0.911422    0.0103964    0.856614    0.754393     0.153102     0.0280034   -0.640058
  0.26807     -0.297751     0.111192      0.123069   -0.221083     0.686738      0.0251466   0.232786   -0.160288    0.528708    0.0435753   0.0505374  -0.540403    -0.20299     -0.616595    0.132442    0.519505   -0.212756     0.374327     0.33239     0.100919     0.714155   -0.186818    -0.585534     0.144321     0.102447
 -0.29339      0.183564    -0.293958      0.306718    0.204608     0.657867      0.0184399   0.131169    0.952956    0.356358   -0.30987     0.0579964   0.530935     0.244085    -0.174428   -0.120227    0.175274   -0.152416     0.392626     0.355082    0.346417     0.22158    -0.208689    -0.618645     0.559583    -0.0366078
 -0.0798268   -0.183491     0.0854736     0.130905    0.0316353   -0.461935     -0.0459499   0.793951   -0.0922704  -0.0206322   0.0608718  -0.402778   -0.0954562    0.346616     0.486061    0.269943   -0.0869258  -0.253085    -0.541643    -0.0168211  -0.105127    -0.122467    0.0381342    0.164166    -0.481084    -0.588126
 -0.237924    -1.01121     -0.419573      0.403976   -0.36073      0.0611799     0.149858   -0.0456188  -0.124363    0.11594     0.416427   -0.145726   -0.440017     0.457144     0.0772552  -0.105708   -0.264819    0.0204272    0.287725    -0.146376   -0.657723     0.562919   -0.236567     0.436683     0.0870286    0.26072
  0.1398      -0.471299     0.0434772     0.336983    0.508455     0.254845      0.353186   -0.134672   -0.202524    0.697868    0.29653     0.144088    0.333255     0.210526    -0.515247   -0.656152   -0.490192   -0.120035    -0.110971    -0.171561   -0.69366      0.106003   -0.447914    -0.460279     0.00904277   0.248366
  0.20319      0.014227     0.0982224     0.966427    0.065342     0.268718      0.472802   -0.220082   -0.11538     0.63042    -0.348623   -0.136927    0.00957409   0.495778     0.0807571   0.453594   -0.369694   -0.197046     0.0955986   -0.287239   -0.310084     0.0669948   0.450292     0.281025    -0.0528176    0.432174
  0.680678    -0.180847     0.339918      0.57914    -0.164227    -0.531964     -0.820049   -0.7374      0.663322    0.242549   -0.551449    0.0750694   0.385576    -0.387583     0.134007    0.629001    0.0732471   0.110759     0.342555     0.713839   -0.637473    -0.836336    0.288253    -0.741118    -1.02064     -0.526447
 -0.140684    -0.115308    -0.10473      -0.0603551   0.249612     0.144978     -0.523785   -0.0638282   0.366925   -0.110609   -0.304957   -0.660199    0.724555    -0.138764     0.320536    0.122152    0.140738    0.107323    -0.138302    -0.380636   -0.0494539   -0.824778    0.00541487  -0.0488776   -0.974744     0.67807
  0.0425503    0.3801      -0.0732973    -0.0338857  -0.61315     -0.171804     -0.818719    0.192753    0.161552   -0.61787    -0.570115   -0.21974    -0.178622     0.0087434    0.36244     0.421959    0.0884045   0.381354     0.338001     0.0361477   0.820493    -0.22717     0.23026      0.293254     0.110671    -0.351025
  0.567316     0.0246616   -0.0861241     0.31605    -0.269084    -0.396544      0.0926476   0.0763047   0.302458    0.106625   -0.167717   -0.1762     -0.453598    -0.217989     0.172692   -0.374778    0.0150009  -0.232214     0.497377    -0.670768    0.28015     -0.894759   -0.102445    -0.0204654    0.517191    -0.154884
 -0.512737    -0.251823    -0.246603     -0.397531    0.370778     0.69752      -0.058832   -0.0105771   0.153744   -0.203388    0.899014   -0.392425    0.297173    -1.02042      0.0903333  -0.36525     0.327432    0.638327     0.0976817   -0.162833   -0.308544    -0.217416   -0.201863    -0.145319     0.141444     0.233273
 -0.00754175  -0.574203     0.530537     -0.428274   -0.312421     0.056427     -0.103129   -0.193735   -0.284938   -0.587695    0.419707    0.204067    0.33534     -0.548528    -0.129862    0.160201    1.04253    -0.521858    -0.405494     0.264469   -0.168761     0.723411   -0.50782     -0.157761    -0.0228643    0.515462
  0.0531218    0.459278     0.18267      -0.45285    -0.0228652    0.262629      0.388337   -0.822559   -0.162815   -0.691477   -0.235382    0.200317   -0.0295713   -0.0424544   -0.0355819   0.138244    0.18245     0.286698     0.0354372    0.139258    0.176468     0.122312    0.235413     0.349201     0.0169834    0.31314
  0.0283057    0.171228     0.114896     -0.110341    0.257551    -0.0516007    -0.169692    0.0269329  -0.168501    0.691177   -0.0765806   0.266667    0.246726    -0.0530515   -0.403139   -0.253489   -0.313955    0.0324484    0.00728881   0.0156537   0.11883      0.0609959   0.0581349   -0.411323    -0.0553695   -0.11776
 -0.323369     0.163425     0.0872297    -0.470866    0.326954     0.279627      0.482502    0.0726959  -0.3059      0.104733    0.507456    0.125646    0.453961     0.117915    -0.0334976   0.139669   -0.268488   -0.00272898  -0.238075     0.248978    0.181507     0.498419    0.259131    -0.155098    -0.425882     0.0405241
 -0.445702    -0.39389     -0.0141442    -0.373721    0.0842592   -0.144022      0.0371354   0.190061    0.0673793  -0.165733   -0.0744987  -0.0249224   0.18663      0.322658     0.848154   -0.705729    0.13843    -0.366787     0.0096071    0.130938    0.00202161   0.352929    0.391331    -0.214956     0.154271     0.0735218
 -0.549819    -0.141134    -0.198999     -0.136324    0.322879     0.229115     -0.556215    0.0167502  -0.486096   -0.116578   -0.16078     0.0915173   0.390638     0.47862     -0.138297    0.689032   -0.305819    0.530656    -0.439155     0.382033   -0.379592     0.489708   -0.0490741    0.203609    -0.042644     0.0735373
 -0.0429702   -0.143014     0.0685101     0.134538    0.118873     0.000721376  -0.161918    0.460695    0.772238   -0.0709737  -0.377106   -0.25262     0.474556     0.399435    -0.204871    0.520342   -0.0122403   0.125529    -0.537176     0.580053   -0.284226     0.586331   -0.0950222   -0.0324794   -0.520279     0.100736
  0.0160278   -0.217231    -0.0290721     0.163852    0.0662416    0.152342     -0.163032   -0.0421884   0.116494    0.0374412   0.120153   -0.12116     0.198824    -0.0725845    0.0329468   0.0403253   0.0252098   0.168248     0.0226918    0.104549   -0.497328    -0.0369234  -0.254003    -0.0596961   -0.239062     0.105055
 -0.0141671    0.144652    -0.000739873  -0.0454774   0.0146424   -0.0297523     0.0783383  -0.0106383  -0.0495576  -0.0825186   0.044432    0.0384719  -0.0329534    0.0533408   -0.0475396   0.034348    0.0192607   0.0593347   -0.106606     0.0505102   0.259213     0.102041    0.189686    -0.00826975   0.158062    -0.0866455
  0.375608     0.332637     0.290916     -0.263583   -0.206686     0.501303     -0.0920166  -0.187306    0.126674    0.048682   -0.292698    0.205917   -0.067171    -0.0212769   -0.127351    0.271359    0.158833   -0.142875     0.293941    -0.398736    0.116147    -0.205788   -0.397303    -0.0536741   -0.0915566   -0.277986
 -0.181455     0.796848     0.39493      -0.229534    0.00568106   0.293085      0.25223    -0.0584829  -0.32383    -0.14272    -0.200611    0.0996938   0.221907    -0.00787781  -0.100566    0.109868   -0.367944   -0.052436    -0.578776    -0.479949    0.0442775   -0.444261   -0.177585    -0.500116    -0.102321     0.754718
 -0.0838405   -0.246059    -0.267476      0.417755   -0.0845056   -0.652873      0.110708   -0.523083   -0.196047   -0.232771    0.118583   -0.202152   -0.172547    -0.111238     0.20462    -0.332229   -0.304659    0.112508     0.0829985   -0.0302213  -0.0251319   -0.322806    0.237352     0.442327    -0.140862     0.0054458
 -0.277375    -0.134169    -0.178755      0.150872   -0.142719    -0.453908      0.0681491   0.347747   -0.0101609   0.202157    0.126044   -0.272572   -0.41578      0.00073096  -0.0935742  -0.237342   -0.182623   -0.196293    -0.124721    -0.317075    0.305351    -0.242708   -0.103919     0.194897    -0.100745    -0.0845276
  0.240362    -0.196331    -0.147734      0.10435    -0.310238    -0.200282     -0.150305   -0.170228   -0.254753   -0.0745068   0.656243    0.0327303  -0.242988    -0.415267    -0.991842    0.80044    -0.354282    0.455889     0.00443785  -0.314798    0.0288725   -0.495111   -0.54409      0.399985    -0.0132343   -0.130487
  0.571621    -0.00491941   0.21985      -0.315532    0.144847    -0.301305     -0.288172   -0.179977   -0.358496   -0.363126    0.111077    0.094807   -0.404826     0.0329346   -0.0923094   0.376296    0.371914    0.193227    -0.497789    -0.47895    -0.22889     -0.394443    0.111244     0.467284    -0.0661179   -0.232264
  0.120322     0.668354     0.677224     -0.542043    0.0629886   -0.775526     -0.190145    0.289695    0.187331   -0.0999274   0.177636    0.37295     0.538765    -0.610512    -0.120188   -0.826708   -0.291921    0.269669    -0.298348     0.115487    0.651382    -0.326463   -0.300516    -0.189926    -0.0182114   -0.165541
  0.0570802    0.949046     0.101145     -0.102632    0.379912    -0.280885      0.12143     0.0500587   0.211571   -0.160526   -0.151403    0.0785973  -0.0465511   -0.471946     0.494147   -0.252974    0.468264    0.0657216   -0.728619     0.419313    0.0995113   -0.0921101   0.365661    -0.244845     0.583277    -0.321356
  0.25632      0.153382     0.119169      0.214843   -0.264635    -0.564898      0.504673   -0.0463979  -0.0966156  -0.0713925   0.0986716   0.641332   -0.377904     0.49122      0.0474271  -0.274065   -0.369503    0.00515722  -0.249295     0.131668   -0.161171     0.748677   -0.0313673    0.15538      0.878276    -0.415185
 -0.201437     0.657021    -0.0939963    -0.204099   -0.322639     0.397931      0.832415    0.291525   -0.419052   -0.236515    0.349298    0.158291   -0.41242      0.200626     0.125205   -0.0489133   0.234049   -0.265269    -0.157811    -0.535647    1.04892      0.667925    0.0805593    0.516364     0.863661    -0.211674[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406533
[ Info: iteration 2, average log likelihood -1.406524
[ Info: iteration 3, average log likelihood -1.406515
[ Info: iteration 4, average log likelihood -1.406506
[ Info: iteration 5, average log likelihood -1.406497
[ Info: iteration 6, average log likelihood -1.406488
[ Info: iteration 7, average log likelihood -1.406479
[ Info: iteration 8, average log likelihood -1.406470
[ Info: iteration 9, average log likelihood -1.406461
[ Info: iteration 10, average log likelihood -1.406453
┌ Info: EM with 100000 data points 10 iterations avll -1.406453
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.596922e+05
      1       7.038190e+05      -2.558732e+05 |       32
      2       6.897772e+05      -1.404177e+04 |       32
      3       6.836369e+05      -6.140371e+03 |       32
      4       6.803890e+05      -3.247920e+03 |       32
      5       6.785007e+05      -1.888205e+03 |       32
      6       6.772039e+05      -1.296887e+03 |       32
      7       6.761842e+05      -1.019679e+03 |       32
      8       6.753946e+05      -7.895888e+02 |       32
      9       6.747329e+05      -6.616779e+02 |       32
     10       6.741940e+05      -5.389365e+02 |       32
     11       6.737369e+05      -4.570522e+02 |       32
     12       6.733558e+05      -3.811043e+02 |       32
     13       6.730182e+05      -3.376708e+02 |       32
     14       6.727103e+05      -3.078386e+02 |       32
     15       6.724245e+05      -2.858474e+02 |       32
     16       6.721748e+05      -2.497136e+02 |       32
     17       6.719615e+05      -2.132168e+02 |       32
     18       6.717880e+05      -1.735526e+02 |       32
     19       6.716400e+05      -1.479550e+02 |       32
     20       6.714914e+05      -1.486114e+02 |       32
     21       6.713566e+05      -1.348331e+02 |       32
     22       6.712336e+05      -1.230096e+02 |       32
     23       6.711142e+05      -1.193956e+02 |       32
     24       6.710023e+05      -1.118628e+02 |       32
     25       6.709023e+05      -1.000227e+02 |       32
     26       6.708221e+05      -8.021090e+01 |       32
     27       6.707512e+05      -7.087566e+01 |       32
     28       6.706838e+05      -6.737532e+01 |       32
     29       6.706081e+05      -7.574199e+01 |       32
     30       6.705306e+05      -7.752588e+01 |       32
     31       6.704575e+05      -7.305517e+01 |       32
     32       6.703929e+05      -6.465063e+01 |       32
     33       6.703362e+05      -5.670541e+01 |       32
     34       6.702844e+05      -5.179714e+01 |       32
     35       6.702374e+05      -4.698405e+01 |       32
     36       6.701903e+05      -4.703515e+01 |       32
     37       6.701435e+05      -4.680084e+01 |       32
     38       6.700936e+05      -4.989667e+01 |       32
     39       6.700449e+05      -4.873828e+01 |       32
     40       6.699900e+05      -5.493823e+01 |       32
     41       6.699309e+05      -5.909844e+01 |       32
     42       6.698804e+05      -5.048733e+01 |       32
     43       6.698339e+05      -4.652177e+01 |       32
     44       6.697896e+05      -4.423703e+01 |       32
     45       6.697485e+05      -4.110176e+01 |       32
     46       6.697072e+05      -4.132160e+01 |       32
     47       6.696651e+05      -4.211423e+01 |       32
     48       6.696195e+05      -4.559757e+01 |       32
     49       6.695808e+05      -3.865953e+01 |       32
     50       6.695439e+05      -3.688086e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669543.9411555985)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418481
[ Info: iteration 2, average log likelihood -1.413505
[ Info: iteration 3, average log likelihood -1.412246
[ Info: iteration 4, average log likelihood -1.411408
[ Info: iteration 5, average log likelihood -1.410512
[ Info: iteration 6, average log likelihood -1.409535
[ Info: iteration 7, average log likelihood -1.408688
[ Info: iteration 8, average log likelihood -1.408130
[ Info: iteration 9, average log likelihood -1.407811
[ Info: iteration 10, average log likelihood -1.407621
[ Info: iteration 11, average log likelihood -1.407493
[ Info: iteration 12, average log likelihood -1.407395
[ Info: iteration 13, average log likelihood -1.407315
[ Info: iteration 14, average log likelihood -1.407246
[ Info: iteration 15, average log likelihood -1.407186
[ Info: iteration 16, average log likelihood -1.407131
[ Info: iteration 17, average log likelihood -1.407081
[ Info: iteration 18, average log likelihood -1.407035
[ Info: iteration 19, average log likelihood -1.406992
[ Info: iteration 20, average log likelihood -1.406951
[ Info: iteration 21, average log likelihood -1.406912
[ Info: iteration 22, average log likelihood -1.406874
[ Info: iteration 23, average log likelihood -1.406839
[ Info: iteration 24, average log likelihood -1.406804
[ Info: iteration 25, average log likelihood -1.406771
[ Info: iteration 26, average log likelihood -1.406739
[ Info: iteration 27, average log likelihood -1.406709
[ Info: iteration 28, average log likelihood -1.406679
[ Info: iteration 29, average log likelihood -1.406651
[ Info: iteration 30, average log likelihood -1.406625
[ Info: iteration 31, average log likelihood -1.406599
[ Info: iteration 32, average log likelihood -1.406575
[ Info: iteration 33, average log likelihood -1.406552
[ Info: iteration 34, average log likelihood -1.406531
[ Info: iteration 35, average log likelihood -1.406510
[ Info: iteration 36, average log likelihood -1.406491
[ Info: iteration 37, average log likelihood -1.406472
[ Info: iteration 38, average log likelihood -1.406454
[ Info: iteration 39, average log likelihood -1.406437
[ Info: iteration 40, average log likelihood -1.406421
[ Info: iteration 41, average log likelihood -1.406406
[ Info: iteration 42, average log likelihood -1.406391
[ Info: iteration 43, average log likelihood -1.406376
[ Info: iteration 44, average log likelihood -1.406362
[ Info: iteration 45, average log likelihood -1.406349
[ Info: iteration 46, average log likelihood -1.406336
[ Info: iteration 47, average log likelihood -1.406324
[ Info: iteration 48, average log likelihood -1.406312
[ Info: iteration 49, average log likelihood -1.406300
[ Info: iteration 50, average log likelihood -1.406289
┌ Info: EM with 100000 data points 50 iterations avll -1.406289
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.265346    -0.180908     0.0808444    0.809       -0.0771741   -0.2424      0.468657     0.0518125   -0.110135    0.440679    -0.368373   -0.180989    -0.21575     0.808529    0.410075     0.494894   -0.498527    -0.368887     0.0113927   -0.405453    -0.216811    0.0913573   0.442446     0.51738     -0.111353   -0.139394
  0.570343     0.138794    -0.136735     0.218134    -0.0826775   -0.420315    0.128633     0.195612     0.309516    0.129334    -0.0558513  -0.201019    -0.303001   -0.187445    0.210794    -0.419572    0.0651972   -0.201799     0.302338    -0.75189      0.342811   -0.78049    -0.140361    -0.0936987    0.590028   -0.244202
  0.189537     0.759147     0.440117     0.203097     0.00559398  -0.574042    0.0623309    0.0502411    0.261992   -0.0926273   -0.334538    0.386428    -0.0891255  -0.117273    0.43682     -0.331923    0.411942    -0.159612    -0.410764     0.632091     0.134824   -0.063618    0.326712    -0.249367     0.306681   -0.381757
  0.776586     0.0679786    0.227124     0.294102    -0.13869     -0.274285   -0.623496    -0.691669     0.575316    0.0349315   -0.536939   -0.148718     0.4727     -0.402331   -0.0495305    0.636391    0.141584     0.0206786    0.242141     0.206492    -0.376812   -1.07561     0.0384715   -0.570696    -0.975298   -0.271675
 -0.121216    -0.0964968   -0.118531     0.480393    -0.0932652   -0.717568    0.253263    -0.191719    -0.20146    -0.110178     0.330441   -0.347307    -0.422794   -0.460057    0.0132144   -0.215562   -0.0601189   -0.0893716   -0.177022     0.0583479    0.119415   -0.485839    0.196475     0.549436    -0.169173   -0.0502399
  0.256202    -0.146502    -0.116296    -0.0657498   -0.154575    -0.0187446  -0.191068    -0.180661    -0.176521   -0.102905     0.75495     0.13042     -0.0254589  -0.421078   -0.925459     0.485101   -0.378102     0.748848     0.0442626   -0.332031    -0.129093   -0.386415   -0.598788     0.2686      -0.0301375  -0.082083
  0.0916732    0.272406     0.690356    -0.219604     0.30631      0.219979    0.522707     0.0799643    0.209101    0.256974     0.276858    0.206093     0.332428    0.112865   -0.110564     0.0616292  -0.0530725   -0.0153536   -0.530988     0.27555     -0.146884    0.377283   -0.161271    -0.295822    -0.0898836   0.0415095
  0.0986475    0.615812     0.0156089   -0.0876941   -0.250281     0.293768    0.715735    -0.086314    -0.395916   -0.172728     0.286019    0.438827    -0.514739    0.0510517   0.0221663    0.0206553   0.120589    -0.00952458   0.00696215  -0.252941     0.639152    0.591292    0.228957     0.352203     0.953016   -0.295649
  0.040984    -0.270129    -0.0203418    0.374564     0.0985392    0.364811    0.00865826  -0.106618     0.0219573   0.319297     0.108377   -0.186295     0.222793    0.0563961  -0.10725      0.0320722  -0.210485     0.126693     0.18164     -0.0141662   -0.52888    -0.046383   -0.307676    -0.234946    -0.273208    0.233758
 -0.161068    -0.314717    -0.447236     0.322214     0.752287     0.401905    0.694819    -0.325881    -0.674392    0.864054     0.469679    0.202329     0.203922    0.413772   -0.563445    -0.294638   -0.226537    -0.19739      0.0123479   -0.172967    -0.535284    0.402093    0.172743    -0.193458    -0.0456381   0.367195
 -0.0771191   -0.318884    -0.0658501    0.00104843   0.182439     0.392933   -0.455204     0.0181473    0.31099    -0.0810381   -0.536455   -0.822004     0.543733   -0.267998    0.584109    -0.0289936   0.500961    -0.106229     0.072622    -0.465457     0.103378   -0.547633    0.411692     0.0430811   -0.703269    0.710342
  0.0827323    0.751703     0.112299    -0.284136    -0.416895    -0.341443   -0.92057      0.346613     0.231719   -0.497405    -0.415814   -0.261253     0.192425   -0.123967    0.5109       0.281887   -0.051913     0.571354     0.0911434    0.138724     1.11149    -0.113155    0.356199     0.327462    -0.0191879  -0.466244
  0.481665    -0.639963     0.573508    -0.130457    -0.208505    -0.404841    0.158005    -0.184972    -0.36423    -0.0690662    0.136887    0.115671    -0.407536   -0.606828   -0.925453     0.175966    0.639473    -0.72996     -0.491792     0.217899     0.107239    0.257532   -0.288109    -0.427811     0.416607    0.562547
  0.0535598    0.0977348    0.121969    -0.162234    -0.00628306  -0.047797    0.0506241   -0.120937    -0.129184    0.00783698   0.056147    0.154851     0.017365   -0.105594   -0.132186    -0.171787   -0.0141526    0.0679503    0.0472924   -0.00538524   0.127947    0.0382253   0.00587565  -0.00248266   0.0254815  -0.0710306
  0.128866     0.0415595   -0.00177486   0.109242     0.173947     0.813656   -0.266998     0.181232     0.548165    0.324172    -0.525322    0.173556     0.266115    0.362548   -0.257457     0.196603    0.185967     0.00603325   0.279896     0.121869     0.0753636   0.520223   -0.255438    -0.528254     0.307683   -0.204953
  0.275822     0.350187     0.35499     -0.375961    -0.412981     0.155465   -0.0879705   -0.0686542    0.0867125  -0.10179     -0.242403    0.091283    -0.244428   -0.131128   -0.173516     0.28712     0.198463    -0.31219     -0.0351625   -0.420483     0.205942   -0.371528   -0.509903     0.144056    -0.145595   -0.190471
  0.0683657   -0.00380974  -0.0802884    0.0412559    0.013083    -0.0550936  -0.0608731   -0.0455721   -0.0517534  -0.0899663    0.0435581   0.0427819   -0.0640435   0.0230998  -0.00589791   0.0547995   0.0845235    0.0844307   -0.0480013   -0.00240539   0.0353776   0.0295289   0.0899102    0.121805     0.0632     -0.112171
 -0.461813     0.265056    -0.098186    -0.212993     0.0709807   -0.127298    0.0594473    0.156823     0.115355   -0.0884675   -0.0560791  -0.193526     0.217917   -0.0247942   0.24137     -0.296733   -0.137873    -0.0541351   -0.0906123    0.134892     0.412334    0.0189886   0.262298    -0.349681     0.0740068   0.0361887
 -0.479242    -0.228403    -0.318751    -0.21226      0.602583     0.752068   -0.0473834    0.0864781    0.207318   -0.0986756    0.931694   -0.479954     0.388955   -1.05661     0.045086    -0.231203    0.568633     0.501817    -0.120571    -0.0760039   -0.410052   -0.212622   -0.208453    -0.248825     0.297323    0.130951
 -0.194274    -0.718749     0.0229425    0.303039    -1.03639      0.714601    0.354521     0.299823    -0.154736    0.00857857   0.40446    -0.181791    -0.237808    0.161995   -0.0409753    0.338187    0.346425    -0.407935     0.30215      0.249368    -0.10881     0.907334   -0.606949     0.12254     -0.22251     0.331174
 -0.310608    -0.55909     -0.163009    -0.898645    -0.0927904   -0.064819   -0.114089     0.62676      0.232602   -0.318013     0.553879    0.10812     -0.0629358   0.153073    0.709775    -0.546735    0.656141    -0.442974    -0.0603997    0.245522     0.200842    0.275704   -0.155087    -0.0109911    0.0222352  -0.734126
  0.217816    -0.246929    -0.25968      0.17057     -0.296579    -0.0554022  -0.130029    -0.191366     0.436259    0.112637    -0.0870825   0.2106      -0.400099   -0.26783    -0.515794    -0.458453    0.677178     0.0397366    0.962242     0.559638     0.165852    0.315284    0.410366     0.0944016    0.214193   -0.35049
 -0.267537    -0.0895433    0.571       -0.827795    -0.0431493    0.0516991  -0.529105    -0.577943     0.160157   -0.467394     0.438085    0.309118     0.887184   -0.634367    0.323213    -0.411373    0.763375    -0.283042    -0.173216     0.0711267   -0.59751     0.457475   -0.238642    -0.219862    -0.243527    0.814675
 -0.0762297    0.0489043   -0.543957     0.0537366    0.123608     0.158303   -0.246637     0.759075    -0.124972   -0.0617736    0.52159     0.262849     0.130841    0.0105003  -0.560878     0.243389    0.00185243   0.0617589    0.118127     0.799752     0.13916     0.902003    0.482137    -0.0850295   -0.427528   -0.595367
  0.343626    -0.148802     0.145203    -0.197786     0.118251    -0.343749   -0.44482     -0.0297982   -0.430553   -0.503104     0.0579424  -0.00693962  -0.199872    0.276116   -0.133017     0.558366    0.251876     0.371657    -0.643998    -0.336302    -0.186481   -0.0413578   0.25573      0.419024    -0.217592   -0.261768
 -0.395202     0.163118    -0.0730635   -0.299235     0.375055     0.41994     0.212665    -0.494376    -0.0326972  -0.450373    -0.440098    0.0958014    0.42649     0.137323    0.134139     0.531336   -0.0118307    0.327004    -0.401203     0.697334    -0.126491    0.651282    0.200913     0.344606    -0.241817    0.337683
 -0.0913194    0.912104     0.341471    -0.0497883    0.121491     0.23877     0.166141    -0.195622    -0.319901   -0.0655052   -0.301328    0.192138     0.234215   -0.0159112  -0.188181    -0.0319722  -0.467971     0.150559    -0.450273    -0.517497     0.0355675  -0.520527   -0.0432124   -0.359552    -0.0526732   0.757033
  0.00615263  -0.681796     0.0667614   -0.0721239   -0.00905991  -0.637909   -0.0584463   -0.047959    -0.0999085   0.448773     0.189003    0.365111    -0.240071    0.280016   -0.135519    -0.804704   -0.668843    -0.199737     0.163612    -0.186267    -0.121698   -0.12632    -0.196091     0.126604    -0.138594    0.152116
 -0.176364    -0.58327     -0.395387     0.39292      0.0361341   -0.413656    0.298212    -0.00442782   0.0648285  -0.188096     0.265253    0.0648137   -0.0582682   0.440337    0.417586    -0.751742   -0.34067      0.114562    -0.136664     0.121616    -0.441526    0.710057    0.244536     0.194427     0.600052    0.0730933
 -0.22949     -0.429634    -0.543877     0.245436    -0.651225    -0.138846   -0.470445    -0.227281     0.0256966  -0.543513    -0.270244   -0.246023    -0.538248   -0.017462    0.205249     0.266751   -0.106675     0.495642     0.645994    -0.142164     0.0130462  -0.466566   -0.368128     0.4533       0.173525   -0.0445349
 -0.383703    -0.463434    -0.121304     0.265004     0.450191    -0.376268   -0.524695     0.43416      0.267839    0.292881    -0.217925   -0.43704      0.432208    0.328528   -0.137925     0.172674   -0.393303     0.260538    -0.42787      0.421057    -0.709713   -0.0923239  -0.266531    -0.0818731   -0.729164    0.131288
 -0.751448     0.171085    -0.0841857   -0.792841     0.0266901    0.145091    0.243937     0.516196    -0.5816     -0.018794     0.568347   -0.318785     0.208152    0.0667924   0.235778     0.126441   -0.5988      -0.182974    -0.465849    -0.566887     0.415045   -0.101157   -0.131849    -0.0895257   -0.268395    0.107461[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406278
[ Info: iteration 2, average log likelihood -1.406268
[ Info: iteration 3, average log likelihood -1.406258
[ Info: iteration 4, average log likelihood -1.406248
[ Info: iteration 5, average log likelihood -1.406238
[ Info: iteration 6, average log likelihood -1.406229
[ Info: iteration 7, average log likelihood -1.406221
[ Info: iteration 8, average log likelihood -1.406212
[ Info: iteration 9, average log likelihood -1.406204
[ Info: iteration 10, average log likelihood -1.406196
┌ Info: EM with 100000 data points 10 iterations avll -1.406196
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
