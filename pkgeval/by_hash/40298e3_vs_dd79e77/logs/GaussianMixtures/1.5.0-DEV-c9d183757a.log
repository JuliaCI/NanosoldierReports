Julia Version 1.5.0-DEV.62
Commit c9d183757a (2020-01-13 22:37 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed PDMats ───────────── v0.9.10
 Installed LegacyStrings ────── v0.4.1
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
 Installed FileIO ───────────── v1.2.1
 Installed StatsBase ────────── v0.32.0
 Installed BinaryProvider ───── v0.5.8
 Installed OrderedCollections ─ v1.1.0
 Installed HDF5 ─────────────── v0.12.5
 Installed QuadGK ───────────── v2.3.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed CMake ────────────── v1.1.2
 Installed Blosc ────────────── v0.5.1
 Installed StaticArrays ─────── v0.12.1
 Installed Distances ────────── v0.8.2
 Installed DataStructures ───── v0.17.7
 Installed Arpack_jll ───────── v3.5.0+2
 Installed JLD ──────────────── v0.9.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Rmath ────────────── v0.6.0
 Installed SpecialFunctions ─── v0.9.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distributions ────── v0.22.1
 Installed DataAPI ──────────── v1.1.0
 Installed SortingAlgorithms ── v0.3.1
 Installed FillArrays ───────── v0.8.4
 Installed URIParser ────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed StatsFuns ────────── v0.9.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.1
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_NkIi2C/Project.toml`
 [no changes]
  Updating `/tmp/jl_NkIi2C/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_IecC1s/Project.toml`
 [no changes]
  Updating `/tmp/jl_IecC1s/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_rSRtyl/Project.toml`
 [no changes]
  Updating `/tmp/jl_rSRtyl/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_Wtd6vy/Project.toml`
 [no changes]
  Updating `/tmp/jl_Wtd6vy/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_7vCaK7/Project.toml`
 [no changes]
  Updating `/tmp/jl_7vCaK7/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_7vCaK7/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.1
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.7085920633016257e6, [170.7315687474653, 99829.26843125254], [540.2531951352156 -119.43850237076155 -4.369004374689611; -943.2804406586101 45.26773570871264 -181.43137268907722], [[1729.9548530161017 -344.2937588346763 -2.013311530766238; -344.2937588346763 236.71858788180134 2.0969510002261256; -2.0133115307662415 2.0969510002261242 158.04085826720274], [98482.65697853512 -183.65310313673984 44.67053342230133; -183.65310313673984 99536.88462676932 -396.6416726433704; 44.6705334223013 -396.6416726433704 100302.32348472645]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.195581e+03
      1       8.663623e+02      -3.292185e+02 |        6
      2       8.414020e+02      -2.496028e+01 |        0
      3       8.414020e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 841.4020160132131)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078067
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.806892
[ Info: iteration 2, lowerbound -3.671685
[ Info: iteration 3, lowerbound -3.513013
[ Info: iteration 4, lowerbound -3.314503
[ Info: iteration 5, lowerbound -3.099595
[ Info: iteration 6, lowerbound -2.904015
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.746088
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.631124
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.544140
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.467195
[ Info: iteration 11, lowerbound -2.405028
[ Info: iteration 12, lowerbound -2.363316
[ Info: iteration 13, lowerbound -2.332732
[ Info: iteration 14, lowerbound -2.313282
[ Info: iteration 15, lowerbound -2.307444
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.302929
[ Info: iteration 17, lowerbound -2.299261
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 14 14:02:27 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 14 14:02:35 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Tue Jan 14 14:02:37 2020: EM with 272 data points 0 iterations avll -2.078067
5.8 data points per parameter
, Tue Jan 14 14:02:39 2020: GMM converted to Variational GMM
, Tue Jan 14 14:02:48 2020: iteration 1, lowerbound -3.806892
, Tue Jan 14 14:02:48 2020: iteration 2, lowerbound -3.671685
, Tue Jan 14 14:02:48 2020: iteration 3, lowerbound -3.513013
, Tue Jan 14 14:02:48 2020: iteration 4, lowerbound -3.314503
, Tue Jan 14 14:02:48 2020: iteration 5, lowerbound -3.099595
, Tue Jan 14 14:02:48 2020: iteration 6, lowerbound -2.904015
, Tue Jan 14 14:02:49 2020: dropping number of Gaussions to 7
, Tue Jan 14 14:02:49 2020: iteration 7, lowerbound -2.746088
, Tue Jan 14 14:02:49 2020: dropping number of Gaussions to 6
, Tue Jan 14 14:02:49 2020: iteration 8, lowerbound -2.631124
, Tue Jan 14 14:02:49 2020: dropping number of Gaussions to 5
, Tue Jan 14 14:02:49 2020: iteration 9, lowerbound -2.544140
, Tue Jan 14 14:02:49 2020: dropping number of Gaussions to 3
, Tue Jan 14 14:02:49 2020: iteration 10, lowerbound -2.467195
, Tue Jan 14 14:02:49 2020: iteration 11, lowerbound -2.405028
, Tue Jan 14 14:02:49 2020: iteration 12, lowerbound -2.363316
, Tue Jan 14 14:02:49 2020: iteration 13, lowerbound -2.332732
, Tue Jan 14 14:02:49 2020: iteration 14, lowerbound -2.313282
, Tue Jan 14 14:02:49 2020: iteration 15, lowerbound -2.307444
, Tue Jan 14 14:02:49 2020: dropping number of Gaussions to 2
, Tue Jan 14 14:02:49 2020: iteration 16, lowerbound -2.302929
, Tue Jan 14 14:02:49 2020: iteration 17, lowerbound -2.299261
, Tue Jan 14 14:02:49 2020: iteration 18, lowerbound -2.299256
, Tue Jan 14 14:02:49 2020: iteration 19, lowerbound -2.299255
, Tue Jan 14 14:02:49 2020: iteration 20, lowerbound -2.299254
, Tue Jan 14 14:02:49 2020: iteration 21, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 22, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 23, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 24, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 25, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 26, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 27, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 28, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 29, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 30, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 31, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 32, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 33, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 34, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 35, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 36, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 37, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 38, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 39, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 40, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 41, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 42, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 43, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 44, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 45, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 46, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 47, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 48, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 49, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: iteration 50, lowerbound -2.299253
, Tue Jan 14 14:02:49 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398611]
β = [178.04509222601396, 95.95490777398611]
m = [4.250300733269907 79.2868669443618; 2.00022925777537 53.85198717246129]
ν = [180.04509222601396, 97.95490777398611]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484738 -0.0076440490423277125; 0.0 0.008581705166333308], [0.37587636119484563 -0.008953123827346287; 0.0 0.012748664777409473]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9753570978529966
avll from llpg:  -0.9753570978529948
avll direct:     -0.9753570978529947
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.018478701464081
avll from llpg:  -1.0184787014640808
avll direct:     -1.0184787014640808
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.176334     0.00316183   0.0688705    0.00898857   -0.0562431    0.111823     0.0599198    0.173751     0.037201    -0.034893     0.017881    -0.076162    -0.0200702  -0.130307     0.184182    -0.0217238    0.0212438    0.0916249    0.201323     0.0219693  -0.00100045  -0.0280092   0.0634428  -0.0195819    0.028126     0.0538615
 -0.0422755    0.0654265    0.0656012    0.0397934     0.057087    -0.182613     0.0388321   -0.062161    -0.0001485    0.0880067    0.114813     0.0403583   -0.053015   -0.136523     0.00912702  -0.11993     -0.141593    -0.101652     0.147854    -0.0235425   0.0516185   -0.0942353   0.0218626   0.0376399   -0.218228     0.121281
 -0.212357     0.0675347   -0.00587103   0.0765155    -0.0869586    0.10524     -0.0348455    0.101146    -0.223303     0.0942443   -0.0638018    0.039424    -0.190476    0.0306938    0.0275443   -0.0540353    0.125208     0.0088988   -0.066678    -0.0679832   0.10534     -0.258657    0.132932   -0.0442924    0.084732    -0.155238
  0.137473     0.0905127    0.0644127   -0.0346029     0.0772299    0.123378    -0.00258222  -0.184483     0.130326    -0.0332756   -0.112095    -0.0370965    0.133032    0.0310982    0.0660571    0.0789634   -0.113612     0.0870472   -0.0963719   -0.09944    -0.0992278   -0.233405   -0.119624    0.0290911   -0.128538     0.049984
  0.0909102    0.0847156   -0.114844    -0.102962     -0.0176277    0.155585    -0.0102405   -0.200078    -0.0913404    0.0324945    0.00815139   0.0623388   -0.0259156   0.184345    -0.112855     0.20021     -0.032841     0.242548     0.149815    -0.037417    0.105057     0.157107    0.112133   -0.105056    -0.114135    -0.032295
  0.0403207    0.01984     -0.0335906    0.0714125     0.0125266    0.0874053   -0.0077854   -0.082911     0.0434913    0.0047162    0.028334    -0.0335231    0.0683678  -0.181634     0.059878    -0.134298     0.16463      0.0633542   -0.0552636   -0.154717    0.175935    -0.0531298   0.0284485   0.0590179   -0.0157991    0.252538
  0.104143     0.0373015    0.0762291    0.0461216    -0.0264832   -0.261918     0.0752247    0.0735862    0.0961942   -0.192568    -0.0345765   -0.0707894   -0.0656271   0.0662878   -0.073291    -0.0377166   -0.00350904   0.0347144    0.0259247   -0.0484026  -0.0171919   -0.0818535  -0.20467     0.104021     0.00246701  -0.00553553
 -0.0268742   -0.20402     -0.0934504   -0.082058      0.00818162   0.12133     -0.129946     0.372594     0.158345    -0.0763325    0.0439697   -0.0237922    0.0336895  -0.0201952    0.0579108   -0.0243242    0.0179834   -0.0167101    0.0582926   -0.151184   -0.0852119    0.0520735   0.146573    0.0444962   -0.0859547   -0.147699
  0.040774    -0.112908    -0.0530368   -0.141305      0.0559905    0.0822002   -0.0951807    0.0719248   -0.125396     0.111041     0.00808526   0.0978392   -0.0404249   0.147308     0.0544014   -0.264648     0.0500799   -0.0983055   -0.099101     0.0388431  -0.0463809   -0.0810994   0.0826379   0.0731159   -0.260635     0.0240701
 -0.129795     0.200928    -0.142132     0.00733817    0.10876     -0.0327402    0.0797117    0.0101081    0.060868    -0.186426    -0.0583352    0.0329075   -0.18387     0.0454879   -0.0784787   -0.161728     0.152865     0.0263952   -0.100333    -0.0543259   0.0311295   -0.0751115   0.125613    0.0670904   -0.076893    -0.0351129
 -0.0904905    0.0232482   -0.0576622    0.0676271    -0.0965285   -0.0914144    0.151888    -0.0336448    0.206999    -0.00520614   0.0618943    0.0303123    0.0770066   0.148239     0.0403595    0.065294    -0.0491116   -0.109877     0.106068    -0.0276118   0.00804695  -0.0162553   0.0918929  -0.0572906    0.0256895   -0.0895289
  0.190362     0.00630589  -0.149802     0.110381     -0.0656862    0.151634     0.0131345    0.0332464   -0.136858     0.114426     0.0257645   -0.0724588   -0.146152   -0.0333572    0.0473972   -0.0671443    0.0477985    0.0912019   -0.00522252  -0.163062   -0.0106084    0.10154    -0.0895951   0.0856993    0.0603555   -0.162594
 -0.120421     0.0158617    0.0901277   -0.0578183     0.00787639  -0.217747    -0.0427223   -0.189977    -0.018585     0.0433662   -0.183437    -0.0414297   -0.0648235   0.0983043    0.0734546    0.088257    -0.0608436    0.0833273   -0.133479    -0.061557   -0.112246     0.0595473  -0.177224    0.00482143   0.175079     0.0921864
  0.113839    -0.109472    -0.0137085   -0.00541044    0.00949554  -0.00208216   0.0191922    0.193734     0.098366     0.0601946    0.00157093   0.0650656   -0.0761371   0.13524     -0.0945648    0.140418     0.139839    -0.155191    -0.0699424    0.161958    0.0144503   -0.174135    0.0417856  -0.127454    -0.0446365   -0.112621
 -0.14482     -0.131899    -0.0629785    0.0513067     0.0723141   -0.008699     0.040569     0.126752    -0.0942184    0.00780428  -0.0920081    0.348088     0.248409   -0.200942     0.151247    -0.00394372  -0.0553925   -0.0925476    0.109978     0.0165972   0.188591    -0.142456   -0.137297   -0.0884667   -0.033756    -0.112623
  0.00772795  -0.0341017   -0.196613    -0.0948751    -0.213169     0.173966    -0.0196669   -0.00419679  -0.0443825    0.0521625    0.0526798    0.0129259    0.0992474  -0.0488277    0.0403925    0.111442     0.0358558   -0.0803719   -0.0629717    0.100803   -0.00091708   0.0226614  -0.167853    0.0833168    0.0637668    0.131471
  0.00834586   0.262107    -0.0923873    0.0696676     0.0792656   -0.0119476    0.0256211   -0.0292817    0.0722196    0.0236742   -0.0205315   -0.127816    -0.0419022  -0.0771125    0.171923     0.0842687   -0.0164148   -0.0569906   -0.0519219   -0.0123144  -0.011585     0.0252618   0.0419222   0.14362     -0.0294072   -0.027667
  0.0821251   -0.0165481   -0.157028    -0.0736152     0.0968648   -0.111564    -0.114259     0.012896     0.183084    -0.270751    -0.0448954   -0.00612569   0.103122   -0.0398217   -0.115933    -0.0626628    0.0658996    0.0249781   -0.109565    -0.0423923  -0.081863     0.0129798   0.056513   -0.00231253   0.125487     0.031855
 -0.0122236    0.0634039    0.0797192   -0.00603995   -0.029178    -0.0604655   -0.016173     0.124665     0.229051    -0.18457     -0.0315995    0.02416     -0.0186908  -0.0852336    0.115481    -0.256423     0.0149395    0.0855429    0.061538     0.130701   -0.0796587   -0.100274    0.124248   -0.0173805    0.184711    -0.0794893
  0.00470986  -0.0437409   -0.126377     0.0595295    -0.0330537   -0.0573768    0.0240574   -0.185679    -0.0266091    0.0361499   -0.0713093    0.0418451   -0.0680576   0.0525222    0.0835552   -0.112004     0.0259936    0.0197818   -0.0920407   -0.134345   -0.147235     0.0128831   0.0909334   0.111911     0.107094    -0.0296271
  0.00723199  -0.0055539    0.00521552   0.1167        0.149383     0.227044    -0.046122     0.0374744    0.00370067  -0.0358928   -0.0811006   -0.0174866    0.0736399   0.0118534   -0.022648    -0.0199208    0.0547935    0.189525    -0.120458     0.0448616  -0.169545     0.0370553   0.233877    0.0233919   -0.0828498   -0.107595
  0.122859    -0.0254538   -0.0476416   -0.0556912     0.0693471    0.102325    -0.0351232    0.114819     0.184235     0.0167418    0.0378765   -0.119081     0.0772324  -0.116641     0.119343    -0.119138     0.0456909   -0.172918     0.0564734   -0.0469061   0.0349631    0.0603883   0.138232   -0.14658     -0.112202     0.0068859
 -0.0590978    0.240258     0.0445543   -0.000106262  -0.030669     0.0328804    0.178591     0.151958     0.0355936   -0.142905    -0.103663     0.0613992   -0.0757829   0.00112481  -0.0501491   -0.109213     0.0198885    0.168318     0.0757253    0.0264436  -0.0384716    0.0538574  -0.108015   -0.0844557   -0.0220308    0.110082
 -0.176293    -0.0841602    0.0393378   -0.186617     -0.0294243    0.0244806   -0.111466    -0.161059     0.173366     0.0653654    0.140289     0.0977904   -0.0688827  -0.00755966  -0.100765     0.0848015   -0.111426     0.0172285   -0.0287957    0.0362096  -0.096034     0.0443155  -0.0278546  -0.362811     0.0532176    0.183572
 -0.058662     0.0356142   -0.00574466  -0.0167554    -0.0118902    0.233796     0.0508812   -0.129039     0.0843196   -0.016341     0.157391    -0.0952748   -0.0281422  -0.0657401   -0.0391311    0.245783    -0.0671154   -0.0389539    0.0901892    0.05901    -0.0218055   -0.219202   -0.0991412  -0.0554107    0.0566095    0.0195104
  0.0711126    0.107471    -0.103064    -0.0660933     0.0282898    0.0681035   -0.162323    -0.0955832   -0.0540981   -0.0185964   -0.279098     0.087642    -0.104385    0.0040518   -0.32582     -0.0523847   -0.0955752    0.0539486    0.107851    -0.0910048  -0.120568    -0.18417    -0.0038572   0.0796848   -0.0264144    0.0419999
  0.0252018    0.107631     0.079023    -0.126999     -0.136845    -0.0311833    0.089916     0.131271    -0.105044    -0.126669     0.0183927    0.148       -0.10657    -0.0219206    0.0829235   -0.0407394    0.0120876   -0.00860156   0.103103     0.0598043   0.126404    -0.0245102   0.0142444  -0.28077      0.158717     0.0364821
  0.151438    -0.00689697  -0.033255    -0.0821683     0.033281     0.0710374    0.036052    -0.0288709    0.082781     0.0800394    0.00143209  -0.0260845    0.191386   -0.0116206   -0.00292576   0.100621    -0.145463    -0.0458452    0.0625469    0.01376    -0.0914514    0.0331013   0.0847526   0.324883    -0.0477189    0.0122967
 -0.0944911   -0.060431     0.028657     0.136405      0.0608969   -0.0221248    0.0634825   -0.0285191    0.184417     0.168454    -0.0942206   -0.141332    -0.0198977  -0.0661331    0.252516     0.156281     0.0212146    0.0765799   -0.0798843   -0.156135   -0.0436299   -0.0715992   0.0436113  -0.0104703   -0.106878     0.0545451
 -0.199185     0.0853504    0.0980759    0.0231877     0.0753122    0.088993    -0.339014    -0.106706     0.0558779   -0.0392132    0.0430866    0.180189     0.0907073   0.113719     0.00260689   0.0283824    0.036738    -0.16191      0.301934    -0.0739134  -0.151867     0.158705   -0.0416424  -0.0450826   -0.0676783    0.107425
  0.0459129    0.0877302   -0.119002     0.0469258    -0.0988542    0.123839     0.0575379    0.0624517   -0.072819    -0.00240058  -0.116055    -0.00865912   0.0840823   0.0821455   -0.149276    -0.131732     0.102352     0.116319    -0.0813749    0.0195649   0.0760793   -0.0309793   0.0580953  -0.0746908   -0.0391085   -0.104791
  0.0392264    0.0301294    0.180297     0.138003      0.123626    -0.0534354   -0.00405907  -0.202842    -0.0741243    0.112667    -0.0785073    0.0227708   -0.0695263  -0.147911    -0.209294     0.213374     0.114002    -0.18799     -0.0642291    0.0106781   0.150683     0.14988     0.0112937   0.0273094   -0.239393     0.0483612kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4112907471425078
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411345
[ Info: iteration 2, average log likelihood -1.411263
[ Info: iteration 3, average log likelihood -1.410360
[ Info: iteration 4, average log likelihood -1.403046
[ Info: iteration 5, average log likelihood -1.390721
[ Info: iteration 6, average log likelihood -1.386772
[ Info: iteration 7, average log likelihood -1.385948
[ Info: iteration 8, average log likelihood -1.385565
[ Info: iteration 9, average log likelihood -1.385329
[ Info: iteration 10, average log likelihood -1.385170
[ Info: iteration 11, average log likelihood -1.385053
[ Info: iteration 12, average log likelihood -1.384963
[ Info: iteration 13, average log likelihood -1.384888
[ Info: iteration 14, average log likelihood -1.384823
[ Info: iteration 15, average log likelihood -1.384763
[ Info: iteration 16, average log likelihood -1.384707
[ Info: iteration 17, average log likelihood -1.384653
[ Info: iteration 18, average log likelihood -1.384598
[ Info: iteration 19, average log likelihood -1.384538
[ Info: iteration 20, average log likelihood -1.384471
[ Info: iteration 21, average log likelihood -1.384398
[ Info: iteration 22, average log likelihood -1.384320
[ Info: iteration 23, average log likelihood -1.384234
[ Info: iteration 24, average log likelihood -1.384134
[ Info: iteration 25, average log likelihood -1.384008
[ Info: iteration 26, average log likelihood -1.383839
[ Info: iteration 27, average log likelihood -1.383616
[ Info: iteration 28, average log likelihood -1.383357
[ Info: iteration 29, average log likelihood -1.383084
[ Info: iteration 30, average log likelihood -1.382786
[ Info: iteration 31, average log likelihood -1.382433
[ Info: iteration 32, average log likelihood -1.382049
[ Info: iteration 33, average log likelihood -1.381675
[ Info: iteration 34, average log likelihood -1.381320
[ Info: iteration 35, average log likelihood -1.380973
[ Info: iteration 36, average log likelihood -1.380614
[ Info: iteration 37, average log likelihood -1.380241
[ Info: iteration 38, average log likelihood -1.379874
[ Info: iteration 39, average log likelihood -1.379538
[ Info: iteration 40, average log likelihood -1.379238
[ Info: iteration 41, average log likelihood -1.378954
[ Info: iteration 42, average log likelihood -1.378644
[ Info: iteration 43, average log likelihood -1.378283
[ Info: iteration 44, average log likelihood -1.377825
[ Info: iteration 45, average log likelihood -1.376951
[ Info: iteration 46, average log likelihood -1.375813
[ Info: iteration 47, average log likelihood -1.375381
[ Info: iteration 48, average log likelihood -1.375214
[ Info: iteration 49, average log likelihood -1.375136
[ Info: iteration 50, average log likelihood -1.375095
┌ Info: EM with 100000 data points 50 iterations avll -1.375095
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4113451803360544
│     -1.4112628837081553
│      ⋮
└     -1.375094946869731
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.375167
[ Info: iteration 2, average log likelihood -1.375037
[ Info: iteration 3, average log likelihood -1.374072
[ Info: iteration 4, average log likelihood -1.366319
[ Info: iteration 5, average log likelihood -1.350277
[ Info: iteration 6, average log likelihood -1.341761
[ Info: iteration 7, average log likelihood -1.338854
[ Info: iteration 8, average log likelihood -1.337656
[ Info: iteration 9, average log likelihood -1.337057
[ Info: iteration 10, average log likelihood -1.336714
[ Info: iteration 11, average log likelihood -1.336503
[ Info: iteration 12, average log likelihood -1.336369
[ Info: iteration 13, average log likelihood -1.336280
[ Info: iteration 14, average log likelihood -1.336219
[ Info: iteration 15, average log likelihood -1.336174
[ Info: iteration 16, average log likelihood -1.336140
[ Info: iteration 17, average log likelihood -1.336112
[ Info: iteration 18, average log likelihood -1.336088
[ Info: iteration 19, average log likelihood -1.336068
[ Info: iteration 20, average log likelihood -1.336050
[ Info: iteration 21, average log likelihood -1.336035
[ Info: iteration 22, average log likelihood -1.336022
[ Info: iteration 23, average log likelihood -1.336012
[ Info: iteration 24, average log likelihood -1.336003
[ Info: iteration 25, average log likelihood -1.335996
[ Info: iteration 26, average log likelihood -1.335990
[ Info: iteration 27, average log likelihood -1.335985
[ Info: iteration 28, average log likelihood -1.335981
[ Info: iteration 29, average log likelihood -1.335978
[ Info: iteration 30, average log likelihood -1.335975
[ Info: iteration 31, average log likelihood -1.335973
[ Info: iteration 32, average log likelihood -1.335971
[ Info: iteration 33, average log likelihood -1.335969
[ Info: iteration 34, average log likelihood -1.335968
[ Info: iteration 35, average log likelihood -1.335967
[ Info: iteration 36, average log likelihood -1.335966
[ Info: iteration 37, average log likelihood -1.335965
[ Info: iteration 38, average log likelihood -1.335964
[ Info: iteration 39, average log likelihood -1.335964
[ Info: iteration 40, average log likelihood -1.335963
[ Info: iteration 41, average log likelihood -1.335963
[ Info: iteration 42, average log likelihood -1.335962
[ Info: iteration 43, average log likelihood -1.335962
[ Info: iteration 44, average log likelihood -1.335961
[ Info: iteration 45, average log likelihood -1.335961
[ Info: iteration 46, average log likelihood -1.335960
[ Info: iteration 47, average log likelihood -1.335960
[ Info: iteration 48, average log likelihood -1.335959
[ Info: iteration 49, average log likelihood -1.335959
[ Info: iteration 50, average log likelihood -1.335958
┌ Info: EM with 100000 data points 50 iterations avll -1.335958
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3751671924970397
│     -1.375037005131449
│      ⋮
└     -1.3359579739151881
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336108
[ Info: iteration 2, average log likelihood -1.335968
[ Info: iteration 3, average log likelihood -1.335584
[ Info: iteration 4, average log likelihood -1.332128
[ Info: iteration 5, average log likelihood -1.317935
[ Info: iteration 6, average log likelihood -1.302319
[ Info: iteration 7, average log likelihood -1.294993
[ Info: iteration 8, average log likelihood -1.291407
[ Info: iteration 9, average log likelihood -1.289248
[ Info: iteration 10, average log likelihood -1.287657
[ Info: iteration 11, average log likelihood -1.286232
[ Info: iteration 12, average log likelihood -1.284727
[ Info: iteration 13, average log likelihood -1.282978
[ Info: iteration 14, average log likelihood -1.280928
[ Info: iteration 15, average log likelihood -1.279374
[ Info: iteration 16, average log likelihood -1.278774
[ Info: iteration 17, average log likelihood -1.278545
[ Info: iteration 18, average log likelihood -1.278382
[ Info: iteration 19, average log likelihood -1.278200
[ Info: iteration 20, average log likelihood -1.277913
[ Info: iteration 21, average log likelihood -1.277355
[ Info: iteration 22, average log likelihood -1.276302
[ Info: iteration 23, average log likelihood -1.275044
[ Info: iteration 24, average log likelihood -1.274247
[ Info: iteration 25, average log likelihood -1.273820
[ Info: iteration 26, average log likelihood -1.273487
[ Info: iteration 27, average log likelihood -1.273200
[ Info: iteration 28, average log likelihood -1.272959
[ Info: iteration 29, average log likelihood -1.272789
[ Info: iteration 30, average log likelihood -1.272692
[ Info: iteration 31, average log likelihood -1.272642
[ Info: iteration 32, average log likelihood -1.272616
[ Info: iteration 33, average log likelihood -1.272599
[ Info: iteration 34, average log likelihood -1.272588
[ Info: iteration 35, average log likelihood -1.272578
[ Info: iteration 36, average log likelihood -1.272570
[ Info: iteration 37, average log likelihood -1.272563
[ Info: iteration 38, average log likelihood -1.272557
[ Info: iteration 39, average log likelihood -1.272551
[ Info: iteration 40, average log likelihood -1.272545
[ Info: iteration 41, average log likelihood -1.272540
[ Info: iteration 42, average log likelihood -1.272535
[ Info: iteration 43, average log likelihood -1.272531
[ Info: iteration 44, average log likelihood -1.272526
[ Info: iteration 45, average log likelihood -1.272522
[ Info: iteration 46, average log likelihood -1.272518
[ Info: iteration 47, average log likelihood -1.272514
[ Info: iteration 48, average log likelihood -1.272510
[ Info: iteration 49, average log likelihood -1.272506
[ Info: iteration 50, average log likelihood -1.272502
┌ Info: EM with 100000 data points 50 iterations avll -1.272502
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3361082476400459
│     -1.3359681077633203
│      ⋮
└     -1.272502328725007
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.272682
[ Info: iteration 2, average log likelihood -1.272465
[ Info: iteration 3, average log likelihood -1.271055
[ Info: iteration 4, average log likelihood -1.258700
[ Info: iteration 5, average log likelihood -1.223005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.193439
[ Info: iteration 7, average log likelihood -1.189342
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.173245
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.176682
[ Info: iteration 10, average log likelihood -1.180965
[ Info: iteration 11, average log likelihood -1.172908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.169856
[ Info: iteration 13, average log likelihood -1.178006
[ Info: iteration 14, average log likelihood -1.169982
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.165387
[ Info: iteration 16, average log likelihood -1.186564
[ Info: iteration 17, average log likelihood -1.176927
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.169533
[ Info: iteration 19, average log likelihood -1.174644
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.162354
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.169962
[ Info: iteration 22, average log likelihood -1.173247
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.161049
[ Info: iteration 24, average log likelihood -1.177687
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.165402
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.168360
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.170044
[ Info: iteration 28, average log likelihood -1.171921
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.160215
[ Info: iteration 30, average log likelihood -1.175783
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.163607
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.166753
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.168347
[ Info: iteration 34, average log likelihood -1.170664
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.159568
[ Info: iteration 36, average log likelihood -1.175197
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.163102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.166172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.167297
[ Info: iteration 40, average log likelihood -1.169479
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.158326
[ Info: iteration 42, average log likelihood -1.173885
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.161900
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.165189
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.166469
[ Info: iteration 46, average log likelihood -1.168880
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.157825
[ Info: iteration 48, average log likelihood -1.173419
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.161456
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.164828
┌ Info: EM with 100000 data points 50 iterations avll -1.164828
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2726819919488797
│     -1.27246545729513
│      ⋮
└     -1.1648278933721452
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.166248
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.161338
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     4
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.156624
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.154296
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.118918
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.093483
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     10
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094732
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.096866
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.075614
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.113867
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.084206
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.095127
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.082592
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.103718
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.077524
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.095683
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.093032
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097486
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.083125
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104265
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.078250
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.096212
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.093040
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.097489
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083182
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.098597
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.081504
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.091552
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.095473
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.093891
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.085400
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.100761
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.081079
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.092619
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.087532
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.096394
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.086164
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.101279
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.081493
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.093102
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.087871
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.096409
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.086159
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.101320
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081528
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.093157
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.087905
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.096409
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     11
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086157
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.101324
┌ Info: EM with 100000 data points 50 iterations avll -1.101324
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1662481192187093
│     -1.1613383155792902
│      ⋮
└     -1.101323630421508
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4112907471425078
│     -1.4113451803360544
│     -1.4112628837081553
│     -1.410359705778508
│      ⋮
│     -1.0964093041059304
│     -1.0861567107904162
└     -1.101323630421508
32×26 Array{Float64,2}:
  0.16934      -0.0688604   -0.0319568   -0.0683881    0.042804     0.0617108    0.0398127   -0.0395887   0.175754     0.103232    -0.000142995  -0.102483     0.259182    -0.0152569    0.00410343   0.083071    -0.763311    -0.0505396    0.0855882   0.0044601   -0.0830831     0.041373    0.155055     0.3255      -0.091176     0.210819
  0.175724      0.117738    -0.0300493   -0.120023     0.0234744    0.074278     0.0386159   -0.0174944   0.0126796    0.0878273    0.00168951    0.041893     0.144073    -0.0107386   -0.00754273   0.123818     0.393581    -0.0762739    0.0549114   0.00861643  -0.10256       0.0201143   0.00871172   0.323788    -0.0017784   -0.137107
 -0.0324958    -0.115735    -0.0603405   -0.159756     0.0550818   -0.0398464   -0.0863045    0.0974892  -0.126625    -0.402133     0.0117318     0.0978372   -0.0410989    0.138543    -0.0792901   -0.626237    -0.104602    -0.0933511   -0.0181414   0.122266    -0.0479109    -0.0789172   0.133821     0.0700101   -0.177704     0.0457288
  0.0904136    -0.128833    -0.10362     -0.125562     0.0546684    0.209064    -0.113869     0.0553971  -0.12512      0.634499     0.00773071    0.0981774   -0.0450427    0.155445     0.133889     0.122523     0.10725     -0.102444    -0.209559   -0.0333533   -0.0385927    -0.0822181   0.0918108    0.0723611   -0.205437     0.036074
  0.16296       0.0347746    0.0794324    0.0311479   -0.0255835   -0.257902     0.0935198    0.0638931   0.096681    -0.162165    -0.0323653    -0.0660004   -0.066971     0.0619599   -0.0865754   -0.0324475    0.0187522    0.0200983    0.0140699  -0.0368478   -0.0127083    -0.0797218  -0.203704     0.0982055   -0.00418539  -0.0104432
  0.0665981    -0.0167817   -0.149251    -0.0778041    0.0947688   -0.108195    -0.133725     0.0111989   0.168188    -0.263126    -0.0320782     3.88634e-5   0.142321    -0.0377004   -0.113025    -0.038185     0.0525848    0.0324794   -0.105298   -0.0410252   -0.0779578     0.0273713   0.0381214   -0.00107698   0.138702     0.0295219
 -0.0901113     0.0236042   -0.0572511    0.0905122   -0.0777434   -0.0896735    0.228431    -0.0132431   0.193269     0.00541194   0.0604671     0.0301764    0.0454423    0.13843      0.0330704    0.0608542   -0.0213383   -0.173039     0.101648   -0.032168    -1.98323      -0.0172087   0.0703732   -0.022541     0.00115102  -0.109293
 -0.079049      0.0238075   -0.061465     0.116978    -0.0549557   -0.0878076    0.181442    -0.0442066   0.203827    -0.0249496    0.0578155     0.0312115    0.184813     0.139359     0.0326578    0.0598124   -0.0912752   -0.047026     0.100661   -0.0181348    2.06653      -0.0146248   0.101612    -0.084452     0.0458207   -0.0681269
 -0.0148993     0.0453666    0.0827839    0.0225631   -0.0293249   -0.0603339    0.020857     0.12017     0.253515    -0.196242    -0.0387698     0.0150433   -0.0191771   -0.0303217    0.123329    -0.257795     0.015134     0.0833158    0.073066    0.131858    -0.0822467    -0.106408    0.131877    -0.0102465    0.238056    -0.074998
  0.0206971     0.10198      0.0710651   -0.108042    -0.12751     -0.0256354    0.139144     0.12769    -0.118477    -0.140397     0.00718246    0.148635    -0.107181    -0.0225863    0.091006    -0.0417764    0.00613051  -0.00502374   0.069564    0.0765703    0.114924     -0.0327847   0.0229782   -0.271332     0.123205     0.048847
 -0.124818      0.225786    -0.143974     0.00883785   0.13042     -0.0279117    0.0960828    0.0128935   0.0719566   -0.180987    -0.0749899     0.0182185   -0.175741     0.031898    -0.0792346   -0.175836     0.160835     0.0165352   -0.101195   -0.0445621    0.010898     -0.0977865   0.120956     0.0624585   -0.0678115   -0.00921066
  0.00889051   -0.0741102   -0.192991    -0.0954908   -0.229805     0.173413     0.0101839   -0.0043216  -0.0395845    0.0551567    0.0485414     0.00285228   0.0979143    0.0424429    0.048416     0.0797007    0.0142243   -0.0827378   -0.0469183   0.104699     0.0129021     0.0271698  -0.171105     0.0831593    0.0631556    0.126616
  0.00605343   -4.89709e-5  -0.139698    -0.0608041   -0.674406    -0.0571142    0.0288568   -0.310879   -0.244524     0.0587879   -0.091372     -0.0468546   -0.09161      0.0423925    0.0372263   -0.114126    -0.00260809   0.017111    -0.128818   -0.152702    -0.131744      0.0606238   0.0621362    0.15463     -0.0432747   -0.147955
 -0.00145682   -0.0823905   -0.113515     0.10226      0.604523    -0.0573323   -0.00984828  -0.0878871   0.159344     0.0175825   -0.0483634     0.125181    -0.0519795    0.0651889    0.17859     -0.107837     0.0559873    0.0204186   -0.0491634  -0.0854133   -0.186419     -0.0560012   0.118538     0.0943971    0.263906     0.0838064
  0.0446359     0.013236    -0.0406629    0.00823078  -0.0157414    0.124622    -0.0503699   -0.0516952   0.0407617   -0.0221828    0.0310227     0.00643377   0.0601204   -0.206328     0.0701134   -0.135266     0.163543     0.0678619   -0.101922   -0.146895     0.292137     -0.0487109   0.0219121    0.0610677   -0.0252341   -0.517049
  0.0409781     0.00773206  -0.0275841    0.13136     -0.0345806    0.0683873   -0.0489172   -0.152725    0.0395053   -0.00254333   0.0397285    -0.113143     0.0705617   -0.155297     0.0489975   -0.142013     0.164512     0.0576946   -0.1256     -0.159474     0.06545      -0.0647619   0.0332649    0.0669248   -0.0160898    1.08026
  0.0887997    -0.104113    -0.0229214    0.00345831   0.00163617   0.00920747   0.0286221    0.193028    0.079655     0.0663454    0.028798      0.0655471   -0.0816666    0.15284     -0.0989075    0.142695     0.147302    -0.164775    -0.0680234   0.126658     0.000518606  -0.168828    0.0456761   -0.125288    -0.0388489   -0.109811
 -0.0356285     0.0645901   -0.0273887    0.0152831    0.00533261   0.157064    -0.0817625   -0.0392958   0.0049485    0.0143691    0.0713129     0.015992    -0.00943541  -0.00929075   0.00455657   0.0576761    0.0201427   -0.0379095    0.139797   -0.050837    -0.0604495     0.0259963  -0.0765279   -0.0180858    0.00344246  -0.00383683
 -0.135313     -0.0963312    0.0232948    0.162158     0.0775941   -0.0138361    0.0631166   -0.0273943   0.227549     0.222149    -0.0991352    -0.129973    -0.0138985   -0.0654139    0.258866     0.145839     0.00763939   0.0859469   -0.0678692  -0.163899    -0.0517162    -0.0585299   0.0285188    0.00763762  -0.11482      0.0339586
 -0.0943015     0.155349    -0.0467821    0.0903222   -0.0149118    0.0648115   -0.0047316    0.0449702  -0.075401     0.0497364   -0.0333685    -0.0200625   -0.12381     -0.0253218    0.106303     0.00618597   0.0698926   -0.0270423   -0.0381315  -0.0395852    0.0622259    -0.117782    0.0978486    0.0506788    0.0438827   -0.0955742
  0.0146612     0.0256801    0.229128     0.164378     0.108602    -0.334953    -0.211471    -0.20936    -0.0887241    0.109298     0.0635461     0.0224101   -0.0350492   -0.0716824   -0.162029     0.129957     0.0904674   -0.229504    -0.0878736   0.0124316   -0.0103643     0.153391    0.128186     0.0213997   -0.141927     0.0564922
  0.070643      0.0267081    0.126104     0.132762     0.150662     0.35634      0.218572    -0.210874   -0.0534306    0.119762    -0.204101      0.00103981  -0.0883432   -0.102589    -0.252279     0.266934     0.126362    -0.137092    -0.0184067   0.0321822    0.289575      0.137869   -0.142293     0.0206367   -0.337684     0.0276225
 -0.0720895    -0.179187    -0.098087    -0.0114425    0.0253942    0.0628758   -0.0466868    0.29232     0.0439479   -0.047629    -0.0220333     0.149681     0.14427     -0.0948574    0.0904854   -0.0409232   -0.0191566   -0.0360031    0.0757839  -0.0808809    0.0423957    -0.0460598   0.0151302   -0.0200469   -0.0545779   -0.166411
 -0.102717      0.0281818    0.0743969   -0.0463922   -0.0050465   -0.145027    -0.054669    -0.155599   -0.0308961    0.0361121   -0.175478     -0.00598829  -0.0512317    0.0836134    0.0615985    0.0570793   -0.0311498    0.0782261   -0.070444   -0.0710622   -0.073165      0.0567858  -0.100375    -0.0065727    0.13149      0.0194681
  0.19493      -0.00510386   0.0680765    0.0170055   -0.0704383    0.103135     0.0459456    0.187575    0.0369729   -0.0347105    0.0219771    -0.0786524   -0.01139     -0.13771      0.193391    -0.047603     0.0230819    0.073899     0.194359    0.0280062   -0.00234537   -0.0149509   0.0644376   -0.0201806    0.0377482    0.034912
  0.0811407     0.0821418   -0.0613418   -0.0248602    0.00754124   0.104783    -0.0391674   -0.0769381   0.00564486  -0.0156179   -0.170725      0.0212262    0.0136943    0.0453536   -0.136191    -0.0384925   -0.046554     0.0914504   -0.024292   -0.0546281   -0.0551629    -0.15267    -0.025519     0.030767    -0.052622    -0.000921961
  0.000594614  -0.00290665   0.00905258   0.130473     0.0926388    0.228206    -0.0629766    0.0347144   0.0081805   -0.091122    -0.083637     -0.0284649   -0.0194342    0.0121476    0.0112546   -0.135944     0.0785879    0.144724    -0.138224    0.0212105   -0.179094      0.0374454   0.238967    -0.00816634  -0.128042    -0.113348
  0.0835729     0.0819866   -0.118654    -0.0903813   -0.0142881    0.157705     0.00153179  -0.168697   -0.0897465    0.0359603    0.00597515    0.053086    -0.0292718    0.144286    -0.107066     0.195336    -0.0176045    0.263314     0.13212     0.0250098    0.111853      0.149484    0.113859    -0.0789392   -0.106152    -0.0423784
  0.043033     -0.0225825   -0.180353    -0.115908     0.0726042    0.131122    -0.0334998    0.182871    0.178151     0.00452476  -0.0402637    -0.249144    -0.0265046   -0.948657     0.0137607   -0.124096     0.0473584   -0.132347     0.0232411  -0.0316727    0.0417645     0.036701    0.220494    -0.127751    -0.0863256    0.0260628
  0.0471027    -0.022747     0.0816701    0.0490493    0.0682198    0.078563    -0.033873     0.0556421   0.179442     0.0304851    0.1219       -0.0423111    0.153208     0.715064     0.32571     -0.118263     0.0406676   -0.159238     0.115246   -0.0779462    0.0329251     0.105116    0.0592561   -0.14226     -0.109252     0.0384976
 -0.00817204    0.14015      0.0586952    0.00902648   0.00276611  -0.063799     0.131027     0.0664514   0.0276015   -0.0602279    0.00519955    0.0501644   -0.0913657   -0.0707947   -0.0070566   -0.0968464   -0.0293623    0.0343115    0.143995    0.014667     0.00748166   -0.0220652  -0.0413526    0.00102713  -0.14138      0.111917
 -0.15725      -0.0591938    0.0626582   -0.165922    -0.0231831    0.0348767   -0.107794    -0.158381    0.178133     0.0986022    0.151121      0.0831142   -0.0426657   -0.0475091   -0.0635093    0.0317096   -0.14211     -0.0143082   -0.031768    0.0319862   -0.0817942     0.0380991   0.0182686   -0.325809     0.0334136    0.177457[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.081532
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.068354
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.079259
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.069330
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.079923
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066756
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.081367
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.068168
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│     10
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079048
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069340
┌ Info: EM with 100000 data points 10 iterations avll -1.069340
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.653490e+05
      1       6.889020e+05      -1.764470e+05 |       32
      2       6.624069e+05      -2.649510e+04 |       32
      3       6.472205e+05      -1.518638e+04 |       32
      4       6.379410e+05      -9.279459e+03 |       32
      5       6.308458e+05      -7.095187e+03 |       32
      6       6.241901e+05      -6.655707e+03 |       32
      7       6.186741e+05      -5.516070e+03 |       32
      8       6.154588e+05      -3.215269e+03 |       32
      9       6.135092e+05      -1.949549e+03 |       32
     10       6.120061e+05      -1.503133e+03 |       32
     11       6.110654e+05      -9.407412e+02 |       32
     12       6.106102e+05      -4.551901e+02 |       32
     13       6.103975e+05      -2.126452e+02 |       32
     14       6.102557e+05      -1.418150e+02 |       32
     15       6.101476e+05      -1.081189e+02 |       32
     16       6.100808e+05      -6.676982e+01 |       32
     17       6.100417e+05      -3.917140e+01 |       32
     18       6.100205e+05      -2.117407e+01 |       32
     19       6.100074e+05      -1.307586e+01 |       29
     20       6.099976e+05      -9.824111e+00 |       30
     21       6.099930e+05      -4.594400e+00 |       25
     22       6.099899e+05      -3.137903e+00 |       23
     23       6.099877e+05      -2.113000e+00 |       16
     24       6.099870e+05      -7.014338e-01 |       18
     25       6.099863e+05      -7.174148e-01 |       16
     26       6.099857e+05      -6.446298e-01 |       15
     27       6.099850e+05      -7.107184e-01 |       13
     28       6.099843e+05      -7.162770e-01 |       17
     29       6.099837e+05      -5.362286e-01 |       12
     30       6.099833e+05      -3.907693e-01 |        8
     31       6.099828e+05      -4.990943e-01 |       11
     32       6.099824e+05      -4.036577e-01 |        9
     33       6.099819e+05      -5.584375e-01 |       10
     34       6.099815e+05      -4.089138e-01 |        5
     35       6.099811e+05      -3.776051e-01 |        6
     36       6.099808e+05      -2.507143e-01 |        6
     37       6.099806e+05      -2.248243e-01 |        7
     38       6.099804e+05      -1.630005e-01 |        2
     39       6.099804e+05      -1.720177e-02 |        0
     40       6.099804e+05       0.000000e+00 |        0
K-means converged with 40 iterations (objv = 609980.420860877)
┌ Info: K-means with 32000 data points using 40 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332282
[ Info: iteration 2, average log likelihood -1.303228
[ Info: iteration 3, average log likelihood -1.275149
[ Info: iteration 4, average log likelihood -1.239841
[ Info: iteration 5, average log likelihood -1.198179
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.141572
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.112660
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.095223
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.123697
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.104467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.083947
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.075137
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.067297
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.112026
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.101380
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.102671
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     18
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.063643
[ Info: iteration 18, average log likelihood -1.134777
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.086158
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     15
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.054997
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     18
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.079128
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.137796
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.104772
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068042
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      6
│      7
│     15
│      ⋮
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.032113
[ Info: iteration 26, average log likelihood -1.129358
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.078333
[ Info: iteration 28, average log likelihood -1.082648
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     15
│     17
│     18
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.027568
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     12
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.094653
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.134217
[ Info: iteration 32, average log likelihood -1.104047
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.053109
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.074310
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.074606
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.073991
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     17
│     18
│     22
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.047407
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097564
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.060154
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.083068
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     18
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.069862
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082508
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     17
│     20
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.039211
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.100871
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.078157
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.086976
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     20
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.061950
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.084224
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.060007
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     15
│     17
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.047207
┌ Info: EM with 100000 data points 50 iterations avll -1.047207
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.128476    -0.06722      0.0213418    0.157226     0.0752959   -0.0222544    0.0613622   -0.0277981    0.222737     0.212022    -0.097276     -0.131163    -0.0154389  -0.06752      0.260715     0.146851    0.00656369   0.0901062    -0.0699799   -0.156945    -0.0489077   -0.0562247    0.031262     0.0112782   -0.111528     0.0329731
 -0.0696167   -0.0309987   -0.00691952  -0.0682486    0.03186     -0.149498    -0.206739    -0.0668742    0.174017    -0.248382    -0.0767406     0.0162243    0.0228975  -0.0502843    0.077017    -0.0583281  -0.0697963    0.094064     -0.112697    -0.00881835  -0.0948439    0.0501489   -0.0606987   -0.0648696    0.0722018    0.0996904
 -0.193991     0.0909109    0.0409043    0.00966896   0.0543331    0.0867768   -0.27847     -0.0936644    0.0633455   -0.0010174    0.0225008     0.18486      0.092522    0.0940243    0.00613478   0.0421374   0.051253    -0.160978      0.301881    -0.0746889   -0.150414     0.160086    -0.0383328   -0.0332431   -0.0413858    0.0871796
  0.0891897   -0.0225199   -0.166197    -0.104326     0.106364    -0.12281     -0.178684     0.00800788   0.199729    -0.260913    -0.0397733     0.00520044   0.224751   -0.0430442   -0.159056    -0.0489894   0.0732885    0.0342332    -0.111454    -0.0441592   -0.0827333    0.0377744    0.0554144   -0.00157295   0.16287      0.0385797
  0.045035    -0.0227549   -0.0527982   -0.0348827    0.0705045    0.105187    -0.0337788    0.120834     0.179113     0.0167186    0.0403833    -0.148708     0.0605125  -0.134833     0.169956    -0.122153    0.0447161   -0.146095      0.0674173   -0.0539497    0.0377037    0.0707369    0.140651    -0.134717    -0.0967889    0.0317926
 -0.0490548    0.00783772  -0.00422627  -0.0273731    0.00871381   0.241278     0.0247439   -0.123368     0.076611    -0.0304376    0.174596     -0.116358    -0.0148702  -0.074681    -0.0201732    0.230529   -0.0684314   -0.033116      0.0902916    0.0558642   -0.0130341   -0.212461    -0.076776    -0.0545479    0.0294858    0.0181755
 -0.112486     0.0121522    0.0916211   -0.0784357    0.00665769  -0.1926      -0.101004    -0.171303    -0.0203279    0.0424573   -0.178736     -0.0205576   -0.0629616   0.0938848    0.0673391    0.0820161  -0.0540448    0.0663772    -0.088245    -0.0751731   -0.102156     0.0641892   -0.105969     0.00356953   0.149012     0.0722997
  0.0413408    0.0903083   -0.131064     0.0565318   -0.102911     0.124181     0.0665585    0.0629391   -0.0756028    0.00891183  -0.107824      0.00563103   0.0150089   0.0916885   -0.151036    -0.146764    0.103416     0.0896046    -0.0803535    0.0184931    0.073656    -0.0234067    0.0571361   -0.0455932   -0.0236457   -0.114243
 -0.0202593    0.058995     0.0641679    0.0371912    0.033618    -0.153619     0.0401889   -0.0468897    0.00607545   0.0598505    0.127477      0.0352474   -0.0674633  -0.139615    -0.00865258  -0.0912756  -0.139036    -0.11237       0.175878    -0.00207987   0.0289881   -0.0958673    0.0411327    0.0218523   -0.212251     0.120739
  0.0565582    0.101371    -0.102486    -0.0814044    0.0249892    0.0673018   -0.175299    -0.0772362   -0.0390995   -0.0168163   -0.285205      0.0964088   -0.09614     0.00311522  -0.342068    -0.0542333  -0.0827182    0.07247       0.0899353   -0.0902999   -0.122924    -0.176445    -0.00488281   0.0842454   -0.00609669   0.0492176
  0.00796756   0.0740043    0.0811703   -0.0434901   -0.0809465   -0.0462044    0.0872909    0.124692     0.0659583   -0.171653    -0.0180645     0.0824313   -0.0637081  -0.0291185    0.106038    -0.153341    0.011522     0.0391794     0.0776219    0.108334     0.0155687   -0.0745007    0.0792828   -0.148106     0.186929    -0.0115255
  0.149883     0.0631396    0.0478297   -0.0448253    0.0633748    0.12312      0.00166997  -0.203043     0.135758    -0.0455376   -0.101884     -0.0387984    0.155771    0.0665334    0.0847581    0.0811289  -0.111663     0.105465     -0.10638     -0.076483    -0.103272    -0.233633    -0.145086     0.0263109   -0.126234     0.046377
  0.15829      0.0341243    0.0790715    0.0347427   -0.0238663   -0.256959     0.0948239    0.0616177    0.0970666   -0.16123     -0.0319825    -0.0640122   -0.0639625   0.0622553   -0.0855865   -0.0318117   0.0183241    0.0209978     0.0123858   -0.0339047   -0.0123043   -0.0797857   -0.204402     0.0947568   -0.00299398  -0.0131155
 -0.143197    -0.133504    -0.0935845    0.0473933    0.0547738    0.00616923   0.0456443    0.151634    -0.0814679    0.00314326  -0.0929381     0.348408     0.246185   -0.163161     0.154904     0.0191186  -0.037135    -0.0970708     0.10777      0.0139239    0.175459    -0.149459    -0.148089    -0.0760629   -0.0167534   -0.133506
 -0.171643    -0.0791714    0.0603621   -0.18768     -0.0364063    0.0660983   -0.111201    -0.155016     0.215023     0.0790756    0.145239      0.0902099   -0.0524392  -0.0274965   -0.0805115    0.0446928  -0.139808    -0.000372572  -0.0489383    0.0342992   -0.0929313    0.0556888    0.0124056   -0.353053     0.0505522    0.183893
  0.00243269  -0.045536    -0.126429     0.0227166   -0.0308305   -0.0574007    0.00804937  -0.200418    -0.0413868    0.03967     -0.0700985     0.0412698   -0.0700115   0.0525938    0.111432    -0.111355    0.0276709    0.018565     -0.088877    -0.121414    -0.159565     0.00486747   0.0910786    0.124531     0.11804     -0.0358959
 -0.128569     0.21905     -0.142543     0.00815987   0.127651    -0.0232694    0.109021     0.010329     0.0736007   -0.185297    -0.0661334     0.0188247   -0.181833    0.0319984   -0.067515    -0.170587    0.157844     0.0198616    -0.101759    -0.0442835    0.0148011   -0.0826423    0.123318     0.061067    -0.0615741   -0.0135674
 -0.211206     0.0634866   -0.00107522   0.101752    -0.0975668    0.113677    -0.0341185    0.102476    -0.224011     0.0789845   -0.040272      0.0621882   -0.207808    0.0222736    0.0306567   -0.0626609   0.126046    -0.000564877  -0.0358558   -0.0823019    0.112386    -0.256266     0.1542      -0.043823     0.114061    -0.162253
  0.0451975    0.0230833    0.17133      0.150557     0.133705    -0.0129594    0.00034072  -0.206543    -0.0675253    0.113016    -0.0691586     0.00993932  -0.0606187  -0.0898824   -0.20376      0.190546    0.106498    -0.185622     -0.0585165    0.0208355    0.126676     0.14421      0.00448047   0.0263084   -0.236638     0.0419066
 -0.0271065    0.242153     0.054768    -0.0649371   -0.0246195    0.0444127    0.173094     0.139708     0.0485635   -0.145945    -0.113089      0.042943    -0.0896123  -0.00635855  -0.0117414   -0.0893084   0.0938192    0.176805      0.0865213    0.0211737   -0.0319021    0.0735214   -0.0807196   -0.0988276   -0.021676     0.109175
  0.172426     0.0227875   -0.0310197   -0.0934806    0.0331276    0.0677572    0.0393755   -0.0281992    0.0940542    0.0954331    0.000782303  -0.030172     0.201257   -0.0127316   -0.00183418   0.103451   -0.18889     -0.0635196     0.0702923    0.00664313  -0.0926774    0.0308054    0.0821299    0.324591    -0.0467977    0.0381806
 -0.0790494    0.0220155   -0.0625055    0.0999668   -0.060825    -0.0918354    0.202465    -0.0263648    0.206952    -0.0188096    0.0616826     0.0289911    0.112793    0.134912     0.0385662    0.0664092  -0.0635043   -0.108574      0.101007    -0.0247728   -0.0283773   -0.0150948    0.0878549   -0.0488913    0.0233573   -0.0785627
  0.0273182   -0.120495    -0.0851729   -0.138743     0.0557928    0.0943636   -0.0979635    0.0801878   -0.120951     0.112704     0.00960075    0.0973167   -0.0445241   0.14105      0.0336541   -0.248189    0.0113075   -0.0953771    -0.118905     0.041527    -0.045048    -0.0792954    0.111681     0.0723811   -0.195914     0.0356059
  0.00161988   0.00154869   0.00561913   0.121716     0.0954242    0.229727    -0.0672589    0.0270726    0.00406825  -0.0870112   -0.0797925    -0.0253198   -0.0237737   0.00992411   0.00710246  -0.109864    0.070747     0.152444     -0.128449     0.0239597   -0.16883      0.0449497    0.236932    -0.01102     -0.125838    -0.110801
 -0.0313189   -0.21331     -0.0784814   -0.0614003   -0.0146178    0.149527    -0.134064     0.468361     0.158633    -0.0703356    0.0486898     0.0094424    0.0437162  -0.0264451    0.0270394   -0.0636036   0.00711542   0.041485      0.0353634   -0.146798    -0.0657029    0.048834     0.154427     0.0372031   -0.0671933   -0.203082
  0.042437     0.0101808   -0.033645     0.0708103   -0.0255648    0.0958734   -0.0457872   -0.106497     0.0382393   -0.0126418    0.0354337    -0.0528638    0.0645056  -0.179904     0.0596769   -0.138597    0.163362     0.0629076    -0.111641    -0.153697     0.175688    -0.0566824    0.0275477    0.0638573   -0.0207667    0.291759
  0.205748    -0.00737102   0.0685004    0.019419    -0.0747198    0.105695     0.0465469    0.183084     0.0384131   -0.031149     0.0205748    -0.0794999   -0.0189376  -0.140296     0.19242     -0.0525609   0.0256074    0.0781797     0.195929     0.0254277   -0.00432921  -0.00569737   0.0644113   -0.0198022    0.0371475    0.0414543
  0.0900372    0.08126     -0.111471    -0.0992298   -0.0188009    0.148167    -0.00528763  -0.179726    -0.0904263    0.0381873    0.00771491    0.0547942   -0.0310882   0.158966    -0.112469     0.195981   -0.0258396    0.262971      0.152293     0.0316942    0.115382     0.1594       0.119854    -0.0818076   -0.113625    -0.034828
  0.189556     0.00486947  -0.150761     0.117795    -0.0498324    0.133999     0.00430579   0.0615014   -0.127344     0.0934077    0.0356609    -0.0734802   -0.148654   -0.0415761    0.0430163   -0.0907207   0.0290849    0.0901482     0.00353399  -0.152783    -0.0250814    0.108266    -0.0994456    0.0691187    0.0556684   -0.162838
  0.0409126    0.337239    -0.0997221    0.068041     0.0980435   -0.0356704    0.0363891   -0.101574     0.0638491    0.0128162   -0.0210925    -0.19375     -0.0442611  -0.0651543    0.205307     0.0791772  -0.00565638  -0.120392     -0.0552176    0.00260441   0.0044949    0.0231456    0.0536227    0.175081    -0.026287    -0.00511137
  0.00784839  -0.0706239   -0.19296     -0.0943623   -0.225619     0.171292     0.00952399  -0.00444351  -0.0386771    0.0531929    0.0434335     0.00374968   0.0971561   0.0417337    0.0475168    0.0752639   0.017133    -0.0820595    -0.0490056    0.104232     0.0109448    0.0271039   -0.168325     0.0832167    0.062738     0.124858
  0.0878964   -0.108075    -0.00889986  -0.00447473   0.00667586   0.00191596   0.0276875    0.198201     0.0890358    0.0613485    0.0303535     0.0749741   -0.0799744   0.154626    -0.0960405    0.165734    0.144781    -0.171978     -0.0686042    0.140602    -0.00430471  -0.17351      0.045133    -0.127029    -0.0342525   -0.111772[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      7
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.076483
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│     20
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.042911
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│     20
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.024963
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.006003
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      7
│     17
│     20
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.052673
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      7
│     20
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.039554
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      7
│     20
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.029529
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.989890
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      7
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.061417
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│     20
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.037863
┌ Info: EM with 100000 data points 10 iterations avll -1.037863
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0507519   -0.0267229    -0.138161    -0.11328     0.106175      0.13671       0.0609708   -0.0913184    5.72139e-5  -0.0353585    0.015142     -0.0559561     0.0187833   0.0874527   -0.0490372   -0.234664     0.0685556     0.00806254   0.0973141    0.0469592    -0.20181      -0.169785    0.0925017   -0.0881885   -0.0133225   0.028484
  0.019893     0.0731307    -0.0113298   -0.0186415   0.013012     -0.000859355  -0.176242    -0.00615699  -0.105863    -0.0310175   -0.106648      0.0492279     0.143821   -0.0556481    0.00764432   0.0790928    0.128866      0.103018    -0.0636405    0.0582671    -0.028088      0.160243    0.180499    -0.08494     -0.116377   -0.0400223
  0.0654182    0.00486945   -0.0928851   -0.126036   -0.0277394     0.101901      0.0409107    0.0211342   -0.142133     0.0290864   -0.0372438    -0.0450521    -0.166343   -0.0369783    0.0209337    0.0530949   -0.146901     -0.082014    -0.0638365    0.0208724    -0.314778      0.125259   -0.0408273    0.0573762   -0.131825   -0.176441
 -0.0353304    0.134643     -0.0448489    0.052055    0.0440705    -0.156193     -0.0936203   -0.23172     -0.135929     0.209016     0.0462598    -0.0639087    -0.142248    0.0783022    0.0587345   -0.056339     0.0897486    -0.0425372    0.0601296   -0.0451936     0.000340853   0.138357    0.147745    -0.172016     0.145724   -0.0955367
 -0.031965     0.000923017   0.135945     0.048228   -0.0217631    -0.230057      0.00810659   0.00943551  -0.153475    -0.0769767    0.0560811     0.0849037    -0.0184343   0.0572974   -0.0227047   -0.0941912    0.0963941    -0.232422    -0.177907    -0.0300009    -0.0246275    -0.0993799   0.0753168   -0.0748971    0.0682256   0.219402
 -0.0783095    0.0307474     0.0075546    0.0168704  -0.000641337  -0.25682      -0.0643685    0.131923    -0.00604357   0.0190405    0.00148937    0.149698     -0.0891635   0.0774777    0.0519666    0.0697462   -0.00344109    0.122351     0.0837182    0.0143474    -0.125978      0.176999    0.0173871    0.159035    -0.0328407  -0.109866
  0.0197113   -0.159584     -0.0650354   -0.107369    0.00462912   -0.00995302   -0.0366681    0.184868     0.0945968    0.181626     0.203039      0.0518659    -0.230854    0.1254       0.0544737    0.0313711   -0.0688537    -0.123024    -0.00599086  -0.198165     -0.0545195     0.0863814  -0.0451395   -0.026669     0.0238474  -0.0300417
  0.247635     0.215161      0.02534     -0.0354303  -0.104684      0.000882249   0.17361      0.176947     0.00748853  -0.0983847    0.133556     -0.142611     -0.142463   -0.0069726   -0.0267768    0.044057     0.0405582    -0.16793      0.0198372    0.0494119    -0.0188738     0.0301857   0.204854     0.117671    -0.102408   -0.01934
  0.174204    -0.0798095     0.0116063   -0.11367    -0.0863068     0.0876417    -0.0349474   -0.0865791    0.0436376   -0.00898995   0.232956     -0.0153309     0.227537   -0.0370979   -0.307117    -0.0464937   -0.0888628     0.206375    -0.00029421   0.0253622    -0.000825586   0.101491    0.111669    -0.0541136    0.187216   -0.123886
 -0.0848685   -0.0855204    -0.00197843  -0.149155   -0.0614728     0.0634571    -0.128419    -0.0355741    0.130916    -0.171597    -0.0872446    -0.172157      0.028606   -0.15348     -0.0134966    0.194884     0.098441      0.0568101    0.0230249   -0.0456301    -0.0129929    -0.0569531  -0.0562863    0.0310738    0.0312825   0.026276
 -0.156336    -0.0190873    -0.0636253    0.0856872  -0.0888583     0.0470561    -0.170084    -0.0442926   -0.134165    -0.108854    -0.0153364     0.150179     -0.084258   -0.0152749    0.133162    -0.00897626   0.026831     -0.0331393   -0.0403366   -0.19311      -0.0996794     0.0122491   0.104878    -0.0581948    0.0534956  -0.0834382
 -0.00940811  -0.00271851    0.0110467   -0.0748787  -0.10303       0.122568      0.117193    -0.113653     0.0693797    0.0405044    0.126452     -0.0622916     0.0266647  -0.0552019    0.00130354   0.093626     0.128051      0.00652873   0.127647    -0.0289567    -0.0563606    -0.0190055  -0.013621     0.0148795    0.0695763   0.0241026
 -0.0362564    0.07181       0.0368053   -0.0469372  -0.209087      0.149293      0.123561     0.0311478   -0.103688    -0.00497111  -0.0547051    -0.000373955  -0.0289128  -0.032215     0.0123687   -0.088639     0.120253      0.0389168   -0.087348     0.0072357    -0.0524917    -0.0174353  -0.0601469    0.0377146   -0.0154956  -0.0870746
 -0.0465814   -0.0550149     0.0286263   -0.0288732  -0.0546583    -0.0173837     0.0712402   -0.0527789   -0.112814     0.0972845    0.0116358    -0.201135      0.0228205  -0.0236531   -0.135921    -0.0519728    0.0764595     0.177763    -0.0994779    0.157467      0.0436086    -0.143559    0.0861381   -0.0332439    0.182477    0.0299163
 -0.182831     0.087648     -0.0513482    0.0037203   0.0542003    -0.158465     -0.0844781    0.0606042   -0.00328882   0.115436    -0.137879      0.026827     -0.0531545   0.083968     0.0250167   -0.0723481   -0.0827087    -0.0270422   -0.126183    -0.132066     -0.0264387     0.136371   -0.0265179    0.05996     -0.0738822   0.12022
  0.0630741    0.0290512     0.0925732   -0.124532   -0.00321647   -0.166179     -0.0879258   -0.126896    -0.218242    -0.0664635    0.0771597     0.182156      0.25276    -0.142322     0.173232     0.0386809   -0.0797347    -0.117584    -0.116761    -0.157699     -0.0494651    -0.0422178   0.0370556    0.133857    -0.0683661   0.0966634
 -0.132619    -0.189725      0.119152    -0.085603    0.0219748     0.178459     -0.124259    -0.0125373   -0.0208028    0.0685999    0.154006      0.299355      0.179793   -0.00606412  -0.0582833    0.0306848    0.139888     -0.0106759    0.114249    -0.0360892    -0.0672449     0.10873    -0.00569961  -0.00497502   0.0107975   0.100077
 -0.113942     0.2368       -0.0972038    0.169456   -0.0302116    -0.186228     -0.0352751    0.036476    -0.0186906    0.130476     0.00893614   -0.125185      0.0544331   0.0932085    0.0700426    0.161478     0.0819042     0.134434     0.162688     0.0506757     0.147986      0.0186695   0.167379    -0.00717545   0.0642513   0.185761
  0.0676793    0.0882352    -0.0446476    0.0796351  -0.191879      0.0793771    -0.152625    -0.00498999  -0.101077    -0.0131117   -0.0538572    -0.123379     -0.0557959   0.174041    -0.164143    -0.0770692    0.0453644     0.123506     0.0914829    0.124778      0.129019      0.13981    -0.120093     0.109147    -0.0204961   0.237036
  0.0791297    0.132022     -0.100832     0.016531   -0.0514776    -0.0587328     0.132222    -0.0339986   -0.0837742   -0.0972005    0.0972127     0.0692588    -0.0576795   0.09013     -0.0505143    0.0323466    0.0181852     0.0718536    0.127814     0.121107     -0.00671725    0.0539781   0.111389    -0.0802674   -0.0727843  -0.0189601
  0.0843468   -0.0300469    -0.131743     0.0519212   0.0876256    -0.112149      0.12463     -0.120192     0.088271    -0.133451    -0.0243959    -0.0348346     0.0520065   0.106575    -0.0775973   -0.0900168   -0.134947      0.019733     0.00559448   0.107638      0.102499     -0.113281   -0.098479     0.0881058   -0.215144    0.00495821
 -0.0300339    0.059299      0.0228212   -0.0863358  -0.0426595    -0.0214826    -0.0262923    0.0159692    0.0696796    0.0703851   -0.0354424    -0.0197339    -0.038597    0.0600629    0.106583     0.092696     0.206577     -0.181703    -0.00807511   0.0164088    -0.00244759   -0.0669124   0.0250817   -0.0295645   -0.0699273  -0.00928214
  0.0288146    0.0692196     0.0924961   -0.0985934   0.0449237    -0.0529106     0.128443     0.174906    -0.0142361    0.137003     0.0602261     0.0263676    -0.0584708   0.0941155   -0.0642839    0.0453432   -0.0766701     0.0304871   -0.0386923   -0.0878905    -0.0304098    -0.149259   -0.0212521   -0.0939761    0.0425704  -0.0558625
 -0.184604    -0.128143     -0.0679707    0.0288725   0.00748792   -0.0365668     0.054618     0.173758    -0.0653549    0.142574    -0.0232047    -0.0175601    -0.101578   -0.0837775    0.0422968    0.0356126    0.0765417     0.0032516   -0.149378    -0.0547415    -0.0335828    -0.0656858  -0.126916     0.0755738    0.0692048  -0.180247
  0.105618    -0.0129818    -0.0772343    0.0282779  -0.121779     -0.223322      0.131657    -0.166701     0.126729     0.0368819   -0.113246     -0.0642052    -0.0412258  -0.0883092   -0.0117502   -0.0248182   -0.00743854    0.189017     0.0153916    0.000842725   0.151732     -0.0941267  -0.0242444    0.0832835   -0.0186241  -0.142065
  0.0696301    0.0202246     0.203458    -0.0198444  -0.0479634    -0.202342      0.0827278   -0.0137813    0.0748652    0.00212762   0.170333     -0.00414678    0.0191355   0.137285    -0.0124318    0.1824       0.0709271     0.00303383   0.160659    -0.0936923     0.291004      0.0835911  -0.0479853    0.0625524   -0.0149097   0.0149905
  0.0336909    0.254629      0.0242542   -0.081518    0.0527184    -0.0211624    -0.174344     0.146916    -0.108894     0.257298    -0.000191104   0.0364605     0.112224   -0.134837    -0.163566     0.192315    -0.000994257  -0.0907159    0.0438295    0.176909     -0.0308939     0.14924     0.00308648   0.0493727    0.054981   -0.153528
 -0.0237798   -0.0251327    -0.24341     -0.294298   -0.17073       0.126379     -0.193355     0.0630829    0.104189     0.00915601  -0.121853      0.0243503     0.0124461   0.00347989   0.0104022    0.0145918    0.244657      0.139942     0.00251976   0.0863523    -0.0399442     0.0155651   0.160573     0.050652     0.108104   -0.127839
 -0.0804199   -0.107494     -0.0560453    0.0825766  -0.211769     -0.178952      0.0180531   -0.0896241   -0.0155791   -0.0453589   -0.0563146     0.149028      0.0264775   0.0151286   -0.114428     0.0215328    0.0105382     0.166855    -0.0181472    0.0462374    -0.107569     -0.047551   -0.0612794    0.0667146    0.0220774   0.0510733
  0.0734899   -0.00274837    0.153712    -0.0733689  -0.039218     -0.109521      0.115869    -0.0639601   -0.00398423   0.11336      0.096074      0.173032      0.100777    0.0305787    0.0884757   -0.0383447   -0.0619889     0.123834    -0.102462     0.21106       0.0286212    -0.111256    0.0200321    0.124454     0.0911325  -0.0722727
 -0.030675    -0.0300212     0.157569     0.11185    -0.0851367    -0.0714551    -0.106095     0.17562     -0.0431637   -0.141314    -0.0273738     0.163944     -0.0529568   0.0156731    0.17647      0.074929     0.0374437     0.175264     0.196259     0.0235372     0.0661332    -0.0289612   0.00783854   0.128556    -0.131606   -0.0130276
 -0.00196935   0.00075506   -0.0169561    0.0800012  -0.0525092     0.0444927     0.101805    -0.147874     0.00856376   0.0133778    0.0728232    -0.105401      0.0782186  -0.00898838   0.0738861   -0.0997918    0.148441      0.0911244    0.144833    -0.183959      0.0373636     0.0972215   0.0383534    0.0671024    0.0821172  -0.0760503kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4173686862518915
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417387
[ Info: iteration 2, average log likelihood -1.417335
[ Info: iteration 3, average log likelihood -1.417298
[ Info: iteration 4, average log likelihood -1.417254
[ Info: iteration 5, average log likelihood -1.417200
[ Info: iteration 6, average log likelihood -1.417133
[ Info: iteration 7, average log likelihood -1.417048
[ Info: iteration 8, average log likelihood -1.416933
[ Info: iteration 9, average log likelihood -1.416747
[ Info: iteration 10, average log likelihood -1.416397
[ Info: iteration 11, average log likelihood -1.415726
[ Info: iteration 12, average log likelihood -1.414639
[ Info: iteration 13, average log likelihood -1.413392
[ Info: iteration 14, average log likelihood -1.412476
[ Info: iteration 15, average log likelihood -1.412023
[ Info: iteration 16, average log likelihood -1.411842
[ Info: iteration 17, average log likelihood -1.411773
[ Info: iteration 18, average log likelihood -1.411747
[ Info: iteration 19, average log likelihood -1.411737
[ Info: iteration 20, average log likelihood -1.411733
[ Info: iteration 21, average log likelihood -1.411731
[ Info: iteration 22, average log likelihood -1.411731
[ Info: iteration 23, average log likelihood -1.411730
[ Info: iteration 24, average log likelihood -1.411730
[ Info: iteration 25, average log likelihood -1.411730
[ Info: iteration 26, average log likelihood -1.411730
[ Info: iteration 27, average log likelihood -1.411729
[ Info: iteration 28, average log likelihood -1.411729
[ Info: iteration 29, average log likelihood -1.411729
[ Info: iteration 30, average log likelihood -1.411729
[ Info: iteration 31, average log likelihood -1.411729
[ Info: iteration 32, average log likelihood -1.411729
[ Info: iteration 33, average log likelihood -1.411729
[ Info: iteration 34, average log likelihood -1.411729
[ Info: iteration 35, average log likelihood -1.411729
[ Info: iteration 36, average log likelihood -1.411729
[ Info: iteration 37, average log likelihood -1.411729
[ Info: iteration 38, average log likelihood -1.411729
[ Info: iteration 39, average log likelihood -1.411729
[ Info: iteration 40, average log likelihood -1.411729
[ Info: iteration 41, average log likelihood -1.411729
[ Info: iteration 42, average log likelihood -1.411729
[ Info: iteration 43, average log likelihood -1.411729
[ Info: iteration 44, average log likelihood -1.411729
[ Info: iteration 45, average log likelihood -1.411729
[ Info: iteration 46, average log likelihood -1.411729
[ Info: iteration 47, average log likelihood -1.411729
[ Info: iteration 48, average log likelihood -1.411729
[ Info: iteration 49, average log likelihood -1.411729
[ Info: iteration 50, average log likelihood -1.411728
┌ Info: EM with 100000 data points 50 iterations avll -1.411728
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417387310741833
│     -1.4173351142769872
│      ⋮
└     -1.411728497486298
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411747
[ Info: iteration 2, average log likelihood -1.411692
[ Info: iteration 3, average log likelihood -1.411652
[ Info: iteration 4, average log likelihood -1.411605
[ Info: iteration 5, average log likelihood -1.411546
[ Info: iteration 6, average log likelihood -1.411476
[ Info: iteration 7, average log likelihood -1.411399
[ Info: iteration 8, average log likelihood -1.411321
[ Info: iteration 9, average log likelihood -1.411248
[ Info: iteration 10, average log likelihood -1.411185
[ Info: iteration 11, average log likelihood -1.411131
[ Info: iteration 12, average log likelihood -1.411083
[ Info: iteration 13, average log likelihood -1.411040
[ Info: iteration 14, average log likelihood -1.410998
[ Info: iteration 15, average log likelihood -1.410956
[ Info: iteration 16, average log likelihood -1.410915
[ Info: iteration 17, average log likelihood -1.410873
[ Info: iteration 18, average log likelihood -1.410831
[ Info: iteration 19, average log likelihood -1.410791
[ Info: iteration 20, average log likelihood -1.410752
[ Info: iteration 21, average log likelihood -1.410715
[ Info: iteration 22, average log likelihood -1.410682
[ Info: iteration 23, average log likelihood -1.410653
[ Info: iteration 24, average log likelihood -1.410627
[ Info: iteration 25, average log likelihood -1.410606
[ Info: iteration 26, average log likelihood -1.410589
[ Info: iteration 27, average log likelihood -1.410575
[ Info: iteration 28, average log likelihood -1.410564
[ Info: iteration 29, average log likelihood -1.410555
[ Info: iteration 30, average log likelihood -1.410548
[ Info: iteration 31, average log likelihood -1.410542
[ Info: iteration 32, average log likelihood -1.410537
[ Info: iteration 33, average log likelihood -1.410534
[ Info: iteration 34, average log likelihood -1.410531
[ Info: iteration 35, average log likelihood -1.410528
[ Info: iteration 36, average log likelihood -1.410526
[ Info: iteration 37, average log likelihood -1.410524
[ Info: iteration 38, average log likelihood -1.410523
[ Info: iteration 39, average log likelihood -1.410522
[ Info: iteration 40, average log likelihood -1.410520
[ Info: iteration 41, average log likelihood -1.410519
[ Info: iteration 42, average log likelihood -1.410518
[ Info: iteration 43, average log likelihood -1.410518
[ Info: iteration 44, average log likelihood -1.410517
[ Info: iteration 45, average log likelihood -1.410516
[ Info: iteration 46, average log likelihood -1.410515
[ Info: iteration 47, average log likelihood -1.410515
[ Info: iteration 48, average log likelihood -1.410514
[ Info: iteration 49, average log likelihood -1.410514
[ Info: iteration 50, average log likelihood -1.410513
┌ Info: EM with 100000 data points 50 iterations avll -1.410513
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4117468859559046
│     -1.4116920407124716
│      ⋮
└     -1.4105134497422038
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410526
[ Info: iteration 2, average log likelihood -1.410475
[ Info: iteration 3, average log likelihood -1.410432
[ Info: iteration 4, average log likelihood -1.410380
[ Info: iteration 5, average log likelihood -1.410315
[ Info: iteration 6, average log likelihood -1.410235
[ Info: iteration 7, average log likelihood -1.410146
[ Info: iteration 8, average log likelihood -1.410053
[ Info: iteration 9, average log likelihood -1.409967
[ Info: iteration 10, average log likelihood -1.409892
[ Info: iteration 11, average log likelihood -1.409831
[ Info: iteration 12, average log likelihood -1.409782
[ Info: iteration 13, average log likelihood -1.409741
[ Info: iteration 14, average log likelihood -1.409707
[ Info: iteration 15, average log likelihood -1.409676
[ Info: iteration 16, average log likelihood -1.409646
[ Info: iteration 17, average log likelihood -1.409618
[ Info: iteration 18, average log likelihood -1.409590
[ Info: iteration 19, average log likelihood -1.409563
[ Info: iteration 20, average log likelihood -1.409535
[ Info: iteration 21, average log likelihood -1.409507
[ Info: iteration 22, average log likelihood -1.409480
[ Info: iteration 23, average log likelihood -1.409454
[ Info: iteration 24, average log likelihood -1.409429
[ Info: iteration 25, average log likelihood -1.409405
[ Info: iteration 26, average log likelihood -1.409382
[ Info: iteration 27, average log likelihood -1.409361
[ Info: iteration 28, average log likelihood -1.409341
[ Info: iteration 29, average log likelihood -1.409322
[ Info: iteration 30, average log likelihood -1.409304
[ Info: iteration 31, average log likelihood -1.409288
[ Info: iteration 32, average log likelihood -1.409272
[ Info: iteration 33, average log likelihood -1.409257
[ Info: iteration 34, average log likelihood -1.409243
[ Info: iteration 35, average log likelihood -1.409230
[ Info: iteration 36, average log likelihood -1.409218
[ Info: iteration 37, average log likelihood -1.409206
[ Info: iteration 38, average log likelihood -1.409196
[ Info: iteration 39, average log likelihood -1.409186
[ Info: iteration 40, average log likelihood -1.409177
[ Info: iteration 41, average log likelihood -1.409168
[ Info: iteration 42, average log likelihood -1.409160
[ Info: iteration 43, average log likelihood -1.409153
[ Info: iteration 44, average log likelihood -1.409146
[ Info: iteration 45, average log likelihood -1.409140
[ Info: iteration 46, average log likelihood -1.409134
[ Info: iteration 47, average log likelihood -1.409128
[ Info: iteration 48, average log likelihood -1.409123
[ Info: iteration 49, average log likelihood -1.409117
[ Info: iteration 50, average log likelihood -1.409112
┌ Info: EM with 100000 data points 50 iterations avll -1.409112
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4105258932379892
│     -1.410474656113163
│      ⋮
└     -1.409112347857243
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409117
[ Info: iteration 2, average log likelihood -1.409055
[ Info: iteration 3, average log likelihood -1.408998
[ Info: iteration 4, average log likelihood -1.408932
[ Info: iteration 5, average log likelihood -1.408853
[ Info: iteration 6, average log likelihood -1.408759
[ Info: iteration 7, average log likelihood -1.408654
[ Info: iteration 8, average log likelihood -1.408544
[ Info: iteration 9, average log likelihood -1.408435
[ Info: iteration 10, average log likelihood -1.408331
[ Info: iteration 11, average log likelihood -1.408234
[ Info: iteration 12, average log likelihood -1.408145
[ Info: iteration 13, average log likelihood -1.408065
[ Info: iteration 14, average log likelihood -1.407992
[ Info: iteration 15, average log likelihood -1.407926
[ Info: iteration 16, average log likelihood -1.407865
[ Info: iteration 17, average log likelihood -1.407810
[ Info: iteration 18, average log likelihood -1.407758
[ Info: iteration 19, average log likelihood -1.407709
[ Info: iteration 20, average log likelihood -1.407664
[ Info: iteration 21, average log likelihood -1.407621
[ Info: iteration 22, average log likelihood -1.407581
[ Info: iteration 23, average log likelihood -1.407544
[ Info: iteration 24, average log likelihood -1.407508
[ Info: iteration 25, average log likelihood -1.407475
[ Info: iteration 26, average log likelihood -1.407444
[ Info: iteration 27, average log likelihood -1.407415
[ Info: iteration 28, average log likelihood -1.407388
[ Info: iteration 29, average log likelihood -1.407363
[ Info: iteration 30, average log likelihood -1.407339
[ Info: iteration 31, average log likelihood -1.407317
[ Info: iteration 32, average log likelihood -1.407296
[ Info: iteration 33, average log likelihood -1.407276
[ Info: iteration 34, average log likelihood -1.407258
[ Info: iteration 35, average log likelihood -1.407240
[ Info: iteration 36, average log likelihood -1.407224
[ Info: iteration 37, average log likelihood -1.407208
[ Info: iteration 38, average log likelihood -1.407193
[ Info: iteration 39, average log likelihood -1.407179
[ Info: iteration 40, average log likelihood -1.407166
[ Info: iteration 41, average log likelihood -1.407153
[ Info: iteration 42, average log likelihood -1.407140
[ Info: iteration 43, average log likelihood -1.407128
[ Info: iteration 44, average log likelihood -1.407117
[ Info: iteration 45, average log likelihood -1.407106
[ Info: iteration 46, average log likelihood -1.407095
[ Info: iteration 47, average log likelihood -1.407084
[ Info: iteration 48, average log likelihood -1.407074
[ Info: iteration 49, average log likelihood -1.407064
[ Info: iteration 50, average log likelihood -1.407054
┌ Info: EM with 100000 data points 50 iterations avll -1.407054
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.409117417946552
│     -1.4090545739650073
│      ⋮
└     -1.4070543254914587
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407052
[ Info: iteration 2, average log likelihood -1.406984
[ Info: iteration 3, average log likelihood -1.406916
[ Info: iteration 4, average log likelihood -1.406835
[ Info: iteration 5, average log likelihood -1.406731
[ Info: iteration 6, average log likelihood -1.406602
[ Info: iteration 7, average log likelihood -1.406450
[ Info: iteration 8, average log likelihood -1.406282
[ Info: iteration 9, average log likelihood -1.406110
[ Info: iteration 10, average log likelihood -1.405942
[ Info: iteration 11, average log likelihood -1.405787
[ Info: iteration 12, average log likelihood -1.405645
[ Info: iteration 13, average log likelihood -1.405520
[ Info: iteration 14, average log likelihood -1.405410
[ Info: iteration 15, average log likelihood -1.405313
[ Info: iteration 16, average log likelihood -1.405228
[ Info: iteration 17, average log likelihood -1.405154
[ Info: iteration 18, average log likelihood -1.405088
[ Info: iteration 19, average log likelihood -1.405028
[ Info: iteration 20, average log likelihood -1.404975
[ Info: iteration 21, average log likelihood -1.404925
[ Info: iteration 22, average log likelihood -1.404880
[ Info: iteration 23, average log likelihood -1.404838
[ Info: iteration 24, average log likelihood -1.404799
[ Info: iteration 25, average log likelihood -1.404762
[ Info: iteration 26, average log likelihood -1.404728
[ Info: iteration 27, average log likelihood -1.404695
[ Info: iteration 28, average log likelihood -1.404664
[ Info: iteration 29, average log likelihood -1.404635
[ Info: iteration 30, average log likelihood -1.404606
[ Info: iteration 31, average log likelihood -1.404580
[ Info: iteration 32, average log likelihood -1.404554
[ Info: iteration 33, average log likelihood -1.404530
[ Info: iteration 34, average log likelihood -1.404506
[ Info: iteration 35, average log likelihood -1.404484
[ Info: iteration 36, average log likelihood -1.404462
[ Info: iteration 37, average log likelihood -1.404442
[ Info: iteration 38, average log likelihood -1.404422
[ Info: iteration 39, average log likelihood -1.404403
[ Info: iteration 40, average log likelihood -1.404385
[ Info: iteration 41, average log likelihood -1.404368
[ Info: iteration 42, average log likelihood -1.404351
[ Info: iteration 43, average log likelihood -1.404335
[ Info: iteration 44, average log likelihood -1.404320
[ Info: iteration 45, average log likelihood -1.404305
[ Info: iteration 46, average log likelihood -1.404290
[ Info: iteration 47, average log likelihood -1.404277
[ Info: iteration 48, average log likelihood -1.404263
[ Info: iteration 49, average log likelihood -1.404250
[ Info: iteration 50, average log likelihood -1.404238
┌ Info: EM with 100000 data points 50 iterations avll -1.404238
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.407052319501843
│     -1.4069838823181404
│      ⋮
└     -1.4042379079997338
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4173686862518915
│     -1.417387310741833
│     -1.4173351142769872
│     -1.4172982355675319
│      ⋮
│     -1.4042632100538766
│     -1.4042503364111583
└     -1.4042379079997338
32×26 Array{Float64,2}:
 -0.345447    -0.0340832  -0.331601    -0.33052     -0.434682    -0.0498662  -0.123823     0.183308   -0.406106     0.0285827    0.0734968  -0.264354    -0.225657     0.625539     0.440895     0.0363362    0.336403    -0.178805    -0.417436   -0.627111    0.242506     0.20452      0.0491447    0.103598   -0.124065     0.293877
  0.00140672   0.199319   -0.513433    -0.264015    -0.107577    -0.227502   -0.907818    -0.160923   -0.487453     0.11575     -0.102969   -0.238975    -0.137993    -0.281572     0.186297     0.336242     0.0644247   -0.669684    -0.326307    0.394068    0.124718     0.594893     0.155766     0.19006    -0.249926    -0.103182
 -0.140193    -0.0609726  -0.177753    -0.20715     -0.0925836    0.0242796  -0.0340239    0.065564   -0.0198449    0.0409487    0.159456   -0.10975     -0.10338     -0.132731     0.125855    -0.150791    -0.136439    -0.0820616    0.238245    0.0905668   0.0345831   -0.0492206    0.16014     -0.0614929  -0.0728214   -0.107399
  0.122925     0.0255334   0.0486759    0.137925     0.00563916  -0.0909141   0.0101755   -0.138201   -0.0745886    0.113723    -0.142912    0.117596     0.0271963    0.146178    -0.143611     0.080767     0.129972     0.129004    -0.0936764  -0.0771607   0.0816015    0.106654    -0.0653676    0.12853     0.0148832    0.0448108
  0.436876     0.072224   -0.459821     0.228233    -0.52063      0.640936   -0.0863575   -0.360183    0.300192     0.338285     0.300626   -0.316985    -0.0276286   -0.233399     0.0874877    0.29971     -0.210293    -0.261639     0.106363    0.303112   -0.259339    -0.59581      0.333267     0.217575    0.0235784    0.484162
  0.28456     -0.092174   -0.21214     -0.0670138   -0.463682     0.359802   -0.504607    -0.0925646  -0.438892     0.147242    -0.0191514  -0.266167    -0.0929561   -0.277628    -0.137152    -0.207603    -0.291745    -0.146755     0.391304    0.290502    0.219802     0.592505     0.485133     0.195137    0.317376     0.359622
  0.387939     0.272911   -0.359699     0.41853     -0.0588269    0.346816    0.384745     0.301527   -0.587337    -0.0133342    0.269473    0.851776    -0.473223     0.941816     0.0683696    0.284489    -0.0555492   -0.054213     0.236467   -0.146578    0.0414149   -0.0380057   -0.0568084    0.550841    0.00141058   0.421125
 -0.0883228   -0.0108615  -0.26342      0.508702    -0.222488    -0.112651    0.414961    -0.31879    -0.424063    -0.0482163   -0.120949    0.45172      0.51747      0.138559     0.096071    -0.787172    -0.219257    -0.137377     0.336624   -0.0699728  -0.363273     0.0236133    0.506949     0.175218    0.211041     0.865956
 -0.168748    -0.445539    0.115282    -0.384509    -0.379548     0.115173   -0.1885       0.448769   -0.309436    -0.440028     0.138327   -0.00920832   0.298086    -0.356276    -0.300766     0.301772    -0.122435     0.212729    -0.335144    0.0917164   0.154534    -0.264785    -0.475594     0.104008    0.382213     0.316775
  0.0541057    0.423332    0.592272    -0.122801    -0.181574    -0.306791   -0.0497336   -0.0187994   0.219386    -0.10852      0.0222927  -0.0242281    0.343272     0.0444171   -0.174447     0.57514      0.368576     0.0494874   -0.494628    0.220904   -0.102124     0.0563468    0.0487973    0.252614    0.286855     0.1634
  0.637221     0.0565257   0.208686     0.258898     0.205827     0.124193    0.317758    -0.574563    0.674515     0.135102     0.0168919   0.233359     0.265091    -0.380408    -0.159191    -0.497813    -0.152493     0.449941     0.224127    0.131509    0.044148    -0.493253     0.166245    -0.0585932   0.0340025   -0.302378
  0.406166    -0.228453    0.33227      0.12008     -0.0243795   -0.175108    0.664406    -0.365307    0.245699     0.162136    -0.640817   -0.152233     0.0372065    0.273242    -0.00118338   0.305922    -0.389497     0.324939    -0.133584    0.198912    0.310758    -0.0249694   -0.214344    -0.125494    0.0509972   -0.607618
 -0.103174     0.219786    0.0198439    0.22878     -0.476       -0.233029    0.328192     0.578772    0.00847218   0.110512    -0.18064    -0.248087    -0.138849     0.410369    -0.118281     0.110698     0.423189    -0.202415     0.342481    0.327196   -0.11132      0.302032     0.0260396   -0.773492    0.105748    -0.0666046
 -0.372031    -0.0875154   0.238906     0.36571      0.746889    -0.215114    0.389422     0.22718    -0.112591    -0.0780923   -0.0502252   0.173025     0.00699154   0.189985    -0.102097    -0.526129     0.224744     0.212589     0.239294   -0.313383   -0.0625969    0.0880743    0.0957964   -0.405704    0.0290001   -0.291628
 -0.128287    -0.201554    0.122339    -0.0479464   -0.136067     0.294001    0.581543     0.2978      0.273814    -0.569112     0.464787    0.197811    -0.325209     0.186389     0.231225    -0.157872    -0.112119     0.110561     0.435468   -0.0998907  -0.687       -0.414173    -0.112744    -0.170031    0.228145    -0.0225762
 -0.3546       0.418522   -0.119056    -0.161449    -0.273501    -0.687691    0.44227     -0.0444924   0.0841093   -0.15598      0.652937   -0.608661    -0.168414     0.226227     0.0571798    0.0263929    0.265477     0.208689     0.424438    0.221862    0.734119    -0.564946     0.143911    -0.0882433  -0.151272    -0.280099
 -0.26694     -0.177068    0.0532856   -0.461908    -0.136995     0.177509   -0.453771     0.182284    0.14593     -0.0374445    0.130136   -0.90878     -1.03605     -0.243359    -0.483566     0.549849    -0.00355938   0.0685734    0.0918306   0.0270559   0.00399157   0.170408    -0.293238    -0.156819    0.0459773   -0.80919
 -0.0597548   -0.264469    0.464717    -0.42688     -0.0307206   -0.261227   -0.231012    -0.31417     0.617837     0.429224    -0.235937   -0.758889     0.726065    -0.580447    -0.017202     0.0332827    0.27273     -0.243513    -0.308496    0.192455    0.164258     0.336067     0.149835    -0.745271   -0.256075    -0.373225
  0.556044     0.181623   -0.00174966  -0.373588     0.378197     0.464397   -0.549485    -0.0444637  -0.329815     0.862232     0.458483    0.112064     0.159501    -0.00177131  -0.157382     0.459306     0.212674    -0.0645832   -0.294128   -0.534555    0.411179     0.0277598   -0.454999     0.20242    -0.236997    -0.656418
 -0.0973005    0.124715    0.195245     0.612707     0.40509     -0.161401    0.0377171    0.145454   -0.0799269    0.827684     0.337859   -0.513187     0.288676    -0.0332821   -0.700383    -0.191713     0.414667     0.143028    -0.0383623   0.611793    0.477197     0.35226     -0.574525     0.623627   -0.470214    -0.499682
 -0.272517     0.375458    0.434106     0.0345903    0.0792206   -0.761547   -0.158541     0.0528643   0.0282448   -0.780232    -0.565807    0.521843     0.316608     0.0689604   -0.301063     0.607406     0.295427     0.417241     0.0187146  -0.559903   -1.07433     -0.212184     0.00119382   0.11313     0.0945074    0.356838
 -0.175849     0.133209    0.882635    -0.393436     0.303465    -0.763547    0.014083     0.676782   -0.404552    -0.439803    -0.312598    0.247279     0.00952468   0.156932     0.133768     0.186716     0.265018    -0.199087    -0.488434   -0.165687    0.520848     0.770438    -0.260886     0.0930419  -0.177398    -0.692268
 -0.306437     0.221698    0.296246     0.105882    -0.482258    -0.0471134   0.0567137    0.236309   -0.670484    -0.293257    -0.0435162  -0.201546     0.292087     0.301327    -0.021998     0.140417     0.324964    -0.368526    -0.167243    0.469995    0.378383     0.37616      0.0131345    0.374225    0.397152     0.416738
 -0.901577     0.624388    0.0517318    0.00545442  -0.539695    -0.67396    -0.636837     0.577137    0.530234    -1.0863       0.0588698   0.110881    -0.281807    -0.99955      0.958134    -0.142348     0.525801     0.305537     0.34505    -0.0208954   0.439466     0.0699154    0.535715     0.0826598   0.114386     0.505314
 -0.755624    -0.0122683  -0.114061    -0.690707     0.412688     0.285304   -0.325129    -0.174649    0.0311957    0.00531464   0.788661   -0.0815307    0.382306    -0.566581     0.00375922  -0.511179    -0.145155     0.123493     0.0418429  -0.622501   -0.26622     -0.312576     0.190514     0.68215    -0.391936     0.34294
 -0.332019    -0.611734   -0.513784    -1.46208      0.448338    -0.140174    0.0265307   -0.401398   -0.0914726   -0.499185     0.314032    0.605422     0.129818     0.2258      -0.139035    -0.363967     0.111071     0.922957    -0.0783922   0.220304    0.152734     0.00975579   0.24971      0.334043    0.164885    -0.466588
  0.0607225    0.178913   -0.0705189    0.0999372    0.582941     0.0661844  -0.496632     0.170892    0.233045     0.373979    -0.108085    0.464145    -0.229899    -0.178024    -0.036535    -0.034305    -0.129937    -0.212684     0.168213   -0.220783   -0.869325    -0.0628533   -0.108001    -0.209974   -0.151577    -0.000104994
 -0.0834241   -0.142072   -0.99926      0.352546     0.217227    -0.23319    -0.302483    -0.109074    0.0896246    0.0743697   -0.239324    0.507098    -0.29135      0.180964     0.313375    -0.12857     -0.151366     0.885045    -0.132393   -0.382634   -0.463464    -0.397126    -0.215366    -0.393237   -0.30214     -0.142538
  0.0157772   -0.91639    -0.452659    -0.167326    -0.594882     0.512857    0.00267772   0.342298   -0.15781      0.00711498  -0.427544   -0.0551831    0.313677    -0.0530964    0.0186618    0.0564496   -0.154857     0.424519     0.39368     0.280012   -0.486625    -0.209563    -0.0449613   -1.02555     0.50043      0.0664088
  0.135857    -0.0351668  -0.0429752    0.0707931    0.0507869    0.0298262   0.274073    -0.0130583   0.132873     0.143882     0.0871695   0.138487    -0.0713364    0.13593     -0.0519995   -0.018056    -0.0956998    0.00860516   0.179961   -0.0204167  -0.279802    -0.1998      -0.0320852   -0.43218    -0.0620374   -0.13542
  0.687922    -0.0587929   0.103145     0.387085     0.450769     0.204078   -0.197226    -0.334362    0.12627      0.170512     0.0299787   0.755171     0.218174    -0.495881     0.207128     0.00779233  -0.0847403    0.269877    -0.25074    -0.537339    0.140616    -0.0802177   -0.154463     1.10666    -0.0816225    0.0988342
 -0.160089     0.384776    0.0570025    0.0643562    0.266916    -0.351275    0.238652    -0.699635    0.407611    -0.0590182    0.104774    0.415213    -0.638724     0.161783     0.430368    -0.281952     0.0253367   -0.465613    -0.328932   -0.19325     0.160745     0.111276     0.159429     0.826641   -0.431369     0.0857863[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404226
[ Info: iteration 2, average log likelihood -1.404214
[ Info: iteration 3, average log likelihood -1.404203
[ Info: iteration 4, average log likelihood -1.404192
[ Info: iteration 5, average log likelihood -1.404182
[ Info: iteration 6, average log likelihood -1.404171
[ Info: iteration 7, average log likelihood -1.404162
[ Info: iteration 8, average log likelihood -1.404152
[ Info: iteration 9, average log likelihood -1.404143
[ Info: iteration 10, average log likelihood -1.404133
┌ Info: EM with 100000 data points 10 iterations avll -1.404133
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.187767e+05
      1       6.969772e+05      -2.217996e+05 |       32
      2       6.843349e+05      -1.264226e+04 |       32
      3       6.799066e+05      -4.428316e+03 |       32
      4       6.775611e+05      -2.345513e+03 |       32
      5       6.761109e+05      -1.450167e+03 |       32
      6       6.750888e+05      -1.022112e+03 |       32
      7       6.742534e+05      -8.354231e+02 |       32
      8       6.735564e+05      -6.969298e+02 |       32
      9       6.729265e+05      -6.299423e+02 |       32
     10       6.723304e+05      -5.960696e+02 |       32
     11       6.718329e+05      -4.975349e+02 |       32
     12       6.714074e+05      -4.254544e+02 |       32
     13       6.710439e+05      -3.635737e+02 |       32
     14       6.707449e+05      -2.990021e+02 |       32
     15       6.704809e+05      -2.639349e+02 |       32
     16       6.702269e+05      -2.540441e+02 |       32
     17       6.699996e+05      -2.272890e+02 |       32
     18       6.698129e+05      -1.867311e+02 |       32
     19       6.696436e+05      -1.692854e+02 |       32
     20       6.695113e+05      -1.322386e+02 |       32
     21       6.693892e+05      -1.221931e+02 |       32
     22       6.692640e+05      -1.251999e+02 |       32
     23       6.691424e+05      -1.215626e+02 |       32
     24       6.690286e+05      -1.138077e+02 |       32
     25       6.689054e+05      -1.231634e+02 |       32
     26       6.687699e+05      -1.354733e+02 |       32
     27       6.686557e+05      -1.142500e+02 |       32
     28       6.685508e+05      -1.048521e+02 |       32
     29       6.684571e+05      -9.377171e+01 |       32
     30       6.683571e+05      -9.998717e+01 |       32
     31       6.682558e+05      -1.012852e+02 |       32
     32       6.681626e+05      -9.315534e+01 |       32
     33       6.680685e+05      -9.418155e+01 |       32
     34       6.679781e+05      -9.035314e+01 |       32
     35       6.678971e+05      -8.101671e+01 |       32
     36       6.678271e+05      -7.001969e+01 |       32
     37       6.677633e+05      -6.378184e+01 |       32
     38       6.677053e+05      -5.802470e+01 |       32
     39       6.676471e+05      -5.816272e+01 |       32
     40       6.675928e+05      -5.427821e+01 |       32
     41       6.675430e+05      -4.986561e+01 |       32
     42       6.674967e+05      -4.629300e+01 |       32
     43       6.674519e+05      -4.472089e+01 |       32
     44       6.674057e+05      -4.619850e+01 |       32
     45       6.673574e+05      -4.830382e+01 |       32
     46       6.673064e+05      -5.107880e+01 |       32
     47       6.672608e+05      -4.554461e+01 |       32
     48       6.672136e+05      -4.717081e+01 |       32
     49       6.671743e+05      -3.931364e+01 |       32
     50       6.671374e+05      -3.690281e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667137.4331005926)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416287
[ Info: iteration 2, average log likelihood -1.411208
[ Info: iteration 3, average log likelihood -1.409742
[ Info: iteration 4, average log likelihood -1.408603
[ Info: iteration 5, average log likelihood -1.407427
[ Info: iteration 6, average log likelihood -1.406410
[ Info: iteration 7, average log likelihood -1.405767
[ Info: iteration 8, average log likelihood -1.405427
[ Info: iteration 9, average log likelihood -1.405238
[ Info: iteration 10, average log likelihood -1.405113
[ Info: iteration 11, average log likelihood -1.405020
[ Info: iteration 12, average log likelihood -1.404945
[ Info: iteration 13, average log likelihood -1.404881
[ Info: iteration 14, average log likelihood -1.404825
[ Info: iteration 15, average log likelihood -1.404774
[ Info: iteration 16, average log likelihood -1.404727
[ Info: iteration 17, average log likelihood -1.404684
[ Info: iteration 18, average log likelihood -1.404643
[ Info: iteration 19, average log likelihood -1.404604
[ Info: iteration 20, average log likelihood -1.404567
[ Info: iteration 21, average log likelihood -1.404532
[ Info: iteration 22, average log likelihood -1.404499
[ Info: iteration 23, average log likelihood -1.404467
[ Info: iteration 24, average log likelihood -1.404436
[ Info: iteration 25, average log likelihood -1.404407
[ Info: iteration 26, average log likelihood -1.404380
[ Info: iteration 27, average log likelihood -1.404353
[ Info: iteration 28, average log likelihood -1.404328
[ Info: iteration 29, average log likelihood -1.404303
[ Info: iteration 30, average log likelihood -1.404280
[ Info: iteration 31, average log likelihood -1.404257
[ Info: iteration 32, average log likelihood -1.404236
[ Info: iteration 33, average log likelihood -1.404215
[ Info: iteration 34, average log likelihood -1.404195
[ Info: iteration 35, average log likelihood -1.404175
[ Info: iteration 36, average log likelihood -1.404156
[ Info: iteration 37, average log likelihood -1.404138
[ Info: iteration 38, average log likelihood -1.404121
[ Info: iteration 39, average log likelihood -1.404104
[ Info: iteration 40, average log likelihood -1.404087
[ Info: iteration 41, average log likelihood -1.404071
[ Info: iteration 42, average log likelihood -1.404055
[ Info: iteration 43, average log likelihood -1.404040
[ Info: iteration 44, average log likelihood -1.404025
[ Info: iteration 45, average log likelihood -1.404010
[ Info: iteration 46, average log likelihood -1.403996
[ Info: iteration 47, average log likelihood -1.403983
[ Info: iteration 48, average log likelihood -1.403970
[ Info: iteration 49, average log likelihood -1.403957
[ Info: iteration 50, average log likelihood -1.403945
┌ Info: EM with 100000 data points 50 iterations avll -1.403945
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.431445     0.376351    0.107813    -0.765136    -0.208887   -0.186952    -0.654574     0.241935    0.206807    -0.108421    -0.061027     0.420628     0.23071     -0.214173     0.227039    0.847679     0.0894169  -0.420432    -0.468951    -0.597067   -0.585976      0.185571    0.238045   -0.230803     0.0930864   0.396506
 -0.222623     0.770209   -0.244543     0.77101      0.604972   -0.413716     0.176673    -0.0333069  -0.361942    -0.0271146   -0.978813     0.629454     0.272634     0.331262     0.197703   -0.312664     0.363467   -0.360881    -0.0786246   -0.278611   -0.233987      0.12559    -0.192337    0.0273176    0.0689453   0.444248
  0.314303     0.267272   -0.35125     -0.0860289    0.312652    0.155362    -0.62376     -0.0105192  -0.413784     0.937397     0.340818    -0.221702     0.105385    -0.292995    -0.0692799  -0.0339087   -0.0274373  -0.41179     -0.392361    -0.0485585   0.47743       0.202265   -0.131948    0.138458    -0.358441   -0.558529
 -0.0978005    0.198311   -0.0368479   -0.278111    -0.156196   -0.425636    -0.0826412   -0.609853    0.375484     0.104634     0.565828    -0.148767    -0.473818    -0.0390225    0.220472    0.00299601  -0.212304   -0.353257    -0.198695    -0.061363    0.29323      -0.0854306   0.40819     0.839229    -0.795387   -0.00375003
 -0.399054     0.190258    0.511521     0.149578    -0.0138374  -0.684748     0.303006     0.0891991   0.00552937  -0.997968    -0.360981     0.494591     0.172502     0.122275    -0.171871    0.246198     0.176907    0.381593     0.184996    -0.123096   -0.841094     -0.261498    0.0805636   0.244351     0.157158    0.472525
 -0.0971911   -0.290793   -0.484223     0.0819123   -0.23904    -0.318598     0.467501    -0.585031    0.370183    -0.453765    -0.498061     0.25142     -0.578584     0.378551     0.995855   -0.206538    -0.40625     0.523697    -0.862063    -0.481975    0.260485     -0.0803296  -0.133322   -0.282944     0.0397759  -0.21745
  0.512485     0.0273345   0.311755     0.0124894    0.404607   -0.17455     -0.293798    -0.294097   -0.0303584    0.123602    -0.287393     0.566147     0.176907     0.0273288   -0.303249    0.396975     0.238991    0.462699    -0.367019    -0.400723    0.0349347     0.228311   -0.204637    0.484418    -0.0431833  -0.177081
  0.038966     0.0867446   0.495134    -0.0596575   -0.613235   -0.32813      0.377908    -0.175206    0.195539     0.00757729  -0.251346    -0.318051     0.248055     0.406323    -0.121239    0.530263     0.171166    0.0847754   -0.856893     0.350315    0.263107     -0.350037   -0.153352    0.10486      0.491048   -0.0244921
  0.0324603    0.160259   -0.700192     0.201959     0.0183096   0.331429    -0.0927744    0.213666   -0.193501     0.102894     0.539984     0.610154    -0.608338     0.422837     0.284423   -0.0668956    0.0508641   0.0101719    0.285985    -0.528682   -0.480814     -0.495188   -0.0175936   0.452167    -0.219759    0.424723
  0.00199296   0.27274    -0.107751    -0.512617    -0.466076   -0.0741373    0.023229    -0.468787   -0.397104    -0.214269     0.313268    -0.509721    -0.442833    -0.140291    -0.121228   -0.328255    -0.135979    0.00172997   0.88131     -0.0731913   0.222882      0.310932    0.877061    0.207959     0.3818     -0.126194
  0.117876    -0.0790576   0.406062     0.256479     0.484936    0.128342     0.518189    -0.383436    0.421505    -0.103443     0.472998     0.398619     0.470506    -0.399519    -0.0173431  -0.772349    -0.299349    0.385466     0.134433    -0.224513   -0.0677306    -0.585675    0.042436    0.346819     0.157978   -0.146895
 -0.580945     0.0844593   0.431568    -0.146179     0.157482    0.236895    -0.135704     0.208391   -0.636329    -0.135067     0.871611    -0.328725     0.165959     0.0839134   -0.320897    0.0086883    0.548794   -0.0820392   -0.0350996    0.0425545   0.295604      0.372645   -0.0498275   0.758282     0.297909    0.30482
 -0.106841    -0.258909    0.618467    -0.281358     0.190076   -0.175855     0.00859771  -0.398846    0.716416     0.207031    -0.14626     -0.822018     0.334217    -0.614217    -0.0927675   0.136811     0.284689    0.0223319   -0.132056     0.292952    0.128529      0.136086   -0.0458707  -0.513405    -0.115978   -0.659873
  0.612398     0.316456   -0.281        0.426308    -0.385736    0.423946    -0.107614    -0.271005    0.188862     0.309856     0.225814    -0.0567069    0.276284    -0.302547    -0.104593    0.129995    -0.167248   -0.210358     0.189298     0.305274   -0.289922     -0.390799    0.442129    0.327956     0.169203    0.739898
 -0.866188     0.667405    0.143506     0.0240036   -0.558273   -0.617428    -0.667972     0.601289    0.513631    -1.16689      0.0166492    0.14758     -0.243193    -0.977857     1.05205    -0.205648     0.612194    0.252347     0.376152    -0.0212302   0.512677      0.153282    0.521017    0.151672     0.170313    0.520125
  0.399579    -0.203247   -0.618782     0.00776994  -0.309711   -0.117216    -0.500123    -0.29854     0.161439    -0.14909     -0.325847     0.201549    -0.056422    -0.618882    -0.308823    0.418668    -0.189977    0.871745     0.261583     0.366631   -0.130525     -0.456334    0.182123   -0.207443     0.125259   -0.0147019
 -0.0655307   -1.07165    -0.203172    -0.135549    -0.746821    0.465185    -0.174847     0.233284   -0.368684    -0.0387602   -0.139475    -0.161267     0.416741    -0.29072     -0.127607   -0.101034    -0.443965   -0.13519      0.16916      0.528247   -0.11499       0.0406836   0.271054   -0.470549     0.378452    0.237236
 -0.507054    -0.633681   -0.742143    -1.34103      0.666082   -0.0611574   -0.0554622   -0.253071   -0.144653    -0.568584     0.391259     0.630708     0.328935     0.118308     0.160385   -0.418124    -0.0786034   0.938113    -0.195256     0.199459    0.0207223    -0.323335    0.106216    0.422176     0.0122617  -0.230486
 -0.490902    -0.376547   -0.363544    -0.150393    -0.0738182   0.0197476   -0.0989236   -0.258143   -0.288274     0.205507    -0.235277     0.00433148   0.375811     0.198834     0.0828013  -0.835233     0.154168   -0.0853729    0.284796    -0.590062   -0.136541      0.304277    0.602673   -0.117147    -0.349919    0.495765
  0.0444493   -0.163641   -0.103701    -0.103348    -0.164359    0.270848    -0.0846382    0.0522282  -0.137164    -0.0111342    0.101826     0.0222492   -0.0626451    0.0244993    0.15323    -0.0269557   -0.0905935  -0.250443     0.0776617    0.0374122   0.0203888     0.0141943   0.0892863  -0.00574069   0.0963741   0.0760575
 -0.107345     0.419327   -0.324981     0.258862    -0.846619   -0.00489102   0.290349     0.257601   -0.62993     -0.242005    -0.100958     0.0638653    0.178888     0.396205     0.21993    -0.0580286   -0.023007    0.104098    -0.24649      0.11892     0.549297      0.384213   -0.116994    0.532075     0.406866    0.933089
 -0.251888     0.0941272   0.847948    -0.324112     0.31679    -0.732577     0.0966348    0.652132   -0.413319    -0.431129    -0.261879     0.093223    -0.00327717   0.228231     0.176804    0.189549     0.242397   -0.177338    -0.462574    -0.0879748   0.516115      0.666571   -0.224556    0.0371845   -0.207888   -0.673762
 -0.136856    -0.278249   -0.140343    -0.755817    -0.550957    0.430033    -0.168617     0.361096   -0.0293176   -0.205097     0.253902    -0.384819    -0.473381    -0.103901    -0.339827    0.534747    -0.0313841   0.381728     0.147699    -0.265822   -0.000764259  -0.302244   -0.864969   -0.0476427    0.0990291  -0.396285
  0.112546     0.113292   -0.0076247    0.269982     0.764891    0.607763    -0.605602    -0.160697   -0.0995271   -0.21612     -0.243367     0.118886    -0.404082    -0.458313     0.569826   -0.0654001   -0.46252    -0.431861    -0.0783294    0.337854   -0.747463      0.327299   -0.295967    0.0787445    0.480564    0.207299
  0.579023    -0.210315    0.160023     0.423606    -0.0224675   0.335198     0.62108     -0.0237696  -0.434316     0.0721765   -0.194038     0.348403    -0.292108     1.10539     -0.123351    0.175178    -0.0885987  -0.176827     0.330496     0.184691   -0.0269289     0.266824   -0.208046   -0.271886     0.159226   -0.163449
  0.17443      0.450928    0.558196     0.301215    -0.426107   -0.157398    -0.0973763    0.64812     0.374964     0.508941    -0.174827    -0.307347     0.190106    -0.17298     -0.694762    0.0804314    0.433426   -0.418341     0.241246     0.501926    0.0154663     0.786984   -0.0436416  -0.0542058    0.143908   -0.123748
 -0.527127     0.383124   -0.207989     0.0165785   -0.276058   -0.299587     0.577757     0.445471    0.021845    -0.0676773    0.507929    -0.587389    -0.0486298    0.310749     0.337096   -0.170661     0.317578   -0.148377     0.580805     0.580498    0.111412     -0.368827    0.201634   -0.695603     0.0385598  -0.0290232
  0.461376    -0.109097   -0.0825145    0.122685     0.234611    0.0648511    0.360474    -0.284265    0.554223     0.347308    -0.34902      0.140927    -0.0431133   -0.00241552   0.0771298  -0.159213    -0.303648    0.232215     0.327308     0.236254   -0.0829015    -0.164327   -0.0548744  -0.290368    -0.30781    -0.411701
 -0.158519     0.130188    0.116534     0.0297554    0.0342746  -0.336706     0.116889     0.0562591   0.0112204   -0.00953165  -0.00438673  -0.0463764    0.0207166    0.0748397   -0.139324    0.0336177    0.177856    0.214696     0.00328925   0.0103327   0.01971       0.0393024  -0.0225878  -0.0156139   -0.0334894  -0.0733859
 -0.118483     0.0603476  -0.448231    -0.294228    -0.37839    -0.297522    -0.88082      0.0498465  -0.574379     0.0341575   -0.257399    -0.550814    -0.274088    -0.0141017    0.094892    0.556107     0.199905   -0.548059    -0.253073     0.411533    0.0911597     0.724874    0.0764866  -0.0110179   -0.248342    0.0149367
 -0.237004    -0.141581   -0.00506512   0.23511      0.444417   -0.14942      0.194829     0.498549    0.128607     0.0525331    0.127518     0.218751    -0.130067     0.118979    -0.262909   -0.28843      0.115108    0.452087     0.291712    -0.484763   -0.475463     -0.29488    -0.0807969  -0.693678     0.0383783  -0.347284
  0.155273     0.0923019  -0.100998    -0.0281282    0.0830569   0.0567438   -0.104575    -0.115937    0.0772292    0.362557     0.135146     0.023446     0.00899857  -0.0900277   -0.0387183   0.10383      0.0697365  -0.0216241   -0.0900379   -0.103589    0.0546933    -0.055808   -0.0292185   0.131301    -0.239862   -0.109672[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403933
[ Info: iteration 2, average log likelihood -1.403921
[ Info: iteration 3, average log likelihood -1.403911
[ Info: iteration 4, average log likelihood -1.403900
[ Info: iteration 5, average log likelihood -1.403890
[ Info: iteration 6, average log likelihood -1.403880
[ Info: iteration 7, average log likelihood -1.403871
[ Info: iteration 8, average log likelihood -1.403862
[ Info: iteration 9, average log likelihood -1.403854
[ Info: iteration 10, average log likelihood -1.403845
┌ Info: EM with 100000 data points 10 iterations avll -1.403845
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
