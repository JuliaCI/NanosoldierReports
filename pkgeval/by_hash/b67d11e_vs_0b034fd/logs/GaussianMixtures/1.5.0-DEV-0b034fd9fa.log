Julia Version 1.5.0-DEV.4
Commit 0b034fd9fa (2020-01-03 14:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed PDMats ───────────── v0.9.10
 Installed CMakeWrapper ─────── v0.2.3
 Installed HDF5 ─────────────── v0.12.5
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed DataStructures ───── v0.17.7
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Arpack ───────────── v0.4.0
 Installed Distances ────────── v0.8.2
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed FillArrays ───────── v0.8.2
 Installed SortingAlgorithms ── v0.3.1
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.9.0
 Installed Missings ─────────── v0.4.3
 Installed CMake ────────────── v1.1.2
 Installed BinDeps ──────────── v1.0.0
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed StatsFuns ────────── v0.9.3
 Installed StaticArrays ─────── v0.12.1
 Installed OrderedCollections ─ v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed Distributions ────── v0.21.12
 Installed Parameters ───────── v0.12.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed Clustering ───────── v0.13.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.12
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_xPdm3p/Project.toml`
 [no changes]
  Updating `/tmp/jl_xPdm3p/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_M3SklP/Project.toml`
 [no changes]
  Updating `/tmp/jl_M3SklP/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_PSfank/Project.toml`
 [no changes]
  Updating `/tmp/jl_PSfank/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_KQXpSd/Project.toml`
 [no changes]
  Updating `/tmp/jl_KQXpSd/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_fCWMyt/Project.toml`
 [no changes]
  Updating `/tmp/jl_fCWMyt/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_fCWMyt/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.12
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -949707.4016727773, [5161.431775099856, 94838.56822490017], [1617.735241594093 2700.5914339295946 -4850.8290044469895; -1413.0999454772457 -2958.8646055228423 4815.938516247528], [[6195.111518151761 -1271.5818206102285 -2501.7772361864672; -1271.5818206102288 7541.8539630135565 -4191.120473555949; -2501.7772361864672 -4191.1204735559495 6030.211036219312], [95041.24213825788 918.1895287556014 2449.3510959942414; 918.1895287556015 92410.68919740082 4266.013742261404; 2449.351095994241 4266.013742261404 93896.93140562535]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.475619e+03
      1       1.099896e+03      -3.757231e+02 |        8
      2       1.023752e+03      -7.614386e+01 |        2
      3       9.705869e+02      -5.316479e+01 |        4
      4       9.214373e+02      -4.914960e+01 |        2
      5       8.959665e+02      -2.547081e+01 |        0
      6       8.959665e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 895.9665391932595)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078339
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.850945
[ Info: iteration 2, lowerbound -3.721690
[ Info: iteration 3, lowerbound -3.570467
[ Info: iteration 4, lowerbound -3.383909
[ Info: iteration 5, lowerbound -3.183920
[ Info: iteration 6, lowerbound -3.003933
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.868250
[ Info: iteration 8, lowerbound -2.784886
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.734031
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.689151
[ Info: iteration 11, lowerbound -2.644470
[ Info: iteration 12, lowerbound -2.601802
[ Info: iteration 13, lowerbound -2.556000
[ Info: iteration 14, lowerbound -2.509984
[ Info: iteration 15, lowerbound -2.466495
[ Info: iteration 16, lowerbound -2.427085
[ Info: iteration 17, lowerbound -2.391767
[ Info: iteration 18, lowerbound -2.359914
[ Info: iteration 19, lowerbound -2.332416
[ Info: iteration 20, lowerbound -2.313367
[ Info: iteration 21, lowerbound -2.307456
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302927
[ Info: iteration 23, lowerbound -2.299260
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Jan  4 00:10:46 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Jan  4 00:10:54 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Sat Jan  4 00:10:56 2020: EM with 272 data points 0 iterations avll -2.078339
5.8 data points per parameter
, Sat Jan  4 00:10:58 2020: GMM converted to Variational GMM
, Sat Jan  4 00:11:06 2020: iteration 1, lowerbound -3.850945
, Sat Jan  4 00:11:06 2020: iteration 2, lowerbound -3.721690
, Sat Jan  4 00:11:06 2020: iteration 3, lowerbound -3.570467
, Sat Jan  4 00:11:06 2020: iteration 4, lowerbound -3.383909
, Sat Jan  4 00:11:06 2020: iteration 5, lowerbound -3.183920
, Sat Jan  4 00:11:06 2020: iteration 6, lowerbound -3.003933
, Sat Jan  4 00:11:07 2020: dropping number of Gaussions to 7
, Sat Jan  4 00:11:07 2020: iteration 7, lowerbound -2.868250
, Sat Jan  4 00:11:07 2020: iteration 8, lowerbound -2.784886
, Sat Jan  4 00:11:07 2020: dropping number of Gaussions to 5
, Sat Jan  4 00:11:07 2020: iteration 9, lowerbound -2.734031
, Sat Jan  4 00:11:07 2020: dropping number of Gaussions to 3
, Sat Jan  4 00:11:07 2020: iteration 10, lowerbound -2.689151
, Sat Jan  4 00:11:07 2020: iteration 11, lowerbound -2.644470
, Sat Jan  4 00:11:07 2020: iteration 12, lowerbound -2.601802
, Sat Jan  4 00:11:07 2020: iteration 13, lowerbound -2.556000
, Sat Jan  4 00:11:07 2020: iteration 14, lowerbound -2.509984
, Sat Jan  4 00:11:07 2020: iteration 15, lowerbound -2.466495
, Sat Jan  4 00:11:07 2020: iteration 16, lowerbound -2.427085
, Sat Jan  4 00:11:07 2020: iteration 17, lowerbound -2.391767
, Sat Jan  4 00:11:07 2020: iteration 18, lowerbound -2.359914
, Sat Jan  4 00:11:07 2020: iteration 19, lowerbound -2.332416
, Sat Jan  4 00:11:07 2020: iteration 20, lowerbound -2.313367
, Sat Jan  4 00:11:07 2020: iteration 21, lowerbound -2.307456
, Sat Jan  4 00:11:07 2020: dropping number of Gaussions to 2
, Sat Jan  4 00:11:07 2020: iteration 22, lowerbound -2.302927
, Sat Jan  4 00:11:07 2020: iteration 23, lowerbound -2.299260
, Sat Jan  4 00:11:07 2020: iteration 24, lowerbound -2.299256
, Sat Jan  4 00:11:07 2020: iteration 25, lowerbound -2.299254
, Sat Jan  4 00:11:07 2020: iteration 26, lowerbound -2.299254
, Sat Jan  4 00:11:07 2020: iteration 27, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 28, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 29, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 30, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 31, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 32, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 33, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 34, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 35, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 36, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 37, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 38, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 39, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 40, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 41, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 42, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 43, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 44, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 45, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 46, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 47, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 48, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 49, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: iteration 50, lowerbound -2.299253
, Sat Jan  4 00:11:07 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398356, 178.04509222601638]
β = [95.95490777398356, 178.04509222601638]
m = [2.000229257775348 53.85198717246118; 4.250300733269891 79.28686694436156]
ν = [97.95490777398356, 180.04509222601638]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119487366 -0.008953123827346459; 0.0 0.012748664777409576], [0.18404155547484247 -0.007644049042327304; 0.0 0.008581705166333187]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000009
avll from stats: -0.9910051649737147
avll from llpg:  -0.9910051649737063
avll direct:     -0.9910051649737063
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9912288070144976
avll from llpg:  -0.9912288070144973
avll direct:     -0.9912288070144973
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.00186565   0.00705321   0.114674    -0.0831103    -0.0904896    0.0924734    0.13124     -0.18419      0.0468297    0.0462706   -0.13016     -0.000863916   0.0955131    0.127188    -0.123103    -0.0625403    0.0899928    0.0381176    0.0837635    0.0687349   -0.0352614   -0.0447867   -0.105885    -0.0480028   0.00958864    0.109518
  0.0309847   -0.0458683   -0.0379431    0.101849     -0.0282337   -0.0678167    0.00519133   0.160429    -0.0111467    0.00633455   0.0130247   -0.0381965    -0.116513     0.00960224  -0.0466938   -0.0223477   -0.0345216    0.112985     0.0801102   -0.166821     0.161404     0.0452827    0.010661    -0.0637762   0.11647       0.125815
  0.157002    -0.0840473   -0.0793355   -0.0744082     0.0273271    0.0198708   -0.15052     -0.0346502   -0.0371204    0.109807     0.0352599    0.0195166     0.0409922    0.183463    -0.00412648  -0.0962825    0.208442    -0.20188     -0.0291841   -0.013841    -0.0165944   -0.117986    -0.188412     0.201745   -0.053985      0.0842701
  0.0977396   -0.0356162   -0.00976085   0.0199724     0.050489    -0.0412123   -0.0918419    0.103928    -0.0315692    0.28858      0.0520941    0.0665792     0.00948253   0.0760279    0.085156    -0.0698263    0.191025     0.080566     0.081124     0.0703358    0.106208     0.152349    -0.00710014   0.0296263  -0.157889      0.0173613
  0.0488996   -0.147815    -0.0523911    0.0256382    -0.0775035    0.0447725   -0.0168149   -0.0660165   -0.0137522   -0.16396      0.0916824    0.032729      0.0752716   -0.0733846   -0.0610507    0.149598     0.0992225   -0.0800462    0.123801    -0.0826107    0.0729756   -0.00491474  -0.181971     0.139052   -0.0606847     0.132087
  0.0454887    0.0931428   -0.0791799    0.0429253     0.0209374   -0.0849145   -0.113728    -0.090845    -0.019255    -0.156738    -0.119502    -0.160914      0.115173    -0.0407338   -0.0428085   -0.147379    -0.0366835    0.0669836    0.0143601    0.117748     0.00918482  -0.0462457   -0.0457269    0.148613   -0.000724538  -0.0547251
 -0.0800017   -0.0541429    0.159966     0.0914194     0.0873386   -0.160496     0.16381     -0.0595747   -0.0421467   -0.0671982   -0.0653164    0.0275458    -0.0262527    0.0614361   -0.0812293   -0.0236247   -0.0834364    0.0679235   -0.185915     0.0275081    0.02535     -0.0177506    0.157212     0.0601415   0.119893     -0.013056
 -0.0289044   -0.00518533  -0.111482    -0.0220562     0.00697177  -0.0445495   -0.00753239   0.150869     0.0530788    0.0358397   -0.00996237  -0.0364935     0.0512392   -0.0491289    0.128758     0.134158     0.0391117   -0.224709    -0.0497873   -0.0734297    0.163243     0.084726     0.19679      0.0110971  -0.122708     -0.0236586
  0.08203      0.148252     0.130173    -0.134291     -0.0819236   -0.120961     0.116844    -0.0103239   -0.0235953    0.0561232   -0.0746308   -0.0967674     0.00281829  -0.10875      0.0201353   -0.0512782   -0.0116923    0.0451193   -0.0171892   -0.1474       0.01927     -0.0864234   -0.0504826    0.135595   -0.0797419     0.0589352
  0.0757251   -0.0297469    0.00561051   0.0416244     0.0740361   -0.00748387   0.061038    -0.0800902    0.0678806   -0.0872755   -0.060209     0.0240108    -0.0229787   -0.0270473   -0.100739    -0.164118    -0.325056    -0.136829    -0.115489     0.250987    -0.127996     0.084879     0.132332     0.241368   -0.101629      0.0534472
  0.0657046    0.00780989   0.123552     0.110133      0.0509026    0.124386     0.0575291    0.0374078    0.0161722   -0.155015     0.0984534    0.0256799    -0.058148     0.0216796    0.0141703    0.0603697    0.00432535  -0.0901955    0.0592449   -0.0162718    0.0518542    0.107794     0.11623      0.018492    0.0998606     0.134043
 -0.0626183   -0.045738     0.160464    -0.0706502     0.0487799   -0.0412814    0.0962488    0.231703     0.022031    -0.0963996    0.0599704    0.0157665     0.0973028   -0.0897314    0.149181    -0.266672    -0.0453918    0.0370267    0.151783     0.174571    -0.0161652   -0.0190532    0.160253     0.0421766  -0.0146964     0.0676129
 -0.0905773   -0.152612     0.0748862    0.019979      0.00848656   0.0889539   -0.207151     0.0163574    0.00199302   0.0245618   -0.0374676    0.0399367     0.235863    -0.0324623    0.173786    -0.127158     0.153324     0.0254326    0.0183887    0.0577842   -0.04361      4.70609e-5   0.185769    -0.10631     0.19883       0.112665
  0.167228     0.0307043   -0.0197245    0.0352826     0.0427895    0.044698     0.0165303    0.0856667   -0.0970188    0.145368     0.0688262   -0.0939101    -0.0824391   -0.0709036    0.0631987    0.0178616    0.160688    -0.0799431   -0.0296639    0.00757363  -0.053861    -0.039129    -0.0282079    0.0499662  -0.0559617    -0.0492431
 -0.0263098   -0.0811489   -0.0493012    0.112665     -0.0294532   -0.036706    -0.0519457   -0.194965    -0.223968    -0.0337407   -0.0121863    0.0443632     0.0396403   -0.0484543    0.0897128   -0.00147612  -0.127275     0.102409    -0.162039    -0.0187423   -0.107611     0.0262371   -0.0465889   -0.0817578   0.0200943    -0.0314491
  0.0223684   -0.0809646   -0.00798943   0.000130184  -0.0710805    0.00940857  -0.0556299   -0.0734957   -0.0254445    0.0304046    0.0565535    0.0758705     0.029585    -0.0321698   -0.116144     0.161574    -0.0506937   -0.0699172   -0.0746505   -0.0332742    0.129749    -0.103035    -0.070386     0.111546   -0.0668846     0.00289446
 -0.0435879   -0.0285735   -0.110511    -0.159394     -0.168646     0.0935908    0.132563    -0.0148951   -0.123718     0.0707951    0.0309636   -0.00295086    0.0870745   -0.108057    -0.124429     0.220867     0.0455622   -0.0784399   -0.167822     0.0263289   -0.0618102   -0.122464     0.071729     0.108427   -0.132784     -0.0570009
  0.0468188   -0.00467538  -0.00980336   0.0320388    -0.0917921   -0.0544494   -0.0740715   -0.0658944   -0.0367887   -0.0178697   -0.0494847    0.0247282     0.0104786    0.0525416    0.0179802   -0.101473    -0.0353354    0.0334945    0.138952    -0.0919359   -0.440091    -0.0901112   -0.0713039    0.014755   -0.186078      0.138806
  0.137006    -0.14398     -0.208303    -0.0177014    -0.0949713   -0.0489125   -0.0542715   -0.0485603    0.0418818   -0.135973    -0.181765     0.0541325    -0.02353     -0.0647972    0.0114718   -0.0294543    0.0236221    0.10971     -0.00604055   0.0900089    0.062727     0.118636     0.0743464   -0.0140069  -0.080736      0.047423
 -0.12063     -0.0284664   -0.0890648   -0.0766831    -0.0167051    0.0651812   -0.0614712    0.146514    -0.047622    -0.166682     0.0237838    0.0494176     0.056378    -0.115733    -0.255741     0.037805     0.00717092   0.061375     0.0147084   -0.0798401   -0.103279    -0.0877349    0.0258653    0.0476997  -0.0091614     0.0244396
 -0.0398471   -0.0561707    0.0220656   -0.102162     -0.144711     0.0467385    0.136939    -0.064806    -0.0666333   -0.0713659    0.0254424   -0.2067       -0.0134726   -0.0307096   -0.0709541    0.069838    -0.0680615    0.149817    -0.097143    -0.0220267    0.105019    -0.047009     0.152011    -0.10547     0.0278256    -0.0759564
 -0.0193972   -0.211148    -0.0938729   -0.0367216    -0.06418     -0.087821    -0.123613     0.0303815    0.10525      0.0989873    0.196964    -0.00792248   -0.0747678    0.0159287    0.0769213    0.100582     0.0449606   -0.04243     -0.0383031    0.0612547    0.0241601   -0.0534286    0.168912    -0.029878    0.125757      0.0702427
 -0.0367099    0.0949113   -0.159499    -0.0682017     0.0968608    0.07408     -0.172752    -0.0487429   -0.115804     0.00757783   0.0931786    0.124697     -0.13644     -0.106147     0.0448364    0.0557792   -0.0552004   -0.147909    -0.129979    -0.0260952    0.0364341    0.169828    -0.0454236    0.0570678   0.095666      0.108741
 -0.192674    -0.0970506   -0.187541    -0.076145      0.00612632  -0.323521     0.14892      0.0607493   -0.0770101    0.10538     -0.115144    -0.170329     -0.0253427    0.077401    -0.204588     0.129688     0.0273022    0.0701385   -0.101946    -0.0313679   -0.119605    -0.132048    -0.0248892    0.0855591  -0.00968889    0.0977184
  0.158846    -0.0217422    0.00193105   0.0441536     0.060295     0.0719485    0.0253422    0.00968375   0.092037     0.0824823   -0.0828563   -0.0369898     0.270934    -0.0200685    0.0484204    0.147909     0.131912     0.110962     0.0106204   -0.0226431    0.0731223   -0.0921781   -0.0169699    0.133196    0.0497554    -0.123832
 -0.0392736   -0.123319    -0.0184295    0.00888597   -0.0687872   -0.0213158    0.0542051   -0.0443622    0.127403    -0.0241147    0.00367596   0.0845556     0.0452599    0.133984     0.052081    -0.126019    -0.0374681   -0.0427882   -0.219042    -0.113036     0.00647197   0.160329    -0.0550497   -0.0124174  -0.0113562     0.0504348
  0.0535003   -0.0323226    0.0594954    0.0637164     0.0980268    0.0199523   -0.201981     0.0192535   -0.0389304    0.152145    -0.142223    -0.0224174    -0.0269455    0.0334064   -0.0556376   -0.10828      0.0372661   -0.0962396    0.0250585    0.0282374    0.0359257   -0.0221275    0.0869777   -0.0196539  -0.128495      0.0634809
 -0.1511      -0.0283285    0.0971929    0.0597427     0.0547758   -0.0409572   -0.0939561    0.0947132   -0.0160863    0.245902     0.0638996   -0.242799     -0.0830063   -0.0197373    0.0124794   -0.147661     0.00918766   0.0625509    0.0172601    0.0568577    0.0850078    0.123728    -0.0702073   -0.0537052  -0.0290854    -0.287134
 -0.0359373   -0.170357    -0.0820532   -0.0207099    -0.0851977    0.0454428    0.0175694    0.121316     0.0077772    0.0469418    0.193733    -0.16555      -0.0781277   -0.0491627   -0.104361    -0.00968454  -0.0254591   -0.00544903  -0.134673     0.100667     0.034793     0.0400952   -0.0212644    0.0311789  -0.0513606     0.0870379
  0.0200929    0.0672914    0.0540184    0.109236     -0.0849636   -0.100153    -0.0383251    0.109143     0.0477396   -0.0998084    0.0874954   -0.181753     -0.0137877   -0.103034     0.0119446    0.0120081    0.0620463   -0.14858     -0.189759     0.0269148    0.127768     0.14135     -0.0722985   -0.0393119   0.127041      0.0175572
 -0.141693     0.0132809    0.068118    -0.0688333     0.0361848    0.00158918   0.0562636    0.249803    -0.228908     0.173568     0.0683436   -0.0785341     0.0657079    0.0797327   -0.110271     0.140337    -0.0399244    0.0844049    0.0423184   -0.0608017    0.0805153   -0.13306      0.0166585   -0.182341    0.161257     -0.00227076
  0.0877341    0.10618      0.141221     0.0250117    -0.0562589    0.112975     0.0513185   -0.0268388   -0.118064     0.0740465    0.147642    -0.0674086     0.0239368   -0.0827345    0.115061    -0.218771     0.13773      0.0124395    0.0306983   -0.00386585   0.169067     0.113941     0.0168426    0.0600809  -0.068966     -0.0535071kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.404629113275916
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404704
[ Info: iteration 2, average log likelihood -1.404646
[ Info: iteration 3, average log likelihood -1.404311
[ Info: iteration 4, average log likelihood -1.399318
[ Info: iteration 5, average log likelihood -1.383161
[ Info: iteration 6, average log likelihood -1.374160
[ Info: iteration 7, average log likelihood -1.372861
[ Info: iteration 8, average log likelihood -1.372511
[ Info: iteration 9, average log likelihood -1.372336
[ Info: iteration 10, average log likelihood -1.372222
[ Info: iteration 11, average log likelihood -1.372137
[ Info: iteration 12, average log likelihood -1.372060
[ Info: iteration 13, average log likelihood -1.371972
[ Info: iteration 14, average log likelihood -1.371851
[ Info: iteration 15, average log likelihood -1.371671
[ Info: iteration 16, average log likelihood -1.371400
[ Info: iteration 17, average log likelihood -1.371017
[ Info: iteration 18, average log likelihood -1.370481
[ Info: iteration 19, average log likelihood -1.369742
[ Info: iteration 20, average log likelihood -1.368875
[ Info: iteration 21, average log likelihood -1.368005
[ Info: iteration 22, average log likelihood -1.367168
[ Info: iteration 23, average log likelihood -1.366337
[ Info: iteration 24, average log likelihood -1.365648
[ Info: iteration 25, average log likelihood -1.365196
[ Info: iteration 26, average log likelihood -1.364950
[ Info: iteration 27, average log likelihood -1.364812
[ Info: iteration 28, average log likelihood -1.364729
[ Info: iteration 29, average log likelihood -1.364676
[ Info: iteration 30, average log likelihood -1.364639
[ Info: iteration 31, average log likelihood -1.364612
[ Info: iteration 32, average log likelihood -1.364593
[ Info: iteration 33, average log likelihood -1.364578
[ Info: iteration 34, average log likelihood -1.364568
[ Info: iteration 35, average log likelihood -1.364560
[ Info: iteration 36, average log likelihood -1.364554
[ Info: iteration 37, average log likelihood -1.364549
[ Info: iteration 38, average log likelihood -1.364546
[ Info: iteration 39, average log likelihood -1.364543
[ Info: iteration 40, average log likelihood -1.364540
[ Info: iteration 41, average log likelihood -1.364538
[ Info: iteration 42, average log likelihood -1.364537
[ Info: iteration 43, average log likelihood -1.364535
[ Info: iteration 44, average log likelihood -1.364534
[ Info: iteration 45, average log likelihood -1.364533
[ Info: iteration 46, average log likelihood -1.364532
[ Info: iteration 47, average log likelihood -1.364531
[ Info: iteration 48, average log likelihood -1.364531
[ Info: iteration 49, average log likelihood -1.364530
[ Info: iteration 50, average log likelihood -1.364530
┌ Info: EM with 100000 data points 50 iterations avll -1.364530
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.404703884368029
│     -1.4046461739304132
│      ⋮
└     -1.3645297319495135
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.364642
[ Info: iteration 2, average log likelihood -1.364546
[ Info: iteration 3, average log likelihood -1.364229
[ Info: iteration 4, average log likelihood -1.360757
[ Info: iteration 5, average log likelihood -1.345383
[ Info: iteration 6, average log likelihood -1.330377
[ Info: iteration 7, average log likelihood -1.325315
[ Info: iteration 8, average log likelihood -1.322780
[ Info: iteration 9, average log likelihood -1.321162
[ Info: iteration 10, average log likelihood -1.320057
[ Info: iteration 11, average log likelihood -1.319237
[ Info: iteration 12, average log likelihood -1.318584
[ Info: iteration 13, average log likelihood -1.318026
[ Info: iteration 14, average log likelihood -1.317521
[ Info: iteration 15, average log likelihood -1.317076
[ Info: iteration 16, average log likelihood -1.316710
[ Info: iteration 17, average log likelihood -1.316431
[ Info: iteration 18, average log likelihood -1.316221
[ Info: iteration 19, average log likelihood -1.316055
[ Info: iteration 20, average log likelihood -1.315916
[ Info: iteration 21, average log likelihood -1.315798
[ Info: iteration 22, average log likelihood -1.315700
[ Info: iteration 23, average log likelihood -1.315621
[ Info: iteration 24, average log likelihood -1.315555
[ Info: iteration 25, average log likelihood -1.315498
[ Info: iteration 26, average log likelihood -1.315447
[ Info: iteration 27, average log likelihood -1.315401
[ Info: iteration 28, average log likelihood -1.315359
[ Info: iteration 29, average log likelihood -1.315320
[ Info: iteration 30, average log likelihood -1.315286
[ Info: iteration 31, average log likelihood -1.315255
[ Info: iteration 32, average log likelihood -1.315230
[ Info: iteration 33, average log likelihood -1.315209
[ Info: iteration 34, average log likelihood -1.315192
[ Info: iteration 35, average log likelihood -1.315177
[ Info: iteration 36, average log likelihood -1.315166
[ Info: iteration 37, average log likelihood -1.315157
[ Info: iteration 38, average log likelihood -1.315149
[ Info: iteration 39, average log likelihood -1.315142
[ Info: iteration 40, average log likelihood -1.315137
[ Info: iteration 41, average log likelihood -1.315132
[ Info: iteration 42, average log likelihood -1.315128
[ Info: iteration 43, average log likelihood -1.315124
[ Info: iteration 44, average log likelihood -1.315121
[ Info: iteration 45, average log likelihood -1.315119
[ Info: iteration 46, average log likelihood -1.315117
[ Info: iteration 47, average log likelihood -1.315115
[ Info: iteration 48, average log likelihood -1.315113
[ Info: iteration 49, average log likelihood -1.315112
[ Info: iteration 50, average log likelihood -1.315111
┌ Info: EM with 100000 data points 50 iterations avll -1.315111
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3646419490443478
│     -1.3645458679516993
│      ⋮
└     -1.3151106148636849
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.315279
[ Info: iteration 2, average log likelihood -1.315128
[ Info: iteration 3, average log likelihood -1.314624
[ Info: iteration 4, average log likelihood -1.308549
[ Info: iteration 5, average log likelihood -1.287870
[ Info: iteration 6, average log likelihood -1.271812
[ Info: iteration 7, average log likelihood -1.264060
[ Info: iteration 8, average log likelihood -1.259199
[ Info: iteration 9, average log likelihood -1.256418
[ Info: iteration 10, average log likelihood -1.255050
[ Info: iteration 11, average log likelihood -1.254264
[ Info: iteration 12, average log likelihood -1.253682
[ Info: iteration 13, average log likelihood -1.253168
[ Info: iteration 14, average log likelihood -1.252658
[ Info: iteration 15, average log likelihood -1.252100
[ Info: iteration 16, average log likelihood -1.251522
[ Info: iteration 17, average log likelihood -1.250965
[ Info: iteration 18, average log likelihood -1.250477
[ Info: iteration 19, average log likelihood -1.250079
[ Info: iteration 20, average log likelihood -1.249741
[ Info: iteration 21, average log likelihood -1.249407
[ Info: iteration 22, average log likelihood -1.249071
[ Info: iteration 23, average log likelihood -1.248762
[ Info: iteration 24, average log likelihood -1.248494
[ Info: iteration 25, average log likelihood -1.248268
[ Info: iteration 26, average log likelihood -1.248087
[ Info: iteration 27, average log likelihood -1.247969
[ Info: iteration 28, average log likelihood -1.247906
[ Info: iteration 29, average log likelihood -1.247878
[ Info: iteration 30, average log likelihood -1.247865
[ Info: iteration 31, average log likelihood -1.247859
[ Info: iteration 32, average log likelihood -1.247855
[ Info: iteration 33, average log likelihood -1.247852
[ Info: iteration 34, average log likelihood -1.247850
[ Info: iteration 35, average log likelihood -1.247849
[ Info: iteration 36, average log likelihood -1.247848
[ Info: iteration 37, average log likelihood -1.247847
[ Info: iteration 38, average log likelihood -1.247846
[ Info: iteration 39, average log likelihood -1.247845
[ Info: iteration 40, average log likelihood -1.247844
[ Info: iteration 41, average log likelihood -1.247843
[ Info: iteration 42, average log likelihood -1.247842
[ Info: iteration 43, average log likelihood -1.247842
[ Info: iteration 44, average log likelihood -1.247841
[ Info: iteration 45, average log likelihood -1.247840
[ Info: iteration 46, average log likelihood -1.247840
[ Info: iteration 47, average log likelihood -1.247839
[ Info: iteration 48, average log likelihood -1.247839
[ Info: iteration 49, average log likelihood -1.247838
[ Info: iteration 50, average log likelihood -1.247838
┌ Info: EM with 100000 data points 50 iterations avll -1.247838
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3152785872745014
│     -1.31512797474599
│      ⋮
└     -1.247838102424931
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.248092
[ Info: iteration 2, average log likelihood -1.247821
[ Info: iteration 3, average log likelihood -1.246588
[ Info: iteration 4, average log likelihood -1.234517
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.202903
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.183117
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.186031
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.171699
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.164816
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.184283
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.171159
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.159641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.179599
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.177899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.171121
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.164832
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.175400
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.177967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.169732
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.171999
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.164985
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.156065
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.169126
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177923
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.176039
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.163473
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.175291
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.174044
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.168229
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.167888
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.160742
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.179004
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.167495
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.158035
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.171430
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.166150
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.181974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.168080
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.167011
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.160466
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.161275
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.172319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.177499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.166506
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.163616
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.164258
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.174601
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.170020
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.160970
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.169066
┌ Info: EM with 100000 data points 50 iterations avll -1.169066
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2480919120790694
│     -1.2478206100989746
│      ⋮
└     -1.1690661052718778
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.168994
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     27
│     28
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.153122
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.157670
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.132245
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.121637
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.071424
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070427
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.044984
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.066860
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.043469
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.072253
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.049798
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.070503
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.044241
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     23
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.055008
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.048454
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.069904
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.056341
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.061427
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.037597
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.077162
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.051639
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.061366
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.037567
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     23
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.059543
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.063593
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.068641
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.044132
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.066615
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      8
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.040896
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.068157
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.044551
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.078502
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047023
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     23
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.056377
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.050443
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.073009
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.046418
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.056541
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      8
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.045666
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.079358
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052484
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.062405
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.039485
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     23
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062045
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052282
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.062372
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.052103
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.068951
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     17
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.041903
┌ Info: EM with 100000 data points 50 iterations avll -1.041903
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.168994298768124
│     -1.1531218334964974
│      ⋮
└     -1.0419032267487371
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.404629113275916
│     -1.404703884368029
│     -1.4046461739304132
│     -1.404310814840385
│      ⋮
│     -1.0521030853544513
│     -1.0689509695280845
└     -1.0419032267487371
 -0.0624897   -0.0491964    0.160056     -0.0907062    0.0816598   -0.0238182    0.0880855     0.212128     0.0279073   -0.0978336   0.0696018    0.0364814    0.155791    -0.092275     0.150007    -0.246041   -0.0435326    0.0459769    0.152656      0.170715    -0.0119474  -0.00701443   0.158025    0.034977    -0.0204571    0.118978
  0.0839175    0.128175     0.131181     -0.13591     -0.0784979   -0.102869     0.109825     -0.0100066   -0.0199319    0.0521241  -0.070778    -0.117412     0.00780989  -0.0919544    0.0232518   -0.0578676   0.00361724   0.0427468   -0.0198854    -0.138732    -0.0342712  -0.0808106   -0.0407934   0.126833    -0.0756778    0.0942973
 -0.0334604   -0.133878    -0.00755897    0.00859267  -0.054085    -0.0223926    0.0508863    -0.0487478    0.121992    -0.0361844  -0.00389388   0.082945     0.0120227    0.155544     0.0593209   -0.11761     0.026709    -0.0698111   -0.218265     -0.0708054   -0.0640493   0.131083    -0.0614845  -0.0113949    0.017611     0.0604586
  0.0220379   -0.0804398   -0.00172786    0.00446137  -0.0698574    0.0107804   -0.0289695    -0.0678526   -0.00733389   0.0789016   0.0563477    0.0794688    0.0858164   -0.00929926  -0.113229     0.152512   -0.0295607   -0.0793539   -0.0749526    -0.0156185    0.12874    -0.101625    -0.0745706   0.111374    -0.0735031   -0.0215208
 -0.0982128    0.187104     0.0690115    -0.0794333   -0.0139917    0.0357294   -0.0349983     0.270516    -0.32774      0.161058    0.0530764   -0.334611     0.117147     0.0664283   -0.0972265    0.273138   -0.221579     0.112333     0.000414332  -0.1256       0.0944136  -0.123553     0.0132323  -0.227019     0.188694    -0.0507165
 -0.197612    -0.171478     0.0649338    -0.0564845    0.142979    -0.0118614    0.135468      0.229319    -0.165132     0.184781    0.100865     0.239328     0.0479481    0.0820959   -0.129861     0.0712439   0.0943887    0.0644078    0.0772396    -0.0895795    0.0719265  -0.139969     0.0359662  -0.146135     0.13821      0.00653815
  0.0730127    0.129585     0.129756      0.0280572   -0.235245     0.111386     0.0558238    -0.136046    -0.141719     0.0708278   0.191476    -0.0837046    0.127041    -0.120329     0.11019     -0.14657     0.167873    -0.00496549   0.00708334   -0.468818     0.228722    0.0913332    0.0157636   0.13189      0.0308843   -0.00657457
  0.0800578    0.0950115    0.140089      0.0208662    0.0463738    0.1177       0.0717669     0.0743165   -0.0189464    0.0767644   0.125411    -0.0616467   -0.0183369   -0.0530037    0.126026    -0.310541    0.112011    -0.00556662   0.0430441     0.404423     0.119015    0.129487     0.0190504  -0.0111881   -0.149941    -0.0941917
 -0.0656729    0.0985774   -0.160278     -0.066377     0.113188     0.0738064   -0.163288     -0.0424144   -0.0968483    0.014571    0.0931119    0.14447     -0.128411    -0.12766      0.0339963    0.064177   -0.0546596   -0.148621    -0.136383     -0.0201899    0.0473839   0.155386    -0.0192133   0.0494062    0.0736802    0.0959772
  0.0162984   -0.00785399  -0.111645     -0.0515192    0.042918    -0.0450662   -0.000511334   0.151008     0.0472138    0.0463554  -0.00076463  -0.010554     0.0451688    0.00245003   0.127258     0.158245    0.0137167   -0.220286    -0.0500808    -0.0778266    0.178076    0.096817     0.189891   -0.00844061  -0.125783    -0.0344481
  0.321349    -0.0573915   -0.090174     -0.12789      0.0130414    0.00206865  -0.158569     -0.0423438    0.214414     0.0538196   0.0340202    0.0283975   -0.342666     0.183097     0.00210009  -0.0973027   0.223599    -0.222991     0.0756253    -0.0138864   -0.0185042  -0.120106    -0.786043    0.174863    -0.123068     0.0946989
  0.0266766   -0.133705    -0.0855916    -0.0598628    0.0467874    0.0412763   -0.114027     -0.0344014   -0.166247     0.14122     0.0354271    0.0456505    0.424247     0.183312    -0.00157139  -0.0958974   0.220559    -0.184028    -0.186931     -0.0138081   -0.0169228  -0.115015     0.296512    0.184581    -0.00418353   0.184514
  0.0332959   -0.0633524   -0.0228862    -0.0629376   -0.0634164    0.0644036    0.039961      0.0501772   -0.0477631    0.0545711   0.0856467   -0.158334    -0.031344    -0.0567479   -0.0250157    0.0274348   0.0334543    0.0171901   -0.0743894     0.0293813    0.0264436  -0.0141391    0.0183365   0.00382491  -0.015864    -0.0342808
  0.0685817    0.0090893   -0.000887464   0.0576391   -0.00311446  -0.0857702   -0.0961524     0.108685    -0.0014224    0.108351    0.102994    -0.0228543   -0.0262624   -0.00400423   0.0518418   -0.018141    0.129686    -0.0200343   -0.0359602     0.0267326    0.124919    0.140691    -0.0526165   0.00880589  -0.0186949    0.0317595
 -0.048112    -0.0992282   -0.0289274     0.0922867   -0.0147064   -0.00326026  -0.121063     -0.158367    -0.141395    -0.031842   -0.0196529   -0.0143038    0.0744404   -0.0346419    0.112901    -0.04181    -0.0552698    0.0828597   -0.112512      0.0115809   -0.0944274   0.0164224    0.0106149  -0.0723044    0.0651003   -0.0114698
  0.0507698   -0.0537685    0.0549224     0.0572812    0.0896413    0.0388285   -0.111198     -0.0103411    0.0234319    0.0389328  -0.119642     0.00439617   0.0127589   -0.0124133   -0.0427087   -0.141176   -0.088022    -0.0975043   -0.0407433     0.132963    -0.0324973   0.0255195    0.127273    0.063161    -0.0760244    0.0482993
  0.0363841   -0.0877477   -0.0503641     0.0948029   -0.0210026   -0.0560652   -0.0212154     0.162534    -0.0269135    0.0462442   0.0125926   -0.0384143   -0.0735635    0.0161432   -0.036151    -0.0115009  -0.049588     0.103153     0.0938495    -0.166997     0.1561      0.0448264    0.0129274  -0.0575998    0.116425     0.0885459
  0.0522368   -0.00984037  -0.0167501     0.0330918   -0.0845808   -0.055359    -0.0556532    -0.0551826   -0.0446286   -0.0175191  -0.0494077    0.0183671    0.00769411   0.0294094    0.0149363   -0.0883762   0.015491     0.0400348    0.117473     -0.0814078   -0.450191   -0.0904588   -0.0648255   0.0172669   -0.180295     0.152396
  8.20094e-5   0.0592105    0.11894      -0.0769386   -0.0717664    0.0597904    0.0575153    -0.169864     0.0461817    0.0406187  -0.143387    -0.00702804   0.137141     0.103368    -0.111458    -0.0646859   0.0895205    0.0258653    0.0746236     0.074593    -0.0369423   0.00174102  -0.130571   -0.0357146    0.0200841    0.121935
  0.135268    -0.161653    -0.225995     -0.0139575   -0.0963032   -0.0450055   -0.0408307    -0.0294918    0.0356665   -0.133345   -0.181962     0.0481439   -0.00605498  -0.0630475    0.0107284   -0.0400058   0.0227027    0.115349     0.00365349    0.0993948    0.06348     0.12993      0.140562   -0.0102239   -0.080415     0.0388086
 -0.142492    -0.0293329    0.0920879     0.074963     0.0273748   -0.0523425   -0.0933623     0.0925845   -0.0122321    0.248339    0.066324    -0.244172    -0.070012    -0.0385463    0.043204    -0.138028    0.0286962    0.0423847    0.0079553     0.0409203    0.0551305   0.11649     -0.0739087  -0.0721741   -0.0175358   -0.269098
 -0.082169    -0.0600156    0.161398      0.0958164    0.0918188   -0.126494     0.172504     -0.00331238  -0.0413872   -0.0673132  -0.0820738    0.026803    -0.0267011    0.0700862   -0.0788378   -0.0172111  -0.0778653    0.0772656   -0.186852      0.0208189    0.0216366  -0.0301349    0.147356    0.088582     0.108077    -0.00867752
 -0.0351031   -0.211629    -0.116743     -0.0568397   -0.0630671   -0.0859297   -0.139951      0.0306706    0.108576     0.0903431   0.19868     -0.0138791   -0.0754051    0.0703196    0.0768626    0.100127    0.0353117   -0.0353406   -0.0434701     0.0597437    0.019519   -0.0468814    0.166398   -0.0322618    0.131527     0.0876932
  0.104848     0.0383575   -0.0514833     0.0361277    0.0291084   -0.0349267   -0.0602269    -0.0217447    0.0351854   -0.045754   -0.0999481   -0.099527     0.179982    -0.0295102    0.00202639  -0.032154    0.13375      0.124067     0.000683078   0.0559154    0.0255991  -0.0477957   -0.0480957   0.137762     0.0047511   -0.0779937
  0.0589236   -0.149604    -0.0451326     0.0296676   -0.0799686    0.0407785   -0.015685     -0.0626325   -0.0114652   -0.172475    0.0804075    0.0583804    0.0744865   -0.086528    -0.0575674    0.153729    0.126401    -0.0831941    0.140166     -0.0837626    0.0954197   0.00937584  -0.178868    0.146096    -0.0699277    0.145138
 -0.209441    -0.151294    -0.146583     -0.0865772   -0.0209553   -0.322285     0.148729      0.0865144   -0.0832499    0.113671   -0.11511     -0.190383    -0.0227382    0.065933    -0.199537     0.14503     0.0331755    0.0659983   -0.11643      -0.0182503   -0.133592   -0.142254    -0.025124    0.0858705   -0.0109452    0.0976083
 -0.0318052   -0.0322258   -0.122759     -0.17345     -0.149128     0.105724     0.185526     -0.232472    -0.198128    -1.54531     0.043977    -0.00156097   0.0886946   -0.10415     -0.128152     0.158604    0.0456431   -0.123843    -0.153375      0.0347619   -0.0801388  -0.129339     0.0719793   0.0747273   -0.101491    -0.15882
 -0.0542518   -0.025354    -0.158631     -0.11541     -0.161016     0.0386347    0.0842126     0.172347     0.0213852    2.00527     0.0295376   -0.00217075   0.088174    -0.106387    -0.13099      0.267169    0.00628662   0.0692716   -0.155759      0.0345597   -0.0746752  -0.118579     0.071926    0.164031    -0.183966     0.0472219
 -0.16166      0.13193     -0.152909     -0.0985946   -0.0207663    0.0650777   -0.0573993     0.194147    -0.0379944   -0.0563295   0.127814     0.0855246   -0.313658    -0.115419    -0.260385     0.152576    0.00200463   0.0981837   -0.168696     -0.150266    -0.0643111  -0.0861769    0.0814081   0.0640882    0.0278658   -0.0830338
 -0.0166726   -0.118154    -0.0764873    -0.0406369   -0.0211975    0.0651703   -0.0530494     0.0340656   -0.0634014   -0.309756   -0.074969     0.0548537    0.588575    -0.114804    -0.254193    -0.165365    0.00447084   0.0115851    0.189346      0.0631621   -0.132603   -0.0828834   -0.0438274   0.0304921    0.0249863    0.0836902
 -0.0732166    0.00606761   0.125347      0.0261118    0.0830835    0.124627     0.0415015     0.0802619    0.0127046   -0.141196    0.0498805    0.0111007   -0.0581104    0.0148979    0.00913268   0.0580746   0.732378    -0.0551029    0.0742152    -0.00217839   0.0688471   0.107567     0.120585    0.0212759    0.0931205    0.167673
  0.161694     0.00595749   0.123349      0.24882      0.0306634    0.12583      0.0383196    -0.0630693    0.0251257   -0.169529    0.141022     0.0518913   -0.0578827    0.0141727    0.0133885    0.0356894  -0.687062    -0.0878506    0.0662945    -0.0315832    0.0504661   0.107628     0.113731    0.0160899    0.111946     0.127076[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.069322
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.038729
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.060580
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     11
│     12
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.029010
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     23
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055791
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041038
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.063157
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      8
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.031287
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058924
kind diag, method kmeans
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     11
│     12
│     17
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.027362
┌ Info: EM with 100000 data points 10 iterations avll -1.027362
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.844282e+05
      1       6.641148e+05      -2.203134e+05 |       32
      2       6.358878e+05      -2.822702e+04 |       32
      3       6.230838e+05      -1.280402e+04 |       32
      4       6.152884e+05      -7.795350e+03 |       32
      5       6.104482e+05      -4.840227e+03 |       32
      6       6.076538e+05      -2.794391e+03 |       32
      7       6.058554e+05      -1.798355e+03 |       32
      8       6.049417e+05      -9.137364e+02 |       32
      9       6.043751e+05      -5.665939e+02 |       32
     10       6.039274e+05      -4.476705e+02 |       32
     11       6.035251e+05      -4.023695e+02 |       31
     12       6.031640e+05      -3.610948e+02 |       32
     13       6.028308e+05      -3.331478e+02 |       32
     14       6.025316e+05      -2.992423e+02 |       32
     15       6.022076e+05      -3.240004e+02 |       32
     16       6.018669e+05      -3.406555e+02 |       32
     17       6.014458e+05      -4.211049e+02 |       32
     18       6.008787e+05      -5.671033e+02 |       32
     19       6.001208e+05      -7.579026e+02 |       31
     20       5.993924e+05      -7.283602e+02 |       32
     21       5.989748e+05      -4.176762e+02 |       31
     22       5.988522e+05      -1.226182e+02 |       32
     23       5.987934e+05      -5.875323e+01 |       32
     24       5.987581e+05      -3.528029e+01 |       31
     25       5.987290e+05      -2.911726e+01 |       31
     26       5.986758e+05      -5.320192e+01 |       32
     27       5.985939e+05      -8.188981e+01 |       31
     28       5.984231e+05      -1.707858e+02 |       31
     29       5.979890e+05      -4.341410e+02 |       32
     30       5.969872e+05      -1.001736e+03 |       31
     31       5.961489e+05      -8.382994e+02 |       31
     32       5.959352e+05      -2.137617e+02 |       31
     33       5.958983e+05      -3.690069e+01 |       29
     34       5.958862e+05      -1.207097e+01 |       25
     35       5.958810e+05      -5.232531e+00 |       24
     36       5.958794e+05      -1.570909e+00 |       17
     37       5.958789e+05      -5.557969e-01 |       12
     38       5.958784e+05      -4.720479e-01 |        9
     39       5.958780e+05      -3.762803e-01 |        9
     40       5.958776e+05      -3.727312e-01 |        4
     41       5.958775e+05      -8.797971e-02 |        4
     42       5.958775e+05      -8.394294e-02 |        2
     43       5.958774e+05      -3.309200e-02 |        2
     44       5.958774e+05      -3.839710e-02 |        2
     45       5.958773e+05      -4.186735e-02 |        0
     46       5.958773e+05       0.000000e+00 |        0
K-means converged with 46 iterations (objv = 595877.349572579)
┌ Info: K-means with 32000 data points using 46 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311180
[ Info: iteration 2, average log likelihood -1.275208
[ Info: iteration 3, average log likelihood -1.236208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.198550
[ Info: iteration 5, average log likelihood -1.167731
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110703
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     16
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.098206
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097991
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.046866
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     16
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059898
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.073366
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072082
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     16
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.039056
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.052555
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.079452
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.063103
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.047224
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.063391
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.082899
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.050309
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.067567
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     18
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.036981
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.056525
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064362
[ Info: iteration 25, average log likelihood -1.082711
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     11
│     13
│     18
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.013429
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072517
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.074362
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.053102
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│     10
│     13
│      ⋮
│     19
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.010640
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.113023
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.067162
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042929
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      9
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.051741
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.061248
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.062611
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     10
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.028628
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044510
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.094202
[ Info: iteration 40, average log likelihood -1.062966
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.979571
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.099287
[ Info: iteration 43, average log likelihood -1.103482
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.038018
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│     13
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.021851
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.091578
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.072910
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.044994
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      9
│     13
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.005375
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.088169
┌ Info: EM with 100000 data points 50 iterations avll -1.088169
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.143494    0.0463805     0.0169677   -0.0544698    0.0276412    0.0581042   0.0417729    0.0800726    -0.0548228    0.195373     0.0564187   -0.0714813   -0.0827411   -0.163288     0.0622529   -0.00661582   0.131524    -0.045856     0.0753335   -0.00583869  -0.0623084   -0.0444484   -0.0395945    0.0769466   -0.0332205   -0.219947
  0.0171329   0.0137756     0.0823356   -0.0713676   -0.0644973    0.0602285   0.048665    -0.168045      0.0443867    0.0251173   -0.148112    -0.00659962   0.122614     0.0832029   -0.0980816   -0.0643969    0.0771302    0.0371328    0.0755064    0.0756224   -0.0273112    0.0231986   -0.118234    -0.0282672    0.00218818   0.114206
 -0.145711   -0.0468303     0.0678609   -0.0716476    0.180471    -0.0187825   0.0355513    0.250242     -0.221537     0.179131     0.0754309    0.0638256    0.0634569    0.0796612   -0.108109     0.18754     -0.147982     0.110747     0.0575612   -0.14753      0.129395    -0.127085     0.0431019   -0.144673     0.152349    -0.0171835
  0.0538756  -0.00903555   -0.0168841    0.0328288   -0.0835734   -0.0549969  -0.0535209   -0.0547181    -0.0459526   -0.0168729   -0.0496845    0.019015     0.00674495   0.0262353    0.0151198   -0.0886052    0.0165268    0.0396434    0.121393    -0.0813798   -0.448254    -0.0907833   -0.0657636    0.0162217   -0.180667     0.148549
 -0.0336551  -0.179372     -0.0678127   -0.203299    -0.100831     0.0473591  -0.0851526    0.133089      0.00536381   0.131129     0.217852    -0.590914    -0.0764583   -0.0528656   -0.103844    -0.0050911   -0.0618349   -0.0244567   -0.364384     0.132235     0.00929795   0.0573996   -0.0500094    0.0670074   -0.0534812    0.0776897
  0.18342    -0.0248006    -0.0047423    0.0314465    0.0979479    0.0658305   0.0216127    0.0188238     0.0935322    0.0866359   -0.0821495   -0.0140697    0.247425    -0.0162782    0.0706401    0.122444     0.144595     0.183646    -0.00366487  -0.0244763    0.0646333   -0.0859437   -0.0146885    0.120611     0.0167741   -0.121212
 -0.0283926  -0.13005      -0.0032028    0.00795063  -0.0582426   -0.0261655   0.0550556   -0.047731      0.119584    -0.0340841   -0.00573015   0.0850966    0.00804994   0.151122     0.0572821   -0.117106     0.0244623   -0.0700818   -0.219081    -0.0725068   -0.0736167    0.131912    -0.061292    -0.0101263    0.0186764    0.0558576
 -0.141926    0.131908      0.0663166   -0.0596196   -0.179823     0.0663526   0.103576     0.232846     -0.286163     0.148894     0.0744828   -0.287774     0.111484     0.0536064   -0.116622     0.121818     0.112383     0.0330655    0.00173837  -0.0302159    0.00618625  -0.137246    -0.0153183   -0.242908     0.177395    -0.0356678
  0.108034   -0.156757     -0.195408     0.00336303  -0.141679    -0.0440472  -0.0418876   -0.0109117     0.0280811   -0.210172    -0.182299     0.0867666   -0.0205534   -0.056197    -0.00324275  -0.0321291   -0.0308608    0.0660157   -0.00455854   0.126871     0.0476923    0.178975     0.250405     0.0220386   -0.0792186    0.0335751
  0.0745348  -0.111434     -0.0158082    0.0338414   -0.0739805    0.0334911  -0.00439754  -0.0772118    -0.00952515  -0.162787     0.0946188    0.0518018    0.0495245   -0.0830808   -0.0560328    0.176659     0.115593    -0.0828324    0.168312    -0.0822508    0.144345     0.01473     -0.147894     0.142783    -0.1118       0.264978
  0.0363552  -0.0899141    -0.0501866    0.0944463   -0.0201503   -0.0555999  -0.0225524    0.162696     -0.0276939    0.0468114    0.0124115   -0.038432    -0.0743333    0.0163855   -0.0385096   -0.0108903   -0.0512545    0.104233     0.0957881   -0.167174     0.155698     0.0453424    0.0126741   -0.0580066    0.116414     0.0895214
  0.121873   -0.0363714    -0.0328982    0.0128242    0.0510731   -0.0828314  -0.095916     0.114774     -0.0371531    0.283144     0.0587534    0.0860889   -0.0107051    0.0766289    0.092342    -0.0738635    0.189998     0.082428     0.0664897    0.0267143    0.117289     0.187177    -0.0187187    0.0325851   -0.161049     0.0167009
  0.0645871  -0.0498909     0.0106639    0.0760245    0.161376    -0.013002    0.136933    -0.0661632     0.0484951   -0.0961869   -0.158099     0.0207498   -0.00855622  -0.0521054   -0.112066    -0.164848    -0.402644    -0.131499    -0.110726     0.242082    -0.1365       0.120466     0.128029     0.227849    -0.0994658    0.0212155
 -0.0833936  -0.0602447     0.161488     0.0952262    0.0919077   -0.127186    0.172886     0.000289527  -0.0408414   -0.0669319   -0.0821235    0.0268534   -0.0268027    0.0705672   -0.0792956   -0.0166735   -0.0776614    0.0761435   -0.186577     0.0204655    0.0208981   -0.0315616    0.146364     0.0887965    0.107311    -0.0089473
 -0.145385   -0.0352292     0.0890368    0.0775465    0.0342704   -0.0568091  -0.0961336    0.0881042    -0.0251645    0.250389     0.064551    -0.240311    -0.0710837   -0.0278036    0.0427569   -0.146569     0.0477936    0.0487895    0.0215841    0.0424888    0.0573266    0.117501    -0.0629712   -0.0692512   -0.0286939   -0.269576
 -0.0395521  -0.0278254    -0.131591    -0.148507    -0.154775     0.0752597   0.136654    -0.0518556    -0.0989509    0.0515942    0.038427    -0.00245351   0.0864162   -0.104458    -0.127625     0.208875     0.0286175   -0.0384462   -0.151658     0.0297116   -0.0759641   -0.120097     0.0710131    0.117256    -0.138457    -0.0560066
  0.154865   -0.079801     -0.126672    -0.0845561    0.00188713   0.0122357  -0.12917     -0.0299688     0.00888144   0.0608931   -0.0172431    0.0528915    0.0173334    0.106624     0.00603636  -0.0731884    0.15677     -0.107289    -0.0592924    0.0164184    0.00095595  -0.0518425   -0.151757     0.129738    -0.0645784    0.120175
  0.0765307   0.108523      0.129057    -0.168953    -0.0943851   -0.100951    0.121068    -0.0422485    -4.88037e-5   0.00389235  -0.083347    -0.153018    -0.0168931   -0.0641229    0.0174956   -0.0578044   -0.069194     0.0311756   -0.0124643   -0.115726    -0.0701973   -0.0375643    0.00595523   0.120339    -0.0799587    0.13393
 -0.0233873  -0.0819474    -0.0495385    0.114107    -0.0380413   -0.0421142  -0.0817991   -0.197891     -0.207392    -0.0331845   -0.0147403   -0.0543766    0.0223141   -0.0442163    0.0977722   -0.00762519  -0.122737     0.101428    -0.162249    -0.0197665   -0.101334     0.0187607   -0.0464461   -0.0814011    0.0139338   -0.0311928
 -0.207235   -0.150808     -0.14596     -0.087973    -0.0212096   -0.321338    0.148659     0.0870186    -0.082786     0.113624    -0.117414    -0.189453    -0.0225574    0.0644905   -0.199522     0.144317     0.0338894    0.0660006   -0.115852    -0.0177163   -0.13245     -0.141946    -0.0248536    0.0861644   -0.0116436    0.0973413
 -0.0471249  -0.0598291    -0.133904    -0.0594109    0.0223568   -0.0129998  -0.156252    -0.00181076    0.0183032    0.0534666    0.14185      0.0646973   -0.104159    -0.0199882    0.0575528    0.0819927   -0.00806626  -0.0899227   -0.0953729    0.0222103    0.0317529    0.0525969    0.0830328    0.00616802   0.103454     0.0903513
  0.0225863  -0.0803039    -0.00209338   0.00381124  -0.0701887    0.0125584  -0.0319856   -0.0681045    -0.00771892   0.0787717    0.0564208    0.0795926    0.0869576   -0.0114397   -0.1135       0.152568    -0.0292125   -0.0777559   -0.0749288   -0.0164712    0.127115    -0.101695    -0.0742146    0.111505    -0.0732018   -0.0225349
  0.014569   -0.00808215   -0.110693    -0.0552207    0.0494286   -0.0441173   0.00127949   0.150398      0.0509294    0.0460525    0.00194784  -0.0113795    0.0429973    0.00309487   0.126644     0.159661     0.0128284   -0.219908    -0.0498113   -0.0789297    0.179677     0.0979379    0.191099    -0.00752672  -0.128249    -0.0320576
  0.0177483   0.0651087     0.0334757    0.113213    -0.0824045   -0.109454   -0.0667972    0.0950035     0.0489749   -0.0893612    0.140438    -0.150503    -0.0529837   -0.106003     0.00277611   0.0277523    0.0538143   -0.137352    -0.181075     0.0218358    0.122539     0.101404    -0.093007    -0.022087     0.126685     0.0397097
  0.0676446  -0.0277787     0.0666408    0.0739153    0.110331     0.0387059  -0.205251     0.0167709    -0.0298796    0.133752    -0.180267    -0.0187145   -0.0391462    0.02081     -0.0658374   -0.108417     0.0205723   -0.0981776   -0.009954     0.0642905    0.0354612   -0.0182828    0.096838    -0.0165728   -0.13003      0.046013
  0.0516246   0.0945199    -0.0788673    0.0383749   -0.00716064  -0.0941454  -0.110731    -0.0669673    -0.0251227   -0.144194    -0.108529    -0.162556     0.123428    -0.0330547   -0.0507156   -0.16631      0.120906     0.0646021    0.0154718    0.125582    -0.00489246  -0.0277004   -0.0702365    0.155895    -0.0281802   -0.0517111
 -0.104111   -0.152574      0.0723098    0.0187735    0.00697049   0.111474   -0.215645     0.0170636     0.0269295    0.0118585   -0.0349529    0.0677827    0.2347      -0.0275772    0.165961    -0.135264     0.138999     0.0222855    0.0233251    0.0565373   -0.0573493    0.00533079   0.174123    -0.0632111    0.205375     0.0780436
 -0.0547958  -0.0403051     0.159348    -0.0934119    0.0836142   -0.0320998   0.0885564    0.203063      0.0236145   -0.0952635    0.0654854    0.0371992    0.143311    -0.0897442    0.142511    -0.239832    -0.0393156    0.0388788    0.13716      0.171901    -0.0085627   -0.00943242   0.149287     0.0426821   -0.0150882    0.120574
 -0.0289222  -0.0422586     0.0164293   -0.113464    -0.164818     0.0320467   0.140477    -0.0566953    -0.0641237   -0.0562506    0.0183435   -0.153791    -0.0238101   -0.0215404   -0.0665898    0.0570787   -0.0629493    0.116194    -0.0974216   -0.0219133    0.099121    -0.0430215    0.0968116   -0.0805872   -0.0169248   -0.0691363
  0.0368073  -0.00577852    0.0609485    0.290924     0.0920177    0.114529    0.0785171    0.0349994     0.00797713  -0.158596     0.207229     0.0699743   -0.0581263   -0.00247455  -0.0154601    0.0518117    0.0362931   -0.105528     0.110506     0.013136     0.0839218    0.0980529    0.082249     0.0301915    0.115653     0.149583
 -0.0613123  -0.000532257  -0.0944459   -0.0406667   -0.0277434    0.0597947  -0.0440955    0.11067      -0.0361813   -0.179734     0.00581768   0.0670115    0.111221    -0.101094    -0.204436    -0.0473914    0.00704274   0.0579051   -0.0173076   -0.0253453   -0.116114    -0.0546137    0.0186428    0.0427681    0.0364052   -0.0149893
  0.0774186   0.111468      0.135043     0.0241741   -0.0888824    0.114711    0.0648409   -0.0263922    -0.0777386    0.0740152    0.156566    -0.0723433    0.050395    -0.0847185    0.117783    -0.230972     0.1369      -0.00458802   0.0257297   -0.0113755    0.172167     0.111711     0.0175579    0.0563789   -0.0619947   -0.0526342[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.092503
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.022722
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.996027
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.068824
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.038691
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     19
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.969193
[ Info: iteration 7, average log likelihood -1.092306
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.020458
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.994386
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.068688
┌ Info: EM with 100000 data points 10 iterations avll -1.068688
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.136225    -0.119091     -0.0164656    0.100873    -0.162186     0.15537     -0.11095      0.0179201    0.0086245    0.0577124    0.0462969   -0.00470903  -0.0399805  -0.0344347    0.00923967   -0.277922    -0.10587      0.095048     0.10796    -0.0969681   -0.00328983  -0.0209601  -0.107329    -0.0533305   -0.0850884    0.114055
 -0.0533239    0.00872459   -0.12555     -0.134738    -0.0356477    0.0228536   -0.0647524   -0.124896    -0.0873675   -0.0737603    0.0536675   -0.0118421    0.0410846  -0.0871012   -0.0353997    -0.0091059   -0.0625176    0.0235579    0.0167957   0.1442      -0.0273961    0.115631   -0.102129    -0.00903651  -0.0151415    0.019748
  0.0240079    0.0427008    -0.0473792    0.0367788   -0.152703    -0.150249     0.0352283    0.0229196   -0.183116    -0.0595118   -0.026253    -0.0308998    0.201042    0.0882427   -0.0329775    -0.0202386   -0.113267    -0.0588155   -0.0419313   0.0908452   -0.0926121    0.0650843  -0.0251308    0.0300812    0.200166    -0.0362119
  0.0119987   -0.10368       0.0170439   -0.144467    -0.143963     0.0818525    0.0855008    0.00934872   0.0276566   -0.0488217    0.0282849   -0.0940911   -0.07959     0.0635673   -0.0371277     0.225526    -0.16133      0.0156622    0.0773088  -0.0190239   -0.181119     0.204557    0.0633345   -0.0640072   -0.0142164    0.0774258
  0.112373     0.000161075  -0.157286    -0.0319653    0.199916     0.0762728    0.0236406    0.0846518    0.11133      0.0604129    0.12816      0.0463571   -0.0270074  -0.191792    -0.0039897     0.0190817   -0.0172222    0.0852945    0.240646   -0.0313868   -0.146346     0.158916    0.0139738    0.0585251   -0.0483542    0.120382
 -0.077163    -0.053833     -0.0294809    0.0167736    0.044186    -0.031983     0.0196       0.0250917   -0.0234388   -0.0880333    0.0360697    0.103786     0.0444685   0.0270058    0.0783455     0.104328    -0.308835    -0.135716    -0.041052    0.0740375   -0.0264276    0.0640667  -0.118248    -0.0234985   -0.125218    -0.0306102
 -0.104196     0.0948462     0.0332453    0.0413311   -0.0954692   -0.0271111   -0.160967     0.0208195   -0.0317879    0.0472305   -0.0699709   -0.0539695    0.0279703   0.0819964    0.0197627    -0.0298587   -0.0411719    0.0397836   -0.0451097   0.0272031    0.0322971    0.0303908  -0.0530296   -0.111739     0.0953784    0.283486
  0.192702    -0.0807143    -0.198927    -0.0878697   -0.0609365    0.038769     0.0539559    0.0612765    0.128093    -0.173302     0.0191894   -0.0952051   -0.145751   -0.0828139    0.0240117     0.0339801    0.104303    -0.0543832   -0.071285   -0.0594891   -0.0469831   -0.100199   -0.019531    -0.101371     0.181407    -0.0259938
 -0.0573505   -0.138589     -0.0977837    0.00542773  -0.109896    -0.117117    -0.0510391    0.0230674    0.0545255    0.161573    -0.119796    -0.0410694   -0.0589224   0.0804413    0.164132      0.0905364   -0.0209263   -0.0271314   -0.0646519  -0.00649518   0.0216618    0.0131251   0.188833    -0.119571    -0.0832518   -0.10401
 -0.114241    -0.00756989   -0.0066559    0.105498    -0.0269812    0.0149659    0.00882358  -0.200294     0.107055     0.165748     0.0779705   -0.0874044   -0.0440669   0.0242423   -0.0233192    -0.315669     0.0686345    0.0165622    0.0824292   0.142643     0.00981955   0.0108718   0.0402333    0.119261     0.100891     0.0631183
  0.101104    -0.032265      0.0583596    0.00508656   0.138156     0.22156      0.0423382    0.0598243    0.0980507   -0.0737429    0.017408    -0.0988394    0.0121418   0.133857    -0.0247155     0.0185166    0.121897     0.352447    -0.025615   -0.217162     0.204032     0.14251     0.0210578    0.00684237  -0.0238225    0.183385
 -0.0173286   -0.0939506     0.0105312   -0.147355     0.0107148    0.0488184    0.140217    -0.141363    -0.0718215   -0.144005     0.051996    -0.136509    -0.158836   -0.132036    -0.00778419   -0.0966436    0.0473642   -0.0815536   -0.0129925   0.0999577   -0.0249153    0.0708843   0.0504997    0.15829      0.0920308   -0.0952714
 -0.0899426    0.133155      0.0576361   -0.0371639    0.146935    -0.0156843   -0.0872362    0.136128     0.01233     -0.0413323    0.212834     0.243768    -0.0593739   0.00442865   0.0486006    -0.00233925  -0.0913135    0.00255448   0.0704936  -0.0123595    0.0675091    0.0721004  -0.0482827   -0.0189229    0.106516     0.0680869
  0.0194866   -0.000733437  -0.0442029   -0.241623    -0.00192928   0.0114782    0.132663     0.0766615   -0.100425     0.0422802    0.057932     0.0345763   -0.0438019  -0.186735     0.0417596    -0.0627699   -0.125165    -0.10085     -0.170764    0.111819    -0.0576689    0.165291    0.0261451   -0.103203    -0.0225199    0.0730634
  0.136088    -0.122747     -0.0403494    0.040318    -0.0988643    0.0377219    0.0194509    0.165549    -0.112855    -0.197343    -0.0501812    0.0194983    0.122239   -0.0796413    0.0669841    -0.0833802    0.0459872    0.123268     0.105211    0.131105     0.141131    -0.0163953   0.27551     -0.0440949   -0.129306     0.0151014
 -0.0847932    0.0731218     0.00422322  -0.151934     0.0174422   -0.0300391   -0.0585134   -0.0482596   -0.00211912  -0.0892747    0.0329657   -0.187988     0.121044    0.302396     0.00448766   -0.0222228   -0.116844    -0.129864    -0.0346748   0.0698311    0.0117531   -0.139893   -0.0908275   -0.0890693   -0.0930135    0.0860048
 -0.0668394    0.267757     -0.00939721  -0.190476    -0.11416     -0.0280754   -0.0381565   -0.0494424   -0.0458085    0.0408093    0.00291456  -0.119734     0.11918    -0.0836934    0.0517095     0.159143     0.127606    -0.00558609   0.0177467   0.0119785   -0.0283036   -0.135525   -0.12777      0.0531421    0.160583    -0.16404
  0.0617605   -0.087918     -0.0322356   -0.186156     0.0150961   -0.0152461   -0.0347186    0.089881     0.0423523   -0.0422092    0.0582429   -0.135502     0.133845   -0.0929355    0.0134958    -0.072173    -0.0243396    0.0711367   -0.120735   -0.114355     0.0312452   -0.103806    0.0627439    0.211491    -0.211565     0.0059804
 -0.0541924   -0.0260959    -0.0991985    0.0395861    0.0641699   -0.0382412   -0.00701606   0.0275652    0.0445562   -0.130209     0.117926     0.0224252    0.0799655  -0.0803235   -0.0968653    -0.198325     0.124321     0.0225752    0.0231632  -0.00815982  -0.0273942   -0.0981078  -0.0234968   -0.138581    -0.148385     0.105427
 -0.0953989   -0.0498933    -0.189943     0.0277503    0.0768207    0.00316661   0.187449     0.0468011   -0.0783316   -0.00828167  -0.0597254    0.122662    -0.0419435  -0.0443252   -0.0571892     0.164735     0.0120657   -0.0476715   -0.0122653  -0.0337471    0.00715862   0.0590574  -0.128843    -0.0140063    0.00537304  -0.0376726
  0.103072     0.083945     -0.15396     -0.00660112   0.0970389   -0.110467    -0.160351    -0.079188    -0.0187588   -0.0324456   -0.0322578   -0.022307    -0.11102    -0.108025    -0.000550512  -0.165578     0.0203087   -0.061478    -0.0624387  -0.00454161  -0.0430815   -0.0310855   0.0194425   -0.0444801    0.0894628   -0.0362021
 -0.0311666    0.0377834    -0.224684    -0.07742     -0.0688833   -0.22077     -0.0313059   -0.030246     0.0537479    0.12072     -0.0512319    0.067602    -0.020673   -0.157094    -0.184842     -0.10149      0.00521346   0.033283     0.166692   -0.021576    -0.137004    -0.0428719   0.0853815    0.0421566    0.0648483   -0.0616992
 -0.119395    -0.0532457    -0.0208422   -0.1843       0.167345    -0.0481588   -0.219344     0.141109    -0.0247384    0.0891288   -0.161393    -0.0285718    0.0516235   0.0002924    0.114731      0.159398     0.0409402    0.0982445   -0.0483743   0.173374    -0.0175893   -0.0245324  -0.0420957    0.0768066   -0.161723    -0.0428251
 -0.0275753    0.0242449     0.0411827   -0.0781644   -0.0179615    0.0621356    0.0207024   -0.130925    -0.0140139    0.00748528   0.072439     0.212118    -0.0394304   0.0347581   -0.0752051     0.0292368   -0.0486332    0.196074    -0.0044469   0.0270621    0.0523878    0.114009   -0.0828978    0.0155472   -0.069307     0.0296976
  0.02662      0.0212009    -0.0381796    0.0263641   -0.189599    -0.0692156   -0.0497151   -0.225895    -0.0462505   -0.114702    -0.133974     0.138882    -0.110064   -0.0720255    0.00691556   -0.0677271   -0.133478    -0.0186412    0.168056   -0.0998272   -0.0257474   -0.217496    0.00124804  -0.166286    -0.0527555   -0.247434
 -0.0571599   -0.0906342    -0.0465062    0.0881313   -0.165644     0.0851003   -0.194258     0.259876    -0.0202263    0.148231    -0.0467417    0.157694     0.194819    0.0649057   -0.0541007    -0.232617     0.0782051    0.0724598    0.0280442   0.257737     0.214323     0.144037    0.052567     0.0972522    0.0663487    0.0698105
 -0.0121291    0.0447112     0.069187    -0.0182425    0.00688029  -0.185152     0.0976947    0.118497    -0.0931197    0.0439809    0.122806    -0.0232163    0.231665   -0.0137971   -0.0275155     0.194098     0.0600243    0.00421702  -0.0104127  -0.126063    -0.0726922   -0.115639    0.0428693   -0.0488953    0.0367865   -0.0981195
 -0.115343     0.0942796     0.00688428  -0.0749206   -0.114498    -0.0157801    0.069434     0.0387501   -0.210247     0.103813    -0.0729579    0.0795529    0.0764661   0.0874767   -0.102147      0.135081    -0.0657788    0.0888452   -0.101349    0.0398322    0.0399995   -0.0713567   0.0114297   -0.129194    -0.0399515    0.213411
  0.11387      0.01679       0.120884     0.163349    -0.00720842   0.15257     -0.0402814   -0.0169536   -0.0222367   -0.0918852    0.0849825    0.202371    -0.0270907   0.0924455   -0.0429105    -0.159556    -0.0180349    0.0174564    0.0319061  -0.00304417  -0.0844275   -0.0707229  -0.0359835   -0.107381     0.004063    -0.0549874
 -0.0938858   -0.17956      -0.0844696   -0.147283    -0.103242     0.0551932   -0.107618     0.18602     -0.0570765    0.0636604   -0.154884     0.162899     0.0748668   0.0817034    0.030449     -0.0007328    0.0454468    0.182767     0.185531   -0.0188452   -0.0302892   -0.031278    0.072199    -0.129346    -0.114602    -0.113549
 -0.00948759   0.184258      0.0837823    0.0753153   -0.138301    -0.148438     0.118907     0.132531     0.0810532    0.162265     0.00608181  -0.160154    -0.0944079  -0.0104932   -0.0691368    -0.0239964    0.195502    -0.178929     0.0783989   0.00590011   0.255134     0.164092   -0.0629073   -0.0253231   -0.0469245   -0.0470957
 -0.0571812    0.0239935    -0.059024    -0.0102692    0.0239693    0.0258713   -0.0332556    0.175214     0.116699    -0.0134515    0.0765996    0.132507    -0.140905    0.116275    -0.0975208     0.0870569    0.0529127   -0.044891    -0.0332487   0.15315      0.0518887   -0.267273   -0.0237239   -0.106553     0.196641    -0.0639237kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4220183527154473
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422037
[ Info: iteration 2, average log likelihood -1.421965
[ Info: iteration 3, average log likelihood -1.421907
[ Info: iteration 4, average log likelihood -1.421838
[ Info: iteration 5, average log likelihood -1.421753
[ Info: iteration 6, average log likelihood -1.421647
[ Info: iteration 7, average log likelihood -1.421509
[ Info: iteration 8, average log likelihood -1.421309
[ Info: iteration 9, average log likelihood -1.420974
[ Info: iteration 10, average log likelihood -1.420383
[ Info: iteration 11, average log likelihood -1.419454
[ Info: iteration 12, average log likelihood -1.418328
[ Info: iteration 13, average log likelihood -1.417393
[ Info: iteration 14, average log likelihood -1.416860
[ Info: iteration 15, average log likelihood -1.416624
[ Info: iteration 16, average log likelihood -1.416529
[ Info: iteration 17, average log likelihood -1.416492
[ Info: iteration 18, average log likelihood -1.416477
[ Info: iteration 19, average log likelihood -1.416471
[ Info: iteration 20, average log likelihood -1.416468
[ Info: iteration 21, average log likelihood -1.416467
[ Info: iteration 22, average log likelihood -1.416466
[ Info: iteration 23, average log likelihood -1.416466
[ Info: iteration 24, average log likelihood -1.416466
[ Info: iteration 25, average log likelihood -1.416465
[ Info: iteration 26, average log likelihood -1.416465
[ Info: iteration 27, average log likelihood -1.416465
[ Info: iteration 28, average log likelihood -1.416465
[ Info: iteration 29, average log likelihood -1.416465
[ Info: iteration 30, average log likelihood -1.416465
[ Info: iteration 31, average log likelihood -1.416465
[ Info: iteration 32, average log likelihood -1.416464
[ Info: iteration 33, average log likelihood -1.416464
[ Info: iteration 34, average log likelihood -1.416464
[ Info: iteration 35, average log likelihood -1.416464
[ Info: iteration 36, average log likelihood -1.416464
[ Info: iteration 37, average log likelihood -1.416464
[ Info: iteration 38, average log likelihood -1.416464
[ Info: iteration 39, average log likelihood -1.416464
[ Info: iteration 40, average log likelihood -1.416464
[ Info: iteration 41, average log likelihood -1.416464
[ Info: iteration 42, average log likelihood -1.416464
[ Info: iteration 43, average log likelihood -1.416464
[ Info: iteration 44, average log likelihood -1.416464
[ Info: iteration 45, average log likelihood -1.416464
[ Info: iteration 46, average log likelihood -1.416464
[ Info: iteration 47, average log likelihood -1.416464
[ Info: iteration 48, average log likelihood -1.416464
[ Info: iteration 49, average log likelihood -1.416464
[ Info: iteration 50, average log likelihood -1.416464
┌ Info: EM with 100000 data points 50 iterations avll -1.416464
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422036604442105
│     -1.4219645579327993
│      ⋮
└     -1.4164638848140052
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416478
[ Info: iteration 2, average log likelihood -1.416416
[ Info: iteration 3, average log likelihood -1.416362
[ Info: iteration 4, average log likelihood -1.416297
[ Info: iteration 5, average log likelihood -1.416217
[ Info: iteration 6, average log likelihood -1.416124
[ Info: iteration 7, average log likelihood -1.416025
[ Info: iteration 8, average log likelihood -1.415930
[ Info: iteration 9, average log likelihood -1.415847
[ Info: iteration 10, average log likelihood -1.415779
[ Info: iteration 11, average log likelihood -1.415725
[ Info: iteration 12, average log likelihood -1.415683
[ Info: iteration 13, average log likelihood -1.415649
[ Info: iteration 14, average log likelihood -1.415622
[ Info: iteration 15, average log likelihood -1.415602
[ Info: iteration 16, average log likelihood -1.415585
[ Info: iteration 17, average log likelihood -1.415572
[ Info: iteration 18, average log likelihood -1.415561
[ Info: iteration 19, average log likelihood -1.415552
[ Info: iteration 20, average log likelihood -1.415543
[ Info: iteration 21, average log likelihood -1.415535
[ Info: iteration 22, average log likelihood -1.415528
[ Info: iteration 23, average log likelihood -1.415520
[ Info: iteration 24, average log likelihood -1.415513
[ Info: iteration 25, average log likelihood -1.415507
[ Info: iteration 26, average log likelihood -1.415500
[ Info: iteration 27, average log likelihood -1.415493
[ Info: iteration 28, average log likelihood -1.415487
[ Info: iteration 29, average log likelihood -1.415481
[ Info: iteration 30, average log likelihood -1.415475
[ Info: iteration 31, average log likelihood -1.415470
[ Info: iteration 32, average log likelihood -1.415464
[ Info: iteration 33, average log likelihood -1.415459
[ Info: iteration 34, average log likelihood -1.415455
[ Info: iteration 35, average log likelihood -1.415450
[ Info: iteration 36, average log likelihood -1.415446
[ Info: iteration 37, average log likelihood -1.415442
[ Info: iteration 38, average log likelihood -1.415438
[ Info: iteration 39, average log likelihood -1.415434
[ Info: iteration 40, average log likelihood -1.415431
[ Info: iteration 41, average log likelihood -1.415428
[ Info: iteration 42, average log likelihood -1.415425
[ Info: iteration 43, average log likelihood -1.415422
[ Info: iteration 44, average log likelihood -1.415419
[ Info: iteration 45, average log likelihood -1.415416
[ Info: iteration 46, average log likelihood -1.415414
[ Info: iteration 47, average log likelihood -1.415411
[ Info: iteration 48, average log likelihood -1.415409
[ Info: iteration 49, average log likelihood -1.415407
[ Info: iteration 50, average log likelihood -1.415404
┌ Info: EM with 100000 data points 50 iterations avll -1.415404
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416478424199369
│     -1.4164155909200014
│      ⋮
└     -1.4154042704053174
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415412
[ Info: iteration 2, average log likelihood -1.415345
[ Info: iteration 3, average log likelihood -1.415282
[ Info: iteration 4, average log likelihood -1.415208
[ Info: iteration 5, average log likelihood -1.415116
[ Info: iteration 6, average log likelihood -1.415005
[ Info: iteration 7, average log likelihood -1.414880
[ Info: iteration 8, average log likelihood -1.414749
[ Info: iteration 9, average log likelihood -1.414621
[ Info: iteration 10, average log likelihood -1.414503
[ Info: iteration 11, average log likelihood -1.414399
[ Info: iteration 12, average log likelihood -1.414309
[ Info: iteration 13, average log likelihood -1.414235
[ Info: iteration 14, average log likelihood -1.414174
[ Info: iteration 15, average log likelihood -1.414127
[ Info: iteration 16, average log likelihood -1.414090
[ Info: iteration 17, average log likelihood -1.414062
[ Info: iteration 18, average log likelihood -1.414040
[ Info: iteration 19, average log likelihood -1.414022
[ Info: iteration 20, average log likelihood -1.414008
[ Info: iteration 21, average log likelihood -1.413996
[ Info: iteration 22, average log likelihood -1.413986
[ Info: iteration 23, average log likelihood -1.413977
[ Info: iteration 24, average log likelihood -1.413969
[ Info: iteration 25, average log likelihood -1.413961
[ Info: iteration 26, average log likelihood -1.413955
[ Info: iteration 27, average log likelihood -1.413948
[ Info: iteration 28, average log likelihood -1.413942
[ Info: iteration 29, average log likelihood -1.413937
[ Info: iteration 30, average log likelihood -1.413932
[ Info: iteration 31, average log likelihood -1.413927
[ Info: iteration 32, average log likelihood -1.413922
[ Info: iteration 33, average log likelihood -1.413918
[ Info: iteration 34, average log likelihood -1.413914
[ Info: iteration 35, average log likelihood -1.413910
[ Info: iteration 36, average log likelihood -1.413906
[ Info: iteration 37, average log likelihood -1.413903
[ Info: iteration 38, average log likelihood -1.413899
[ Info: iteration 39, average log likelihood -1.413896
[ Info: iteration 40, average log likelihood -1.413893
[ Info: iteration 41, average log likelihood -1.413890
[ Info: iteration 42, average log likelihood -1.413887
[ Info: iteration 43, average log likelihood -1.413884
[ Info: iteration 44, average log likelihood -1.413882
[ Info: iteration 45, average log likelihood -1.413879
[ Info: iteration 46, average log likelihood -1.413877
[ Info: iteration 47, average log likelihood -1.413874
[ Info: iteration 48, average log likelihood -1.413872
[ Info: iteration 49, average log likelihood -1.413870
[ Info: iteration 50, average log likelihood -1.413868
┌ Info: EM with 100000 data points 50 iterations avll -1.413868
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.415411807076622
│     -1.415344959611003
│      ⋮
└     -1.4138678828912399
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413875
[ Info: iteration 2, average log likelihood -1.413824
[ Info: iteration 3, average log likelihood -1.413779
[ Info: iteration 4, average log likelihood -1.413726
[ Info: iteration 5, average log likelihood -1.413662
[ Info: iteration 6, average log likelihood -1.413584
[ Info: iteration 7, average log likelihood -1.413492
[ Info: iteration 8, average log likelihood -1.413387
[ Info: iteration 9, average log likelihood -1.413276
[ Info: iteration 10, average log likelihood -1.413164
[ Info: iteration 11, average log likelihood -1.413055
[ Info: iteration 12, average log likelihood -1.412955
[ Info: iteration 13, average log likelihood -1.412866
[ Info: iteration 14, average log likelihood -1.412788
[ Info: iteration 15, average log likelihood -1.412722
[ Info: iteration 16, average log likelihood -1.412667
[ Info: iteration 17, average log likelihood -1.412621
[ Info: iteration 18, average log likelihood -1.412583
[ Info: iteration 19, average log likelihood -1.412550
[ Info: iteration 20, average log likelihood -1.412522
[ Info: iteration 21, average log likelihood -1.412497
[ Info: iteration 22, average log likelihood -1.412475
[ Info: iteration 23, average log likelihood -1.412455
[ Info: iteration 24, average log likelihood -1.412437
[ Info: iteration 25, average log likelihood -1.412420
[ Info: iteration 26, average log likelihood -1.412403
[ Info: iteration 27, average log likelihood -1.412388
[ Info: iteration 28, average log likelihood -1.412374
[ Info: iteration 29, average log likelihood -1.412360
[ Info: iteration 30, average log likelihood -1.412347
[ Info: iteration 31, average log likelihood -1.412334
[ Info: iteration 32, average log likelihood -1.412321
[ Info: iteration 33, average log likelihood -1.412310
[ Info: iteration 34, average log likelihood -1.412298
[ Info: iteration 35, average log likelihood -1.412287
[ Info: iteration 36, average log likelihood -1.412276
[ Info: iteration 37, average log likelihood -1.412266
[ Info: iteration 38, average log likelihood -1.412256
[ Info: iteration 39, average log likelihood -1.412246
[ Info: iteration 40, average log likelihood -1.412237
[ Info: iteration 41, average log likelihood -1.412228
[ Info: iteration 42, average log likelihood -1.412219
[ Info: iteration 43, average log likelihood -1.412210
[ Info: iteration 44, average log likelihood -1.412201
[ Info: iteration 45, average log likelihood -1.412193
[ Info: iteration 46, average log likelihood -1.412185
[ Info: iteration 47, average log likelihood -1.412176
[ Info: iteration 48, average log likelihood -1.412168
[ Info: iteration 49, average log likelihood -1.412160
[ Info: iteration 50, average log likelihood -1.412152
┌ Info: EM with 100000 data points 50 iterations avll -1.412152
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413874673176787
│     -1.4138243570004787
│      ⋮
└     -1.4121522288203958
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412153
[ Info: iteration 2, average log likelihood -1.412093
[ Info: iteration 3, average log likelihood -1.412035
[ Info: iteration 4, average log likelihood -1.411968
[ Info: iteration 5, average log likelihood -1.411884
[ Info: iteration 6, average log likelihood -1.411779
[ Info: iteration 7, average log likelihood -1.411651
[ Info: iteration 8, average log likelihood -1.411505
[ Info: iteration 9, average log likelihood -1.411347
[ Info: iteration 10, average log likelihood -1.411184
[ Info: iteration 11, average log likelihood -1.411023
[ Info: iteration 12, average log likelihood -1.410870
[ Info: iteration 13, average log likelihood -1.410728
[ Info: iteration 14, average log likelihood -1.410597
[ Info: iteration 15, average log likelihood -1.410480
[ Info: iteration 16, average log likelihood -1.410374
[ Info: iteration 17, average log likelihood -1.410280
[ Info: iteration 18, average log likelihood -1.410196
[ Info: iteration 19, average log likelihood -1.410121
[ Info: iteration 20, average log likelihood -1.410054
[ Info: iteration 21, average log likelihood -1.409993
[ Info: iteration 22, average log likelihood -1.409938
[ Info: iteration 23, average log likelihood -1.409887
[ Info: iteration 24, average log likelihood -1.409840
[ Info: iteration 25, average log likelihood -1.409797
[ Info: iteration 26, average log likelihood -1.409756
[ Info: iteration 27, average log likelihood -1.409719
[ Info: iteration 28, average log likelihood -1.409683
[ Info: iteration 29, average log likelihood -1.409649
[ Info: iteration 30, average log likelihood -1.409618
[ Info: iteration 31, average log likelihood -1.409587
[ Info: iteration 32, average log likelihood -1.409559
[ Info: iteration 33, average log likelihood -1.409531
[ Info: iteration 34, average log likelihood -1.409505
[ Info: iteration 35, average log likelihood -1.409480
[ Info: iteration 36, average log likelihood -1.409457
[ Info: iteration 37, average log likelihood -1.409434
[ Info: iteration 38, average log likelihood -1.409412
[ Info: iteration 39, average log likelihood -1.409391
[ Info: iteration 40, average log likelihood -1.409370
[ Info: iteration 41, average log likelihood -1.409351
[ Info: iteration 42, average log likelihood -1.409332
[ Info: iteration 43, average log likelihood -1.409314
[ Info: iteration 44, average log likelihood -1.409296
[ Info: iteration 45, average log likelihood -1.409279
[ Info: iteration 46, average log likelihood -1.409263
[ Info: iteration 47, average log likelihood -1.409247
[ Info: iteration 48, average log likelihood -1.409231
[ Info: iteration 49, average log likelihood -1.409216
[ Info: iteration 50, average log likelihood -1.409201
┌ Info: EM with 100000 data points 50 iterations avll -1.409201
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412153389317043
│     -1.4120930259371272
│      ⋮
└     -1.4092010744898635
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4220183527154473
│     -1.422036604442105
│     -1.4219645579327993
│     -1.4219067726839505
│      ⋮
│     -1.409230984056609
│     -1.4092158181396033
└     -1.4092010744898635
32×26 Array{Float64,2}:
  0.169483    -0.246769   -0.757093     0.683818    -0.0809071    0.483082   -0.0132687   0.170878     0.355983   -0.414879    -0.348714    -0.388507     0.276952    -0.322781    -0.365822   -0.237501    -0.125905   -0.278001    -0.208368    -0.403837   -0.230447    -0.0731834   0.0114615   -0.115794    -0.836293    -0.419502
  0.263724    -0.307856   -0.010609     0.157546    -0.106356     0.13239    -0.156886   -0.037233    -0.386101   -0.354236     0.24651     -0.255854    -0.159031    -0.315963     0.412871   -0.0456578   -0.0602587   0.472282     0.0609362   -0.322642   -0.523982    -0.119014   -0.0916488   -5.57051e-5  -0.540538    -0.0452365
 -0.339077    -0.315814   -0.167895     0.219793     0.0938344    0.573228   -0.22531     0.0980533   -0.26198    -0.383406    -0.0288308    0.069034    -0.536806     0.0491113   -0.258991    0.0713942    0.13853     0.239014     0.0873925   -0.123179    0.501399     0.555663   -0.431282    -0.359988     0.558514    -0.30368
  0.311417    -0.102398    0.00730299  -0.0469393    0.126649    -0.32953     0.745632    0.300298    -0.614686   -0.760787     0.0321066   -0.0750884   -0.585509    -0.207791    -0.128895   -0.0510686   -0.443908    0.1686      -0.136013     0.557793    0.0373499    0.285635   -0.257266    -0.317284     0.675697    -0.286766
 -0.322518    -0.296296    0.308286     0.285448     0.024081     0.210049   -0.0517957   0.334958     0.0327491   0.0192258   -0.479241     0.346361     0.329225     0.0587651   -1.02043    -0.283006    -0.032907    0.317373     0.215168    -0.310057    0.859759    -0.221397   -0.0571186    0.00174201  -0.114463     0.600599
  0.297387    -0.774977    0.862805    -0.260629    -0.622482    -0.285766   -0.166694    0.043707     0.103351   -0.0259178   -0.61464      0.0223443    0.141366    -0.337608     0.332291   -0.620285    -0.183673    0.00637488  -0.147072    -0.162952    0.224063     0.491126   -0.325929     0.464497     0.0456186    0.131804
 -0.0349502   -0.0378827   0.086027    -0.0360009    0.187039    -0.0133309   0.547785   -0.54242      0.082788    0.00525991  -0.0809513    0.227095     0.107762     0.060298     0.0742199  -0.31498     -0.292354    0.00722541  -0.98003     -0.113159    0.0661034    0.202553    0.186782     0.0105797   -0.226502     0.127247
 -0.0131809    0.17368     0.276167    -0.152391    -0.123765    -0.0722021   0.652006    0.0351247    0.710051   -0.0218302    0.00935673   0.00817041  -0.0370099    0.141561     0.307428   -0.0113075   -0.766984    0.25269     -0.121609     0.407806   -0.00649539  -0.24171     0.0360248    0.0587328   -0.461826     0.427863
 -0.0631336    0.095603    0.141271    -0.188821    -0.198377    -0.548834   -0.13406     0.0889007   -0.505969   -0.218715     0.512089    -0.101319    -0.136794     0.0937688    0.331045    0.472507     0.0877231   0.193887     0.0295042   -0.550781   -0.0615866   -0.229618   -0.0461893    0.0872613    0.780657    -0.174716
 -0.195457     0.196418   -0.247306    -0.068105    -0.456961    -0.217928    0.0343646  -0.279343     0.430669   -0.248584     0.166938    -0.00427247   0.170179     0.372153    -0.123726    0.27676     -0.306641    0.0917823    0.306011    -0.455152    0.517607    -0.228243   -0.0890021    0.454896    -0.0148796   -0.109416
 -0.0755375   -0.0128272   0.0455819   -0.0367385    0.0939305   -0.0963986   0.0113789  -0.10543     -0.280572   -0.169944     0.0109       0.120549     0.326627    -0.0334045   -0.27722    -0.386338     0.232798    0.0844455    0.0706009   -0.267949    0.136013    -0.260639    0.0549274   -0.187508     0.102169     0.0255415
  0.0195924    0.0749007  -0.15416     -0.0266189   -0.081999     0.0103635   0.0153318   0.0159599    0.0266698   0.0486381    0.00832871   0.0125519   -0.0706737    0.0584294   -0.0116004   0.18035     -0.009286   -0.00927159  -0.00629611   0.0576699  -0.0513958    0.0758077   0.00543271   0.0541367   -0.0135141   -0.0812785
 -0.146693     0.120963   -0.237521    -0.454789    -0.00486564   0.172683   -0.237726   -0.18892      0.395953    0.306824     0.0887308   -0.481735     0.309878    -0.00173027   0.256896   -0.00572375   0.288932    0.0878088    0.527576     0.244586   -0.202124    -0.114873   -0.19137     -0.176155    -0.379272     0.191416
 -0.0189333   -0.0371598   0.341515     0.198665    -0.24234      0.333492   -0.0988083   0.848886    -0.0410523   0.142614     0.00871112  -0.328469    -0.348679    -0.0622307    0.0843276   0.184489    -0.186466   -0.0241643    0.246158     0.375914    0.0406646   -0.0860235  -0.110957    -0.0438621    0.237711     0.0814046
  0.0349792   -0.183025   -0.328341    -0.148445     0.301946    -0.331011   -0.260604    0.0283767    0.0952698   0.11617     -0.395833     0.380705    -0.189357    -0.138051     0.0576709  -0.0748737   -0.440311   -0.482359    -0.00502169   0.514852   -0.193452     0.180028   -0.0801729   -0.227182     0.0232868    0.153589
 -0.187856     0.0722719   0.137613    -0.21233     -0.0419783   -0.14148    -0.443976   -0.00939831   0.1595      0.706938     0.324845     0.47278      0.211705     0.0551627    0.178236    0.198994     0.564567   -0.295092     0.198169     0.0126524   0.0378502    0.136269    0.315915     0.105961     0.253859     0.146058
  0.280971    -0.552706    0.0892937   -0.270683     0.302926     0.239716   -0.287996    0.675111     0.143121   -0.0873573    0.566715    -0.408278    -0.541099    -0.227395    -0.214152    0.265324     0.268316    0.630484     1.01446     -0.2547      0.256228    -0.386058    0.188508    -0.444358     0.00993308   0.594724
 -0.0604758    0.261361   -0.105909     0.899863     0.224351     0.132079   -0.230823    0.681865    -0.591613   -0.659744     0.334312    -0.0168804   -0.0891784    0.00777632  -0.193937   -0.0916323   -0.122427    0.0256896   -0.057577    -0.331439   -0.00596838  -0.609393    0.127904    -0.455911    -0.00121855  -0.402552
 -0.739037     0.017183    0.206106    -0.296187     0.14016      0.0584868  -0.390952    0.774645    -0.085897    0.0617299   -0.324655     0.223921    -0.0345871    0.323537    -0.0934426  -0.370614    -0.441581   -0.435684     0.749149     0.237029    0.353407    -0.392131   -0.277704    -0.320154     0.0729055   -0.216103
 -0.00621682   0.554028   -0.428053    -0.151841     0.511472     0.444191   -0.272553    0.382019    -0.0899475   0.00916809   0.60595      0.498471    -0.622584     0.702153    -0.377147   -0.184336    -0.513944   -0.00142969   0.0880457    0.425496    0.0761244   -0.53131     0.572873    -0.00512104  -0.228526    -0.225921
  0.166267     0.379975    0.325097     0.374383     0.432139     0.342003    0.139447   -0.223519    -0.822419    0.709101     0.349762     0.0556036   -0.981378    -0.396287    -0.0811625  -0.286478     0.775373    0.373765    -0.236635     0.301754   -0.314177     0.367866    0.213414    -0.613933    -0.0114472   -0.0683388
 -0.122999    -0.320015    0.182637     0.0223031   -0.0757057   -0.37592     0.0657562  -0.538889    -0.511042   -0.0303995    0.017414    -0.0927325    0.44878     -0.815843     0.131572    0.354687     1.18265    -0.0891331   -0.213879    -0.572684   -0.378187     0.718216   -0.500017    -0.338741     0.250953    -0.0582637
  0.0553196    0.534678   -0.781441    -0.340679     0.368289    -0.170775   -0.0818173  -0.414164    -0.106862   -0.266393    -0.093627     0.301078     0.320187    -0.18506     -0.739644   -0.224103     0.621709   -0.255734     0.520888    -0.207221    0.193739    -0.0820759   0.0530976   -0.00679916  -0.216051    -0.22419
 -0.275687     0.109074   -0.313247     0.298713     0.0312266   -0.461554   -0.31945    -0.484762    -0.362401    0.151207    -0.145185     0.399628     0.656587     0.861122    -0.28054    -0.304037     0.419439    0.610484    -0.0367897   -0.278834    0.0307723    0.297445    0.46992     -0.343064     0.213506    -0.551056
  0.104929    -0.346876   -0.209289    -0.839856    -0.100274    -0.318961    0.0409368  -0.123865    -0.226561    0.746366    -0.0582498   -0.128929    -0.111254     0.0613029    0.47306     0.550925    -0.0353785  -0.301653     0.273705     0.921278   -0.989497     0.0924037  -0.0943025   -0.221633     0.289076     0.0503791
 -0.172529     0.799077   -0.391616    -0.264976    -0.396548    -0.145572    0.059917   -0.420413    -0.109389    0.157569    -0.113835     0.00883928   0.071564     0.00692881   0.640052    0.32632     -0.157693   -0.430624    -0.483138     0.279214   -0.614258     0.421108   -0.250797     0.433413    -0.0081134   -0.723685
  0.283311    -0.206231    0.393171    -0.00792999   0.5502       0.452096    0.146998    0.336556     0.31376     0.0878859   -0.571897    -0.490329     0.0905636   -0.019971     0.143774   -0.70773     -0.113152   -0.673668    -0.666676     0.521158    0.255971     0.150791   -0.259473    -0.285712    -0.0881346    0.313092
  0.00921991  -0.0326932  -0.107615    -0.0120491   -0.13194     -0.0448933  -0.0185047  -0.263205     0.0721175  -0.127759    -0.153298     0.157512    -0.00483634  -0.00204621  -0.0674321  -0.00665886  -0.142582    0.0163729   -0.0031837   -0.125863    0.198236     0.226234   -0.181552     0.225243    -0.0945497   -0.0451619
  0.138833     0.229528    0.285966    -0.187646     0.0117789   -0.192543    0.030841   -0.00626663  -0.39332     0.0745474    0.282063    -0.236805     0.607379    -0.354955     0.272605   -0.387691     0.0474892   0.256438    -0.207107    -0.11657    -0.83379     -0.773815    0.60613     -0.015357    -0.638822     0.213873
 -0.0531969    0.133072   -0.116987    -0.142317    -0.118284    -0.140996    0.306563   -0.418014     0.596463    0.394889     0.664639    -0.0485827    0.411901     0.235812     0.204528    0.497444     0.394912    0.309641    -0.237344     0.293686    0.135986    -0.144545    0.419164    -0.219078     0.192702     0.583281
  0.280739    -0.004353   -0.184675     0.0128424   -0.560491     0.0531082  -0.189612    0.344887     0.484073    0.209571    -0.0102396    0.146022    -0.238339    -0.345741     0.231092    0.474273    -0.413171   -0.587021    -0.0327392    0.324887   -0.293682    -0.250203    0.104892     1.06196     -0.0906919    0.383685
  0.726883     0.0282606  -0.0570883    0.055142    -0.589809     0.511383    0.657692   -0.118375     0.341861   -0.042772     0.0524225   -0.186453     0.0172929   -0.127335    -0.0942036  -0.0770567    0.311512    0.771312    -0.562473     0.149126   -0.0723821    0.551454    0.421991     0.762454    -0.112276     0.198782[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409187
[ Info: iteration 2, average log likelihood -1.409173
[ Info: iteration 3, average log likelihood -1.409159
[ Info: iteration 4, average log likelihood -1.409146
[ Info: iteration 5, average log likelihood -1.409133
[ Info: iteration 6, average log likelihood -1.409121
[ Info: iteration 7, average log likelihood -1.409109
[ Info: iteration 8, average log likelihood -1.409097
[ Info: iteration 9, average log likelihood -1.409086
[ Info: iteration 10, average log likelihood -1.409075
┌ Info: EM with 100000 data points 10 iterations avll -1.409075
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.320392e+05
      1       7.072992e+05      -2.247400e+05 |       32
      2       6.920742e+05      -1.522502e+04 |       32
      3       6.862006e+05      -5.873530e+03 |       32
      4       6.831758e+05      -3.024794e+03 |       32
      5       6.813285e+05      -1.847347e+03 |       32
      6       6.800978e+05      -1.230734e+03 |       32
      7       6.791054e+05      -9.923408e+02 |       32
      8       6.783134e+05      -7.920120e+02 |       32
      9       6.776438e+05      -6.696428e+02 |       32
     10       6.770886e+05      -5.551626e+02 |       32
     11       6.765885e+05      -5.001140e+02 |       32
     12       6.761385e+05      -4.499848e+02 |       32
     13       6.757327e+05      -4.057650e+02 |       32
     14       6.753636e+05      -3.691213e+02 |       32
     15       6.750587e+05      -3.049365e+02 |       32
     16       6.747868e+05      -2.718657e+02 |       32
     17       6.745017e+05      -2.851121e+02 |       32
     18       6.742183e+05      -2.833647e+02 |       32
     19       6.739639e+05      -2.544467e+02 |       32
     20       6.737233e+05      -2.406309e+02 |       32
     21       6.735087e+05      -2.145034e+02 |       32
     22       6.733031e+05      -2.056631e+02 |       32
     23       6.731067e+05      -1.963767e+02 |       32
     24       6.729333e+05      -1.733716e+02 |       32
     25       6.727793e+05      -1.540631e+02 |       32
     26       6.726523e+05      -1.270195e+02 |       32
     27       6.725313e+05      -1.209646e+02 |       32
     28       6.724195e+05      -1.118016e+02 |       32
     29       6.723052e+05      -1.143382e+02 |       32
     30       6.722008e+05      -1.043486e+02 |       32
     31       6.721090e+05      -9.178516e+01 |       32
     32       6.720265e+05      -8.247146e+01 |       32
     33       6.719505e+05      -7.605891e+01 |       32
     34       6.718777e+05      -7.276533e+01 |       32
     35       6.718146e+05      -6.309905e+01 |       32
     36       6.717481e+05      -6.654234e+01 |       32
     37       6.716841e+05      -6.402665e+01 |       32
     38       6.716236e+05      -6.049279e+01 |       32
     39       6.715708e+05      -5.271283e+01 |       32
     40       6.715163e+05      -5.451451e+01 |       32
     41       6.714593e+05      -5.703879e+01 |       32
     42       6.713994e+05      -5.991868e+01 |       32
     43       6.713426e+05      -5.681413e+01 |       32
     44       6.712773e+05      -6.529842e+01 |       32
     45       6.712136e+05      -6.362406e+01 |       32
     46       6.711577e+05      -5.589588e+01 |       32
     47       6.711009e+05      -5.682377e+01 |       32
     48       6.710527e+05      -4.817205e+01 |       32
     49       6.710119e+05      -4.080933e+01 |       32
     50       6.709747e+05      -3.721312e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670974.7254820054)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421086
[ Info: iteration 2, average log likelihood -1.416084
[ Info: iteration 3, average log likelihood -1.414827
[ Info: iteration 4, average log likelihood -1.413959
[ Info: iteration 5, average log likelihood -1.412984
[ Info: iteration 6, average log likelihood -1.411904
[ Info: iteration 7, average log likelihood -1.411001
[ Info: iteration 8, average log likelihood -1.410447
[ Info: iteration 9, average log likelihood -1.410150
[ Info: iteration 10, average log likelihood -1.409978
[ Info: iteration 11, average log likelihood -1.409864
[ Info: iteration 12, average log likelihood -1.409777
[ Info: iteration 13, average log likelihood -1.409707
[ Info: iteration 14, average log likelihood -1.409647
[ Info: iteration 15, average log likelihood -1.409596
[ Info: iteration 16, average log likelihood -1.409551
[ Info: iteration 17, average log likelihood -1.409511
[ Info: iteration 18, average log likelihood -1.409474
[ Info: iteration 19, average log likelihood -1.409441
[ Info: iteration 20, average log likelihood -1.409410
[ Info: iteration 21, average log likelihood -1.409382
[ Info: iteration 22, average log likelihood -1.409356
[ Info: iteration 23, average log likelihood -1.409331
[ Info: iteration 24, average log likelihood -1.409308
[ Info: iteration 25, average log likelihood -1.409286
[ Info: iteration 26, average log likelihood -1.409265
[ Info: iteration 27, average log likelihood -1.409246
[ Info: iteration 28, average log likelihood -1.409227
[ Info: iteration 29, average log likelihood -1.409208
[ Info: iteration 30, average log likelihood -1.409191
[ Info: iteration 31, average log likelihood -1.409174
[ Info: iteration 32, average log likelihood -1.409157
[ Info: iteration 33, average log likelihood -1.409141
[ Info: iteration 34, average log likelihood -1.409126
[ Info: iteration 35, average log likelihood -1.409110
[ Info: iteration 36, average log likelihood -1.409095
[ Info: iteration 37, average log likelihood -1.409081
[ Info: iteration 38, average log likelihood -1.409066
[ Info: iteration 39, average log likelihood -1.409052
[ Info: iteration 40, average log likelihood -1.409038
[ Info: iteration 41, average log likelihood -1.409025
[ Info: iteration 42, average log likelihood -1.409011
[ Info: iteration 43, average log likelihood -1.408998
[ Info: iteration 44, average log likelihood -1.408986
[ Info: iteration 45, average log likelihood -1.408973
[ Info: iteration 46, average log likelihood -1.408961
[ Info: iteration 47, average log likelihood -1.408950
[ Info: iteration 48, average log likelihood -1.408939
[ Info: iteration 49, average log likelihood -1.408928
[ Info: iteration 50, average log likelihood -1.408918
┌ Info: EM with 100000 data points 50 iterations avll -1.408918
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0636623  -0.0900682  -0.141247   -0.0987183    0.32603    -0.224528    -0.101515   -0.016817     -0.0778117   0.202567   -0.242652    0.36121     -0.223573    -0.317811    0.0982364   -0.165875   -0.332952    -0.367999   -0.151784    0.34348     -0.256317    0.170173   -0.0776779  -0.285926    -0.00853095   0.0439918
 -0.317306    0.122534   -0.411515    0.212698     0.0882389  -0.709682    -0.204644   -0.691019     -0.232878    0.118504   -0.0746008   0.390639     0.76193      0.889417   -0.36839     -0.1851      0.303344     0.551739    0.103102   -0.32628      0.089932    0.16732     0.331608   -0.314869     0.22062     -0.473594
 -0.0459949   0.411611    0.122276   -0.26832     -0.377678   -0.39212     -0.588586    0.153185      0.459381    0.55454     0.383437   -0.00721616   0.134539     0.164436    0.34906      0.445912    0.448788    -0.222183    0.605796   -0.120362     0.300926    0.0574265   0.143015    0.311141     0.0995364    0.0549772
 -0.330696   -0.128609    0.346604    0.174477    -0.410724   -0.0442249   -0.168753    0.435566     -0.52155    -0.233934    0.530439   -0.0396276   -0.0169198   -0.0203012   0.0392042    0.33576     0.0199771    0.198509    0.275206   -0.424312     0.0545957  -0.332882   -0.0447902  -0.181576     0.917166    -0.200236
  0.227302    0.220957    0.380463    0.629289     0.0962662   0.372768    -0.22439     0.146151     -0.316952    0.0646478  -0.174905    0.0354999    0.0764339    0.140057    0.32724     -0.58594     0.481581     0.494563   -0.904491   -0.00255805  -0.152061    0.327363    0.77595    -0.184957    -0.0880123   -0.156203
  0.530198    0.244126    0.0442553  -0.00633508  -0.589492    0.177495     0.580227    0.104943      0.527806   -0.105038    0.241167   -0.0674633   -0.0802337    0.0526851   0.293325     0.12978    -0.477545     0.540945   -0.180875    0.280497    -0.155084   -0.156404    0.253975    0.662198    -0.385438     0.199614
 -0.662574   -0.0854877   0.230531   -0.300187     0.0187103   0.21388     -0.414822    0.713613     -0.135609    0.0154794  -0.133556    0.217641    -0.368689     0.20018    -0.140031    -0.374737   -0.744021    -0.404755    0.725491    0.323729     0.32788    -0.377636   -0.291729   -0.120526     0.0177484   -0.272841
  0.574311   -0.140169   -0.834032    0.712693     0.045918    0.169425    -0.152368    0.38321       0.0942725  -0.481272   -0.22358    -0.412252     0.0821702   -0.340328   -0.506764    -0.375833   -0.152871    -0.492819   -0.0401567  -0.243648    -0.242537    0.0383095  -0.0929115  -0.0784792   -0.319749    -0.712341
  0.0573788   0.276922   -0.225398   -0.0957188    0.110544   -0.210843    -0.0316459  -0.395322     -0.220253   -0.136365    0.1679      0.110396     0.143215     0.0657094   0.012521     0.0692095   0.387945     0.0956668  -0.153386   -0.4926      -0.0495502   0.0432569   0.0167864   0.019491     0.21795     -0.275005
 -0.563716    0.389732   -0.719508    0.0253492    0.53145     0.644919    -0.312086   -0.0392498     0.231637    0.868739    0.878513    0.266139    -0.152604     0.127605   -0.420437     0.151055    0.564026     0.0248679   0.313734    0.579074    -0.221413   -0.0855369   0.503074   -0.370896    -0.259771     0.0616673
  0.418444   -0.710671    0.920007   -0.160297    -0.618116   -0.303718     0.0385269   0.124248     -0.0304509  -0.200879   -0.637896   -0.0997716    0.0554093   -0.488859    0.38055     -0.557094   -0.225798    -0.0736549  -0.239374   -0.229697     0.194635    0.48872    -0.448376    0.394255     0.165721     0.0877733
  0.580706   -0.697558    0.213051   -0.164148     0.397594    0.31202     -0.380359    0.622893      0.0404126  -0.0174259   0.606263   -0.416081    -0.623869    -0.4942     -0.17607      0.147936    0.371847     0.839036    0.890707   -0.28535      0.198585   -0.391447    0.345157   -0.464876    -0.36927      0.508263
 -0.100068   -0.127324    0.189845   -0.16141     -0.150686   -0.183916     0.0808647  -0.145222      0.167031    0.0278396   0.0576834   0.104652     0.160296     0.171818   -0.00341154  -0.012048   -0.214486     0.0449038  -0.0406099   0.0878529    0.174539   -0.0665485   0.0430958   0.0723834    0.0387856    0.193776
 -0.161108   -0.264347    0.46197     0.187523     0.104817   -0.251621     0.148144   -0.158061     -0.723277    0.231955    1.04737    -0.437564    -0.556817    -0.2558      1.13545      0.201689   -0.199105     0.506416   -0.665546   -0.463448    -0.625014   -0.0368166  -0.251063    0.0535878   -0.0377292    0.0891149
  0.136574    0.220864   -0.16494    -0.323456     0.208676   -0.236054     0.491171   -0.903162      0.306102    0.0322279   0.0310389   0.38886      0.120353     0.196541   -0.083225    -0.358502   -0.14919     -0.191245   -0.738413   -0.0201539    0.283936    0.204705    0.39481     0.204302    -0.227171     0.13447
 -0.262237   -0.49863    -0.091316   -0.51027      0.0267156  -0.380338     0.132251    0.248901      0.165621    0.375492   -0.16851    -0.121965     0.0481243    0.106432   -0.155351     0.562917   -0.284507     0.0569989   0.462466    0.377118    -0.244031   -0.330712   -0.190696    0.00240408   0.661793     0.883269
 -0.0152309   0.41199    -0.505826   -0.160517    -0.0914864  -0.127576     0.192388   -0.279942     -0.0484608  -0.382848    0.353639   -0.238856     0.168668     0.0203735  -0.299664    -0.0984953   0.0496125    0.365305    0.385781   -0.148296    -0.071644   -0.512164    0.0798899  -0.131769    -0.430701    -0.162801
 -0.390542   -0.356582   -0.395793    0.202815    -0.365647    0.193249    -0.134538   -0.536871      0.426646   -0.13361    -0.328684   -0.0853383    0.589118    -0.285947    0.188695     0.245262   -0.258912    -0.212891   -0.171483   -0.949637    -0.078443   -0.179066   -0.0199541   0.635579    -0.816079     0.233488
 -0.74595     0.403095    0.0106909  -0.23367     -0.542073   -0.162463     0.112324   -0.0299331     0.171999    0.211877   -0.671342    0.18563     -0.00856787   0.957054    0.544393    -0.0255899  -0.117492    -0.110286   -0.520401    0.267968    -0.0832287   0.584727   -0.258616    0.308218     0.0274548   -0.486214
  0.213221    0.190472   -0.324237   -0.644487    -0.208914   -0.291382    -0.0256918  -0.293644     -0.159054    0.396345    0.0413053  -0.110063     0.0112465   -0.15792     0.762965     0.533629   -0.0397842   -0.494738   -0.0812331   0.698426    -1.02358     0.145522   -0.0109154   0.0217909    0.0187085   -0.357296
 -0.185191   -0.0790279  -0.199574   -0.0553851    0.126807   -0.0282468   -0.374642   -0.362994     -0.934641   -0.196539   -0.0906793   0.306187    -0.0364371   -0.584686   -0.463297    -0.108971    0.941475    -0.0605191   0.0316845  -0.438888    -0.220778    0.483755   -0.323213   -0.113906     0.0259057   -0.637794
 -0.0637979   0.217946   -0.394257    0.416315     0.717497    0.122748    -0.0629992   0.818311     -0.2767     -0.841619    0.299514    0.361767    -0.391821     0.536131   -0.0467265    0.214095   -0.720246    -0.0905787  -0.105367   -0.184119     0.100846   -0.617101    0.24367    -0.0905144   -0.192688    -0.0380144
 -0.0871186  -0.205329   -0.461272   -0.0961377    0.197796    0.259989    -0.190097    0.000818595   0.132358   -0.429893   -0.142073    0.0287683   -0.47909      0.380641   -0.104222     0.359989    0.12165      0.0751836   0.223294   -0.00935253   0.623092    0.499735   -0.432445   -0.232028     0.69053     -0.133862
 -0.0716136  -0.0426587  -0.0434763   0.0185243    0.0786088   0.0206176   -0.203191    0.311638     -0.0624312   0.0990336  -0.564154    0.319664     0.534213     0.0203799  -0.678627    -0.370111    0.359815    -0.11229     0.453045    0.0175251    0.170591   -0.344869    0.124448   -0.138522    -0.116786     0.351466
  0.25785     0.123556    0.103198    0.109568     0.246528   -0.0409854    0.721176    0.298726     -0.779421   -0.304083    0.175433   -0.0256914   -0.921324    -0.251811   -0.264578    -0.177362   -0.059414     0.398731   -0.0396685   0.746813     0.16374     0.484474   -0.188848   -0.774145     0.681963    -0.298111
 -0.104282    0.423736    0.193006   -0.0603796    0.116165   -0.0100936   -0.121758    0.217769     -0.258721   -0.10313     0.183901   -0.133514     0.166875     0.0880856  -0.0229674   -0.194142    0.155587     0.0336782   0.0813187  -0.164147     0.0470208  -0.518109    0.263951   -0.321849    -0.0338471   -0.213609
  0.232223   -0.112908   -0.327821    0.110112    -0.336887    0.0405402    0.0293789  -0.257524      0.377043    0.0559889  -0.110665    0.228844     0.00330477  -0.28038     0.0390101    0.242941   -0.232106    -0.123414   -0.0742885   0.221235    -0.104678    0.26877    -0.0838121   0.46683     -0.186474     0.249525
  0.292108   -0.055419    0.253567    0.0533069    0.307871    0.251283     0.29292     0.508691      0.585629    0.171928   -0.209753   -0.38516     -0.151624    -0.0781811   0.120067    -0.251885   -0.41676     -0.614617   -0.244904    0.760259     0.241554   -0.096056   -0.249339   -0.105604    -0.0947217    0.612246
  0.354946   -0.302079    0.346077   -0.0635889   -0.135271   -0.00569592   0.427816   -0.744358     -0.0964843   0.28498     0.6872     -0.288704     0.393337    -0.550357    0.00360304   0.259999    1.09375      0.440819   -0.323784    0.0677203   -0.143108    0.353579   -0.0290388  -0.0124363    0.315246     0.573268
 -0.151686   -0.210954    0.303559   -0.603945     0.435422    0.409397     0.0218741  -0.0576934     0.0649761   0.0658704  -0.49021    -0.388302     0.520414    -0.0719785   0.548058    -0.54996     0.0287766    0.234943   -0.258406    0.152419    -0.551527   -0.134773    0.120185   -0.496301    -0.544235     0.361473
  0.0221416  -0.0300579  -0.0528167   0.163559    -0.186438    0.375864    -0.030162    0.414678     -0.0415214   0.0702661  -0.034628   -0.211184    -0.272612    -0.114131    0.0372898    0.114854   -0.00565985   0.0445074   0.130704    0.135438    -0.0922038   0.0712462  -0.086971   -0.0177238   -0.100198    -0.0627993
 -0.296053   -0.128232    0.309975    0.458474    -0.0711842   0.434509     0.134337    0.217277     -0.0997186  -0.344821   -0.239955    0.282012     0.0533916    0.0455493  -1.06477     -0.501133   -0.198739     0.604736   -0.150434   -0.486746     1.06845     0.12335    -0.233485    0.0391996   -0.162251     0.259113[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408908
[ Info: iteration 2, average log likelihood -1.408898
[ Info: iteration 3, average log likelihood -1.408889
[ Info: iteration 4, average log likelihood -1.408880
[ Info: iteration 5, average log likelihood -1.408872
[ Info: iteration 6, average log likelihood -1.408864
[ Info: iteration 7, average log likelihood -1.408856
[ Info: iteration 8, average log likelihood -1.408849
[ Info: iteration 9, average log likelihood -1.408841
[ Info: iteration 10, average log likelihood -1.408834
┌ Info: EM with 100000 data points 10 iterations avll -1.408834
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
