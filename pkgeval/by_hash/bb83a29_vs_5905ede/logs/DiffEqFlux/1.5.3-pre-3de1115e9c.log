Current time is 2020-10-25T21:55:27.605
Julia Version 1.5.3-pre.13
Commit 3de1115e9c (2020-10-23 21:58 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: AMD EPYC 7502 32-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, znver2)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2
  JULIA_MAX_NUM_PRECOMPILE_FILES = 9223372036854775807
  JULIA_PKG_SERVER = 

Starting installation at 2020-10-25T21:55:31.037
  Resolving package versions...
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed Rmath_jll ──────────────────── v0.2.2+1
  Installed FunctionWrappers ───────────── v1.1.1
  Installed Roots ──────────────────────── v1.0.5
  Installed Requires ───────────────────── v1.1.0
  Installed LatticeRules ───────────────── v0.0.1
  Installed IRTools ────────────────────── v0.4.1
  Installed DiffEqFlux ─────────────────── v1.24.0
  Installed Zlib_jll ───────────────────── v1.2.11+18
  Installed StatsFuns ──────────────────── v0.9.5
  Installed RecipesBase ────────────────── v1.1.0
  Installed FiniteDifferences ──────────── v0.11.2
  Installed NNlib ──────────────────────── v0.7.5
  Installed DiffEqCallbacks ────────────── v2.14.1
  Installed ArrayLayouts ───────────────── v0.4.10
  Installed CodecZlib ──────────────────── v0.7.0
  Installed ArrayInterface ─────────────── v2.13.6
  Installed Distances ──────────────────── v0.9.2
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed LoggingExtras ──────────────── v0.4.2
  Installed Distributions ──────────────── v0.23.12
  Installed PositiveFactorizations ─────── v0.2.3
  Installed CEnum ──────────────────────── v0.4.1
  Installed Compat ─────────────────────── v3.22.0
  Installed RandomNumbers ──────────────── v1.4.0
  Installed Optim ──────────────────────── v1.2.0
  Installed LightGraphs ────────────────── v1.3.0
  Installed TreeViews ──────────────────── v0.3.0
  Installed CPUTime ────────────────────── v1.0.0
  Installed CpuId ──────────────────────── v0.2.2
  Installed OpenSpecFun_jll ────────────── v0.5.3+4
  Installed MuladdMacro ────────────────── v0.2.2
  Installed LoopVectorization ──────────── v0.8.26
  Installed JLLWrappers ────────────────── v1.1.3
  Installed ChainRules ─────────────────── v0.7.31
  Installed CUDA ───────────────────────── v1.3.3
  Installed VertexSafeGraphs ───────────── v0.1.2
  Installed CommonSubexpressions ───────── v0.3.0
  Installed ChainRulesTestUtils ────────── v0.5.3
  Installed GPUArrays ──────────────────── v5.2.1
  Installed ForwardDiff ────────────────── v0.10.12
  Installed CompilerSupportLibraries_jll ─ v0.3.4+0
  Installed DiffResults ────────────────── v1.0.2
  Installed Tracker ────────────────────── v0.2.12
  Installed FixedPointNumbers ──────────── v0.8.4
  Installed Media ──────────────────────── v0.5.0
  Installed VectorizationBase ──────────── v0.12.33
  Installed FFTW_jll ───────────────────── v3.3.9+6
  Installed ReverseDiff ────────────────── v1.4.3
  Installed SortingAlgorithms ──────────── v0.3.1
  Installed MacroTools ─────────────────── v0.5.6
  Installed GPUCompiler ────────────────── v0.6.1
  Installed PoissonRandom ──────────────── v0.4.0
  Installed ExprTools ──────────────────── v0.1.3
  Installed DiffEqNoiseProcess ─────────── v5.4.0
  Installed IterativeSolvers ───────────── v0.8.4
  Installed UnPack ─────────────────────── v1.0.2
  Installed OrderedCollections ─────────── v1.3.1
  Installed AbstractTrees ──────────────── v0.3.3
  Installed ConsoleProgressMonitor ─────── v0.1.2
  Installed SpecialFunctions ───────────── v0.10.3
  Installed DiffEqSensitivity ──────────── v6.33.0
  Installed TimerOutputs ───────────────── v0.5.6
  Installed TranscodingStreams ─────────── v0.9.5
  Installed ChainRulesCore ─────────────── v0.9.17
  Installed LabelledArrays ─────────────── v1.3.0
  Installed DiffRules ──────────────────── v1.0.1
  Installed DataStructures ─────────────── v0.18.8
  Installed Rmath ──────────────────────── v0.6.1
  Installed IteratorInterfaceExtensions ── v1.0.0
  Installed ResettableStacks ───────────── v1.0.0
  Installed StochasticDiffEq ───────────── v6.26.0
  Installed LLVM ───────────────────────── v2.0.0
  Installed Richardson ─────────────────── v1.2.0
  Installed QuasiMonteCarlo ────────────── v0.2.1
  Installed Juno ───────────────────────── v0.8.4
  Installed DataValueInterfaces ────────── v1.0.0
  Installed FastClosures ───────────────── v0.3.2
  Installed SimpleTraits ───────────────── v0.9.3
  Installed PDMats ─────────────────────── v0.10.1
  Installed ExponentialUtilities ───────── v1.8.0
  Installed Sobol ──────────────────────── v1.4.0
  Installed Parameters ─────────────────── v0.12.1
  Installed ZipFile ────────────────────── v0.9.3
  Installed RecursiveFactorization ─────── v0.1.4
  Installed OrdinaryDiffEq ─────────────── v5.43.0
  Installed Zygote ─────────────────────── v0.5.9
  Installed FiniteDiff ─────────────────── v2.7.0
  Installed ColorTypes ─────────────────── v0.10.9
  Installed GalacticOptim ──────────────── v0.3.1
  Installed ProgressLogging ────────────── v0.1.3
  Installed SIMDPirates ────────────────── v0.8.25
  Installed SLEEFPirates ───────────────── v0.5.5
  Installed Tables ─────────────────────── v1.1.0
  Installed LeftChildRightSiblingTrees ─── v0.1.2
  Installed Inflate ────────────────────── v0.1.2
  Installed SparseDiffTools ────────────── v1.10.0
  Installed DocStringExtensions ────────── v0.8.3
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed LineSearches ───────────────── v7.1.0
  Installed Reexport ───────────────────── v0.2.0
  Installed StaticArrays ───────────────── v0.12.4
  Installed TableTraits ────────────────── v1.0.0
  Installed DiffEqJump ─────────────────── v6.10.1
  Installed NaNMath ────────────────────── v0.3.4
  Installed GenericSVD ─────────────────── v0.3.0
  Installed NLSolversBase ──────────────── v7.7.1
  Installed QuadGK ─────────────────────── v2.4.1
  Installed Missings ───────────────────── v0.4.4
  Installed StatsBase ──────────────────── v0.33.2
  Installed ZygoteRules ────────────────── v0.2.0
  Installed RecursiveArrayTools ────────── v2.7.2
  Installed FFTW ───────────────────────── v1.2.4
  Installed ProgressMeter ──────────────── v1.4.0
  Installed Artifacts ──────────────────── v1.3.0
  Installed TerminalLoggers ────────────── v0.1.2
  Installed DiffEqBase ─────────────────── v6.48.2
  Installed NLsolve ────────────────────── v4.4.1
  Installed FillArrays ─────────────────── v0.9.7
  Installed Functors ───────────────────── v0.1.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed Flux ───────────────────────── v0.11.1
  Installed ArnoldiMethod ──────────────── v0.0.4
  Installed DataAPI ────────────────────── v1.3.0
  Installed Colors ─────────────────────── v0.12.4
  Installed Adapt ──────────────────────── v2.3.0
  Installed OffsetArrays ───────────────── v1.3.1
  Installed DistributionsAD ────────────── v0.6.9
  Installed SpatialIndexing ────────────── v0.1.2
  Installed BlackBoxOptim ──────────────── v0.5.0
  Installed LatinHypercubeSampling ─────── v1.6.4
Updating `~/.julia/environments/v1.5/Project.toml`
  [aae7a2af] + DiffEqFlux v1.24.0
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [1520ce14] + AbstractTrees v0.3.3
  [79e6a3ab] + Adapt v2.3.0
  [ec485272] + ArnoldiMethod v0.0.4
  [4fba245c] + ArrayInterface v2.13.6
  [4c555306] + ArrayLayouts v0.4.10
  [56f22d72] + Artifacts v1.3.0
  [b99e7846] + BinaryProvider v0.5.10
  [a134a8b2] + BlackBoxOptim v0.5.0
  [fa961155] + CEnum v0.4.1
  [a9c8d775] + CPUTime v1.0.0
  [052768ef] + CUDA v1.3.3
  [082447d4] + ChainRules v0.7.31
  [d360d2e6] + ChainRulesCore v0.9.17
  [cdddcdb0] + ChainRulesTestUtils v0.5.3
  [944b1d66] + CodecZlib v0.7.0
  [3da002f7] + ColorTypes v0.10.9
  [5ae59095] + Colors v0.12.4
  [bbf7d656] + CommonSubexpressions v0.3.0
  [34da2185] + Compat v3.22.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.4+0
  [88cd18e8] + ConsoleProgressMonitor v0.1.2
  [adafc99b] + CpuId v0.2.2
  [9a962f9c] + DataAPI v1.3.0
  [864edb3b] + DataStructures v0.18.8
  [e2d170a0] + DataValueInterfaces v1.0.0
  [2b5f629d] + DiffEqBase v6.48.2
  [459566f4] + DiffEqCallbacks v2.14.1
  [aae7a2af] + DiffEqFlux v1.24.0
  [c894b116] + DiffEqJump v6.10.1
  [77a26b50] + DiffEqNoiseProcess v5.4.0
  [41bf760c] + DiffEqSensitivity v6.33.0
  [163ba53b] + DiffResults v1.0.2
  [b552c78f] + DiffRules v1.0.1
  [b4f34e82] + Distances v0.9.2
  [31c24e10] + Distributions v0.23.12
  [ced4e74d] + DistributionsAD v0.6.9
  [ffbed154] + DocStringExtensions v0.8.3
  [d4d017d3] + ExponentialUtilities v1.8.0
  [e2ba6199] + ExprTools v0.1.3
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+6
  [9aa1b823] + FastClosures v0.3.2
  [1a297f60] + FillArrays v0.9.7
  [6a86dc24] + FiniteDiff v2.7.0
  [26cc04aa] + FiniteDifferences v0.11.2
  [53c48c17] + FixedPointNumbers v0.8.4
  [587475ba] + Flux v0.11.1
  [f6369f11] + ForwardDiff v0.10.12
  [069b7b12] + FunctionWrappers v1.1.1
  [d9f16b24] + Functors v0.1.0
  [0c68f7d7] + GPUArrays v5.2.1
  [61eb1bfa] + GPUCompiler v0.6.1
  [a75be94c] + GalacticOptim v0.3.1
  [01680d73] + GenericSVD v0.3.0
  [7869d1d1] + IRTools v0.4.1
  [d25df0c9] + Inflate v0.1.2
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [42fd0dbc] + IterativeSolvers v0.8.4
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [692b3bcd] + JLLWrappers v1.1.3
  [e5e0dc1b] + Juno v0.8.4
  [929cbde3] + LLVM v2.0.0
  [2ee39098] + LabelledArrays v1.3.0
  [a5e1c1ea] + LatinHypercubeSampling v1.6.4
  [73f95e8e] + LatticeRules v0.0.1
  [1d6d02ad] + LeftChildRightSiblingTrees v0.1.2
  [093fc24a] + LightGraphs v1.3.0
  [d3d80556] + LineSearches v7.1.0
  [e6f89c97] + LoggingExtras v0.4.2
  [bdcacae8] + LoopVectorization v0.8.26
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.6
  [e89f7d12] + Media v0.5.0
  [e1d29d7a] + Missings v0.4.4
  [46d2c3a1] + MuladdMacro v0.2.2
  [d41bc354] + NLSolversBase v7.7.1
  [2774e3e8] + NLsolve v4.4.1
  [872c559c] + NNlib v0.7.5
  [77ba4419] + NaNMath v0.3.4
  [6fe1bfb0] + OffsetArrays v1.3.1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+4
  [429524aa] + Optim v1.2.0
  [bac558e1] + OrderedCollections v1.3.1
  [1dea7af3] + OrdinaryDiffEq v5.43.0
  [90014a1f] + PDMats v0.10.1
  [d96e819e] + Parameters v0.12.1
  [e409e4f3] + PoissonRandom v0.4.0
  [85a6dd25] + PositiveFactorizations v0.2.3
  [33c8b6b6] + ProgressLogging v0.1.3
  [92933f4c] + ProgressMeter v1.4.0
  [1fd47b50] + QuadGK v2.4.1
  [8a4e6c94] + QuasiMonteCarlo v0.2.1
  [e6cf234a] + RandomNumbers v1.4.0
  [3cdcf5f2] + RecipesBase v1.1.0
  [731186ca] + RecursiveArrayTools v2.7.2
  [f2c3362d] + RecursiveFactorization v0.1.4
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.1.0
  [ae5879a3] + ResettableStacks v1.0.0
  [37e2e3b7] + ReverseDiff v1.4.3
  [708f8203] + Richardson v1.2.0
  [79098fc4] + Rmath v0.6.1
  [f50d1b31] + Rmath_jll v0.2.2+1
  [f2b01f46] + Roots v1.0.5
  [21efa798] + SIMDPirates v0.8.25
  [476501e8] + SLEEFPirates v0.5.5
  [699a6c99] + SimpleTraits v0.9.3
  [ed01d8cd] + Sobol v1.4.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [47a9eef4] + SparseDiffTools v1.10.0
  [d4ead438] + SpatialIndexing v0.1.2
  [276daf66] + SpecialFunctions v0.10.3
  [90137ffa] + StaticArrays v0.12.4
  [2913bbd2] + StatsBase v0.33.2
  [4c63d2b9] + StatsFuns v0.9.5
  [789caeaf] + StochasticDiffEq v6.26.0
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v1.1.0
  [5d786b92] + TerminalLoggers v0.1.2
  [a759f4b9] + TimerOutputs v0.5.6
  [9f7883ad] + Tracker v0.2.12
  [3bb67fe8] + TranscodingStreams v0.9.5
  [a2a6695c] + TreeViews v0.3.0
  [3a884ed6] + UnPack v1.0.2
  [3d5dd08c] + VectorizationBase v0.12.33
  [19fa3120] + VertexSafeGraphs v0.1.2
  [a5390f91] + ZipFile v0.9.3
  [83775a58] + Zlib_jll v1.2.11+18
  [e88e6eb3] + Zygote v0.5.9
  [700de1a5] + ZygoteRules v0.2.0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [9fa8497b] + Future
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [9abbd945] + Profile
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [4607b0f0] + SuiteSparse
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building SLEEFPirates → `~/.julia/packages/SLEEFPirates/jGsib/deps/build.log`
   Building FFTW ────────→ `~/.julia/packages/FFTW/DMUbN/deps/build.log`
Starting tests at 2020-10-25T21:56:01.068
    Testing DiffEqFlux
Status `/tmp/jl_CtiKIX/Project.toml`
  [79e6a3ab] Adapt v2.3.0
  [a134a8b2] BlackBoxOptim v0.5.0
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [82cc6244] DataInterpolations v3.2.1
  [bcd4f6db] DelayDiffEq v5.25.1
  [2b5f629d] DiffEqBase v6.48.2
  [459566f4] DiffEqCallbacks v2.14.1
  [aae7a2af] DiffEqFlux v1.24.0
  [41bf760c] DiffEqSensitivity v6.33.0
  [163ba53b] DiffResults v1.0.2
  [b4f34e82] Distances v0.9.2
  [31c24e10] Distributions v0.23.12
  [ced4e74d] DistributionsAD v0.6.9
  [587475ba] Flux v0.11.1
  [f6369f11] ForwardDiff v0.10.12
  [a75be94c] GalacticOptim v0.3.1
  [7e08b658] GeometricFlux v0.7.2
  [e6f89c97] LoggingExtras v0.4.2
  [76087f3c] NLopt v0.6.1
  [429524aa] Optim v1.2.0
  [1dea7af3] OrdinaryDiffEq v5.43.0
  [33c8b6b6] ProgressLogging v0.1.3
  [731186ca] RecursiveArrayTools v2.7.2
  [ae029012] Requires v1.1.0
  [37e2e3b7] ReverseDiff v1.4.3
  [1bc83da4] SafeTestsets v0.0.1
  [90137ffa] StaticArrays v0.12.4
  [789caeaf] StochasticDiffEq v6.26.0
  [5d786b92] TerminalLoggers v0.1.2
  [9f7883ad] Tracker v0.2.12
  [e88e6eb3] Zygote v0.5.9
  [700de1a5] ZygoteRules v0.2.0
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_CtiKIX/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [1520ce14] AbstractTrees v0.3.3
  [79e6a3ab] Adapt v2.3.0
  [ec485272] ArnoldiMethod v0.0.4
  [4fba245c] ArrayInterface v2.13.6
  [4c555306] ArrayLayouts v0.4.10
  [56f22d72] Artifacts v1.3.0
  [6e4b80f9] BenchmarkTools v0.5.0
  [b99e7846] BinaryProvider v0.5.10
  [a134a8b2] BlackBoxOptim v0.5.0
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [6e34b625] Bzip2_jll v1.0.6+5
  [fa961155] CEnum v0.4.1
  [a9c8d775] CPUTime v1.0.0
  [336ed68f] CSV v0.7.7
  [052768ef] CUDA v1.3.3
  [324d7699] CategoricalArrays v0.8.3
  [082447d4] ChainRules v0.7.31
  [d360d2e6] ChainRulesCore v0.9.17
  [cdddcdb0] ChainRulesTestUtils v0.5.3
  [523fee87] CodecBzip2 v0.7.2
  [944b1d66] CodecZlib v0.7.0
  [3da002f7] ColorTypes v0.10.9
  [5ae59095] Colors v0.12.4
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.22.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.4+0
  [8f4d0f93] Conda v1.4.1
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [adafc99b] CpuId v0.2.2
  [9a962f9c] DataAPI v1.3.0
  [124859b0] DataDeps v0.7.2
  [a93c6f00] DataFrames v0.21.8
  [82cc6244] DataInterpolations v3.2.1
  [864edb3b] DataStructures v0.18.8
  [e2d170a0] DataValueInterfaces v1.0.0
  [bcd4f6db] DelayDiffEq v5.25.1
  [2b5f629d] DiffEqBase v6.48.2
  [459566f4] DiffEqCallbacks v2.14.1
  [aae7a2af] DiffEqFlux v1.24.0
  [c894b116] DiffEqJump v6.10.1
  [77a26b50] DiffEqNoiseProcess v5.4.0
  [41bf760c] DiffEqSensitivity v6.33.0
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [b4f34e82] Distances v0.9.2
  [31c24e10] Distributions v0.23.12
  [ced4e74d] DistributionsAD v0.6.9
  [ffbed154] DocStringExtensions v0.8.3
  [d4d017d3] ExponentialUtilities v1.8.0
  [e2ba6199] ExprTools v0.1.3
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+6
  [9aa1b823] FastClosures v0.3.2
  [1a297f60] FillArrays v0.9.7
  [6a86dc24] FiniteDiff v2.7.0
  [26cc04aa] FiniteDifferences v0.11.2
  [53c48c17] FixedPointNumbers v0.8.4
  [587475ba] Flux v0.11.1
  [f6369f11] ForwardDiff v0.10.12
  [069b7b12] FunctionWrappers v1.1.1
  [d9f16b24] Functors v0.1.0
  [0c68f7d7] GPUArrays v5.2.1
  [61eb1bfa] GPUCompiler v0.6.1
  [a75be94c] GalacticOptim v0.3.1
  [01680d73] GenericSVD v0.3.0
  [7e08b658] GeometricFlux v0.7.2
  [a1251efa] GraphLaplacians v0.1.0
  [21828b05] GraphMLDatasets v0.1.1
  [3ebe565e] GraphSignals v0.1.5
  [f67ccb44] HDF5 v0.13.6
  [0234f1f7] HDF5_jll v1.10.5+6
  [cd3eb016] HTTP v0.8.19
  [7869d1d1] IRTools v0.4.1
  [d25df0c9] Inflate v0.1.2
  [83e8ac13] IniFile v0.5.0
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [41ab1584] InvertedIndices v1.0.0
  [42fd0dbc] IterativeSolvers v0.8.4
  [82899510] IteratorInterfaceExtensions v1.0.0
  [033835bb] JLD2 v0.2.4
  [692b3bcd] JLLWrappers v1.1.3
  [682c06a0] JSON v0.21.1
  [7d188eb4] JSONSchema v0.3.2
  [e5e0dc1b] Juno v0.8.4
  [929cbde3] LLVM v2.0.0
  [2ee39098] LabelledArrays v1.3.0
  [a5e1c1ea] LatinHypercubeSampling v1.6.4
  [73f95e8e] LatticeRules v0.0.1
  [1d6d02ad] LeftChildRightSiblingTrees v0.1.2
  [093fc24a] LightGraphs v1.3.0
  [d3d80556] LineSearches v7.1.0
  [e6f89c97] LoggingExtras v0.4.2
  [bdcacae8] LoopVectorization v0.8.26
  [5ced341a] Lz4_jll v1.9.2+2
  [23992714] MAT v0.8.1
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.6
  [b8f27783] MathOptInterface v0.9.17
  [fdba3010] MathProgBase v0.7.8
  [739be429] MbedTLS v1.0.2
  [c8ffd9c3] MbedTLS_jll v2.16.8+0
  [e89f7d12] Media v0.5.0
  [626554b9] MetaGraphs v0.6.6
  [e1d29d7a] Missings v0.4.4
  [46d2c3a1] MuladdMacro v0.2.2
  [d8a4904e] MutableArithmetics v0.2.10
  [d41bc354] NLSolversBase v7.7.1
  [76087f3c] NLopt v0.6.1
  [079eb43e] NLopt_jll v2.6.2+0
  [2774e3e8] NLsolve v4.4.1
  [872c559c] NNlib v0.7.5
  [77ba4419] NaNMath v0.3.4
  [6fe1bfb0] OffsetArrays v1.3.1
  [efe28fd5] OpenSpecFun_jll v0.5.3+4
  [429524aa] Optim v1.2.0
  [bac558e1] OrderedCollections v1.3.1
  [1dea7af3] OrdinaryDiffEq v5.43.0
  [90014a1f] PDMats v0.10.1
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.11
  [e409e4f3] PoissonRandom v0.4.0
  [2dfb63ee] PooledArrays v0.5.3
  [85a6dd25] PositiveFactorizations v0.2.3
  [33c8b6b6] ProgressLogging v0.1.3
  [92933f4c] ProgressMeter v1.4.0
  [438e738f] PyCall v1.92.1
  [1fd47b50] QuadGK v2.4.1
  [8a4e6c94] QuasiMonteCarlo v0.2.1
  [e6cf234a] RandomNumbers v1.4.0
  [3cdcf5f2] RecipesBase v1.1.0
  [731186ca] RecursiveArrayTools v2.7.2
  [f2c3362d] RecursiveFactorization v0.1.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.1.0
  [ae5879a3] ResettableStacks v1.0.0
  [37e2e3b7] ReverseDiff v1.4.3
  [708f8203] Richardson v1.2.0
  [79098fc4] Rmath v0.6.1
  [f50d1b31] Rmath_jll v0.2.2+1
  [f2b01f46] Roots v1.0.5
  [21efa798] SIMDPirates v0.8.25
  [476501e8] SLEEFPirates v0.5.5
  [1bc83da4] SafeTestsets v0.0.1
  [b1168b60] ScatterNNlib v0.1.3
  [91c51154] SentinelArrays v1.2.16
  [699a6c99] SimpleTraits v0.9.3
  [47aef6b3] SimpleWeightedGraphs v1.1.1
  [ed01d8cd] Sobol v1.4.0
  [a2af1166] SortingAlgorithms v0.3.1
  [47a9eef4] SparseDiffTools v1.10.0
  [d4ead438] SpatialIndexing v0.1.2
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.2
  [4c63d2b9] StatsFuns v0.9.5
  [789caeaf] StochasticDiffEq v6.26.0
  [856f2bd8] StructTypes v1.1.0
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v1.1.0
  [5d786b92] TerminalLoggers v0.1.2
  [a759f4b9] TimerOutputs v0.5.6
  [9f7883ad] Tracker v0.2.12
  [3bb67fe8] TranscodingStreams v0.9.5
  [a2a6695c] TreeViews v0.3.0
  [3a884ed6] UnPack v1.0.2
  [3d5dd08c] VectorizationBase v0.12.33
  [81def892] VersionParsing v1.2.0
  [19fa3120] VertexSafeGraphs v0.1.2
  [a5390f91] ZipFile v0.9.3
  [83775a58] Zlib_jll v1.2.11+18
  [3161d3a3] Zstd_jll v1.4.5+2
  [e88e6eb3] Zygote v0.5.9
  [700de1a5] ZygoteRules v0.2.0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [9abbd945] Profile
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [4607b0f0] SuiteSparse
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
Starting tests
416.7086995514811301.86465432569827213.21697213391016149.3929796071194115.2247517913104296.3438136311290279.3936123278511765.5625775751988754.73408970504229446.2626159904189439.55562467607837434.29338639796445430.54262397471921328.93102825992030330.78230280655101637.5616921386252547.3899178101139352.31771747076819448.8559023431533241.1409918445188933.4998573173513127.7136171838481823.8213532431337521.2574969683678819.43364473086034417.9080234863235616.40169427585258414.75827680393393112.9155083938401710.8813206837866058.7182734287630626.5317427624672214.45717155975515762.6440088213855261.23592071815229730.34657206429314730.032376452495214510.26367482940779230.905567097641851.72975726545156162.4738072183786732.93352765725007243.03618679634409672.84498125290393672.49864919108605132.1348949032518721.84171784634708581.64735382952383951.53548374223780541.46787860302471571.40348733006078131.31057624087927451.1723646987133380.98792068128521930.77000396330597080.54099857867771020.327773302321376360.156017818275280080.0445653704883056740.00091322139101779030.0190239786206280320.080410475436539270.159197271761418070.229589835455646730.27324885152407110.28364198270243850.26573545746272670.231707259387955280.195075966066423880.16585180213779310.148215404734272720.140797690163480650.13867239213660060.135911948945067140.127791420961522520.112133203758811030.089657382441687130.063454110359997350.037871264121909730.017167018654110830.0042911560636956050.000132331621225468740.0034254726393664930.0112719546828020260.020185633126746330.027176635651557520.0305475552150724330.0301433293399415230.027042574606087690.0228944748810245740.0192068480124802340.0168492892211720180.0158974341901012840.0157962049318957630.0157121461393411320.0149121397453862370.013034469259305310.0101844853779321530.0068527418229991870.00371107376408517140.41651472333630622.0574979950004412.0370170061059436.5135123950745713.44931932189921181.7559468701164440.84093619554414190.37442507954085170.168532382317527320.113993033837653730.146123430878245250.226085903016524930.330334854476624140.44453607046360510.55999043965512660.67148965890465460.77600896170330960.87189794211576280.95837284804221071.03519453504103541.102462468119151.1604809403635251.2096740246675781.2505296827649941.28356389938792611.3092977792750041.3282432671420641.3408945567685451.3477231917904121.34917568299961181.34567275651153921.33760965969436761.32535713923978181.30926283119076661.28965288718113881.26683371815545651.24109377565182391.21270532363075211.18192615543916561.14900120277133591.11416408494757111.0776385384441541.03963972907575551.00037545475925030.96004716055324730.91885085925083050.87697796780162950.83461578453768470.79194791465576250.7491546092974780.70641292726443780.66389667527127090.62177597710401310.58021695098207630.53938109283327550.49942448098243830.46049683701543230.422740446135237870.386288958824478560.351266106102598450.31778436152719740.28594358960323430.25582972628403930.227513541949103480.20104954040439650.17647504822376870.153809547487706370.133054301003206670.11419231258130050.097188655030507010.081991185732421780.068531653945972460.056727195199598220.0464821741737222950.037690330900355420.0302371660240337120.024002485214972780.018863008126808380.0146949697216094770.011376587915764770.008790320506736630.0068248311695943480.0053766232540579290.0043512582546466540.0036641684658992570.003241059631909680.00301792543950275570.00294072194226196620.0029647594934878470.00305388071927276130.00317949724857487840.0033195565264025470.0034575035527390830.00358129205678411840.0036824867525255790.0037554842797734490.00379686650199046730.0038048872648166380.00377908325254354550.003719992014970818416.70869955148316301.87186997430365213.22801705361297149.40648614478837115.2240412249364696.3454391345538679.3977976779125865.5678714713974554.73969630607274446.2681431647925939.5608383606454234.2980229596167530.54633410011867428.9332381463373130.78208250143966437.5587566610162847.3870414634704752.3184906512701248.8589544323429841.14383255919601433.5012140860317727.71329342894746323.81952936942857221.2543767187669819.4294856183711817.90303100693667616.39608500849614714.75230897079328312.90945584534311610.8754625577971288.712882525457966.5270686024001344.4534149599774862.6412962392444671.2342795663056390.3459158046638280.032506748634095760.264310414146053160.90639787468961761.7305156642179892.4743407762289472.9338239544033673.0363286740031682.84506488225275162.49872238818174442.13494430274363721.8416920826943291.6471951659831451.53515198186780831.46736343542057451.40280885504569251.30977827422533061.1715059590677530.98706641658549010.76921762520158130.54033333964074280.32726603243509670.155685347538229820.044402053227207340.00089265358725995560.0191039242369983630.080534769824929170.159307303717266780.229641600525029880.273224851436197740.283552996888048250.26561206968046450.23158584804701470.194985613398158870.165806707487119760.14821387238102470.140826097601411540.13871147379454670.135943057155115480.12780127946737040.112116466759106760.089616889144780110.063399129505176940.037814459743258160.017120978004210560.00426522788223897450.00013060182132885350.00344585479851722280.011306698777051870.0202248123961467770.02721155913652230.0305730930624841660.030158440940405340.027049241017987240.022895782224433470.0192051454721658860.016845112348903880.0158894783750984330.015782221974403340.015690315650227170.0148822708785586060.0129985681020147110.0101464819170533940.0068175358724189420.003683289147449469Test Summary: | Pass  Total
Layers Tests  |    6      6
Test Summary: | Pass  Total
Fast Layers   |    9      9
Training   0%|                                          |  ETA: N/A
494.2089032199091loss: 494   1%|▍                                        |  ETA: 0:03:19
416.7086995514831loss: 417   2%|▉                                        |  ETA: 0:01:45
301.87186997430365loss: 302   3%|█▎                                       |  ETA: 0:01:10
213.22801705361297loss: 213   4%|█▋                                       |  ETA: 0:00:52
149.40648614478843loss: 149   5%|██                                       |  ETA: 0:00:41
115.22404122493646loss: 115   6%|██▌                                      |  ETA: 0:00:34
96.34543913455384loss: 96.3   7%|██▊                                     |  ETA: 0:00:29
79.39779767791259loss: 79.4   8%|███▎                                    |  ETA: 0:00:26
65.56787147139745loss: 65.6   9%|███▋                                    |  ETA: 0:00:23
54.739696306072744loss: 54.7  10%|████                                    |  ETA: 0:00:20
46.26814316479258loss: 46.3  11%|████▍                                   |  ETA: 0:00:18
39.560838360645405loss: 39.6  12%|████▊                                   |  ETA: 0:00:17
34.298022959616745loss: 34.3  13%|█████▎                                  |  ETA: 0:00:15
30.54633410011867loss: 30.5  14%|█████▋                                  |  ETA: 0:00:14
28.933238146337313loss: 28.9  15%|██████                                  |  ETA: 0:00:13
30.78208250143967loss: 30.8  16%|██████▍                                 |  ETA: 0:00:12
37.55875666101628loss: 37.6  17%|██████▊                                 |  ETA: 0:00:11
47.38704146347047loss: 47.4  18%|███████▎                                |  ETA: 0:00:11
52.318490651270146loss: 52.3  19%|███████▋                                |  ETA: 0:00:10
48.85895443234298loss: 48.9  20%|████████                                |  ETA: 0:00:10
41.143832559196loss: 41.1  21%|████████▍                               |  ETA: 0:00:09
33.50121408603177loss: 33.5  22%|████████▊                               |  ETA: 0:00:09
27.713293428947466loss: 27.7  23%|█████████▎                              |  ETA: 0:00:08
23.819529369428558loss: 23.8  24%|█████████▋                              |  ETA: 0:00:08
21.254376718766984loss: 21.3  25%|██████████                              |  ETA: 0:00:07
19.42948561837119loss: 19.4  26%|██████████▍                             |  ETA: 0:00:07
17.90303100693668loss: 17.9  27%|██████████▊                             |  ETA: 0:00:07
16.396085008496147loss: 16.4  28%|███████████▎                            |  ETA: 0:00:06
14.752308970793283loss: 14.8  29%|███████████▋                            |  ETA: 0:00:06
12.909455845343116loss: 12.9  30%|████████████                            |  ETA: 0:00:06
10.875462557797128loss: 10.9  31%|████████████▍                           |  ETA: 0:00:06
8.71288252545796loss: 8.71  32%|████████████▊                           |  ETA: 0:00:06
6.527068602400136loss: 6.53  33%|█████████████▎                          |  ETA: 0:00:05
4.4534149599774855loss: 4.45  34%|█████████████▋                          |  ETA: 0:00:05
2.6412962392444665loss: 2.64  35%|██████████████                          |  ETA: 0:00:05
1.2342795663056394loss: 1.23  36%|██████████████▍                         |  ETA: 0:00:05
0.34591580466382804loss: 0.346  37%|██████████████▍                        |  ETA: 0:00:05
0.03250674863409575loss: 0.0325  38%|██████████████▌                       |  ETA: 0:00:04
0.2643104141460533loss: 0.264  39%|███████████████▎                       |  ETA: 0:00:04
0.9063978746896175loss: 0.906  40%|███████████████▋                       |  ETA: 0:00:04
1.7305156642179889loss: 1.73  41%|████████████████▍                       |  ETA: 0:00:04
2.474340776228947loss: 2.47  42%|████████████████▊                       |  ETA: 0:00:04
2.933823954403367loss: 2.93  43%|█████████████████▎                      |  ETA: 0:00:04
3.036328674003168loss: 3.04  44%|█████████████████▋                      |  ETA: 0:00:04
2.845064882252751loss: 2.85  45%|██████████████████                      |  ETA: 0:00:03
2.498722388181745loss: 2.5  46%|██████████████████▉                      |  ETA: 0:00:03
2.1349443027436377loss: 2.13  47%|██████████████████▊                     |  ETA: 0:00:03
1.8416920826943293loss: 1.84  48%|███████████████████▎                    |  ETA: 0:00:03
1.647195165983145loss: 1.65  49%|███████████████████▋                    |  ETA: 0:00:03
1.5351519818678083loss: 1.54  50%|████████████████████                    |  ETA: 0:00:03
1.467363435420574loss: 1.47  51%|████████████████████▍                   |  ETA: 0:00:03
1.402808855045693loss: 1.4  52%|█████████████████████▍                   |  ETA: 0:00:03
1.3097782742253306loss: 1.31  53%|█████████████████████▎                  |  ETA: 0:00:03
1.171505959067753loss: 1.17  54%|█████████████████████▋                  |  ETA: 0:00:02
0.9870664165854897loss: 0.987  55%|█████████████████████▌                 |  ETA: 0:00:02
0.7692176252015813loss: 0.769  56%|█████████████████████▉                 |  ETA: 0:00:02
0.5403333396407428loss: 0.54  57%|██████████████████████▊                 |  ETA: 0:00:02
0.3272660324350968loss: 0.327  58%|██████████████████████▋                |  ETA: 0:00:02
0.1556853475382298loss: 0.156  59%|███████████████████████                |  ETA: 0:00:02
0.04440205322720733loss: 0.0444  60%|██████████████████████▊               |  ETA: 0:00:02
0.0008926535872599556loss: 0.000893  61%|██████████████████████              |  ETA: 0:00:02
0.019103924236998377loss: 0.0191  62%|███████████████████████▌              |  ETA: 0:00:02
0.08053476982492919loss: 0.0805  63%|████████████████████████              |  ETA: 0:00:02
0.15930730371726676loss: 0.159  64%|█████████████████████████              |  ETA: 0:00:02
0.22964160052502988loss: 0.23  65%|██████████████████████████              |  ETA: 0:00:02
0.2732248514361978loss: 0.273  66%|█████████████████████████▊             |  ETA: 0:00:02
0.2835529968880482loss: 0.284  67%|██████████████████████████▏            |  ETA: 0:00:02
0.2656120696804645loss: 0.266  68%|██████████████████████████▌            |  ETA: 0:00:01
0.23158584804701468loss: 0.232  69%|██████████████████████████▉            |  ETA: 0:00:01
0.19498561339815892loss: 0.195  70%|███████████████████████████▎           |  ETA: 0:00:01
0.1658067074871198loss: 0.166  71%|███████████████████████████▊           |  ETA: 0:00:01
0.14821387238102476loss: 0.148  72%|████████████████████████████▏          |  ETA: 0:00:01
0.14082609760141152loss: 0.141  73%|████████████████████████████▌          |  ETA: 0:00:01
0.13871147379454676loss: 0.139  74%|████████████████████████████▉          |  ETA: 0:00:01
0.13594305715511545loss: 0.136  75%|█████████████████████████████▎         |  ETA: 0:00:01
0.1278012794673704loss: 0.128  76%|█████████████████████████████▋         |  ETA: 0:00:01
0.11211646675910676loss: 0.112  77%|██████████████████████████████         |  ETA: 0:00:01
0.0896168891447801loss: 0.0896  78%|█████████████████████████████▋        |  ETA: 0:00:01
0.06339912950517693loss: 0.0634  79%|██████████████████████████████        |  ETA: 0:00:01
0.03781445974325816loss: 0.0378  80%|██████████████████████████████▍       |  ETA: 0:00:01
0.017120978004210557loss: 0.0171  81%|██████████████████████████████▊       |  ETA: 0:00:01
0.004265227882238975loss: 0.00427  82%|██████████████████████████████▍      |  ETA: 0:00:01
0.00013060182132885353loss: 0.000131  83%|█████████████████████████████▉      |  ETA: 0:00:01
0.0034458547985172228loss: 0.00345  84%|███████████████████████████████▏     |  ETA: 0:00:01
0.01130669877705187loss: 0.0113  85%|████████████████████████████████▎     |  ETA: 0:00:01
0.020224812396146763loss: 0.0202  86%|████████████████████████████████▋     |  ETA: 0:00:01
0.0272115591365223loss: 0.0272  87%|█████████████████████████████████     |  ETA: 0:00:01
0.030573093062484166loss: 0.0306  88%|█████████████████████████████████▌    |  ETA: 0:00:00
0.03015844094040534loss: 0.0302  89%|█████████████████████████████████▉    |  ETA: 0:00:00
0.027049241017987252loss: 0.027  90%|███████████████████████████████████▏   |  ETA: 0:00:00
0.02289578222443347loss: 0.0229  91%|██████████████████████████████████▋   |  ETA: 0:00:00
0.019205145472165897loss: 0.0192  92%|███████████████████████████████████   |  ETA: 0:00:00
0.01684511234890388loss: 0.0168  93%|███████████████████████████████████▍  |  ETA: 0:00:00
0.01588947837509843loss: 0.0159  94%|███████████████████████████████████▊  |  ETA: 0:00:00
0.015782221974403335loss: 0.0158  95%|████████████████████████████████████▏ |  ETA: 0:00:00
0.01569031565022717loss: 0.0157  96%|████████████████████████████████████▌ |  ETA: 0:00:00
0.014882270878558595loss: 0.0149  97%|████████████████████████████████████▉ |  ETA: 0:00:00
0.01299856810201471loss: 0.013  98%|██████████████████████████████████████▎|  ETA: 0:00:00
0.010146481917053394loss: 0.0101  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.0068175358724189405loss: 0.00682 100%|█████████████████████████████████████| Time: 0:00:03
0.00013060182132885353Training 100%|██████████████████████████████████████████| Time: 0:00:04
494.2089032199089473.8777272120393667.1074203352925518.2054619170083578.8154382368062646.0053562468045710.16231672434129890.00118010501859213252.6199969581810063e-72.6199995221555827e-7494.2089032199089473.732958217371967.6525410631349228.2939447105199618.918170043729313.9279108564900232.35248343766358660.046835997229179536.353324108127963e-56.901903337638466e-50.0114590337976664260.00081457673100001553.635453873943374e-69.694315777963093e-71.1767027710477412e-69.694315777963093e-73.4794595759808757e-71.5536009694147404e-71.5957294409569188e-71.5536009694147404e-71.5957294409569188e-71.5957294409569188e-71.5957298549742173e-7Training   0%|                                          |  ETA: N/A
74.23325824778604loss: 74.2   1%|▍                                       |  ETA: 0:00:24
40.4164194498653loss: 40.4   2%|▊                                       |  ETA: 0:00:12
22.057491209158513loss: 22.1   3%|█▎                                      |  ETA: 0:00:08
12.037002416237797loss: 12   4%|█▋                                        |  ETA: 0:00:06
6.513514176038034loss: 6.51   5%|██                                      |  ETA: 0:00:05
3.449315856483889loss: 3.45   6%|██▍                                     |  ETA: 0:00:04
1.7559405779241133loss: 1.76   7%|██▊                                     |  ETA: 0:00:03
0.8409318703400847loss: 0.841   8%|███▏                                   |  ETA: 0:00:03
0.37442386292913404loss: 0.374   9%|███▌                                   |  ETA: 0:00:03
0.16853186673666665loss: 0.169  10%|███▉                                   |  ETA: 0:00:02
0.11399290140978496loss: 0.114  11%|████▎                                  |  ETA: 0:00:02
0.14612335704642926loss: 0.146  12%|████▋                                  |  ETA: 0:00:02
0.2260857703754901loss: 0.226  13%|█████▏                                 |  ETA: 0:00:02
0.3303346615355988loss: 0.33  14%|█████▋                                  |  ETA: 0:00:02
0.4445359230978686loss: 0.445  15%|█████▉                                 |  ETA: 0:00:01
0.5599902753192113loss: 0.56  16%|██████▍                                 |  ETA: 0:00:01
0.6714894127392135loss: 0.671  17%|██████▋                                |  ETA: 0:00:01
0.7760086714524222loss: 0.776  18%|███████                                |  ETA: 0:00:01
0.8718976552638854loss: 0.872  19%|███████▍                               |  ETA: 0:00:01
0.9583726548559248loss: 0.958  20%|███████▊                               |  ETA: 0:00:01
1.0351944772621668loss: 1.04  21%|████████▍                               |  ETA: 0:00:01
1.1024622728294085loss: 1.1  22%|█████████                                |  ETA: 0:00:01
1.1604806407794377loss: 1.16  23%|█████████▎                              |  ETA: 0:00:01
1.2096736667176855loss: 1.21  24%|█████████▋                              |  ETA: 0:00:01
1.2505292974467475loss: 1.25  25%|██████████                              |  ETA: 0:00:01
1.283563492652668loss: 1.28  26%|██████████▍                             |  ETA: 0:00:01
1.3092973590051766loss: 1.31  27%|██████████▊                             |  ETA: 0:00:01
1.3282428527895576loss: 1.33  28%|███████████▎                            |  ETA: 0:00:01
1.3408941543284723loss: 1.34  29%|███████████▋                            |  ETA: 0:00:01
1.347722799827034loss: 1.35  30%|████████████                            |  ETA: 0:00:01
1.3491752967037178loss: 1.35  31%|████████████▍                           |  ETA: 0:00:01
1.3456723700693698loss: 1.35  32%|████████████▊                           |  ETA: 0:00:01
1.3376092677219953loss: 1.34  33%|█████████████▎                          |  ETA: 0:00:01
1.325356737798009loss: 1.33  34%|█████████████▋                          |  ETA: 0:00:01
1.3092624186822712loss: 1.31  35%|██████████████                          |  ETA: 0:00:01
1.2896524652827968loss: 1.29  36%|██████████████▍                         |  ETA: 0:00:00
1.2668332928708992loss: 1.27  37%|██████████████▊                         |  ETA: 0:00:00
1.2410933585100037loss: 1.24  38%|███████████████▎                        |  ETA: 0:00:00
1.2127049259187612loss: 1.21  39%|███████████████▋                        |  ETA: 0:00:00
1.1819257771614318loss: 1.18  40%|████████████████                        |  ETA: 0:00:00
1.149000846100309loss: 1.15  41%|████████████████▍                       |  ETA: 0:00:00
1.114163756065005loss: 1.11  42%|████████████████▊                       |  ETA: 0:00:00
1.0776382490548937loss: 1.08  43%|█████████████████▎                      |  ETA: 0:00:00
1.0396394962407705loss: 1.04  44%|█████████████████▋                      |  ETA: 0:00:00
1.0003752816538773loss: 1  45%|███████████████████▍                       |  ETA: 0:00:00
0.9600470518264401loss: 0.96  46%|██████████████████▍                     |  ETA: 0:00:00
0.9188508239173396loss: 0.919  47%|██████████████████▍                    |  ETA: 0:00:00
0.8769779454263259loss: 0.877  48%|██████████████████▊                    |  ETA: 0:00:00
0.8346156986981961loss: 0.835  49%|███████████████████▏                   |  ETA: 0:00:00
0.7919477468877152loss: 0.792  50%|███████████████████▌                   |  ETA: 0:00:00
0.7491544012715825loss: 0.749  51%|███████████████████▉                   |  ETA: 0:00:00
0.7064127220919338loss: 0.706  52%|████████████████████▎                  |  ETA: 0:00:00
0.6638964439341639loss: 0.664  53%|████████████████████▋                  |  ETA: 0:00:00
0.621775717268065loss: 0.622  54%|█████████████████████                  |  ETA: 0:00:00
0.5802166741263294loss: 0.58  55%|██████████████████████                  |  ETA: 0:00:00
0.5393808160869739loss: 0.539  56%|█████████████████████▉                 |  ETA: 0:00:00
0.4994242148273938loss: 0.499  57%|██████████████████████▎                |  ETA: 0:00:00
0.46049658508887287loss: 0.46  58%|███████████████████████▎                |  ETA: 0:00:00
0.422740206254793loss: 0.423  59%|███████████████████████                |  ETA: 0:00:00
0.3862887259190619loss: 0.386  60%|███████████████████████▍               |  ETA: 0:00:00
0.3512658747724826loss: 0.351  61%|███████████████████████▊               |  ETA: 0:00:00
0.31778412752220664loss: 0.318  62%|████████████████████████▏              |  ETA: 0:00:00
0.28594335040894087loss: 0.286  63%|████████████████████████▋              |  ETA: 0:00:00
0.2558294812693047loss: 0.256  64%|█████████████████████████              |  ETA: 0:00:00
0.2275132922770024loss: 0.228  65%|█████████████████████████▍             |  ETA: 0:00:00
0.2010492888596346loss: 0.201  66%|█████████████████████████▊             |  ETA: 0:00:00
0.17647479886217407loss: 0.176  67%|██████████████████████████▏            |  ETA: 0:00:00
0.15380930463603779loss: 0.154  68%|██████████████████████████▌            |  ETA: 0:00:00
0.13305406858608437loss: 0.133  69%|██████████████████████████▉            |  ETA: 0:00:00
0.1141920936172176loss: 0.114  70%|███████████████████████████▎           |  ETA: 0:00:00
0.09718845122621063loss: 0.0972  71%|███████████████████████████           |  ETA: 0:00:00
0.08199099776286106loss: 0.082  72%|████████████████████████████▏          |  ETA: 0:00:00
0.06853148399898737loss: 0.0685  73%|███████████████████████████▊          |  ETA: 0:00:00
0.05672704615215089loss: 0.0567  74%|████████████████████████████▏         |  ETA: 0:00:00
0.0464820484633796loss: 0.0465  75%|████████████████████████████▌         |  ETA: 0:00:00
0.037690229420949496loss: 0.0377  76%|████████████████████████████▉         |  ETA: 0:00:00
0.030237086932483195loss: 0.0302  77%|█████████████████████████████▎        |  ETA: 0:00:00
0.024002423470514525loss: 0.024  78%|██████████████████████████████▍        |  ETA: 0:00:00
0.018862961694512584loss: 0.0189  79%|██████████████████████████████        |  ETA: 0:00:00
0.014694935290963164loss: 0.0147  80%|██████████████████████████████▍       |  ETA: 0:00:00
0.01137655951206971loss: 0.0114  81%|██████████████████████████████▊       |  ETA: 0:00:00
0.00879029145714628loss: 0.00879  82%|██████████████████████████████▍      |  ETA: 0:00:00
0.0068248013697039984loss: 0.00682  83%|██████████████████████████████▊      |  ETA: 0:00:00
0.005376592448207337loss: 0.00538  84%|███████████████████████████████▏     |  ETA: 0:00:00
0.004351226758845359loss: 0.00435  85%|███████████████████████████████▌     |  ETA: 0:00:00
0.003664137311381933loss: 0.00366  86%|███████████████████████████████▉     |  ETA: 0:00:00
0.0032410294485036894loss: 0.00324  87%|████████████████████████████████▎    |  ETA: 0:00:00
0.0030178966227528115loss: 0.00302  88%|████████████████████████████████▌    |  ETA: 0:00:00
0.0029406947081914757loss: 0.00294  89%|████████████████████████████████▉    |  ETA: 0:00:00
0.002964733832868185loss: 0.00296  90%|█████████████████████████████████▎   |  ETA: 0:00:00
0.0030538563717949383loss: 0.00305  91%|█████████████████████████████████▋   |  ETA: 0:00:00
0.003179473774834676loss: 0.00318  92%|██████████████████████████████████   |  ETA: 0:00:00
0.003319533428035687loss: 0.00332  93%|██████████████████████████████████▍  |  ETA: 0:00:00
0.003457480368934461loss: 0.00346  94%|██████████████████████████████████▊  |  ETA: 0:00:00
0.0035812684112175508loss: 0.00358  95%|███████████████████████████████████▏ |  ETA: 0:00:00
0.0036824623647110978loss: 0.00368  96%|███████████████████████████████████▌ |  ETA: 0:00:00
0.0037554589589010225loss: 0.00376  97%|███████████████████████████████████▉ |  ETA: 0:00:00
0.003796840145991127loss: 0.0038  98%|█████████████████████████████████████▎|  ETA: 0:00:00
0.003804859847567066loss: 0.0038  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.003779054814435765loss: 0.00378 100%|█████████████████████████████████████| Time: 0:00:00
0.0029406947081914757Training 100%|██████████████████████████████████████████| Time: 0:00:00
74.233330581471791.56137418678787941.51944967050779931.51474756200861660.68245297239012170.19137638568159760.000192859980237446451.788836458252143e-61.0547470544227319e-105.254137262629107e-171.8119148916795115e-29Training   0%|                                          |  ETA: N/A
494.2089032199091loss: 494   1%|▍                                        |  ETA: 0:00:26
416.7086995514831loss: 417   2%|▉                                        |  ETA: 0:00:14
301.87186997430365loss: 302   3%|█▎                                       |  ETA: 0:00:10
213.22801705361297loss: 213   4%|█▋                                       |  ETA: 0:00:07
149.40648614478843loss: 149   5%|██                                       |  ETA: 0:00:06
115.22404122493646loss: 115   6%|██▌                                      |  ETA: 0:00:05
96.34543913455384loss: 96.3   7%|██▊                                     |  ETA: 0:00:05
79.39779767791259loss: 79.4   8%|███▎                                    |  ETA: 0:00:10
65.56787147139745loss: 65.6   9%|███▋                                    |  ETA: 0:00:09
54.739696306072744loss: 54.7  10%|████                                    |  ETA: 0:00:08
46.26814316479258loss: 46.3  11%|████▍                                   |  ETA: 0:00:07
39.560838360645405loss: 39.6  12%|████▊                                   |  ETA: 0:00:07
34.298022959616745loss: 34.3  13%|█████▎                                  |  ETA: 0:00:06
30.54633410011867loss: 30.5  14%|█████▋                                  |  ETA: 0:00:06
28.933238146337313loss: 28.9  15%|██████                                  |  ETA: 0:00:05
30.78208250143967loss: 30.8  16%|██████▍                                 |  ETA: 0:00:05
37.55875666101628loss: 37.6  17%|██████▊                                 |  ETA: 0:00:05
47.38704146347047loss: 47.4  18%|███████▎                                |  ETA: 0:00:05
52.318490651270146loss: 52.3  19%|███████▋                                |  ETA: 0:00:04
48.85895443234298loss: 48.9  20%|████████                                |  ETA: 0:00:04
41.143832559196loss: 41.1  21%|████████▍                               |  ETA: 0:00:04
33.50121408603177loss: 33.5  22%|████████▊                               |  ETA: 0:00:04
27.713293428947466loss: 27.7  23%|█████████▎                              |  ETA: 0:00:04
23.819529369428558loss: 23.8  24%|█████████▋                              |  ETA: 0:00:04
21.254376718766984loss: 21.3  25%|██████████                              |  ETA: 0:00:03
19.42948561837119loss: 19.4  26%|██████████▍                             |  ETA: 0:00:03
17.90303100693668loss: 17.9  27%|██████████▊                             |  ETA: 0:00:03
16.396085008496147loss: 16.4  28%|███████████▎                            |  ETA: 0:00:03
14.752308970793283loss: 14.8  29%|███████████▋                            |  ETA: 0:00:03
12.909455845343116loss: 12.9  30%|████████████                            |  ETA: 0:00:03
10.875462557797128loss: 10.9  31%|████████████▍                           |  ETA: 0:00:03
8.71288252545796loss: 8.71  32%|████████████▊                           |  ETA: 0:00:03
6.527068602400136loss: 6.53  33%|█████████████▎                          |  ETA: 0:00:03
4.4534149599774855loss: 4.45  34%|█████████████▋                          |  ETA: 0:00:02
2.6412962392444665loss: 2.64  35%|██████████████                          |  ETA: 0:00:02
1.2342795663056394loss: 1.23  36%|██████████████▍                         |  ETA: 0:00:02
0.34591580466382804loss: 0.346  37%|██████████████▍                        |  ETA: 0:00:02
0.03250674863409575loss: 0.0325  38%|██████████████▌                       |  ETA: 0:00:02
0.2643104141460533loss: 0.264  39%|███████████████▎                       |  ETA: 0:00:02
0.9063978746896175loss: 0.906  40%|███████████████▋                       |  ETA: 0:00:02
1.7305156642179889loss: 1.73  41%|████████████████▍                       |  ETA: 0:00:02
2.474340776228947loss: 2.47  42%|████████████████▊                       |  ETA: 0:00:02
2.933823954403367loss: 2.93  43%|█████████████████▎                      |  ETA: 0:00:02
3.036328674003168loss: 3.04  44%|█████████████████▋                      |  ETA: 0:00:02
2.845064882252751loss: 2.85  45%|██████████████████                      |  ETA: 0:00:02
2.498722388181745loss: 2.5  46%|██████████████████▉                      |  ETA: 0:00:02
2.1349443027436377loss: 2.13  47%|██████████████████▊                     |  ETA: 0:00:02
1.8416920826943293loss: 1.84  48%|███████████████████▎                    |  ETA: 0:00:02
1.647195165983145loss: 1.65  49%|███████████████████▋                    |  ETA: 0:00:02
1.5351519818678083loss: 1.54  50%|████████████████████                    |  ETA: 0:00:02
1.467363435420574loss: 1.47  51%|████████████████████▍                   |  ETA: 0:00:01
1.402808855045693loss: 1.4  52%|█████████████████████▍                   |  ETA: 0:00:01
1.3097782742253306loss: 1.31  53%|█████████████████████▎                  |  ETA: 0:00:01
1.171505959067753loss: 1.17  54%|█████████████████████▋                  |  ETA: 0:00:02
0.9870664165854897loss: 0.987  55%|█████████████████████▌                 |  ETA: 0:00:02
0.7692176252015813loss: 0.769  56%|█████████████████████▉                 |  ETA: 0:00:02
0.5403333396407428loss: 0.54  57%|██████████████████████▊                 |  ETA: 0:00:02
0.3272660324350968loss: 0.327  58%|██████████████████████▋                |  ETA: 0:00:02
0.1556853475382298loss: 0.156  59%|███████████████████████                |  ETA: 0:00:01
0.04440205322720733loss: 0.0444  60%|██████████████████████▊               |  ETA: 0:00:01
0.0008926535872599556loss: 0.000893  61%|██████████████████████              |  ETA: 0:00:01
0.019103924236998377loss: 0.0191  62%|███████████████████████▌              |  ETA: 0:00:01
0.08053476982492919loss: 0.0805  63%|████████████████████████              |  ETA: 0:00:01
0.15930730371726676loss: 0.159  64%|█████████████████████████              |  ETA: 0:00:01
0.22964160052502988loss: 0.23  65%|██████████████████████████              |  ETA: 0:00:01
0.2732248514361978loss: 0.273  66%|█████████████████████████▊             |  ETA: 0:00:01
0.2835529968880482loss: 0.284  67%|██████████████████████████▏            |  ETA: 0:00:01
0.2656120696804645loss: 0.266  68%|██████████████████████████▌            |  ETA: 0:00:01
0.23158584804701468loss: 0.232  69%|██████████████████████████▉            |  ETA: 0:00:01
0.19498561339815892loss: 0.195  70%|███████████████████████████▎           |  ETA: 0:00:01
0.1658067074871198loss: 0.166  71%|███████████████████████████▊           |  ETA: 0:00:01
0.14821387238102476loss: 0.148  72%|████████████████████████████▏          |  ETA: 0:00:01
0.14082609760141152loss: 0.141  73%|████████████████████████████▌          |  ETA: 0:00:01
0.13871147379454676loss: 0.139  74%|████████████████████████████▉          |  ETA: 0:00:01
0.13594305715511545loss: 0.136  75%|█████████████████████████████▎         |  ETA: 0:00:01
0.1278012794673704loss: 0.128  76%|█████████████████████████████▋         |  ETA: 0:00:01
0.11211646675910676loss: 0.112  77%|██████████████████████████████         |  ETA: 0:00:01
0.0896168891447801loss: 0.0896  78%|█████████████████████████████▋        |  ETA: 0:00:01
0.06339912950517693loss: 0.0634  79%|██████████████████████████████        |  ETA: 0:00:01
0.03781445974325816loss: 0.0378  80%|██████████████████████████████▍       |  ETA: 0:00:01
0.017120978004210557loss: 0.0171  81%|██████████████████████████████▊       |  ETA: 0:00:01
0.004265227882238975loss: 0.00427  82%|██████████████████████████████▍      |  ETA: 0:00:01
0.00013060182132885353loss: 0.000131  83%|█████████████████████████████▉      |  ETA: 0:00:01
0.0034458547985172228loss: 0.00345  84%|███████████████████████████████▏     |  ETA: 0:00:00
0.01130669877705187loss: 0.0113  85%|████████████████████████████████▎     |  ETA: 0:00:00
0.020224812396146763loss: 0.0202  86%|████████████████████████████████▋     |  ETA: 0:00:00
0.0272115591365223loss: 0.0272  87%|█████████████████████████████████     |  ETA: 0:00:00
0.030573093062484166loss: 0.0306  88%|█████████████████████████████████▌    |  ETA: 0:00:00
0.03015844094040534loss: 0.0302  89%|█████████████████████████████████▉    |  ETA: 0:00:00
0.027049241017987252loss: 0.027  90%|███████████████████████████████████▏   |  ETA: 0:00:00
0.02289578222443347loss: 0.0229  91%|██████████████████████████████████▋   |  ETA: 0:00:00
0.019205145472165897loss: 0.0192  92%|███████████████████████████████████   |  ETA: 0:00:00
0.01684511234890388loss: 0.0168  93%|███████████████████████████████████▍  |  ETA: 0:00:00
0.01588947837509843loss: 0.0159  94%|███████████████████████████████████▊  |  ETA: 0:00:00
0.015782221974403335loss: 0.0158  95%|████████████████████████████████████▏ |  ETA: 0:00:00
0.01569031565022717loss: 0.0157  96%|████████████████████████████████████▌ |  ETA: 0:00:00
0.014882270878558595loss: 0.0149  97%|████████████████████████████████████▉ |  ETA: 0:00:00
0.01299856810201471loss: 0.013  98%|██████████████████████████████████████▎|  ETA: 0:00:00
0.010146481917053394loss: 0.0101  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.0068175358724189405loss: 0.00682 100%|█████████████████████████████████████| Time: 0:00:02
0.00013060182132885353Training 100%|██████████████████████████████████████████| Time: 0:00:02
494.2089032199089473.853379851477267.1910394712543619.3668972750808739.7656628835067256.7213112337089560.210802099219018020.0020064861760209748.733413153743843e-78.643809856106826e-98.541033704918051e-98.361164356847039e-98.317372464516128e-98.267710578974257e-98.216170538005704e-98.173508817546354e-98.063992267734478e-98.01162363901422e-97.99607035692014e-97.995962747971687e-97.995960116772822e-97.995967489500663e-97.99597547131374e-97.995662408675744e-97.995669375120758e-97.995673048410948e-97.995676395300453e-97.99568327296117e-97.99569002316523e-97.99569746035344e-97.995701886601305e-97.9957040481837e-97.995709575241539e-97.995712114952812e-97.995716473122468e-97.995723291744883e-97.99572691195183e-97.995734716823819e-97.995739182586709e-97.995741237207654e-97.995749174284868e-97.995748905929765e-97.995755232736463e-97.995760664785721e-97.995762348628909e-97.995767302157528e-97.995771370158946e-97.995777275180081e-97.995779661491644e-97.99578162003234e-97.995785794246537e-97.995792779685345e-97.995793743178586e-97.995798981400384e-97.995803539989782e-97.995807902980197e-97.995811511198476e-97.995810863138465e-97.99581423357792e-97.995820014805759e-97.995826173766786e-97.99583341659563e-97.995837475940589e-97.995837312443771e-97.995837312443771e-9494.2089032199089473.708957785740967.7761833565412430.5372695141565522.04440028004954416.404636288026654.9603066990716880.194591219854741950.004058851617001157.147148065319896e-55.9510123639957265e-50.000174518373440634830.0092706812141542420.0030222390251977141.0267359218644397e-51.4522343521301269e-67.686833463033755e-73.600496406843956e-74.4080691381235183e-73.383496109152047e-72.997152385067193e-78.121733108639196e-60.000221220080970844770.000224682794264422385.115195482952544e-52.5246311087766757e-71.658383660753623e-71.6373827534887686e-71.617313496531134e-71.617313496531134e-71.6418100153072227e-71.627983834787014e-71.6278472928886177e-71.622205096529859e-71.6184830275795784e-71.6202521100770352e-71.6192994667779848e-71.617701806125376e-71.6178952685705337e-71.6170325502039833e-71.6170337698312493e-71.6170127737038035e-71.616995626495644e-71.6170023507994416e-71.61689289041066e-71.6167978864730173e-71.616631790217669e-71.6165370513116566e-71.6163597445265485e-71.616385441563922e-71.616768432566055e-71.6165198001880525e-71.6179955219939407e-71.6168228608773648e-71.6244289819974508e-71.6370822034695743e-71.6431092303357142e-71.6674359270248463e-71.6234428150324763e-71.6234428150324763e-71.6211570028014825e-71.6209513912125766e-71.620792332612904e-71.6186159331785565e-71.6174685856950145e-71.6175081825339462e-71.6175471419503582e-71.6175471419503582e-71.616263516958333e-71.6160566488838499e-71.6158819738258231e-71.6158828263356447e-71.615884102814833e-71.615884102814833e-71.6156418250349603e-71.615510819833142e-71.6154674672019237e-71.615468232636376e-71.6154261988320252e-71.6154274208162867e-71.6154274208162867e-71.6154268565361845e-71.6154275268917293e-71.615351523485621e-71.6153527413086692e-71.6153537626333673e-71.6153537626333673e-71.615354138316092e-71.615355339353219e-71.6153555031848379e-71.6153555031848379e-71.615355251719032e-71.6153563315234064e-71.6153574946852075e-71.615356192900127e-71.615356847619923e-71.615356847619923e-71.6153549950763138e-71.6153556403305155e-71.6153567354890933e-71.6153569655059297e-71.6153569655059297e-71.6153520457967951e-71.6153532226424755e-71.61535394509749e-71.6153553624345332e-71.6153553624345332e-71.6153512613802895e-71.6153527152583922e-71.6153538611332498e-71.615354412162688e-71.6153556977944278e-71.6153556977944278e-71.6153556371528738e-71.6153563218904874e-71.6153522464103947e-71.615353398646347e-71.615353398646347e-71.6153538987552076e-71.6153479618046807e-71.6153495763174002e-71.6153495763174002e-71.6153510735076292e-71.615352225233006e-71.615352359535805e-71.6153539744532424e-71.6153539744532424e-71.6153489865193656e-71.6153505991276366e-71.615351682094142e-71.6153522265748675e-71.615352456787326e-71.6153532531634003e-71.6153532531634003e-71.615352860094826e-71.615354475374803e-71.6153556733403397e-71.6153567993325209e-71.6153567993325209e-71.61535752249614e-71.6153587516411636e-71.615359914180785e-71.6153458921725698e-71.6153458921725698e-71.615346699016413e-71.6153475722187842e-71.6153485715241128e-71.6153485715241128e-71.6153472327208884e-71.6153479290056528e-71.6153482845328204e-71.6153487017145276e-71.6153500145071232e-71.6153500145071232e-71.6153510816324778e-71.6153525555078433e-71.615349889100664e-71.615351503615881e-71.615353005131499e-71.615353005131499e-71.6153454159938873e-71.6153468840389835e-71.6153469545701517e-71.6153469545701517e-71.6153449767331242e-71.6153462099888634e-71.6153477329161382e-71.6153492580499782e-71.6153492580499782e-71.6153459487718344e-71.6153474326359352e-71.6153483375302097e-71.615343534480381e-71.6153449749967305e-71.61534305441681e-71.6153438048579065e-71.6153447756640818e-71.615346390412961e-71.615346390412961e-71.615347714839545e-71.6153451543667691e-71.6153461965120228e-71.6153461965120228e-71.6153474728454482e-71.6153490874043246e-71.6153507026023638e-71.6153507026023638e-71.615338132108385e-71.615339746540621e-71.6153409932081768e-71.6153397033712106e-71.6153400611269582e-71.6153400611269582e-71.6153415755474105e-71.6153414413320063e-71.6153424838914903e-71.6153424838914903e-71.6153396426250628e-71.615341257568645e-71.6153428728680176e-71.6153425580307392e-71.615344173245751e-71.615344173245751e-71.6153356694787596e-71.6153372840979217e-71.6153386454999824e-71.6153386454999824e-71.615335277644336e-71.615336877575755e-71.6153352107760183e-71.615335846958087e-71.615336744795237e-71.6153379648876818e-71.6153379648876818e-71.6153332400112389e-71.6153339773793926e-71.61533530619655e-71.61533530619655e-71.6153320901681433e-71.6153334733875456e-71.6153344295079261e-71.6153344295079261e-71.6153311595651954e-71.6153325107451323e-71.6153335233750968e-71.6153335233750968e-71.615331626592291e-71.6153324684428524e-71.6153334260166798e-71.6153334260166798e-71.6153280909193748e-71.6153297057630316e-71.615331304707733e-71.615331304707733e-71.6153307646404597e-71.6153323668331498e-71.6153331101647523e-71.6153331101647523e-71.6153313336911435e-71.6153325496327542e-71.6153314597383173e-71.6153291932523552e-71.6153308077795584e-71.6153308077795584e-71.615331551017958e-71.6153331658235916e-71.6153338706473428e-71.615335023543526e-71.615335023543526e-71.6153294532823335e-71.6153310680218928e-71.6153326826487103e-71.6153326826487103e-71.61532689172708e-71.6153271946562e-71.6153278875733768e-71.6153278875733768e-71.6153234095536003e-71.6153243400842052e-71.6153259116877276e-71.615327185768902e-71.615327185768902e-71.6153202314385944e-71.6153218449698115e-71.6153217737063933e-71.6153222958915115e-71.61532248415465e-71.61532248415465e-71.6153223721750181e-71.6153239865864102e-71.61532547801728e-71.61532547801728e-71.6153254757647132e-71.6153264458011577e-71.61532806018049e-71.61532806018049e-71.615322032356971e-71.615322203904612e-71.6153234454871805e-71.6153234454871805e-71.615323480313273e-71.615324936262222e-71.615326165116769e-71.6153274664279575e-71.6153274664279575e-71.615324893336885e-71.615325421309044e-71.615327035376395e-71.6153278800175626e-71.6153278800175626e-71.6153228324476842e-71.6153231722259563e-71.6153245394776647e-71.6153245394776647e-71.6153233245933356e-71.615324495821995e-71.6153250506506052e-71.6153262126981842e-71.6153278274908123e-71.6153278274908123e-71.6153244530648735e-71.615325150167149e-71.6153264374236847e-71.6153264374236847e-71.6153113399863392e-71.6153129552081857e-71.615313380520267e-71.6153146225515348e-71.6153146225515348e-71.6153102075116469e-71.6153112462842205e-71.6153115047248822e-71.6153122056512717e-71.6153122056512717e-71.6153069114632262e-71.6153073774594988e-71.6153088294597406e-71.615308526974776e-71.615308526974776e-71.6153069570042933e-71.615307132759902e-71.6153084649742758e-71.615305502325397e-71.61530643207106e-71.61530643207106e-71.6153044039150194e-71.6153059322903374e-71.6153075465403728e-71.61530776609745e-71.61530776609745e-71.6153090110769378e-71.615309820583902e-71.6153114358044066e-71.6153114358044066e-71.615295847080446e-71.615296663326916e-71.6152961879774673e-71.6152973165647348e-71.6152973165647348e-71.6152778336701392e-71.6152794476790593e-71.615280093072967e-71.615280093072967e-71.6152773555186844e-71.6152787510181062e-71.6152803661200112e-71.6152803661200112e-71.6152811750049686e-71.6152826450375926e-71.6152835448171285e-71.6152835448171285e-71.615277520960448e-71.6152784788557558e-71.6152797771318558e-71.6152761727327152e-71.61527714934241e-71.61527714934241e-71.6152783050024557e-71.6152775288084215e-71.6152784290795717e-71.6152793705901342e-71.6152793705901342e-71.6152772168724908e-71.6152783531359725e-71.61527955989798e-71.6152806102747296e-71.6152806102747296e-71.615280125253513e-71.6152817399217067e-71.6152833546749282e-71.61528471083763e-71.61528471083763e-71.6152787206694467e-71.6152800704212789e-71.6152816849455524e-71.6152825616327951e-71.6152825616327951e-71.6152807007807794e-71.6152712579668514e-71.6152727407576935e-71.61527435594079e-71.6152759698696004e-71.6152759698696004e-71.615267517588116e-71.61526817177605e-71.6152690910239493e-71.615270706174908e-71.615270706174908e-71.6152642727253105e-71.6152658873391212e-71.6152664279072848e-71.6152664279072848e-71.6152607824979532e-71.6152610584188955e-71.6152626729829915e-71.6152626729829915e-71.6151637258617565e-71.615165340967188e-71.615166955603241e-71.6151682388379047e-71.6151682388379047e-71.6151696757253785e-71.615170847816435e-71.6151721184000302e-71.6151721184000302e-71.6151579802459787e-71.6151595952356945e-71.6151576541103682e-71.6151552861372774e-71.6151569009194176e-71.6151574653967834e-7┌ Warning: dt <= dtmin. Aborting. There is either an error in your model specification or the true solution is unstable.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:343
┌ Warning: Instability detected. Aborting
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:349
┌ Warning: dt <= dtmin. Aborting. There is either an error in your model specification or the true solution is unstable.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:343
┌ Warning: Interrupted. Larger maxiters is needed.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:329
┌ Warning: Instability detected. Aborting
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:349
┌ Warning: Interrupted. Larger maxiters is needed.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:329
┌ Warning: Interrupted. Larger maxiters is needed.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:329
┌ Warning: Instability detected. Aborting
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:349
┌ Warning: Interrupted. Larger maxiters is needed.
└ @ DiffEqBase ~/.julia/packages/DiffEqBase/3iigH/src/integrator_interface.jl:329
Test Summary:      | Pass  Total
Layers SciML Tests |   16     16
Test Summary: | Pass  Total
Layers SDE    |    3      3
Test Summary: | Pass  Total
Layers DDE    |    3      3
Test Summary:          | Pass  Total
Collocation Regression |    2      2
Starting tests
Going to start!
Finally!
[ Info: Test some gradients
[ Info: Test some fast layers
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:102
[ Info: Test some adjoints
[ Info: Test Tracker
[ Info: Test non-ODEs
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:246
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:262
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:274
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:287
┌ Warning: Assignment to `grads` in soft scope is ambiguous because a global variable by the same name exists: `grads` will be treated as a new local. Disambiguate by using `local grads` to suppress this warning or `global grads` to assign to the existing global variable.
└ @ ~/.julia/packages/DiffEqFlux/8UHw5/test/neural_de.jl:299
Test Summary:   | Pass  Broken  Total
Neural DE Tests |   87      11     98
Test Summary:             | Pass  Total
Augmented Neural DE Tests |    8      8
┌ Warning: CUDA unavailable, not loading CUDA support
└ @ ScatterNNlib ~/.julia/packages/ScatterNNlib/0K3In/src/ScatterNNlib.jl:47
Test Summary:   | Pass  Total
Neural Graph DE |    1      1
102.52345f042.272057f032.69307f018.48579f020.765924f018.204617f08.399447f05.8579082f05.9152055f05.640875f04.279157f03.8272147f08.731827f050.344913f044.82775f06.9657845f021.00152f012.1083145f04.4760056f010.157249f010.588452f04.5298996f02.68015f03.7936695f04.308358f03.693533f03.3657057f04.4064093f05.9493723f06.2289505f05.2305937f04.3826017f04.328081f04.5539603f04.3916855f03.7293468f03.0296845f02.8279893f03.1073844f03.2587252f02.876115f02.2802331f01.9408838f01.8263795f01.5956889f01.1433175f00.7468061f00.68978864f00.8407012f00.82645667f00.60143936f00.42482358f00.36630902f00.28779143f00.19140998f00.23743688f00.40607575f00.45491272f00.34179264f00.28590125f00.34449238f00.3677414f00.32556897f00.32508403f00.34218094f00.27462026f00.1885669f00.18451929f00.20537543f00.17537688f00.1351785f00.13494399f00.13700642f00.112281665f00.103372656f00.1277858f00.14359924f00.13386157f00.12821777f00.13592423f00.13461718f00.12484094f00.12650582f00.13365485f00.12818435f00.11615412f00.11190886f00.110477895f00.10429066f00.10118648f00.10435887f00.104220666f00.09914152f00.09772832f00.10010422f00.10014277f00.099752605f00.10206547f00.10292865f00.100589626f00.099573605f00.10061876f00.100292206f00.09912215f00.09910462f00.09862292f00.09698278f00.09639315f00.09696617f00.096814856f00.09634604f00.096520096f00.09654387f00.0961536f00.09633728f00.09682021f00.09672832f00.09647943f00.09651614f00.096395254f00.09614165f00.096180096f00.096233875f00.095990546f00.09582668f00.09583912f00.095773324f00.095719784f00.09581785f00.09581721f00.09571914f00.09573673f00.0957771f00.09574053f00.09574352f00.09576166f00.09568688f00.09563358f00.095646426f00.09562657f00.0955879f00.09558617f00.09556114f00.095530845f00.09553166f00.09553982f00.09552646f00.09552262f00.09551577f00.095499404f00.09548782f00.09549342f00.095479585f00.09546123f00.095450826f00.095435f00.09542538f00.09541374f00.095404044f00.095391385f00.09538431f00.09538487f00.09537105f00.09537208f00.095359154f00.095344104f00.09534178f00.095340006f00.0953186f00.095316194f00.09530456f00.0952917f00.09528937f00.09527713f00.09526857f00.09526751f00.09524881f00.09524669f00.0952319f00.09522815f00.095217474f00.095209874f00.09519434f00.095189124f00.0951807f00.095168665f00.09516149f00.09515724f00.095143974f00.09513133f00.09512263f00.09511232f00.095109925f00.09510192f00.095090285f00.09508175f00.095067106f00.095061295f00.09504857f00.09504863f00.09503651f0Test Summary: |
Hybrid DE     | No tests
0.446828018728844640.036193331592466880.033871899664529090.000278676073544794332.605755149105229e-52.466247488987687e-52.45741167371368e-52.45741167371368e-5Test Summary:       | Pass  Total
Neural ODE MM Tests |    1      1
Test Summary:         | Pass  Total
Fast Neural ODE Tests |    6      6
Training   0%|                                          |  ETA: N/A
l = 4.596991306809186
loss: 4.6   1%|▍                                        |  ETA: 0:39:31
l = 3.7278910414021342
loss: 3.73   2%|▊                                       |  ETA: 0:19:51
l = 2.9604728333610177
loss: 2.96   3%|█▎                                      |  ETA: 0:13:08
l = 2.4951323894341315
loss: 2.5   4%|█▋                                       |  ETA: 0:09:47
l = 2.178862131819817
loss: 2.18   5%|██                                      |  ETA: 0:07:46
l = 1.9462049983489962
loss: 1.95   6%|██▍                                     |  ETA: 0:06:25
l = 1.8824944929909475
loss: 1.88   7%|██▊                                     |  ETA: 0:05:31
l = 1.8268961049704118
loss: 1.83   8%|███▎                                    |  ETA: 0:04:48
l = 1.72922448545195
loss: 1.73   9%|███▋                                    |  ETA: 0:04:14
l = 1.6068027244242356
loss: 1.61  10%|████                                    |  ETA: 0:03:47
l = 1.4865560318702038
loss: 1.49  11%|████▍                                   |  ETA: 0:03:24
l = 1.4139179285732066
loss: 1.41  12%|████▊                                   |  ETA: 0:03:06
l = 1.3610924339245802
loss: 1.36  13%|█████▎                                  |  ETA: 0:02:50
l = 1.277495058129624
loss: 1.28  14%|█████▋                                  |  ETA: 0:02:36
l = 1.1709676379312763
loss: 1.17  15%|██████                                  |  ETA: 0:02:25
l = 1.0679958795783582
loss: 1.07  16%|██████▍                                 |  ETA: 0:02:15
l = 0.9836136027407734
loss: 0.984  17%|██████▋                                |  ETA: 0:02:07
l = 0.9099116488179714
loss: 0.91  18%|███████▎                                |  ETA: 0:01:58
l = 0.860808731181085
loss: 0.861  19%|███████▍                               |  ETA: 0:01:51
l = 0.8276560896401395
loss: 0.828  20%|███████▊                               |  ETA: 0:01:45
l = 0.7723994386537264
loss: 0.772  21%|████████▎                              |  ETA: 0:01:39
l = 0.7566165531265595
loss: 0.757  22%|████████▋                              |  ETA: 0:01:33
l = 0.6973077577118697
loss: 0.697  23%|█████████                              |  ETA: 0:01:28
l = 0.6277697374580612
loss: 0.628  24%|█████████▍                             |  ETA: 0:01:24
l = 0.5651045029259878
loss: 0.565  25%|█████████▊                             |  ETA: 0:01:20
l = 0.5031583210352388
loss: 0.503  26%|██████████▏                            |  ETA: 0:01:16
l = 0.490500046804273
loss: 0.491  27%|██████████▌                            |  ETA: 0:01:12
l = 0.4656224319631676
loss: 0.466  28%|██████████▉                            |  ETA: 0:01:09
l = 0.45069022867452774
loss: 0.451  29%|███████████▎                           |  ETA: 0:01:06
l = 0.4429062489823425
loss: 0.443  30%|███████████▊                           |  ETA: 0:01:03
l = 0.41656315319329795
loss: 0.417  31%|████████████▏                          |  ETA: 0:01:01
l = 0.4024548188523019
loss: 0.402  32%|████████████▌                          |  ETA: 0:00:58
l = 0.3857635756537305
loss: 0.386  33%|████████████▉                          |  ETA: 0:00:56
l = 0.3528266165760087
loss: 0.353  34%|█████████████▎                         |  ETA: 0:00:53
l = 0.33266461400060165
loss: 0.333  35%|█████████████▋                         |  ETA: 0:00:51
l = 0.29971393009054065
loss: 0.3  36%|██████████████▊                          |  ETA: 0:00:49
l = 0.28417287945608455
loss: 0.284  37%|██████████████▍                        |  ETA: 0:00:47
l = 0.2655175837393797
loss: 0.266  38%|██████████████▉                        |  ETA: 0:00:45
l = 0.256309191514984
loss: 0.256  39%|███████████████▎                       |  ETA: 0:00:44
l = 0.25711656053222665
loss: 0.257  40%|███████████████▋                       |  ETA: 0:00:42
l = 0.2619722390104557
loss: 0.262  41%|████████████████                       |  ETA: 0:00:40
l = 0.24688864983107495
loss: 0.247  42%|████████████████▍                      |  ETA: 0:00:39
l = 0.2341001863720253
loss: 0.234  43%|████████████████▊                      |  ETA: 0:00:37
l = 0.2284387261243307
loss: 0.228  44%|█████████████████▏                     |  ETA: 0:00:36
l = 0.20711698428951855
loss: 0.207  45%|█████████████████▌                     |  ETA: 0:00:35
l = 0.20314203342392903
loss: 0.203  46%|██████████████████                     |  ETA: 0:00:33
l = 0.18611321742967443
loss: 0.186  47%|██████████████████▍                    |  ETA: 0:00:32
l = 0.18242113460559942
loss: 0.182  48%|██████████████████▊                    |  ETA: 0:00:31
l = 0.1729090217481255
loss: 0.173  49%|███████████████████▏                   |  ETA: 0:00:30
l = 0.15418147875261193
loss: 0.154  50%|███████████████████▌                   |  ETA: 0:00:29
l = 0.13760485345373769
loss: 0.138  51%|███████████████████▉                   |  ETA: 0:00:28
l = 0.1319602868388819
loss: 0.132  52%|████████████████████▎                  |  ETA: 0:00:27
l = 0.13130186687768092
loss: 0.131  53%|████████████████████▋                  |  ETA: 0:00:26
l = 0.1286565250173659
loss: 0.129  54%|█████████████████████                  |  ETA: 0:00:25
l = 0.1384567105142543
loss: 0.138  55%|█████████████████████▌                 |  ETA: 0:00:24
l = 0.12910302760347736
loss: 0.129  56%|█████████████████████▉                 |  ETA: 0:00:23
l = 0.09839721029877282
loss: 0.0984  57%|█████████████████████▋                |  ETA: 0:00:22
l = 0.10834363418242193
loss: 0.108  58%|██████████████████████▋                |  ETA: 0:00:21
l = 0.12136105738003074
loss: 0.121  59%|███████████████████████                |  ETA: 0:00:21
l = 0.10484920039449243
loss: 0.105  60%|███████████████████████▍               |  ETA: 0:00:20
l = 0.08607174813544585
loss: 0.0861  61%|███████████████████████▏              |  ETA: 0:00:19
l = 0.11575381383984405
loss: 0.116  62%|████████████████████████▏              |  ETA: 0:00:18
l = 0.10860128225482486
loss: 0.109  63%|████████████████████████▋              |  ETA: 0:00:18
l = 0.11670778358467936
loss: 0.117  64%|█████████████████████████              |  ETA: 0:00:17
l = 0.08414210351431485
loss: 0.0841  65%|████████████████████████▊             |  ETA: 0:00:16
l = 0.10002745481068137
loss: 0.1  66%|███████████████████████████              |  ETA: 0:00:16
l = 0.10562023582016296
loss: 0.106  67%|██████████████████████████▏            |  ETA: 0:00:15
l = 0.0867147501734059
loss: 0.0867  68%|█████████████████████████▉            |  ETA: 0:00:14
l = 0.1110027853534099
loss: 0.111  69%|██████████████████████████▉            |  ETA: 0:00:14
l = 0.0767874465966782
loss: 0.0768  70%|██████████████████████████▋           |  ETA: 0:00:13
l = 0.12947747636761037
loss: 0.129  71%|███████████████████████████▊           |  ETA: 0:00:13
l = 0.09287699095020645
loss: 0.0929  72%|███████████████████████████▍          |  ETA: 0:00:12
l = 0.13686875407363844
loss: 0.137  73%|████████████████████████████▌          |  ETA: 0:00:11
l = 0.1254943960134987
loss: 0.125  74%|████████████████████████████▉          |  ETA: 0:00:11
l = 0.11944622512456451
loss: 0.119  75%|█████████████████████████████▎         |  ETA: 0:00:10
l = 0.1046141436968491
loss: 0.105  76%|█████████████████████████████▋         |  ETA: 0:00:10
l = 0.1044462101880539
loss: 0.104  77%|██████████████████████████████         |  ETA: 0:00:09
l = 0.11167406081864104
loss: 0.112  78%|██████████████████████████████▍        |  ETA: 0:00:09
l = 0.09172544375753482
loss: 0.0917  79%|██████████████████████████████        |  ETA: 0:00:08
l = 0.11097553191134223
loss: 0.111  80%|███████████████████████████████▎       |  ETA: 0:00:08
l = 0.07012074432848356
loss: 0.0701  81%|██████████████████████████████▊       |  ETA: 0:00:07
l = 0.10861269009677614
loss: 0.109  82%|████████████████████████████████       |  ETA: 0:00:07
l = 0.07893632216510292
loss: 0.0789  83%|███████████████████████████████▌      |  ETA: 0:00:07
l = 0.10449731038725883
loss: 0.104  84%|████████████████████████████████▊      |  ETA: 0:00:06
l = 0.09508280698970027
loss: 0.0951  85%|████████████████████████████████▎     |  ETA: 0:00:06
l = 0.08891141204016309
loss: 0.0889  86%|████████████████████████████████▋     |  ETA: 0:00:05
l = 0.10615334441096436
loss: 0.106  87%|█████████████████████████████████▉     |  ETA: 0:00:05
l = 0.0966593885074387
loss: 0.0967  88%|█████████████████████████████████▌    |  ETA: 0:00:04
l = 0.06243650086367027
loss: 0.0624  89%|█████████████████████████████████▉    |  ETA: 0:00:04
l = 0.0871951684376955
loss: 0.0872  90%|██████████████████████████████████▎   |  ETA: 0:00:04
l = 0.0661576134072488
loss: 0.0662  91%|██████████████████████████████████▋   |  ETA: 0:00:03
l = 0.07488148986413297
loss: 0.0749  92%|███████████████████████████████████   |  ETA: 0:00:03
l = 0.07630693284175072
loss: 0.0763  93%|███████████████████████████████████▍  |  ETA: 0:00:02
l = 0.07375524052190928
loss: 0.0738  94%|███████████████████████████████████▊  |  ETA: 0:00:02
l = 0.06363025001523043
loss: 0.0636  95%|████████████████████████████████████▏ |  ETA: 0:00:02
l = 0.07188514084913782
loss: 0.0719  96%|████████████████████████████████████▌ |  ETA: 0:00:01
l = 0.06954583026248308
loss: 0.0695  97%|████████████████████████████████████▉ |  ETA: 0:00:01
l = 0.07143087266644378
loss: 0.0714  98%|█████████████████████████████████████▎|  ETA: 0:00:01
l = 0.07547776710621858
loss: 0.0755  99%|█████████████████████████████████████▋|  ETA: 0:00:00
l = 0.07309339143023834
loss: 0.0731 100%|██████████████████████████████████████| Time: 0:00:33
l = 0.06243650086367027
Training 100%|██████████████████████████████████████████| Time: 0:00:33
Training   0%|                                          |  ETA: N/A
l = 0.06307393249933689
loss: 0.0631   1%|▍                                     |  ETA: 0:00:12
l = 0.06836850733346445
loss: 0.0684   2%|▊                                     |  ETA: 0:00:19
l = 0.06251360751148909
loss: 0.0625   3%|█▏                                    |  ETA: 0:00:15
l = 0.050646986146737044
loss: 0.0506   4%|█▌                                    |  ETA: 0:00:13
l = 0.04854885515152379
loss: 0.0485   5%|█▉                                    |  ETA: 0:00:12
l = 0.04687659289983039
loss: 0.0469   6%|██▎                                   |  ETA: 0:00:11
l = 0.04397617127428097
loss: 0.044   7%|██▊                                    |  ETA: 0:00:10
l = 0.04305188413871674
loss: 0.0431   8%|███                                   |  ETA: 0:00:10
l = 0.041285347350347966
loss: 0.0413   9%|███▍                                  |  ETA: 0:00:09
l = 0.039529529620033095
loss: 0.0395  10%|███▊                                  |  ETA: 0:00:09
l = 0.0403567325792174
loss: 0.0404  11%|████▏                                 |  ETA: 0:00:08
l = 0.03904960031243638
loss: 0.039  12%|████▋                                  |  ETA: 0:00:09
l = 0.03795196961554648
loss: 0.038  13%|█████▏                                 |  ETA: 0:00:09
l = 0.03703905711099922
loss: 0.037  14%|█████▌                                 |  ETA: 0:00:09
l = 0.034846419021673916
loss: 0.0348  15%|█████▊                                |  ETA: 0:00:08
l = 0.03445082516843607
loss: 0.0345  16%|██████▏                               |  ETA: 0:00:08
l = 0.03647147354718556
loss: 0.0365  17%|██████▌                               |  ETA: 0:00:08
l = 0.0357947387152904
loss: 0.0358  18%|██████▉                               |  ETA: 0:00:08
l = 0.03336549461714336
loss: 0.0334  19%|███████▎                              |  ETA: 0:00:08
l = 0.03306164832565734
loss: 0.0331  20%|███████▋                              |  ETA: 0:00:07
l = 0.033651585104989584
loss: 0.0337  21%|████████                              |  ETA: 0:00:07
l = 0.03303441246348464
loss: 0.033  22%|████████▋                              |  ETA: 0:00:07
l = 0.03296582480434116
loss: 0.033  23%|█████████                              |  ETA: 0:00:07
l = 0.03317046410877754
loss: 0.0332  24%|█████████▏                            |  ETA: 0:00:07
l = 0.03204012206538645
loss: 0.032  25%|█████████▊                             |  ETA: 0:00:07
l = 0.03163146719546005
loss: 0.0316  26%|█████████▉                            |  ETA: 0:00:07
l = 0.03164739382665413
loss: 0.0316  27%|██████████▎                           |  ETA: 0:00:07
l = 0.03186625577750959
loss: 0.0319  28%|██████████▋                           |  ETA: 0:00:07
l = 0.03160186641283101
loss: 0.0316  29%|███████████                           |  ETA: 0:00:07
l = 0.0308982570748863
loss: 0.0309  30%|███████████▍                          |  ETA: 0:00:06
l = 0.031095119620619158
loss: 0.0311  31%|███████████▊                          |  ETA: 0:00:06
l = 0.030643678688073807
loss: 0.0306  32%|████████████▏                         |  ETA: 0:00:06
l = 0.03029846737157018
loss: 0.0303  33%|████████████▌                         |  ETA: 0:00:06
l = 0.030729047823103192
loss: 0.0307  34%|████████████▉                         |  ETA: 0:00:06
l = 0.03004860259713229
loss: 0.03  35%|██████████████                          |  ETA: 0:00:06
l = 0.030105432351811786
loss: 0.0301  36%|█████████████▋                        |  ETA: 0:00:06
l = 0.03008086554859822
loss: 0.0301  37%|██████████████                        |  ETA: 0:00:06
l = 0.03003609455502251
loss: 0.03  38%|███████████████▎                        |  ETA: 0:00:06
l = 0.029404908166923455
loss: 0.0294  39%|██████████████▉                       |  ETA: 0:00:06
l = 0.02950147029691068
loss: 0.0295  40%|███████████████▎                      |  ETA: 0:00:05
l = 0.029378913623931267
loss: 0.0294  41%|███████████████▋                      |  ETA: 0:00:05
l = 0.029299917073794177
loss: 0.0293  42%|████████████████                      |  ETA: 0:00:05
l = 0.029115689583224528
loss: 0.0291  43%|████████████████▍                     |  ETA: 0:00:05
l = 0.028912424602502568
loss: 0.0289  44%|████████████████▊                     |  ETA: 0:00:05
l = 0.028874772889199683
loss: 0.0289  45%|█████████████████▏                    |  ETA: 0:00:05
l = 0.028777652008517375
loss: 0.0288  46%|█████████████████▌                    |  ETA: 0:00:05
l = 0.028650952909375627
loss: 0.0287  47%|█████████████████▉                    |  ETA: 0:00:05
l = 0.028508878300052914
loss: 0.0285  48%|██████████████████▎                   |  ETA: 0:00:05
l = 0.02841606821506858
loss: 0.0284  49%|██████████████████▋                   |  ETA: 0:00:05
l = 0.02827388581420314
loss: 0.0283  50%|███████████████████                   |  ETA: 0:00:05
l = 0.02823392991210912
loss: 0.0282  51%|███████████████████▍                  |  ETA: 0:00:04
l = 0.028107927565080616
loss: 0.0281  52%|███████████████████▊                  |  ETA: 0:00:04
l = 0.027968460149982898
loss: 0.028  53%|████████████████████▋                  |  ETA: 0:00:04
l = 0.027913938811103205
loss: 0.0279  54%|████████████████████▌                 |  ETA: 0:00:04
l = 0.027771487584391023
loss: 0.0278  55%|████████████████████▉                 |  ETA: 0:00:04
l = 0.027718705228353586
loss: 0.0277  56%|█████████████████████▎                |  ETA: 0:00:04
l = 0.027581875665949402
loss: 0.0276  57%|█████████████████████▋                |  ETA: 0:00:04
l = 0.027626229751540977
loss: 0.0276  58%|██████████████████████                |  ETA: 0:00:04
l = 0.027437593311221548
loss: 0.0274  59%|██████████████████████▍               |  ETA: 0:00:04
l = 0.027379013748334416
loss: 0.0274  60%|██████████████████████▊               |  ETA: 0:00:04
l = 0.02725183349651892
loss: 0.0273  61%|███████████████████████▏              |  ETA: 0:00:04
l = 0.027169451865255066
loss: 0.0272  62%|███████████████████████▌              |  ETA: 0:00:03
l = 0.02710769006360391
loss: 0.0271  63%|████████████████████████              |  ETA: 0:00:03
l = 0.02695601731799823
loss: 0.027  64%|█████████████████████████              |  ETA: 0:00:03
l = 0.027023530814820222
loss: 0.027  65%|█████████████████████████▍             |  ETA: 0:00:03
l = 0.026918949163918855
loss: 0.0269  66%|█████████████████████████▏            |  ETA: 0:00:03
l = 0.02675681742567671
loss: 0.0268  67%|█████████████████████████▌            |  ETA: 0:00:03
l = 0.026748703269032757
loss: 0.0267  68%|█████████████████████████▉            |  ETA: 0:00:03
l = 0.026643605572771113
loss: 0.0266  69%|██████████████████████████▎           |  ETA: 0:00:03
l = 0.026596617477703276
loss: 0.0266  70%|██████████████████████████▋           |  ETA: 0:00:03
l = 0.02645642210772623
loss: 0.0265  71%|███████████████████████████           |  ETA: 0:00:03
l = 0.02631140711719162
loss: 0.0263  72%|███████████████████████████▍          |  ETA: 0:00:02
l = 0.02647551252308488
loss: 0.0265  73%|███████████████████████████▊          |  ETA: 0:00:02
l = 0.02619790902224885
loss: 0.0262  74%|████████████████████████████▏         |  ETA: 0:00:02
l = 0.026081290583223487
loss: 0.0261  75%|████████████████████████████▌         |  ETA: 0:00:02
l = 0.02612919031208414
loss: 0.0261  76%|████████████████████████████▉         |  ETA: 0:00:02
l = 0.02599177360675594
loss: 0.026  77%|██████████████████████████████         |  ETA: 0:00:02
l = 0.025990586757915154
loss: 0.026  78%|██████████████████████████████▍        |  ETA: 0:00:02
l = 0.026064560057482564
loss: 0.0261  79%|██████████████████████████████        |  ETA: 0:00:02
l = 0.02592682021508377
loss: 0.0259  80%|██████████████████████████████▍       |  ETA: 0:00:02
l = 0.025606893316899217
loss: 0.0256  81%|██████████████████████████████▊       |  ETA: 0:00:02
l = 0.02553937399978424
loss: 0.0255  82%|███████████████████████████████▏      |  ETA: 0:00:02
l = 0.02608886899523517
loss: 0.0261  83%|███████████████████████████████▌      |  ETA: 0:00:02
l = 0.02609730752472873
loss: 0.0261  84%|███████████████████████████████▉      |  ETA: 0:00:01
l = 0.025440793921147117
loss: 0.0254  85%|████████████████████████████████▎     |  ETA: 0:00:01
l = 0.025342782543585855
loss: 0.0253  86%|████████████████████████████████▋     |  ETA: 0:00:01
l = 0.02547335355431323
loss: 0.0255  87%|█████████████████████████████████     |  ETA: 0:00:01
l = 0.025356804215153943
loss: 0.0254  88%|█████████████████████████████████▌    |  ETA: 0:00:01
l = 0.025316699539573533
loss: 0.0253  89%|█████████████████████████████████▉    |  ETA: 0:00:01
l = 0.02516375759757033
loss: 0.0252  90%|██████████████████████████████████▎   |  ETA: 0:00:01
l = 0.024973836873233842
loss: 0.025  91%|███████████████████████████████████▌   |  ETA: 0:00:01
l = 0.025115890120488416
loss: 0.0251  92%|███████████████████████████████████   |  ETA: 0:00:01
l = 0.025168900544144453
loss: 0.0252  93%|███████████████████████████████████▍  |  ETA: 0:00:01
l = 0.02573278738777129
loss: 0.0257  94%|███████████████████████████████████▊  |  ETA: 0:00:01
l = 0.025102277127823574
loss: 0.0251  95%|████████████████████████████████████▏ |  ETA: 0:00:00
l = 0.024911368190069588
loss: 0.0249  96%|████████████████████████████████████▌ |  ETA: 0:00:00
l = 0.025594317119675483
loss: 0.0256  97%|████████████████████████████████████▉ |  ETA: 0:00:00
l = 0.025011485230099932
loss: 0.025  98%|██████████████████████████████████████▎|  ETA: 0:00:00
l = 0.024544978141255797
loss: 0.0245  99%|█████████████████████████████████████▋|  ETA: 0:00:00
l = 0.024501123553984053
loss: 0.0245 100%|██████████████████████████████████████| Time: 0:00:08
l = 0.024501123553984053
Training 100%|██████████████████████████████████████████| Time: 0:00:08
l = 0.02467062911589118
l = 0.024445135171345292
l = 0.024348480292703263
l = 0.024306995009575682
l = 0.024288037109727347
l = 0.02427230123604448
l = 0.02421682882677418
l = 0.024059240700770836
l = 0.023992597526881605
l = 0.02396147861142731
l = 0.023927082634753443
l = 0.023853733499678096
l = 0.02382369691498273
l = 0.02372801176684986
l = 0.023630891516432252
l = 0.02356244395425702
l = 0.023331418533026956
l = 0.023177921901344312
l = 0.023026383744662766
l = 0.022783524444231137
l = 0.022194827707997154
l = 0.021927429224840814
l = 0.021205010969335872
l = 0.0206730598292672
l = 0.019814839814913363
l = 0.01932258538225214
l = 0.01878798509540374
l = 0.018356466384903933
l = 0.017908054421703862
l = 0.017696979864702124
l = 0.017418517613892594
l = 0.017151960524154086
l = 0.016964696023924575
l = 0.016699528291829885
l = 0.01637991127817361
l = 0.01617012930456377
l = 0.01567367754582357
l = 0.015424242274792336
l = 0.015046053414669042
l = 0.014608997402161011
l = 0.014301686453981005
l = 0.013963103537137034
l = 0.013671402894443404
l = 0.013466745407871806
l = 0.013300888406994506
l = 0.013159988172980527
l = 0.013038146329299878
l = 0.012876908008534022
l = 0.012602709123343152
l = 0.012204858525739935
l = 0.011864921571828486
l = 0.011576535414500122
l = 0.011315446315997962
l = 0.011102321199294078
l = 0.01094856871742294
l = 0.010814970254247505
l = 0.010662308566600491
