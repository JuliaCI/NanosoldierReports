Julia Version 1.3.2-pre.0
Commit 2e6715c045 (2019-12-31 00:49 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Rmath ────────────── v0.6.0
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed StaticArrays ─────── v0.12.1
 Installed BinaryProvider ───── v0.5.8
 Installed OrderedCollections ─ v1.1.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed JLD ──────────────── v0.9.1
 Installed SortingAlgorithms ── v0.3.1
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed QuadGK ───────────── v2.3.1
 Installed FillArrays ───────── v0.8.4
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distances ────────── v0.8.2
 Installed URIParser ────────── v0.4.0
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed StatsBase ────────── v0.32.0
 Installed CMake ────────────── v1.1.2
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.22.3
 Installed Compat ───────────── v2.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed DataStructures ───── v0.17.9
 Installed FileIO ───────────── v1.2.1
 Installed PDMats ───────────── v0.9.11
 Installed Clustering ───────── v0.13.3
 Installed NearestNeighbors ─── v0.4.4
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_stCd6G/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -2.7632308722842988e6, [98447.19197645245, 1552.8080235475582], [2994.4021721841536 -675.7328658991142 -2310.48727599933; -2489.561093407269 401.74022538690787 2245.141981301305], Array{Float64,2}[[94634.17219411956 622.7531148230358 3279.712906735873; 622.7531148230358 99873.31909568643 -615.0901874939866; 3279.7129067358724 -615.0901874939866 95531.98330867867], [4741.865484542949 -817.3247688326903 -2986.130953588809; -817.3247688326903 439.23397637029075 746.4107371238936; -2986.1309535888086 746.4107371238936 4728.838585213083]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.000731e+03
      1       9.133941e+02      -8.733702e+01 |        2
      2       9.060565e+02      -7.337622e+00 |        2
      3       8.987645e+02      -7.291999e+00 |        0
      4       8.987645e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 898.7644597120516)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.073927
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.738017
[ Info: iteration 2, lowerbound -3.572082
[ Info: iteration 3, lowerbound -3.403884
[ Info: iteration 4, lowerbound -3.225342
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.048063
[ Info: iteration 6, lowerbound -2.894887
[ Info: iteration 7, lowerbound -2.795632
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.748999
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.710908
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.667998
[ Info: iteration 11, lowerbound -2.627654
[ Info: iteration 12, lowerbound -2.586415
[ Info: iteration 13, lowerbound -2.542742
[ Info: iteration 14, lowerbound -2.499230
[ Info: iteration 15, lowerbound -2.458153
[ Info: iteration 16, lowerbound -2.420632
[ Info: iteration 17, lowerbound -2.386496
[ Info: iteration 18, lowerbound -2.355379
[ Info: iteration 19, lowerbound -2.328850
[ Info: iteration 20, lowerbound -2.311554
[ Info: iteration 21, lowerbound -2.307763
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302917
[ Info: iteration 23, lowerbound -2.299259
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 26 19:25:44 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 26 19:25:51 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Jan 26 19:25:53 2020: EM with 272 data points 0 iterations avll -2.073927
5.8 data points per parameter
, Sun Jan 26 19:25:55 2020: GMM converted to Variational GMM
, Sun Jan 26 19:26:03 2020: iteration 1, lowerbound -3.738017
, Sun Jan 26 19:26:03 2020: iteration 2, lowerbound -3.572082
, Sun Jan 26 19:26:03 2020: iteration 3, lowerbound -3.403884
, Sun Jan 26 19:26:03 2020: iteration 4, lowerbound -3.225342
, Sun Jan 26 19:26:04 2020: dropping number of Gaussions to 7
, Sun Jan 26 19:26:04 2020: iteration 5, lowerbound -3.048063
, Sun Jan 26 19:26:04 2020: iteration 6, lowerbound -2.894887
, Sun Jan 26 19:26:04 2020: iteration 7, lowerbound -2.795632
, Sun Jan 26 19:26:04 2020: dropping number of Gaussions to 6
, Sun Jan 26 19:26:04 2020: iteration 8, lowerbound -2.748999
, Sun Jan 26 19:26:04 2020: dropping number of Gaussions to 4
, Sun Jan 26 19:26:04 2020: iteration 9, lowerbound -2.710908
, Sun Jan 26 19:26:04 2020: dropping number of Gaussions to 3
, Sun Jan 26 19:26:04 2020: iteration 10, lowerbound -2.667998
, Sun Jan 26 19:26:04 2020: iteration 11, lowerbound -2.627654
, Sun Jan 26 19:26:04 2020: iteration 12, lowerbound -2.586415
, Sun Jan 26 19:26:04 2020: iteration 13, lowerbound -2.542742
, Sun Jan 26 19:26:04 2020: iteration 14, lowerbound -2.499230
, Sun Jan 26 19:26:04 2020: iteration 15, lowerbound -2.458153
, Sun Jan 26 19:26:04 2020: iteration 16, lowerbound -2.420632
, Sun Jan 26 19:26:04 2020: iteration 17, lowerbound -2.386496
, Sun Jan 26 19:26:04 2020: iteration 18, lowerbound -2.355379
, Sun Jan 26 19:26:04 2020: iteration 19, lowerbound -2.328850
, Sun Jan 26 19:26:04 2020: iteration 20, lowerbound -2.311554
, Sun Jan 26 19:26:04 2020: iteration 21, lowerbound -2.307763
, Sun Jan 26 19:26:04 2020: dropping number of Gaussions to 2
, Sun Jan 26 19:26:04 2020: iteration 22, lowerbound -2.302917
, Sun Jan 26 19:26:04 2020: iteration 23, lowerbound -2.299259
, Sun Jan 26 19:26:04 2020: iteration 24, lowerbound -2.299256
, Sun Jan 26 19:26:04 2020: iteration 25, lowerbound -2.299254
, Sun Jan 26 19:26:04 2020: iteration 26, lowerbound -2.299254
, Sun Jan 26 19:26:04 2020: iteration 27, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 28, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 29, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 30, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 31, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 32, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 33, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 34, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 35, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 36, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 37, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 38, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 39, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 40, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 41, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 42, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 43, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 44, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 45, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 46, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 47, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 48, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 49, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: iteration 50, lowerbound -2.299253
, Sun Jan 26 19:26:04 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260162, 95.95490777398385]
β = [178.0450922260162, 95.95490777398385]
m = [4.250300733269891 79.28686694436156; 2.00022925777535 53.85198717246117]
ν = [180.0450922260162, 97.95490777398385]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.184041555474843 -0.007644049042327506; 0.0 0.008581705166333137], [0.37587636119487067 -0.008953123827346463; 0.0 0.012748664777409388]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9936777857256093
avll from llpg:  -0.9936777857256097
avll direct:     -0.9936777857256096
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9960909955495943
avll from llpg:  -0.9960909955495943
avll direct:     -0.9960909955495943
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0272699    0.111971    -0.060134    0.105783    -0.0704571   -0.105696    -0.170736     0.0381835   -0.0412481    0.066022    -0.00480005  -0.069335    -0.018916     0.106616    0.0320425   0.0507674    0.0910232     0.0266644    0.0623082    0.00378755  -0.0275861    0.00760426   -0.140629      0.100943    -0.07975     -0.153358  
  0.0967544    0.0601231   -0.0527825   0.0352063   -0.0321156   -0.0677512   -0.0345923    0.049944    -0.110323     0.0803215   -0.0354408    0.0391108    0.059037     0.0327431  -0.0663814   0.200238    -0.0992013    -0.00240219   0.130103    -0.0646821    0.0542055   -0.109435      0.110603     -0.103311     0.150705    -0.148003  
  0.0714105    0.13524     -0.0277455  -0.0963843   -0.103707     0.257441     0.0185919    0.00120785   0.118389     0.0221515   -0.131165    -0.122173     0.0664408   -0.13948    -0.0231992   0.0287444   -0.161987     -0.0694274    0.16555     -0.125732    -0.099549    -0.00196489    0.126075     -0.0749252   -0.0379469    0.0899013 
  0.203058     0.325593    -0.0891313  -0.0482223    0.040282    -0.0932171   -0.0473888    0.0693695   -0.114787    -0.0443449   -0.0608601    0.0454104   -0.0326978   -0.0379993   0.0290063  -0.00955815   0.00615064    0.0263878    0.00866523  -0.0669476   -0.114438    -0.0932619    -0.136383      0.1505      -0.0286613    0.0226474 
  0.0520457    0.211301     0.043237   -0.0942999    0.0682226    0.0725846    0.112381    -0.0417347   -0.137023    -0.117719    -0.105553    -0.0966165   -0.215242     0.118073    0.0490052   0.0788118   -0.137007      0.187024    -0.0334299    0.138702     0.00326368  -0.0499562    -0.0234801    -0.0915487    0.0161134    0.185695  
  0.0167475    0.207809     0.0652177  -0.114347     0.0696516   -0.0602928    0.0105988   -0.0412911    0.0749999    0.0513124   -0.00165139  -0.00782861   0.141879     0.0702929  -0.0772957   0.201948     0.049429     -0.124512     0.154812     0.110381     0.0534092   -0.0660262    -0.0186704     0.00726652  -0.134494     0.00860101
  0.0458286    0.0392255    0.0668777  -0.192335    -0.0590673    0.0221102    0.0418553   -0.0763787    0.0982852   -0.00222804  -0.0492717   -0.0895527   -0.0469278   -0.168683   -0.0839565   0.00393736  -0.115328      0.228038     0.00678982  -0.164764     0.152781     0.021315     -0.0438461     0.118067    -0.0834422   -0.137793  
 -0.10694      0.00281285   0.0622786  -0.0922047    0.100467     0.00501204   0.022257     0.128981    -0.0503383   -0.0932181    0.0583786    0.0240479   -0.100235     0.029362   -0.154154    0.0211208    0.0571794     0.0367924    0.0532198    0.0428126    0.00939284  -0.0469641     0.114765      0.00344683  -0.0760488    0.0753511 
 -0.117001     0.0718397   -0.118749    0.158567    -0.0303189   -0.044568    -0.0914348   -0.0114387    0.015253    -0.107697     0.0091296   -0.0547817   -0.0843073    0.161719   -0.118216   -0.0151509    0.0252997     0.0494602    0.0041191    0.12461      0.0159135   -0.0994612     0.104099      0.023841     0.0352919    0.0371685 
 -0.211093    -0.0369236   -0.119995   -0.246151     0.0309322   -0.01946     -0.065399     0.133211    -0.0642642    0.149719    -0.0757342    0.034805    -0.0629517    0.0181929   0.0185728   0.00520163  -0.180883     -0.123187    -0.267403     0.180441     0.0207602    0.0266329    -0.00410297    0.0174883   -0.0741999   -0.00905445
  0.306613     0.0962234    0.0035919  -0.126362     0.0446256    0.116962    -0.197012     0.103479    -0.15001      0.0465953   -0.173198     0.0144726    0.0867785   -0.13337     0.0100147  -0.0256258   -0.0493208    -0.0766464    0.123457     0.0080028    0.153845     0.0896664     0.216964      0.0429658    0.00837088   0.0172209 
  0.0758274   -0.0620818   -0.0740423   0.0191911    0.14413     -0.0499807   -0.0280968    0.109772    -0.0994303   -0.120781    -0.0428426   -0.0783709    0.0378652   -0.0313709   0.0354683   0.00254028   0.0855803    -0.0528869    0.0113568   -0.0828924   -0.0548625    0.00521462    0.161886     -0.0658835    0.00416221  -0.0984061 
  0.0514202    0.141939    -0.143883    0.191684     0.0314428   -0.148188    -0.0372914    0.130383    -0.187355    -0.0722839   -0.0119469   -0.0092911   -0.02145      0.134442   -0.107911    0.100948    -0.000700805  -0.028076     0.011035    -0.0225218    0.0604843    0.384358      0.159994     -0.130392    -0.0216633   -0.0357856 
 -0.172937     0.0963845   -0.0228656  -0.0551975    0.0394794    0.165816    -0.143183    -0.114715     0.162572    -0.0705029    0.0149551    0.0340562    0.0297152    0.139557    0.0912777   0.0859582   -0.0152098     0.260622     0.0818906    0.240094     0.0433209    0.207925      0.154534      0.0378921   -0.0943624    0.116637  
  0.0832244    0.0520844    0.0407915  -0.0587336   -0.00289107   0.212497     0.0493541   -0.0473877   -0.0618619    0.00875581   0.0668886   -0.0586338    0.0913501    0.0588712   0.0147572   0.0702756    0.101569      0.122116    -0.280331    -0.00402466   0.0631352   -0.0902966    -0.0811351     0.0424666    0.150893    -0.0211445 
 -0.04673     -0.175548     0.0194195   0.0344789    0.260198     0.0091974    0.185341     0.0564392   -0.134795    -0.164466     0.111157    -0.0172688   -0.0150696   -0.117035   -0.0583968   0.0255342   -0.0364009     0.108547     0.149286    -0.102461    -0.126846     0.0437817     0.0778377    -0.0728444   -0.125974    -0.13599   
  0.175631     0.11489     -0.0874321  -0.0228755   -0.145864    -0.169572     0.0160535   -0.00379277  -0.124598    -0.0730987    0.149907     0.00652075   0.0908878    0.0540209   0.0116321  -0.109611    -0.0908724    -0.0795268    0.0402293   -0.0163709   -0.0383627   -0.0150066    -0.0973717     0.031609     0.284345    -0.0607794 
 -0.0784713   -0.0192489    0.232809    0.00421628   0.0430699    0.0354332   -0.00596229  -0.0885541    0.212608    -0.0485131    0.0255836   -0.0985894    0.0660451   -0.0294234  -0.170195    0.0338546    0.146761     -0.0637308    0.187078    -0.0591067    0.067079     0.0124137     0.0311395    -0.0516908    0.123936     0.0589729 
  0.111155    -0.0666764    0.0677735  -0.035211     0.108939     0.0299934   -0.014306    -0.0122109   -0.00925518  -0.0768049   -0.153941    -0.155646     0.16684      0.0415488   0.0496117   0.11045      0.143015     -0.108748     0.0737095   -0.0528777    0.0280208   -0.115455      0.000351271  -0.0941056   -0.0261654   -0.210829  
  0.135333    -0.181219    -0.108867    0.0556219    0.125802    -0.214008    -0.0809222    0.162101     0.077984     0.0248312    0.185402     0.0460851    0.131582     0.0976496   0.0548379   0.135544     0.0767722    -0.024993    -0.0730879    0.0562198    0.31086      0.0554757     0.00493168    0.120544     0.161415     0.00842554
  0.0342462   -0.022928     0.0720374  -0.0626682    0.0441815    0.0277193   -0.0112112   -0.266679    -0.0341237    0.129548     0.142138    -0.0763693   -0.0653751   -0.0481926  -0.0371773   0.0277651   -0.0612756     0.0832838    0.0230603   -0.0508524   -0.0474911    0.0967224    -0.0815364     0.0859477   -0.126343    -0.0141517 
  0.0471721    0.0570222   -0.0562777  -0.19169      0.103579    -0.0699717   -0.00127745  -0.0530067    0.0494744   -0.04449      0.26893     -0.0289131   -0.0295503   -0.0735068  -0.0407122   0.0580828    0.0359374    -0.0871613   -0.141618     0.1854      -0.118449     0.0808338    -0.0245997     0.109165    -0.0831916   -0.00837427
  0.103689    -0.00533019  -0.0113784   0.201346    -0.0499335    0.102491     0.00710818   0.142242     0.0184246   -0.056883    -0.083397    -0.00970924   0.0562688   -0.0780869   0.0762719   0.0897985    0.00229728    0.0410521   -0.0158709    0.0742534    0.0481233   -0.114738     -0.0674401    -0.113716    -0.0340575    0.0933366 
  0.120271    -0.0120228    0.0129312  -0.0929211   -0.0467721    0.10432     -0.0444       0.157439    -0.132183    -0.0280169    0.0179205    0.101226    -0.0386848    0.128248   -0.0447633  -0.173017     0.131928     -0.074835    -0.0824802   -0.0893024    0.127152     0.0586958    -0.175115      0.0337196    0.0185891   -0.0610615 
 -0.0908494    0.184102    -0.108064    0.0680835   -0.00234941   0.135409    -0.00746669   0.103722    -0.18694     -0.18804      0.192944     0.0637888    0.0464926    0.0545646  -0.0223727  -0.153751     0.122333      0.0213576    0.00142346  -0.0726741    0.0145971   -0.0106619    -0.0473372    -0.0240323   -0.0909974    0.00838487
  0.0230987   -0.00363847  -0.0936842  -0.134456     0.0626765    0.0854407    0.101762    -0.0188461    0.0774121    0.0785221   -0.0604753   -0.0307284   -0.0222992   -0.0692248  -0.142997    0.0750434    0.0203269     0.103104     0.0246789   -0.0086621   -0.0555473   -0.000117516   0.0390983    -0.0176072    0.139243     0.11089   
 -0.0731218    0.216248     0.0951742  -0.0449007    0.106703    -0.00542157  -0.0658319    0.0418473   -0.00163511  -0.113718    -0.062639     0.178555     0.00336104   0.0315757  -0.183074   -0.0206795   -0.0156037    -0.119841     0.0981988   -0.0293172    0.1832      -0.190484      0.0880562     0.0301086    0.0217493    0.00739626
  0.0856205   -0.101475     0.0862011   0.0872782   -0.0430721   -0.0772263    0.022679    -0.0242478    0.0543761    0.103763    -0.0427222    0.0848047   -0.00849141  -0.070899    0.0349176  -0.0591864    0.0326954     0.164456    -0.037456    -0.0426124    0.0240838   -0.00928146    0.0723136    -0.00885425  -0.00994951  -0.0174034 
  0.102023     0.0234969    0.0866975   0.0293338    0.0492168    0.0439281   -0.0433146   -0.0715163    0.0556912    0.0989584   -0.00932998  -0.0280524    0.0308985   -0.118803    0.0401151   0.0924345    0.0613295    -0.142882    -0.166473    -0.00260083   0.107749     0.0591231    -0.0620339     0.0716132    0.0698236    0.0845253 
 -0.0809289    0.0154122    0.0370747  -0.0126089    0.134061    -0.118168     0.00103291   0.0898616    0.106458     0.131944     0.127992    -0.104174     0.173211    -0.0784802   0.0466251   0.0723208   -0.0589362    -0.133248     0.138327     0.0546923   -0.0882159    0.0281721    -0.182575     -0.0867432    0.0381072   -0.0379971 
  0.14233      0.0729608   -0.0884094   0.0257727    0.0778548   -0.0740982    0.147845    -0.0490826    0.180305    -0.0587818    0.10356     -0.0504772    0.0549057   -0.229314   -0.106303   -0.26638     -0.0900463     0.0811309    0.00203755   0.0780058   -0.0714675   -0.0158411    -0.0236956    -0.0761273    0.183274     0.0005734 
  0.00495349  -0.186024     0.0078192   0.0511947   -0.0992014    0.0687908   -0.115146     0.0113892   -0.037226    -0.0572647    0.0939338   -0.096694     0.124373    -0.0571354   0.0910284  -0.0620549    0.0513955    -0.0457738   -0.0761368    0.0990455    0.0667365    0.182996     -0.00933497    0.201918     0.00529081   0.0659864 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3682312120827613
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368271
[ Info: iteration 2, average log likelihood -1.368206
[ Info: iteration 3, average log likelihood -1.367580
[ Info: iteration 4, average log likelihood -1.361085
[ Info: iteration 5, average log likelihood -1.343385
[ Info: iteration 6, average log likelihood -1.335373
[ Info: iteration 7, average log likelihood -1.333050
[ Info: iteration 8, average log likelihood -1.331799
[ Info: iteration 9, average log likelihood -1.331206
[ Info: iteration 10, average log likelihood -1.330957
[ Info: iteration 11, average log likelihood -1.330832
[ Info: iteration 12, average log likelihood -1.330755
[ Info: iteration 13, average log likelihood -1.330698
[ Info: iteration 14, average log likelihood -1.330649
[ Info: iteration 15, average log likelihood -1.330596
[ Info: iteration 16, average log likelihood -1.330527
[ Info: iteration 17, average log likelihood -1.330410
[ Info: iteration 18, average log likelihood -1.330226
[ Info: iteration 19, average log likelihood -1.330008
[ Info: iteration 20, average log likelihood -1.329807
[ Info: iteration 21, average log likelihood -1.329652
[ Info: iteration 22, average log likelihood -1.329541
[ Info: iteration 23, average log likelihood -1.329463
[ Info: iteration 24, average log likelihood -1.329410
[ Info: iteration 25, average log likelihood -1.329373
[ Info: iteration 26, average log likelihood -1.329348
[ Info: iteration 27, average log likelihood -1.329330
[ Info: iteration 28, average log likelihood -1.329318
[ Info: iteration 29, average log likelihood -1.329309
[ Info: iteration 30, average log likelihood -1.329303
[ Info: iteration 31, average log likelihood -1.329299
[ Info: iteration 32, average log likelihood -1.329296
[ Info: iteration 33, average log likelihood -1.329293
[ Info: iteration 34, average log likelihood -1.329292
[ Info: iteration 35, average log likelihood -1.329291
[ Info: iteration 36, average log likelihood -1.329290
[ Info: iteration 37, average log likelihood -1.329289
[ Info: iteration 38, average log likelihood -1.329289
[ Info: iteration 39, average log likelihood -1.329289
[ Info: iteration 40, average log likelihood -1.329288
[ Info: iteration 41, average log likelihood -1.329288
[ Info: iteration 42, average log likelihood -1.329288
[ Info: iteration 43, average log likelihood -1.329288
[ Info: iteration 44, average log likelihood -1.329288
[ Info: iteration 45, average log likelihood -1.329288
[ Info: iteration 46, average log likelihood -1.329288
[ Info: iteration 47, average log likelihood -1.329288
[ Info: iteration 48, average log likelihood -1.329288
[ Info: iteration 49, average log likelihood -1.329288
[ Info: iteration 50, average log likelihood -1.329288
┌ Info: EM with 100000 data points 50 iterations avll -1.329288
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3682708356798812
│     -1.368205580298209 
│      ⋮                 
└     -1.329287968372794 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329395
[ Info: iteration 2, average log likelihood -1.329257
[ Info: iteration 3, average log likelihood -1.328640
[ Info: iteration 4, average log likelihood -1.324147
[ Info: iteration 5, average log likelihood -1.312075
[ Info: iteration 6, average log likelihood -1.304214
[ Info: iteration 7, average log likelihood -1.301264
[ Info: iteration 8, average log likelihood -1.299144
[ Info: iteration 9, average log likelihood -1.297318
[ Info: iteration 10, average log likelihood -1.295817
[ Info: iteration 11, average log likelihood -1.294591
[ Info: iteration 12, average log likelihood -1.293558
[ Info: iteration 13, average log likelihood -1.292685
[ Info: iteration 14, average log likelihood -1.292005
[ Info: iteration 15, average log likelihood -1.291559
[ Info: iteration 16, average log likelihood -1.291306
[ Info: iteration 17, average log likelihood -1.291160
[ Info: iteration 18, average log likelihood -1.291064
[ Info: iteration 19, average log likelihood -1.290991
[ Info: iteration 20, average log likelihood -1.290929
[ Info: iteration 21, average log likelihood -1.290873
[ Info: iteration 22, average log likelihood -1.290821
[ Info: iteration 23, average log likelihood -1.290771
[ Info: iteration 24, average log likelihood -1.290726
[ Info: iteration 25, average log likelihood -1.290686
[ Info: iteration 26, average log likelihood -1.290651
[ Info: iteration 27, average log likelihood -1.290622
[ Info: iteration 28, average log likelihood -1.290598
[ Info: iteration 29, average log likelihood -1.290577
[ Info: iteration 30, average log likelihood -1.290560
[ Info: iteration 31, average log likelihood -1.290547
[ Info: iteration 32, average log likelihood -1.290536
[ Info: iteration 33, average log likelihood -1.290527
[ Info: iteration 34, average log likelihood -1.290519
[ Info: iteration 35, average log likelihood -1.290513
[ Info: iteration 36, average log likelihood -1.290509
[ Info: iteration 37, average log likelihood -1.290504
[ Info: iteration 38, average log likelihood -1.290501
[ Info: iteration 39, average log likelihood -1.290498
[ Info: iteration 40, average log likelihood -1.290496
[ Info: iteration 41, average log likelihood -1.290493
[ Info: iteration 42, average log likelihood -1.290491
[ Info: iteration 43, average log likelihood -1.290490
[ Info: iteration 44, average log likelihood -1.290488
[ Info: iteration 45, average log likelihood -1.290486
[ Info: iteration 46, average log likelihood -1.290485
[ Info: iteration 47, average log likelihood -1.290483
[ Info: iteration 48, average log likelihood -1.290481
[ Info: iteration 49, average log likelihood -1.290480
[ Info: iteration 50, average log likelihood -1.290478
┌ Info: EM with 100000 data points 50 iterations avll -1.290478
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3293947414421865
│     -1.3292573832740227
│      ⋮                 
└     -1.2904781986437364
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290620
[ Info: iteration 2, average log likelihood -1.290458
[ Info: iteration 3, average log likelihood -1.289900
[ Info: iteration 4, average log likelihood -1.285158
[ Info: iteration 5, average log likelihood -1.268475
[ Info: iteration 6, average log likelihood -1.253105
[ Info: iteration 7, average log likelihood -1.246207
[ Info: iteration 8, average log likelihood -1.243136
[ Info: iteration 9, average log likelihood -1.241567
[ Info: iteration 10, average log likelihood -1.240419
[ Info: iteration 11, average log likelihood -1.239305
[ Info: iteration 12, average log likelihood -1.238204
[ Info: iteration 13, average log likelihood -1.237246
[ Info: iteration 14, average log likelihood -1.236491
[ Info: iteration 15, average log likelihood -1.235904
[ Info: iteration 16, average log likelihood -1.235415
[ Info: iteration 17, average log likelihood -1.234994
[ Info: iteration 18, average log likelihood -1.234595
[ Info: iteration 19, average log likelihood -1.234192
[ Info: iteration 20, average log likelihood -1.233752
[ Info: iteration 21, average log likelihood -1.233222
[ Info: iteration 22, average log likelihood -1.232526
[ Info: iteration 23, average log likelihood -1.231522
[ Info: iteration 24, average log likelihood -1.230049
[ Info: iteration 25, average log likelihood -1.228426
[ Info: iteration 26, average log likelihood -1.227136
[ Info: iteration 27, average log likelihood -1.226105
[ Info: iteration 28, average log likelihood -1.225293
[ Info: iteration 29, average log likelihood -1.224734
[ Info: iteration 30, average log likelihood -1.224419
[ Info: iteration 31, average log likelihood -1.224237
[ Info: iteration 32, average log likelihood -1.224097
[ Info: iteration 33, average log likelihood -1.223971
[ Info: iteration 34, average log likelihood -1.223851
[ Info: iteration 35, average log likelihood -1.223734
[ Info: iteration 36, average log likelihood -1.223623
[ Info: iteration 37, average log likelihood -1.223524
[ Info: iteration 38, average log likelihood -1.223444
[ Info: iteration 39, average log likelihood -1.223379
[ Info: iteration 40, average log likelihood -1.223326
[ Info: iteration 41, average log likelihood -1.223283
[ Info: iteration 42, average log likelihood -1.223248
[ Info: iteration 43, average log likelihood -1.223217
[ Info: iteration 44, average log likelihood -1.223189
[ Info: iteration 45, average log likelihood -1.223160
[ Info: iteration 46, average log likelihood -1.223131
[ Info: iteration 47, average log likelihood -1.223100
[ Info: iteration 48, average log likelihood -1.223069
[ Info: iteration 49, average log likelihood -1.223037
[ Info: iteration 50, average log likelihood -1.223002
┌ Info: EM with 100000 data points 50 iterations avll -1.223002
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2906204222231805
│     -1.2904582805034976
│      ⋮                 
└     -1.2230020055743192
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.223130
[ Info: iteration 2, average log likelihood -1.222856
[ Info: iteration 3, average log likelihood -1.220374
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.194461
[ Info: iteration 5, average log likelihood -1.177118
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      9
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.142197
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.164332
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.144640
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.146323
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.143436
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.153760
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.151775
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.148127
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.150827
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.154770
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.132372
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.158767
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.139625
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.139588
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.153270
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.153966
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.131470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.159099
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.140709
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.141543
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.145470
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.149460
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.136562
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.160343
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.141447
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.142615
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.147073
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.151599
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.129086
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.155936
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.146518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.143802
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.147741
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.152502
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.130374
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.157587
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.138388
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.138440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.151258
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.151836
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.129133
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.156797
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.138327
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.139212
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.143043
┌ Info: EM with 100000 data points 50 iterations avll -1.143043
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2231299776256144
│     -1.22285624136246  
│      ⋮                 
└     -1.1430426719886815
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.147257
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.121715
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.145481
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.103542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088844
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.053636
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.078849
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.067573
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     12
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079120
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.052998
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.076699
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.045405
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.089975
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056364
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     12
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067273
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.051556
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│     12
│     14
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.056236
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.054659
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.065155
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.040633
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│     11
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.064465
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.046216
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.064846
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.037226
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.067281
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.037544
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.078568
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.044378
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.046195
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.060650
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073258
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.046134
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.050964
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.075460
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066916
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.039751
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.063886
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057435
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.071241
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.044493
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063947
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.064806
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.063110
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.045024
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.060710
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067705
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     15
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.054260
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.058161
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     11
│     12
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.067627
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.047006
┌ Info: EM with 100000 data points 50 iterations avll -1.047006
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1472568548609656
│     -1.121714584831162 
│      ⋮                 
└     -1.0470062883034057
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3682312120827613
│     -1.3682708356798812
│     -1.368205580298209 
│     -1.3675800706881456
│      ⋮                 
│     -1.058160685162969 
│     -1.0676269551460906
└     -1.0470062883034057
32×26 Array{Float64,2}:
 -0.00578852   0.027784     0.0362923  -0.0309849    0.0606482    0.0158006     0.0152088    0.0227446    0.0306927    0.0221427    0.110672    -0.0453601    0.137858     0.00229032   0.0202667   0.0661391    0.0207403   -0.00679609   -0.0665479    0.0272519    -0.0124944   -0.0202145   -0.199425     -0.010023     0.10054     -0.0475372 
 -0.0741311    0.109496     0.0249026  -0.0967447    0.0701753    0.0262833    -0.0363114   -0.0128711    0.078952    -0.0265266    0.0259702    0.0180749    0.0376359    0.0913477   -0.0570431   0.0973468    0.0358228    0.0637443     0.0811295    0.121306      0.0321972    0.0433036    0.0603704     0.0194535   -0.104881     0.0669806 
  0.0430819    0.0572796   -0.0616255  -0.189764     0.0919195   -0.124929     -0.00903869  -0.0495563    0.0464218   -0.0500883    0.265587    -0.031649    -0.0314566   -0.0606572   -0.0467793   0.0468921    0.0218476   -0.0833345    -0.152451     0.177591     -0.10835      0.0566633   -0.0355055     0.0963505   -0.0859401   -0.00776581
  0.090432     0.0274627    0.0863505   0.0387329    0.0359951    0.0408348    -0.0416854   -0.0700095    0.01729      0.0939144   -0.0193806    0.00279262  -0.0153208   -0.137449     0.0390325   0.0913846    0.065656    -0.116848     -0.182464     0.0138021     0.0998747    0.0470345   -0.038626      0.0825383    0.0618246    0.0777477 
 -0.0825423    0.21476     -0.104479    0.0638658   -0.127554     0.13558      -0.0170464    0.0814132   -0.198133    -0.144166     0.187041     0.065344     0.180993     0.114672    -0.397969   -0.127797     0.121726     0.106447     -0.00168308  -0.0714346     0.0141983   -0.246191    -0.0138252     0.00641833  -0.0629817    0.0429478 
 -0.124735     0.162162    -0.117113    0.0584347    0.0855893    0.135488     -0.013297     0.120575    -0.137036    -0.203464     0.193298     0.0830956   -0.038244     0.0101677    0.429948   -0.183165     0.121391    -0.0808057    -0.0034397   -0.0702863     0.0229216    0.234065    -0.0693205    -0.0433023   -0.107729    -0.0127576 
  0.110762     0.21742     -0.113227    0.0618073    0.0188277   -0.122501     -0.0340436    0.111204    -0.169292    -0.0886509   -0.0235373    0.0207999   -0.0336917    0.0661355   -0.0425728   0.0393418    0.00719954   0.00390495    0.0137922   -0.0349359    -0.0367227    0.102561     0.0302936    -0.00252544  -0.0282531   -0.00894793
  0.00670909   0.0955586   -0.0271789  -0.093792    -0.102086     0.239406      0.0166775    0.00746236   0.110761     0.0273285   -0.108885    -0.111751     0.0460878   -0.103455    -0.0227774   0.0181672   -0.149745    -0.0751591     0.120984    -0.125299     -0.0890648   -0.0108319    0.129694     -0.0633361   -0.0438924    0.0933747 
  0.140948     0.111832    -0.440433   -0.0733023   -0.247569    -0.178346      0.0169436    0.0264169   -0.029022    -0.0702784    0.159217    -0.00144092   0.194576    -0.0911855    0.0059013  -0.081606    -0.113327    -0.039294      0.0294469    0.0102339    -0.0256283   -0.0167523   -0.104778      0.0575179    0.315735     0.0542589 
  0.292057     0.114495     0.323723    0.0324337   -0.0342683   -0.160312      0.018085    -0.0319849   -0.180046    -0.0735175    0.146789    -0.00842921   0.0438775    0.145884     0.0213786  -0.143832    -0.0675659   -0.152075      0.065224    -0.0646312    -0.061316    -0.00811862  -0.0883698    -0.0044891    0.29907     -0.239201  
  0.242265     0.067527    -0.027832    0.154148    -0.0291654    0.00324602   -0.034757    -0.0705254   -0.119119    -0.274535     0.016606    -0.131186    -0.0457796    0.0562901    0.0473866   0.22501     -0.0378787   -0.00197688    0.00295305  -0.0664613     0.0394981   -0.108878     0.096842     -0.0971916    0.147974    -0.10847   
 -0.0434507    0.0601221   -0.102942   -0.0571269   -0.0138434   -0.128051     -0.0346285    0.189561    -0.140543     0.410268    -0.0845634    0.242964     0.143432     0.0711067   -0.142236    0.16409     -0.106318    -0.0219526     0.192481    -0.0686683     0.0542562   -0.108697     0.129008     -0.098435     0.146087    -0.202914  
  0.0205072    0.114448    -0.0638986   0.0878938   -0.0691823   -0.100657     -0.161759     0.0408002   -0.0438621    0.0700504    0.00494655  -0.0571142   -0.0302784    0.105805     0.039074    0.0514063    0.0754848    0.0390988     0.0591335    0.00438988   -0.0402375    0.010256    -0.123276      0.0855628   -0.085021    -0.148265  
 -0.0906843   -0.175468     0.0202001   0.0551859    0.274227     0.00932811    0.213633     0.060755    -0.136449    -0.166551     0.141209    -0.0313714   -0.0121599   -0.127729    -0.0679014   0.0261544   -0.0276915    0.101022      0.120388    -0.0969145    -0.120006     0.0437737    0.0793013    -0.0731066   -0.126352    -0.136008  
 -0.0616041    0.21548      0.0862272  -0.0403069    0.120991     0.000324258  -0.0741068    0.0414384   -0.0308853   -0.106094    -0.0555905    0.203376    -0.0085246    0.0362769   -0.181675   -0.0124151    0.0305114   -0.103164      0.0952585   -0.03097       0.183516    -0.190939     0.101107      0.0311741    0.0160717    0.00350569
  0.0426244   -1.42479e-5  -0.0829804  -0.125824     0.0609302    0.0794088     0.103744    -0.0260608    0.0609642    0.0688226   -0.0485454   -0.0312616   -0.00725384  -0.039711    -0.147237    0.0791153    0.0286792    0.110305      0.0200052    0.0107383    -0.0483565    0.0118395    0.0384981     0.0130713    0.12758      0.10743   
  0.106908    -0.00575717  -0.0168347   0.227603    -0.0728814    0.0773472    -0.00528054   0.14632      0.00955629  -0.040976    -0.0613791    0.00733366   0.0562093   -0.0773611    0.0751502   0.100144     0.0236307    0.0348635    -0.00936753   0.0796398     0.0853419   -0.113556    -0.0742238    -0.111929    -0.043785     0.085911  
 -0.116036     0.0766911   -0.140001    0.158168    -0.0636714   -0.0205075    -0.08585     -0.00698105   0.016003    -0.111458     0.00602981  -0.0602666   -0.086789     0.159272    -0.135253   -0.0139957    0.0246511    0.0515493     0.00156483   0.147573     -0.0111496   -0.100804     0.103789      0.0305406    0.0279676    0.0408254 
  0.172437    -0.074281    -0.0536714   0.140442     0.228452    -0.00329446   -0.0230066    0.144407    -0.0179973   -0.0906134   -0.0577248   -0.0303525   -0.0334647    0.172337    -0.074709   -0.00564126   0.00997248   0.083085     -0.00519592  -0.0470765    -0.0424885   -0.0986294    0.154873     -0.139198     0.0266377    0.022544  
  0.0765013   -0.0594709   -0.0736442   0.00879789   0.140187    -0.0573291    -0.0249613    0.108196    -0.0995581   -0.119541    -0.0422792   -0.0793204    0.0391664   -0.0234997    0.052262    0.0585999    0.0752306   -0.0540691     0.0590889   -0.0909714    -0.0511096    0.00844965   0.164085     -0.0636184    0.00506337  -0.0964546 
  0.152937     0.0742725   -0.102587    0.022896    -0.00532029   0.0320691     0.138261    -0.0328451    0.154437    -0.26149      0.0990367   -0.0916059    0.0521674   -0.217351    -0.103259   -0.146111    -0.223267     0.161556      0.0964891    0.220271     -0.0268696   -0.0769214   -0.0218544    -0.0318877    0.187564    -0.418355  
  0.189058     0.0841606   -0.076817    0.0647244    0.120115    -0.0905205     0.151294    -0.0416736    0.229026     0.0912125    0.0508304   -0.00448475   0.0619632   -0.229122    -0.0861448  -0.401237     0.0316509   -0.000699698  -0.0791455   -0.1676       -0.0976645    0.0250044   -0.029916     -0.105015     0.180939     0.371409  
  0.0310185   -0.0933703    0.0712217   0.0232171    0.0200728   -0.0138474     0.0120405   -0.125964    -0.0216178    0.120703     0.0566312    0.00385022  -0.0311203   -0.0604996    0.0190219  -0.0345093   -0.0268999    0.129006      0.00720549  -0.0791885     0.00479533   0.0618418   -0.000893941   0.0206714   -0.102907     0.00278597
  0.0649144    0.187295     0.0512827  -0.0745423    0.0621612    0.0902573     0.0762269   -0.0685504   -0.150174    -0.104054    -0.0924807   -0.100866    -0.201144     0.092157     0.0537786   0.100373    -0.137474     0.185168     -0.0149199    0.143111     -0.0223118   -0.0375624   -0.0191925    -0.0780155    0.00817356   0.161792  
  0.0484526   -0.00995181   0.0665976  -0.233444    -0.0629671    0.0241625     0.035003    -0.0800847    0.08862     -0.00458711  -0.0476047   -0.104941    -0.0159344   -0.172319    -0.0807551   0.0259852   -0.103665     0.203366      0.0120548   -0.165306      0.158564     0.0385256   -0.0424636     0.108099    -0.0880103   -0.111126  
 -0.141109    -0.0192548    0.0715278  -0.105851     0.0374166   -0.00265821   -0.0325118    0.0508818    0.0903838    0.0494717   -0.0240749   -0.0531004    0.00431609  -0.00518365  -0.0667911   0.0329821   -0.00608965  -0.095505     -0.0190858    0.0449322     0.0399464    0.0274055    0.0112429     0.00405124   0.0280049    0.0391428 
  0.142608    -0.0556472    0.066746   -0.0337072    0.107836     0.03926       0.0200534    0.00125559  -0.0143346   -0.0720889   -0.155227    -0.130066     0.118308     0.0716879   -0.0163984   0.0675949    0.124425    -0.0994124     0.0657735   -0.0220075     0.0465527   -0.0852857   -0.0355253    -0.0943537   -0.0250172   -0.182897  
  0.0423936   -0.0955429    0.0137611  -0.0111876   -0.0974112    0.0903388    -0.069092     0.0957455   -0.0807541   -0.0316042    0.0969103    0.00653227   0.0563731    0.00950055   0.0455168  -0.114781     0.0891093   -0.0554152    -0.0825237    0.0241152     0.0819239    0.124623    -0.0713261     0.159343     0.0227517    0.0128942 
  0.307191     0.0780361    0.0764938  -0.12628      0.00754557   0.161137     -0.218618     0.201915    -0.17096      0.0480877   -0.364681    -0.0320085    0.221073    -0.104793    -0.0809841  -0.0218943   -0.0766026   -0.0774154     0.128836     0.00446384    0.244559     0.0925118    0.247359      0.0507205    0.00591765   0.0164714 
  0.310674     0.0856803   -0.145535   -0.145809     0.171616     0.0749352    -0.23188     -0.347191    -0.0969234    0.0561788    0.477961     0.371511    -0.295506    -0.190731     0.315201   -0.00281402   0.0711222   -0.0591689     0.140253     0.000140894  -0.157209     0.0855267    0.140282      0.0497615    0.00721809   0.0169797 
  0.124055    -0.159381    -0.102967    0.0676927    0.130942    -0.210951     -0.0801641    0.161859     0.0756136    0.0227237    0.184863     0.0404215    0.133836    -0.132846    -0.147961    0.137403     0.0316033   -0.0311093    -0.0333597    0.174919      0.309557    -0.0643352    0.00713231    0.129923     0.160846    -0.250983  
  0.131451    -0.214696    -0.0960805   0.0706061    0.117867    -0.20049      -0.239782     0.162935     0.0752157    0.0242653    0.175206     0.0666208    0.120879     0.509697     0.636223    0.137407     0.142643    -0.00317062   -0.182063    -0.0883095     0.311047     0.191949    -0.00396039    0.140596     0.16105      0.470189  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     12
│     13
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.068506
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.034373
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.047728
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.044314
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.047048
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.029994
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062130
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.035895
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      6
│      8
│      ⋮
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.048860
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044203
┌ Info: EM with 100000 data points 10 iterations avll -1.044203
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.228454e+05
      1       6.202452e+05      -2.026002e+05 |       32
      2       5.976896e+05      -2.255556e+04 |       32
      3       5.847006e+05      -1.298898e+04 |       32
      4       5.757572e+05      -8.943438e+03 |       32
      5       5.698770e+05      -5.880185e+03 |       32
      6       5.669418e+05      -2.935268e+03 |       32
      7       5.652882e+05      -1.653551e+03 |       32
      8       5.639353e+05      -1.352879e+03 |       32
      9       5.624812e+05      -1.454087e+03 |       32
     10       5.612615e+05      -1.219713e+03 |       32
     11       5.605680e+05      -6.934765e+02 |       32
     12       5.601122e+05      -4.558111e+02 |       32
     13       5.597610e+05      -3.512871e+02 |       32
     14       5.595034e+05      -2.575460e+02 |       32
     15       5.592940e+05      -2.093619e+02 |       32
     16       5.591222e+05      -1.718387e+02 |       32
     17       5.589983e+05      -1.238780e+02 |       32
     18       5.589021e+05      -9.621556e+01 |       32
     19       5.587978e+05      -1.043487e+02 |       32
     20       5.587121e+05      -8.565029e+01 |       31
     21       5.586540e+05      -5.815841e+01 |       31
     22       5.586152e+05      -3.871303e+01 |       32
     23       5.585850e+05      -3.024708e+01 |       31
     24       5.585639e+05      -2.112331e+01 |       31
     25       5.585500e+05      -1.388007e+01 |       30
     26       5.585421e+05      -7.900027e+00 |       28
     27       5.585369e+05      -5.140527e+00 |       27
     28       5.585343e+05      -2.691205e+00 |       28
     29       5.585320e+05      -2.301883e+00 |       19
     30       5.585301e+05      -1.843007e+00 |       27
     31       5.585279e+05      -2.196797e+00 |       23
     32       5.585266e+05      -1.267103e+00 |       19
     33       5.585249e+05      -1.716221e+00 |       17
     34       5.585237e+05      -1.251693e+00 |       16
     35       5.585231e+05      -6.044198e-01 |       15
     36       5.585225e+05      -6.022301e-01 |       18
     37       5.585219e+05      -6.104082e-01 |       13
     38       5.585215e+05      -4.009213e-01 |       11
     39       5.585213e+05      -2.035255e-01 |        5
     40       5.585211e+05      -1.613739e-01 |        9
     41       5.585208e+05      -3.089135e-01 |        7
     42       5.585205e+05      -3.214906e-01 |        6
     43       5.585202e+05      -2.399681e-01 |        4
     44       5.585201e+05      -1.254467e-01 |        2
     45       5.585201e+05      -1.921157e-02 |        0
     46       5.585201e+05       0.000000e+00 |        0
K-means converged with 46 iterations (objv = 558520.0835148559)
┌ Info: K-means with 32000 data points using 46 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.286061
[ Info: iteration 2, average log likelihood -1.258245
[ Info: iteration 3, average log likelihood -1.230375
[ Info: iteration 4, average log likelihood -1.192830
[ Info: iteration 5, average log likelihood -1.144910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.093973
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054134
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050604
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076464
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063499
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.039836
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.037459
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.010807
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.023002
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.038008
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.021504
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     21
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.001106
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.062317
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.026186
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.004504
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.042685
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.046934
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.023545
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.015901
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.031959
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.037631
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.016300
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.014563
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.032037
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.037846
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.016497
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.015046
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.032351
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.038440
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.017493
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.016108
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.033055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.039683
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.020226
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.018214
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.034219
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.039406
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.016669
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     11
│     15
│     16
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.977637
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.060171
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.059358
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.025710
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     15
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.985412
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     11
│     16
│     17
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.017603
[ Info: iteration 50, average log likelihood -1.085866
┌ Info: EM with 100000 data points 50 iterations avll -1.085866
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.124102    -0.139019     -0.0940829    0.0509562    0.122002    -0.184973    -0.113891     0.148029      0.0678982    0.0231483    0.178336     0.0443537    0.118985     0.0744565    0.112035      0.123433     0.0685373    -0.0170902   -0.0810367     0.0679719    0.278826    0.0281706    0.0124229    0.117454      0.142718     0.0130844 
 -0.0811366    0.00544618    0.0224022   -0.00524278   0.136148    -0.12278      0.00154158   0.0601596     0.0966103    0.0857943    0.133775    -0.0519393    0.170044    -0.0400676    0.0177793     0.0720796   -0.0598138    -0.128538     0.12746       0.0457204   -0.0765733   0.04415     -0.167308    -0.0471778     0.0217443   -0.0428822 
  0.0335509   -0.146592      0.0808475    0.123917    -0.0136364   -0.071432     0.0192613   -0.0570705     0.00504816   0.121997    -0.0397146    0.0688928   -0.0376529   -0.0680754    0.0343411    -0.0881333    0.0229063     0.174477    -0.0260482    -0.0487284    0.0327069   0.00278889   0.0706238   -0.0345268    -0.0541316    0.00969854
  0.0476776    0.0604861    -0.0638578   -0.177715     0.0808099   -0.132417    -0.0197997   -0.0495136     0.043874    -0.0508075    0.249939    -0.030457    -0.0321298   -0.0515772   -0.0500895     0.0473377    0.024169     -0.0842025   -0.133971      0.176829    -0.102648    0.0521551   -0.0258493    0.0932284    -0.0866881   -0.0129592 
  0.189893     0.31414      -0.0852241   -0.0505098    0.0319007   -0.0938376   -0.039512     0.0729513    -0.119905    -0.0421418   -0.0328266    0.0443962   -0.0218904   -0.00692472   0.0229838    -0.0149742    0.00669439    0.0309451    0.0252037    -0.065428    -0.124763   -0.108991    -0.110516     0.147577     -0.0283576    0.0262237 
  0.0807007    0.210965      0.0477564   -0.0791932    0.0555487    0.0870789    0.0862505   -0.0613982    -0.142147    -0.125142    -0.106817    -0.0997233   -0.201472     0.0884046    0.0417835     0.109284    -0.153749      0.181466    -0.0153807     0.11066     -0.0246056  -0.0587175   -0.0192595   -0.0879454     0.0226592    0.17233   
  0.281926     0.102397      0.0462897   -0.143564     0.0475646    0.187565    -0.261118     0.103722     -0.154549     0.0226233   -0.225853     0.067663     0.0991776   -0.0617079    0.0566829    -0.0174162   -0.149844     -0.0769681    0.111843      0.00793545   0.199071    0.00578133   0.263011     0.0627418     0.00777769   3.23294e-5
  0.0511749   -0.0263321     0.0585118   -0.0851639    0.0432105    0.0622531   -0.0228228   -0.176709     -0.0591953    0.109779     0.143782    -0.0833888   -0.0460528   -0.0374313   -0.0106252     0.0262272   -0.0510625     0.0801953    0.0494252    -0.0739408   -0.0299238   0.104616    -0.0710221    0.0852682    -0.13023     -0.0232152 
  0.0831482    0.0576671     0.0615995   -0.0597631   -0.0404709    0.264505     0.072747    -0.00629498   -0.0882119   -0.023142     0.103537    -0.0990219    0.0201858    0.0284247   -0.000529762  -0.0524381    0.0992518     0.107121    -0.245593     -0.0211722    0.0468368  -0.181909     1.50626      0.0129914     0.18738      0.0445021 
  0.0833454    0.0494583     0.038647    -0.0587892    0.00830024   0.180208     0.0159375   -0.0211844    -0.0585003   -0.0777424    0.0822964   -0.00778043   0.118392     0.0494244    0.0197539     0.10604      0.0954808     0.134039    -0.309557      0.00851435   0.0570609  -0.0557115   -1.11671      0.0475257     0.164195    -0.0744569 
  0.155595    -0.0259292     0.0739424   -0.0362564    0.0954208    0.0527517    0.00860511   0.0159114    -0.0297613   -0.136561    -0.223696    -0.144451     0.175432     0.0263626    0.00439191    0.0465091    0.138187     -0.118641     0.0727566    -0.0216012    0.0259324  -0.0816827    0.0406278   -0.101181     -0.036924    -0.124631  
  0.114103     0.000202488   0.0136844   -0.0742229   -0.0547273    0.106891     0.00891934   0.144792     -0.0949908   -0.00274955  -0.0039262    0.101851    -0.0237312    0.110606    -0.0424167    -0.14049      0.132291     -0.0681989   -0.066394     -0.0847383    0.102914    0.0556154   -0.16423      0.0320451     0.014768    -0.0573999 
  0.0464618    0.00674869    0.0672527   -0.220839    -0.0619928    0.0243082    0.0296616   -0.0768206     0.0956779   -0.00798492  -0.0503164   -0.101144    -0.0161333   -0.167163    -0.0891897     0.0163134   -0.0887903     0.211688     0.0148215    -0.160781     0.159094    0.027915    -0.0461073    0.105315     -0.0850879   -0.108907  
 -0.215157    -0.0396749    -0.119258    -0.227623     0.0349404   -0.0323271   -0.0646073    0.127195     -0.065306     0.135333    -0.0758275    0.00495036  -0.0584677    0.0191558    0.033996      0.00240747  -0.173991     -0.12813     -0.256246      0.13834      0.0108076   0.040168     0.008873     0.0290056    -0.0648992   -0.0130492 
  0.105934     0.0744905    -0.0528108    0.0673575   -0.0153115   -0.0632649   -0.041927     0.0514365    -0.121688     0.0957048   -0.0397214    0.109428     0.0514895    0.058142    -0.103323      0.17582     -0.130613     -0.00419376   0.0927515    -0.0571536    0.0599919  -0.0985568    0.108018    -0.0853234     0.120265    -0.122412  
 -0.0411801    0.193313      0.203087    -0.0417795    0.110117    -0.0270591   -0.0854104    0.0398657    -7.2707e-5   -0.0562285   -0.061843     0.22554     -0.0205605    0.0464632   -0.248724     -0.0142934    0.108651     -0.125447     0.0906396    -0.0250595    0.18307    -0.128531     0.111688     0.0541273     0.0256586   -0.0227757 
  0.112255     0.0383808     0.0781641    0.0373567    0.0382547    0.0687734   -0.0182735   -0.071596      0.0476661    0.11452     -0.0132843    0.0286875   -0.0835545   -0.135828     0.0908394     0.0630021    0.0815327    -0.121876    -0.155949      0.00576839   0.115293    0.0875583   -0.006396     0.146357      0.0531113    0.0616818 
  0.0403786    0.138449     -0.143777     0.187989    -0.00602543  -0.152765    -0.0342821    0.141012     -0.208752    -0.130243    -0.00884464  -0.0102586   -0.0320217    0.150617    -0.111123      0.10529     -0.000936481  -0.0337513    0.00320255   -0.0186766    0.0537921   0.338044     0.171216    -0.153108     -0.0231486   -0.043421  
  0.0193986    0.170404      0.0694727   -0.112483     0.0686883   -0.0765212    0.0208076   -0.0272669     0.0718854    0.0571362   -0.0152029   -0.00277373   0.146351     0.0654695   -0.0731856     0.210921     0.0413472    -0.117348     0.148249      0.0878851    0.0517804  -0.0680967   -0.0475426    0.00929867   -0.133751     0.0242254 
 -0.0286315    0.070587     -0.00443269  -0.0706326   -0.0470734    0.175809     0.0183091    0.0437182     0.0672802   -0.023763    -0.0504955   -0.0624338    0.00862803  -0.0607132   -0.0827273     0.00602484  -0.0645547    -0.0311011    0.108229     -0.0780495   -0.0651063  -0.0248039    0.113769    -0.0408416    -0.0465672    0.0727126 
 -0.080331     0.174747     -0.0955011    0.0572665    0.00481956   0.111157    -0.0182717    0.0843346    -0.27048     -0.169042     0.205979     0.101995     0.098193     0.0448382    0.00337889   -0.142589     0.131151      0.0409114    0.00543693   -0.0509659    0.0449544  -0.00974575  -0.0562138   -0.0155586    -0.091378     0.0224195 
 -0.00334249  -0.166216      0.00177827   0.0477551   -0.100257     0.0724479   -0.111317     0.0223353    -0.0579819   -0.0459785    0.1176      -0.110763     0.121342    -0.077421     0.100697     -0.0751583    0.054217     -0.0233312   -0.0680357     0.105319     0.0634869   0.148467    -0.00906883   0.197532      0.00515133   0.0505895 
 -0.0741079   -0.17104       0.021517     0.0517617    0.265201     0.00843056   0.201532     0.0592915    -0.137484    -0.161318     0.133243    -0.0325606   -0.0106673   -0.123503    -0.064255      0.0276221   -0.0288862     0.0955543    0.119667     -0.0947624   -0.118823    0.0432006    0.080938    -0.0727791    -0.122939    -0.131211  
  0.212893     0.113426     -0.0788333   -0.02583     -0.145257    -0.170568     0.0171006   -0.000945631  -0.0994024   -0.0723794    0.153754    -0.00362991   0.121369     0.020993     0.0128412    -0.110418    -0.0917271    -0.0945476    0.0458805    -0.0252662   -0.0419844  -0.0138992   -0.0974752    0.0283491     0.308269    -0.0843458 
 -0.0774794   -0.00880747    0.23179      0.0179847    0.0398328    0.0323602   -0.004484    -0.0157113     0.219782    -0.0436198    0.0232366   -0.0988524    0.0667272   -0.0253702   -0.162041      0.0646948    0.141549     -0.0592476    0.194831     -0.0633258    0.0714896   0.0112419    0.0324265   -0.0353152     0.117702     0.0810988 
 -0.166902     0.112888     -0.0457251   -0.075986     0.0587167    0.155822    -0.125361    -0.0947095     0.152834    -0.0795424    0.0179307    0.0259989    0.0188396    0.157184     0.0626893     0.0335078   -0.00825499    0.21454      0.0477579     0.229634     0.036741    0.198446     0.15405      0.000272249  -0.0966878    0.105674  
  0.0369948    0.108603     -0.0795657    0.0659786   -0.0350932   -0.0880511   -0.178416     0.0321771    -0.0374463    0.0692561    0.0630292   -0.0806763   -0.0259488    0.0947587    0.0548558     0.0723823    0.136808      0.0269904    0.0671363     0.0100326   -0.0455442  -0.00859783  -0.20525      0.0931482    -0.0876934   -0.126939  
  0.0945544   -0.0202574    -0.0652253    0.0205694    0.116072    -0.0585879   -0.0251364    0.0949783    -0.0944695   -0.115867    -0.0429077   -0.0639445    0.0251461    0.00916322   0.0390055     0.0813091    0.0764597    -0.0579779    0.0611565    -0.0781429   -0.0245572  -0.0214291    0.148575    -0.0604065     0.0199632   -0.0858637 
 -0.22215      0.0675061    -0.158884     0.142927    -0.0493593   -0.06696     -0.112203     0.00747065    0.00742289  -0.0923476    0.00116019  -0.0846553   -0.0801279    0.147561    -0.122334     -0.013035     0.0223091     0.0431562   -0.00240474    0.157557    -0.0148227  -0.0958501    0.104061     0.0263666     0.0326435    0.0194212 
  0.11165     -0.00682429   -0.0182596    0.21761     -0.0548973    0.0641827   -0.00871085   0.143597      0.00157478  -0.0474043   -0.0598996    0.00337007   0.0545388   -0.0729592    0.0780841     0.10032      0.0388319     0.0321914   -0.000896979   0.068798     0.0729829  -0.110431    -0.0542529   -0.108002     -0.0357073    0.0718574 
  0.169603     0.0779147    -0.0902977    0.0472773    0.0576411   -0.0341166    0.145269    -0.0377062     0.193928    -0.0797372    0.0746739   -0.045741     0.0566469   -0.224218    -0.0950167    -0.283359    -0.087102      0.0786448    0.00349061    0.0160507   -0.0647837  -0.0307982   -0.0254828   -0.0710752     0.184214    -0.00658518
  0.0344869    0.00367915   -0.0858675   -0.125111     0.0637163    0.0795435    0.101262    -0.0229207     0.0655857    0.0640836   -0.0472727   -0.031788    -0.00632968  -0.0402609   -0.146127      0.078773     0.0279759     0.109012     0.0219074     0.0108929   -0.0439885   0.00705586   0.0392448    0.0107845     0.131314     0.106853  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.031968
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     15
│     20
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.973375
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     16
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.977635
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     15
│     20
│     21
│     23
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.980005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.005351
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│     11
│     15
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.947864
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.015143
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     15
│     20
│     21
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.967202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     16
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.985336
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     15
│     20
│     23
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.984261
┌ Info: EM with 100000 data points 10 iterations avll -0.984261
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.201661    -0.100033     0.0562218   0.0145607   -0.0533879    0.244141     0.0466278    0.201547    -0.0766167    0.227381     0.0666144    0.0588622   -0.104968    -0.0912833   0.0208432    -0.0277736    0.00944019   0.0737233    0.149868     0.0936831   -0.0332329   -0.117398    0.252996      0.0350351    -0.0573213   -0.0145581
 -0.0917622    0.0363579    0.0513199  -0.059228     0.0199013    0.20746     -0.0911024    0.137557    -0.137563     0.0746989    0.0271219   -0.141942     0.086499     0.0237934   0.103773      0.134249    -0.0573374    0.125979    -0.115327     0.299747    -0.0746698   -0.0351584   0.0618841     0.00533888   -0.00373084   0.0216091
  0.0387972    0.134664     0.035963    0.107949    -0.0539461    0.0167602   -0.0626631    0.0408285    0.0558002   -0.100024     0.164559    -0.00903983   0.066366    -0.0499497   0.306044      0.026253     0.164398     0.142939     0.0505987   -0.155019    -0.0986703    0.176757   -0.148349      0.0427335    -0.0116049    0.0436955
  0.0319239    0.0322203    0.147634   -0.0266556    0.0729682   -0.0691521   -0.0087339   -0.0244017    0.119553     0.175497    -0.0160425    0.187141     0.124445     0.164887    0.000455123  -0.14957     -0.202736    -0.018858     0.0175406   -0.301598     0.114025    -0.0294206  -0.000260722  -0.0461265     0.0265954    0.061622 
  0.0663737   -0.207264    -0.0408763  -0.039176    -0.0679843   -0.0398667   -0.0195993    0.0721605    0.158345    -0.164725     0.0705534    0.0953634    0.00827049  -0.162663    0.0169315    -0.056348    -0.0799968    0.118002    -0.0228666    0.0150929   -0.0416499   -0.0988798   0.0643638    -0.18965      -0.0623494   -0.0973349
 -0.0352595    0.0936368   -0.068302   -0.101643     0.0101606   -0.0240314    0.0490846   -0.0238872   -0.0342966   -0.0440199    0.032344    -0.0388974   -0.0843916   -0.0270929   0.183667      0.222862     0.00757424   0.0382068    0.0879806    0.117193     0.138        0.0877948  -0.128257      0.068622     -0.181249     0.110249 
  0.177797    -0.0378385   -0.0602981  -0.0188099    0.0595611    0.0297876   -0.0543577   -0.0458075   -0.0366442    0.0734197    0.0144524   -0.0868047    0.10489     -0.0145201  -0.154753     -0.110694    -0.0258191   -0.0262061   -0.188062    -0.0182533   -0.0488127    0.0482855  -0.19054      -0.102737      0.0050066   -0.0997128
  0.131007     0.00835145  -0.0131951  -0.0890493   -0.024144    -0.191801     0.00234496  -0.102462    -0.0747879    0.0283042    0.0813144    0.0495433   -0.00815906   0.0271446   0.060086      0.0792877    0.107167     0.102611    -0.110222    -0.141294     0.0602603    0.0227806   0.0443167    -0.0552363     0.131299     0.0524646
 -0.142422    -0.0323057   -0.0441018  -0.0665795   -0.111973     0.0706103   -0.164688    -0.14273     -0.0499205    0.1252       0.160314     0.0130054   -0.131842    -0.026313    0.0314974    -0.0162819    0.18798      0.171392    -0.00326549   0.146723    -0.0731768   -0.0172392   0.118812      0.0704942    -0.00354306   0.0895856
  0.0330307   -0.0644206    0.183864    0.203434     0.068168     0.10963      0.0178828   -0.129505     0.151275    -0.0289385   -0.161804    -0.150277    -0.193205    -0.181317   -0.014251      0.0462473   -0.0540784   -0.0205124   -0.00681083  -0.20574     -0.0441386    0.0962527   0.164025      0.106396     -0.107266     0.184154 
 -0.0367508   -0.153049     0.165844   -0.00396668  -0.0833253    0.0699679    0.0210138   -0.10191      0.103898    -0.0315621   -0.0687851    0.118306     0.141852    -0.106462   -0.106862     -0.134707     0.134792     0.0542366   -0.1211       0.227704    -0.0507899    0.194521   -0.176947      0.01747      -0.0529296   -0.135701 
 -0.122152    -0.014965    -0.0349107  -0.0125347    0.209661     0.0824588   -0.0745306    0.0189486    0.0251001    0.0977858    0.112008    -0.0953504   -0.0696931   -0.0790046  -0.0173018    -0.203537    -0.093496    -0.164808    -0.0287242   -0.19257     -0.186966     0.0438309   0.183138      0.172772     -0.0432824    0.236714 
 -0.146255    -0.0789877   -0.21589    -0.00580371  -0.0829175   -0.0681201   -0.0326436    0.0081125   -0.0200958   -0.0403876    0.217492     0.0921538    0.0167825   -0.0361278   0.0157718    -0.142907     0.00369157   0.08014     -0.0275634   -0.0586459   -0.009891    -0.296731    0.044443     -0.0428372    -0.0858034    0.0671786
  0.161433     0.107478    -0.0194352   0.0784265   -0.044874     0.081815    -0.105019     0.0532739   -0.110755     0.0200245    0.105081     0.234455    -0.0850739    0.175382   -0.0711847     0.124342    -0.0132636    0.0553633    0.0289568    0.00554415   0.0152543   -0.0116972  -0.0228639    -0.0388696     0.0603491   -0.149165 
  0.0623203    0.0809719    0.0930707  -0.139236     0.122649    -0.0457696    0.0595469    0.20907     -0.12046      0.193202     0.00990273  -0.0202299    0.0166793   -0.0385741  -0.113397      0.171692     0.11283      0.156441    -0.135119     0.115275     0.0318868    0.0844264   0.142113      0.127318      0.0279871   -0.0375691
  0.053498     0.0714044    0.0126131   0.132374     0.0757573    0.146314     0.01922      0.0375682   -0.240686    -0.00114072  -0.0118457    0.0831917    0.132036    -0.0414254  -0.144109     -0.106717    -0.0891199    0.0152368    0.133387     0.0852416   -0.0102561    0.0941493   0.0349469     0.121252      0.0722796    0.0274971
  0.0176556    0.00671521  -0.0651488   0.184886     0.0802235   -0.0899675    0.154862    -0.00730167  -0.0209326    0.0441898   -0.0966697    0.100275    -0.155224     0.14187    -0.0662967     0.0919195   -0.0415277   -0.0222035   -0.0180226    0.0290381   -0.0539227   -0.0141362   0.0992224     0.023486     -0.0447985   -0.150042 
 -0.0329279    0.19269      0.0249099  -0.102225     0.105249    -0.067761    -0.105062     0.0491217    0.143375    -0.0698701    0.207037    -0.0854365    0.0113679    0.0814815  -0.119859     -0.00583002  -0.0344445    0.273395     0.00603097   0.0620809    0.173438    -0.0857628  -0.182832     -0.092293     -0.119251    -0.0828132
  0.195657    -0.0435472   -0.0747717   0.0401167   -0.151889    -0.0951479   -0.0252797    0.0398901    0.0618696   -0.168106    -0.0184598    0.0557025   -0.0232116   -0.0342264   0.181595      0.126659     0.173952    -0.250721    -0.0285294    0.202687    -0.120676     0.167314   -0.0757179     0.0354088     0.00615131   0.187465 
 -0.0740662    0.208396    -0.167225   -0.0248848   -0.1751      -0.0597828    0.103688     0.215042     0.0500127   -0.0264078    0.263032     0.0341664   -0.00306627  -0.0385957   0.170212     -0.0306897   -0.0173407    0.188088    -0.0673847   -0.0637613   -0.0313281   -0.0104249  -0.0250007     0.0962374     0.0655809   -0.0860407
 -0.00364456  -0.0995177    0.0815539   0.0853508   -0.0835468   -0.0428031    0.0359098   -0.0960714    0.00207756  -0.0695727    0.036713    -0.0482838    0.124168    -0.0464844  -0.0137363     0.0141528    0.0394919    0.0367733    0.135846     0.156539     0.00437195  -0.117517    0.0444802    -0.000338779  -0.122274     0.0133178
 -0.078842     0.117077    -0.0143115   0.0457337   -0.0520308   -0.0417503   -0.0397553   -0.0685242    0.0267519    0.140158     0.14191     -0.00459062  -0.0643275   -0.140649    0.131437     -0.0747529   -0.129132     0.224148     0.0604226   -0.212862     0.0291941    0.0377093   0.0637112     0.0862694     0.0288444    0.11095  
 -0.00116767  -0.116665    -0.0290098  -0.0960421   -0.00637476   0.140509    -0.0128136   -0.0921733   -0.0289706   -0.0603174    0.0589009   -0.128459     0.0589118   -0.147062   -0.0482834     0.199022     0.0514665   -0.0446346    0.13759      0.072767     0.086755     0.134574    0.122282     -0.0355898    -0.175789     0.0374818
 -0.0218613   -0.118362    -0.0304207  -0.044869    -0.0597219    0.201931     0.0620179    0.022479    -0.0354486   -0.0425556    0.077441    -0.0773373   -0.120416     0.0504895   0.0154477    -0.103755    -0.219631     0.136343    -0.0288493   -0.0128654   -0.0199872    0.0428485   0.0264281    -0.0666424    -0.183284     0.0194425
 -0.0633082    0.0497314   -0.0343543   0.155843     0.0742125    0.0571339   -0.00613735   0.0655179   -0.178608    -0.0474489   -0.0637888   -0.175755     0.151614    -0.0328917   0.0257238    -0.0617204    0.0573068   -0.0649592    0.149689    -0.127878    -0.154892     0.108185    0.148008     -0.148245      0.0296596   -0.172524 
  0.0422951   -0.166313     0.0973521   0.105703     0.164308     0.157976     0.121094    -0.152466    -0.102404     0.0213105   -0.0398745   -0.130247     0.209409    -0.0646452  -0.00523086   -0.136277     0.00912448  -0.0603637    0.217837    -0.105176    -0.0197667   -0.0915578  -0.0412885     0.00752859   -0.00748938  -0.0163151
  0.0843862    0.0399703    0.0731618  -0.150154    -0.00838496   0.103654     0.0182046    0.137795    -0.115667    -0.108637    -0.0836247   -0.00964976  -0.182776    -0.0481785  -0.0439829    -0.0945888   -0.019573    -0.0413708   -0.0120735    0.0344601   -0.111275     0.0296639  -0.0107299    -0.0099932     0.186248    -0.157675 
 -0.0878149   -0.0915219    0.0275635  -0.0353142    0.11728     -0.011597    -0.0845791    0.015552    -0.0550796    0.0930329    0.144322    -0.13441      0.133209    -0.117571    0.0838748     0.0207915    0.102531    -0.00966537  -0.0946796    0.0157334   -0.199357    -0.128546   -0.0827644    -0.13676       0.0843165    0.0824533
  0.0701291   -0.0130428    0.0737083  -0.0762852    0.0859506   -0.14751      0.106371     0.1833      -0.0914255   -0.17105     -0.0664153   -0.147284     0.07884     -0.0683807   0.113723      0.00966598   0.210554    -0.0221022   -0.0380858    0.0544487   -0.0405727    0.0777937  -0.0590078     0.246194     -0.00311044  -0.0118028
  0.134621    -0.0150826    0.143794   -0.140753    -0.098       -0.0493045   -0.151179    -0.0525618    0.0346404   -0.0643848   -0.0863716    0.00226228  -0.0565669    0.0675005  -0.00375037   -0.0157911   -0.229255    -0.0223305    0.0696995    0.00694137  -0.0483427    0.0130408   0.187754     -0.000983519  -0.207094     0.203133 
 -0.0810363    0.0299176   -0.064343   -0.0241877   -0.0398112    0.00957704  -0.0450709   -0.137332    -0.0685153   -0.111499    -0.038674     0.0165636    0.0834033    0.0490402  -0.154182      0.182262    -0.0214794    0.0454444    0.0451609   -0.0670429    0.0213757   -0.161203    0.0755332    -0.0914657    -0.119938    -0.0158456
 -0.0109588    0.0118478   -0.022872   -0.137195    -0.049773     0.0454101   -0.140316    -0.120371     0.0162627   -0.002631    -0.0618036   -0.141086     0.0403821    0.107521    0.125206      0.104698    -0.0511438   -0.0506735    0.00768999  -0.0276069   -0.0665688   -0.0648216  -0.0651278    -0.0744075    -0.0255776   -0.0968635kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4271115321924104
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427130
[ Info: iteration 2, average log likelihood -1.427072
[ Info: iteration 3, average log likelihood -1.427025
[ Info: iteration 4, average log likelihood -1.426963
[ Info: iteration 5, average log likelihood -1.426878
[ Info: iteration 6, average log likelihood -1.426769
[ Info: iteration 7, average log likelihood -1.426635
[ Info: iteration 8, average log likelihood -1.426476
[ Info: iteration 9, average log likelihood -1.426281
[ Info: iteration 10, average log likelihood -1.426008
[ Info: iteration 11, average log likelihood -1.425581
[ Info: iteration 12, average log likelihood -1.424927
[ Info: iteration 13, average log likelihood -1.424068
[ Info: iteration 14, average log likelihood -1.423198
[ Info: iteration 15, average log likelihood -1.422542
[ Info: iteration 16, average log likelihood -1.422158
[ Info: iteration 17, average log likelihood -1.421967
[ Info: iteration 18, average log likelihood -1.421878
[ Info: iteration 19, average log likelihood -1.421837
[ Info: iteration 20, average log likelihood -1.421819
[ Info: iteration 21, average log likelihood -1.421810
[ Info: iteration 22, average log likelihood -1.421806
[ Info: iteration 23, average log likelihood -1.421804
[ Info: iteration 24, average log likelihood -1.421803
[ Info: iteration 25, average log likelihood -1.421803
[ Info: iteration 26, average log likelihood -1.421802
[ Info: iteration 27, average log likelihood -1.421802
[ Info: iteration 28, average log likelihood -1.421802
[ Info: iteration 29, average log likelihood -1.421802
[ Info: iteration 30, average log likelihood -1.421802
[ Info: iteration 31, average log likelihood -1.421802
[ Info: iteration 32, average log likelihood -1.421802
[ Info: iteration 33, average log likelihood -1.421801
[ Info: iteration 34, average log likelihood -1.421801
[ Info: iteration 35, average log likelihood -1.421801
[ Info: iteration 36, average log likelihood -1.421801
[ Info: iteration 37, average log likelihood -1.421801
[ Info: iteration 38, average log likelihood -1.421801
[ Info: iteration 39, average log likelihood -1.421801
[ Info: iteration 40, average log likelihood -1.421801
[ Info: iteration 41, average log likelihood -1.421801
[ Info: iteration 42, average log likelihood -1.421801
[ Info: iteration 43, average log likelihood -1.421801
[ Info: iteration 44, average log likelihood -1.421801
[ Info: iteration 45, average log likelihood -1.421801
[ Info: iteration 46, average log likelihood -1.421801
[ Info: iteration 47, average log likelihood -1.421801
[ Info: iteration 48, average log likelihood -1.421801
[ Info: iteration 49, average log likelihood -1.421801
[ Info: iteration 50, average log likelihood -1.421801
┌ Info: EM with 100000 data points 50 iterations avll -1.421801
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.427129629803172 
│     -1.4270719316290743
│      ⋮                 
└     -1.4218008514104512
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421815
[ Info: iteration 2, average log likelihood -1.421758
[ Info: iteration 3, average log likelihood -1.421708
[ Info: iteration 4, average log likelihood -1.421642
[ Info: iteration 5, average log likelihood -1.421555
[ Info: iteration 6, average log likelihood -1.421445
[ Info: iteration 7, average log likelihood -1.421317
[ Info: iteration 8, average log likelihood -1.421187
[ Info: iteration 9, average log likelihood -1.421070
[ Info: iteration 10, average log likelihood -1.420974
[ Info: iteration 11, average log likelihood -1.420899
[ Info: iteration 12, average log likelihood -1.420842
[ Info: iteration 13, average log likelihood -1.420798
[ Info: iteration 14, average log likelihood -1.420763
[ Info: iteration 15, average log likelihood -1.420735
[ Info: iteration 16, average log likelihood -1.420711
[ Info: iteration 17, average log likelihood -1.420691
[ Info: iteration 18, average log likelihood -1.420674
[ Info: iteration 19, average log likelihood -1.420658
[ Info: iteration 20, average log likelihood -1.420644
[ Info: iteration 21, average log likelihood -1.420631
[ Info: iteration 22, average log likelihood -1.420619
[ Info: iteration 23, average log likelihood -1.420607
[ Info: iteration 24, average log likelihood -1.420597
[ Info: iteration 25, average log likelihood -1.420587
[ Info: iteration 26, average log likelihood -1.420577
[ Info: iteration 27, average log likelihood -1.420568
[ Info: iteration 28, average log likelihood -1.420559
[ Info: iteration 29, average log likelihood -1.420551
[ Info: iteration 30, average log likelihood -1.420543
[ Info: iteration 31, average log likelihood -1.420536
[ Info: iteration 32, average log likelihood -1.420529
[ Info: iteration 33, average log likelihood -1.420523
[ Info: iteration 34, average log likelihood -1.420517
[ Info: iteration 35, average log likelihood -1.420511
[ Info: iteration 36, average log likelihood -1.420506
[ Info: iteration 37, average log likelihood -1.420502
[ Info: iteration 38, average log likelihood -1.420497
[ Info: iteration 39, average log likelihood -1.420493
[ Info: iteration 40, average log likelihood -1.420490
[ Info: iteration 41, average log likelihood -1.420487
[ Info: iteration 42, average log likelihood -1.420484
[ Info: iteration 43, average log likelihood -1.420481
[ Info: iteration 44, average log likelihood -1.420479
[ Info: iteration 45, average log likelihood -1.420476
[ Info: iteration 46, average log likelihood -1.420474
[ Info: iteration 47, average log likelihood -1.420473
[ Info: iteration 48, average log likelihood -1.420471
[ Info: iteration 49, average log likelihood -1.420470
[ Info: iteration 50, average log likelihood -1.420468
┌ Info: EM with 100000 data points 50 iterations avll -1.420468
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4218153295167821
│     -1.4217580243756458
│      ⋮                 
└     -1.4204682528491817
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420477
[ Info: iteration 2, average log likelihood -1.420412
[ Info: iteration 3, average log likelihood -1.420357
[ Info: iteration 4, average log likelihood -1.420295
[ Info: iteration 5, average log likelihood -1.420222
[ Info: iteration 6, average log likelihood -1.420136
[ Info: iteration 7, average log likelihood -1.420038
[ Info: iteration 8, average log likelihood -1.419933
[ Info: iteration 9, average log likelihood -1.419826
[ Info: iteration 10, average log likelihood -1.419722
[ Info: iteration 11, average log likelihood -1.419626
[ Info: iteration 12, average log likelihood -1.419539
[ Info: iteration 13, average log likelihood -1.419464
[ Info: iteration 14, average log likelihood -1.419401
[ Info: iteration 15, average log likelihood -1.419349
[ Info: iteration 16, average log likelihood -1.419308
[ Info: iteration 17, average log likelihood -1.419275
[ Info: iteration 18, average log likelihood -1.419250
[ Info: iteration 19, average log likelihood -1.419229
[ Info: iteration 20, average log likelihood -1.419212
[ Info: iteration 21, average log likelihood -1.419197
[ Info: iteration 22, average log likelihood -1.419185
[ Info: iteration 23, average log likelihood -1.419174
[ Info: iteration 24, average log likelihood -1.419164
[ Info: iteration 25, average log likelihood -1.419154
[ Info: iteration 26, average log likelihood -1.419145
[ Info: iteration 27, average log likelihood -1.419137
[ Info: iteration 28, average log likelihood -1.419129
[ Info: iteration 29, average log likelihood -1.419122
[ Info: iteration 30, average log likelihood -1.419115
[ Info: iteration 31, average log likelihood -1.419108
[ Info: iteration 32, average log likelihood -1.419102
[ Info: iteration 33, average log likelihood -1.419095
[ Info: iteration 34, average log likelihood -1.419089
[ Info: iteration 35, average log likelihood -1.419083
[ Info: iteration 36, average log likelihood -1.419078
[ Info: iteration 37, average log likelihood -1.419072
[ Info: iteration 38, average log likelihood -1.419067
[ Info: iteration 39, average log likelihood -1.419061
[ Info: iteration 40, average log likelihood -1.419056
[ Info: iteration 41, average log likelihood -1.419051
[ Info: iteration 42, average log likelihood -1.419046
[ Info: iteration 43, average log likelihood -1.419042
[ Info: iteration 44, average log likelihood -1.419037
[ Info: iteration 45, average log likelihood -1.419032
[ Info: iteration 46, average log likelihood -1.419028
[ Info: iteration 47, average log likelihood -1.419023
[ Info: iteration 48, average log likelihood -1.419019
[ Info: iteration 49, average log likelihood -1.419015
[ Info: iteration 50, average log likelihood -1.419011
┌ Info: EM with 100000 data points 50 iterations avll -1.419011
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4204768038273128
│     -1.4204119995209128
│      ⋮                 
└     -1.4190105108543571
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419015
[ Info: iteration 2, average log likelihood -1.418957
[ Info: iteration 3, average log likelihood -1.418902
[ Info: iteration 4, average log likelihood -1.418837
[ Info: iteration 5, average log likelihood -1.418753
[ Info: iteration 6, average log likelihood -1.418645
[ Info: iteration 7, average log likelihood -1.418513
[ Info: iteration 8, average log likelihood -1.418360
[ Info: iteration 9, average log likelihood -1.418198
[ Info: iteration 10, average log likelihood -1.418038
[ Info: iteration 11, average log likelihood -1.417890
[ Info: iteration 12, average log likelihood -1.417756
[ Info: iteration 13, average log likelihood -1.417640
[ Info: iteration 14, average log likelihood -1.417541
[ Info: iteration 15, average log likelihood -1.417458
[ Info: iteration 16, average log likelihood -1.417389
[ Info: iteration 17, average log likelihood -1.417331
[ Info: iteration 18, average log likelihood -1.417283
[ Info: iteration 19, average log likelihood -1.417242
[ Info: iteration 20, average log likelihood -1.417207
[ Info: iteration 21, average log likelihood -1.417177
[ Info: iteration 22, average log likelihood -1.417150
[ Info: iteration 23, average log likelihood -1.417126
[ Info: iteration 24, average log likelihood -1.417105
[ Info: iteration 25, average log likelihood -1.417085
[ Info: iteration 26, average log likelihood -1.417068
[ Info: iteration 27, average log likelihood -1.417051
[ Info: iteration 28, average log likelihood -1.417036
[ Info: iteration 29, average log likelihood -1.417021
[ Info: iteration 30, average log likelihood -1.417008
[ Info: iteration 31, average log likelihood -1.416995
[ Info: iteration 32, average log likelihood -1.416983
[ Info: iteration 33, average log likelihood -1.416971
[ Info: iteration 34, average log likelihood -1.416960
[ Info: iteration 35, average log likelihood -1.416950
[ Info: iteration 36, average log likelihood -1.416940
[ Info: iteration 37, average log likelihood -1.416931
[ Info: iteration 38, average log likelihood -1.416921
[ Info: iteration 39, average log likelihood -1.416913
[ Info: iteration 40, average log likelihood -1.416904
[ Info: iteration 41, average log likelihood -1.416896
[ Info: iteration 42, average log likelihood -1.416889
[ Info: iteration 43, average log likelihood -1.416881
[ Info: iteration 44, average log likelihood -1.416874
[ Info: iteration 45, average log likelihood -1.416867
[ Info: iteration 46, average log likelihood -1.416861
[ Info: iteration 47, average log likelihood -1.416854
[ Info: iteration 48, average log likelihood -1.416848
[ Info: iteration 49, average log likelihood -1.416842
[ Info: iteration 50, average log likelihood -1.416836
┌ Info: EM with 100000 data points 50 iterations avll -1.416836
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4190154154233996
│     -1.4189572787202187
│      ⋮                 
└     -1.4168362468728506
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416839
[ Info: iteration 2, average log likelihood -1.416773
[ Info: iteration 3, average log likelihood -1.416708
[ Info: iteration 4, average log likelihood -1.416629
[ Info: iteration 5, average log likelihood -1.416525
[ Info: iteration 6, average log likelihood -1.416392
[ Info: iteration 7, average log likelihood -1.416228
[ Info: iteration 8, average log likelihood -1.416042
[ Info: iteration 9, average log likelihood -1.415846
[ Info: iteration 10, average log likelihood -1.415654
[ Info: iteration 11, average log likelihood -1.415475
[ Info: iteration 12, average log likelihood -1.415316
[ Info: iteration 13, average log likelihood -1.415176
[ Info: iteration 14, average log likelihood -1.415054
[ Info: iteration 15, average log likelihood -1.414947
[ Info: iteration 16, average log likelihood -1.414853
[ Info: iteration 17, average log likelihood -1.414770
[ Info: iteration 18, average log likelihood -1.414698
[ Info: iteration 19, average log likelihood -1.414634
[ Info: iteration 20, average log likelihood -1.414576
[ Info: iteration 21, average log likelihood -1.414525
[ Info: iteration 22, average log likelihood -1.414479
[ Info: iteration 23, average log likelihood -1.414436
[ Info: iteration 24, average log likelihood -1.414397
[ Info: iteration 25, average log likelihood -1.414361
[ Info: iteration 26, average log likelihood -1.414326
[ Info: iteration 27, average log likelihood -1.414294
[ Info: iteration 28, average log likelihood -1.414263
[ Info: iteration 29, average log likelihood -1.414233
[ Info: iteration 30, average log likelihood -1.414205
[ Info: iteration 31, average log likelihood -1.414178
[ Info: iteration 32, average log likelihood -1.414152
[ Info: iteration 33, average log likelihood -1.414126
[ Info: iteration 34, average log likelihood -1.414103
[ Info: iteration 35, average log likelihood -1.414080
[ Info: iteration 36, average log likelihood -1.414058
[ Info: iteration 37, average log likelihood -1.414037
[ Info: iteration 38, average log likelihood -1.414018
[ Info: iteration 39, average log likelihood -1.413999
[ Info: iteration 40, average log likelihood -1.413981
[ Info: iteration 41, average log likelihood -1.413965
[ Info: iteration 42, average log likelihood -1.413948
[ Info: iteration 43, average log likelihood -1.413933
[ Info: iteration 44, average log likelihood -1.413918
[ Info: iteration 45, average log likelihood -1.413904
[ Info: iteration 46, average log likelihood -1.413890
[ Info: iteration 47, average log likelihood -1.413877
[ Info: iteration 48, average log likelihood -1.413865
[ Info: iteration 49, average log likelihood -1.413853
[ Info: iteration 50, average log likelihood -1.413841
┌ Info: EM with 100000 data points 50 iterations avll -1.413841
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416838597180391 
│     -1.4167732558547386
│      ⋮                 
└     -1.4138407265178334
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4271115321924104
│     -1.427129629803172 
│     -1.4270719316290743
│     -1.4270247450132718
│      ⋮                 
│     -1.4138647110351146
│     -1.413852518247468 
└     -1.4138407265178334
32×26 Array{Float64,2}:
 -0.783778     -0.353996   -0.716237     -0.244557    -0.215422   -0.120071     0.495361    0.240784     0.0352625   0.0740791  -0.0495812    0.330797    -0.379295   -0.373686    0.145821    -0.268424    -0.38788      0.212474    0.375405    0.0857702    -0.0105917   0.344947    0.127438    -0.196056     0.738866     0.0178398  
 -0.246937      0.301669   -0.688461     -0.462174    -0.0996126   0.332345    -0.0549827  -0.0886301   -0.0979252   0.361789   -0.496745     0.00283158  -0.370174    0.954876   -0.382432     0.260218     0.139447     0.092513    0.75261    -0.142541      0.104699    0.210335   -0.116362     0.21871      0.173944     0.0639236  
  0.402123      0.195012   -0.173891      0.913842    -0.315286    0.26806      0.0330662   0.297963    -0.574108    0.13688    -0.18456     -0.213735    -0.416412    0.0140463   0.208691     0.217174     0.186484    -0.137519    0.195016    0.0399218    -0.481282    0.179124    0.160707    -0.31242      0.352769     0.244304   
  0.529532      0.22464     0.126351     -0.0157549    0.0784828   0.344718     0.168942   -0.0199453    0.606225   -0.597065   -0.0257009    0.573267    -0.602445    0.300033   -0.330671    -0.195334     0.373981    -0.101789    0.543173    0.132844     -0.314237    0.0600289   0.0187747    0.00352754   0.335801     0.330658   
 -0.115253     -0.360261    0.215463      0.0179709    0.67009    -0.511073     0.354827    0.27168      0.127477   -0.0707641  -0.0792187   -0.136502     0.20381     0.451304   -0.0216392   -0.0615472   -0.36393     -0.209455    0.380035   -0.223249      0.527826    0.15955    -0.0742752   -0.334096    -0.0453067   -0.0766493  
 -0.513749     -0.542231    0.280144      0.0339328    0.577254    0.0596093   -0.189455    0.244464    -0.274726   -0.207219    0.3973       0.410425     0.167844    0.295001   -0.419403     0.0826149   -0.141204    -0.194498    0.0551795  -0.337372     -0.0614099   0.0406365   0.551569     0.585597    -0.15691      0.103156   
 -0.0611488    -0.167878   -0.087923     -0.0188553    0.033857   -0.00359028   0.190671    0.224494    -0.0217678   0.102189    0.106608    -0.181201    -0.248493   -0.150579    0.0935318    0.181476    -0.078292     0.105233    0.0370951   0.125545      0.253438    0.324602    0.196681    -0.0251988   -0.00803762   0.195073   
  0.0262264     0.0267394   0.0882254     0.00621274  -0.0110814   0.114086     0.106491   -0.115953     0.0434782  -0.164471    0.062848     0.0602407    0.224659    0.0145412  -0.00922918  -0.097458     0.142538     0.109626   -0.0214408  -0.135895     -0.155955   -0.134988   -0.194771    -0.0766341   -0.0479906   -0.0916645  
  0.016045      0.195087   -0.276537     -0.0449873   -0.0927144   0.025268    -0.641733   -0.165518    -0.253459    0.170392   -0.218455     0.00514662   0.0264243  -0.21165    -0.0858102    0.0095284   -0.2669      -0.182089   -0.0377806   0.243894     -0.220531   -0.161549    0.0616405    0.213158    -0.0431538   -0.163887   
  0.0825057    -0.0512216   0.813558      0.298147    -0.558731   -0.443832    -0.639823   -0.237791     0.383585   -0.0150553   0.307208     0.596732    -0.0155339  -0.424894    0.296626     0.52795     -0.395279    -0.056418   -0.044442    0.264106     -0.0574386  -0.326504    0.253301    -0.00813729   0.221009     0.0720687  
 -0.0461909     0.532513    0.000876685  -0.623782    -0.356624   -0.0683628   -0.238625    0.0736634    0.464694   -0.125907    0.188353     0.152697     0.265161   -0.184622    0.549196    -0.352391     0.442062     0.435185   -0.140336    0.229831      0.240792   -0.194848   -0.501004     0.173082     0.0621547    0.0257363  
 -0.187165      0.378819   -0.143107     -0.444488    -0.431725    0.330409    -0.0649452   0.00303975  -0.0379561   0.21738     0.568517     0.049936    -0.161429    0.0176556  -0.33363     -0.268419     0.0406336    0.685442   -0.53513     0.057523      0.0818544  -0.495497    0.402552     0.0426399   -0.153138    -0.287259   
  0.613622      0.0848134  -0.075128     -0.326366     0.123382   -0.280071    -0.295066   -0.10704      0.17783    -0.0771934  -0.335071     0.626194     0.152594   -0.602705   -0.141921     0.171035     0.193084    -0.548588   -0.157527   -0.549394     -0.479298   -0.253911   -0.584155    -0.494363    -0.683196     0.142061   
  0.632766      0.260465    0.436383      0.0196304    0.321008   -0.119982    -0.335571   -0.304583     0.114706    0.220071   -0.33307     -0.217591     0.81624     0.755731   -0.187927     0.00530001   0.0695901   -0.397809   -0.231845   -0.494304     -0.563551   -0.196769   -0.412269    -0.0345846   -0.497383     0.274779   
  0.215758     -0.145822    0.176318      0.468065    -0.480037   -0.0717624   -0.108964   -0.804487    -0.0542712  -0.189432   -0.809448    -0.276082     0.114687   -0.0776262   0.529233    -0.698766     0.247736    -0.0834549   0.0548605  -0.430983     -0.43951    -0.0379924  -0.405189    -0.0422551    0.093105     0.0704928  
  0.3952        0.081324    0.218187      0.532821    -0.112451    0.263736    -0.538001   -0.426643    -0.447499    0.106779    0.365057    -0.275662     0.0907964   0.101511    0.228357     0.0548748    0.689075    -0.125504    0.0884038  -0.0548425    -0.296929   -0.292766   -0.10552      0.678835    -0.687065    -0.520056   
  0.0487806    -0.0966694   0.113992     -0.0310432    0.0675363  -0.0324237    0.0902053  -0.0452593    0.0180986  -0.0233471   0.00195186   0.0561966   -0.0420512   0.148938   -0.0188426   -0.0906605    0.151015    -0.019249    0.092092   -0.0805428     0.0260375  -0.0101128  -0.112453    -0.0261258   -0.006738     0.102075   
  0.159752      0.649852   -0.123339     -0.180216     0.115815    0.0561492   -1.10878     0.190769    -0.315902    0.266929   -0.148732     0.290575     0.223845   -0.0975878  -0.129431     0.0287428   -0.374305    -0.348326    0.0702229   0.286139     -0.493845   -0.130655    0.336246     0.359376     0.07238     -0.12743    
  0.0318198     0.634166    0.421236      0.170839    -0.233282    0.172256    -0.487184   -0.444732     0.260615   -0.0448965   0.135154    -0.350553     0.411697    0.819451   -0.345132    -0.639422    -0.248953     0.41729     0.0668477   0.000742882   0.663665   -0.48251    -0.411209    -0.480375     0.0842782    0.078532   
  0.0631967     0.341848   -0.339759     -0.0443589    0.2951      0.0448892    0.253302   -0.178128     0.191728   -0.0396576  -0.0959055    0.491016     0.134238    0.620086   -0.0556749   -0.62174     -0.205729     0.0179542   0.494982   -0.188496     -0.354641   -0.976224    0.106319     0.194369     0.227241    -1.1504     
  0.65232      -0.397338   -0.0910277    -0.144362     0.659892    0.277215     0.884969    0.210605    -0.140974   -0.11134    -0.0776544   -0.202947    -0.607369   -0.29123    -0.122812     0.0205916    0.704576    -0.503997    0.597278   -0.300942     -0.738315    0.635133    0.329844    -0.0512937   -0.26865     -0.000887866
  0.000311128   0.128735   -0.719162     -0.334447     0.48943     0.527744     0.635366    0.197316    -0.271465   -0.09079    -0.0335571   -0.864764     0.340178    0.0477617  -0.0266625   -0.354763     0.559553     0.208118   -0.130181   -0.215364     -0.0249509   0.758365   -0.266862     0.0947758   -0.440199    -0.0859774  
  0.427236     -0.328225   -0.159601      0.0827405    0.2203     -0.0952543    0.596332    0.263092    -0.0876192  -0.0319961   0.899817     0.0120989    0.427743   -0.646529    0.184803     0.36738      0.00149007   0.0797916  -0.329104    0.077697     -0.909272   -0.329231    0.00370955   0.0854254   -0.127205    -0.52247    
 -0.0224183    -0.123892    0.189269      1.31329      0.333144   -0.45473      0.651111    0.44845     -0.441875   -0.275434    0.500078     0.209297     0.320625   -0.537889   -0.0678054   -0.305238    -0.242893    -0.124311   -0.611156   -0.427403     -0.363588   -0.0931471   0.185165    -0.300313    -0.344487    -0.910743   
 -0.282306     -0.282069    0.469126     -0.0970333    0.0531931   0.0839443   -0.219364    0.403863    -0.228559    0.370708   -0.149515    -1.24778      0.720718   -0.189986    0.718817     0.418696    -0.0269268    0.425643   -0.648907    0.220311      0.549212    0.0542662   0.054268    -0.439184    -0.0542488    0.0605208  
 -0.817334      0.0209522   0.0447438     0.0423592   -0.573845   -0.393012    -0.467657   -0.310527    -0.684441    0.713377    0.102661     0.0313689    0.440117   -0.412948    0.280764     0.347287    -0.710128    -0.249111   -0.722567   -0.182546      0.468982    0.247907   -0.444608     0.0862443   -0.0355633    0.0731331  
  0.00989124   -0.552181   -0.528297     -0.00661406  -0.0772868  -0.152631    -0.109731    0.386403    -0.0344187   0.167414    0.0410233   -0.555133    -0.453794   -0.368169    0.55373      1.02731     -0.329481     0.354114    0.412129    0.303238      0.306968    0.0562359   0.624474     0.264671    -0.623177    -0.132184   
 -0.691047     -0.122373    0.141289      0.061161    -0.185636    0.468297     0.145431   -0.276131    -0.215136   -0.15233     0.403717    -0.882804     0.0128337   0.272355   -0.164262    -0.0522945   -0.455903     0.569991    0.495997    0.850084      0.525073    0.422987    0.648744     0.6031       0.497468    -0.120053   
  0.458565     -0.0417802  -0.111879      0.0268211   -0.427098   -0.0828884    0.32044     0.178975     0.17349     0.157191    0.234877     0.0967214   -0.429247   -0.371924   -0.21106      0.403229    -0.169391     0.655486   -0.614867    0.559934      0.130299   -0.0490307  -0.170894    -0.599031     0.101497     0.62786    
 -0.562345     -0.103808    0.147104     -0.627622     0.8238     -0.142788     0.536776    0.507166     0.206293   -0.148313   -0.228336    -0.0281232    0.0962382  -0.42943    -0.651156    -0.358208     0.0339282    0.305241   -0.493099    0.461037      0.181249    0.214092    0.296122    -0.444254     0.17806      0.468601   
  0.0409363    -0.4082      0.624724      0.204015    -0.126831    0.0514086    0.130938   -0.299609     0.183807   -0.751141    0.0504956    0.109153    -0.344058   -0.409578   -0.0349258   -0.0916492   -0.0306214    0.14933    -0.106849   -0.480579      0.605126    0.307377    0.188958     0.123602    -0.152014     0.604327   
 -0.298925     -0.98402     0.769965     -0.12506     -0.134714    0.0108284    0.0878986  -0.213084     0.242461   -0.0119622   0.260908     0.155401    -0.28417    -0.189778    0.781297     0.442995     0.486379    -0.405554   -0.189458   -0.0417016     0.159104    0.749896   -0.111445     0.365298     0.0590461    0.30852    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413829
[ Info: iteration 2, average log likelihood -1.413818
[ Info: iteration 3, average log likelihood -1.413807
[ Info: iteration 4, average log likelihood -1.413797
[ Info: iteration 5, average log likelihood -1.413787
[ Info: iteration 6, average log likelihood -1.413777
[ Info: iteration 7, average log likelihood -1.413767
[ Info: iteration 8, average log likelihood -1.413758
[ Info: iteration 9, average log likelihood -1.413748
[ Info: iteration 10, average log likelihood -1.413739
┌ Info: EM with 100000 data points 10 iterations avll -1.413739
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.341485e+05
      1       7.112957e+05      -2.228528e+05 |       32
      2       6.962888e+05      -1.500689e+04 |       32
      3       6.908866e+05      -5.402248e+03 |       32
      4       6.882388e+05      -2.647804e+03 |       32
      5       6.865633e+05      -1.675527e+03 |       32
      6       6.854170e+05      -1.146266e+03 |       32
      7       6.845541e+05      -8.629357e+02 |       32
      8       6.838470e+05      -7.070287e+02 |       32
      9       6.832702e+05      -5.768475e+02 |       32
     10       6.827955e+05      -4.746801e+02 |       32
     11       6.824000e+05      -3.954604e+02 |       32
     12       6.820247e+05      -3.753343e+02 |       32
     13       6.817000e+05      -3.246643e+02 |       32
     14       6.814151e+05      -2.849023e+02 |       32
     15       6.811648e+05      -2.503119e+02 |       32
     16       6.809388e+05      -2.260185e+02 |       32
     17       6.807396e+05      -1.992501e+02 |       32
     18       6.805611e+05      -1.784308e+02 |       32
     19       6.804031e+05      -1.580323e+02 |       32
     20       6.802426e+05      -1.605417e+02 |       32
     21       6.800885e+05      -1.540997e+02 |       32
     22       6.799429e+05      -1.455591e+02 |       32
     23       6.798035e+05      -1.394075e+02 |       32
     24       6.796787e+05      -1.247541e+02 |       32
     25       6.795606e+05      -1.181554e+02 |       32
     26       6.794466e+05      -1.140094e+02 |       32
     27       6.793426e+05      -1.039601e+02 |       32
     28       6.792477e+05      -9.490829e+01 |       32
     29       6.791602e+05      -8.751240e+01 |       32
     30       6.790717e+05      -8.850001e+01 |       32
     31       6.789817e+05      -8.998028e+01 |       32
     32       6.788914e+05      -9.026222e+01 |       32
     33       6.788106e+05      -8.084729e+01 |       32
     34       6.787348e+05      -7.580015e+01 |       32
     35       6.786632e+05      -7.164758e+01 |       32
     36       6.785965e+05      -6.660869e+01 |       32
     37       6.785359e+05      -6.065473e+01 |       32
     38       6.784775e+05      -5.843239e+01 |       32
     39       6.784156e+05      -6.189370e+01 |       32
     40       6.783503e+05      -6.524075e+01 |       32
     41       6.782799e+05      -7.038209e+01 |       32
     42       6.782050e+05      -7.495468e+01 |       32
     43       6.781315e+05      -7.349083e+01 |       32
     44       6.780576e+05      -7.387452e+01 |       32
     45       6.779879e+05      -6.968343e+01 |       32
     46       6.779186e+05      -6.933055e+01 |       32
     47       6.778510e+05      -6.764642e+01 |       32
     48       6.777795e+05      -7.141895e+01 |       32
     49       6.777175e+05      -6.207851e+01 |       32
     50       6.776612e+05      -5.624377e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677661.2170838345)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425388
[ Info: iteration 2, average log likelihood -1.420463
[ Info: iteration 3, average log likelihood -1.419142
[ Info: iteration 4, average log likelihood -1.418180
[ Info: iteration 5, average log likelihood -1.417202
[ Info: iteration 6, average log likelihood -1.416311
[ Info: iteration 7, average log likelihood -1.415679
[ Info: iteration 8, average log likelihood -1.415306
[ Info: iteration 9, average log likelihood -1.415091
[ Info: iteration 10, average log likelihood -1.414956
[ Info: iteration 11, average log likelihood -1.414861
[ Info: iteration 12, average log likelihood -1.414788
[ Info: iteration 13, average log likelihood -1.414728
[ Info: iteration 14, average log likelihood -1.414677
[ Info: iteration 15, average log likelihood -1.414632
[ Info: iteration 16, average log likelihood -1.414591
[ Info: iteration 17, average log likelihood -1.414555
[ Info: iteration 18, average log likelihood -1.414521
[ Info: iteration 19, average log likelihood -1.414489
[ Info: iteration 20, average log likelihood -1.414459
[ Info: iteration 21, average log likelihood -1.414430
[ Info: iteration 22, average log likelihood -1.414403
[ Info: iteration 23, average log likelihood -1.414377
[ Info: iteration 24, average log likelihood -1.414352
[ Info: iteration 25, average log likelihood -1.414327
[ Info: iteration 26, average log likelihood -1.414303
[ Info: iteration 27, average log likelihood -1.414280
[ Info: iteration 28, average log likelihood -1.414258
[ Info: iteration 29, average log likelihood -1.414236
[ Info: iteration 30, average log likelihood -1.414214
[ Info: iteration 31, average log likelihood -1.414193
[ Info: iteration 32, average log likelihood -1.414172
[ Info: iteration 33, average log likelihood -1.414151
[ Info: iteration 34, average log likelihood -1.414131
[ Info: iteration 35, average log likelihood -1.414111
[ Info: iteration 36, average log likelihood -1.414092
[ Info: iteration 37, average log likelihood -1.414072
[ Info: iteration 38, average log likelihood -1.414053
[ Info: iteration 39, average log likelihood -1.414034
[ Info: iteration 40, average log likelihood -1.414015
[ Info: iteration 41, average log likelihood -1.413996
[ Info: iteration 42, average log likelihood -1.413977
[ Info: iteration 43, average log likelihood -1.413958
[ Info: iteration 44, average log likelihood -1.413939
[ Info: iteration 45, average log likelihood -1.413921
[ Info: iteration 46, average log likelihood -1.413903
[ Info: iteration 47, average log likelihood -1.413885
[ Info: iteration 48, average log likelihood -1.413868
[ Info: iteration 49, average log likelihood -1.413852
[ Info: iteration 50, average log likelihood -1.413836
┌ Info: EM with 100000 data points 50 iterations avll -1.413836
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.800621   -0.342651     0.383277    -0.946982     0.568278   -0.233873     0.168571   -0.186804   -0.447915   -0.345518     0.418216    -0.875024     0.436006   -0.159934    -0.644594     0.10528    -0.411497     0.734424      0.172798     1.05112     0.609709    0.733214    0.386717    0.218266   -0.0576698    0.102007 
 -0.224227    0.52757     -0.196284    -0.458918    -0.570453    0.474942    -0.392689   -0.588527    0.231096    0.0585925   -0.372394    -0.169224    -0.328467    0.463464    -0.187963    -0.230424    0.13012      0.19529       0.472553     0.232957    0.632651    0.139569   -0.497097    0.023805    0.221806     0.320251 
  0.622731    0.64931      0.418966    -0.125838    -0.0175152  -0.0154477   -0.87165    -0.374342    0.338151   -0.263645    -0.113389     0.307971     0.365703    0.00739369  -0.279646    -0.0123125   0.107341    -0.623865      0.0570949   -0.290917   -0.716262    0.128727    0.148745    0.227403   -0.572781     0.519403 
 -0.158996   -0.0975908   -0.213564     0.138633     0.0304644  -0.0367592   -0.106553   -0.100083   -0.55344     0.286907     0.0658379   -0.214915     0.0617805   0.108531     0.0300935   -0.0232614  -0.0141243   -0.420459      0.230666    -0.0816809  -0.0743351   0.0953865   0.144872    0.274255   -0.203933    -0.389301 
 -0.445022    0.049869     0.149465     0.0448461   -0.205886   -0.360479    -0.797205   -0.0415639  -0.510776    0.54625      0.023724    -0.143877     0.680212   -0.423317     0.328447     0.192271   -0.72841     -0.120356     -0.742761     0.0739705   0.179899   -0.0935688  -0.213842    0.0371295  -0.0678907   -0.114951 
 -0.037457   -0.43748      0.324356    -0.136882    -0.348523    0.203012     0.406175    0.0718835   0.800456   -0.407709     0.225026     0.293602    -0.131399   -0.4389      -0.0737358    0.0158247  -0.24243      0.639505     -0.371379     0.288384    0.338246   -0.0988872   0.0499399  -0.452973    0.21448      0.524652 
  0.354721   -0.0834869   -0.209597     0.103976     0.233497    0.58395      0.361371    0.062996   -0.57411     0.185012     0.013254    -0.365528    -0.0241842  -0.572637     0.269712    -0.115099    0.554169    -0.335285      0.293386     0.113541   -0.964378    0.445259    0.18002     0.266401   -0.0658571   -0.424191 
 -0.217522   -0.572254     0.564702    -0.346478    -0.0364459  -0.24116     -0.105465   -0.380314    0.562131   -0.639965     0.278052     0.377942     0.0192009  -0.347893     0.180317    -0.0393392   0.180285    -0.0774506     0.00540624  -0.444694    0.27195     0.183433    0.217741    0.481466   -0.0835408    0.040773 
 -0.783362   -0.343881    -0.343928    -0.0546801    0.0497603  -0.0840348    0.824863    0.31058    -0.0578166   0.18131      0.0693105   -0.154365    -0.213317   -0.0451976    0.308124    -0.35054    -0.209318     0.35176       0.151208     0.104185    0.455322    0.360094    0.113617   -0.256392    0.749686     0.0145724
  0.0278807   0.00851421   0.0236516    0.00707288  -0.0163969   0.0656851   -0.0504574  -0.0128939   0.018845   -0.0221053   -0.017936    -0.0203138    0.0231781  -0.100621    -0.00426945   0.0687926  -0.0384185    0.0512741    -0.0236744    0.0111585  -0.0166433   0.0362952  -0.048331   -0.0585247  -0.0297842    0.0777957
 -0.368564   -0.624036     0.782718     0.0189824   -0.139334    0.432998    -0.346328    0.0438988  -0.238905    0.317892    -0.0349576   -0.670158     0.249067    0.0453323    0.96944      0.647687    0.277475    -0.0817624    -0.573547     0.191132    0.456926    0.548268   -0.0982204   0.0686049   0.0770483    0.625571 
  0.196384    0.458127    -0.159853     0.139427    -0.206387   -0.00901475   0.243913    0.0231115  -0.108367    0.399982     0.95678      0.154003    -0.0835648  -0.164406    -0.641642    -0.0922672  -0.408693     0.215965     -0.775198     0.310756   -0.180601   -0.555988    0.412828   -0.627165   -0.200923    -0.262725 
  0.013027   -0.0193542   -0.658613    -0.481945     0.540771    0.640001     0.682193    0.217826   -0.0663992  -0.274946    -0.126546    -0.661176     0.156673    0.138749    -0.040624    -0.411378    0.647336     0.129488     -0.124551    -0.374624    0.0360129   0.831764   -0.475795    0.0543271  -0.4916      -0.0625808
  0.336935    0.159901     0.0640691   -0.494841    -0.0846145  -0.677518    -0.100565    0.462895    0.0499908   0.224934     0.106432     0.53721     -0.475123   -0.400296    -0.187643     0.318166    0.193359     0.000593735  -0.309106     0.42729     0.304879    0.386236   -0.532422    0.0714403   0.407684     0.474727 
 -0.516328    0.225174    -0.45814     -0.111685    -0.355075    0.225164    -0.444564    0.384316   -0.0597873   0.21472     -0.258534     0.569455    -0.0361374  -0.0826658   -0.433212     0.491861   -0.750408    -0.228987      0.811819     0.312865   -0.485221    0.428399    0.523789    0.143308    0.582801     0.0186855
  0.0136093  -0.469625    -0.681653    -0.354796     0.0255197  -0.15458     -0.20387     0.334323    0.0518718   0.360208    -0.00498972  -0.551801    -0.505621   -0.0488649    0.485906     1.10965    -0.304562     0.377007      0.574306     0.443118    0.258265   -0.0679752   0.693565    0.166893   -0.531139    -0.181464 
 -0.0677733   0.421209    -0.0790205   -0.450118    -0.22243     0.0609708   -0.0248942   0.111711    0.196508   -0.0330291    0.222376     0.0730155    0.399543   -0.0719228    0.18839     -0.313419    0.276594     0.514588     -0.292209     0.0460129  -0.165981   -0.392368   -0.219383    0.0206881   0.00300385  -0.232496 
  0.428014    0.253437     0.00992224   0.808543    -0.657306   -0.0362523   -0.765027   -0.0611528  -0.260502   -0.0755342   -0.908588     0.0697073   -0.392456   -0.0274998    0.53546     -0.220344    0.286198     0.0333908    -0.191708    -0.345225   -0.637449   -0.206291    0.105778   -0.241651    0.339641     0.413466 
  0.528418   -0.0284072    0.00774148  -0.137548    -0.0113067  -0.145783    -0.352019   -0.448866    0.0191539   0.193842    -0.42736      0.291283     0.184697   -0.0772366   -0.00681318   0.178163    0.197706    -0.422959     -0.138498    -0.341616   -0.549198   -0.579625   -0.738376   -0.280227   -0.727824    -0.21063  
 -0.162853    0.139345    -0.887811     0.252152     0.264669    0.0384894    0.546803    0.380949   -0.679069    0.858322    -0.870398    -0.410941     0.0878061   0.298236    -0.558933     0.380954   -0.0855148   -0.33783       0.135688     0.418076   -0.502642   -0.0578941  -0.249216   -0.569354   -0.246222     0.607958 
 -0.171996   -0.621042     0.131483     0.582158     0.39293    -0.299697     0.562813    0.425556   -0.436648   -0.327874     0.819462     0.40648      0.325073   -0.298338    -0.106685     0.2945      0.0755152    0.0022295    -0.27283     -0.360305   -0.495988   -0.221012    0.190371    0.255329   -0.330129    -0.610603 
  0.429839    0.285093     0.509121     0.216452     0.193263    0.505261    -0.344653   -0.0682959  -0.122365    0.00331418   0.552046    -0.410883     0.167612    0.166308     0.137617    -0.401274    0.532152     0.496722     -0.481609     0.164062    0.342506   -0.869342   -0.169923    0.282681   -0.638782    -0.305899 
 -0.369006   -0.175107     0.0576276    0.00186546  -0.46466     0.0451167   -0.341044   -0.0337037   0.274612    0.0996165    0.209458     0.162443    -0.27215    -0.406542     0.109266     0.12646    -0.499824     0.461235     -0.20814      0.503262    0.256343   -0.242558    0.489325   -0.0418118   0.158195     0.0416536
  0.317932    0.312848     0.610525     0.925825    -0.564022   -0.0339513   -0.612784   -0.2477     -0.18717     0.0870118    0.538872    -0.0821813   -0.0148837   0.0729252    0.474161     0.528706    0.00426901   0.107403      0.655295     0.220915   -0.363817   -0.170789    0.403392    0.426971    0.23683     -0.309695 
  0.230878   -0.0151047   -0.115644     0.123995     0.148704    0.476139     0.477993    0.040737    0.110854   -0.4446       0.091675     0.427855    -0.677804    0.128859    -0.347397    -0.263979    0.278111    -0.0250591     0.502339     0.0383878  -0.347865    0.0327962   0.236842    0.0392623   0.270446     0.0534701
 -0.0976292   0.715749    -0.217714    -0.242409    -0.217788    0.566879    -0.220352    0.417952   -0.340917    0.0708491    0.23729     -0.718901     0.0939342   0.362841    -0.250699    -0.269794    0.00341174   0.982068     -0.0238419   -0.184603    0.390383    0.335608    1.15979     0.435736    0.189278     0.0114602
 -0.1746     -0.290743     0.224139    -0.172566     0.78545    -0.229527     0.0350321   0.409961    0.120067   -0.0475454   -0.0997161   -0.00568526   0.0115402   0.422977    -0.288437     0.100329   -0.28496     -0.122266      0.237132    -0.240162    0.421024    0.0925913   0.249953   -0.155032   -0.162934     0.282618 
  0.773777   -0.270525    -0.0975863    0.256038     0.196242   -0.0569337    0.515227    0.196994    0.0360729  -0.15682      0.176202    -0.382355    -0.0844699  -0.249748     0.253207     0.525921    0.307927     0.233106     -0.163837     0.0395525  -0.399934    0.3738     -0.129673   -0.316282    0.123163     0.423607 
  0.230481    0.0904874    0.545344     0.488406     0.086179   -0.179785     0.195421   -0.504466    0.223128   -0.226557    -0.174446    -0.180755     0.821769    0.486422    -0.0124373   -0.595926   -0.221956    -0.0154366     0.0221011   -0.367899    0.0887219  -0.0946135  -0.684589   -0.278676    0.0919535    0.0037356
  0.055834   -0.511047     0.17614      0.717609    -0.480792   -0.00170335   0.171623   -0.0169035  -0.255566   -0.335999    -0.0962791   -0.379133    -0.75818    -0.835117     0.348394     0.332246   -0.255955     0.0359119    -0.246577    -0.179344    0.542603    0.357203    0.168767    0.151883   -0.796596     0.319829 
  0.109966   -0.279371     0.204432    -0.0175983    0.341998   -0.349044     0.305019    0.0809396   0.114731   -0.0996113   -0.117758     0.100805    -0.167904    0.123095    -0.0813502   -0.057931    0.286334    -0.393195      0.238656    -0.400227   -0.0795498   0.468628   -0.018868   -0.142772    0.0507705    0.345115 
  0.0325533   0.375885    -0.399645    -0.166999     0.240154    0.0369072   -0.198171   -0.214339    0.0488026   0.00572686  -0.175852     0.477905     0.0739389   0.657078    -0.125889    -0.372333   -0.187764    -0.115456      0.526637    -0.0427734  -0.299219   -0.815443    0.0348775   0.327761    0.203903    -0.817161 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413820
[ Info: iteration 2, average log likelihood -1.413806
[ Info: iteration 3, average log likelihood -1.413792
[ Info: iteration 4, average log likelihood -1.413778
[ Info: iteration 5, average log likelihood -1.413765
[ Info: iteration 6, average log likelihood -1.413753
[ Info: iteration 7, average log likelihood -1.413741
[ Info: iteration 8, average log likelihood -1.413730
[ Info: iteration 9, average log likelihood -1.413719
[ Info: iteration 10, average log likelihood -1.413709
┌ Info: EM with 100000 data points 10 iterations avll -1.413709
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
