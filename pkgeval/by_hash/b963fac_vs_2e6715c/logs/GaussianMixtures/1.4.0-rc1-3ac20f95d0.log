Julia Version 1.4.0-rc1.4
Commit 3ac20f95d0 (2020-01-26 14:15 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed URIParser ────────── v0.4.0
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+4
  Installed FillArrays ───────── v0.8.4
  Installed Arpack ───────────── v0.4.0
  Installed StatsFuns ────────── v0.9.3
  Installed CMakeWrapper ─────── v0.2.3
  Installed SortingAlgorithms ── v0.3.1
  Installed Rmath ────────────── v0.6.0
  Installed BinDeps ──────────── v1.0.0
  Installed QuadGK ───────────── v2.3.1
  Installed StatsBase ────────── v0.32.0
  Installed Distributions ────── v0.22.3
  Installed Blosc ────────────── v0.5.1
  Installed StaticArrays ─────── v0.12.1
  Installed HDF5 ─────────────── v0.12.5
  Installed NearestNeighbors ─── v0.4.4
  Installed BinaryProvider ───── v0.5.8
  Installed Arpack_jll ───────── v3.5.0+2
  Installed SpecialFunctions ─── v0.9.0
  Installed DataStructures ───── v0.17.9
  Installed ScikitLearnBase ──── v0.5.0
  Installed Distances ────────── v0.8.2
  Installed Compat ───────────── v2.2.0
  Installed Parameters ───────── v0.12.0
  Installed CMake ────────────── v1.1.2
  Installed OrderedCollections ─ v1.1.0
  Installed DataAPI ──────────── v1.1.0
  Installed LegacyStrings ────── v0.4.1
  Installed FileIO ───────────── v1.2.1
  Installed Missings ─────────── v0.4.3
  Installed Clustering ───────── v0.13.3
  Installed JLD ──────────────── v0.9.1
#=#=#                                                                         #####                                                                      7.1%######################################################################## 100.0%
#=#=#                                                                                                                                                    0.1%#############                                                             19.4%##################################                                        47.4%################################################                          67.0%##########################################################                81.7%#####################################################################     96.7%######################################################################## 100.0%
#=#=#                                                                         #######                                                                   10.9%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_LlN93q/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [9abbd945] Profile 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.3646544214912723e6, [99987.887020953, 12.11297904699459], [457.7895328572944 131.7276257329862 -32.98857376881444; 10.985459232554296 37.89535749559615 20.18322221693863], [[99410.49918626924 -544.9246800351707 -58.509613237050274; -544.9246800351707 99081.50020382024 701.6658462967129; -58.509613237050274 701.6658462967129 99826.04350287055], [74.56673293698411 18.290969873319572 17.40279268290187; 18.29096987331957 130.6898122828664 56.96688727092725; 17.40279268290187 56.966887270927245 42.19144559843138]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.563161e+03
      1       1.007885e+03      -5.552754e+02 |        5
      2       9.717730e+02      -3.611216e+01 |        0
      3       9.717730e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 971.7730182956711)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070196
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.858629
[ Info: iteration 2, lowerbound -3.758382
[ Info: iteration 3, lowerbound -3.656562
[ Info: iteration 4, lowerbound -3.534972
[ Info: iteration 5, lowerbound -3.402960
[ Info: iteration 6, lowerbound -3.281427
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -3.171704
[ Info: iteration 8, lowerbound -3.065315
[ Info: iteration 9, lowerbound -2.978923
[ Info: iteration 10, lowerbound -2.913565
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.861031
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.817605
[ Info: iteration 13, lowerbound -2.796878
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.788687
[ Info: iteration 15, lowerbound -2.779531
[ Info: iteration 16, lowerbound -2.771293
[ Info: iteration 17, lowerbound -2.758434
[ Info: iteration 18, lowerbound -2.738408
[ Info: iteration 19, lowerbound -2.707956
[ Info: iteration 20, lowerbound -2.663954
[ Info: iteration 21, lowerbound -2.605653
[ Info: iteration 22, lowerbound -2.537735
[ Info: iteration 23, lowerbound -2.470429
[ Info: iteration 24, lowerbound -2.413427
[ Info: iteration 25, lowerbound -2.369692
[ Info: iteration 26, lowerbound -2.337342
[ Info: iteration 27, lowerbound -2.315777
[ Info: iteration 28, lowerbound -2.307451
[ Info: dropping number of Gaussions to 2
[ Info: iteration 29, lowerbound -2.302964
[ Info: iteration 30, lowerbound -2.299262
[ Info: iteration 31, lowerbound -2.299257
[ Info: iteration 32, lowerbound -2.299255
[ Info: iteration 33, lowerbound -2.299254
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Jan 26 22:33:27 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Jan 26 22:33:35 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Jan 26 22:33:37 2020: EM with 272 data points 0 iterations avll -2.070196
5.8 data points per parameter
, Sun Jan 26 22:33:39 2020: GMM converted to Variational GMM
, Sun Jan 26 22:33:47 2020: iteration 1, lowerbound -3.858629
, Sun Jan 26 22:33:47 2020: iteration 2, lowerbound -3.758382
, Sun Jan 26 22:33:47 2020: iteration 3, lowerbound -3.656562
, Sun Jan 26 22:33:47 2020: iteration 4, lowerbound -3.534972
, Sun Jan 26 22:33:47 2020: iteration 5, lowerbound -3.402960
, Sun Jan 26 22:33:47 2020: iteration 6, lowerbound -3.281427
, Sun Jan 26 22:33:48 2020: dropping number of Gaussions to 6
, Sun Jan 26 22:33:48 2020: iteration 7, lowerbound -3.171704
, Sun Jan 26 22:33:48 2020: iteration 8, lowerbound -3.065315
, Sun Jan 26 22:33:48 2020: iteration 9, lowerbound -2.978923
, Sun Jan 26 22:33:48 2020: iteration 10, lowerbound -2.913565
, Sun Jan 26 22:33:48 2020: dropping number of Gaussions to 5
, Sun Jan 26 22:33:48 2020: iteration 11, lowerbound -2.861031
, Sun Jan 26 22:33:48 2020: dropping number of Gaussions to 4
, Sun Jan 26 22:33:48 2020: iteration 12, lowerbound -2.817605
, Sun Jan 26 22:33:48 2020: iteration 13, lowerbound -2.796878
, Sun Jan 26 22:33:48 2020: dropping number of Gaussions to 3
, Sun Jan 26 22:33:48 2020: iteration 14, lowerbound -2.788687
, Sun Jan 26 22:33:48 2020: iteration 15, lowerbound -2.779531
, Sun Jan 26 22:33:48 2020: iteration 16, lowerbound -2.771293
, Sun Jan 26 22:33:48 2020: iteration 17, lowerbound -2.758434
, Sun Jan 26 22:33:48 2020: iteration 18, lowerbound -2.738408
, Sun Jan 26 22:33:48 2020: iteration 19, lowerbound -2.707956
, Sun Jan 26 22:33:48 2020: iteration 20, lowerbound -2.663954
, Sun Jan 26 22:33:48 2020: iteration 21, lowerbound -2.605653
, Sun Jan 26 22:33:48 2020: iteration 22, lowerbound -2.537735
, Sun Jan 26 22:33:48 2020: iteration 23, lowerbound -2.470429
, Sun Jan 26 22:33:48 2020: iteration 24, lowerbound -2.413427
, Sun Jan 26 22:33:48 2020: iteration 25, lowerbound -2.369692
, Sun Jan 26 22:33:48 2020: iteration 26, lowerbound -2.337342
, Sun Jan 26 22:33:48 2020: iteration 27, lowerbound -2.315777
, Sun Jan 26 22:33:48 2020: iteration 28, lowerbound -2.307451
, Sun Jan 26 22:33:48 2020: dropping number of Gaussions to 2
, Sun Jan 26 22:33:48 2020: iteration 29, lowerbound -2.302964
, Sun Jan 26 22:33:48 2020: iteration 30, lowerbound -2.299262
, Sun Jan 26 22:33:48 2020: iteration 31, lowerbound -2.299257
, Sun Jan 26 22:33:48 2020: iteration 32, lowerbound -2.299255
, Sun Jan 26 22:33:48 2020: iteration 33, lowerbound -2.299254
, Sun Jan 26 22:33:48 2020: iteration 34, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 35, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 36, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 37, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 38, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 39, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 40, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 41, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 42, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 43, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 44, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 45, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 46, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 47, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 48, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 49, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: iteration 50, lowerbound -2.299253
, Sun Jan 26 22:33:48 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222701668, 95.95490777298338]
β = [178.04509222701668, 95.95490777298338]
m = [4.250300733261776 79.28686694424219; 2.000229257766947 53.851987172417424]
ν = [180.04509222701668, 97.95490777298338]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547373202 -0.007644049042434469; 0.0 0.008581705166182922], [0.37587636120884366 -0.00895312382751246; 0.0 0.012748664777451832]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.981687461141701
avll from llpg:  -0.9816874611417007
avll direct:     -0.9816874611417007
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9936864934238381
avll from llpg:  -0.9936864934238381
avll direct:     -0.9936864934238382
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0570097   -0.134418    -0.0211743   0.0510631   -0.121221    -0.0571667    0.101219    -0.174451    -0.150264    -0.0138718   -0.0827379   -0.0946683    0.0886977    0.210261     0.0369867   -0.00970312   0.00636388   0.0589044    0.0041357    0.00323173  -0.0920755   -0.0196512   -0.104398    -0.0959487    0.0166726    0.0796271
  0.0264728    0.00590894   0.0266852   0.0111234    0.188509    -0.102696     0.0499198   -0.175816     0.092394     0.055056    -0.149397     0.0896822   -0.0545795   -0.150683    -0.276768    -0.0471037   -0.0418063   -0.0189075    0.0379149   -0.102387    -0.108746     0.0094862    0.0855703    0.014899     0.149629     0.0309421
 -0.0207205    0.208367     0.0646987  -0.0860226    0.0464897    0.104334    -0.1333       0.0263029    0.0356705    0.0957201   -0.0353812   -0.126233    -0.0359556   -0.0558849    0.0297999   -0.00289987  -0.0119647    0.313948     0.0480337    0.0831053    0.101441     0.167586     0.154562    -0.0248251    0.0979227   -0.0374924
 -0.212686    -0.0527062    0.0701644  -0.0767935   -0.104125     0.0164762   -0.114722    -0.00521567  -0.0534334   -0.0446632    0.0357079   -0.0937332    0.0686093   -0.101948     0.130796    -0.0271266   -0.117134     0.180518    -0.175997    -0.131562     0.014165    -0.0223084    0.0184675    0.0985291    0.00786365  -0.168411
 -0.0468457    0.0645199    0.0192192   0.0948006   -0.0590654    0.0399111   -0.0511846   -0.0220252    0.065239     0.150816    -0.0789088    0.103097    -0.0387337   -0.0339317   -0.019719     0.100923     0.0198677   -0.15115      0.0438436    0.0344671    0.172662    -0.147564     0.00298581  -0.125567    -0.0511664    0.035798
 -0.137696    -0.108429    -0.165491    0.0484751    0.0336863    0.0493721   -0.0443795   -0.21642      0.0192508   -0.085898    -0.031371    -0.0449737    0.010839    -0.120907    -0.100598     0.0208736   -0.0710801   -0.0577389   -0.0170737    0.0577768   -0.0440282   -0.0335478   -0.0174662   -0.0315447   -0.0913079   -0.097718
 -0.139179    -0.0647885    0.0332513  -0.254937     0.00189942   0.216567    -0.0698321   -0.0927655    0.166817    -0.0239429   -0.0529852   -0.100493    -0.177143    -0.0421582   -0.082715    -0.0149684    0.102262    -0.034675    -0.233544     0.00660248   0.0961249   -0.0184257   -0.0948755   -0.0422243    0.166698    -0.0981732
 -0.0774932   -0.0802829   -0.0862435  -0.0321249   -0.0949999    0.106616     0.0698508   -0.137967    -0.0307779   -0.108034     0.0844176    0.0313296    0.182365     0.14433      0.0461903    0.121284     0.0852065   -0.106593    -0.228938     0.107112    -0.0894986    0.0193183   -0.0447129   -0.106106    -0.0323346   -0.0432421
  0.0507429    0.0186357    0.157846   -0.0110487   -0.0460555   -0.0367667    0.0711794    0.137967     0.102149    -0.0465939   -0.106876    -0.0414471   -0.0441674    0.109763     0.0727344   -0.0698146   -0.0531854    0.0098931    0.111503    -0.217787    -0.0401766   -0.147369     0.0539541    0.0716839   -0.0821325   -0.0323396
  0.0470024    0.165312    -0.0653143  -0.0183782    0.177415     0.0283359   -0.133326    -0.189314    -0.155442     0.11582      0.176523     0.137156     0.018829     0.0438334   -0.111554    -0.019055    -0.0260177   -0.11831     -0.051348     0.0757153    0.185054    -0.220439    -0.174831     0.0459684   -0.177802    -0.0320011
 -0.0836701    0.078889     0.0565228  -0.100876    -0.0378962   -0.066232     0.0942601    0.0121709   -0.0028154    0.0495273   -0.0406681   -0.0589653    0.0911339   -0.037416    -0.0473916   -0.0581837   -0.0544478    0.217198     0.0422102    0.0338762   -0.136562    -0.00333544   0.0322887    0.00747936   0.0389497   -0.196507
  0.053213     0.183559     0.0779139  -0.102013    -0.0788353    0.0353201    0.162831    -0.0896383   -0.0625154   -0.133818     0.0338522    0.0101741   -0.0227312    0.00283908   0.143984    -0.0120543    0.0570443   -0.0279711    0.0400835   -0.221772     0.0699942   -0.196456    -0.0861723    0.0458007    0.0884454   -0.109491
 -0.0742067    0.0936564   -0.0712945   0.169211     0.0582062   -0.00914847  -0.0405859   -0.0114468   -0.147273     0.0159547   -0.00431318   0.0795333    0.147587     0.0720356    0.0296944   -0.0489368    0.0144182    0.00036709   0.00722723   0.00765383   0.151593    -0.113799    -0.196815     0.00388635  -0.054244    -0.0199258
  0.0842278   -0.0253346   -0.187834    0.305986    -0.119503     0.149346     0.0323819   -0.00262841   0.0266907   -0.026171     0.0885761   -0.15785     -0.197824    -0.0594159   -0.0276202   -0.145637    -0.0494781   -0.192547    -0.0371381   -0.0532989   -0.140575    -0.165972     0.0330438    0.0253177    0.103441     0.0203105
 -0.0927848   -0.166049    -0.138059    0.0237031    0.130708    -0.129828    -0.0332372    0.191002     0.0464261    0.00925472  -0.0138276   -0.078895    -0.0124103   -0.0215655    0.0507784    0.0423977    0.095019     0.0244667    0.142787    -0.127366    -0.0660798   -0.0881101    0.0162934    0.174652    -0.0579243    0.132378
  0.0156031   -0.0294669    0.03446     0.0112199    0.170719     0.0550615   -0.0370307    0.0451266    0.112377    -0.185876     0.0824213    0.0176736   -0.0901314   -0.0876749   -0.018477     0.0370542    0.00811398  -0.0103858    0.00214936  -0.0155982   -0.0310769   -0.0721149   -0.00420467  -0.136094    -0.130849    -0.00674591
 -0.136208     0.0891004   -0.0635936  -0.0574882   -0.0440974   -0.0640953   -0.057257    -0.00724112   0.0407368    0.0247694   -0.00967432   0.00524592  -0.0139217    0.190848     0.0996543    0.0294123   -0.0140081    0.127232    -0.0904514    0.102771     0.0393838   -0.0328132    0.0674       0.119118     0.00475676   0.0801384
  0.0969646    0.128939     0.0711074  -0.0350557    0.066619     0.184673    -0.00450174   0.0759294   -0.109194    -0.039351     0.0525412    0.0847063    0.141073    -0.0768801    0.269257    -0.0280234    0.101239    -0.0408478    0.0708928    0.0955045    0.10487     -0.0924084    0.14494      0.0422068   -0.161005     0.0110543
 -0.1083       0.0896595   -0.112058   -0.066135     0.0856833    0.0362498    0.0459942    0.245637     0.0830841   -0.0248969    0.0853456   -0.0495982    0.0850064   -0.12173      0.0846349   -0.210152    -0.0974822   -0.169056    -0.0730096   -0.022571    -0.119965    -0.178962     0.0634629   -0.0257461   -0.0670376    0.0187491
 -0.131932     0.0659679   -0.0187608  -0.0440168    0.0407735    0.0943515    0.0619824   -0.056992    -0.0534441   -0.130528     0.0998708   -0.196387     0.116313    -0.0552582   -0.0611061    0.0445304    0.0288221    0.0653736   -0.0505377   -0.0742533    0.182468     0.0904012   -0.0536234    0.115831    -0.0885963    0.216634
 -0.091124    -0.11801      0.119785    0.10092     -0.022745     0.142969    -0.0488044    0.150516     0.13788     -0.169228     0.184139    -0.0278719   -0.159899     0.153618     0.0359719    0.00856628   0.0646512    0.096267     0.0311541   -0.12067     -0.0385548   -0.0101096    0.143044     0.128419     0.0762522    0.166349
 -0.128622     0.154519     0.0226102  -0.214344     0.0930195   -0.0958551   -0.102829     0.00634395  -0.00443272  -0.0902846    0.0901541    0.0444056    0.0599685    0.0564046   -0.229867     0.035907     0.0940937   -0.100837    -0.152592     0.101897    -0.120267    -0.0413986   -0.119633    -0.0960231    0.0118225   -0.0497224
  0.0146052   -0.0295069   -0.105646   -0.122043    -0.0962891   -0.155484     0.120785    -0.0220973   -0.0296609    0.181556     0.200737     0.0374722   -0.00235787   0.0204862    0.0824048   -0.122199    -0.010714     0.22771      0.0253977   -0.0249414   -0.01182     -0.134357    -0.11031     -0.16692     -0.180674    -0.0436987
  0.00189693   0.00408152  -0.139865    0.00174574  -0.0677127    0.0209904    0.091185    -0.140955    -0.0240118    0.00432838   0.206304     0.120101     0.027379     0.0213       0.12982      0.00468022  -0.0029016   -0.0830429    0.0505381   -0.111502     0.125662    -0.0458221   -0.0751336   -0.109905    -0.0145235   -0.156793
  0.024572     0.136367    -0.0898407  -0.0462023   -0.0129048    0.0802845   -0.116608    -0.102478     0.00160931  -0.0924617   -0.0733447    0.122534    -0.175579    -0.0128328    0.0729337   -0.255579    -0.0600872   -0.0403582    0.017113    -0.319146    -0.0222908   -0.0733595   -0.00897595  -0.0578725    0.0750178   -0.0486799
 -0.156883    -0.0904085   -0.0708678  -0.0155893    0.0596566    0.143728    -0.273473    -0.137692    -0.109746    -0.0118805    0.0220424    0.0315688   -0.0412463   -0.0875451    0.150052    -0.0258875    0.116662    -0.0267686   -0.0531566   -0.00032727   0.0916991    0.0378465    0.0626462    0.140138    -0.0584987   -0.0990643
 -0.109086    -0.0683911    0.108508   -0.0727225   -0.0145566    0.174149     0.188213     0.0194633   -0.105647     0.00207255  -0.262063     0.205428     0.00244913  -0.0658784   -0.0294313   -0.252623     0.00981097   0.0459863   -0.0192909   -0.0642615   -0.00112307  -0.00784553  -0.0605653    0.0273328    0.092174    -0.165906
 -0.0874084   -0.038777    -0.127376   -0.0449691   -0.191027     0.242118    -0.0667525   -0.0187945    0.0260751   -0.0795227    0.106669    -0.14915     -0.0164902    0.096766     0.249794    -0.106071     0.0189634    0.0317968   -0.109547     0.0172608   -0.165399     0.0603375   -0.067682     0.110773    -0.0495482   -0.0579135
 -0.166437    -0.0900445    0.167508    0.092138    -0.0624785   -0.0318229    0.155634     0.0539731    0.0911756    0.0233309   -0.0269302    0.107785    -0.0234634   -0.0710692   -0.00795083  -0.147413     0.0766053   -0.0140577   -0.0207581   -0.0652784    0.195124     0.0580852    0.115315     0.196015    -0.086177     0.00226948
  0.0249406   -0.0699641    0.169361    0.0898317   -0.0492766   -0.122991    -0.0292428   -0.0116299   -0.0900144   -0.1396       0.0997485    0.0696878    0.00891454   0.121788     0.0618983   -0.123013     0.161503    -0.0253447   -0.113024     0.00819677   0.0120157    0.13927     -0.0437167    0.123012     0.0966923    0.0425454
  0.208012     0.0198576    0.0184589   0.177593     0.082621     0.0759702    0.0488965    0.0973372    0.0852676    0.0896844    0.0841173   -0.04432      0.0457864   -0.019365     0.0830108   -0.0165359    0.161365    -0.0828624   -0.0883246   -0.0738398    0.101527    -0.0251137   -0.0561542    0.00213428  -0.104395     0.0689333
  0.0509159    0.0578432   -0.103431    0.214523     0.10178      0.0140847   -0.0418213    0.0530027   -0.0330073   -0.0750417    0.184855     0.157622    -0.0411766    0.0567415   -0.0172316   -0.0119938    0.0094975   -0.228309    -0.0347397   -0.0168563    0.0442032   -0.0291241    0.0977829   -0.019815     0.0178764   -0.100536kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3957456534238644
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395835
[ Info: iteration 2, average log likelihood -1.395760
[ Info: iteration 3, average log likelihood -1.395384
[ Info: iteration 4, average log likelihood -1.390301
[ Info: iteration 5, average log likelihood -1.371575
[ Info: iteration 6, average log likelihood -1.362034
[ Info: iteration 7, average log likelihood -1.360770
[ Info: iteration 8, average log likelihood -1.360361
[ Info: iteration 9, average log likelihood -1.360179
[ Info: iteration 10, average log likelihood -1.360092
[ Info: iteration 11, average log likelihood -1.360046
[ Info: iteration 12, average log likelihood -1.360019
[ Info: iteration 13, average log likelihood -1.360001
[ Info: iteration 14, average log likelihood -1.359990
[ Info: iteration 15, average log likelihood -1.359982
[ Info: iteration 16, average log likelihood -1.359976
[ Info: iteration 17, average log likelihood -1.359971
[ Info: iteration 18, average log likelihood -1.359968
[ Info: iteration 19, average log likelihood -1.359966
[ Info: iteration 20, average log likelihood -1.359964
[ Info: iteration 21, average log likelihood -1.359963
[ Info: iteration 22, average log likelihood -1.359962
[ Info: iteration 23, average log likelihood -1.359961
[ Info: iteration 24, average log likelihood -1.359961
[ Info: iteration 25, average log likelihood -1.359960
[ Info: iteration 26, average log likelihood -1.359960
[ Info: iteration 27, average log likelihood -1.359960
[ Info: iteration 28, average log likelihood -1.359960
[ Info: iteration 29, average log likelihood -1.359960
[ Info: iteration 30, average log likelihood -1.359959
[ Info: iteration 31, average log likelihood -1.359959
[ Info: iteration 32, average log likelihood -1.359959
[ Info: iteration 33, average log likelihood -1.359959
[ Info: iteration 34, average log likelihood -1.359959
[ Info: iteration 35, average log likelihood -1.359959
[ Info: iteration 36, average log likelihood -1.359959
[ Info: iteration 37, average log likelihood -1.359959
[ Info: iteration 38, average log likelihood -1.359959
[ Info: iteration 39, average log likelihood -1.359959
[ Info: iteration 40, average log likelihood -1.359959
[ Info: iteration 41, average log likelihood -1.359959
[ Info: iteration 42, average log likelihood -1.359959
[ Info: iteration 43, average log likelihood -1.359959
[ Info: iteration 44, average log likelihood -1.359959
[ Info: iteration 45, average log likelihood -1.359959
[ Info: iteration 46, average log likelihood -1.359959
[ Info: iteration 47, average log likelihood -1.359959
[ Info: iteration 48, average log likelihood -1.359959
[ Info: iteration 49, average log likelihood -1.359959
[ Info: iteration 50, average log likelihood -1.359959
┌ Info: EM with 100000 data points 50 iterations avll -1.359959
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3958345753756143
│     -1.3957604564237511
│      ⋮
└     -1.3599591828341637
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.360074
[ Info: iteration 2, average log likelihood -1.359974
[ Info: iteration 3, average log likelihood -1.359622
[ Info: iteration 4, average log likelihood -1.356421
[ Info: iteration 5, average log likelihood -1.345527
[ Info: iteration 6, average log likelihood -1.335454
[ Info: iteration 7, average log likelihood -1.331316
[ Info: iteration 8, average log likelihood -1.329798
[ Info: iteration 9, average log likelihood -1.328947
[ Info: iteration 10, average log likelihood -1.328284
[ Info: iteration 11, average log likelihood -1.327685
[ Info: iteration 12, average log likelihood -1.327134
[ Info: iteration 13, average log likelihood -1.326605
[ Info: iteration 14, average log likelihood -1.326075
[ Info: iteration 15, average log likelihood -1.325559
[ Info: iteration 16, average log likelihood -1.325050
[ Info: iteration 17, average log likelihood -1.324569
[ Info: iteration 18, average log likelihood -1.324131
[ Info: iteration 19, average log likelihood -1.323729
[ Info: iteration 20, average log likelihood -1.323339
[ Info: iteration 21, average log likelihood -1.322926
[ Info: iteration 22, average log likelihood -1.322473
[ Info: iteration 23, average log likelihood -1.321991
[ Info: iteration 24, average log likelihood -1.321487
[ Info: iteration 25, average log likelihood -1.320951
[ Info: iteration 26, average log likelihood -1.320407
[ Info: iteration 27, average log likelihood -1.319832
[ Info: iteration 28, average log likelihood -1.319223
[ Info: iteration 29, average log likelihood -1.318624
[ Info: iteration 30, average log likelihood -1.318127
[ Info: iteration 31, average log likelihood -1.317689
[ Info: iteration 32, average log likelihood -1.317226
[ Info: iteration 33, average log likelihood -1.316711
[ Info: iteration 34, average log likelihood -1.316143
[ Info: iteration 35, average log likelihood -1.315549
[ Info: iteration 36, average log likelihood -1.314981
[ Info: iteration 37, average log likelihood -1.314497
[ Info: iteration 38, average log likelihood -1.314111
[ Info: iteration 39, average log likelihood -1.313820
[ Info: iteration 40, average log likelihood -1.313620
[ Info: iteration 41, average log likelihood -1.313483
[ Info: iteration 42, average log likelihood -1.313383
[ Info: iteration 43, average log likelihood -1.313308
[ Info: iteration 44, average log likelihood -1.313250
[ Info: iteration 45, average log likelihood -1.313205
[ Info: iteration 46, average log likelihood -1.313168
[ Info: iteration 47, average log likelihood -1.313137
[ Info: iteration 48, average log likelihood -1.313110
[ Info: iteration 49, average log likelihood -1.313087
[ Info: iteration 50, average log likelihood -1.313068
┌ Info: EM with 100000 data points 50 iterations avll -1.313068
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3600743323135978
│     -1.3599737573137511
│      ⋮
└     -1.3130682802413156
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.313196
[ Info: iteration 2, average log likelihood -1.313021
[ Info: iteration 3, average log likelihood -1.312227
[ Info: iteration 4, average log likelihood -1.305393
[ Info: iteration 5, average log likelihood -1.286676
[ Info: iteration 6, average log likelihood -1.272852
[ Info: iteration 7, average log likelihood -1.266659
[ Info: iteration 8, average log likelihood -1.263374
[ Info: iteration 9, average log likelihood -1.261665
[ Info: iteration 10, average log likelihood -1.260601
[ Info: iteration 11, average log likelihood -1.259756
[ Info: iteration 12, average log likelihood -1.259030
[ Info: iteration 13, average log likelihood -1.258525
[ Info: iteration 14, average log likelihood -1.258202
[ Info: iteration 15, average log likelihood -1.257949
[ Info: iteration 16, average log likelihood -1.257714
[ Info: iteration 17, average log likelihood -1.257480
[ Info: iteration 18, average log likelihood -1.257253
[ Info: iteration 19, average log likelihood -1.257055
[ Info: iteration 20, average log likelihood -1.256902
[ Info: iteration 21, average log likelihood -1.256786
[ Info: iteration 22, average log likelihood -1.256684
[ Info: iteration 23, average log likelihood -1.256570
[ Info: iteration 24, average log likelihood -1.256414
[ Info: iteration 25, average log likelihood -1.256150
[ Info: iteration 26, average log likelihood -1.255588
[ Info: iteration 27, average log likelihood -1.254402
[ Info: iteration 28, average log likelihood -1.252502
[ Info: iteration 29, average log likelihood -1.251762
[ Info: iteration 30, average log likelihood -1.251742
[ Info: iteration 31, average log likelihood -1.251736
[ Info: iteration 32, average log likelihood -1.251732
[ Info: iteration 33, average log likelihood -1.251729
[ Info: iteration 34, average log likelihood -1.251727
[ Info: iteration 35, average log likelihood -1.251726
[ Info: iteration 36, average log likelihood -1.251725
[ Info: iteration 37, average log likelihood -1.251724
[ Info: iteration 38, average log likelihood -1.251724
[ Info: iteration 39, average log likelihood -1.251723
[ Info: iteration 40, average log likelihood -1.251723
[ Info: iteration 41, average log likelihood -1.251723
[ Info: iteration 42, average log likelihood -1.251723
[ Info: iteration 43, average log likelihood -1.251723
[ Info: iteration 44, average log likelihood -1.251723
[ Info: iteration 45, average log likelihood -1.251723
[ Info: iteration 46, average log likelihood -1.251723
[ Info: iteration 47, average log likelihood -1.251723
[ Info: iteration 48, average log likelihood -1.251723
[ Info: iteration 49, average log likelihood -1.251723
[ Info: iteration 50, average log likelihood -1.251723
┌ Info: EM with 100000 data points 50 iterations avll -1.251723
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3131963071012691
│     -1.3130205711981828
│      ⋮
└     -1.2517225447605125
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251934
[ Info: iteration 2, average log likelihood -1.251726
[ Info: iteration 3, average log likelihood -1.251157
[ Info: iteration 4, average log likelihood -1.243969
[ Info: iteration 5, average log likelihood -1.215861
[ Info: iteration 6, average log likelihood -1.190319
[ Info: iteration 7, average log likelihood -1.174790
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.165690
[ Info: iteration 9, average log likelihood -1.190467
[ Info: iteration 10, average log likelihood -1.176525
[ Info: iteration 11, average log likelihood -1.168807
[ Info: iteration 12, average log likelihood -1.162934
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.157306
[ Info: iteration 14, average log likelihood -1.184407
[ Info: iteration 15, average log likelihood -1.170970
[ Info: iteration 16, average log likelihood -1.164987
[ Info: iteration 17, average log likelihood -1.161774
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.157745
[ Info: iteration 19, average log likelihood -1.183125
[ Info: iteration 20, average log likelihood -1.170015
[ Info: iteration 21, average log likelihood -1.164553
[ Info: iteration 22, average log likelihood -1.162325
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.160517
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.169949
[ Info: iteration 25, average log likelihood -1.168612
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.158230
[ Info: iteration 27, average log likelihood -1.172957
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.165452
[ Info: iteration 29, average log likelihood -1.173505
[ Info: iteration 30, average log likelihood -1.164745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.159113
[ Info: iteration 32, average log likelihood -1.172095
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.164655
[ Info: iteration 34, average log likelihood -1.172629
[ Info: iteration 35, average log likelihood -1.164133
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.158924
[ Info: iteration 37, average log likelihood -1.171537
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.164309
[ Info: iteration 39, average log likelihood -1.172437
[ Info: iteration 40, average log likelihood -1.164190
[ Info: iteration 41, average log likelihood -1.159292
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.154667
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.170259
[ Info: iteration 44, average log likelihood -1.175279
[ Info: iteration 45, average log likelihood -1.165612
[ Info: iteration 46, average log likelihood -1.161535
[ Info: iteration 47, average log likelihood -1.157696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.153151
[ Info: iteration 49, average log likelihood -1.181080
[ Info: iteration 50, average log likelihood -1.168342
┌ Info: EM with 100000 data points 50 iterations avll -1.168342
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2519343170935846
│     -1.2517264779765356
│      ⋮
└     -1.168341881835936
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.162975
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.159352
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.156080
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.139778
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.085537
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.061390
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.073275
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     16
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.069391
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079614
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076050
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      5
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.055922
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.063188
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.085351
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.063870
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064131
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.079903
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.056211
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     19
│     20
│     21
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.063424
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.080768
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.067900
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.065439
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.066430
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      5
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.060673
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     19
│     20
│     21
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.063891
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.077273
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.055641
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.056935
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.070600
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.062935
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     15
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.056880
[ Info: iteration 31, average log likelihood -1.081003
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     11
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.045697
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.063123
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.075704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057487
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.061150
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.070582
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     19
│     20
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.051596
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.068017
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.070394
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.061808
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051155
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.076639
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     19
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.056892
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062743
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.075035
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.051883
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     20
│     21
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.057251
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.081635
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     15
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.051439
┌ Info: EM with 100000 data points 50 iterations avll -1.051439
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1629754288491247
│     -1.1593522931979565
│      ⋮
└     -1.0514391449792173
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3957456534238644
│     -1.3958345753756143
│     -1.3957604564237511
│     -1.3953844375606432
│      ⋮
│     -1.0572511738894321
│     -1.081634873125247
└     -1.0514391449792173
32×26 Array{Float64,2}:
 -0.210004    -0.022757    0.0734962   -0.0690312   -0.105296     0.0164747   -0.114036    -0.00978093  -0.0415336   -0.0450576    0.0353943   -0.144921      0.0779428   -0.110011     0.145018    -0.0055779   -0.136781     0.136935     -0.172349    -0.109149     0.0172057   -0.0238915    0.0174302    0.0981611    0.00541745  -0.167739
 -0.0973626    0.11154    -0.0796378    0.172776     0.072614    -0.00848009  -0.00794497  -0.0222378   -0.126696     0.0136409   -0.0199753    0.0961401     0.148375     0.0772296    0.038604    -0.0486161    0.0139182   -0.0226353     0.00684738   0.0267558    0.158592    -0.117518    -0.169549    -0.00714903  -0.0236926   -0.0310849
 -1.20483     -0.178276    0.0320454   -0.238909     0.0675221    0.219155    -0.0561098   -0.0922525    0.164428     0.00306576  -0.0483858   -0.0909754    -0.206381    -0.0581274   -0.0833659   -0.0131642    0.0914958   -0.0937301    -0.241234     0.00883319   0.105838    -0.018822    -0.202053    -0.0333336    0.133828    -0.090774
  1.00022      0.0248742   0.00637261  -0.274778    -0.0381153    0.202099    -0.0648269   -0.0958383    0.158562    -0.0485651   -0.0594573   -0.114387     -0.117023    -0.00348639  -0.0818172   -0.0142688    0.103171     0.0854523    -0.231382    -0.00171518   0.0978918   -0.018385     0.0997789   -0.050474     0.194018    -0.108079
 -0.127786    -0.0525706   0.0763106   -0.111828    -0.00200348   0.168674     0.114466     0.0056447   -0.0657904    0.0308866   -0.230072     0.197255      0.00934953  -0.0562732   -0.0547346   -0.236039    -0.00142289   0.028491     -0.0163822   -0.0652518   -0.0213528   -0.0093414   -0.0755642    0.033949     0.0879652   -0.154021
  0.0457926   -0.026431    0.168936     0.0918183   -0.0181794   -0.113527    -0.0322938   -0.0158561   -0.083035    -0.126545     0.103341     0.0822675     0.0320358    0.121127     0.0629536   -0.112145     0.153628    -0.00456695   -0.112025     0.0161386    0.0265553    0.117422    -0.0579448    0.133188     0.0903155    0.0147639
  0.00328384   0.0657932   0.0195964    0.0985305   -0.0495771    0.0425878   -0.0480887   -0.0195932    0.0452091    0.156063    -0.0686892    0.1394       -0.0241604   -0.0335758   -0.00862637   0.097383     0.0236586   -0.152036      0.0496105    0.0354364    0.149532    -0.144737     0.00351401  -0.120721    -0.0699533    0.0370834
  0.0838292    0.12956     0.0551025   -0.0280897    0.0650351    0.183344     0.0346655    0.0646823   -0.112617    -0.042408     0.0477406    0.0698065     0.13702     -0.0300243    0.263384    -0.00947486   0.0988761   -0.0459267     0.067872     0.0927447    0.108841    -0.0958876    0.134927     0.0429254   -0.181316     0.0306378
 -0.152704     0.0542112  -0.0652275   -0.0594341    0.0352347   -0.0366214   -0.0537098   -0.0959624    0.00171685  -0.0807536    0.0387426   -0.0502107     0.0353984    0.0573859   -0.0927233    0.0318332    0.00151267   0.0107326    -0.0858978    0.055206     0.0263624   -0.018386    -0.0334553    0.0284913   -0.0272321    0.0455754
 -0.00959695   0.0152101  -0.137065     0.00397603  -0.0640651    0.0210799    0.111916    -0.139534    -0.0373554   -0.00171658   0.195787     0.115899      0.0298242    0.0207103    0.132713     0.00785263  -0.0502144   -0.0695818     0.0579429   -0.0683116    0.12996     -0.0373286   -0.0893507   -0.126569    -0.0149194   -0.172294
 -0.156746    -0.0863571  -0.0655179   -0.0289802    0.0580636    0.139925    -0.277855    -0.158758    -0.141084    -0.0116167    0.0259856    0.0111219    -0.0418174   -0.0957476    0.151012    -0.0352787    0.0903044   -0.0223371    -0.0569219    0.00744161   0.0697331    0.0415241    0.0638043    0.134671    -0.0570486   -0.0871859
 -0.0209886    0.195242    0.0485393   -0.0751948    0.0488415    0.111272    -0.154117     0.0180279    0.0350327    0.115795    -0.0339324   -0.137765     -0.0251762   -0.069961     0.00540951   0.0120892   -0.023512     0.332251      0.0452938    0.122968     0.117053     0.156285     0.151649    -0.0198952    0.115509    -0.038774
  0.0892077   -0.169393   -0.166504     0.304314    -0.121949     0.116501     0.0286668    0.0555085    0.0149098    0.0146869    0.0821847   -0.21948      -0.304596    -0.0458618   -0.0684323   -0.163417     0.0473483   -0.18291      -0.0372243   -0.0500461   -0.145576    -0.539173     0.0116593    0.0193481    0.128773     0.0347048
  0.0759905    0.0342718  -0.213572     0.262597    -0.118925     0.138086     0.0650058   -0.064029     0.039051    -0.083363     0.0938204   -0.129282     -0.113444    -0.0541337   -0.00127393  -0.157688    -0.16604     -0.156238     -0.034967    -0.0608397   -0.156578     0.233667     0.105713     0.0106996    0.0863391    0.00435686
 -0.0171102   -0.0285355   0.0388864   -0.0121953    0.16296      0.0549102    0.0035255    0.0447093    0.113341    -0.195079     0.0799448    0.0221671    -0.0889631   -0.0905015    0.0373947    0.0304777    0.0235984   -0.0177094    -0.0119531   -0.0180531   -0.0288833   -0.0796171   -0.014348    -0.156502    -0.129531     0.0010879
 -0.125617    -0.0982078   0.148889     0.102013    -0.0409623    0.0381358    0.0405567    0.098484     0.0959714   -0.0804646    0.0849449    0.0247946    -0.0973341    0.0455683    0.0175824   -0.0685934    0.0648011    0.0504487     0.00667356  -0.0899477    0.0549461    0.00595361   0.116499     0.188498     0.00295924   0.0979699
 -0.0627929   -0.0671358  -0.063285    -0.0454708   -0.092879     0.107924     0.0709416   -0.130037    -0.0364572   -0.113016     0.0877953    0.0487777     0.17192      0.127864     0.0361098    0.203358     0.0905056   -0.109314     -0.232559     0.106999    -0.0960282    0.0175379   -0.0590573   -0.121219    -0.0384312   -0.0388459
 -0.0892832    0.0977052  -0.0870574   -0.0685391    0.0483384    0.032687     0.0215795    0.233959     0.0943699    0.0491719    0.129017    -0.0241354     0.122029    -0.0979424    0.0333632   -0.182777    -0.0953592   -0.166948     -0.0647448   -0.00839603  -0.0999284   -0.179369     0.0283149   -0.0309734   -0.0666426    0.0164126
 -0.00171034   0.134336   -0.117658     0.146521     0.0558168    0.0823094   -0.0778427    0.0221006   -0.899047    -0.0855933   -0.0264932    0.105385     -0.163031    -0.004731     0.0815879   -0.00390428   0.00470168   0.0642039     0.332884    -0.318838    -0.143592    -0.0732912    0.178784     0.0512891    0.229857    -0.0187818
  0.0511257    0.141312   -0.0604185   -0.205613    -0.0417028    0.086788    -0.151593    -0.19003      0.704046    -0.0954623   -0.0692759    0.141032     -0.188357    -0.00403573   0.0620102   -0.475256    -0.163211    -0.12883      -0.184685    -0.318887     0.0254817   -0.0716267   -0.082111    -0.0888289    0.00487484  -0.0694594
  0.0478867    0.0626902   0.210732     0.214487     0.319557    -0.0601543   -0.041855     0.0528281   -0.204746    -0.0323075    0.365103     0.171881     -0.0115369   -0.728415     0.0117625   -0.0126264    0.0108618   -0.245202     -0.238313     0.0295454    0.0531395   -0.030677    -0.104954    -0.0194033   -0.200166    -0.123841
  0.0734099    0.0541852  -0.258912     0.214152    -0.0266373    0.0590211   -0.0410346    0.0523788    0.057151    -0.0925547    0.114661     0.161473     -0.0501584    0.376081    -0.0548096   -0.012616     0.00872318  -0.222056      0.0963996   -0.0520962    0.0521287   -0.0295341    0.184946    -0.0294424    0.0527158   -0.0942015
  0.0288096    0.0104512   0.0196765    0.00630849   0.164361    -0.102344     0.0462404   -0.166555     0.0930613    0.0509353   -0.139135     0.077045     -0.0282273   -0.136619    -0.276852    -0.0466267   -0.0479126   -0.065136      0.0836495   -0.0422682   -0.0980112    0.00939457   0.0788935    0.0867362    0.163126     0.0313562
 -0.103751    -0.15678    -0.137565     0.0222304    0.130645    -0.142392    -0.033062     0.191097     0.028667    -0.00358866  -0.0103183   -0.0948214     0.0125701   -0.0217076    0.0513272    0.0354254    0.105258    -0.0330879     0.163084    -0.140116    -0.0658539   -0.0932764    0.0218679    0.175166    -0.10304      0.130897
  0.101951     0.0438061   0.0884544   -0.0515911    0.0552702    0.0467589    0.211031    -0.0806113   -0.0565248   -0.138112     0.00642516   0.00875158    0.0276916   -0.070307     0.168628     0.1277       0.0704594   -0.10142       0.109624    -0.198966     0.0973466   -0.299357    -0.0845652    0.019201     0.0770918   -1.14105
  0.075796     0.0612397   0.113011     0.0179582   -0.0285771    0.034862     0.133519    -0.173521    -0.088534    -0.130433     0.119684     0.000546349  -0.391616    -0.0693387    0.115796    -0.0505444    0.0815763   -0.0695363    -0.00917139  -0.264085     0.195367    -0.0848155   -0.0858073    0.0413985    0.0926767    0.722438
 -0.0138576    0.265996    0.0527361   -0.164189    -0.182875     0.0225047    0.148486    -0.0493345   -0.0593566   -0.132861    -0.0272618    0.0145934     0.0865148   -0.00181575   0.133127    -0.0253311    0.0230509    0.107069      0.0814579   -0.246624     0.0421474   -0.175162    -0.095557     0.0540788    0.102505    -0.953724
  0.0608658    0.292203    0.0445087   -0.21348     -0.102142     0.0508959    0.154672    -0.0394921   -0.0402084   -0.134567     0.0142247    0.0245095     0.277441     0.216091     0.171872    -0.321265     0.0909634   -0.0638285     0.0686077   -0.128383    -0.0292973   -0.270791    -0.0883814    0.0740869    0.0799344    1.06605
  0.0235077   -0.0325698  -0.0825279   -0.0913757   -0.0830596   -0.120616     0.103597    -0.0585629   -0.0343746    0.167477     0.18044      0.037797      0.00584125   0.0595609    0.0735931   -0.135488     0.00049864   0.161396      0.0201539   -0.0192538    0.00156913  -0.143752    -0.109568    -0.146171    -0.180204    -0.0198286
  0.0259563    0.0293228   0.0128061    0.0306489    0.0188417   -0.00636937   0.0573603   -0.0139757   -0.0259971    0.041677     0.0128566   -0.042586      0.084289     0.0307932    0.00247138  -0.0161857    0.0313499    0.0475711    -0.0182872   -0.0134466   -0.025014    -0.0185112   -0.0339102   -0.00806389  -0.0330663   -0.0225151
  0.0543692    0.019474    0.142594     0.0101422   -0.0388684   -0.0379267    0.052465     0.113095     0.0903014   -0.040405    -0.0848867   -0.0391442    -0.0416605    0.107199     0.0156075   -0.0709916   -0.0362988   -0.000383774   0.0961298   -0.174211    -0.0226401   -0.147487     0.0561727    0.0578161   -0.0838373   -0.0376267
 -0.079454    -0.0498004  -0.132321    -0.0594239   -0.202392     0.248587    -0.0541829   -0.0273693    0.0251505   -0.0783791    0.103413    -0.15241      -0.0129093    0.0978674    0.236516    -0.107767     0.0440965    0.0512429    -0.115767     0.0230434   -0.156992     0.0534481   -0.0612299    0.116652    -0.00883875  -0.0135935[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.067085
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.047888
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│      8
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041318
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     11
│     19
│     20
│     21
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.045886
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.048548
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│     11
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.044316
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│      8
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.058050
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     19
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.047151
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│      8
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.039780
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      8
│     11
│     15
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.043907
┌ Info: EM with 100000 data points 10 iterations avll -1.043907
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.836740e+05
      1       6.604790e+05      -2.231949e+05 |       32
      2       6.351904e+05      -2.528862e+04 |       32
      3       6.225039e+05      -1.268656e+04 |       32
      4       6.130638e+05      -9.440086e+03 |       32
      5       6.058921e+05      -7.171676e+03 |       32
      6       6.017732e+05      -4.118844e+03 |       32
      7       5.990541e+05      -2.719109e+03 |       32
      8       5.968872e+05      -2.166907e+03 |       32
      9       5.952824e+05      -1.604807e+03 |       32
     10       5.938227e+05      -1.459697e+03 |       32
     11       5.923306e+05      -1.492167e+03 |       32
     12       5.908989e+05      -1.431677e+03 |       32
     13       5.898677e+05      -1.031144e+03 |       32
     14       5.893231e+05      -5.446320e+02 |       32
     15       5.889291e+05      -3.940513e+02 |       32
     16       5.885871e+05      -3.419302e+02 |       32
     17       5.882840e+05      -3.031510e+02 |       32
     18       5.880116e+05      -2.724023e+02 |       32
     19       5.878046e+05      -2.069509e+02 |       32
     20       5.876216e+05      -1.829794e+02 |       32
     21       5.874799e+05      -1.417523e+02 |       32
     22       5.873792e+05      -1.006411e+02 |       32
     23       5.873222e+05      -5.702546e+01 |       31
     24       5.872843e+05      -3.792948e+01 |       32
     25       5.872542e+05      -3.005654e+01 |       32
     26       5.872247e+05      -2.954888e+01 |       31
     27       5.871979e+05      -2.677319e+01 |       30
     28       5.871688e+05      -2.914990e+01 |       31
     29       5.871397e+05      -2.905183e+01 |       31
     30       5.871065e+05      -3.319386e+01 |       31
     31       5.870690e+05      -3.753331e+01 |       32
     32       5.870203e+05      -4.870940e+01 |       32
     33       5.869660e+05      -5.423782e+01 |       32
     34       5.869101e+05      -5.598356e+01 |       32
     35       5.868395e+05      -7.060138e+01 |       31
     36       5.867466e+05      -9.286655e+01 |       31
     37       5.866115e+05      -1.350558e+02 |       32
     38       5.864953e+05      -1.162305e+02 |       31
     39       5.864144e+05      -8.089959e+01 |       31
     40       5.863565e+05      -5.788813e+01 |       32
     41       5.863238e+05      -3.266860e+01 |       32
     42       5.863059e+05      -1.794513e+01 |       31
     43       5.862907e+05      -1.514905e+01 |       27
     44       5.862752e+05      -1.552577e+01 |       31
     45       5.862617e+05      -1.349525e+01 |       29
     46       5.862484e+05      -1.328962e+01 |       30
     47       5.862359e+05      -1.250246e+01 |       29
     48       5.862236e+05      -1.235383e+01 |       30
     49       5.862053e+05      -1.826590e+01 |       29
     50       5.861894e+05      -1.591499e+01 |       29
K-means terminated without convergence after 50 iterations (objv = 586189.3999896019)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311230
[ Info: iteration 2, average log likelihood -1.279761
[ Info: iteration 3, average log likelihood -1.250316
[ Info: iteration 4, average log likelihood -1.218296
[ Info: iteration 5, average log likelihood -1.183808
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.144422
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097531
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068976
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      6
│      8
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069710
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.107476
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     13
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.062162
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.088475
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.094542
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064933
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.054206
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.108399
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.079415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.064198
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     13
│     14
│     18
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.061273
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.100600
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060721
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      6
│     11
│     13
│     14
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.040184
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.110115
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.111933
[ Info: iteration 26, average log likelihood -1.097686
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     13
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.036255
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.073355
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     18
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.084180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.086408
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073709
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.077415
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.097996
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     14
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.039929
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      8
│     11
│     13
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.059042
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.122974
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.083259
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.073298
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     14
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.059292
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│     11
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081705
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.112470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082198
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.048790
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      6
│     14
│     18
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.049660
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.106830
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.086045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078892
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.052952
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     13
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.069282
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.108018
┌ Info: EM with 100000 data points 50 iterations avll -1.108018
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0359119   -0.0843763    0.142815    0.0474276   -0.0210421    0.119486     0.0810538    0.14867      0.126467    -0.156651      0.179194    -0.0104492  -0.162448      0.141308     0.0583557    0.0408754    0.0439969     0.110525     0.0408102   -0.118303   -0.0406758    -0.0155801    0.157912      0.0935838    0.0540841    0.245303
 -0.13876     -0.0698908    0.108689   -0.116174    -0.00324896   0.197494     0.297524     0.0350451   -0.0687494    0.0436351    -0.317134     0.172931    0.0402241    -0.0811438   -0.0613755   -0.25874      0.0199506     0.0401074   -0.0143946   -0.102816   -0.0935265     0.00683499  -0.102638      0.0281932    0.0677153   -0.167233
 -0.23524     -0.0930973    0.119655    0.0250338   -0.0544083    0.0246535   -0.135709     0.0870952    0.0449216   -0.10226       0.076336    -0.0992484  -0.062601      0.0237396    0.119642    -0.0753051   -0.156644      0.107453    -0.141556    -0.0915707  -0.0119236    -0.0145773    0.0875223     0.174735     0.0141437   -0.0360224
  0.023387     0.00508416   0.0219599   0.00854736   0.173187    -0.105398     0.0469826   -0.152343     0.101955     0.0343041    -0.141881     0.0842954  -0.0312834    -0.15911     -0.264272    -0.0518124   -0.0423975    -0.0694077    0.107707    -0.042117   -0.101592      0.00910472   0.092276      0.102295     0.17043      0.0243102
 -0.133821     0.136322     0.0429536  -0.165225     0.0796619   -0.0959612   -0.109071    -0.0350237    0.00656677  -0.084252      0.0741859    0.042778    0.0775655     0.0402482   -0.207222     0.0261171    0.0860072    -0.055393    -0.149747     0.0976791  -0.0897211    -0.0275796   -0.122644     -0.0694117    0.041318    -0.0218671
  0.0272242    0.137552    -0.0879161  -0.0466532    0.00100488   0.0835684   -0.115313    -0.0870643   -0.0296507   -0.0910291    -0.051094     0.124942   -0.174765     -0.00499334   0.0708342   -0.259155    -0.0872833    -0.0404332    0.0558282   -0.318981   -0.0477823    -0.071739     0.0404706    -0.027318     0.111632    -0.0481421
  0.0520622    0.145639    -0.0625484  -0.0135501    0.180783     0.0355145   -0.133915    -0.140188    -0.112389     0.121645      0.159352     0.140476    0.0128145     0.0462265   -0.138965    -0.0235133   -0.019387     -0.118238    -0.0517191    0.0728727   0.19704      -0.200243    -0.184074      0.0498921   -0.168771    -0.0370071
 -0.0341476   -0.0572231    0.178206    0.13057      0.00631678   0.148752    -0.0135599    0.154971     0.203972    -0.110598      0.104663    -0.0119002  -0.11972       0.0846377    0.0476324   -0.00997436   0.055865      0.0487565    0.0221323   -0.100362    0.000348716  -0.0109095    0.167421      0.111736     0.0510005    0.181899
  0.0828574   -0.0671695   -0.187123    0.292005    -0.120632     0.130266     0.0448348    0.00367663   0.0263368   -0.0301494     0.0891499   -0.179598   -0.215155     -0.0501531   -0.0351228   -0.164389    -0.0573556    -0.172296    -0.0363932   -0.055616   -0.151494     -0.168855     0.0560735     0.0181889    0.111373     0.0170007
 -0.0218766    0.190374     0.0426396  -0.0726604    0.0480403    0.115811    -0.144285     0.0134628    0.0348301    0.113786     -0.0340175   -0.13199    -0.0299557    -0.0749567    0.0101665    0.020697    -0.0174189     0.328151     0.0480687    0.126272    0.111043      0.154483     0.153865     -0.0152809    0.11766     -0.0352909
 -0.14059      0.0705416   -0.0227445   0.0859758    0.0060012    0.00488287  -0.0368619   -0.0202379   -0.11447     -0.00519606   -0.011328     0.0169843   0.130186      0.0111325    0.0706014   -0.0427198   -0.0143271     0.022026    -0.0491391   -0.0129707   0.108804     -0.0849993   -0.102773      0.0302686   -0.00334545  -0.081568
 -0.079068    -0.0751633    0.0192416  -0.25696      0.0135145    0.209925    -0.0604666   -0.0940365    0.161562    -0.0233281    -0.0540521   -0.103121   -0.160742     -0.0308268   -0.0826303   -0.0138143    0.0977796    -0.00308469  -0.236206     0.0038976   0.101998     -0.0186395   -0.0473664    -0.0417604    0.164188    -0.0995227
 -0.166427    -0.0870335   -0.0456977  -0.00827423   0.0510906    0.157029    -0.468631    -0.169908    -0.14598     -0.000811558   0.00444325   0.0418297  -0.0771512    -0.116484     0.126364    -0.099642     0.0945781    -0.0230617   -0.0473586    0.0289972   0.0566023     0.0337378    0.0843177     0.116131    -0.0593626   -0.155748
 -0.242292    -0.114146    -0.148166    0.0352665    0.0250787    0.0501366   -0.0518445   -0.170211     0.0306439   -0.09566      -0.034895    -0.0697776   0.000373043  -0.107422    -0.094934     0.0152246   -0.0500292    -0.0509383   -0.016587     0.051382   -0.0336067    -0.0035469    0.000331287  -0.0488692   -0.0404473   -0.0894584
 -0.141382     0.0527907   -0.0187001  -0.0390514    0.0404481    0.087291     0.0500719   -0.0465729   -0.0364533   -0.132601      0.0994855   -0.170241    0.102298     -0.0374891   -0.0702455    0.0391086    0.020849      0.0662503   -0.0470954   -0.0616579   0.161991      0.0680893   -0.0529935     0.0968277   -0.0858404    0.188308
 -0.0857476    0.0720939   -0.104117   -0.023397    -0.0403049   -0.0991112   -0.0356065   -0.00663121   0.0326004   -0.0267467     0.0171921    0.026912   -0.0293205     0.246317     0.0841856    0.0114752   -0.012562      0.101216    -0.0830643    0.0733727   0.0617497    -0.0240553    0.0657906     0.116657    -0.00216161   0.0553442
  0.0240133   -0.0233932   -0.0818276  -0.097502    -0.103081    -0.142767     0.107672    -0.0318706   -0.0221088    0.170335      0.204355     0.0334819   0.00492856    0.0540177    0.104811    -0.164721     0.0057922     0.195988     0.0219092   -0.0417745  -0.0122657    -0.137867    -0.0969217    -0.151657    -0.197732    -0.0462597
 -0.00488237   0.0417871   -0.0220785   0.0382538    0.0500417   -0.0277614    0.0635161    0.0354899   -0.025184    -0.0146346     0.0659375    0.0428476   0.0334995    -0.0377593   -0.0294368   -0.0135389   -0.00150592    0.00612579   0.0114085   -0.0101364  -0.0835547    -0.00372411   0.0724107    -0.00248131   0.0291392   -0.159756
 -0.104126    -0.156523    -0.137209    0.0209739    0.130021    -0.141491    -0.033456     0.192047     0.0233402   -0.00228595   -0.00923431  -0.0925471   0.0108384    -0.021353     0.0514186    0.0354773    0.10629      -0.032666     0.159449    -0.140378   -0.065854     -0.0929553    0.0223526     0.1749      -0.104466     0.12946
  0.0244999    0.0635477   -0.102349    0.0580265    0.0315179    0.0498426   -0.0739934   -0.0511427    0.00689301  -0.0489157    -0.0320216    0.102034   -0.112604      0.0365955    0.0449613   -0.187112     0.0339095    -0.0837623    0.0101794   -0.287047   -0.0726042    -0.0295912    0.0413316    -0.0680773    0.133797    -0.0729348
  0.154787     0.0219477    0.01236     0.140334     0.113088     0.0318034    0.0536335    0.105562     0.095128     0.0609238     0.0765181   -0.0295031   0.0510879    -0.00671329   0.0611634   -0.0380741    0.0966548    -0.0830646   -0.0719351   -0.0739838   0.126423     -0.00967267  -0.0556517    -0.0104302   -0.118082     0.0251428
  0.0410673    0.0583892    0.0524478  -0.0227522    0.106144     0.123641     0.0231032    0.0713318   -0.00905978  -0.115638      0.0573026    0.0497389   0.0329401    -0.0574902    0.159125     0.00972757   0.0664682    -0.0324721    0.0271025    0.041424    0.0438147    -0.0897401    0.0746381    -0.0478622   -0.155635     0.0195686
 -0.150314    -0.0915157    0.185437    0.134005    -0.0530736   -0.0776862    0.166772     0.0670415    0.0825893    0.00211515   -0.0113997    0.0950877  -0.0393481    -0.0704165   -0.00762818  -0.156105     0.0970566    -0.0224812   -0.0299729   -0.0701836   0.174083      0.0305592    0.108796      0.314247    -0.0910517    0.00288249
 -0.00978324  -0.0139689    0.0136883  -0.0203152   -0.121976     0.103876     0.00545032   0.0552301    0.0657233   -0.0645766     0.00778282  -0.100031   -0.028216      0.100836     0.124514    -0.0936415    0.00587665    0.0288007   -0.00564102  -0.0820412  -0.101939     -0.0438601    0.0146989     0.0876347   -0.0501245   -0.0353355
  0.0584221    0.156246     0.0765116  -0.0960123   -0.0593021    0.0387492    0.163579    -0.0887239   -0.0618422   -0.134042      0.0296878    0.0116381  -0.0123519     0.00926166   0.146533    -0.052385     0.0665556    -0.0329718    0.0631776   -0.211729    0.0810685    -0.206861    -0.088206      0.0452825    0.0881063   -0.135172
 -0.189847    -0.0489472    0.0827483  -0.0745713   -0.101766     0.00819162  -0.0860519    0.00502183   0.0198592   -0.035752      0.0172602   -0.137261    0.0467859    -0.114227     0.111907     0.0173346   -0.1742        0.197562    -0.152431    -0.227899    0.00114064   -0.0221065    0.0201308     0.0810252    0.00300345  -0.150227
  0.0258402   -0.0347408    0.170483    0.0741931   -0.0249734   -0.0912295   -0.0194084   -0.0095155   -0.0696768   -0.118206      0.0949121    0.0893048   0.0382295     0.114138     0.0572026   -0.130948     0.146277      0.00188394  -0.109266     0.0123136   0.0151185     0.11782     -0.0550677     0.129309     0.0919443   -0.00293026
  0.00271909   0.00946412  -0.126335    0.00494574  -0.0512717    0.0433044    0.115949    -0.127207    -0.00560923  -0.00462906    0.175731     0.118156    0.0274888     0.00947308   0.141425    -0.0083721   -0.0426408    -0.0720043    0.0615765   -0.0720465   0.128317     -0.0419371   -0.0784992    -0.123804    -0.0205146   -0.184645
  0.00286728   0.0660546    0.0198365   0.0984424   -0.05189      0.0431869   -0.0483872   -0.0191144    0.0387877    0.153897     -0.0690882    0.141526   -0.0253522    -0.0345965   -0.0123387    0.0972512    0.0230668    -0.151762     0.0500911    0.0364271   0.146665     -0.143387     0.00679279   -0.121036    -0.0642722    0.0366886
 -0.088978     0.08927     -0.0892036  -0.0546651    0.0305198    0.0331447    0.0330305    0.225        0.106442     0.0472384     0.1234      -0.0204609   0.123792     -0.110183     0.0451387   -0.185032    -0.0947078    -0.16777     -0.064368    -0.0195398  -0.108085     -0.17044      0.0377733    -0.0388994   -0.0565223    0.0131534
 -0.0402209   -0.125595    -0.0310797   0.0526012   -0.128101    -0.0528958    0.097852    -0.166797    -0.148502     0.00273514   -0.0750872   -0.0730676   0.0792206     0.192366     0.0187218   -0.0107296    0.000763259   0.0272874   -0.00165843   0.0002946  -0.0760229    -0.0109773   -0.0840441    -0.0819121    0.027272     0.103158
 -0.0625115   -0.0688782   -0.0577476  -0.047274    -0.0983549    0.106683     0.0708782   -0.131903    -0.0367671   -0.111567      0.0800013    0.0468701   0.169707      0.129406     0.0372318    0.204878     0.0937531    -0.10814     -0.229368     0.104224   -0.0959995     0.0169084   -0.0535207    -0.122366    -0.0366937   -0.0380966[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086631
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     13
│     17
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.033525
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│     11
│     14
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.034347
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│     13
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.048733
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     11
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.043658
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│     13
│     14
│     17
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.035027
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      4
│     11
│     18
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046595
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.056031
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     14
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.014696
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      8
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.055418
┌ Info: EM with 100000 data points 10 iterations avll -1.055418
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.157555     0.210978    -0.06652     -0.00110404   0.00723084   0.0161445   -0.0549656    0.0226007    0.0145477    0.206644      0.0133929   -0.126173    -0.0299245     0.0412568    0.0400818    -0.125907    -0.0579698   -0.0413782    0.160282     0.03545      0.00283383  -0.227549     -0.0929636    0.0194651   -0.120523    -0.0682712
 -0.0705376   -0.051507     0.0452482   -0.14374     -0.0974218   -0.115849    -0.064975     0.11593     -0.0640235   -0.00520705    0.0023942   -0.011192    -0.0549214     0.211815     0.105331      0.150255    -0.0567191   -0.321999     0.0645402    0.159048     0.00955675   0.0622994     0.151273     0.0232546    0.149571    -0.19877
 -0.127847    -0.0418283    0.154813     0.0167344   -0.117867    -0.0844907   -0.0332521   -0.0196766    0.0300415   -0.162126     -0.0421146   -0.00775038  -0.0785719     0.173146    -0.182877      0.0253492   -0.0761496   -0.0429871    0.0114279    0.0809088    0.0953694    0.0780414     0.136262    -0.1643       0.130705     0.0332441
  0.114189    -0.0933821    0.047576     0.0793738    0.116302     0.00284687   0.0748515    0.116459    -0.00911787   0.0545409     0.0400568   -0.0736432    0.0877816     0.146421     0.0763658    -0.183804    -0.0218183    0.13394     -0.158076     0.221285    -0.105858     0.127128     -0.0745648   -0.00618085   0.00749351  -0.129928
  0.200455    -0.0310171   -0.216328    -0.133186    -0.0520826   -0.00526273   0.0637429   -0.0330282    0.0682722   -0.000976778   0.0971741    0.139816     0.000420307  -0.0460198    0.0121262     0.154837    -0.0677473   -0.0445134    0.0669673   -0.143833     0.130481    -0.0955669     0.0992773    0.104325    -0.0693261    0.123883
 -0.115982    -0.0524796    0.088948     0.155997    -0.0113129   -0.0429798    0.0292931   -0.0157655    0.111508    -0.030387     -0.0514007   -0.0214084    0.061967     -0.0653088    0.0100793    -0.179362     0.111248    -0.150462    -0.193516     0.105408     0.10513      0.102619     -0.125342     0.0543554    0.0534299   -0.0179485
  0.0357128    0.0272371    0.033352     0.0108311    0.133752    -0.0813372   -0.0452698   -0.00593392   0.113253    -0.00154212   -0.071861    -0.0668808    0.0828341     0.0275787   -0.0927151    -0.0266956   -0.13223     -0.0596975   -0.0117259   -0.0380916    0.0440457   -0.0600088     0.0428703   -0.0233825   -0.072458    -0.0131463
 -0.0307329    0.0219802    0.0586367   -0.0124048    0.115014     0.0141712    0.0415166   -0.0601876    0.0526841    0.0246669    -0.144663    -0.0712695   -0.00579916    0.0520232    0.130781      0.0546605   -0.0129978   -0.110705    -0.0284037    0.0279542   -0.0122818    0.222723      0.0667752   -0.0846213    0.0878205   -0.0509236
  0.0254378   -0.172658    -0.0503307   -0.136412     0.134955    -0.126694    -0.0135548    0.0209809   -0.0260826   -0.0791941     0.0820576   -0.0144015    0.083842     -0.0710663   -0.00087668   -0.0586915   -0.055113    -0.00430488   0.132115    -0.0781594    0.20151     -0.0902251     0.18149      0.125085     0.161322     0.143154
  0.0920855    0.0656511   -0.065447    -0.157647    -0.0210849   -0.0635779   -0.0908027    0.0620161   -0.0452694   -0.0982947     0.0265757    0.016489    -0.124109     -0.0337439   -0.125318      0.125069     0.0928363    0.198991     0.169184     0.191134    -0.0515357   -0.181804      0.0743326   -0.174237     0.0289712    0.220006
 -0.0551847   -0.0664532    0.0668464   -0.049706    -0.00483492   0.193127    -0.0160647    0.248037    -0.0511305    0.228488     -0.118354     0.0396818    0.0722444     0.190571     0.0634046    -0.0711614   -0.108731    -0.0281545   -0.0928358    0.00281704   0.0152357    0.0180479    -0.0287943   -0.0113405    0.00617265  -0.00105716
 -0.0668834   -0.0263395    0.054917     0.0901984   -0.088472     0.0917843   -0.166988     0.203593     0.271389    -0.015234      0.115236     0.202395     0.0290235    -0.0981404   -0.0675287     0.00180059   0.0350924   -0.0254303    0.0155473   -0.0272162   -0.0366713    0.039764      0.067262    -0.110802     0.157574    -0.00211622
 -0.125367     0.0192715    0.0913819   -0.0244884   -0.0311128    0.0262981    0.322312    -0.0711427   -0.1026       0.0766283     0.0539481    0.0725443   -0.0207226     0.0224801   -0.0570197    -0.0733927    0.00369133   0.00292115  -0.0890251    0.0961043   -0.0238324   -0.00100033    0.0129426    0.00106467   0.151891     0.0152381
 -0.00328618   0.0184487   -0.0424371   -0.100223     0.0284617    0.0977874   -0.0428039   -0.0881419   -0.0177147   -0.0699914     0.090757     0.0095581    0.164093      0.00577557  -0.0967095     0.0704358    0.146914     0.109869    -0.0120869   -0.0529044    0.0463495   -0.180422     -0.0286818    0.0208622   -0.177551    -0.0941338
 -0.0493731   -0.00814209  -0.019115    -0.117372    -0.0131159    0.0219105   -0.0697018   -0.0341162    0.00577885   0.0694634    -0.0131267   -0.214006     0.0854804     0.103403    -0.0448336     0.0376383    0.00374789  -0.0378858    0.0935893   -0.170242    -0.134579     0.0428998    -0.0213865    0.0602887   -0.101552    -0.0491091
 -0.0132956   -0.00636427  -0.057505     0.12471     -0.0579076   -0.0664185    0.0340873   -0.0597729    0.0205701    0.0619012    -0.14432      0.0418809    0.0193501    -0.179437     0.112463     -0.0692075   -0.180246     0.0781402   -0.0883095   -0.174836     0.0810769   -0.0274577     0.0500752    0.0759206   -0.0178652   -0.0546972
  0.226222    -0.10536     -0.118613    -0.110437    -0.0281521    0.133615     0.0311071   -0.123342    -0.0794128   -0.162635      0.0663094   -0.0874683    0.145992     -0.182473    -0.000999663  -0.0231983   -0.105987    -0.0837583    0.092579    -0.228123    -0.0553386    0.0583366    -0.132        0.10407      0.114265    -0.215542
 -0.103001     0.1215      -0.114158     0.0354119    0.146224     0.168443    -0.139817    -0.0406792    0.144773     0.0158596     0.0977695   -0.012191     0.108064      0.171881     0.0361477     0.12742     -0.180946     0.0143499    0.0556971   -0.103351     0.115789    -0.0500907     0.0586964    0.11345     -0.0834354    0.0135607
 -0.0808765    0.0205989    0.0414066    0.00280437  -0.174732     0.156311    -0.0968948   -0.139126     0.00952133   0.0487321     0.143865    -0.00732057  -0.159303      0.177164    -0.0846103     0.0345199    0.084792    -0.00520658  -0.0574478   -0.170751    -0.0511899   -0.0308926    -0.00352211  -0.164314     0.0660249    0.0781507
 -0.0712521    0.100429     0.135254     0.182192     0.166261     0.17323      0.0600345    0.188941     0.0555589    0.00126514    0.0103428    0.00973022   0.0887353    -0.123213    -0.161257      0.0540215   -0.089359     0.121822    -0.0534546   -0.152648     0.111173     0.215085      0.0891283   -0.0280228   -0.0507348   -0.0747083
 -0.0727509    0.0990533    0.102554     0.1042      -0.0426466   -0.0586566   -0.00521928  -0.0550451   -0.178617     0.0520277     0.0442804    0.170384    -0.129612      0.114492     0.261181     -0.0710438   -0.0930379    0.0802538   -0.0531791    0.221096     0.0319085    0.135039      0.0298025    0.0117223    0.0732805    0.194603
 -0.0375735   -0.0857324   -0.0581683    0.00969345  -0.0208673   -0.245933    -0.167412     0.104548     0.0374076   -0.179028      0.00483222  -0.0170567    0.140077      0.0414971    0.058781     -0.260476     0.0499693    0.0701905   -0.0918783   -0.120011     0.0517836   -0.0307119     0.199653    -0.0327602   -0.00231032  -0.2353
  0.130362    -0.0955407    0.162045     0.0457562    0.144582     0.108512     0.138028     0.0315456    0.0375556    0.0837984    -0.118051    -0.101716     0.0999401     0.0769977    0.0129914     0.139672     0.016975     0.0644698   -0.0137874   -0.0610002    0.170953     0.193928     -0.0981187   -0.0238456   -0.011203     0.0425273
 -0.124126     0.081773    -0.0734537   -0.00891306  -0.0386618   -0.168253    -0.197705    -0.00775082   0.226662     0.121307     -0.118892    -0.0267055    0.0410819    -0.0078081    0.0250629    -0.00949035  -0.124521    -0.132147    -0.0224662   -0.190261    -0.143432    -0.059961      0.0687571   -0.174801     0.0922171   -0.19418
  0.167806     0.0473218   -0.17374     -0.0722198   -0.0542265    0.0873427    0.285122     0.0181853    0.129246     0.0120505     0.0102753    0.0447903    0.062767     -0.157087    -0.000492219   0.0452227    0.120655    -0.0147675    0.0687871   -0.114702    -0.0159401    0.0684611     0.120738     0.0344772   -0.0127436   -0.132105
  0.0819432   -0.00295791  -0.0517678    0.0790889   -0.038494    -0.0483533    0.0791921   -0.0610741    0.0867404   -0.129661      0.0487375   -0.142823     0.0756608    -0.0619922   -0.256963      0.0512011    0.10841     -0.076271     0.0276444   -0.0170491    0.0106802   -0.106949      0.130151     0.151537    -0.0794034    0.122441
 -0.0212634   -0.12779      0.0593815    0.059151    -0.108069     0.100905     0.112844     0.00328831   0.0709841    0.00522164   -0.06371      0.163836     0.0636265    -0.0359442    0.176556     -0.119929    -0.0195213    0.0126028    0.139775     0.0875237    0.0940692    0.0272941     0.0151748    0.123566    -0.149258    -0.0279137
  0.0330602   -0.222044     0.0208772   -0.00923182   0.0534442   -0.0807222    0.0574972   -0.0232065    0.0902387   -0.13107       0.0283232   -0.182392    -0.105503     -0.0710318   -0.00240714   -0.0292346   -0.0506755   -0.0758774    0.00746479   0.00859673   0.14076     -0.0995204    -0.015476     0.0181126   -0.0603123   -0.0619671
 -0.0129755    0.0232666    0.00977224  -0.00270987   0.0538459   -0.0808888   -0.180073     0.142509     0.0787932   -0.106409      0.113197     0.0926108   -0.156116     -0.00701519   0.0634605    -0.0934459    0.0247359    0.0515841    0.0203457   -0.0299953   -0.0209654   -0.0582008    -0.00319928   0.31148     -0.124139     0.0338841
 -0.087924     0.197455     0.0994456    0.0453108   -0.0135907    0.00375616  -0.174299    -0.143569    -0.0204179    0.0139526     0.170868     0.0534525   -0.0013393    -0.0693983    0.0352261    -0.0656737   -0.0305036   -0.0653482   -0.0909363    0.0436066    0.0214184    0.000279814   0.173735    -0.0837623    0.00898592   0.0208294
  0.0676951   -0.0964676   -0.0307085    0.275718     0.0487355   -0.0553662   -0.0183835   -0.108202    -0.0200117   -0.0497952     0.0645697    0.152958     0.16968      -0.136817     0.0565467    -0.00597711   0.0754098   -0.0758707   -0.0615124    0.065682    -0.0512129   -0.0716936    -0.0808452   -0.08947      0.0229109   -0.121496
  0.0165906   -0.086397    -0.0867259   -0.112616    -0.0216604    0.113841     0.00574349   0.177699    -0.037882    -0.125336      0.0982841    0.0200704   -0.00190507   -0.116348    -0.0441249     0.031232    -0.0434833   -0.05962     -0.0363863    0.0421622   -0.0119784   -0.154013     -0.119615     0.0777819    0.0126309   -0.0378015kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4242096520769831
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424230
[ Info: iteration 2, average log likelihood -1.424159
[ Info: iteration 3, average log likelihood -1.424104
[ Info: iteration 4, average log likelihood -1.424042
[ Info: iteration 5, average log likelihood -1.423968
[ Info: iteration 6, average log likelihood -1.423882
[ Info: iteration 7, average log likelihood -1.423784
[ Info: iteration 8, average log likelihood -1.423668
[ Info: iteration 9, average log likelihood -1.423510
[ Info: iteration 10, average log likelihood -1.423246
[ Info: iteration 11, average log likelihood -1.422768
[ Info: iteration 12, average log likelihood -1.421967
[ Info: iteration 13, average log likelihood -1.420898
[ Info: iteration 14, average log likelihood -1.419901
[ Info: iteration 15, average log likelihood -1.419270
[ Info: iteration 16, average log likelihood -1.418973
[ Info: iteration 17, average log likelihood -1.418851
[ Info: iteration 18, average log likelihood -1.418803
[ Info: iteration 19, average log likelihood -1.418784
[ Info: iteration 20, average log likelihood -1.418776
[ Info: iteration 21, average log likelihood -1.418773
[ Info: iteration 22, average log likelihood -1.418771
[ Info: iteration 23, average log likelihood -1.418770
[ Info: iteration 24, average log likelihood -1.418770
[ Info: iteration 25, average log likelihood -1.418770
[ Info: iteration 26, average log likelihood -1.418770
[ Info: iteration 27, average log likelihood -1.418769
[ Info: iteration 28, average log likelihood -1.418769
[ Info: iteration 29, average log likelihood -1.418769
[ Info: iteration 30, average log likelihood -1.418769
[ Info: iteration 31, average log likelihood -1.418769
[ Info: iteration 32, average log likelihood -1.418769
[ Info: iteration 33, average log likelihood -1.418769
[ Info: iteration 34, average log likelihood -1.418769
[ Info: iteration 35, average log likelihood -1.418769
[ Info: iteration 36, average log likelihood -1.418768
[ Info: iteration 37, average log likelihood -1.418768
[ Info: iteration 38, average log likelihood -1.418768
[ Info: iteration 39, average log likelihood -1.418768
[ Info: iteration 40, average log likelihood -1.418768
[ Info: iteration 41, average log likelihood -1.418768
[ Info: iteration 42, average log likelihood -1.418768
[ Info: iteration 43, average log likelihood -1.418768
[ Info: iteration 44, average log likelihood -1.418768
[ Info: iteration 45, average log likelihood -1.418768
[ Info: iteration 46, average log likelihood -1.418768
[ Info: iteration 47, average log likelihood -1.418768
[ Info: iteration 48, average log likelihood -1.418768
[ Info: iteration 49, average log likelihood -1.418768
[ Info: iteration 50, average log likelihood -1.418768
┌ Info: EM with 100000 data points 50 iterations avll -1.418768
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4242303740666842
│     -1.4241586979628469
│      ⋮
└     -1.4187680401639222
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418784
[ Info: iteration 2, average log likelihood -1.418708
[ Info: iteration 3, average log likelihood -1.418639
[ Info: iteration 4, average log likelihood -1.418551
[ Info: iteration 5, average log likelihood -1.418440
[ Info: iteration 6, average log likelihood -1.418304
[ Info: iteration 7, average log likelihood -1.418151
[ Info: iteration 8, average log likelihood -1.417996
[ Info: iteration 9, average log likelihood -1.417855
[ Info: iteration 10, average log likelihood -1.417741
[ Info: iteration 11, average log likelihood -1.417660
[ Info: iteration 12, average log likelihood -1.417607
[ Info: iteration 13, average log likelihood -1.417576
[ Info: iteration 14, average log likelihood -1.417558
[ Info: iteration 15, average log likelihood -1.417547
[ Info: iteration 16, average log likelihood -1.417539
[ Info: iteration 17, average log likelihood -1.417533
[ Info: iteration 18, average log likelihood -1.417529
[ Info: iteration 19, average log likelihood -1.417525
[ Info: iteration 20, average log likelihood -1.417521
[ Info: iteration 21, average log likelihood -1.417517
[ Info: iteration 22, average log likelihood -1.417514
[ Info: iteration 23, average log likelihood -1.417511
[ Info: iteration 24, average log likelihood -1.417508
[ Info: iteration 25, average log likelihood -1.417505
[ Info: iteration 26, average log likelihood -1.417502
[ Info: iteration 27, average log likelihood -1.417500
[ Info: iteration 28, average log likelihood -1.417497
[ Info: iteration 29, average log likelihood -1.417495
[ Info: iteration 30, average log likelihood -1.417493
[ Info: iteration 31, average log likelihood -1.417491
[ Info: iteration 32, average log likelihood -1.417489
[ Info: iteration 33, average log likelihood -1.417488
[ Info: iteration 34, average log likelihood -1.417486
[ Info: iteration 35, average log likelihood -1.417485
[ Info: iteration 36, average log likelihood -1.417484
[ Info: iteration 37, average log likelihood -1.417482
[ Info: iteration 38, average log likelihood -1.417481
[ Info: iteration 39, average log likelihood -1.417480
[ Info: iteration 40, average log likelihood -1.417479
[ Info: iteration 41, average log likelihood -1.417478
[ Info: iteration 42, average log likelihood -1.417477
[ Info: iteration 43, average log likelihood -1.417477
[ Info: iteration 44, average log likelihood -1.417476
[ Info: iteration 45, average log likelihood -1.417475
[ Info: iteration 46, average log likelihood -1.417474
[ Info: iteration 47, average log likelihood -1.417474
[ Info: iteration 48, average log likelihood -1.417473
[ Info: iteration 49, average log likelihood -1.417472
[ Info: iteration 50, average log likelihood -1.417472
┌ Info: EM with 100000 data points 50 iterations avll -1.417472
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418784364609408
│     -1.4187084016666869
│      ⋮
└     -1.4174718230542713
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417486
[ Info: iteration 2, average log likelihood -1.417427
[ Info: iteration 3, average log likelihood -1.417379
[ Info: iteration 4, average log likelihood -1.417324
[ Info: iteration 5, average log likelihood -1.417256
[ Info: iteration 6, average log likelihood -1.417174
[ Info: iteration 7, average log likelihood -1.417079
[ Info: iteration 8, average log likelihood -1.416978
[ Info: iteration 9, average log likelihood -1.416878
[ Info: iteration 10, average log likelihood -1.416785
[ Info: iteration 11, average log likelihood -1.416701
[ Info: iteration 12, average log likelihood -1.416627
[ Info: iteration 13, average log likelihood -1.416561
[ Info: iteration 14, average log likelihood -1.416502
[ Info: iteration 15, average log likelihood -1.416447
[ Info: iteration 16, average log likelihood -1.416396
[ Info: iteration 17, average log likelihood -1.416348
[ Info: iteration 18, average log likelihood -1.416303
[ Info: iteration 19, average log likelihood -1.416259
[ Info: iteration 20, average log likelihood -1.416219
[ Info: iteration 21, average log likelihood -1.416181
[ Info: iteration 22, average log likelihood -1.416147
[ Info: iteration 23, average log likelihood -1.416117
[ Info: iteration 24, average log likelihood -1.416089
[ Info: iteration 25, average log likelihood -1.416065
[ Info: iteration 26, average log likelihood -1.416044
[ Info: iteration 27, average log likelihood -1.416025
[ Info: iteration 28, average log likelihood -1.416008
[ Info: iteration 29, average log likelihood -1.415993
[ Info: iteration 30, average log likelihood -1.415980
[ Info: iteration 31, average log likelihood -1.415968
[ Info: iteration 32, average log likelihood -1.415957
[ Info: iteration 33, average log likelihood -1.415948
[ Info: iteration 34, average log likelihood -1.415939
[ Info: iteration 35, average log likelihood -1.415931
[ Info: iteration 36, average log likelihood -1.415924
[ Info: iteration 37, average log likelihood -1.415917
[ Info: iteration 38, average log likelihood -1.415912
[ Info: iteration 39, average log likelihood -1.415906
[ Info: iteration 40, average log likelihood -1.415901
[ Info: iteration 41, average log likelihood -1.415897
[ Info: iteration 42, average log likelihood -1.415893
[ Info: iteration 43, average log likelihood -1.415889
[ Info: iteration 44, average log likelihood -1.415886
[ Info: iteration 45, average log likelihood -1.415882
[ Info: iteration 46, average log likelihood -1.415879
[ Info: iteration 47, average log likelihood -1.415877
[ Info: iteration 48, average log likelihood -1.415874
[ Info: iteration 49, average log likelihood -1.415872
[ Info: iteration 50, average log likelihood -1.415869
┌ Info: EM with 100000 data points 50 iterations avll -1.415869
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4174861497065536
│     -1.4174266090901917
│      ⋮
└     -1.415869274888399
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415878
[ Info: iteration 2, average log likelihood -1.415821
[ Info: iteration 3, average log likelihood -1.415769
[ Info: iteration 4, average log likelihood -1.415709
[ Info: iteration 5, average log likelihood -1.415633
[ Info: iteration 6, average log likelihood -1.415537
[ Info: iteration 7, average log likelihood -1.415423
[ Info: iteration 8, average log likelihood -1.415296
[ Info: iteration 9, average log likelihood -1.415166
[ Info: iteration 10, average log likelihood -1.415042
[ Info: iteration 11, average log likelihood -1.414928
[ Info: iteration 12, average log likelihood -1.414827
[ Info: iteration 13, average log likelihood -1.414737
[ Info: iteration 14, average log likelihood -1.414658
[ Info: iteration 15, average log likelihood -1.414588
[ Info: iteration 16, average log likelihood -1.414525
[ Info: iteration 17, average log likelihood -1.414469
[ Info: iteration 18, average log likelihood -1.414419
[ Info: iteration 19, average log likelihood -1.414373
[ Info: iteration 20, average log likelihood -1.414331
[ Info: iteration 21, average log likelihood -1.414293
[ Info: iteration 22, average log likelihood -1.414258
[ Info: iteration 23, average log likelihood -1.414225
[ Info: iteration 24, average log likelihood -1.414194
[ Info: iteration 25, average log likelihood -1.414164
[ Info: iteration 26, average log likelihood -1.414136
[ Info: iteration 27, average log likelihood -1.414110
[ Info: iteration 28, average log likelihood -1.414085
[ Info: iteration 29, average log likelihood -1.414060
[ Info: iteration 30, average log likelihood -1.414037
[ Info: iteration 31, average log likelihood -1.414015
[ Info: iteration 32, average log likelihood -1.413994
[ Info: iteration 33, average log likelihood -1.413974
[ Info: iteration 34, average log likelihood -1.413954
[ Info: iteration 35, average log likelihood -1.413936
[ Info: iteration 36, average log likelihood -1.413919
[ Info: iteration 37, average log likelihood -1.413902
[ Info: iteration 38, average log likelihood -1.413886
[ Info: iteration 39, average log likelihood -1.413872
[ Info: iteration 40, average log likelihood -1.413857
[ Info: iteration 41, average log likelihood -1.413844
[ Info: iteration 42, average log likelihood -1.413831
[ Info: iteration 43, average log likelihood -1.413819
[ Info: iteration 44, average log likelihood -1.413808
[ Info: iteration 45, average log likelihood -1.413797
[ Info: iteration 46, average log likelihood -1.413786
[ Info: iteration 47, average log likelihood -1.413777
[ Info: iteration 48, average log likelihood -1.413767
[ Info: iteration 49, average log likelihood -1.413759
[ Info: iteration 50, average log likelihood -1.413750
┌ Info: EM with 100000 data points 50 iterations avll -1.413750
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158783621790456
│     -1.4158206204707906
│      ⋮
└     -1.4137501660764182
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413751
[ Info: iteration 2, average log likelihood -1.413687
[ Info: iteration 3, average log likelihood -1.413627
[ Info: iteration 4, average log likelihood -1.413557
[ Info: iteration 5, average log likelihood -1.413471
[ Info: iteration 6, average log likelihood -1.413364
[ Info: iteration 7, average log likelihood -1.413238
[ Info: iteration 8, average log likelihood -1.413095
[ Info: iteration 9, average log likelihood -1.412941
[ Info: iteration 10, average log likelihood -1.412786
[ Info: iteration 11, average log likelihood -1.412635
[ Info: iteration 12, average log likelihood -1.412494
[ Info: iteration 13, average log likelihood -1.412367
[ Info: iteration 14, average log likelihood -1.412252
[ Info: iteration 15, average log likelihood -1.412152
[ Info: iteration 16, average log likelihood -1.412063
[ Info: iteration 17, average log likelihood -1.411986
[ Info: iteration 18, average log likelihood -1.411917
[ Info: iteration 19, average log likelihood -1.411857
[ Info: iteration 20, average log likelihood -1.411803
[ Info: iteration 21, average log likelihood -1.411754
[ Info: iteration 22, average log likelihood -1.411709
[ Info: iteration 23, average log likelihood -1.411668
[ Info: iteration 24, average log likelihood -1.411630
[ Info: iteration 25, average log likelihood -1.411595
[ Info: iteration 26, average log likelihood -1.411562
[ Info: iteration 27, average log likelihood -1.411530
[ Info: iteration 28, average log likelihood -1.411501
[ Info: iteration 29, average log likelihood -1.411472
[ Info: iteration 30, average log likelihood -1.411445
[ Info: iteration 31, average log likelihood -1.411420
[ Info: iteration 32, average log likelihood -1.411395
[ Info: iteration 33, average log likelihood -1.411371
[ Info: iteration 34, average log likelihood -1.411349
[ Info: iteration 35, average log likelihood -1.411327
[ Info: iteration 36, average log likelihood -1.411306
[ Info: iteration 37, average log likelihood -1.411285
[ Info: iteration 38, average log likelihood -1.411266
[ Info: iteration 39, average log likelihood -1.411247
[ Info: iteration 40, average log likelihood -1.411228
[ Info: iteration 41, average log likelihood -1.411211
[ Info: iteration 42, average log likelihood -1.411193
[ Info: iteration 43, average log likelihood -1.411177
[ Info: iteration 44, average log likelihood -1.411161
[ Info: iteration 45, average log likelihood -1.411145
[ Info: iteration 46, average log likelihood -1.411130
[ Info: iteration 47, average log likelihood -1.411115
[ Info: iteration 48, average log likelihood -1.411101
[ Info: iteration 49, average log likelihood -1.411087
[ Info: iteration 50, average log likelihood -1.411074
┌ Info: EM with 100000 data points 50 iterations avll -1.411074
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4137508563812267
│     -1.4136872773954148
│      ⋮
└     -1.4110742109498795
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4242096520769831
│     -1.4242303740666842
│     -1.4241586979628469
│     -1.424104401435487
│      ⋮
│     -1.4111011258663506
│     -1.4110874352959955
└     -1.4110742109498795
32×26 Array{Float64,2}:
 -0.062442     0.139335     0.0936537   0.118384     0.00671989   0.429066    -0.336121   -0.561655    -0.00553417  -0.77445    -0.200949   -0.236103   -0.0109599    0.257274     0.0375495    0.221032   -0.568984    -0.322539    0.34967     -0.434442     0.054735    0.00682064   0.239832    -0.308312    -0.406532     0.0857614
  0.0586205    0.256946     0.115152    0.247421     0.196228    -0.214783    -0.347717   -0.419643     0.106245    -0.207594   -0.194946   -0.426539    0.623046    -0.252171     0.0788604   -0.0800879   0.528341     0.010756    0.155611    -0.427526    -0.225549    0.231738     0.092589     0.0268378    0.0672993   -0.279023
  0.338385    -0.198621     0.338995    0.0073062   -0.568819    -0.779835    -0.148994    0.566954     0.1236       0.0962493  -0.0858482   0.0096047   0.413354     0.249819    -0.195499     0.282364    0.25393     -0.210768    0.434502    -0.386465    -0.827715   -0.030422     0.345267     0.440569    -0.586479     0.266732
  0.486426    -0.0697378   -0.286753    0.115558     0.109289     0.354647    -0.225998    0.435653     0.330216    -0.0452696   0.413587   -0.264513    0.1004       0.24695     -0.146575     0.299467    0.461219    -0.389286    0.115798    -0.404237    -0.309236   -0.299061     0.0843931    0.515322     0.341465    -0.219445
  0.316211     0.257183     0.15794    -0.112243    -0.119409    -0.0535724   -0.140739   -0.223824    -0.339459    -0.367616    0.668041   -0.140728    0.289719    -0.485934    -0.301353     0.244768    0.0697756   -0.433863   -0.152159     0.693855    -0.182932   -0.491081    -0.0818466   -0.00693822   0.142973    -0.0539558
 -0.100427     0.155414     0.316474    0.0259046   -0.0552998    0.239695    -0.537472    0.127137     0.128163    -0.339074   -0.234122   -0.0591729   0.115006    -0.116216    -0.454171     0.1962     -0.376712    -0.0978231   0.643804     0.699348     0.266844   -1.16305     -0.508768    -0.00251799  -0.0573482    0.704072
 -0.268583     0.552144     0.0173566   0.225551     0.410495    -0.00682063  -0.518213   -0.177452     0.465113     0.349777   -0.689904   -0.431125    0.605744     0.126431    -0.597593    -0.149008   -0.184736    -0.262835   -0.136486     0.200472    -0.117369    0.667339     0.270397    -0.173143    -0.0230252    0.225308
 -0.183542     0.872642    -0.386501    0.0377508    0.0489571   -0.627434    -0.30466    -0.431856     0.308077     0.0223486  -0.45287     0.0336494   0.489856    -0.413448     0.122545    -0.0823104  -0.139176    -0.277593   -0.0800476    0.499669    -0.50542     0.0610977   -0.0654774   -0.0773793   -0.179877     0.383483
  0.146786     0.223148    -0.28138    -0.0746456   -0.0943461   -0.977784     0.492544    0.941978    -0.165009     0.353167    0.654201    0.26681     0.00508688   0.079529     0.464627    -0.455335    0.519109     0.487997   -0.536321     0.124657    -0.140126    0.283896    -0.150964     0.34686      0.646841    -0.0391684
  0.157226    -0.542162     0.236389   -0.196429    -0.264421    -0.0679706    0.656402    0.267728    -0.276035    -0.0754569   0.521969    0.52267    -0.497577     0.291445     0.45392      0.016571    0.0449437    0.189247   -0.00884385   0.138538     0.348298   -0.790939    -0.0197607    0.273831     0.140559     0.218921
  0.33503      0.217967     0.422292   -0.572412     0.515672     0.0968964   -0.108102    0.196414    -0.474567     0.209724    0.247654    0.0861439   0.0396123    0.225413    -0.00227714  -0.219899   -0.229464     0.532376   -0.325359    -0.1795       0.240323    0.0976768   -0.0226951    0.308464     0.124111    -0.326715
  0.0636681   -0.390031     0.0922305   0.547462     0.0990605    0.239978     0.438356    0.171466    -0.211195    -0.154506   -0.118293   -0.228428    0.204061     0.0437315   -0.288167    -0.381216    0.316537     0.481      -0.150428    -0.37327      0.75557     0.341577    -0.0179105    0.176304    -0.215262    -0.534887
 -0.2301      -0.00465236  -0.0420526  -0.0142766    0.0786242   -0.103133    -0.160048   -0.00654435  -0.0906701    0.209076    0.054004   -0.240145   -0.0125648   -0.0321409    0.0817352    0.0299023  -0.0408438   -0.210033    0.103991     0.033194     0.182703   -0.182587    -0.0359387   -0.043212    -0.00492301  -0.053226
  0.190411    -0.00188691   0.127213   -0.0197985    0.0248631   -0.0246174    0.220473    0.128913     0.0643409   -0.171262    0.0890027   0.255509    0.041795    -0.00256008  -0.0939807   -0.0986762  -0.00781539   0.236723   -0.116145     0.00956277  -0.074596    0.185137     0.0656818    0.027549    -0.00296069   0.0593472
  0.097534    -0.342959    -0.500101   -0.185944    -0.251004     0.278173    -0.071928    0.0704304    0.175675     0.43546    -0.0543784   0.346826   -0.730451     0.162258    -0.0215698   -0.178347   -0.268323    -0.0755592  -0.175839     0.257965     0.122626   -0.0369535    0.146291    -0.111186    -0.121602     0.0169256
 -0.266281    -0.64646     -0.516283    0.602386    -0.278101     0.227872     0.254688   -0.0168107    0.621435     0.0994404  -0.386557    0.329665   -0.00787221   0.0569393    0.320571    -0.123123    0.0709811   -0.171033    0.0103976   -0.00360706   0.0223493   0.248386     0.167003     0.0640631   -0.320686    -0.118782
  0.0426257   -0.312842    -0.269042    0.297917     0.168814    -0.0378449   -1.04418    -0.7904      -0.414716     0.358357   -0.452443   -0.869496    0.523108    -0.165558     0.213208     0.499097    0.382184     0.131239   -0.395718    -0.246867    -0.0342639   0.0529208   -0.110713    -0.538359    -0.147051    -0.785036
 -0.673905    -0.0760499   -0.117414    0.237174     0.705164    -0.46133     -0.0208808   0.00198442   0.27748      0.0318236   0.0107511  -0.751051    0.457448    -0.73504      0.0742694    0.293407    0.439489    -0.363678    0.293978    -0.390906     0.177808   -0.107161    -0.434577     0.3499       0.318994    -0.161346
 -0.679208    -0.13055      0.134438    0.110259    -0.457944    -0.192417     0.276785    0.60608      0.10858      0.0168744   0.234162    0.188609   -0.241211    -0.292271    -0.173006     0.658418   -0.112292    -0.07926     0.377788    -0.227716     0.214979    0.276473    -0.0696268   -0.232979     0.444498     0.0584534
 -0.720715     0.118071    -0.161464   -0.28761      0.519536    -0.0806231    0.0574121   0.0603095   -0.0417662    0.241748   -0.0201016  -0.188719   -0.29611     -0.266606     0.244035     0.297781   -0.485239     0.240335   -0.210525     0.251874     0.493566    0.23791     -0.272918    -0.457635     0.288724    -0.0518702
 -0.201256    -0.335355     0.684192    0.0773134   -0.387809    -0.396633     0.0965746  -0.717713    -0.486926    -0.176135   -0.698375    0.0117209   0.0333661   -0.51782      0.23106     -0.0667808  -0.662288    -0.305961   -0.0528359    0.487019     0.013748    0.314057    -0.00472873  -0.546191    -0.509192    -0.623982
  0.00710475  -0.289623     0.493526   -0.231788    -0.389831    -0.104899     0.591734   -0.540425    -0.496917     0.129262   -0.0664497   0.447886   -0.195185    -0.220507    -0.0685273   -0.870802   -0.110182     0.795985   -0.440116     0.28821      0.0555077   0.188047    -0.0433808   -0.241964    -0.286455     0.245447
 -0.110154    -0.570146    -0.414974   -0.816858     0.5311       0.0887699    0.439846   -0.473134     0.420587     0.199455   -0.415957    0.796289    0.132435    -0.786189     0.179957     0.0330599   0.0618522   -0.293633    0.332768    -0.189214    -0.104517   -0.569371     0.68502     -0.535114    -0.372469    -0.0149253
  0.179095     0.412736    -0.754142   -0.0354726    0.380011     0.271341     0.368847   -0.543425     0.143958     0.157749   -0.106258    0.356707   -0.378457    -0.0582714    0.707414    -0.340352   -0.305296    -0.301573    0.214404     0.723325    -0.0586138  -0.495346     0.185683    -0.341862     0.188497     0.205436
 -0.200929     0.501406     0.355792   -0.31613      0.115287    -0.699561     0.150961    0.0204241   -0.0980844   -0.165404   -0.181483    0.0407008   0.38664     -0.14591     -0.0546564    0.117582   -0.191855     0.298874   -0.014771     0.0952153    0.114862    0.00594432   0.172788    -0.147787     0.117994     0.217988
  0.0578828   -0.201666    -0.269008    0.172803    -0.130961     0.701961    -0.138221    0.205753     0.195344    -0.0899595   0.263036    0.0382503  -0.368896     0.343792    -0.0810208    0.147868   -0.0938422   -0.382423    0.0416902   -0.13582      0.102284   -0.204731    -0.104549     0.227298    -0.0092677   -0.0233561
  0.431407    -0.880291    -0.224177    0.293837     0.34424      0.183376     0.644754    0.431336     0.119381     0.291769    0.591345    0.168638   -0.303085    -0.181453     0.0338342   -0.0305234   0.754155     0.0425657   0.106258    -0.543343    -0.544446    0.842815     0.399707    -0.240194     0.297429    -0.337032
  0.253076     0.147247     0.121897    0.494873     0.239633     0.129518     0.102296    0.461012     0.491919    -0.174801    0.544824    0.0351416  -0.277519    -0.64391     -0.385885     0.105223   -0.257815     0.44607     0.162153     0.2778      -0.740729    0.856857    -0.00570092  -0.153416    -0.240595     0.172465
  1.01379      0.102155     0.258146   -0.00107186  -0.151078     0.381993    -0.309238   -0.722956     0.228779    -0.166462   -0.13759     0.0416091   0.43487      0.365307     0.00756142  -0.999318    0.131016     0.155174   -0.0506869    0.0126933   -0.369105   -0.351317     0.329868     0.434104    -0.199085    -0.018879
  0.697756    -0.0199029    0.211577    0.0538008   -0.789073     0.516419    -0.702999    0.306458    -0.215456    -0.210875    0.0544362  -0.110359   -0.254026     1.09236     -0.212933    -0.0679754  -0.150042     0.106929   -0.584134    -0.161978    -0.088043    0.322565    -0.168473     0.105062    -0.0760776   -0.00492483
 -0.3528       0.187678     0.144861   -0.383464    -0.295465     0.0593343   -0.0737252  -0.284096    -0.484925     0.347912   -0.307218   -0.0645039   0.30428      0.733499     0.125752    -0.103014    0.314971    -0.643138   -0.164305    -0.238056     0.799839   -0.627146     0.0278366    0.264522     0.229708    -0.29732
 -0.540923    -4.57628e-5  -0.575365   -0.0126209    0.14241      0.413252    -0.0702199   0.538128     0.890681    -0.205434   -0.211931    0.317699    0.200105     0.755834     0.0788401    0.0399163  -0.287461     0.0306834   0.429077    -0.995451     0.469264    0.141172     0.231736     0.455009     0.316739     0.210155[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411061
[ Info: iteration 2, average log likelihood -1.411049
[ Info: iteration 3, average log likelihood -1.411037
[ Info: iteration 4, average log likelihood -1.411026
[ Info: iteration 5, average log likelihood -1.411015
[ Info: iteration 6, average log likelihood -1.411004
[ Info: iteration 7, average log likelihood -1.410994
[ Info: iteration 8, average log likelihood -1.410985
[ Info: iteration 9, average log likelihood -1.410975
[ Info: iteration 10, average log likelihood -1.410966
┌ Info: EM with 100000 data points 10 iterations avll -1.410966
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.095614e+05
      1       7.017577e+05      -2.078037e+05 |       32
      2       6.891973e+05      -1.256037e+04 |       32
      3       6.843751e+05      -4.822221e+03 |       32
      4       6.817981e+05      -2.576967e+03 |       32
      5       6.801730e+05      -1.625096e+03 |       32
      6       6.789422e+05      -1.230766e+03 |       32
      7       6.779725e+05      -9.697449e+02 |       32
      8       6.771894e+05      -7.830900e+02 |       32
      9       6.765247e+05      -6.647250e+02 |       32
     10       6.760036e+05      -5.210547e+02 |       32
     11       6.755730e+05      -4.306631e+02 |       32
     12       6.751982e+05      -3.747395e+02 |       32
     13       6.748681e+05      -3.301016e+02 |       32
     14       6.745806e+05      -2.874909e+02 |       32
     15       6.743249e+05      -2.557252e+02 |       32
     16       6.740866e+05      -2.382711e+02 |       32
     17       6.738745e+05      -2.121846e+02 |       32
     18       6.736801e+05      -1.943289e+02 |       32
     19       6.735188e+05      -1.612918e+02 |       32
     20       6.733920e+05      -1.268369e+02 |       32
     21       6.732710e+05      -1.210357e+02 |       32
     22       6.731612e+05      -1.097143e+02 |       32
     23       6.730604e+05      -1.007973e+02 |       32
     24       6.729743e+05      -8.610213e+01 |       32
     25       6.728957e+05      -7.866392e+01 |       32
     26       6.728084e+05      -8.726909e+01 |       32
     27       6.727232e+05      -8.524251e+01 |       32
     28       6.726461e+05      -7.711089e+01 |       32
     29       6.725850e+05      -6.105727e+01 |       32
     30       6.725278e+05      -5.723824e+01 |       32
     31       6.724719e+05      -5.585914e+01 |       32
     32       6.724130e+05      -5.886167e+01 |       32
     33       6.723634e+05      -4.960054e+01 |       32
     34       6.723128e+05      -5.069112e+01 |       32
     35       6.722722e+05      -4.052500e+01 |       32
     36       6.722401e+05      -3.217073e+01 |       32
     37       6.722125e+05      -2.757526e+01 |       32
     38       6.721860e+05      -2.647738e+01 |       32
     39       6.721600e+05      -2.596812e+01 |       32
     40       6.721316e+05      -2.847977e+01 |       32
     41       6.721058e+05      -2.576618e+01 |       32
     42       6.720815e+05      -2.429190e+01 |       32
     43       6.720576e+05      -2.387886e+01 |       32
     44       6.720333e+05      -2.431960e+01 |       32
     45       6.720095e+05      -2.383382e+01 |       32
     46       6.719892e+05      -2.021795e+01 |       32
     47       6.719710e+05      -1.824321e+01 |       32
     48       6.719546e+05      -1.640244e+01 |       32
     49       6.719394e+05      -1.521641e+01 |       32
     50       6.719239e+05      -1.551199e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671923.8713883463)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423090
[ Info: iteration 2, average log likelihood -1.418003
[ Info: iteration 3, average log likelihood -1.416536
[ Info: iteration 4, average log likelihood -1.415373
[ Info: iteration 5, average log likelihood -1.414204
[ Info: iteration 6, average log likelihood -1.413244
[ Info: iteration 7, average log likelihood -1.412643
[ Info: iteration 8, average log likelihood -1.412310
[ Info: iteration 9, average log likelihood -1.412113
[ Info: iteration 10, average log likelihood -1.411979
[ Info: iteration 11, average log likelihood -1.411877
[ Info: iteration 12, average log likelihood -1.411795
[ Info: iteration 13, average log likelihood -1.411725
[ Info: iteration 14, average log likelihood -1.411664
[ Info: iteration 15, average log likelihood -1.411610
[ Info: iteration 16, average log likelihood -1.411562
[ Info: iteration 17, average log likelihood -1.411518
[ Info: iteration 18, average log likelihood -1.411479
[ Info: iteration 19, average log likelihood -1.411442
[ Info: iteration 20, average log likelihood -1.411409
[ Info: iteration 21, average log likelihood -1.411377
[ Info: iteration 22, average log likelihood -1.411348
[ Info: iteration 23, average log likelihood -1.411321
[ Info: iteration 24, average log likelihood -1.411295
[ Info: iteration 25, average log likelihood -1.411271
[ Info: iteration 26, average log likelihood -1.411248
[ Info: iteration 27, average log likelihood -1.411226
[ Info: iteration 28, average log likelihood -1.411205
[ Info: iteration 29, average log likelihood -1.411185
[ Info: iteration 30, average log likelihood -1.411166
[ Info: iteration 31, average log likelihood -1.411147
[ Info: iteration 32, average log likelihood -1.411129
[ Info: iteration 33, average log likelihood -1.411111
[ Info: iteration 34, average log likelihood -1.411095
[ Info: iteration 35, average log likelihood -1.411078
[ Info: iteration 36, average log likelihood -1.411062
[ Info: iteration 37, average log likelihood -1.411047
[ Info: iteration 38, average log likelihood -1.411032
[ Info: iteration 39, average log likelihood -1.411018
[ Info: iteration 40, average log likelihood -1.411004
[ Info: iteration 41, average log likelihood -1.410991
[ Info: iteration 42, average log likelihood -1.410978
[ Info: iteration 43, average log likelihood -1.410966
[ Info: iteration 44, average log likelihood -1.410954
[ Info: iteration 45, average log likelihood -1.410942
[ Info: iteration 46, average log likelihood -1.410931
[ Info: iteration 47, average log likelihood -1.410920
[ Info: iteration 48, average log likelihood -1.410910
[ Info: iteration 49, average log likelihood -1.410900
[ Info: iteration 50, average log likelihood -1.410890
┌ Info: EM with 100000 data points 50 iterations avll -1.410890
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.373936   -0.143906    -0.0789134   -0.787092     0.346977   -0.469714    0.427674    -0.0616695  -0.0607021    0.597872   -0.145328     0.220295     0.273473    -0.754726     0.112553    0.195375     0.112242   -0.458223    0.380241     0.0929484   -0.218322   -0.441966    0.373069     -0.458572   -0.362625     0.039178
  0.0917484   0.64677     -0.340476    -0.294157     0.0540731  -0.320146    0.00363563   0.115018   -0.125484     0.468587    0.0740556    0.325543    -0.0563674    0.189432     0.456931   -0.622671    -0.183553    0.325173   -0.717514     0.129695    -0.490095    0.536026   -0.120345      0.208287    0.177668    -0.222805
  0.587183   -0.233724     0.181073     0.222016    -0.539119   -0.558809   -0.258995     0.442303    0.297618    -0.0605805   0.029445    -0.00433414   0.360453     0.264253    -0.127857    0.280472     0.251852   -0.293384    0.412766    -0.380293    -0.958848   -0.0566135   0.378979      0.665726   -0.551595     0.187348
  0.109924   -0.536675     0.171527    -0.225576    -0.329735   -0.287642    0.756        0.268037   -0.345719     0.200858    0.518116     0.518231    -0.43486      0.151959     0.324089   -0.279843     0.170308    0.528583   -0.444529     0.168153     0.305616   -0.254228    0.0652301     0.169963    0.152606     0.0799313
 -0.59317    -0.0275452   -0.188366    -0.205969     0.420715   -0.176173   -0.19389     -0.216097   -0.171986     0.0379124  -0.28953     -0.396075    -0.206014     0.00463223   0.370627    0.280864    -0.732814    0.253273   -0.631668     0.277889     0.982639    0.0645398  -0.182464     -0.543517    0.342332    -0.385063
 -0.343307    0.161122    -0.10484      0.155645     0.297318    0.616874   -0.533874    -0.33559     0.159112    -0.361551   -0.350089    -0.378153     0.249663     0.344072     0.0190029   0.327627    -0.468275   -0.365375    0.656109    -0.795621     0.14996    -0.182806    0.261465     -0.228751   -0.434959     0.0674919
 -0.0791099   0.16049      0.0501072    0.421085     0.278313   -0.209757   -0.595947    -0.446054   -0.00661131   0.0554087  -0.111172    -0.700532     0.674028    -0.468106    -0.0627527   0.0956195    0.607749   -0.0207937   0.0236646   -0.205979    -0.181785    0.221328   -0.1226       -0.0394092   0.061323    -0.36211
  0.372304    0.0692711   -0.072387    -0.0751363    0.0157201   0.368192   -0.209852     0.366648   -0.0742025    0.130703    0.248547    -0.170737    -0.0779814    0.461602    -0.078429    0.081326     0.221517   -0.184506   -0.0088087   -0.271827     0.0199007  -0.152833    0.163542      0.298424    0.09691     -0.181371
  0.0945734  -0.217012     0.00311716   0.122227    -0.223568   -0.047575   -0.149187    -0.235259   -0.210955    -0.219679    0.246495     0.0298235   -0.0349085   -0.239381    -0.0247142   0.0478026   -0.0468137  -0.41795    -0.0204961    0.612579     0.0803695  -0.595017   -0.0957399     0.0242638  -0.0512272   -0.108047
  0.289173    0.706374     0.201582    -0.180953     0.144332   -0.234051   -0.0819184   -0.116151    0.186862    -0.440665    0.62903     -0.0540536    0.418509    -0.411981    -0.258083    0.724821    -0.177334   -0.243885    0.10199      0.541732    -0.620381   -0.0703027  -0.000169642  -0.15824     0.57135      0.237291
 -0.563307    0.519714    -0.338865     0.419814     0.494047   -0.371097    0.167555     0.470715    0.917353    -0.436696    0.201777     0.0558774    0.388817    -0.0974167    0.229612    0.0832018   -0.156509   -0.0575941   0.751261    -0.368288     0.18029     0.0782125   0.107925      0.373829    0.864233     0.200365
 -0.0746251   0.0464825   -0.587021    -0.260857     0.860984    0.391537    0.0922426   -0.304498    0.0679835   -0.220616    0.300191    -0.337764    -0.050354    -0.613062    -0.237001    0.196444     0.0357306  -0.204338   -0.318951     0.121278     0.486327   -0.0963752  -0.455961      0.0367701   0.33516     -0.561985
 -0.24482    -0.847453    -0.604398     0.0732713    0.0870597   0.325489    0.390142    -0.276774    0.45849      0.0898809  -0.740704     0.468988    -0.050501    -0.156659     0.227321   -0.377684     0.203189    0.138016    0.0360948   -0.309118     0.51828    -0.0260444   0.37442      -0.175072   -0.349383    -0.26796
 -0.597917    0.0070026   -0.469868     0.30073     -0.308428   -0.223118    0.121057     0.406681    0.109568     0.298418   -0.160254     0.0245483   -0.35215     -0.244355     0.0952734   0.414144    -0.14446    -0.352599    0.290976     0.256736    -0.139142    0.179238   -0.0252548    -0.353212    0.0594072    0.0744669
 -0.20532     0.652268    -0.118505     0.113921     0.310837   -0.288549   -0.4367      -0.397352    0.540847     0.248128   -0.837127    -0.273783     0.718069    -0.0498517   -0.212699   -0.159362    -0.100573   -0.291185   -0.137219     0.267708    -0.263212    0.468081    0.391693     -0.227054   -0.194517     0.411147
  0.635837    0.32693     -0.3614      -0.186287     0.187318    0.557364    0.0742107   -0.511328   -0.233615    -0.140396    0.166307     0.425946    -0.433923     0.0597083    0.486121   -0.174692    -0.591219   -0.161564    0.269675     0.708267    -0.0235996  -0.407987    0.42999      -0.514824   -0.256429     0.263625
 -0.103201   -0.721405     0.758909     0.12337     -0.458617    0.150463   -0.232946    -0.0703919   0.0944628   -0.420934    0.0518036   -0.500965    -0.539816    -0.651868    -0.0518935   0.427498     0.0525413  -0.0332877   0.713052    -1.05539      0.0299826   0.469705    0.298127     -0.336824    0.355937    -0.310188
 -0.389157    0.0885424    0.178988    -0.316317    -0.287182   -0.0273321  -0.0243277   -0.31893    -0.414892     0.314704   -0.294136    -0.0202042    0.333244     0.699067     0.191356   -0.0981425    0.388951   -0.591283   -0.157584    -0.28732      0.844727   -0.576879    0.0117643     0.336067    0.321196    -0.295999
  0.466802   -0.110805    -0.186625     0.162805    -0.413827    0.903612   -0.377464     0.171948    0.249983    -0.340543    0.330357     0.106225    -0.185804     1.06283     -0.170243    0.00130705  -0.314671   -0.0865866  -0.126805    -0.515956     0.320386   -0.143448    0.124832      0.673979    0.171224     0.0236849
  0.289177   -0.42871     -0.316554     0.371825     0.296824    0.298319    0.358233     0.551737    0.183429     0.202355    0.560365     0.00561854  -0.00184206  -0.0207293   -0.0330662  -0.072971     1.00652    -0.106489    0.101442    -0.306749    -0.343128    0.216189    0.0921146     0.263255    0.303678    -0.271873
 -0.448437    0.555612    -0.25177     -0.147143    -0.341849    0.195169   -0.877503    -0.250164    0.369508    -0.501279   -0.844284    -0.16802      0.103547    -0.0799305   -0.0393208   0.187061    -0.578722   -0.334753    0.389115     0.675532     0.134898   -1.11874    -0.83555       0.413787   -0.175248     0.537102
 -0.179595   -0.195051     0.668947     0.0888558   -0.44617    -0.261274    0.35409     -0.644172   -0.372567    -0.219698   -0.648684     0.242876     0.081554    -0.442142    -0.0297946  -0.361195    -0.480197    0.171077   -0.173428     0.458448     0.0605123   0.459053    0.00698428   -0.493178   -0.515879    -0.187853
 -0.247058   -0.41837     -0.514434     0.0283432   -0.0700783   0.474684    0.153429     0.346716    0.760363     0.183371    0.229518     0.507228    -0.712289     0.458919     0.0439689   0.135949    -0.565281   -0.216524    0.237933    -0.0445765    0.10492    -0.0420699   0.0916236     0.108503    0.189196     0.484722
  0.204781   -0.00949678   0.0728717    0.484723     0.249181    0.183136    0.137108     0.510531    0.40262     -0.10974     0.543414     0.0849138   -0.418585    -0.739171    -0.467723   -0.0160517   -0.372189    0.622719   -0.00532724   0.33456     -0.586713    0.821773   -0.092195     -0.191752   -0.499378     0.0475708
 -0.239745    0.119936     0.0646817   -0.0183753    0.072917   -0.413029    0.00345206  -0.0609751  -0.0943411    0.0799458  -0.133665    -0.134004     0.179225    -0.247173     0.0594626   0.0896883    0.0358926   0.0166141  -0.0613026    0.00059712   0.0519991   0.0475764  -0.0223459    -0.155633    0.0406175   -0.111349
  0.729671   -0.451675    -0.0017864   -0.125088    -0.602604    0.628991   -0.709854    -0.286296   -0.335923     0.345835   -0.302041    -0.276204    -0.287129     0.563025    -0.118504   -0.215818     0.171021   -0.0918426  -0.728766     0.0237726   -0.37859    -0.0241428  -0.12879      -0.396866   -0.406054    -0.244228
 -0.17063    -0.0913643    0.0799456    0.0702845   -0.103517   -0.176854    0.364314     0.683011    0.280825    -0.311804   -0.0211276    0.200095     0.409767     0.316133    -0.255866    0.151706     0.140489    0.202337   -0.13203     -0.786734     0.267218    0.536061    0.0239438     0.279143    0.00815709  -0.252924
  0.877669    0.129334     0.376214    -0.0792166    0.0571808   0.141527   -0.138606    -0.43703    -0.0721725   -0.423676   -0.0408861    0.0800991    0.396015     0.306979    -0.102201   -0.705415    -0.0428784   0.362894   -0.181059    -0.0880768   -0.0480094  -0.0561793   0.229007      0.351718   -0.201256    -0.27852
 -0.0772395  -0.0379251    0.0284361    0.00321862   0.0914153  -0.0468206   0.0757465   -0.0188367   0.0837289   -0.0120647  -0.00746339   0.0564432    0.0151375   -0.0708438    0.0140982  -0.064805    -0.0676785   0.0914938  -0.00687625  -0.0176191    0.0544365   0.112234    0.0310088    -0.0439412  -0.0284861    0.0278905
 -0.0719609  -0.20137      0.486932    -0.201846     0.140941   -0.0690223   0.144371     0.617055   -0.588609     0.19624     0.412404    -0.116888    -0.360544    -0.120493    -0.0455688   0.236931    -0.304676    0.417634    0.336035    -0.199334     0.664086   -0.130926   -0.59941       0.177061    0.577959     0.0286392
 -0.196377    0.610527     0.671225    -0.248858    -0.0630485  -0.282469   -0.17503      0.228864   -0.50733     -0.368572    0.267529    -0.047523     0.208336     0.441303    -0.428193    0.0504942   -0.31043     0.330666   -0.147652     0.238194     0.161261   -0.187847   -0.0157991    -0.0734009  -0.389776     0.805833
  0.511919    0.0212443    0.34648      0.0828594   -0.156623    0.308538    0.419198    -0.124892    0.67625      0.114979   -0.00332667   0.402119    -0.0406171   -0.139661    -0.0291226  -0.842584     0.514264   -0.0115864   0.468961     0.700263    -0.707451   -0.784587   -0.237962      0.31074     0.420801     0.907688[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410881
[ Info: iteration 2, average log likelihood -1.410872
[ Info: iteration 3, average log likelihood -1.410863
[ Info: iteration 4, average log likelihood -1.410855
[ Info: iteration 5, average log likelihood -1.410846
[ Info: iteration 6, average log likelihood -1.410838
[ Info: iteration 7, average log likelihood -1.410831
[ Info: iteration 8, average log likelihood -1.410823
[ Info: iteration 9, average log likelihood -1.410816
[ Info: iteration 10, average log likelihood -1.410809
┌ Info: EM with 100000 data points 10 iterations avll -1.410809
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
