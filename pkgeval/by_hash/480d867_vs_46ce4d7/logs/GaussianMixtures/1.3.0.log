Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed SortingAlgorithms ── v0.3.1
 Installed JLD ──────────────── v0.9.1
 Installed Arpack ───────────── v0.4.0
 Installed FileIO ───────────── v1.2.0
 Installed DataStructures ───── v0.17.6
 Installed StaticArrays ─────── v0.12.1
 Installed BinaryProvider ───── v0.5.8
 Installed QuadGK ───────────── v2.3.1
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed Rmath ────────────── v0.6.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed Distributions ────── v0.21.11
 Installed Parameters ───────── v0.12.0
 Installed OrderedCollections ─ v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed SpecialFunctions ─── v0.9.0
 Installed BinDeps ──────────── v1.0.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed DataAPI ──────────── v1.1.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distances ────────── v0.8.2
 Installed CMake ────────────── v1.1.2
 Installed Blosc ────────────── v0.5.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed PDMats ───────────── v0.9.10
 Installed HDF5 ─────────────── v0.12.5
 Installed FillArrays ───────── v0.8.2
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_wWFusA/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -1.8560480800501958e6, [85536.46236774701, 14463.537632253014], [-9418.178540918825 -7595.627652406958 -19209.709525476286; 9417.390523505605 7177.545381186044 19127.57265811544], Array{Float64,2}[[82206.79530717124 -3452.498070561232 -8960.179378882201; -3452.4980705612315 83399.67641807412 -6636.51262378263; -8960.179378882201 -6636.51262378263 68654.67600492106], [18139.608036876998 3000.1891265151453 9156.529253793644; 3000.1891265151453 16697.288712332258 6137.65665108905; 9156.529253793644 6137.65665108905 31921.05185671286]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.694701e+03
      1       9.601125e+02      -7.345890e+02 |        6
      2       9.255381e+02      -3.457440e+01 |        2
      3       9.053730e+02      -2.016506e+01 |        2
      4       8.797649e+02      -2.560807e+01 |        2
      5       8.729943e+02      -6.770655e+00 |        0
      6       8.729943e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 872.9942895907825)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076377
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.859333
[ Info: iteration 2, lowerbound -3.749090
[ Info: iteration 3, lowerbound -3.616970
[ Info: iteration 4, lowerbound -3.439175
[ Info: iteration 5, lowerbound -3.233568
[ Info: iteration 6, lowerbound -3.037332
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.876352
[ Info: iteration 8, lowerbound -2.763025
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.693155
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.623175
[ Info: iteration 11, lowerbound -2.544881
[ Info: iteration 12, lowerbound -2.476939
[ Info: iteration 13, lowerbound -2.418543
[ Info: iteration 14, lowerbound -2.373462
[ Info: iteration 15, lowerbound -2.340043
[ Info: iteration 16, lowerbound -2.317334
[ Info: iteration 17, lowerbound -2.307636
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.303000
[ Info: iteration 19, lowerbound -2.299263
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec 18 07:11:04 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec 18 07:11:12 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Wed Dec 18 07:11:14 2019: EM with 272 data points 0 iterations avll -2.076377
5.8 data points per parameter
, Wed Dec 18 07:11:16 2019: GMM converted to Variational GMM
, Wed Dec 18 07:11:24 2019: iteration 1, lowerbound -3.859333
, Wed Dec 18 07:11:24 2019: iteration 2, lowerbound -3.749090
, Wed Dec 18 07:11:24 2019: iteration 3, lowerbound -3.616970
, Wed Dec 18 07:11:24 2019: iteration 4, lowerbound -3.439175
, Wed Dec 18 07:11:24 2019: iteration 5, lowerbound -3.233568
, Wed Dec 18 07:11:24 2019: iteration 6, lowerbound -3.037332
, Wed Dec 18 07:11:25 2019: dropping number of Gaussions to 7
, Wed Dec 18 07:11:25 2019: iteration 7, lowerbound -2.876352
, Wed Dec 18 07:11:25 2019: iteration 8, lowerbound -2.763025
, Wed Dec 18 07:11:25 2019: dropping number of Gaussions to 6
, Wed Dec 18 07:11:25 2019: iteration 9, lowerbound -2.693155
, Wed Dec 18 07:11:25 2019: dropping number of Gaussions to 3
, Wed Dec 18 07:11:25 2019: iteration 10, lowerbound -2.623175
, Wed Dec 18 07:11:25 2019: iteration 11, lowerbound -2.544881
, Wed Dec 18 07:11:25 2019: iteration 12, lowerbound -2.476939
, Wed Dec 18 07:11:25 2019: iteration 13, lowerbound -2.418543
, Wed Dec 18 07:11:25 2019: iteration 14, lowerbound -2.373462
, Wed Dec 18 07:11:25 2019: iteration 15, lowerbound -2.340043
, Wed Dec 18 07:11:25 2019: iteration 16, lowerbound -2.317334
, Wed Dec 18 07:11:25 2019: iteration 17, lowerbound -2.307636
, Wed Dec 18 07:11:25 2019: dropping number of Gaussions to 2
, Wed Dec 18 07:11:25 2019: iteration 18, lowerbound -2.303000
, Wed Dec 18 07:11:25 2019: iteration 19, lowerbound -2.299263
, Wed Dec 18 07:11:25 2019: iteration 20, lowerbound -2.299257
, Wed Dec 18 07:11:25 2019: iteration 21, lowerbound -2.299255
, Wed Dec 18 07:11:25 2019: iteration 22, lowerbound -2.299254
, Wed Dec 18 07:11:25 2019: iteration 23, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 24, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 25, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 26, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 27, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 28, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 29, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 30, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 31, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 32, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 33, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 34, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 35, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 36, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 37, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 38, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 39, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 40, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 41, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 42, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 43, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 44, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 45, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 46, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 47, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 48, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 49, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: iteration 50, lowerbound -2.299253
, Wed Dec 18 07:11:25 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398606]
β = [178.04509222601396, 95.95490777398606]
m = [4.250300733269908 79.2868669443618; 2.0002292577753695 53.85198717246129]
ν = [180.04509222601396, 97.95490777398606]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484752 -0.007644049042327673; 0.0 0.008581705166333357], [0.3758763611948415 -0.008953123827346003; 0.0 0.01274866477740934]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9951323544795572
avll from llpg:  -0.9951323544795567
avll direct:     -0.9951323544795567
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9443702929829505
avll from llpg:  -0.9443702929829505
avll direct:     -0.9443702929829505
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0400828    0.183304    -0.0421124   0.0117756   -0.0793834  -0.045833    -0.0986636     0.162404     0.0464817    0.0546526   0.0576095    0.136411    -0.0292607     0.155463     0.127155     0.0929048   -0.0122891     0.0207729  -0.0306319    -0.0243441   -0.0123812   -0.127586      0.0736777    0.225766     0.261307     -0.244004  
  0.0669988   -0.0165102    0.0548756  -0.00184312  -0.0209896   0.0634739   -0.0100017     0.11199     -0.166267     0.274937   -0.0445668    0.111561     0.1382       -0.0327095   -0.0478529   -0.00380859  -0.0400846     0.0248428   0.132737     -0.0756302   -0.192171    -0.119037     -0.103289     0.0241167    0.117784     -0.269912  
  0.0817745   -0.0655557    0.0612693   0.0418001   -0.0281156   0.0984284    0.0326337    -0.0476468   -0.0443206    0.0320029   0.193709     0.0598091   -0.108131      0.07061      0.0997352   -0.0810409    0.141521      0.129413   -0.000412693  -0.0192031   -0.176808     0.0787845    -0.0868303   -0.123933     0.0377535    -0.037761  
  0.0993258   -0.0406738    0.115376   -0.121207     0.0728379  -0.0229438   -0.0204914     0.13558     -0.108256    -0.018809    0.179123     0.0245536   -0.138138     -0.105641    -0.0166907    0.0843784   -0.0970159    -0.137301    0.0940082     0.0262784   -0.0457469    0.228176      0.138687    -0.150769    -0.038055     -0.0803639 
 -0.0172429    0.0287135   -0.295451   -0.0916102   -0.153221   -0.00837568  -0.0452777    -0.0475856    0.0944964   -0.03892     0.0604349   -0.0816377   -0.00289366    0.0599307   -0.00273269   0.0515222   -0.116682      0.155922   -0.157538      0.127594     0.015166     0.26105       0.0380282    0.131767     0.0287234     0.0784141 
  0.0136743    0.0433331   -0.0507909   0.144065     0.0975317  -0.0548976    0.0392198     0.0166248    0.0276598    0.0839303  -0.0940099   -0.0767373    0.0363095     0.0659275   -0.134187    -0.146173    -0.0435148     0.0582479   0.108101     -0.184802     0.0048734   -0.0222273    -0.0205464   -0.10148      0.10678      -0.00466994
 -0.10696     -0.114512     0.058879    0.0244574   -0.0488249   0.0406792    0.0451199    -0.0678381   -0.044535     0.0512968  -0.0354718   -0.133176    -0.0433105    -0.0315835   -0.25755     -0.115373     0.00650543    0.0466131   0.0130312     0.00266763   0.095641     0.00750738   -0.00204422  -0.0339348   -0.0223295    -0.0311014 
 -0.150807     0.0756869   -0.0490921   0.176707     0.103322    0.13369     -0.0172881    -0.0300496    0.0601377   -0.0104126   0.0952738    0.100347     0.0243669    -0.11776     -0.0273189    0.0870709   -0.164647      0.0584905  -0.0890275    -0.0459606   -0.0805356   -0.131659      0.226414     0.0371637    0.0347545    -0.12043   
 -0.0454979    0.113583     0.034154   -0.0420709    0.222542   -0.0988912   -0.0160292    -0.0238912    0.0452837    0.241136    0.107049    -0.207938     0.147279      0.0802493    0.0590549    0.153347     0.0798035     0.110274    0.129348     -0.104261     0.0956905   -0.148314      0.0162811   -0.184645     0.000245802  -0.0797298 
 -0.0401037   -0.0222843    0.0387114  -0.072739     0.0913971  -0.0318563   -0.0647012     0.200949    -0.0344496    0.0423685  -0.0105868   -0.0382062    0.0280637     0.304779     0.0133963    0.0826448   -0.0842671    -0.0601389   0.000316532   0.115408    -0.118894    -0.0244028    -0.0501508   -0.0784571   -0.0536102     0.0257797 
  0.123995     0.11453     -0.0733247   0.0353342   -0.0321723   0.103558    -0.103405     -0.061332     0.0310218    0.107594   -0.0285835   -0.0156379   -0.0772109    -0.0521315   -0.0335667   -0.00421406  -0.0955956    -0.0117395   0.0971318     0.0679262    0.0959291   -0.0321355    -0.0137932    0.182328    -0.0157247    -0.0269933 
 -0.0687867    0.0625435    0.0432813  -0.044982     0.0558081   0.0651236    0.12523       0.0483104   -0.0707757    0.040986   -0.068694    -0.0314188   -0.00634759   -0.190422     0.0678777   -0.0785437   -0.014645      0.156296    0.0183783     0.00928296  -0.110886     0.286402     -0.181295    -0.119399     0.137816      0.032637  
 -0.0366879    0.0554954   -0.140937    0.0482542   -0.0571107   0.00482183  -0.126748     -0.085017    -0.0922469    0.0230064  -0.154787     0.0245101    0.0726881     0.088361    -0.0687808    0.0945914   -0.129442      0.0726271   0.0625892    -0.0630665    0.0504985    0.175011     -0.172623    -0.113306    -0.21425       0.00645173
 -0.0418526    0.0127323   -0.0402511  -0.124235    -0.0331725  -0.00431455   0.0408701     0.0521907   -0.127346    -0.0107415  -0.0594318    0.0498102   -0.0321114     0.0849956    0.0568461    0.135975    -0.0445274     0.0481872  -0.0532526    -0.0577474    0.0353257    0.114009     -0.228065    -0.0114887   -0.0595721    -0.0818445 
  0.110049    -0.084163     0.0865315   0.0649521   -0.0233633   0.0676387   -0.144263     -0.0221701    0.0556119    0.110721    0.070187     0.0803089    0.00420024    0.0418513   -0.0221064    0.105959    -0.0424242    -0.0328102   0.0231689    -0.0967141   -0.153479     0.000628263   0.171829     0.0226258    0.0931383    -0.0503529 
 -0.00966874  -0.209886     0.085685    0.0832097   -0.0454237  -0.0363544   -0.0128752     0.170778     0.109893     0.0617382  -0.0896642    0.0224488    0.0473252     0.0341583    0.0559149    0.00649612  -0.0690489     0.111329    0.194068     -0.135551    -0.0848308    0.188008     -0.284245    -0.127849     0.106389      0.00222854
  0.0381119   -0.137708     0.0181832   0.0612847    0.131719    0.229703    -0.136071      0.175038     0.116327     0.131873   -0.00617473  -0.0442781   -0.0917877     0.047512    -0.248817     0.117239    -0.000197282   0.19321    -0.108854     -0.022469    -0.093256     0.134157     -0.0384014    0.107987    -0.165667     -0.103359  
  0.0176276   -0.111181     0.0111299  -0.114307     0.0108966   0.0680465   -0.0546929     0.0926293    0.0384574    0.150478    0.153945     0.0761298    0.00637948   -0.0373368   -0.150539     0.0386124   -0.0979613    -0.0877242   0.0113829    -0.114136     0.0397535    0.090257      0.0703825   -0.0252001    0.0107902     0.151829  
 -0.162556     0.0244952   -0.0993647  -0.104668    -0.110102   -0.0986215   -0.05508       0.0713298   -0.0969051    0.140363    0.060281    -0.0242562    0.000516794   0.0114908   -0.0758164    0.0727036    0.0481139     0.0200532   0.171781     -0.0744327    0.0507163   -0.118421      0.0399376   -0.113257    -0.0132328     0.20902   
  0.0241048    0.00762872   0.139513    0.0698487   -0.0397997  -0.00684318  -0.141401      0.0417244   -0.0999701    0.165643   -0.0113805    0.174303    -0.017894      0.0140707    0.0452687   -0.00643904  -0.00265089   -0.0704204  -0.0635748    -0.0635389    0.053525    -0.0625185     0.0134886   -0.140576    -0.115698     -0.0932622 
 -0.0554744    0.0130831   -0.0175033   0.130308    -0.0478886   0.031621    -0.000688909   0.111624     0.0652263    0.102692   -0.111042     0.166639     0.112929     -0.191981     0.0960708   -0.165863    -0.0735217    -0.24545    -0.0697335    -0.129368    -0.138803     0.149659     -0.06868     -0.0298333    0.0522704     0.0276376 
  0.0370004    0.186507     0.0241677  -0.0339785    0.0269907  -0.11413     -0.0433935     0.0446784   -0.00875565   0.0397834   0.041909     0.161686     0.142814      0.00802542   0.112664     0.069382    -0.00217366    0.0695684   0.132766     -0.0603503    0.104631    -0.0331414     0.0344264    0.0887775   -0.0659707     0.139415  
 -0.00948777  -0.276484     0.027085   -0.0990752   -0.0740202  -0.00362417   0.0619663     0.0953008   -0.0588352   -0.110836   -0.156297     0.172701    -0.144491      0.234455     0.00382592   0.0813403    0.195187     -0.0134815  -0.110343     -0.0733944   -0.0309847   -0.0621778     0.144205     0.108617     0.106268      0.0402556 
  0.0069281   -0.0585069   -0.0289714   0.0673863   -0.0687425  -0.0612657   -0.0875136     0.00560331  -0.18858     -0.0634934  -0.00237715  -0.0391264    0.133702      0.115617    -0.0314126   -0.0634454    0.171802      0.0732733   0.224085     -0.0315828   -0.0180972    0.107489      0.142886    -0.0216703    0.0275272     0.0663074 
  0.287077    -0.0301368    0.0573874  -0.14397     -0.0168034   0.00709951   0.0848075    -0.124073    -0.0712882    0.104761    0.00663207   0.0182718    0.126        -0.032451    -0.0103788   -0.0508404   -0.210435     -0.121073    0.0489517    -0.176182     0.0658235   -0.0665889    -0.0834007    0.148978    -0.100847     -0.119488  
 -0.232133    -0.117369     0.209253    0.0181348    0.0471043  -0.0143712   -0.0061681     0.150346     0.125906    -0.0392066   0.0341449   -0.0471762   -0.0631139    -0.118331     0.0937795    0.0334839   -0.182956      0.0496617  -0.000828774   0.125097    -0.122807     0.045822      0.0315855   -0.176534    -0.161272      0.276824  
 -0.0435355   -0.0939656   -0.0295972  -0.0576666    0.174178   -0.103263     0.16693       0.214677    -0.0388376   -0.016616   -0.0674812    0.136603    -0.216729      0.0329885   -0.0542154    0.0482135   -0.0401733    -0.306045   -0.0778659     0.0344659   -0.132004     0.000117836  -0.0887947   -0.257783     0.151348     -0.0243201 
  0.00825402   0.146697    -0.015946   -0.238668     0.0326151   0.118672     0.0760875     0.047279     0.0909806   -0.0673705  -0.0692744   -0.100903     0.130619      0.0429198    0.15994      0.10615      0.0622274     0.178099    0.032202     -0.0386159    0.0657518    0.0007846    -0.151814    -0.0560214    0.0249463     0.129078  
  0.133868     0.0218459    0.0679491   0.0593454    0.0497658   0.0319217    0.0804402     0.0898654   -0.229485     0.0334935   0.0496038   -0.0206752   -0.0464893     0.0656899   -0.0131978    0.158717    -0.0932898    -0.0686341  -0.147928     -0.0844407   -0.00290642   0.0551982    -0.0165803    0.157751    -0.014592      0.00678249
 -0.0784647    0.100014     0.122114    0.0190334    0.0289408   0.00123224   0.0604116    -0.087299    -0.0839086    0.0867726   0.0288173   -0.073785    -0.148937     -0.240796    -0.0870069    0.0570565    0.0114654     0.0917717  -0.119367      0.00963817  -0.039165     0.0289218    -0.016453    -0.034796     0.0260885    -0.0443618 
 -0.0497574   -0.00237464  -0.155572    0.03858      0.0318306  -0.12699      0.0278097    -0.0871163    0.0857511    0.072612   -0.0394628    0.167066    -0.0716042     0.0037858   -0.2078       0.126219     0.0323271    -0.0123524   0.0177215     0.195188    -0.0725456   -0.0571045    -0.0725704    0.155596    -0.0238298     0.00373922
  0.140455     0.0574964    0.0319572  -0.157837    -0.0745802  -0.093409     0.0044268     0.0883808    0.062454    -0.0835748   0.0422197   -0.00136469  -0.0294834     0.0704382    0.095786     0.110179     0.0112501     0.08501    -0.124697      0.0845968   -0.0728903   -0.0771171     0.00637045  -0.00316154   0.093254     -0.0542394 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.410293078846661
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410398
[ Info: iteration 2, average log likelihood -1.410298
[ Info: iteration 3, average log likelihood -1.409644
[ Info: iteration 4, average log likelihood -1.402638
[ Info: iteration 5, average log likelihood -1.385954
[ Info: iteration 6, average log likelihood -1.380550
[ Info: iteration 7, average log likelihood -1.379762
[ Info: iteration 8, average log likelihood -1.379143
[ Info: iteration 9, average log likelihood -1.378237
[ Info: iteration 10, average log likelihood -1.376743
[ Info: iteration 11, average log likelihood -1.375665
[ Info: iteration 12, average log likelihood -1.375102
[ Info: iteration 13, average log likelihood -1.374724
[ Info: iteration 14, average log likelihood -1.374443
[ Info: iteration 15, average log likelihood -1.374226
[ Info: iteration 16, average log likelihood -1.374048
[ Info: iteration 17, average log likelihood -1.373892
[ Info: iteration 18, average log likelihood -1.373752
[ Info: iteration 19, average log likelihood -1.373624
[ Info: iteration 20, average log likelihood -1.373507
[ Info: iteration 21, average log likelihood -1.373401
[ Info: iteration 22, average log likelihood -1.373302
[ Info: iteration 23, average log likelihood -1.373210
[ Info: iteration 24, average log likelihood -1.373120
[ Info: iteration 25, average log likelihood -1.373028
[ Info: iteration 26, average log likelihood -1.372916
[ Info: iteration 27, average log likelihood -1.372735
[ Info: iteration 28, average log likelihood -1.372403
[ Info: iteration 29, average log likelihood -1.372030
[ Info: iteration 30, average log likelihood -1.371782
[ Info: iteration 31, average log likelihood -1.371620
[ Info: iteration 32, average log likelihood -1.371498
[ Info: iteration 33, average log likelihood -1.371390
[ Info: iteration 34, average log likelihood -1.371283
[ Info: iteration 35, average log likelihood -1.371164
[ Info: iteration 36, average log likelihood -1.371023
[ Info: iteration 37, average log likelihood -1.370851
[ Info: iteration 38, average log likelihood -1.370644
[ Info: iteration 39, average log likelihood -1.370365
[ Info: iteration 40, average log likelihood -1.369832
[ Info: iteration 41, average log likelihood -1.369154
[ Info: iteration 42, average log likelihood -1.368903
[ Info: iteration 43, average log likelihood -1.368813
[ Info: iteration 44, average log likelihood -1.368756
[ Info: iteration 45, average log likelihood -1.368710
[ Info: iteration 46, average log likelihood -1.368668
[ Info: iteration 47, average log likelihood -1.368629
[ Info: iteration 48, average log likelihood -1.368590
[ Info: iteration 49, average log likelihood -1.368552
[ Info: iteration 50, average log likelihood -1.368514
┌ Info: EM with 100000 data points 50 iterations avll -1.368514
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4103977447901654
│     -1.4102983936909346
│      ⋮                 
└     -1.368514092256862 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368619
[ Info: iteration 2, average log likelihood -1.368461
[ Info: iteration 3, average log likelihood -1.368046
[ Info: iteration 4, average log likelihood -1.364458
[ Info: iteration 5, average log likelihood -1.351823
[ Info: iteration 6, average log likelihood -1.339811
[ Info: iteration 7, average log likelihood -1.334899
[ Info: iteration 8, average log likelihood -1.332821
[ Info: iteration 9, average log likelihood -1.331709
[ Info: iteration 10, average log likelihood -1.330960
[ Info: iteration 11, average log likelihood -1.330418
[ Info: iteration 12, average log likelihood -1.330020
[ Info: iteration 13, average log likelihood -1.329711
[ Info: iteration 14, average log likelihood -1.329445
[ Info: iteration 15, average log likelihood -1.329190
[ Info: iteration 16, average log likelihood -1.328930
[ Info: iteration 17, average log likelihood -1.328657
[ Info: iteration 18, average log likelihood -1.328356
[ Info: iteration 19, average log likelihood -1.328012
[ Info: iteration 20, average log likelihood -1.327656
[ Info: iteration 21, average log likelihood -1.327351
[ Info: iteration 22, average log likelihood -1.327101
[ Info: iteration 23, average log likelihood -1.326886
[ Info: iteration 24, average log likelihood -1.326690
[ Info: iteration 25, average log likelihood -1.326492
[ Info: iteration 26, average log likelihood -1.326270
[ Info: iteration 27, average log likelihood -1.326013
[ Info: iteration 28, average log likelihood -1.325736
[ Info: iteration 29, average log likelihood -1.325475
[ Info: iteration 30, average log likelihood -1.325248
[ Info: iteration 31, average log likelihood -1.325047
[ Info: iteration 32, average log likelihood -1.324861
[ Info: iteration 33, average log likelihood -1.324671
[ Info: iteration 34, average log likelihood -1.324456
[ Info: iteration 35, average log likelihood -1.324192
[ Info: iteration 36, average log likelihood -1.323869
[ Info: iteration 37, average log likelihood -1.323562
[ Info: iteration 38, average log likelihood -1.323356
[ Info: iteration 39, average log likelihood -1.323224
[ Info: iteration 40, average log likelihood -1.323127
[ Info: iteration 41, average log likelihood -1.323046
[ Info: iteration 42, average log likelihood -1.322972
[ Info: iteration 43, average log likelihood -1.322900
[ Info: iteration 44, average log likelihood -1.322828
[ Info: iteration 45, average log likelihood -1.322754
[ Info: iteration 46, average log likelihood -1.322679
[ Info: iteration 47, average log likelihood -1.322602
[ Info: iteration 48, average log likelihood -1.322518
[ Info: iteration 49, average log likelihood -1.322417
[ Info: iteration 50, average log likelihood -1.322283
┌ Info: EM with 100000 data points 50 iterations avll -1.322283
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3686189523724681
│     -1.3684609449282281
│      ⋮                 
└     -1.3222831201467593
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322253
[ Info: iteration 2, average log likelihood -1.321785
[ Info: iteration 3, average log likelihood -1.320275
[ Info: iteration 4, average log likelihood -1.310744
[ Info: iteration 5, average log likelihood -1.288236
[ Info: iteration 6, average log likelihood -1.275160
[ Info: iteration 7, average log likelihood -1.269252
[ Info: iteration 8, average log likelihood -1.265182
[ Info: iteration 9, average log likelihood -1.262759
[ Info: iteration 10, average log likelihood -1.261566
[ Info: iteration 11, average log likelihood -1.260936
[ Info: iteration 12, average log likelihood -1.260527
[ Info: iteration 13, average log likelihood -1.260235
[ Info: iteration 14, average log likelihood -1.260034
[ Info: iteration 15, average log likelihood -1.259908
[ Info: iteration 16, average log likelihood -1.259830
[ Info: iteration 17, average log likelihood -1.259781
[ Info: iteration 18, average log likelihood -1.259747
[ Info: iteration 19, average log likelihood -1.259719
[ Info: iteration 20, average log likelihood -1.259695
[ Info: iteration 21, average log likelihood -1.259671
[ Info: iteration 22, average log likelihood -1.259646
[ Info: iteration 23, average log likelihood -1.259619
[ Info: iteration 24, average log likelihood -1.259584
[ Info: iteration 25, average log likelihood -1.259534
[ Info: iteration 26, average log likelihood -1.259449
[ Info: iteration 27, average log likelihood -1.259288
[ Info: iteration 28, average log likelihood -1.258994
[ Info: iteration 29, average log likelihood -1.258415
[ Info: iteration 30, average log likelihood -1.257410
[ Info: iteration 31, average log likelihood -1.256321
[ Info: iteration 32, average log likelihood -1.255771
[ Info: iteration 33, average log likelihood -1.255510
[ Info: iteration 34, average log likelihood -1.255220
[ Info: iteration 35, average log likelihood -1.254869
[ Info: iteration 36, average log likelihood -1.254519
[ Info: iteration 37, average log likelihood -1.254204
[ Info: iteration 38, average log likelihood -1.253991
[ Info: iteration 39, average log likelihood -1.253880
[ Info: iteration 40, average log likelihood -1.253823
[ Info: iteration 41, average log likelihood -1.253797
[ Info: iteration 42, average log likelihood -1.253786
[ Info: iteration 43, average log likelihood -1.253781
[ Info: iteration 44, average log likelihood -1.253778
[ Info: iteration 45, average log likelihood -1.253777
[ Info: iteration 46, average log likelihood -1.253776
[ Info: iteration 47, average log likelihood -1.253775
[ Info: iteration 48, average log likelihood -1.253775
[ Info: iteration 49, average log likelihood -1.253775
[ Info: iteration 50, average log likelihood -1.253775
┌ Info: EM with 100000 data points 50 iterations avll -1.253775
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3222530579516194
│     -1.321785004444611 
│      ⋮                 
└     -1.2537747713159966
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.254019
[ Info: iteration 2, average log likelihood -1.253735
[ Info: iteration 3, average log likelihood -1.252684
[ Info: iteration 4, average log likelihood -1.242110
[ Info: iteration 5, average log likelihood -1.206178
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.174318
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.189664
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.183208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.169707
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.160950
[ Info: iteration 11, average log likelihood -1.179624
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.157248
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.171686
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.163652
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.170615
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.163408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.170038
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.162038
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.167523
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.161113
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.173360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.163399
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.169814
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.161483
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.166798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.160577
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.165419
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.164780
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.169458
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.161533
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.167350
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.161310
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.166215
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.158882
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.165740
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.164985
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.168261
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.162176
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.167412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.160048
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.166979
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.159000
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.164557
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.165753
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.168596
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.161177
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.168329
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.160251
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.165916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.159921
┌ Info: EM with 100000 data points 50 iterations avll -1.159921
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.254019376900812 
│     -1.2537354181300924
│      ⋮                 
└     -1.1599214920165397
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.165082
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.149156
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.154171
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.128807
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090517
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.050592
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.091605
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059209
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058519
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082071
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.067150
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.050915
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.090073
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.059274
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.059432
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.081932
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.067372
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.051503
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.090026
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.059372
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.059665
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.081912
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.067413
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.051607
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.090012
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059393
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.059715
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.081904
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067425
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051635
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.090004
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.059399
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.059732
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.081898
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.067429
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.051648
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.089999
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.059402
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.059741
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081894
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.067431
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051655
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.089996
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.059403
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.059746
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.081891
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     21
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.067431
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051674
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.089995
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.059406
┌ Info: EM with 100000 data points 50 iterations avll -1.059406
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1650820752113813
│     -1.1491564782943609
│      ⋮                 
└     -1.0594055115286638
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.410293078846661 
│     -1.4103977447901654
│     -1.4102983936909346
│     -1.4096444597305002
│      ⋮                 
│     -1.0516742281516602
│     -1.0899954967441035
└     -1.0594055115286638
32×26 Array{Float64,2}:
 -0.0151094    0.0115538    0.0130656    0.0360197   -0.0092322   -0.00778143   0.0131796    0.0397057  -0.112255     0.014277   -0.0182168    -0.042678     0.0653396   -0.0326422    0.031383    -0.0568661    0.0842471    0.109355      0.0892103    0.00188127   -0.0644624    0.188236     -0.0174458  -0.053589     0.0788769    0.0273753 
  0.0392759    0.047584     0.0769059    0.0599804   -0.0369917    0.0121377   -0.0779317    0.101907   -0.0922766    0.172535   -0.00314263    0.115101     0.0592745    0.033712     0.0334162   -0.00409596  -0.0271307    0.0206058     0.0110829   -0.0566579    -0.0563653   -0.0986069    -0.0317764  -0.00587081   0.0616398   -0.208201  
  0.27463     -0.0593827    0.056583    -0.177872     0.0136517    0.00269979   0.0575571   -0.13189    -0.0712987    0.10859     0.026458      0.039533     0.121793    -0.0271471    0.027199    -0.0656749   -0.210319    -0.117667      0.0497493   -0.17765       0.0436635   -0.0633922    -0.0823682   0.182075    -0.120401    -0.115135  
 -0.0814218    0.106214     0.116857     0.0188833    0.041718    -0.0137487    0.0521719   -0.0859129  -0.0902377    0.0776488   0.0320707    -0.0696874   -0.124686    -0.238077    -0.0852316    0.0705402    0.0181371    0.0906405    -0.0996511   -0.00506535   -0.0387745    0.0260637    -0.015346   -0.00847102   0.0499375   -0.0540807 
 -0.11625      0.0290061   -0.0991445   -0.106502    -0.120895    -0.112173    -0.0561119    0.0632228  -0.0906064    0.13488    -0.172596      0.00728734   0.00421835  -1.70889     -0.0740575    0.10827     -0.0261683    0.0388177     0.157181    -0.0769994     0.0274445   -0.0854276    -0.0160146  -0.0752051    0.050508     0.202222  
 -0.128604     0.0325678   -0.0991398   -0.0884374   -0.0948944   -0.0630989   -0.0536608    0.0713101  -0.0872308    0.145457    0.170533     -0.0491712   -0.00479531   1.81436     -0.0738194    0.165066     0.171617     0.00138877    0.157299    -0.0714238     0.0343883   -0.154289      0.052036   -0.0915897   -0.0725351    0.200675  
  0.120069    -0.193162     0.0991826    0.120974    -0.00783537   0.0841055   -0.248505    -0.0248065   0.128828     0.0938627   0.0656783     0.0899919   -0.0133927    0.00658996  -0.0232672   -0.0935707   -0.271159    -0.0354246    -0.00796588  -0.0995973    -0.38796      0.0145664     0.094627    0.0139322    0.103325    -0.020051  
  0.110422    -0.00305743   0.116629    -0.0146049   -0.0338737    0.0461306   -0.0879835   -0.0522225   0.0443582    0.128092    0.0737404     0.0536366    0.0173348    0.0518771   -0.01015      0.325491     0.117271    -0.0243975    -0.0544011   -0.050349      0.115333    -0.0487186     0.208387    0.0277082    0.10584     -0.0645532 
  0.0343953   -0.141527     0.0148114    0.0642209    0.132456     0.224669    -0.141857     0.163577    0.115006     0.130762    0.000138485  -0.0424445   -0.100924     0.0495187   -0.247211     0.112789     0.00878109   0.179406     -0.11345     -0.0332481    -0.0546251    0.122725     -0.0439186   0.105923    -0.15846     -0.0867013 
  0.106179    -0.0643255    0.0744993    0.0392255   -0.00747485   0.0991493    0.00967978  -0.0311635  -0.0604882    0.0571868   0.194715      0.0672883   -0.0740822    0.0714704    0.100343    -0.0776058    0.132658     0.127288     -0.0152089   -0.0183173    -0.180326     0.0758108    -0.0930301  -0.14523      0.0170565   -0.0141326 
 -0.0873336    0.00442329  -0.299048    -0.10766     -0.206426    -0.0121035    0.182962    -0.202926    0.087798     0.0713955   0.0586999    -0.0942166   -0.426667     0.0694157   -0.0022797    0.051637    -0.177805     0.164706     -0.237456     0.152055     -0.163626     0.312404      0.0433007   0.119663    -0.0314799   -0.0577987 
  0.0578915    0.0567021   -0.276242    -0.127853    -0.0903648   -0.00783433  -0.1939       0.136426    0.0765708   -0.154876    0.0617479    -0.0828438    0.458953     0.0450094    0.012705     0.0514092   -0.0799319    0.171766     -0.0430922    0.093249      0.171104     0.219662      0.0342041   0.135166     0.118175     0.256502  
  0.0970477   -0.061571     0.135338    -0.143519    -0.161043    -0.0229836   -0.0206929   -0.151253   -0.10015     -0.0721027   0.179759     -0.0530823   -0.157114    -0.104308    -0.0154582    0.0962083   -0.0929433   -0.133597      0.155675     0.0307165    -0.045925     0.140115      0.0822286  -0.152608    -0.0122499   -0.0803126 
  0.124897    -0.0179651    0.106026    -0.0561659    0.76969     -0.0503133   -0.0255994    0.97823    -0.116753     0.151355    0.179686      0.170365    -0.135772    -0.0896109   -0.0173306    0.0664169   -0.0994442   -0.143539      0.0860183    0.0248492    -0.0458104    0.475336      0.219736   -0.127342    -0.0905936   -0.0815252 
  0.0305659    0.115219     0.109982    -0.0515946   -0.14156     -0.0987316    0.09761     -0.0231358   0.0416314    0.213635    0.13428      -0.122219     0.212555     0.0660209   -0.0437993    0.167661     0.0872076    0.0952161     0.126719    -0.143202      0.0319177   -0.20681       0.179347   -0.137473    -0.036523    -0.074064  
 -0.180176     0.115698    -0.0193966   -0.0355989    0.611397    -0.0985862   -0.128621    -0.0250086   0.0511571    0.181338    0.0775259    -0.318229     0.0630123    0.0974243    0.122927     0.126933     0.0749504    0.0675075     0.12972     -0.0871542     0.128538    -0.0784961    -0.124172   -0.21985      0.0465545   -0.0721635 
  0.00532815  -0.0795893    0.0213819   -0.125528    -0.00905379   0.0990059   -0.0554593    0.0913497   0.0375545    0.150625    0.129398      0.0573795    0.0633136   -0.0551983   -0.157216     0.0414328   -0.0988275   -0.0885147     0.01514     -0.108994      0.0372836    0.0900897     0.0817586  -0.032365    -0.0016335    0.158163  
  0.121399     0.008732     0.0442896    0.0536529    0.0372973    0.0206127    0.071992     0.0896997  -0.235765     0.0339122   0.0602764     0.00434993  -0.0538837    0.0682162   -0.02858      0.114413    -0.0774786   -0.0930449    -0.140818    -0.0915812     0.0012372    0.0439329    -0.0173578   0.149276    -0.0211012   -0.00487401
 -0.155551     0.0587804   -0.0893493    0.22961      0.138986     0.13302     -0.00818998  -0.0380226   0.0562447   -0.0138496   0.0976166     0.110116     0.046924    -0.121826     0.0414485    0.0841565   -0.181528     0.0659507    -0.0894674   -0.0580291    -0.0964113   -0.130847      0.222094    0.0374375    0.0319668   -0.11526   
  0.00564049   0.146614    -0.0333263   -0.224647     0.0390952    0.106846     0.0434409    0.0459317   0.0814105   -0.0635984  -0.0722082    -0.103105     0.130396     0.0857524    0.171717     0.0920019    0.059996     0.157373      0.030169    -0.0330022     0.0789707   -0.00922238   -0.143253   -0.0509461    0.0300817    0.139694  
 -0.106428    -0.145792     0.0584123   -0.00898013  -0.0449798    0.0369303   -0.00950756   1.97052    -0.029862     0.0514268  -0.0998684    -0.133707    -0.0187897   -0.0126981   -0.248536    -0.103767     0.0088324    0.0474509     0.0130478    0.000851691   0.284065    -0.0163953     0.0219156  -0.0402081   -0.0355574   -0.0287294 
 -0.106814    -0.0501147    0.04891      0.109772    -0.0497389    0.0374204    0.0506977   -1.99471    -0.00243989   0.0460716  -0.0720776    -0.127162    -0.0385468   -0.0469138   -0.270662    -0.114612     0.011141     0.0500995     0.0131681    0.0402979    -0.166115    -0.000142039  -0.0396974  -0.0394661    0.0244236   -0.0352961 
  0.036233     0.184307     0.0495799   -0.0226332    0.0290052   -0.082737    -0.0210001    0.0443263   0.0125346    0.059857    0.0348519     0.184935     0.138253     0.00837549   0.134211     0.0694059   -0.0170406    0.0623908     0.131274    -0.0640609     0.103603    -0.0358036     0.0251704   0.0879453   -0.0613694    0.175103  
 -0.00940804  -0.204662     0.0890277    0.0868594   -0.0453181   -0.0400595   -0.0197976    0.168431    0.12467      0.0780985  -0.0989929    -0.0131444    0.0407818    0.0343412    0.0824251    0.0108729   -0.0690025    0.13492       0.191586    -0.140177     -0.0834855    0.166804     -0.272308   -0.131773     0.105692     0.00400748
 -0.0890742   -0.140514     0.0751755   -0.0696574   -0.00407833  -0.0175452    0.00088051   0.156078   -0.0298166   -0.0249826  -0.0560444     0.0628546   -0.0655049    0.27488      0.00865105   0.0640667    0.0363782   -0.0385046    -0.0522542    0.0375451    -0.0711237   -0.0432032     0.0384858   0.0151143    0.048341     0.045865  
 -0.00484157  -0.0236262   -0.0496731   -0.0513937   -0.0344365   -0.0510175    0.032679     0.0547628  -0.112021    -0.0124982  -0.0901247     0.0648083   -0.0413656    0.0915843    0.0546075    0.160694    -0.0351075    0.0467517    -0.0574373   -0.0823177     0.0455427    0.087269     -0.189569    0.0202529   -0.0426257   -0.0563276 
 -0.0536644   -0.0964412   -0.1356      -0.811478    -0.0402031   -0.203197     0.0613742   -0.0882879   0.0597566    0.0764221  -0.0531329     0.176683    -0.0623661    0.199539    -0.205139     0.175243     0.05806      0.000837245  -0.0129228    0.195712     -0.0849072   -0.0758184    -0.0815614   0.161626    -0.00226063  -0.096176  
 -0.0446613    0.0162289   -0.114242     0.753857     0.052154    -0.111303    -0.0658286   -0.0903671   0.120649     0.0674951  -0.0433068     0.159228    -0.0600192   -0.113764    -0.207675     0.105356     0.0222323   -0.0503115     0.00996596   0.187798     -0.056189    -0.0345085    -0.0793983   0.141178    -0.0932312    0.127083  
 -0.0334043   -0.0779656   -0.0173887    0.0359398    0.0605128   -0.0284098    0.0762356    0.168764    0.0125452    0.0332935  -0.0901741     0.152239    -0.0483645   -0.0760196    0.022357    -0.0594338   -0.0584714   -0.273917     -0.0766164   -0.0483577    -0.136591     0.0759681    -0.079907   -0.143065     0.101546     0.00345067
  0.0139314    0.0622054   -0.144067     0.0585044   -0.0522019    0.0326379   -0.125183    -0.083334   -0.0994546    0.0290524  -0.165892      0.0253265    0.0820047    0.151156    -0.0841909    0.095821    -0.12974      0.0812847     0.0689985   -0.0611222     0.0485051    0.172704     -0.190221   -0.114807    -0.216428    -0.00109456
 -0.0945755   -0.036375     0.0803849    0.0783768    0.0514391   -0.0367984    0.0177099    0.097395    0.0826548    0.0152311  -0.0228046    -0.0630222   -0.0137336   -0.0314699   -0.0131262   -0.0608578   -0.108213     0.0427759     0.0387024   -0.04984      -0.0649393   -0.00901753    0.0189264  -0.154089    -0.0248595    0.120717  
  0.145456     0.0795273   -0.00418236  -0.0506171   -0.0716024   -0.00126159  -0.0505935    0.0294971   0.0478684    0.0150323  -0.00215447    0.00318496  -0.0592542    0.0311       0.0509865    0.0464748   -0.0475612    0.0311383     0.00317141   0.0847315     0.00318367  -0.0637511    -0.0122344   0.117165     0.0560219   -0.0422521 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.059751
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.051551
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.059654
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.051534
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.059649
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.051529
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.059645
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051526
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.059642
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      9
│     11
│      ⋮
│     21
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.051525
┌ Info: EM with 100000 data points 10 iterations avll -1.051525
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.338958e+05
      1       6.759178e+05      -1.579779e+05 |       32
      2       6.438456e+05      -3.207220e+04 |       32
      3       6.230812e+05      -2.076437e+04 |       32
      4       6.086065e+05      -1.447475e+04 |       32
      5       6.022249e+05      -6.381599e+03 |       32
      6       5.986801e+05      -3.544815e+03 |       32
      7       5.956866e+05      -2.993465e+03 |       32
      8       5.936951e+05      -1.991486e+03 |       32
      9       5.929701e+05      -7.250283e+02 |       32
     10       5.926392e+05      -3.308795e+02 |       32
     11       5.923621e+05      -2.771663e+02 |       32
     12       5.920953e+05      -2.668028e+02 |       32
     13       5.918677e+05      -2.275920e+02 |       32
     14       5.916843e+05      -1.833560e+02 |       32
     15       5.915219e+05      -1.624357e+02 |       32
     16       5.913742e+05      -1.476244e+02 |       32
     17       5.912299e+05      -1.443086e+02 |       32
     18       5.910854e+05      -1.445563e+02 |       32
     19       5.909508e+05      -1.345481e+02 |       32
     20       5.908222e+05      -1.286039e+02 |       32
     21       5.906682e+05      -1.540218e+02 |       32
     22       5.905216e+05      -1.466265e+02 |       32
     23       5.904099e+05      -1.116956e+02 |       31
     24       5.903203e+05      -8.961042e+01 |       32
     25       5.902191e+05      -1.011551e+02 |       32
     26       5.900623e+05      -1.567927e+02 |       32
     27       5.897855e+05      -2.768530e+02 |       32
     28       5.894481e+05      -3.373805e+02 |       32
     29       5.891253e+05      -3.227850e+02 |       31
     30       5.888634e+05      -2.619447e+02 |       32
     31       5.887160e+05      -1.473286e+02 |       31
     32       5.886383e+05      -7.778145e+01 |       31
     33       5.886092e+05      -2.906248e+01 |       31
     34       5.885981e+05      -1.108925e+01 |       30
     35       5.885918e+05      -6.289268e+00 |       26
     36       5.885889e+05      -2.861631e+00 |       25
     37       5.885870e+05      -1.973212e+00 |       17
     38       5.885861e+05      -8.391995e-01 |       10
     39       5.885859e+05      -2.189628e-01 |        8
     40       5.885858e+05      -1.477326e-01 |        5
     41       5.885857e+05      -1.104885e-01 |        8
     42       5.885854e+05      -2.356833e-01 |       10
     43       5.885849e+05      -4.912739e-01 |       12
     44       5.885846e+05      -3.372082e-01 |       13
     45       5.885843e+05      -3.241210e-01 |        6
     46       5.885841e+05      -1.279536e-01 |        6
     47       5.885840e+05      -1.254649e-01 |        6
     48       5.885838e+05      -1.866466e-01 |        2
     49       5.885837e+05      -9.479625e-02 |        5
     50       5.885836e+05      -1.069119e-01 |        0
K-means terminated without convergence after 50 iterations (objv = 588583.6287690876)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306657
[ Info: iteration 2, average log likelihood -1.272735
[ Info: iteration 3, average log likelihood -1.241340
[ Info: iteration 4, average log likelihood -1.209064
[ Info: iteration 5, average log likelihood -1.166451
[ Info: iteration 6, average log likelihood -1.107835
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     12
│     18
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038375
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│     14
│     15
│     16
│     19
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.071705
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.133277
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.080740
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     18
│     20
│     21
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.028098
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│      8
│     12
│     13
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.038127
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.111565
[ Info: iteration 14, average log likelihood -1.102899
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.025477
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      8
│      9
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.000941
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.158420
[ Info: iteration 18, average log likelihood -1.104705
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     21
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.037771
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      8
│     12
│     15
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.033188
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     13
│     16
│     19
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.077303
[ Info: iteration 22, average log likelihood -1.107157
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     21
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.037289
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      8
│     15
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.044550
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.074183
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.067585
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     20
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.042055
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.071461
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.060648
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     13
│     16
│     19
│     20
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.029184
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.093170
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      8
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.070492
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.073935
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     15
│     16
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.027926
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.125689
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.058485
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.048979
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     15
│     16
│      ⋮
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044799
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.115611
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068057
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.042042
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│      9
│     15
│      ⋮
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.039465
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.124962
[ Info: iteration 44, average log likelihood -1.090461
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     18
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.026992
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      8
│      9
│      ⋮
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.032382
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.144493
[ Info: iteration 48, average log likelihood -1.092795
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.028786
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      8
│      9
│      ⋮
│     21
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.019580
┌ Info: EM with 100000 data points 50 iterations avll -1.019580
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0451812    0.0124121    -0.006615    0.126603    -0.0565321    0.0317735   -0.011011     0.115996     0.0542751    0.0766775   -0.110991      0.162724      0.112674     -0.189129     0.101979    -0.165662   -0.0770955    -0.252145    -0.0765954   -0.138673    -0.139012      0.150204    -0.0949127   -0.0320136    0.0518711    0.0309604 
  0.112864    -0.101313      0.102981    0.0532674   -0.0208347    0.0646825   -0.164986    -0.0470417    0.0876939    0.108239     0.0694333     0.0680739     0.00222893    0.0284789   -0.0211833    0.120244   -0.0745082    -0.0272931   -0.0305401   -0.0782633   -0.139883     -0.0105527    0.152849     0.0208045    0.10428     -0.0422566 
  0.0150455    0.0623728    -0.144457    0.059006    -0.0522068    0.0326552   -0.125211    -0.0833641   -0.0989692    0.0292119   -0.165857      0.0250551     0.0819126     0.15184     -0.082134     0.0962023  -0.129651      0.0810597    0.0692212   -0.0612264    0.0485223     0.171939    -0.191891    -0.114763    -0.216687    -0.00151333
  0.0359489    0.184312      0.0481845  -0.0214785    0.029272    -0.0838474   -0.0228769    0.0448895    0.0142601    0.0557833    0.0346609     0.183263      0.138988      0.00856752   0.135442     0.0694063  -0.0178315     0.0635366    0.131287    -0.0656774    0.103906     -0.03587      0.0236605    0.0873357   -0.0617931    0.174616  
  0.10551     -0.0484067     0.126938   -0.117772     0.109509    -0.0309511   -0.0223175    0.177864    -0.105131    -0.00650598   0.179732      0.0138325    -0.150152     -0.0998964   -0.0159896    0.0876495  -0.0947718    -0.13674      0.135659     0.0297074   -0.0458894     0.237261     0.122481    -0.145062    -0.0350776   -0.080684  
 -0.069356    -0.0165799     0.0675708  -0.0508044    0.0894483   -0.0224023   -0.0470708    0.200692    -0.00951831   0.0438349   -0.00911952   -0.0383905     0.0293759     0.302503     0.0105175    0.0823397  -0.092655     -0.0538748   -0.0229502    0.117036    -0.112192     -0.0278508   -0.0606875   -0.0771563   -0.0487262    0.051874  
 -0.042433     0.0308471    -0.0724481   1.26489      0.0436571   -0.124305    -0.0463639   -0.0885967    0.112387     0.0714495   -0.03645       0.162722     -0.0723763    -0.117691    -0.209356     0.0995601   0.0369948    -0.040558     0.00750873   0.191063    -0.0771247    -0.0431544   -0.0787972    0.129009    -0.0723471    0.147505  
 -0.237063    -0.112801      0.209479    0.0132959    0.0469226   -0.00918903  -0.00906431   0.155129     0.126358    -0.0471871    0.0344019    -0.0516701    -0.0629828    -0.12552      0.0954869    0.0374093  -0.168721      0.0534568   -0.00421993   0.122478    -0.135495      0.03573      0.045843    -0.194307    -0.189032     0.253557  
  0.0560394    0.0313084    -0.0468701   0.140386     0.0620139   -0.0548781    0.0564101    0.0349679    0.0307198    0.0907685   -0.0969211    -0.0870536     0.0364732     0.0710265   -0.13714     -0.177626   -0.0426841     0.045565     0.102949    -0.230959     0.00356742   -0.0474183   -0.0378066   -0.0851236    0.131243    -0.00694954
 -0.054432    -0.091573     -0.162942   -0.961599    -0.0198222   -0.178906     0.0324422   -0.0882627    0.0706998    0.0723309   -0.0549916     0.171766     -0.0528415     0.16499     -0.20427      0.170752    0.0408373    -0.00955947  -0.00980623   0.191578    -0.0676125    -0.0635626   -0.0806959    0.168481    -0.032499    -0.0823017 
  0.0300419    0.179393     -0.0307933   0.0298939   -0.0792327   -0.0407392   -0.118281     0.161068     0.0428339    0.0578155    0.0664099     0.149005      0.00499684    0.136486     0.120251     0.123806   -0.0477606     0.0414875   -0.0671984   -0.0051256   -0.0127323    -0.121571     0.0883452    0.203242     0.24462     -0.242154  
  0.0278865   -0.0467189    -0.044813    0.0934833   -0.068639    -0.0502395   -0.112357     0.00728197  -0.186832    -0.0366632    0.0180882    -0.0670724     0.148996      0.115317     0.0334235   -0.110146    0.159199      0.0853735    0.417121     0.0130736   -0.0292425     0.135562     0.130421    -0.00667423   0.0312545    0.0915378 
 -0.0197845    0.00247148   -0.0619628  -0.0480838   -0.0335223   -0.0573002    0.0320202    0.0522206   -0.119883    -0.00608893  -0.076569      0.0555789    -0.0303025     0.0824854    0.0570114    0.164977   -0.0406035     0.0493415   -0.0530742   -0.0719339    0.0447284     0.104042    -0.22208      0.00613301  -0.0535296   -0.0641801 
 -0.00284421  -0.0339349     0.032713   -0.0738132   -0.00615515   0.0330882    0.00893712   0.106336     0.107684     0.00342829  -0.0872393    -0.0568812     0.0847349     0.0585261    0.131623     0.043456   -0.000352469   0.145813     0.108666    -0.0891706   -0.00155565    0.0817198   -0.208785    -0.0893902    0.06867      0.0722231 
 -0.022024    -0.15524      -0.0338502  -0.0554137    0.179615    -0.0919571    0.163277     0.217347    -0.0350617   -0.00100438  -0.0729967     0.14122      -0.210657      0.0326625   -0.0577502    0.0471676  -0.0397367    -0.298146    -0.0741539    0.0458916   -0.135252      3.61697e-5  -0.0639933   -0.249896     0.150229    -0.0247649 
 -0.0859385   -0.278262      0.0773311  -0.0893681   -0.085127    -0.00661379   0.0570288    0.104106    -0.059656    -0.101941    -0.115049      0.177698     -0.163167      0.235476     0.00260808   0.0354959   0.161643     -0.0124907   -0.0968802   -0.0757046   -0.0300149    -0.0573394    0.142413     0.133588     0.139025     0.0450899 
 -0.0569379    0.0770103     0.0409416   0.00992969   0.0562679    0.0385205    0.123532     0.0495799   -0.065751     0.0517737   -0.0567071    -0.0343765    -0.000206842  -0.187095     0.0628776   -0.116042   -0.00957102    0.153622    -0.0199393   -0.0128853   -0.111414      0.296455    -0.172539    -0.113975     0.127681     0.0236958 
  0.0636551   -0.013018      0.0547639   0.0733125   -0.0164252    0.0500492   -0.0125078    0.139608    -0.17469      0.272318    -0.047985      0.0616478     0.119749     -0.0493513   -0.0265906   -0.015065   -0.0287622     0.0858618    0.0995198   -0.0750399   -0.187403     -0.104873    -0.115622    -0.00501519   0.110666    -0.276902  
 -0.0762128    0.114576      0.0435547  -0.043961     0.246361    -0.0987418   -0.0184296   -0.0237471    0.0458177    0.195903     0.106385     -0.225151      0.136971      0.0840296    0.0395134    0.145437    0.0812345     0.0820768    0.127342    -0.115945     0.0812976    -0.140947     0.0230419   -0.178639     0.00721112  -0.0723393 
 -0.124728     0.0259474    -0.0993704  -0.0982904   -0.110532    -0.0904161   -0.0549411    0.0644414   -0.0916641    0.140728    -0.0104992    -0.0261762     0.00114026   -0.0283233   -0.0735619    0.131481    0.070575      0.0200808    0.162677    -0.0764748    0.0315888    -0.118651     0.0138449   -0.0935459   -0.0148568    0.208541  
  0.0331406   -0.141791      0.0141388   0.0647111    0.134453     0.226918    -0.143893     0.160205     0.115864     0.131958     0.000155905  -0.0431082    -0.102535      0.0467495   -0.248142     0.114088    0.00694025    0.181179    -0.111976    -0.0333858   -0.0542061     0.129387    -0.0443104    0.107774    -0.159418    -0.0848043 
 -0.150137     0.0541963    -0.080598    0.217707     0.12986      0.129948    -0.00344714  -0.0419377    0.0335548   -0.013409     0.0902627     0.0946151     0.0467367    -0.116523     0.0277097    0.0794896  -0.170507      0.0656515   -0.0848519   -0.0592136   -0.0913099    -0.127098     0.211165     0.0373077    0.02821     -0.105144  
 -0.106343    -0.0942967     0.0467671   0.0685123   -0.0577453    0.0289477    0.027721    -0.10028     -0.0104394    0.0485092   -0.0940927    -0.140958     -0.0208001    -0.015908    -0.316611    -0.118725    0.0139355     0.0601866    0.0142708    0.0229094    0.0806494     0.00579708  -0.00841716  -0.0297225   -0.00485285  -0.0292267 
  0.174382     0.0870807    -0.0715698   0.0342181   -0.0751565    0.102008    -0.0985199   -0.0606105    0.0447459    0.0856543   -0.0546505    -0.0142839    -0.0779481    -0.0437995   -0.0276327   -0.0106996  -0.0869744    -0.00392853   0.131832     0.0759766    0.100042     -0.0504125   -0.00425989   0.18401     -0.0228317   -0.0113282 
  0.128258     0.000501689   0.0530853   0.0619583    0.0233931    0.0108332    0.0801085    0.0882569   -0.247766     0.0238162    0.0617059    -0.00573037   -0.0348332     0.070716    -0.0232135    0.195787   -0.0609111    -0.12069     -0.150462    -0.109208    -0.003294      0.0354404   -0.00972321   0.138583    -0.0228036   -0.00205704
  0.0104482   -0.080159      0.0108539  -0.119001    -0.00575779   0.100516    -0.0545833    0.0919348    0.0359392    0.148956     0.132418      0.0515589     0.062643     -0.052849    -0.160693     0.0399931  -0.100377     -0.091137     0.0125679   -0.111531     0.0368824     0.0907448    0.0814138   -0.0307611    0.00140386   0.153795  
 -0.0799666    0.103475      0.118298    0.0197513    0.0492998   -0.0181733    0.0557528   -0.0822013   -0.0964627    0.0792559    0.0341626    -0.0785908    -0.122861     -0.244635    -0.0800812    0.0668139   0.017656      0.0904306   -0.0975502   -0.00464341  -0.0360371     0.0293098   -0.0156901   -0.00859717   0.0436028   -0.0523078 
  0.145856     0.0373531     0.0650465  -0.150016    -0.0741365   -0.0967387   -0.0129857    0.087531     0.0567012   -0.074441     0.0525751     0.000295154  -0.0165441     0.0681876    0.113015     0.103685    0.0116154     0.0773716   -0.11443      0.120425    -0.0873269    -0.0545952   -0.0216336    1.71593e-5   0.0926022   -0.0258051 
  0.0105548    0.0121403     0.117936    0.0591564   -0.0453257    0.0111873   -0.104897     0.025853    -0.0841313    0.131588     0.0195966     0.137619      0.00947165    0.0606471    0.0497006   -0.0213438  -0.00530844   -0.040911    -0.0689753   -0.0380571    0.0550718    -0.0404969    0.0081751   -0.107149    -0.0972958   -0.120553  
 -0.0269649    0.0334083    -0.310293   -0.197713    -0.173117    -0.0157649    0.00103646  -0.0353033    0.0856927   -0.0545348    0.0563074    -0.105649     -0.00360757    0.0571403    0.0223468    0.0495167  -0.126148      0.183091    -0.218513     0.162652    -0.000746857   0.320014     0.040318     0.122652     0.0425431    0.140504  
  0.103404    -0.059744      0.0605825   0.0411194   -0.0192499    0.0970222    0.0119661   -0.0346456   -0.0569976    0.055845     0.190469      0.0635616    -0.0796459     0.0729786    0.0978174   -0.0720422   0.122267      0.131534    -0.0237227   -0.0184547   -0.171974      0.0751886   -0.0878932   -0.140155     0.0255541   -0.0145862 
  0.279583    -0.0592459     0.0598843  -0.173966     0.0136027    0.00333626   0.0565531   -0.126529    -0.0710917    0.108203     0.0244941     0.0368907     0.121082     -0.0275694    0.0253982   -0.0709178  -0.208674     -0.119532     0.0485516   -0.175047     0.0307573    -0.0638751   -0.0822531    0.180151    -0.123403    -0.113628  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.164020
[ Info: iteration 2, average log likelihood -1.098026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.034327
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      5
│      8
│      9
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.967915
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.153936
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.096494
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.036988
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      5
│      8
│      9
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.964550
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.157093
[ Info: iteration 10, average log likelihood -1.100821
┌ Info: EM with 100000 data points 10 iterations avll -1.100821
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0196831    0.0370495    0.00957179  -0.0524591    0.0322307   -0.121767    -0.0308937   -0.0150403     0.163854    -0.045693     0.16598     -0.0818174    -0.117195    -0.037105    -0.0325895    0.0759839    0.0892387    -0.170327     -0.137435    -0.0727061     0.0168622    0.151269     0.0488892    -0.0145315   0.0539604  -0.0331399  
  0.0315324   -0.0630247   -0.251838     0.0429697    0.147112    -0.167565    -0.143981     0.000768088   0.127732    -0.0683027   -0.00322348  -0.0281445     0.206782    -0.0706647    0.08043     -0.0916664   -0.0218454     0.15232      -0.023442    -0.0116279     0.119847     0.00525836  -0.00739156   -0.020832    0.107569    0.0217075  
  0.0396404   -0.0938251   -0.00397277  -0.009529    -0.0534877    0.0574096   -0.203379    -0.0502589    -0.0199067    0.0681039    0.146413    -0.00369205    0.0306629   -0.00870951   0.0421748   -0.0192214    0.0620662    -0.190329     -0.0463335    0.112189      0.0412035    0.100059     0.0379546    -0.0694765  -0.126868   -0.0909033  
 -0.113316    -0.0106051   -0.0599068    0.134754     0.00106266   0.0786613   -0.0361213   -0.0198045     0.109053     0.061414     0.142672    -0.00663369    0.0123885    0.0463948   -0.12732      0.0243906    0.199508     -0.00447614    0.00978011   0.0599767     0.0302459   -0.0433629    0.134374      0.15402     0.148139   -0.10035    
 -0.0486514   -0.0522661   -0.0615702    0.00255082  -0.017833     0.0785221   -0.0949886    0.00654349    0.00176851   0.139337     0.0348821   -0.0639789     0.00943995  -0.0491715    0.268012     0.0119376    0.178422      0.00558221    0.0735953    0.0486531     0.0158794    0.0524      -0.117367     -0.0116922   0.0140868  -0.0407287  
  0.11843      0.0617955   -0.0363877    0.0432266    0.0175209   -0.00882882  -0.0352873   -0.120309     -0.0494194   -0.0939747    0.0229279   -0.0909984     0.0703635   -0.125028     0.114329    -0.0894632   -0.0853209    -0.0619874    -0.135662     0.0767204    -0.0581108    0.126038     0.0539753    -0.17821     0.194698   -0.0163679  
 -0.0496393    0.0894975   -0.00344997   0.0212653   -0.054156    -0.0805557   -0.0789704    0.0630985     0.095734    -0.0533846   -0.0132107   -0.0881509     0.0255634   -0.0110009   -0.110052     0.135131     0.0517633     0.114579     -0.0180623   -0.0414325     0.0219107   -0.0436946   -0.0996999    -0.0345493  -0.0158533  -0.133437   
  0.201704    -0.37315      0.0644236   -0.0214006    0.0334535   -0.0378552   -0.0204346   -0.0538629     0.0632043    0.0827374   -0.216199    -0.00532955   -0.0157205    0.119688    -0.00727741   0.0264619   -0.0637413     0.125365      0.0184042    0.043365      0.108813    -0.13973      0.0798535     0.0690177   0.0279039   0.12721    
  0.0369878   -0.0886726    0.0129389   -0.0347998   -0.0180382   -0.0652506   -0.0577138   -0.0127734    -0.158093    -0.101299     0.029635     0.00612177    0.0230341   -0.0502755   -0.0037429    0.117588     0.235512     -0.153383      0.0939935    0.102332     -0.0433059   -0.00338139  -0.0832866     0.143902    0.0246999   0.115994   
  0.183152    -0.226747     0.0537578    0.0057526   -0.0469133    0.0897      -0.111351     0.11538       0.019014    -0.190992    -0.0274822    0.0429535    -0.0825154   -0.0655808   -0.0136425    0.00634951   0.000994908  -0.000694123  -0.0303793   -0.0173741    -0.0951528   -0.177159    -0.0478444     0.0356102  -0.124557   -0.000656525
  0.115467     0.136188     0.0325169    0.00706923   0.0692534    0.0315011    0.0123845   -0.0831743     0.0318656   -0.141053    -0.0592681    0.000433862   0.0493917   -0.0186248   -0.0768592   -0.0506439    0.105671      0.0348644    -0.0512552    0.0681318    -0.0624911   -0.0271443    0.0905312    -0.0137187  -0.126773   -0.135267   
  0.210922    -0.0427941   -0.151625     0.0727173   -0.00656526  -0.0183251   -0.0290324   -0.0793855    -0.147535    -0.0462717   -0.0362983   -0.0106921    -0.00711442  -0.0701129    0.107509    -0.19478      0.0155168    -0.0740003    -0.0537322    0.000805077   0.162643    -0.132738     0.0270397    -0.100051   -0.0706923   0.164958   
  0.00910425   0.0160645   -0.0135858   -0.0270114   -0.00904562  -0.0138199   -0.00830929  -0.057757     -0.111969     0.0973661   -0.0253185   -0.0265441     0.0287118   -0.0712676    0.151517    -0.0766743    0.199512     -0.0281789    -0.0309801    0.122253     -0.00742526   0.126428     0.0777092    -0.0226032  -0.0352257  -0.0925659  
  0.0637052   -0.0643114    0.0215075    0.127543    -0.00318795   0.0914763    0.13091     -0.150315     -0.130391    -0.0183515    0.0391039   -0.0451786    -0.0743694    0.140156     0.105491     0.0189266   -0.0606599    -0.0763494    -0.0179322   -0.227325     -0.139023    -0.0798471   -0.0567183    -0.0141883  -0.125776   -0.148285   
 -0.0147108    0.0754506    0.125123     0.0366241    0.136101     0.0677555    0.0595773    0.0062201    -0.0988073   -0.00550186  -0.0694384    0.0351983    -0.0409051    0.0947329   -0.00998     -0.0616926    0.015632     -0.137615      0.148596    -0.116691      0.0603858    0.027442    -0.071831      0.0433398   0.0636549   0.0995317  
  0.0193855    0.176638    -0.0479651   -0.0466842    0.0718808    0.0253514   -0.117433    -0.00127335   -0.0170626   -0.0111833    0.128148    -0.152748      0.0542639    0.0390691   -0.080511     0.0843036    0.176466      0.000454073  -0.10898     -0.118146      0.0725468    0.00720939   0.0917248    -0.211936   -0.0940222  -0.0209314  
 -0.0591898   -0.167068     0.136496     0.0882901    0.200428     0.0424366    0.0363367   -0.143989     -0.0635627   -0.00586556   0.0491956    0.126241     -0.0150974   -0.0306441    0.00808741  -0.0974293    0.0650982    -0.0534315     0.0994875    0.0471006     0.0520926   -0.0908277   -0.0972158     0.0728351  -0.145235   -0.0168767  
 -0.00349277   0.147664    -0.0528205    0.0179645    0.0187416    0.169004     0.0815142   -0.00666795   -0.102069     0.0574594    0.10942     -0.0958857     0.0412823   -0.155283     0.0422909   -0.0314196    0.0586161     0.11398      -0.0586998    0.254872      0.0165167   -0.0859912    0.0459062    -0.102599    0.0596035  -0.26307    
 -0.0470408    0.0844625    0.0495611   -0.0158937    0.012977    -0.0911626   -0.0248742   -0.0247045    -0.00225734  -0.0459208   -0.00950724  -0.00782815   -0.0127048    0.0213756    0.071073     0.0437537    0.0731815     0.0538357     0.0174394    0.0664731     0.0260971    0.00128654   0.145344     -0.0377857   0.0514913  -0.00755024 
  0.0501146   -0.147708    -0.0315799   -0.163792    -0.0568326   -0.0542107   -0.134003    -0.0669427    -0.146022     0.175113    -0.274474    -0.133372      0.121633    -0.0176791    0.155059    -0.109222     0.167657     -0.11356       0.117308     0.139055     -0.025729    -0.190239    -0.000906455  -0.0173878  -0.0267013   0.045173   
 -0.113426    -0.0865285    0.0405957    0.164998     0.0100654    0.0141614   -0.0756598    0.190524     -0.139441     0.0149155   -0.0397672   -0.0709203    -0.15762      0.139819     0.0972004    0.0998064    0.0883913    -0.0562774    -0.0234147   -0.0878416    -0.195935     0.108596     0.0558005     0.146879   -0.0944579  -0.0162085  
 -0.197924     0.0653956    0.149809    -0.0545901   -0.206621     0.0652658    0.0350436   -0.0356946     0.0550518   -0.0633041   -0.102648    -0.225644      0.00224803   0.0887277   -0.0275526    0.142005    -0.145504      0.0169429     0.0997516    0.0676596    -0.0467993   -0.324775     0.077777      0.0774688  -0.14408    -0.030568   
 -0.0617057    0.122964     0.0470971   -0.0202105    0.256692     0.0486832    0.096693     0.0710678     0.109933     0.163305     0.0919568   -0.0501132    -0.13107      0.0986941    0.0791524   -0.0197081   -0.030951      0.162914      0.0972945    0.0649728    -0.067646     0.149125    -0.0456054     0.0440199  -0.046697   -0.0203005  
  0.131707     0.131335    -0.13311     -0.0110054   -0.102508     0.121227     0.0730925   -0.0806532    -0.0488971   -0.0633328    0.0453829    0.14282      -0.199225     0.192119     0.0663947    0.0446778   -0.139948     -0.142048     -0.122517     0.0329912     0.0314647   -0.0191079    0.0353567     0.0359479   0.050987    0.0748376  
 -0.115699     0.142239    -0.0441212   -0.0801995   -0.184029    -0.28892     -0.0580525    0.118882     -0.0159949    0.0656058    0.121067    -0.1242       -0.0688736    0.0188295    0.106186     0.0528025    0.0340759    -0.0872211    -0.0418056    0.174405      0.0300474   -0.0595517    0.151011     -0.029356    0.0952314   0.0785057  
  0.129036    -0.0909972    0.0394348   -0.0203949    0.135628    -0.182485    -0.108534    -0.11151       0.238899     0.0863019    0.0694038   -0.0447138     0.0813616   -0.0336327   -0.173575     0.12808     -0.160395     -0.0143717    -0.209491    -0.116552     -0.0389038   -0.0424341   -0.0554075     0.103483    0.155911    0.0123286  
  0.0789766    0.180857    -0.0609788    0.089742     0.061384     0.0326427   -0.0942448   -0.0654013     0.00170335   0.00296412   0.0786218   -0.195385      0.0767329   -0.131393    -0.00655639   0.030028     0.0254945     0.0578852    -0.17151     -0.0207076    -0.0269604   -0.0690282   -0.0233526    -0.0253598   0.07125    -0.202      
 -0.0262669   -0.119213    -0.109594    -0.128992    -0.0681278   -0.132203     0.00736394  -0.157432     -0.0172046   -0.0539875    0.00579749  -0.00467177    0.125483     0.023533    -0.0742285   -0.0260058    0.0159348     0.0730865     0.0312721   -0.020406     -0.0641897   -0.0427483   -0.159423      0.0540297   0.0624514  -0.0655509  
  0.130546    -0.0317758   -0.0911806   -0.0341205   -0.348407    -0.0860284   -0.0637709    0.144456      0.0535181    0.0331932   -0.0148619    0.203196      0.0921625   -0.10736     -0.0558578   -0.0610472   -0.0913409    -0.029766     -0.0331572    0.0492266     0.00904959  -0.0200769    0.0250834     0.0633836  -0.198611    0.164186   
 -0.0199637   -0.00334974  -0.0737609   -0.0822867    0.0576191   -0.0406798    0.0317138   -0.0729511    -0.0591485   -0.0173335    0.13854     -0.0885646    -0.0526939   -0.00749088   0.125941     0.114332     0.0853784    -0.046319      0.0156404   -0.0948059    -0.0934714   -0.0494026   -0.0704926     0.144008    0.21951    -0.0166747  
  0.166188    -0.0884406    0.00658881   0.0883185   -0.0893414   -0.0501428   -0.106111    -0.0471524    -0.187176     0.0651544   -0.0281814   -0.0773886     0.13124      0.0139664   -0.0237058   -0.196493     0.120326     -0.0805781    -0.064418     0.0264834     0.0283298   -0.0179846   -0.0354332     0.0787554   0.0223971  -0.148184   
  0.00491165  -0.0144598    0.140535     0.0276195   -0.0870765    0.118465     0.00999823  -0.115957      0.151536    -0.0614878    0.0151366    0.00507079   -0.167568     0.357413     0.157849     0.141966     0.0641692    -0.0496015    -0.00420506  -0.0202202    -0.0689414    0.0485696    0.158941      0.108109   -0.106866   -0.0223907  kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4134903069945897
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413509
[ Info: iteration 2, average log likelihood -1.413434
[ Info: iteration 3, average log likelihood -1.413377
[ Info: iteration 4, average log likelihood -1.413313
[ Info: iteration 5, average log likelihood -1.413241
[ Info: iteration 6, average log likelihood -1.413161
[ Info: iteration 7, average log likelihood -1.413072
[ Info: iteration 8, average log likelihood -1.412964
[ Info: iteration 9, average log likelihood -1.412801
[ Info: iteration 10, average log likelihood -1.412502
[ Info: iteration 11, average log likelihood -1.411934
[ Info: iteration 12, average log likelihood -1.410998
[ Info: iteration 13, average log likelihood -1.409837
[ Info: iteration 14, average log likelihood -1.408860
[ Info: iteration 15, average log likelihood -1.408308
[ Info: iteration 16, average log likelihood -1.408071
[ Info: iteration 17, average log likelihood -1.407980
[ Info: iteration 18, average log likelihood -1.407946
[ Info: iteration 19, average log likelihood -1.407933
[ Info: iteration 20, average log likelihood -1.407927
[ Info: iteration 21, average log likelihood -1.407925
[ Info: iteration 22, average log likelihood -1.407924
[ Info: iteration 23, average log likelihood -1.407923
[ Info: iteration 24, average log likelihood -1.407922
[ Info: iteration 25, average log likelihood -1.407922
[ Info: iteration 26, average log likelihood -1.407922
[ Info: iteration 27, average log likelihood -1.407921
[ Info: iteration 28, average log likelihood -1.407921
[ Info: iteration 29, average log likelihood -1.407921
[ Info: iteration 30, average log likelihood -1.407920
[ Info: iteration 31, average log likelihood -1.407920
[ Info: iteration 32, average log likelihood -1.407920
[ Info: iteration 33, average log likelihood -1.407920
[ Info: iteration 34, average log likelihood -1.407920
[ Info: iteration 35, average log likelihood -1.407920
[ Info: iteration 36, average log likelihood -1.407919
[ Info: iteration 37, average log likelihood -1.407919
[ Info: iteration 38, average log likelihood -1.407919
[ Info: iteration 39, average log likelihood -1.407919
[ Info: iteration 40, average log likelihood -1.407919
[ Info: iteration 41, average log likelihood -1.407919
[ Info: iteration 42, average log likelihood -1.407919
[ Info: iteration 43, average log likelihood -1.407919
[ Info: iteration 44, average log likelihood -1.407919
[ Info: iteration 45, average log likelihood -1.407919
[ Info: iteration 46, average log likelihood -1.407919
[ Info: iteration 47, average log likelihood -1.407919
[ Info: iteration 48, average log likelihood -1.407919
[ Info: iteration 49, average log likelihood -1.407919
[ Info: iteration 50, average log likelihood -1.407919
┌ Info: EM with 100000 data points 50 iterations avll -1.407919
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4135088912426967
│     -1.4134339410783308
│      ⋮                 
└     -1.407918595926948 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407934
[ Info: iteration 2, average log likelihood -1.407861
[ Info: iteration 3, average log likelihood -1.407800
[ Info: iteration 4, average log likelihood -1.407730
[ Info: iteration 5, average log likelihood -1.407647
[ Info: iteration 6, average log likelihood -1.407555
[ Info: iteration 7, average log likelihood -1.407460
[ Info: iteration 8, average log likelihood -1.407366
[ Info: iteration 9, average log likelihood -1.407281
[ Info: iteration 10, average log likelihood -1.407207
[ Info: iteration 11, average log likelihood -1.407144
[ Info: iteration 12, average log likelihood -1.407095
[ Info: iteration 13, average log likelihood -1.407059
[ Info: iteration 14, average log likelihood -1.407033
[ Info: iteration 15, average log likelihood -1.407015
[ Info: iteration 16, average log likelihood -1.407003
[ Info: iteration 17, average log likelihood -1.406994
[ Info: iteration 18, average log likelihood -1.406988
[ Info: iteration 19, average log likelihood -1.406983
[ Info: iteration 20, average log likelihood -1.406979
[ Info: iteration 21, average log likelihood -1.406975
[ Info: iteration 22, average log likelihood -1.406971
[ Info: iteration 23, average log likelihood -1.406968
[ Info: iteration 24, average log likelihood -1.406965
[ Info: iteration 25, average log likelihood -1.406962
[ Info: iteration 26, average log likelihood -1.406960
[ Info: iteration 27, average log likelihood -1.406957
[ Info: iteration 28, average log likelihood -1.406955
[ Info: iteration 29, average log likelihood -1.406953
[ Info: iteration 30, average log likelihood -1.406950
[ Info: iteration 31, average log likelihood -1.406948
[ Info: iteration 32, average log likelihood -1.406946
[ Info: iteration 33, average log likelihood -1.406944
[ Info: iteration 34, average log likelihood -1.406943
[ Info: iteration 35, average log likelihood -1.406941
[ Info: iteration 36, average log likelihood -1.406939
[ Info: iteration 37, average log likelihood -1.406937
[ Info: iteration 38, average log likelihood -1.406936
[ Info: iteration 39, average log likelihood -1.406934
[ Info: iteration 40, average log likelihood -1.406933
[ Info: iteration 41, average log likelihood -1.406931
[ Info: iteration 42, average log likelihood -1.406930
[ Info: iteration 43, average log likelihood -1.406928
[ Info: iteration 44, average log likelihood -1.406927
[ Info: iteration 45, average log likelihood -1.406926
[ Info: iteration 46, average log likelihood -1.406924
[ Info: iteration 47, average log likelihood -1.406923
[ Info: iteration 48, average log likelihood -1.406922
[ Info: iteration 49, average log likelihood -1.406920
[ Info: iteration 50, average log likelihood -1.406919
┌ Info: EM with 100000 data points 50 iterations avll -1.406919
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4079338204474956
│     -1.4078608495012337
│      ⋮                 
└     -1.4069190420992306
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406928
[ Info: iteration 2, average log likelihood -1.406859
[ Info: iteration 3, average log likelihood -1.406789
[ Info: iteration 4, average log likelihood -1.406702
[ Info: iteration 5, average log likelihood -1.406589
[ Info: iteration 6, average log likelihood -1.406450
[ Info: iteration 7, average log likelihood -1.406296
[ Info: iteration 8, average log likelihood -1.406142
[ Info: iteration 9, average log likelihood -1.406006
[ Info: iteration 10, average log likelihood -1.405895
[ Info: iteration 11, average log likelihood -1.405809
[ Info: iteration 12, average log likelihood -1.405742
[ Info: iteration 13, average log likelihood -1.405690
[ Info: iteration 14, average log likelihood -1.405648
[ Info: iteration 15, average log likelihood -1.405614
[ Info: iteration 16, average log likelihood -1.405586
[ Info: iteration 17, average log likelihood -1.405563
[ Info: iteration 18, average log likelihood -1.405544
[ Info: iteration 19, average log likelihood -1.405528
[ Info: iteration 20, average log likelihood -1.405514
[ Info: iteration 21, average log likelihood -1.405502
[ Info: iteration 22, average log likelihood -1.405491
[ Info: iteration 23, average log likelihood -1.405481
[ Info: iteration 24, average log likelihood -1.405472
[ Info: iteration 25, average log likelihood -1.405462
[ Info: iteration 26, average log likelihood -1.405453
[ Info: iteration 27, average log likelihood -1.405444
[ Info: iteration 28, average log likelihood -1.405435
[ Info: iteration 29, average log likelihood -1.405426
[ Info: iteration 30, average log likelihood -1.405417
[ Info: iteration 31, average log likelihood -1.405408
[ Info: iteration 32, average log likelihood -1.405399
[ Info: iteration 33, average log likelihood -1.405389
[ Info: iteration 34, average log likelihood -1.405380
[ Info: iteration 35, average log likelihood -1.405370
[ Info: iteration 36, average log likelihood -1.405359
[ Info: iteration 37, average log likelihood -1.405349
[ Info: iteration 38, average log likelihood -1.405338
[ Info: iteration 39, average log likelihood -1.405328
[ Info: iteration 40, average log likelihood -1.405316
[ Info: iteration 41, average log likelihood -1.405305
[ Info: iteration 42, average log likelihood -1.405294
[ Info: iteration 43, average log likelihood -1.405282
[ Info: iteration 44, average log likelihood -1.405270
[ Info: iteration 45, average log likelihood -1.405258
[ Info: iteration 46, average log likelihood -1.405246
[ Info: iteration 47, average log likelihood -1.405234
[ Info: iteration 48, average log likelihood -1.405222
[ Info: iteration 49, average log likelihood -1.405211
[ Info: iteration 50, average log likelihood -1.405199
┌ Info: EM with 100000 data points 50 iterations avll -1.405199
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4069283581152057
│     -1.4068587796197183
│      ⋮                 
└     -1.4051988379611655
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405195
[ Info: iteration 2, average log likelihood -1.405136
[ Info: iteration 3, average log likelihood -1.405083
[ Info: iteration 4, average log likelihood -1.405024
[ Info: iteration 5, average log likelihood -1.404954
[ Info: iteration 6, average log likelihood -1.404871
[ Info: iteration 7, average log likelihood -1.404774
[ Info: iteration 8, average log likelihood -1.404666
[ Info: iteration 9, average log likelihood -1.404551
[ Info: iteration 10, average log likelihood -1.404435
[ Info: iteration 11, average log likelihood -1.404323
[ Info: iteration 12, average log likelihood -1.404217
[ Info: iteration 13, average log likelihood -1.404121
[ Info: iteration 14, average log likelihood -1.404036
[ Info: iteration 15, average log likelihood -1.403960
[ Info: iteration 16, average log likelihood -1.403894
[ Info: iteration 17, average log likelihood -1.403836
[ Info: iteration 18, average log likelihood -1.403785
[ Info: iteration 19, average log likelihood -1.403740
[ Info: iteration 20, average log likelihood -1.403700
[ Info: iteration 21, average log likelihood -1.403664
[ Info: iteration 22, average log likelihood -1.403630
[ Info: iteration 23, average log likelihood -1.403599
[ Info: iteration 24, average log likelihood -1.403570
[ Info: iteration 25, average log likelihood -1.403542
[ Info: iteration 26, average log likelihood -1.403515
[ Info: iteration 27, average log likelihood -1.403490
[ Info: iteration 28, average log likelihood -1.403465
[ Info: iteration 29, average log likelihood -1.403441
[ Info: iteration 30, average log likelihood -1.403417
[ Info: iteration 31, average log likelihood -1.403395
[ Info: iteration 32, average log likelihood -1.403373
[ Info: iteration 33, average log likelihood -1.403351
[ Info: iteration 34, average log likelihood -1.403331
[ Info: iteration 35, average log likelihood -1.403311
[ Info: iteration 36, average log likelihood -1.403291
[ Info: iteration 37, average log likelihood -1.403272
[ Info: iteration 38, average log likelihood -1.403254
[ Info: iteration 39, average log likelihood -1.403237
[ Info: iteration 40, average log likelihood -1.403220
[ Info: iteration 41, average log likelihood -1.403203
[ Info: iteration 42, average log likelihood -1.403188
[ Info: iteration 43, average log likelihood -1.403173
[ Info: iteration 44, average log likelihood -1.403158
[ Info: iteration 45, average log likelihood -1.403145
[ Info: iteration 46, average log likelihood -1.403131
[ Info: iteration 47, average log likelihood -1.403119
[ Info: iteration 48, average log likelihood -1.403107
[ Info: iteration 49, average log likelihood -1.403095
[ Info: iteration 50, average log likelihood -1.403084
┌ Info: EM with 100000 data points 50 iterations avll -1.403084
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4051953831152002
│     -1.405136069165869 
│      ⋮                 
└     -1.403083989663813 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403082
[ Info: iteration 2, average log likelihood -1.403019
[ Info: iteration 3, average log likelihood -1.402961
[ Info: iteration 4, average log likelihood -1.402894
[ Info: iteration 5, average log likelihood -1.402812
[ Info: iteration 6, average log likelihood -1.402711
[ Info: iteration 7, average log likelihood -1.402590
[ Info: iteration 8, average log likelihood -1.402450
[ Info: iteration 9, average log likelihood -1.402300
[ Info: iteration 10, average log likelihood -1.402147
[ Info: iteration 11, average log likelihood -1.401999
[ Info: iteration 12, average log likelihood -1.401862
[ Info: iteration 13, average log likelihood -1.401737
[ Info: iteration 14, average log likelihood -1.401626
[ Info: iteration 15, average log likelihood -1.401528
[ Info: iteration 16, average log likelihood -1.401441
[ Info: iteration 17, average log likelihood -1.401365
[ Info: iteration 18, average log likelihood -1.401298
[ Info: iteration 19, average log likelihood -1.401238
[ Info: iteration 20, average log likelihood -1.401184
[ Info: iteration 21, average log likelihood -1.401136
[ Info: iteration 22, average log likelihood -1.401091
[ Info: iteration 23, average log likelihood -1.401051
[ Info: iteration 24, average log likelihood -1.401013
[ Info: iteration 25, average log likelihood -1.400978
[ Info: iteration 26, average log likelihood -1.400945
[ Info: iteration 27, average log likelihood -1.400914
[ Info: iteration 28, average log likelihood -1.400885
[ Info: iteration 29, average log likelihood -1.400858
[ Info: iteration 30, average log likelihood -1.400831
[ Info: iteration 31, average log likelihood -1.400806
[ Info: iteration 32, average log likelihood -1.400782
[ Info: iteration 33, average log likelihood -1.400759
[ Info: iteration 34, average log likelihood -1.400738
[ Info: iteration 35, average log likelihood -1.400717
[ Info: iteration 36, average log likelihood -1.400696
[ Info: iteration 37, average log likelihood -1.400677
[ Info: iteration 38, average log likelihood -1.400658
[ Info: iteration 39, average log likelihood -1.400640
[ Info: iteration 40, average log likelihood -1.400623
[ Info: iteration 41, average log likelihood -1.400606
[ Info: iteration 42, average log likelihood -1.400590
[ Info: iteration 43, average log likelihood -1.400574
[ Info: iteration 44, average log likelihood -1.400558
[ Info: iteration 45, average log likelihood -1.400543
[ Info: iteration 46, average log likelihood -1.400528
[ Info: iteration 47, average log likelihood -1.400514
[ Info: iteration 48, average log likelihood -1.400499
[ Info: iteration 49, average log likelihood -1.400485
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.400471
┌ Info: EM with 100000 data points 50 iterations avll -1.400471
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4030822923036246
│     -1.403019445466059 
│      ⋮                 
└     -1.4004714890291747
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4134903069945897
│     -1.4135088912426967
│     -1.4134339410783308
│     -1.4133766894329742
│      ⋮                 
│     -1.4004994606008536
│     -1.4004853679807254
└     -1.4004714890291747
 -0.078532    0.275102    -0.38765      0.337356     0.0695535     0.724294    0.126338    -0.513261   -0.375822     0.421809     0.387093   -0.513354     -0.255283    0.257829     0.572495     0.0484772  -0.291327   -0.114842    -0.23903    -0.257843    -0.281616    -0.397101   -0.0801847  -0.464494   -0.244713    -0.387387  
 -0.130498    0.193859    -0.177211     0.27861      0.381334      0.157601   -0.463636     0.142836   -0.193324    -0.473741     0.320823    0.0660054    -0.288472    0.0977916    0.849338     0.656497   -0.259142   -0.138977     0.0647468  -0.689576    -0.322412    -0.478793   -0.467892    0.275187    0.00439064  -0.759477  
 -0.0802036  -0.506204     0.223887     0.147197    -0.0385864    -0.216707   -0.134787     0.286466   -0.0259549    0.38075      0.324355   -0.217579      0.302093   -0.566688     0.191137     0.446622    0.904725   -0.00234775   0.10651     0.381144    -0.294018    -0.389845    0.1144     -0.0698252  -0.310493    -0.316136  
 -0.408639   -0.193914     0.152417     0.00416283   0.0928549     0.102692   -0.358373     0.792639   -0.104964     0.435783     0.284421    0.0137595     0.596712    0.00199377   0.559168     0.230787    0.162091   -0.109888     0.279827    0.25316     -0.116069    -0.557591    0.365988   -0.249919    0.601022     0.503609  
 -0.0745829   0.292546     0.312551    -0.333202    -0.0758575     0.469976   -0.367104    -0.389483   -0.125818    -0.168989    -0.831619   -0.237363      0.12363    -0.356385     0.911042     0.171069    0.950086    0.425937    -0.718728   -0.403738    -0.133587    -0.586187    0.362772   -0.559971   -0.41421     -0.132847  
  0.294502    0.284026     0.00104829   0.190831     0.3591        0.127762   -0.00512555  -0.528091   -0.133704    -0.12411     -0.943489   -0.155563      0.819974   -0.53671     -0.0867199    0.0539042   0.614682   -0.181036     0.112216    0.154479    -0.138407    -0.45384    -0.0720942  -0.0743195   0.0356437   -0.313562  
  0.145146   -0.568781     0.325477    -0.52892      0.757706     -0.0563634  -0.0681415    0.148696    0.0467839   -0.148841     0.0406149   0.218157     -0.13688    -0.525153    -0.212433     0.114619    0.0270728   0.0201817   -0.194026    0.236351    -0.235788    -0.392133   -0.654064    0.404719   -0.430917    -0.256821  
  0.0415576   0.534376     0.148443    -0.63858      0.458988     -0.0834985  -0.370249    -0.324333   -0.356293    -0.106097    -0.172677   -0.0639051     0.444796   -0.385913    -0.0437792   -0.531775   -0.107588    0.264328    -0.471759   -0.150449     0.331802     0.216588   -0.472546    0.393078    0.298129    -0.235573  
  0.0344399   0.0284678   -0.358309     0.718039    -0.248482      0.092078    0.534208    -0.12165    -0.397518    -0.191947     0.20803    -0.192209     -0.123444    0.174342    -0.632408    -0.161446   -0.187811    0.0981146   -0.434949    0.131864    -0.0136677   -0.577319   -0.437498   -0.287817    0.0931135   -0.0180899 
  0.200383    0.193458    -0.41468      0.222049    -0.573012     -0.0830876   0.066496    -0.0522267  -0.368338    -0.154217    -0.0309785  -0.313326     -0.149255   -0.277739     0.141451    -0.359104    0.508085    0.0129607   -0.800398    0.603862    -0.558891    -0.215546   -0.705094    0.421423    0.234553     0.134438  
  0.529706    0.141773    -0.361562    -0.106673    -0.104591     -0.0967765   0.386058    -0.531009    0.325511    -0.269303    -0.263243   -0.56681      -0.664304    0.100962    -0.330853     0.288532    0.0124462   0.0456899   -0.664265   -0.0182246    0.252984     0.553316    0.0369094   0.230401   -0.514389    -0.284767  
  0.0695042   0.162008    -0.245837    -0.170224    -0.266176     -0.0439039   0.360128    -0.142417    0.393479    -0.0819242   -0.0864088  -0.0768044    -0.140652    0.402318    -0.372656    -0.692448   -0.708969    0.491113    -0.178053   -0.0503046    0.193243     0.427478   -0.0218558  -0.21641     0.28256      0.506613  
 -0.0494437   0.0346957    0.17069     -0.0164283    0.138131     -0.0206505  -0.101864    -0.156592    0.00958035  -0.408484    -0.108401   -0.140303     -0.132861    0.0781757   -0.206596     0.180216   -0.0217072   0.179763    -0.0333773   0.106691    -0.108332     0.137457    0.0690349  -0.106259    0.199147    -0.17773   
 -0.0625841   0.0769501   -0.235141    -0.175405    -0.159079     -0.350084   -0.166619     0.0697425   0.436703     0.360717     0.144539   -0.251451     -0.0991924   0.0650235    0.287815     0.216941   -0.145865    0.11833      0.135045    0.031233    -0.00447323   0.062718    0.177658    0.105805    0.0959735    0.0821225 
  0.0688741  -0.165433     0.324421     0.120861    -0.0970133     0.0971517  -0.0612835    0.181327   -0.296047     0.198247     0.202211    0.25648       0.0709994   0.0611558    0.0699913   -0.0926427   0.083659   -0.359198     0.0102899   0.00721503   0.0984551   -0.072652    0.141945   -0.0400417  -0.0773769    0.0201964 
  0.0834458   0.1845      -0.396048     0.131056     0.032974      0.24912     0.0647226   -0.051355   -0.0371298    0.00725247  -0.0311447   0.000932662   0.0901031  -0.0735116    0.123408    -0.169173    0.143492   -0.205515     0.0970966  -0.28573      0.0594178   -0.234601   -0.141363    0.123904   -0.17022      0.17094   
  0.202959    0.0927653    0.0797223   -0.322191    -0.0961514    -0.589944   -0.205216     0.363463    0.234842    -0.718121    -0.115374    0.470061     -0.269602    0.411771     0.00174025   0.646744    0.134871   -0.033263     0.295269   -0.230397     0.140367     0.573271    0.54043     0.0822338  -0.1335      -0.072792  
  0.0175083   0.239307     0.143947    -0.198148    -0.362089     -0.663883   -0.242831    -0.331246   -0.0724064   -0.225841     0.415171    0.201958     -0.523596   -0.220543     0.489407     0.528429    0.19437    -0.423117    -0.519567   -0.0146166   -0.152185     0.24972    -0.338296   -0.181646   -0.122632     0.522926  
 -0.350668    0.0389752    0.540307    -0.422221     0.508723     -0.354597   -0.374042    -0.0187018   0.309256     0.564483     0.0752411   0.349504      0.443593   -0.054305     0.35031     -0.261122   -0.0789506  -0.0978796    0.73774    -0.299062     0.30418      0.617001    0.733337    0.184992    0.097914    -0.247156  
 -0.0989008  -0.257853    -0.109236    -0.0341861   -0.0361261    -0.416696    0.021192     0.431978   -0.191506     0.380164     0.880879    0.276745     -0.180715    0.282107    -0.410035    -0.168433   -0.761008   -0.350866     0.36159     0.617676     0.140929     0.325413   -0.0966348   0.508417    0.437185     0.163522  
 -0.194428   -0.1223      -0.0228162   -0.0834335    0.223916     -0.249093   -0.610993    -0.354918    0.449842     0.140277     0.0282876  -0.537772     -0.332242   -0.0279204    0.262208     0.262354   -0.401442    0.571103     0.241756    0.466599    -0.762739     0.168025   -0.0656096  -0.0852902   0.297652    -0.275228  
 -0.338586   -0.423772     0.470583    -0.394858     0.217362      1.04401    -0.662499    -0.109891   -0.440226     0.226081    -0.148731   -0.330986      0.197643    0.100579    -0.216957    -0.461146   -0.18089     0.263545    -0.230393    0.34288     -0.209413    -0.298877    0.0579157  -0.0649931  -0.00740424  -0.0679446 
  0.253411    0.0946823   -0.110565    -0.508872    -0.000274669  -0.637509   -0.191091     0.0298918  -0.00828312   0.509124    -0.229116    0.614314      0.126434    0.51075      0.150647    -0.413775   -0.5898      0.204467    -0.218592   -0.0434192   -0.723666    -0.68694    -0.974147    0.222149    0.311944     0.336459  
 -0.489996   -0.169114     0.494767    -0.16872     -0.00512633   -0.36272     0.181396    -0.376079    0.215137    -0.433847    -0.290373    0.722941     -0.156463    0.167733    -0.41175     -0.258412   -0.822005   -0.00979198  -0.503955   -0.342064     0.699315    -0.377751   -0.234384    0.143066    0.614506    -0.0448204 
  0.0419162   0.119656    -0.0640862    0.10585      0.0196174    -0.157544    0.0320633   -0.163334    0.0667693   -0.0546702    0.0024663  -0.137702      0.030548   -0.241331     0.00997073   0.102012    0.174301   -0.0260031   -0.141648    0.00536396   0.0085009   -0.0461744  -0.105978    0.0437392   0.00485472   0.00325899
  0.841835   -0.0501155   -0.134323    -0.121208    -0.74569      -0.174599    0.489312     0.145044   -0.090832     0.489786    -0.22746     0.348202      0.412879    0.189924    -0.320979    -0.0183545   0.471126   -0.421429    -0.365223    0.0464253    0.65704     -0.0259777   0.503355   -0.0308184  -0.0630524    0.687642  
  0.192384    0.202356    -0.534481    -0.0166226   -0.0303651     0.780738    0.540698    -0.0634541  -0.329266     0.334897     0.347101   -0.0209807     0.304086    0.127683     0.0543355   -0.667868   -0.217601   -0.661019     0.107456   -0.300046     0.345305    -0.114747   -0.174585    0.702594   -0.846506    -0.100821  
 -0.104107    0.339488    -0.232665     0.180573     0.321538      0.852752    0.425676     0.0854827  -0.0122235   -0.182139    -0.0883756  -0.248533      0.338512   -0.0933058    0.104256    -0.252921    0.809545   -0.389624     0.154598   -0.847454     0.634386     0.102362    0.476613   -0.501689   -0.460986     0.155034  
  0.389902   -1.08974      0.322856     0.349277     0.0853154     0.091982    0.0738588    0.127075   -0.260455    -0.0574975    0.387932    0.341198     -0.322134    1.12289      0.244555    -0.109489    0.0381844  -0.342433     0.450389   -0.30944     -0.0531827    0.21606    -0.0542926  -0.557773   -0.205673     0.0103675 
  0.0517613   0.00899566  -0.168642     0.949643    -0.446873     -0.0198989   0.29241      0.0705852   0.306642    -0.166271     0.456952   -0.4366       -0.610635    0.138957    -0.113131     0.615545    0.238354   -0.223455     0.6263     -0.0121314    0.148821     0.411436    0.657263   -0.362279   -0.0715865   -0.0459357 
 -0.264391   -0.257074    -0.119537     0.494761    -0.0433367     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.434748    0.190863     0.358361    0.130412    -0.167707    -0.749651   -0.0549599    -0.0598868   0.34759     -0.440228    -0.344978    0.0695275   0.493444     0.628419    0.1151      -0.060307    -0.287806    0.443539    0.248253    0.108224    -0.660473  
  0.303724   -0.437049     0.0262744    0.104681    -0.242869      0.149194    0.202863     0.0684893   0.066497    -0.170825    -0.43947     0.104252      0.571923   -0.133338    -0.511498    -0.522585    0.412665    0.0992487    0.332091    0.392718     0.393846     0.513886    0.425118    0.124432    0.050371     0.274125  [ Info: iteration 1, average log likelihood -1.400458
[ Info: iteration 2, average log likelihood -1.400444
[ Info: iteration 3, average log likelihood -1.400431
[ Info: iteration 4, average log likelihood -1.400418
[ Info: iteration 5, average log likelihood -1.400405
[ Info: iteration 6, average log likelihood -1.400392
[ Info: iteration 7, average log likelihood -1.400380
[ Info: iteration 8, average log likelihood -1.400368
[ Info: iteration 9, average log likelihood -1.400356
[ Info: iteration 10, average log likelihood -1.400344
┌ Info: EM with 100000 data points 10 iterations avll -1.400344
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.009058e+05
      1       6.848009e+05      -2.161050e+05 |       32
      2       6.749015e+05      -9.899318e+03 |       32
      3       6.707868e+05      -4.114767e+03 |       32
      4       6.684629e+05      -2.323882e+03 |       32
      5       6.668396e+05      -1.623309e+03 |       32
      6       6.656172e+05      -1.222408e+03 |       32
      7       6.647630e+05      -8.541908e+02 |       32
      8       6.641122e+05      -6.507654e+02 |       32
      9       6.635876e+05      -5.246484e+02 |       32
     10       6.631648e+05      -4.227340e+02 |       32
     11       6.628175e+05      -3.473371e+02 |       32
     12       6.625293e+05      -2.881501e+02 |       32
     13       6.622605e+05      -2.688053e+02 |       32
     14       6.619958e+05      -2.647519e+02 |       32
     15       6.617466e+05      -2.491577e+02 |       32
     16       6.615085e+05      -2.381059e+02 |       32
     17       6.612956e+05      -2.129391e+02 |       32
     18       6.611152e+05      -1.803860e+02 |       32
     19       6.609510e+05      -1.641852e+02 |       32
     20       6.608006e+05      -1.504307e+02 |       32
     21       6.606594e+05      -1.411719e+02 |       32
     22       6.605141e+05      -1.452920e+02 |       32
     23       6.603827e+05      -1.313859e+02 |       32
     24       6.602648e+05      -1.179318e+02 |       32
     25       6.601493e+05      -1.155412e+02 |       32
     26       6.600399e+05      -1.094079e+02 |       32
     27       6.599383e+05      -1.015114e+02 |       32
     28       6.598353e+05      -1.030018e+02 |       32
     29       6.597312e+05      -1.041080e+02 |       32
     30       6.596255e+05      -1.057149e+02 |       32
     31       6.595239e+05      -1.015812e+02 |       32
     32       6.594297e+05      -9.420178e+01 |       32
     33       6.593360e+05      -9.376187e+01 |       32
     34       6.592425e+05      -9.349192e+01 |       32
     35       6.591513e+05      -9.122459e+01 |       32
     36       6.590662e+05      -8.505040e+01 |       32
     37       6.589842e+05      -8.203411e+01 |       32
     38       6.589133e+05      -7.082451e+01 |       32
     39       6.588485e+05      -6.482490e+01 |       32
     40       6.587808e+05      -6.771468e+01 |       32
     41       6.587117e+05      -6.910864e+01 |       32
     42       6.586385e+05      -7.319391e+01 |       32
     43       6.585662e+05      -7.234982e+01 |       32
     44       6.585102e+05      -5.591696e+01 |       32
     45       6.584625e+05      -4.769906e+01 |       32
     46       6.584222e+05      -4.028793e+01 |       32
     47       6.583872e+05      -3.505706e+01 |       32
     48       6.583527e+05      -3.446760e+01 |       32
     49       6.583192e+05      -3.350657e+01 |       32
     50       6.582889e+05      -3.035037e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 658288.8672942099)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412347
[ Info: iteration 2, average log likelihood -1.407316
[ Info: iteration 3, average log likelihood -1.405920
[ Info: iteration 4, average log likelihood -1.404815
[ Info: iteration 5, average log likelihood -1.403625
[ Info: iteration 6, average log likelihood -1.402580
[ Info: iteration 7, average log likelihood -1.401926
[ Info: iteration 8, average log likelihood -1.401589
[ Info: iteration 9, average log likelihood -1.401406
[ Info: iteration 10, average log likelihood -1.401288
[ Info: iteration 11, average log likelihood -1.401200
[ Info: iteration 12, average log likelihood -1.401130
[ Info: iteration 13, average log likelihood -1.401070
[ Info: iteration 14, average log likelihood -1.401018
[ Info: iteration 15, average log likelihood -1.400971
[ Info: iteration 16, average log likelihood -1.400928
[ Info: iteration 17, average log likelihood -1.400889
[ Info: iteration 18, average log likelihood -1.400853
[ Info: iteration 19, average log likelihood -1.400819
[ Info: iteration 20, average log likelihood -1.400788
[ Info: iteration 21, average log likelihood -1.400758
[ Info: iteration 22, average log likelihood -1.400730
[ Info: iteration 23, average log likelihood -1.400704
[ Info: iteration 24, average log likelihood -1.400679
[ Info: iteration 25, average log likelihood -1.400655
[ Info: iteration 26, average log likelihood -1.400633
[ Info: iteration 27, average log likelihood -1.400611
[ Info: iteration 28, average log likelihood -1.400591
[ Info: iteration 29, average log likelihood -1.400571
[ Info: iteration 30, average log likelihood -1.400553
[ Info: iteration 31, average log likelihood -1.400535
[ Info: iteration 32, average log likelihood -1.400517
[ Info: iteration 33, average log likelihood -1.400501
[ Info: iteration 34, average log likelihood -1.400484
[ Info: iteration 35, average log likelihood -1.400469
[ Info: iteration 36, average log likelihood -1.400454
[ Info: iteration 37, average log likelihood -1.400439
[ Info: iteration 38, average log likelihood -1.400425
[ Info: iteration 39, average log likelihood -1.400411
[ Info: iteration 40, average log likelihood -1.400398
[ Info: iteration 41, average log likelihood -1.400385
[ Info: iteration 42, average log likelihood -1.400373
[ Info: iteration 43, average log likelihood -1.400361
[ Info: iteration 44, average log likelihood -1.400349
[ Info: iteration 45, average log likelihood -1.400338
[ Info: iteration 46, average log likelihood -1.400327
[ Info: iteration 47, average log likelihood -1.400316
[ Info: iteration 48, average log likelihood -1.400306
[ Info: iteration 49, average log likelihood -1.400296
[ Info: iteration 50, average log likelihood -1.400286
32×26 ┌ Info: EM with 100000 data points 50 iterations avll -1.400286
└ 59.0 data points per parameter
Array{Float64,2}:
 -0.0633471   0.018866    -0.0326136    0.121222   -0.00270476   0.0442194   -0.0240259   0.0417276  -0.0643824    0.0212499   0.212575    -0.0984949  -0.098975    0.0739198   0.0972475    0.133836    0.0389104  -0.0696919   -0.0125962   -0.0954879  -0.0104723  -0.137152   -0.00944878  -0.0448314     0.0452835  -0.0116625
 -0.400987    0.699339    -0.60017     -0.226408   -0.20162     -0.359001    -0.0998079   0.429207    0.526557     0.500333    0.172711    -0.548613    0.265283   -0.314462    0.220807     0.342574   -0.421338    0.00359819   0.122386    -0.0471093   0.259312   -0.469052    0.433302     0.441262      0.235005    0.197217 
 -0.387395   -0.01548     -0.162721     0.241348    0.692338     0.110186    -0.511391   -0.268888    0.179307    -0.149199    0.340263    -0.393676   -0.372797   -0.258302    0.272139     0.373548   -0.410185    0.257839     0.038997     0.0368412  -0.730541   -0.545948   -0.658141     0.083586      0.203248   -0.575333 
  0.0553334   0.587988    -0.42953      0.225273    0.073418     0.187275     0.301594   -0.520794   -0.0470555   -0.217553   -0.179589     0.213647    0.184141   -0.29466     0.104448    -0.301847    0.248712   -0.387426    -0.00577783  -0.346887    0.177993   -0.226086   -0.351919     0.142977     -0.296248    0.136393 
 -0.155013   -0.225132     0.367322     0.287255   -0.212391    -0.130852     0.0799138   0.440849   -0.197643     0.186065    0.30504      0.513535    0.572853   -0.146441    0.256234     0.198101    0.573501   -0.69655     -0.0540728   -0.175329    0.212399   -0.204552    0.209363    -0.385021      0.250547    0.442047 
 -0.0621928   0.190898     0.0446325   -0.295913   -0.00460871  -0.380204    -0.143527   -0.515625    0.34874     -0.0459414  -0.0368455   -0.19655    -0.23509     0.266453    0.0411977    0.0422079  -0.452974    0.290159     0.00773388  -0.103781    0.0659154   0.479148    0.33064     -0.281296      0.341218    0.0166092
  0.417379   -0.136281     0.0388975    0.178411   -0.851873    -0.304681    -0.360924   -0.327307   -0.193922     0.515317    0.696858     0.0750171  -0.209496    0.0815521   0.242838    -0.0173194   0.394175    0.199499    -0.917659     0.752168   -0.383295    0.218817   -0.511631     0.107999      0.58813     0.267131 
 -0.0328647   0.00725695  -0.135549    -0.295717    0.728076     0.729381    -0.0995027   0.0578756  -0.357052     0.869333   -0.0110554   -0.168057    0.440045    0.401734    0.170039    -0.634838    0.318992   -0.167529     0.301344    -0.328445    0.231341   -0.10712     0.151125    -0.0581112    -0.161036   -0.0717961
 -0.0697214  -0.385299     0.32656     -0.422594   -0.260197    -0.989889     0.575991   -0.294817    0.311126     0.203762   -0.0652792    0.823159   -0.0434591   0.374748   -0.554029    -0.479812   -0.901443    0.0990166   -0.636986    -0.445237    0.10862    -0.505451   -0.517421     0.0555117     0.544285    0.327503 
 -0.15125    -0.29087      0.294277    -0.148734    0.040911     0.357509    -0.254458   -0.252338   -0.00822137   0.22053    -0.193831    -0.37295    -0.017222    0.0325863  -0.157335    -0.240857   -0.221331    0.246097    -0.106718     0.408725   -0.229266   -0.0973303   0.00205478  -0.0141362     0.0872636  -0.0961477
  0.0851623   0.319022    -0.139175     0.245442    0.15558      0.00537815   0.293215   -0.0659731   0.0726119   -0.443456   -0.0305272   -0.0291796   0.142242   -0.128253   -0.122376     0.319075    0.490882   -0.262481     0.37523     -0.453134    0.470722    0.198776    0.406965    -0.227415     -0.29292    -0.0422177
  0.199014    0.0281696   -0.379869    -0.25397     0.122744     0.158844    -0.508713    0.20162     0.492946    -0.160993   -0.0284313   -0.495726   -0.345052    0.059127    0.480395     0.4713      0.338427    0.16113      0.350709    -0.087651    0.0745406   0.751861    0.420863     0.429686     -0.128917   -0.0175218
  0.0979528   0.33991      0.236639    -0.0976637  -0.0595773    0.425318    -0.258548   -0.444179   -0.140486    -0.259951   -0.803731    -0.325355    0.243585   -0.408199    0.543034     0.242047    0.937677    0.228496    -0.501608    -0.272064   -0.186919   -0.512163    0.271101    -0.538498     -0.270874   -0.233812 
  0.0975752   0.100061    -0.515437     0.585125   -0.0203327    0.414558     0.549727   -0.0362887  -0.506251     0.23083     0.0177117   -0.435434    0.154423   -0.357757   -0.042004    -0.238544    0.297409   -0.300208    -0.344175     0.169331   -0.128698   -0.805226   -0.525226     0.226566     -0.178513   -0.130005 
  0.0831519  -0.185753    -0.127187     0.176086   -0.00833513   0.166497     0.191856   -0.2716     -0.0630307   -0.451216   -0.399058    -0.372834    0.12738    -0.10274    -0.549562    -0.39696     0.144155    0.327209    -0.207294     0.257141    0.107914    0.0573207  -0.195802     0.0597196     0.188549    0.051497 
  0.135169   -0.266772     0.409255    -0.544009    0.106384    -0.0918363   -0.347058   -0.351414   -0.017768     0.627661    0.410214    -0.520979   -0.0291207  -0.163126    0.428364     0.71124    -0.190535   -0.418998    -0.416246     0.447445   -0.263735   -0.16255    -0.00740939  -0.465835     -0.345667    0.18834  
  0.0150957  -0.353713    -0.223799     0.0869836   0.0661049   -0.211369     0.147844    0.568223   -0.0656422    0.299909    0.901426     0.22337    -0.207811    0.352406   -0.451035    -0.19987    -0.735766   -0.314909     0.493846     0.361489    0.184351    0.234948   -0.140748     0.251778      0.245704    0.245955 
  0.413223    0.153882    -0.26907      0.177216   -0.536559    -0.80723      0.300744   -0.268695    0.589934    -0.437386    0.0604337   -0.107768   -0.846189   -0.327358    0.063264     0.580513    0.288487   -0.437878    -0.324093     0.0478419  -0.0863025   0.36379    -0.0609286   -0.0515323    -0.362709    0.210308 
 -0.436965   -0.0686512    0.641108    -0.30962     0.378139    -0.124166    -0.303832   -0.107014    0.143848     0.15551    -0.00815213   0.338184    0.63441    -0.33217    -0.00869187  -0.422896   -0.132902    0.124067     0.707986     0.0759952   0.631963    0.650447    0.717893     0.364722      0.262324   -0.472371 
  0.0709172   0.136552     0.0244277   -0.675479    0.843716    -0.132717    -0.498741   -0.273085   -0.173253     0.123881   -0.39996      0.0572362   0.967616   -0.512272    0.0697589   -0.488067    0.120771    0.181769    -0.575631    -0.0538866   0.066098   -0.271034   -0.598639     0.391571      0.26488    -0.232165 
 -0.0785449  -0.70167      0.195468    -0.0214574  -0.132406    -0.28442     -0.085818    0.393431    0.0336818    0.391224    0.320046    -0.442653    0.409629   -0.674591    0.126169     0.434039    1.08541     0.391718     0.141695     0.437654   -0.237309   -0.350574    0.0694964   -0.000509612  -0.436444   -0.276859 
  0.219459    0.0931908    0.111007    -0.360067    0.385541    -0.140923     0.263549    0.0834984   0.0542678   -0.478735   -0.311608    -0.118753   -0.147786   -0.0133502  -0.564461     0.427945   -0.42677     0.374255    -0.240037     0.432369   -0.150113    0.0816517  -0.139914     0.366163     -0.127131   -0.68256  
  0.176961   -0.694385     0.541904    -0.254019    0.528544    -0.178874    -0.107562    0.127237   -0.271335    -0.454232    0.208468     0.633715   -0.395003    0.11635     0.0528316    0.239718    0.145966   -0.133595     0.0503238   -0.249556    0.118184   -0.0314739  -0.324825     0.131351     -0.388165   -0.0853951
 -0.508632   -0.0689626    0.286508    -0.0477721   0.26379     -0.034009    -0.819232    0.388218   -0.0503696    0.17515     0.022819     0.213421    0.0859873  -0.16673     0.634763     0.0609154   0.197667    0.0677864    0.445566     0.245663   -0.668804   -0.384034    0.141368    -0.0771837     0.158901    0.0489812
 -0.137009    0.809078    -0.00908396  -0.385067   -0.230581    -0.172988    -0.175534   -0.282098   -0.635103    -0.451024    0.0207551    0.107597   -0.484575   -0.0388006   0.233393    -0.258891   -0.270542    0.193261    -0.644411    -0.181025   -0.0778929   0.256243   -0.839045     0.286474     -0.0247909   0.140816 
  0.334531   -0.0897504    0.112885    -0.117882   -0.244933    -0.0505289   -0.0581104   0.159404   -0.0650195    0.187924   -0.155944     0.245093    0.26932    -0.174095   -0.0370415   -0.259241    0.145377   -0.241148     0.0080227    0.309946   -0.0556596   0.0434678   0.0537874    0.212332     -0.104221    0.0536675
  0.116747    0.0705303   -0.218391     0.440941   -0.0364661    0.536383    -0.0545375  -0.232646   -0.430181     0.0907211   0.496816    -0.172083   -0.476757    0.615164    0.689294     0.119275   -0.274533   -0.624172    -0.140168    -0.807517   -0.188031   -0.0878746  -0.0234835   -0.0530371    -0.348165   -0.501609 
  0.79703    -0.105861    -0.244344    -0.27141    -0.599912     0.169955     0.675036    0.028297   -0.0289145    0.182437   -0.363776     0.198443    0.27232     0.217045   -0.416444    -0.243841    0.540566   -0.239838    -0.390254    -0.114368    0.880858    0.51948     0.771392     0.119431     -0.386964    0.487496 
 -0.164611   -0.401771     0.0338974    0.878592   -0.166499     0.219834     0.222986    0.299427    0.189135    -0.0661291  -0.169216    -0.185115   -0.116213    0.330352   -0.27538      0.112909    0.382562    0.0852402    0.67767      0.160216   -0.0703444  -0.0889788   0.596624    -0.219583      0.0489598  -0.280756 
  0.261943    0.189207    -0.772005     0.551308   -0.687463     0.465898     0.624077   -0.371478   -0.124467    -0.0273412   0.245376    -0.436056   -0.117061    0.840834   -0.149808     0.0238845  -0.641909    0.391632    -0.319908     0.1558      0.0617578  -0.0477639   0.0786129   -0.742065     -0.300535   -0.0700122
  0.0700819  -0.0664686    0.256092    -0.221152   -0.211263    -0.946922    -0.659433    0.61045     0.137286     0.0218662   0.0728081    0.714899   -0.0432617   0.50062     0.465317     0.548377   -0.129281    0.0904826    0.459661     0.103147   -0.404495   -0.0336258   0.262431    -0.0490979     0.430805    0.191109 
 -0.0789465   0.0299125   -0.176542     0.102103   -0.224297     0.511668     0.102997    0.289942    0.274607    -0.322172   -0.672828     0.447006    0.0286392   0.509001   -0.296627    -0.913002   -0.511809    0.234942     0.346085    -0.282621    0.159844   -0.143018    0.0590313    0.326013      0.217809    0.0820446[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.400276
[ Info: iteration 2, average log likelihood -1.400267
[ Info: iteration 3, average log likelihood -1.400258
[ Info: iteration 4, average log likelihood -1.400249
[ Info: iteration 5, average log likelihood -1.400241
[ Info: iteration 6, average log likelihood -1.400232
[ Info: iteration 7, average log likelihood -1.400224
[ Info: iteration 8, average log likelihood -1.400216
[ Info: iteration 9, average log likelihood -1.400209
[ Info: iteration 10, average log likelihood -1.400201
┌ Info: EM with 100000 data points 10 iterations avll -1.400201
└ 59.0 data points per parameter
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
