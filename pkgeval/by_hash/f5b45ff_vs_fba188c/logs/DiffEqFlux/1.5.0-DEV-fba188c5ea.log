Julia Version 1.5.0-DEV.162
Commit fba188c5ea (2020-01-28 03:57 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Requires ──────────────────── v1.0.0
 Installed Arpack_jll ────────────────── v3.5.0+2
 Installed FixedPointNumbers ─────────── v0.6.1
 Installed CommonSubexpressions ──────── v0.2.0
 Installed DiffEqFlux ────────────────── v1.1.1
 Installed Tracker ───────────────────── v0.2.6
 Installed StaticArrays ──────────────── v0.12.1
 Installed NNlib ─────────────────────── v0.6.4
 Installed GenericSVD ────────────────── v0.2.2
 Installed ZygoteRules ───────────────── v0.2.0
 Installed SortingAlgorithms ─────────── v0.3.1
 Installed QuadGK ────────────────────── v2.3.1
 Installed Missings ──────────────────── v0.4.3
 Installed TableTraits ───────────────── v1.0.0
 Installed Parsers ───────────────────── v0.3.10
 Installed Sobol ─────────────────────── v1.3.0
 Installed Colors ────────────────────── v0.9.6
 Installed DiffEqCallbacks ───────────── v2.11.0
 Installed FFTW ──────────────────────── v1.2.0
 Installed JSON ──────────────────────── v0.21.0
 Installed MKL_jll ───────────────────── v2019.0.117+2
 Installed SimpleTraits ──────────────── v0.9.1
 Installed RecursiveArrayTools ───────── v2.0.4
 Installed FFTW_jll ──────────────────── v3.3.9+3
 Installed LatinHypercubeSampling ────── v1.4.0
 Installed ForwardDiff ───────────────── v0.10.9
 Installed LLVM ──────────────────────── v1.3.3
 Installed OrdinaryDiffEq ────────────── v5.28.1
 Installed TreeViews ─────────────────── v0.3.0
 Installed CUDAdrv ───────────────────── v5.0.1
 Installed FunctionWrappers ──────────── v1.0.0
 Installed ColorTypes ────────────────── v0.8.1
 Installed AbstractTrees ─────────────── v0.3.1
 Installed DiffEqBase ────────────────── v6.13.1
 Installed Parameters ────────────────── v0.12.0
 Installed PooledArrays ──────────────── v0.5.3
 Installed Zlib_jll ──────────────────── v1.2.11+8
 Installed OpenBLAS_jll ──────────────── v0.3.7+5
 Installed CategoricalArrays ─────────── v0.7.7
 Installed PDMats ────────────────────── v0.9.11
 Installed Compat ────────────────────── v2.2.0
 Installed StatsBase ─────────────────── v0.32.0
 Installed Flux ──────────────────────── v0.10.1
 Installed Juno ──────────────────────── v0.7.2
 Installed GLM ───────────────────────── v1.3.6
 Installed DataAPI ───────────────────── v1.1.0
 Installed SparseDiffTools ───────────── v1.3.3
 Installed RecipesBase ───────────────── v0.7.0
 Installed VertexSafeGraphs ──────────── v0.1.1
 Installed DataValueInterfaces ───────── v1.0.0
 Installed Media ─────────────────────── v0.5.0
 Installed BinaryProvider ────────────── v0.5.8
 Installed SpecialFunctions ──────────── v0.9.0
 Installed TranscodingStreams ────────── v0.9.5
 Installed FiniteDiff ────────────────── v2.1.0
 Installed AbstractFFTs ──────────────── v0.5.0
 Installed ExponentialUtilities ──────── v1.6.0
 Installed CEnum ─────────────────────── v0.2.0
 Installed Reexport ──────────────────── v0.2.0
 Installed InvertedIndices ───────────── v1.0.0
 Installed OpenSpecFun_jll ───────────── v0.5.3+1
 Installed DataStructures ────────────── v0.17.9
 Installed Distances ─────────────────── v0.8.2
 Installed Rmath ─────────────────────── v0.6.0
 Installed IRTools ───────────────────── v0.3.1
 Installed Tables ────────────────────── v0.2.11
 Installed Arpack ────────────────────── v0.4.0
 Installed DocStringExtensions ───────── v0.8.1
 Installed CUDAapi ───────────────────── v2.1.0
 Installed DataFrames ────────────────── v0.20.0
 Installed Inflate ───────────────────── v0.1.1
 Installed DiffRules ─────────────────── v1.0.0
 Installed ShiftedArrays ─────────────── v1.0.0
 Installed Adapt ─────────────────────── v1.0.0
 Installed CuArrays ──────────────────── v1.7.0
 Installed NaNMath ───────────────────── v0.3.3
 Installed Zygote ────────────────────── v0.4.6
 Installed ChainRulesCore ────────────── v0.6.1
 Installed ArnoldiMethod ─────────────── v0.0.4
 Installed Roots ─────────────────────── v0.8.4
 Installed FillArrays ────────────────── v0.8.4
 Installed Distributions ─────────────── v0.21.12
 Installed MacroTools ────────────────── v0.5.3
 Installed LineSearches ──────────────── v7.0.1
 Installed TimerOutputs ──────────────── v0.5.3
 Installed GPUArrays ─────────────────── v2.0.1
 Installed DiffEqSensitivity ─────────── v6.6.0
 Installed NLsolve ───────────────────── v4.3.0
 Installed RecursiveFactorization ────── v0.1.0
 Installed StatsFuns ─────────────────── v0.9.3
 Installed MuladdMacro ───────────────── v0.2.2
 Installed IterativeSolvers ──────────── v0.8.1
 Installed CUDAnative ────────────────── v2.8.1
 Installed OrderedCollections ────────── v1.1.0
 Installed CodecZlib ─────────────────── v0.6.0
 Installed LightGraphs ───────────────── v1.3.0
 Installed IteratorInterfaceExtensions ─ v1.0.0
 Installed NLSolversBase ─────────────── v7.6.0
 Installed IntelOpenMP_jll ───────────── v2018.0.3+0
 Installed ArrayInterface ────────────── v2.3.1
 Installed ZipFile ───────────────────── v0.9.1
 Installed QuasiMonteCarlo ───────────── v0.1.0
 Installed StatsModels ───────────────── v0.6.7
 Installed DiffResults ───────────────── v1.0.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [aae7a2af] + DiffEqFlux v1.1.1
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [1520ce14] + AbstractTrees v0.3.1
  [79e6a3ab] + Adapt v1.0.0
  [ec485272] + ArnoldiMethod v0.0.4
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [4fba245c] + ArrayInterface v2.3.1
  [b99e7846] + BinaryProvider v0.5.8
  [fa961155] + CEnum v0.2.0
  [3895d2a7] + CUDAapi v2.1.0
  [c5f51814] + CUDAdrv v5.0.1
  [be33ccc6] + CUDAnative v2.8.1
  [324d7699] + CategoricalArrays v0.7.7
  [d360d2e6] + ChainRulesCore v0.6.1
  [944b1d66] + CodecZlib v0.6.0
  [3da002f7] + ColorTypes v0.8.1
  [5ae59095] + Colors v0.9.6
  [bbf7d656] + CommonSubexpressions v0.2.0
  [34da2185] + Compat v2.2.0
  [3a865a2d] + CuArrays v1.7.0
  [9a962f9c] + DataAPI v1.1.0
  [a93c6f00] + DataFrames v0.20.0
  [864edb3b] + DataStructures v0.17.9
  [e2d170a0] + DataValueInterfaces v1.0.0
  [2b5f629d] + DiffEqBase v6.13.1
  [459566f4] + DiffEqCallbacks v2.11.0
  [aae7a2af] + DiffEqFlux v1.1.1
  [41bf760c] + DiffEqSensitivity v6.6.0
  [163ba53b] + DiffResults v1.0.2
  [b552c78f] + DiffRules v1.0.0
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.12
  [ffbed154] + DocStringExtensions v0.8.1
  [d4d017d3] + ExponentialUtilities v1.6.0
  [7a1cc6ca] + FFTW v1.2.0
  [f5851436] + FFTW_jll v3.3.9+3
  [1a297f60] + FillArrays v0.8.4
  [6a86dc24] + FiniteDiff v2.1.0
  [53c48c17] + FixedPointNumbers v0.6.1
  [587475ba] + Flux v0.10.1
  [f6369f11] + ForwardDiff v0.10.9
  [069b7b12] + FunctionWrappers v1.0.0
  [38e38edf] + GLM v1.3.6
  [0c68f7d7] + GPUArrays v2.0.1
  [01680d73] + GenericSVD v0.2.2
  [7869d1d1] + IRTools v0.3.1
  [d25df0c9] + Inflate v0.1.1
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [41ab1584] + InvertedIndices v1.0.0
  [42fd0dbc] + IterativeSolvers v0.8.1
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [e5e0dc1b] + Juno v0.7.2
  [929cbde3] + LLVM v1.3.3
  [a5e1c1ea] + LatinHypercubeSampling v1.4.0
  [093fc24a] + LightGraphs v1.3.0
  [d3d80556] + LineSearches v7.0.1
  [856f044c] + MKL_jll v2019.0.117+2
  [1914dd2f] + MacroTools v0.5.3
  [e89f7d12] + Media v0.5.0
  [e1d29d7a] + Missings v0.4.3
  [46d2c3a1] + MuladdMacro v0.2.2
  [d41bc354] + NLSolversBase v7.6.0
  [2774e3e8] + NLsolve v4.3.0
  [872c559c] + NNlib v0.6.4
  [77ba4419] + NaNMath v0.3.3
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [1dea7af3] + OrdinaryDiffEq v5.28.1
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.10
  [2dfb63ee] + PooledArrays v0.5.3
  [1fd47b50] + QuadGK v2.3.1
  [8a4e6c94] + QuasiMonteCarlo v0.1.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [731186ca] + RecursiveArrayTools v2.0.4
  [f2c3362d] + RecursiveFactorization v0.1.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.0
  [79098fc4] + Rmath v0.6.0
  [f2b01f46] + Roots v0.8.4
  [1277b4bf] + ShiftedArrays v1.0.0
  [699a6c99] + SimpleTraits v0.9.1
  [ed01d8cd] + Sobol v1.3.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [47a9eef4] + SparseDiffTools v1.3.3
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [3eaba693] + StatsModels v0.6.7
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [a759f4b9] + TimerOutputs v0.5.3
  [9f7883ad] + Tracker v0.2.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [a2a6695c] + TreeViews v0.3.0
  [19fa3120] + VertexSafeGraphs v0.1.1
  [a5390f91] + ZipFile v0.9.1
  [83775a58] + Zlib_jll v1.2.11+8
  [e88e6eb3] + Zygote v0.4.6
  [700de1a5] + ZygoteRules v0.2.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building NNlib ────→ `~/.julia/packages/NNlib/3krvM/deps/build.log`
  Updating `/tmp/jl_LAO5Xb/Project.toml`
 [no changes]
  Updating `/tmp/jl_LAO5Xb/Manifest.toml`
 [no changes]
  Building FFTW ─────→ `~/.julia/packages/FFTW/qqcBj/deps/build.log`
  Updating `/tmp/jl_7ngH0F/Project.toml`
 [no changes]
  Updating `/tmp/jl_7ngH0F/Manifest.toml`
 [no changes]
  Building Rmath ────→ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_vnSQic/Project.toml`
 [no changes]
  Updating `/tmp/jl_vnSQic/Manifest.toml`
 [no changes]
  Building CodecZlib → `~/.julia/packages/CodecZlib/5t9zO/deps/build.log`
  Updating `/tmp/jl_l74ZOY/Project.toml`
 [no changes]
  Updating `/tmp/jl_l74ZOY/Manifest.toml`
 [no changes]
   Testing DiffEqFlux
 Installed ResettableStacks ─── v1.0.0
 Installed RandomNumbers ────── v1.4.0
 Installed SafeTestsets ─────── v0.0.1
 Installed DiffEqNoiseProcess ─ v3.8.0
 Installed DelayDiffEq ──────── v5.20.0
 Installed StochasticDiffEq ─── v6.18.0
  Updating `/tmp/jl_3ZHCz9/Project.toml`
  [bcd4f6db] + DelayDiffEq v5.20.0
  [1bc83da4] + SafeTestsets v0.0.1
  [789caeaf] + StochasticDiffEq v6.18.0
  Updating `/tmp/jl_3ZHCz9/Manifest.toml`
  [bcd4f6db] + DelayDiffEq v5.20.0
  [77a26b50] + DiffEqNoiseProcess v3.8.0
  [e6cf234a] + RandomNumbers v1.4.0
  [ae5879a3] + ResettableStacks v1.0.0
  [1bc83da4] + SafeTestsets v0.0.1
  [789caeaf] + StochasticDiffEq v6.18.0
Running sandbox
Status `/tmp/jl_3ZHCz9/Project.toml`
  [79e6a3ab] Adapt v1.0.0
  [bcd4f6db] DelayDiffEq v5.20.0
  [2b5f629d] DiffEqBase v6.13.1
  [aae7a2af] DiffEqFlux v1.1.1
  [41bf760c] DiffEqSensitivity v6.6.0
  [163ba53b] DiffResults v1.0.2
  [587475ba] Flux v0.10.1
  [f6369f11] ForwardDiff v0.10.9
  [1dea7af3] OrdinaryDiffEq v5.28.1
  [731186ca] RecursiveArrayTools v2.0.4
  [ae029012] Requires v1.0.0
  [1bc83da4] SafeTestsets v0.0.1
  [789caeaf] StochasticDiffEq v6.18.0
  [9f7883ad] Tracker v0.2.6
  [e88e6eb3] Zygote v0.4.6
  [700de1a5] ZygoteRules v0.2.0
  [37e2e46d] LinearAlgebra 
  [10745b16] Statistics 
  [8dfed614] Test 
WARNING: could not import Compiler.just_construct_ssa into Wrap
[ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message)
416.7086995514811301.86465432569827213.21697213391016149.3929796071194115.2247517913104296.3438136311290279.3936123278511765.5625775751988754.73408970504229446.2626159904189439.55562467607837434.29338639796445430.54262397471921328.93102825992030330.78230280655101637.5616921386252547.3899178101139352.31771747076819448.8559023431533241.1409918445188933.4998573173513127.7136171838481823.8213532431337521.2574969683678819.43364473086034417.9080234863235616.40169427585258414.75827680393393112.9155083938401710.8813206837866058.7182734287630626.5317427624672214.45717155975515762.6440088213855261.23592071815229730.34657206429314730.032376452495214510.26367482940779230.905567097641851.72975726545156162.4738072183786732.93352765725007243.03618679634409672.84498125290393672.49864919108605132.1348949032518721.84171784634708581.64735382952383951.53548374223780541.46787860302471571.40348733006078131.31057624087927451.1723646987133380.98792068128521930.77000396330597080.54099857867771020.327773302321376360.156017818275280080.0445653704883056740.00091322139101779030.0190239786206280320.080410475436539270.159197271761418070.229589835455646730.27324885152407110.28364198270243850.26573545746272670.231707259387955280.195075966066423880.16585180213779310.148215404734272720.140797690163480650.13867239213660060.135911948945067140.127791420961522520.112133203758811030.089657382441687130.063454110359997350.037871264121909730.017167018654110830.0042911560636956050.000132331621225468740.0034254726393664930.0112719546828020260.020185633126746330.027176635651557520.0305475552150724330.0301433293399415230.027042574606087690.0228944748810245740.0192068480124802340.0168492892211720180.0158974341901012840.0157962049318957630.0157121461393411320.0149121397453862370.013034469259305310.0101844853779321530.0068527418229991870.00371107376408517140.4165147233362722.05751179643776512.0370348750825446.5135289307582873.449333306531671.75595775427527250.84094404510196110.37443021329731420.168535206820125380.113993952659645580.14612280653523340.226084045725327640.330332022874183450.44453247713033560.55998625789770480.67148502941274520.77600399853146430.87189273800292740.95836747901718211.0351890634502321.10245694557194661.1604754095191231.20966852063708031.25052423564283081.2835585350637151.30929252012980051.32823813261122381.34088956395894551.34771835589330261.34917101754319881.34566827355986881.33760537000416971.32535305237952781.3092589556259561.28964923032371751.26683028643724121.24109057471993341.21270235834551791.18192342984249591.1489987200334731.11416184733963771.07763654722752691.03963798482855641.00037395775048380.96004591038236690.91884985470282140.87697720670379020.83461526360589680.7919476293528450.74915455390755560.70641309478823010.66389705719105320.62177656310939280.58021772941819840.53938205058489960.499425603913018160.46049810994840570.422741852769967950.386290481421706360.35126772601631440.31778605930360250.28594534513841270.25583151905008280.22751535136575560.20105134613579230.176476830517125620.15381128755533310.1330559813874410.11419391750516230.09719017064561390.081992600314648580.068532958104907030.056728382019807190.0464832393086062960.0376912726048983450.030237985082358330.024003184698996550.0188635931042838160.0146954469766707920.011376965643921810.0087906079973395050.0068250384014155160.0053767605408925280.0043513359078645020.00366419648931561170.00324104747251205680.00301788180419505560.0029406546810552010.00296467549401477260.0030537858504463320.00317939638715525940.0033194536355839830.00345740178203429080.00358119384934399170.00368239395638591830.00375539825338016240.00379678821100120670.0038048173655808540.0037790221553037110.0037199399315911872416.70869955148316301.87186997430365213.22801705361297149.40648614478837115.2240412249364696.3454391345538679.3977976779125865.5678714713974554.73969630607274446.2681431647925939.5608383606454234.2980229596167530.54633410011867428.9332381463373130.78208250143966437.5587566610162847.3870414634704752.3184906512701248.8589544323429841.14383255919601433.5012140860317727.71329342894746323.81952936942857221.2543767187669819.4294856183711817.90303100693667616.39608500849614714.75230897079328312.90945584534311610.8754625577971288.712882525457966.5270686024001344.4534149599774862.6412962392444671.2342795663056390.3459158046638280.032506748634095760.264310414146053160.90639787468961761.7305156642179892.4743407762289472.9338239544033673.0363286740031682.84506488225275162.49872238818174442.13494430274363721.8416920826943291.6471951659831451.53515198186780831.46736343542057451.40280885504569251.30977827422533061.1715059590677530.98706641658549010.76921762520158130.54033333964074280.32726603243509670.155685347538229820.044402053227207340.00089265358725995560.0191039242369983630.080534769824929170.159307303717266780.229641600525029880.273224851436197740.283552996888048250.26561206968046450.23158584804701470.194985613398158870.165806707487119760.14821387238102470.140826097601411540.13871147379454670.135943057155115480.12780127946737040.112116466759106760.089616889144780110.063399129505176940.037814459743258160.017120978004210560.00426522788223897450.00013060182132885350.00344585479851722280.011306698777051870.0202248123961467770.02721155913652230.0305730930624841660.030158440940405340.027049241017987240.022895782224433470.0192051454721658860.016845112348903880.0158894783750984330.015782221974403340.015690315650227170.0148822708785586060.0129985681020147110.0101464819170533940.0068175358724189420.003683289147449469Test Summary: | Pass  Total
Layers Tests  |    6      6
Test Summary: | Pass  Total
Layers SDE    |    2      2
Test Summary: | Pass  Total
Layers DDE    |    3      3
4921.8252741349712317.17607567990261208.7459484255783668.1116929665505373.591041917807200.3314261180958104.4529358283813157.3138215258823534.32119428773293623.00067562422833218.12036039950615417.12597192218196818.38676708518351820.73091139694933523.31418352305031825.83594425345194528.2714424609499930.54643652796871632.53970044402460434.18718539872835.47480087834690536.3845017897876336.97114129712160537.25134235223478637.2627632524933437.0375236734635336.6005797078884635.9731756137308235.174505664654734.2262258270057533.1564351256670531.98065986407443330.7158346130359329.3810401288643227.9970894386508726.5988538685920725.17795742013946723.76978885961625222.38315600243469621.05025855873586219.78072978313227318.58395487536728317.46929326363028416.4490617863162415.51075932428809914.65835904580749213.8865830261551313.18807642074406212.55328355145845611.97154036216499411.43216286935378410.92508995804154510.4412884568655559.973053407198959.5141930211534569.060086309073828.6076180969602828.1550545807119897.7018622570740217.2485936813957846.79678428158544456.3487040397705015.9069742122563875.4744959273566785.0552931819356054.65230431179507154.2671100272408283.9016429007326623.55721847718319633.23468157075657642.9345580479832892.6568455035211892.401832105399052.1693524505581841.95806300172912361.76607235753308721.59174649731689581.43381002324094561.29095139258983771.16175831254542181.04481083303797880.93892941264289680.84284247911402380.75528214936003710.67519208736800940.60173194629611610.53426967609171950.47233112982576810.41555162110782830.363554278364917160.31609840944450740.272919696136243450.23376622741716190.198448158162193330.166820206931371670.138755340611349980.114099500151986740.092704690960577580.07435278640620720.05878273363362060.045756485807158014Test Summary:                  | Pass  Total
Size Handling in Adjoint Tests |    1      1
Test Summary: |
odenet        | No tests
Loss: 10.983616846195044
Loss: 0.1104974563629995
Loss: 1.8404895642035137
Loss: 3.846337166661437
Loss: 5.085075715981268
Loss: 5.641143955873096
Loss: 5.6572681394719595
Loss: 5.234647934458423
Loss: 4.446703067947699
Loss: 3.3692216736205123
Loss: 2.1224148014234543
Loss: 0.9304014962405507
Loss: 0.17828942849285145
Loss: 0.3348156054855288
Loss: 1.419964804568503
Loss: 2.3084593629178127
Loss: 1.9225139158131659
Loss: 0.8788770692336202
Loss: 0.20576429485124761
Loss: 0.14965646314119138
Loss: 0.451564533272536
Loss: 0.8141037334533884
Loss: 1.0574651798874395
Loss: 1.1101270170902389
Loss: 0.9735036351794316
Loss: 0.7007412421490805
Loss: 0.38757537596097924
Loss: 0.15863862705013612
Loss: 0.12402415403636978
Loss: 0.2935761238881823
Loss: 0.5139083024272643
Loss: 0.5722532887885254
Loss: 0.42277538864891634
Loss: 0.21838969233669672
Loss: 0.11434661684265326
Loss: 0.14037114401246537
Loss: 0.23351303246364608
Loss: 0.3155989564383942
Loss: 0.33825966709000244
Loss: 0.29407132621183907
Loss: 0.2106335727397588
Loss: 0.13530137320131336
Loss: 0.11062196649718517
Loss: 0.14521901486486455
Loss: 0.20145566526118655
Loss: 0.22450759372065862
Loss: 0.19476514287665236
Loss: 0.14302020658937195
Loss: 0.11214083617403076
Loss: 0.11748685144713714
Loss: 0.14370859061298677
Loss: 0.16533095744606194
Loss: 0.1662202300823176
Loss: 0.147305517367968
Loss: 0.12304786928995072
Loss: 0.11043287585867957
Loss: 0.11629989844855342
Loss: 0.1318119797368459
Loss: 0.14061363864914148
Loss: 0.1345577394646405
Loss: 0.12041862063820247
Loss: 0.11094383440643747
Loss: 0.11214786353736649
Loss: 0.11989523395961693
Loss: 0.1258063885482601
Loss: 0.12476440988214674
Loss: 0.11816209466134912
Loss: 0.11175057579421971
Loss: 0.11042149614750962
Loss: 0.11407427593173776
Loss: 0.11813472810149286
Loss: 0.11831939686319896
Loss: 0.11472742889074822
Loss: 0.11103843396408834
Loss: 0.11033346298223218
Loss: 0.11236839087040026
Loss: 0.11451845121471102
Loss: 0.11459737169178463
Loss: 0.11268563860987085
Loss: 0.11066942835825304
Loss: 0.1102623105369315
Loss: 0.1114222302278067
Loss: 0.1126119913921194
Loss: 0.11251842853234788
Loss: 0.11133468959762341
Loss: 0.11031229584118472
Loss: 0.11031818673269767
Loss: 0.11105743500631282
Loss: 0.11158951628951974
Loss: 0.1113578060242918
Loss: 0.11065554508587679
Loss: 0.11019696152228263
Loss: 0.11034316558041503
Loss: 0.1107886845392028
Loss: 0.11097463812783849
Loss: 0.11071058506623425
Loss: 0.1103128165063275
Loss: 0.1101829979473383
Loss: 0.11037322913126248
Loss: 0.11059765771061796
Loss: 0.11059054026671997
Loss: 0.11059054026671997
Loss: 10.983616846195027
Loss: 0.1104974563629996
Loss: 1.8404894101499076
Loss: 3.8463366111318638
Loss: 5.085074683032128
Loss: 5.641142392988326
Loss: 5.657265994722879
Loss: 5.234645165711661
Loss: 4.44669967657572
Loss: 3.369217777686793
Loss: 2.122410773309322
Loss: 0.930398162889526
Loss: 0.1782882371953363
Loss: 0.3348179835732101
Loss: 1.4199695218490973
Loss: 2.308461719046682
Loss: 1.9225124101517403
Loss: 0.8788748258897118
Loss: 0.2057634638002814
Loss: 0.14965689575818386
Loss: 0.4515653798097273
Loss: 0.8141043102772356
Loss: 1.0574651264313493
Loss: 1.1101262350302978
Loss: 0.9735022325215642
Loss: 0.7007395216686174
Loss: 0.3875738328183265
Loss: 0.15863786395676555
Loss: 0.12402458096501147
Loss: 0.29357747202374096
Loss: 0.5139095443452492
Loss: 0.5722535751267336
Loss: 0.42277490986689714
Loss: 0.21838918780268343
Loss: 0.11434651234394706
Loss: 0.14037136765644276
Loss: 0.23351328577039732
Loss: 0.3155989779734896
Loss: 0.3382593527970312
Loss: 0.29407075107035
Loss: 0.21063295795185452
Loss: 0.13530099873610155
Loss: 0.11062201892709149
Loss: 0.14521942909833452
Loss: 0.20145612839154722
Loss: 0.22450780449245944
Loss: 0.19476507684491884
Loss: 0.14302006572671558
Loss: 0.11214079458361864
Loss: 0.11748691613788696
Loss: 0.14370865212726822
Loss: 0.16533090730085773
Loss: 0.16622004184209532
Loss: 0.14730526284456433
Loss: 0.12304767616272509
Loss: 0.11043284628150946
Loss: 0.11630003277679493
Loss: 0.13181217139691365
Loss: 0.14061376412141816
Loss: 0.13455776115709642
Loss: 0.12041859296849178
Loss: 0.11094382254684179
Loss: 0.11214787800404101
Loss: 0.11989523648115823
Loss: 0.1258063403250738
Loss: 0.12476431134717451
Loss: 0.11816198953856559
Loss: 0.11175052067251759
Loss: 0.11042151803914305
Loss: 0.11407435141016543
Loss: 0.11813480474583568
Loss: 0.11831943816399822
Loss: 0.114727437193363
Loss: 0.11103843229708026
Loss: 0.11033346361146702
Loss: 0.11236838527931968
Loss: 0.11451842522224774
Loss: 0.11459732515824389
Loss: 0.11268559051462061
Loss: 0.11066940369439988
Loss: 0.11026232080269274
Loss: 0.11142226486317693
Loss: 0.11261202804961798
Loss: 0.11251845163614692
Loss: 0.11133469862348247
Loss: 0.11031229773612306
Loss: 0.11031818447439858
Loss: 0.1110574252970685
Loss: 0.11158949649875792
Loss: 0.11135778092875448
Loss: 0.11065552578601032
Loss: 0.11019695743615127
Loss: 0.11034317715558446
Loss: 0.11078870356940063
Loss: 0.1109746549370719
Loss: 0.1107105950702043
Loss: 0.1103128203632835
Loss: 0.11018299725515929
Loss: 0.1103732237351035
Loss: 0.11059764723864729
Loss: 0.11059052703631903
Loss: 0.11059052703631903
Test Summary:        | Pass  Total
GDP Regression Tests |    2      2
Test Summary:   | Pass  Broken  Total
Neural DE Tests |   44       2     46
19.15721
9.671388
6.7394023
5.632591
5.323156
5.2244453
5.185457
5.15607
5.1375637
5.0777655
5.052895
5.0235267
5.006511
4.960742
4.929734
4.9137316
4.8725057
4.849117
4.8250613
4.7870708
4.7551556
4.7191296
4.7109094
4.679693
4.6480856
4.6118145
4.5963297
4.562545
4.534982
4.526584
4.4793224
4.456945
4.4241724
4.3974504
4.2034645
4.346471
4.154563
4.3013096
4.105692
4.246514
4.0504045
4.056948
4.018001
4.145297
4.1152616
3.9428344
3.9155097
3.8847466
3.878464
3.8483155
3.8191264
3.7982533
3.806766
3.756645
3.7538
3.7158718
3.710159
3.6711652
3.6572936
3.6323292
3.608344
3.6127815
3.5669599
3.54287
3.5325265
3.5056186
3.49538
3.4680042
3.456765
3.441383
3.4174643
3.3953667
3.3708198
3.3603015
3.3407722
3.3267758
3.3066826
3.2781026
3.2580695
3.241852
3.2160022
3.204279
3.189444
3.1783373
3.1549845
3.1389003
3.1227708
3.1041985
3.0821614
3.0708168
2.9368682
2.9168322
2.8995926
2.8873777
2.9893982
2.856275
2.8365092
2.8248343
2.808828
2.7854068
2.7715614
2.7737708
2.7444158
2.7342494
2.7143974
2.699663
2.6888328
2.6704993
2.6757329
2.6606212
2.620599
2.6096985
2.6011848
2.5897143
2.5704782
2.5619347
2.4614475
2.5389552
2.5217245
2.5064588
2.4866338
2.4830737
2.467362
2.460621
2.4493136
2.4310815
2.4103081
2.4005547
2.3887815
2.3721168
2.3615646
2.350415
2.3394506
2.3364394
2.2253604
2.296527
2.1941206
2.2763925
2.2639322
2.2606509
2.2349641
2.2304091
2.1315303
2.1119256
2.1962755
2.182722
2.0860584
2.1626403
2.067419
2.0514607
2.0387738
2.0290449
2.1027944
2.006259
1.9937272
1.9979163
2.0555882
1.9620464
1.9530365
1.9465919
1.9376738
1.9327126
1.9199553
1.9848428
1.9106238
1.8838891
1.8776665
1.867567
1.8579539
1.8517925
1.8364213
1.8368185
1.8150618
1.8094859
1.7970164
1.7939926
1.7763721
1.769537
1.7641891
1.7535295
1.7441722
1.7493322
1.726502
1.7218419
1.7083294
1.7032024
1.6311595
1.6868912
1.6728253
1.672093
1.5958878
1.6499834
1.6502544
1.6335942
1.6281554
1.6184101
1.616865
1.6015908
1.5361663
1.5887423
1.5771723
1.5046846
1.4996651
1.5541817
1.4940739
1.4803774
1.4647114
1.5204595
1.4533261
1.4457092
1.499247
1.5014797
1.4219115
1.4171556
1.4715492
1.4049311
1.4591535
1.3925339
1.3858798
1.3785709
1.375215
1.3642999
1.3526882
1.3556033
1.3390132
1.3350809
1.3322544
1.3255925
1.3183662
1.3083928
1.3022885
1.3025749
1.2905616
1.2942312
1.2770725
1.2687678
1.2661006
1.2588446
1.2526802
1.2456316
1.2444192
1.236037
1.2296207
1.2272791
1.2188703
1.2127192
1.2051574
1.2077056
1.1977302
1.1384435
1.1813097
1.1790361
1.175445
1.1673849
1.1605448
1.112067
1.1541015
1.0962812
1.1426827
1.1316464
1.1305264
1.0774155
1.117121
1.115015
1.1080124
1.103407
1.0497055
1.0915068
1.0373679
1.0381643
1.0365317
1.0718592
1.0639744
1.0161291
1.0105652
1.0033305
1.0464481
0.9950547
0.9906391
0.9886955
0.9833037
1.0208217
1.0164669
1.0129622
1.0059247
1.0018404
0.95136935
0.950443
0.9430056
0.9435371
0.93381083
0.9335957
0.9251968
0.92373854
0.9580724
0.9126756
0.9116409
0.9052597
0.900161
0.8987265
0.931788
0.8923513
0.8827094
0.8461591
0.8773774
0.8719809
0.8711145
0.8659717
0.861263
0.8566613
0.85529876
0.85408646
0.84731185
0.8064724
0.8378496
0.83716947
0.83535576
0.82528603
0.82133424
0.817835
0.81699926
0.81275946
0.80690575
0.7691866
0.79932094
0.7974755
0.796449
0.78960115
0.78648394
0.78268456
0.7801588
0.7749739
0.7731704
0.7697768
0.7671229
0.7265966
0.7584348
0.75642973
0.7527574
0.74901706
0.7460129
0.7414159
0.7041612
0.7347738
0.73341733
0.69505984
0.7263497
0.724143
0.6886138
0.7162479
0.71338695
0.67753404
0.70602125
0.7029817
0.66861475
0.6659448
0.69495434
0.69341296
0.68779093
0.65548444
0.6823462
0.6474653
0.6468624
0.6726805
0.64038116
0.637742
0.63414854
0.63272077
0.62893414
0.62611043
0.6240733
0.65099025
0.61748993
0.6173412
0.6133825
0.6121507
0.60685915
0.60383946
0.60290974
0.60047704
0.5968763
0.59321314
0.59255826
0.58898044
0.58751094
0.58438283
0.58128846
0.58104706
0.57752955
0.5727315
0.5753539
0.54299545
0.5678619
0.5658618
0.5628212
0.5602586
0.53296906
0.5552049
0.5542667
0.5248669
0.5482856
0.5471084
0.54477686
0.5420283
0.514864
0.513798
0.51012534
0.5079258
0.5062446
0.5278509
0.526292
0.4985588
0.5225954
0.5198282
0.51685774
0.5158253
0.4892318
0.48745438
0.48336875
0.48308784
0.48226038
0.47899222
0.50064975
0.4999768
0.47369036
0.4949883
0.4699974
0.46769637
0.46654052
0.4642043
0.46175528
0.45977467
0.4579105
0.4579458
0.45537764
0.45183814
0.45091054
0.4490335
0.44722718
0.44480485
0.4437067
0.44225466
0.44018131
0.43833935
0.4371213
0.43470314
0.4328431
0.43161443
0.42980483
0.42795312
0.42652488
0.4246189
0.4235909
0.42176652
0.4194287
0.41794035
0.41622588
0.4147598
0.39272046
0.4120085
0.40986457
0.38888738
0.40676245
0.40553185
0.40299958
0.4015192
0.40032378
0.39891
0.3969519
0.37591344
0.39357194
0.39291435
0.3904979
0.38989627
0.38838324
0.36809435
0.3849512
0.36442596
0.38148496
0.3807539
0.36117262
0.35915452
0.3757917
0.3558715
0.35505155
0.35321888
0.37102345
0.35063183
0.34906548
0.3477442
0.346906
0.36283818
0.34394693
0.34250295
0.3418578
0.34016317
0.33940694
0.33748758
0.33656532
0.33482844
0.33385503
0.33251864
0.33149198
0.32995662
0.3284349
0.3276151
0.32598296
0.32532972
0.32362467
0.32264164
0.32144326
0.32016188
0.31881523
0.31791252
0.31648734
0.31499133
0.31412145
0.3129508
0.3119525
0.31084967
0.30934423
0.30833808
0.30738533
0.2902779
0.30480593
0.28861603
0.30284774
0.30210492
0.28477755
0.2997242
0.29864994
0.29740036
0.29649633
0.28019565
0.29412594
0.29307434
0.2917734
0.27613807
0.289862
0.27409273
0.27307168
0.2867309
0.27107453
0.28460166
0.2838569
0.26817942
0.26698032
0.2661111
0.2795957
0.26429558
0.26339749
0.27669132
0.26133326
0.26060346
0.2596052
0.2587998
0.2579771
0.25741917
0.2562014
0.25512192
0.25412962
0.2533862
0.2525204
0.25159344
0.25089622
0.2498292
0.24879964
0.24816692
0.24720386
0.24617921
0.2455492
0.23113544
0.2439399
0.24298462
0.24201532
0.24129944
0.22733177
0.23940524
0.23881513
0.22498672
0.22411811
0.23634689
0.23524885
0.23479697
0.22098494
0.2205498
0.21977185
0.2188355
0.2306026
0.21751258
0.22891957
0.21592231
0.21538085
0.2144205
0.21396546
0.21283098
0.21230218
0.21131808
0.21102096
0.21032119
0.20959227
0.19675075
0.20795162
0.20751974
0.19458926
0.2062109
0.20524767
0.20450303
0.2040477
0.20345433
0.20259273
0.19050369
0.18968476
0.18892711
0.18812813
0.19930403
0.18743849
0.1862247
0.18606141
0.18518665
0.18455932
0.18426211
0.18384881
0.18268457
0.18277486
0.18219575
0.18132949
0.18102615
0.18035853
0.17934078
0.17895482
0.17830332
0.17773746
0.16671045
0.16583048
0.16523257
0.16485849
0.16412324
0.17443351
0.16321588
0.16264571
0.16250655
0.16210361
0.16116187
0.160814
0.16007988
0.14923571
0.15989281
0.15845953
0.14835835
0.15782683
0.15745308
0.14696947
0.15657453
0.15640119
0.15551487
0.14523484
0.1444388
0.15435435
0.15402628
0.15322362
0.15282077
0.15253796
0.16182297
0.15153876
0.15097038
0.15104266
0.15991288
0.15932335
0.14936703
0.14886214
0.15788664
0.14824452
0.15682448
0.14730366
0.15580207
0.14583623
0.15534438
0.15453875
0.15422529
0.15368265
0.15344247
0.15305401
0.15275472
0.15172644
0.15094747
0.1600663
0.15079713
0.1501839
0.14937973
0.14907637
0.14839025
0.15716608
0.14801708
0.14726016
0.14691132
0.155256
0.15479925
0.15402363
0.15352531
0.15293862
0.1524893
0.14353453
0.15164705
0.15119499
0.15076078
0.15029263
0.14151315
0.14949189
0.1487519
0.14870745
0.14838046
0.14770073
0.14630002
0.1468414
0.14663227
0.13612151
0.14595827
0.14479882
0.14465883
0.14415127
0.1435915
0.14326039
0.14245199
0.14272197
0.14234596
0.14158994
0.1408906
0.1410816
0.14030546
0.14772666
0.139318
0.14690447
0.13835283
0.14596473
0.13770534
0.14500305
0.14444111
0.14415509
0.13569936
0.13530232
0.1427758
0.13434677
0.13403752
0.14086929
0.14103077
0.13330734
0.13315734
0.13164009
0.13903798
0.13881116
0.13106315
0.13037983
0.13745546
0.13627902
0.13690986
0.13636693
0.13592252
0.12818491
0.12790014
0.12742996
0.13429564
0.13390934
0.13294604
0.13282084
0.12584044
0.13161631
0.13177428
0.13182642
0.13056204
0.13027033
0.12300865
0.12262331
0.12948962
0.121196985
0.1292398
0.1280826
0.12780732
0.12702903
0.1271752
0.12660038
0.126418
0.12545352
0.12474235
0.12501362
0.1251805
0.11776652
0.124229975
0.12384459
0.12249882
0.12332132
0.12214561
0.1221369
0.12201373
0.120411895
0.12091789
0.121041656
0.12051872
0.120083965
0.11962967
0.11901286
0.12528089
0.11803515
0.11857593
0.11748858
0.11703768
0.11698373
0.11663859
0.12233154
0.11602659
0.108639956
0.11554903
0.11534463
0.120572835
0.11390367
0.113590956
0.11367458
0.11329336
0.11323723
0.111722104
0.112128176
0.11100763
0.11072558
0.11131333
0.111146145
0.11049965
0.115953445
0.10948631
0.109637156
0.114691876
0.108902305
0.10848543
0.10724213
0.10750829
0.11369577
0.10750993
0.11191344
0.112528324
0.10657869
0.10604425
0.105241165
0.10547853
0.11027307
0.10531686
0.109684214
0.10422421
0.10345151
0.103420176
0.10310886
0.10812735
0.10786686
0.10174312
0.1065765
0.10092186
0.10727425
0.10098321
0.10075899
0.10508728
0.106064804
0.10485978
0.1002706
0.10401924
0.10450843
0.10375737
0.102867804
0.10237543
0.10322258
0.10218687
0.09740408
0.102253176
0.10140368
0.09643075
0.100779556
0.100394286
0.099874444
0.0950054
0.094624616
0.09984984
0.09904731
0.09867132
0.098482385
0.09837145
0.09336481
0.0981136
0.097648434
0.092972845
0.096618354
0.096177764
0.09638276
0.09078377
0.09089253
0.09521943
0.095681265
0.09523948
0.09482981
0.09453408
0.094101414
0.089256935
0.09332994
0.09306833
0.08791336
0.09229009
0.0923587
0.092204794
0.091796026
0.08705284
0.09105097
0.09084214
0.08677158
0.09089522
0.09002435
0.09012627
0.09001843
0.08918426
0.08973267
0.08912933
0.08865795
0.08775591
0.087680876
0.08800449
0.08748884
0.08711896
0.08736797
0.086633675
0.08690791
0.086094245
0.08180677
0.085794695
0.08472417
0.08531033
0.081431344
0.08042297
0.08416372
0.084137976
0.07949563
0.08396242
0.083213985
0.08329402
0.083254606
0.08277925
0.08230829
0.08226465
0.08282368
0.08241247
0.08197959
0.08161717
0.076488405
0.08049047
0.080988094
0.080146104
0.08025254
0.07982535
0.07525095
0.0739528
0.079681285
0.0784458
0.07874525
0.07864821
0.07770897
0.07869814
0.078348994
0.073829934
0.07782771
0.076273955
0.07703423
0.07733384
0.07652821
0.07684158
0.0753065
0.0724411
0.075635076
0.07515256
0.07557346
0.07526837
0.07477619
0.0744068
0.07503923
0.07475547
0.073598444
0.073285766
0.07403383
0.07272518
0.073424995
0.07285851
0.07261685
0.072348595
0.072066665
0.072251536
0.07180744
0.07168746
0.07136858
0.07096886
0.07098756
0.07038977
0.07071551
0.07034233
0.070630394
0.06972033
0.070340216
0.06619736
0.06989479
45.50348
16298.43
7.0159507
56.0421
66.40783
69.79718
70.811035
70.74275
70.09968
69.12492
67.950584
66.65561
65.2866
63.87645
62.44433
61.004417
59.566357
58.136513
56.719112
55.318043
53.93584
52.574497
51.235584
49.92051
48.630383
47.36595
46.12794
44.91683
43.733032
42.57672
41.44772
40.34615
39.271538
38.223827
37.202908
36.207256
35.23746
34.292465
33.37176
32.474426
31.60046
30.74921
29.919603
29.111729
28.324984
27.559202
26.813538
26.087862
25.382172
24.695404
24.028759
23.381021
22.752014
22.142931
21.553501
20.983099
20.432701
19.901098
19.390371
18.89995
18.430124
17.98086
17.552965
17.146093
16.76127
16.39805
16.05692
15.737508
15.440284
15.164999
14.911826
14.680349
14.470166
14.28047
14.111337
13.961334
13.829931
13.716205
13.618725
13.536329
13.467747
13.411498
13.366065
13.330084
13.301912
13.280326
13.263758
13.250895
13.240712
13.232125
13.22405
13.215721
13.206699
13.196324
13.184459
13.170757
13.155299
13.138004
13.118924
13.098411
13.076442
13.053497
13.029643
13.005247
12.980364
12.9553175
12.930436
12.905664
12.881018
12.856852
12.833129
12.809952
12.7872505
12.764869
12.743006
12.721745
12.700503
12.679942
12.659438
12.639286
12.619236
12.599251
12.579375
12.559582
12.539635
12.519683
12.49989
12.479873
12.459794
12.439597
12.419171
12.398946
12.378436
12.357768
12.337233
12.316536
12.295755
12.274727
12.253858
12.233022
12.212088
12.191097
12.170032
12.1488695
12.12764
12.106714
12.085367
12.064357
12.043054
12.021923
12.000613
11.979397
11.958092
11.9367695
11.91541
11.894013
11.872645
11.851103
11.8296995
11.808286
11.786729
11.765236
11.743617
11.721906
11.700183
11.678501
11.656773
11.6348715
11.613105
11.591267
11.569488
11.547666
11.525608
11.5035925
11.481584
11.459584
11.437639
11.415575
11.393352
11.37134
11.349194
11.327035
11.304869
11.282538
11.260222
11.23796
11.215582
11.193264
11.170756
11.148579
11.126238
11.103725
11.081254
11.0588045
11.036216
11.013657
10.991027
10.968585
10.945941
10.923105
10.900594
10.877837
10.855162
10.832397
10.80979
10.786838
10.7641945
10.741344
10.718484
10.695567
10.672778
10.64969
10.627157
10.603876
10.5808325
10.557847
10.53491
10.511907
10.488816
10.465683
10.442631
10.419585
10.396383
10.373332
10.350136
10.32688
10.303707
10.280421
10.257265
10.233961
10.2107115
10.187369
10.164154
10.140853
10.1174
10.094062
10.070736
10.047129
10.023833
10.00055
9.976871
9.953574
9.930128
9.906593
9.882994
9.8596735
9.836186
9.81249
9.789053
9.765376
9.741793
9.718271
9.694694
9.671077
9.647379
9.6236925
9.600034
9.576505
9.552664
9.529046
9.505396
9.481588
9.457771
9.434106
9.410388
9.386583
9.362784
9.339164
9.315314
9.291525
9.26771
9.243799
9.220071
9.196303
9.1724205
9.148411
9.1245985
9.100844
9.076913
9.052953
9.02907
9.005281
8.981362
8.957515
8.933471
8.909612
8.885724
8.861761
8.837802
8.813916
8.789884
8.766037
8.742038
8.718114
8.694135
8.670097
8.646144
8.622397
8.598214
8.57442
8.550426
Partial Neural Tests: Test Failed at /home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/partial_neural.jl:79
  Expression: 10loss2 < loss1
   Evaluated: 85.50426f0 < 45.50348f0
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/partial_neural.jl:79
 [2] include(::Module, ::String) at ./Base.jl:377
 [3] include(::String) at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:23
 [4] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/runtests.jl:16
 [5] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1113
 [6] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/runtests.jl:16
Test Summary:        | Pass  Fail  Total
Partial Neural Tests |    1     1      2
ERROR: LoadError: Some tests did not pass: 1 passed, 1 failed, 0 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/runtests.jl:7
err = ProcessFailedException(Base.Process[Process(`/opt/julia/bin/julia -Cnative -J/opt/julia/lib/julia/sys.so -g1 --code-coverage=none --color=no --compiled-modules=yes --check-bounds=yes --inline=yes --startup-file=no --track-allocation=none --eval 'append!(empty!(Base.DEPOT_PATH), ["/home/pkgeval/.julia", "/opt/julia/local/share/julia", "/opt/julia/share/julia", "/usr/local/share/julia"])
append!(empty!(Base.DL_LOAD_PATH), String[])

cd("/home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test")
append!(empty!(ARGS), String[])
include("/home/pkgeval/.julia/packages/DiffEqFlux/jSspb/test/runtests.jl")
'`, ProcessExited(1))])
ERROR: Package DiffEqFlux errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:54
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1471
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:313
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:300
 [5] #test#66 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [7] #test#65 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [11] top-level scope at none:13
