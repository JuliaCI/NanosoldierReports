Julia Version 1.5.0-DEV.190
Commit 347859e828 (2020-01-29 01:19 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed FillArrays ───────── v0.8.4
 Installed Arpack ───────────── v0.4.0
 Installed BinaryProvider ───── v0.5.8
 Installed StaticArrays ─────── v0.12.1
 Installed LegacyStrings ────── v0.4.1
 Installed CMake ────────────── v1.1.2
 Installed SortingAlgorithms ── v0.3.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Clustering ───────── v0.13.3
 Installed StatsBase ────────── v0.32.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Compat ───────────── v2.2.0
 Installed BinDeps ──────────── v1.0.0
 Installed JLD ──────────────── v0.9.1
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed DataAPI ──────────── v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed OrderedCollections ─ v1.1.0
 Installed Rmath ────────────── v0.6.0
 Installed URIParser ────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed DataStructures ───── v0.17.9
 Installed Distributions ────── v0.22.3
 Installed Blosc ────────────── v0.5.1
 Installed PDMats ───────────── v0.9.11
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed Distances ────────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_cBblly/Project.toml`
 [no changes]
  Updating `/tmp/jl_cBblly/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_tTDGNS/Project.toml`
 [no changes]
  Updating `/tmp/jl_tTDGNS/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_0noWVb/Project.toml`
 [no changes]
  Updating `/tmp/jl_0noWVb/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_9AGU2O/Project.toml`
 [no changes]
  Updating `/tmp/jl_9AGU2O/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_up65MM/Project.toml`
 [no changes]
  Updating `/tmp/jl_up65MM/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_up65MM/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.4620066099553788e6, [26551.329169386707, 73448.6708306133], [-2905.039314890078 -29506.200325663754 -13782.787548364526; 2628.737942295865 29865.148205314883 13752.520295944265], [[25288.08876021927 1667.76486614024 1124.971969833721; 1667.7648661402395 43274.11006899618 7528.536653790772; 1124.971969833721 7528.536653790772 30799.658809663168], [74602.49664953104 -1748.3261323747765 -1333.651063632315; -1748.3261323747765 56651.5982904127 -6991.011029243869; -1333.6510636323155 -6991.01102924387 68691.68483868965]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1026
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.240116e+03
      1       9.577951e+02      -2.823207e+02 |        6
      2       9.267042e+02      -3.109084e+01 |        2
      3       9.072307e+02      -1.947357e+01 |        2
      4       9.057135e+02      -1.517132e+00 |        0
      5       9.057135e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 905.7135331957625)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.073516
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.774826
[ Info: iteration 2, lowerbound -3.637691
[ Info: iteration 3, lowerbound -3.489116
[ Info: iteration 4, lowerbound -3.316855
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.135694
[ Info: iteration 6, lowerbound -2.974477
[ Info: iteration 7, lowerbound -2.866930
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.815067
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.796854
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.782768
[ Info: iteration 11, lowerbound -2.771163
[ Info: iteration 12, lowerbound -2.764951
[ Info: iteration 13, lowerbound -2.756044
[ Info: iteration 14, lowerbound -2.743465
[ Info: iteration 15, lowerbound -2.726158
[ Info: iteration 16, lowerbound -2.703174
[ Info: iteration 17, lowerbound -2.673955
[ Info: iteration 18, lowerbound -2.638628
[ Info: iteration 19, lowerbound -2.598217
[ Info: iteration 20, lowerbound -2.554679
[ Info: iteration 21, lowerbound -2.510610
[ Info: iteration 22, lowerbound -2.468516
[ Info: iteration 23, lowerbound -2.429897
[ Info: iteration 24, lowerbound -2.394870
[ Info: iteration 25, lowerbound -2.362924
[ Info: iteration 26, lowerbound -2.334899
[ Info: iteration 27, lowerbound -2.314747
[ Info: iteration 28, lowerbound -2.307411
[ Info: dropping number of Gaussions to 2
[ Info: iteration 29, lowerbound -2.302944
[ Info: iteration 30, lowerbound -2.299261
[ Info: iteration 31, lowerbound -2.299256
[ Info: iteration 32, lowerbound -2.299255
[ Info: iteration 33, lowerbound -2.299254
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 29 03:11:07 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 29 03:11:15 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Wed Jan 29 03:11:18 2020: EM with 272 data points 0 iterations avll -2.073516
5.8 data points per parameter
, Wed Jan 29 03:11:19 2020: GMM converted to Variational GMM
, Wed Jan 29 03:11:28 2020: iteration 1, lowerbound -3.774826
, Wed Jan 29 03:11:28 2020: iteration 2, lowerbound -3.637691
, Wed Jan 29 03:11:28 2020: iteration 3, lowerbound -3.489116
, Wed Jan 29 03:11:28 2020: iteration 4, lowerbound -3.316855
, Wed Jan 29 03:11:28 2020: dropping number of Gaussions to 7
, Wed Jan 29 03:11:28 2020: iteration 5, lowerbound -3.135694
, Wed Jan 29 03:11:28 2020: iteration 6, lowerbound -2.974477
, Wed Jan 29 03:11:28 2020: iteration 7, lowerbound -2.866930
, Wed Jan 29 03:11:28 2020: dropping number of Gaussions to 6
, Wed Jan 29 03:11:28 2020: iteration 8, lowerbound -2.815067
, Wed Jan 29 03:11:28 2020: dropping number of Gaussions to 5
, Wed Jan 29 03:11:28 2020: iteration 9, lowerbound -2.796854
, Wed Jan 29 03:11:28 2020: dropping number of Gaussions to 3
, Wed Jan 29 03:11:28 2020: iteration 10, lowerbound -2.782768
, Wed Jan 29 03:11:28 2020: iteration 11, lowerbound -2.771163
, Wed Jan 29 03:11:28 2020: iteration 12, lowerbound -2.764951
, Wed Jan 29 03:11:28 2020: iteration 13, lowerbound -2.756044
, Wed Jan 29 03:11:28 2020: iteration 14, lowerbound -2.743465
, Wed Jan 29 03:11:28 2020: iteration 15, lowerbound -2.726158
, Wed Jan 29 03:11:28 2020: iteration 16, lowerbound -2.703174
, Wed Jan 29 03:11:28 2020: iteration 17, lowerbound -2.673955
, Wed Jan 29 03:11:28 2020: iteration 18, lowerbound -2.638628
, Wed Jan 29 03:11:28 2020: iteration 19, lowerbound -2.598217
, Wed Jan 29 03:11:28 2020: iteration 20, lowerbound -2.554679
, Wed Jan 29 03:11:28 2020: iteration 21, lowerbound -2.510610
, Wed Jan 29 03:11:28 2020: iteration 22, lowerbound -2.468516
, Wed Jan 29 03:11:28 2020: iteration 23, lowerbound -2.429897
, Wed Jan 29 03:11:28 2020: iteration 24, lowerbound -2.394870
, Wed Jan 29 03:11:28 2020: iteration 25, lowerbound -2.362924
, Wed Jan 29 03:11:28 2020: iteration 26, lowerbound -2.334899
, Wed Jan 29 03:11:28 2020: iteration 27, lowerbound -2.314747
, Wed Jan 29 03:11:28 2020: iteration 28, lowerbound -2.307411
, Wed Jan 29 03:11:28 2020: dropping number of Gaussions to 2
, Wed Jan 29 03:11:28 2020: iteration 29, lowerbound -2.302944
, Wed Jan 29 03:11:28 2020: iteration 30, lowerbound -2.299261
, Wed Jan 29 03:11:28 2020: iteration 31, lowerbound -2.299256
, Wed Jan 29 03:11:28 2020: iteration 32, lowerbound -2.299255
, Wed Jan 29 03:11:28 2020: iteration 33, lowerbound -2.299254
, Wed Jan 29 03:11:28 2020: iteration 34, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 35, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 36, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 37, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 38, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 39, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 40, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 41, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 42, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 43, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 44, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 45, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 46, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 47, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 48, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 49, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: iteration 50, lowerbound -2.299253
, Wed Jan 29 03:11:28 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222687838, 95.95490777312166]
β = [178.04509222687838, 95.95490777312166]
m = [4.250300733262897 79.28686694425873; 2.000229257768109 53.85198717242347]
ν = [180.04509222687838, 97.95490777312166]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547388729 -0.007644049042420117; 0.0 0.008581705166203973], [0.37587636120691736 -0.008953123827489633; 0.0 0.012748664777445979]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9910018262767165
avll from llpg:  -0.9910018262767157
avll direct:     -0.9910018262767158
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -1.017846060142673
avll from llpg:  -1.0178460601426729
avll direct:     -1.0178460601426729
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.139619      0.070453     0.0449986    0.254103    -0.115841    -0.0631589    -0.14537      0.0184115  -0.0915358    0.0733125    0.0355537    0.158797     0.0512006    0.221387      0.00149334  -0.0215962   -0.129146     0.0562316    0.0465012   -0.0598704   -0.152299     0.0761425   -0.0194595   -0.14807      0.122892    -0.180062
  0.151046      0.0276716    0.0321533   -0.0439712   -0.0103794    0.0481842    -0.0696655   -0.0425945  -0.121365    -0.0669891   -0.0164845   -0.0764518   -0.15261      0.0407219     0.179905     0.0109469   -0.0443708    0.00356689   0.00203764   0.244616     0.127715    -0.190522    -0.031859     0.0784612    0.0662743    0.117625
  0.180207     -0.04524     -0.169522     0.0616358    0.0551712   -0.0957285    -0.0400665   -0.0883336   0.028319     0.0573317   -0.00803054   0.0122653   -0.0995774    0.124499     -0.165559     0.0515143    0.0676332   -0.0546128    0.030615     0.0689617   -0.00215354   0.166892     0.0936027   -0.143757     0.0235847    0.00305858
 -0.0769716     0.054613     0.0542042    0.0226065   -0.0974064    0.0987273     0.0173069    0.0534248  -0.0876899    0.0891356    0.143557    -0.0326146   -0.0816584    0.078041      0.0119565    0.022882     0.13376      0.0836729   -0.019275    -0.00822666  -0.0930614   -0.0193249   -0.0318475   -0.0692339   -0.260216     0.0120695
  0.0528783     0.0698168   -0.201484    -0.118061     0.0788988   -0.124465      0.0172676   -0.0796598  -0.0679523   -0.00973763  -0.0402055   -0.136358    -0.0819842   -0.202634     -0.118084     0.258866     0.113069     0.0539911   -0.00375541  -0.0104695   -0.0210652    0.0874866   -0.123786     0.205386     0.169546     0.0644959
  0.116077      0.189389     0.0798163   -0.0442419    0.137099    -0.0188951    -0.0601253    0.0644554   0.064889    -0.0120636   -0.0163926   -0.0998809   -0.0535841    0.0238426     0.0439078   -0.046409    -0.0467347   -0.0620411    0.0198728    0.126313     0.017491     0.0172542   -0.00525565   0.164881    -0.0052884   -0.0449104
  0.0692662    -0.0610023   -0.107536    -0.0627652    0.0744541   -0.0170113    -0.0404756   -0.135199   -0.00276565   0.0385224    0.155958     0.18334      0.0171158   -0.182421     -0.0384936    0.0313568    0.0140804    0.066656    -0.114774     0.0306798   -0.0407791    0.022728    -0.0345302    0.0472173    0.173126     0.00823882
 -0.0885305    -0.0140933   -0.0705011    0.185697     0.0500187    0.0940957     0.0629356    0.116906   -0.0547955    0.158974    -0.0155524    0.0707086   -0.0446958   -0.0102848     0.0683365    0.0207358    0.011913    -0.232462    -0.0441408    0.256842     0.0117483   -0.13191      0.0222367   -0.0905094    0.0265536    0.00594983
 -0.0944831     0.0559715   -0.0735699   -0.0133407   -0.192764    -0.00822598   -0.0513817   -0.041204    0.0546006    0.0136137    0.136039    -0.0463949    0.00367263  -0.00177462    0.0855995    0.0157211    0.132281    -0.00920619  -0.00276771   0.0842531   -0.12729      0.117134    -0.0648384    0.0132334   -0.0885211    0.0153227
  0.114375      0.111493     0.176316     0.0587267   -0.0134547   -0.0782479     0.0602167    0.0857153   0.0356222    0.0578314   -0.0947668    0.119344    -0.335887    -0.0245059    -0.0281869    0.0385171    0.00315249   0.0443466   -0.109961    -0.0283563   -0.017483     0.0819125   -0.124       -0.157983     0.15319      0.00357437
  0.0104874     0.155842    -0.0714642   -0.0410257   -0.312243    -0.0173497    -0.0710815    0.0901238   0.105031     0.068742    -0.0409907    0.0470678    0.0816377    0.0958065     0.147441    -0.139487    -0.0815618   -0.0407575    0.0694418    0.0777095    0.193227     0.0517206   -0.112982     0.0175663    0.0645212    0.0459843
 -0.0863648     0.0141715    0.0397996    0.0620175   -0.0455442    0.0273978     0.119014     0.0282448   0.120703     0.0692535    0.0525826    0.087784    -0.0365042    0.000384347  -0.0115939    0.0822521    0.0369091    0.103262     0.00504859  -0.0188168    0.0753414    0.0984439    0.0707591    0.0948383   -0.244738     0.0443251
  0.108053      0.03729      0.0458049   -0.123425    -0.0909927   -0.14292       0.0115109   -0.0267451  -0.0575996   -0.0906678    0.0110112   -0.126075    -0.25624      0.0367374     0.0216005    0.122546    -0.0665518   -0.162119     0.0383089    0.023272     0.190328    -0.0772653    0.123094    -0.0268907    0.127301     0.0531495
  0.00933809   -0.0147072   -0.23078     -0.127668     0.0208819   -0.0237527     0.0888272    0.146881    0.0713176   -0.0669249   -0.0339231   -0.00454601   0.246726     0.0684281     0.0165967   -0.296525     0.131066    -0.032919    -0.102757     0.0495879    0.149984     0.0210174   -0.0281353   -0.0987984   -0.164199    -0.0338892
 -0.0489485    -0.0348433   -0.00744971   0.152287    -0.143759    -0.0646413     0.058426    -0.0962028   0.0392351    0.0404177    0.107729     0.0171594    0.0124383    0.0778077     0.162727    -0.0514558    0.0150052    0.16627      0.186492     0.086271    -0.0457103    0.0910199    0.0366258   -0.0627761   -0.110097     0.140006
 -0.0231235    -0.0270624   -0.128275    -0.0133928   -0.0168902   -0.19542      -0.0309598    0.0656293   0.101882    -0.0655188   -0.00109623   0.028427    -0.062106     0.13083       0.0775655    0.0570184    0.133901     0.105578    -0.104597    -0.0304143    0.0156945    0.0577029   -0.031774    -0.0454451   -0.00145201  -0.00669142
 -0.176554      0.0633158    0.197784     0.0061181   -0.0304364   -0.145881     -0.0159752   -0.102635   -0.044456    -0.0430088   -0.128729    -0.0404121    0.130649    -0.0229821     0.0342781    0.00528232   0.0880788    0.0512308   -0.0253253    0.0817138   -0.0309341    0.0182424   -0.0382414   -0.180078     0.167136     0.111708
  0.0398444     0.0569912    0.0843764   -0.104109     0.0461705    0.180148      0.195717     0.0471524   0.0585208    0.0229702   -0.14107      0.0362008    0.0159831   -0.0243383    -0.0327653    0.0152498    0.115621    -0.103239    -0.119396     0.00700652  -0.104874    -0.0387821    0.105415     0.0730493   -0.105177     0.0156468
 -0.0471139     0.0744879    0.00837942  -0.0424062   -0.222973     0.000316567   0.189006    -0.221428   -0.0440261   -0.00585824  -0.00874906  -0.0930529   -0.134808     0.187523      0.0475329    0.132399    -0.0617697    0.0168765   -0.0750153   -0.268642     0.162173     0.0821562   -0.137308     0.110909    -0.265152    -0.0887427
  0.0382248     0.0126439    0.174699    -0.0992798   -0.0551611   -0.106486      0.160822    -0.0651661  -0.237572     0.00209405   0.050712    -0.0102809   -0.0630829    0.0537575    -0.0435465   -0.0398982    0.122611     0.0940649    0.0993098   -0.0643715   -0.00666446   0.101463     0.0768293    0.0155437    0.103312     0.0552142
 -0.00604975   -0.0145921    0.0415191   -0.141932     0.0354801   -0.00282688   -0.182086     0.0562912  -0.00908969  -0.155576    -0.104131     0.0935521   -0.020519     0.00694437   -0.106791    -0.123947    -0.0429309    0.00696689   0.0065043   -0.0352776    0.00289364   0.00688109  -0.039452    -0.0425647    0.00931133   0.140576
 -0.197938     -0.0229339    0.107796     0.00343407  -0.0246992    0.09024      -0.00623233  -0.0381575  -0.149071    -0.0964084   -0.0347617    0.0420982   -0.081833     0.0181654    -0.0279885   -0.00566482  -0.0924363    0.0259771    0.0761505    0.0967576   -0.0761386   -0.0616912    0.062753     0.00117339  -0.0950161   -0.192527
  0.0788983     0.0861897    0.166724     0.157067     0.144143    -0.206885     -0.122117    -0.0915609   0.140323     0.0409842    0.0733695    0.00159724   0.119748     0.163029     -0.0945955   -0.0515523    0.00978975  -0.108827    -0.133069     0.0118562    0.0834898    0.00779548   0.0805752    0.0559813   -0.0462581   -0.00440986
 -0.00428756   -0.0922065    0.0338621    0.0358714    0.0760745   -0.0702972    -0.0831061    0.154725    0.191981     0.0277424    0.0164493   -0.132689    -0.0401315    0.0266128    -0.12684      0.0150204    0.0533101   -0.0756318   -0.0290233    0.131195    -0.013184    -0.0881195    0.00174682  -0.0166525   -0.140747    -0.0205139
  0.142252      0.00187688  -0.0873196    0.112252     0.0115156   -0.0257246    -0.0529185    0.182911   -0.0320658    0.19202     -0.0838943   -0.0194494    0.246584     0.178843     -0.0788777   -0.0159228   -0.106184    -0.0717914    0.104911     0.0706849   -0.0605506    0.0682439   -0.0232155    0.0611634    0.00829424  -0.0285785
  0.0072932     0.30543     -0.022125     0.155519     0.14789     -0.191117     -0.0419947    0.0143979  -0.208196    -0.0249256    0.00678817  -0.0254777    0.105451    -0.0509563     0.0608922   -0.0574437   -0.247633    -0.0250046    0.0906141   -0.10462      0.0168897    0.0835884   -0.0143203   -0.0518957    0.107019     0.112894
  0.0102395    -0.0493875    0.0106242    0.0462178    0.0146507    0.0238452    -0.173339     0.1092     -0.0350499   -0.0819337   -0.109568    -0.195757    -0.0136196    0.104094     -0.0773148    0.00503955  -0.083586    -0.0435236    0.106119     0.206131     0.0576289    0.314589    -0.156438     0.00114154   0.0495902    0.203815
 -0.0488419     0.0467434    0.0164132   -0.0201788    0.0880637   -0.00658723   -0.12068      0.148691    0.174877     0.00852021   0.112186     0.139773     0.0682478    0.161887     -0.00204695   0.0971312    0.201232     0.0873648   -0.00251297   0.0399882    0.160182    -0.061952     0.053037     0.0253113    0.173595    -0.123194
 -0.020449      0.0336287    0.0928362   -0.128981     0.0243766    0.00924658   -0.0504497    0.209996   -0.0267381   -0.0134462    0.132841    -0.00668726   0.0694285   -0.143341     -0.0507866    0.073478     0.192967     0.0249527   -0.030348     0.0243504    0.086695    -0.0681095   -0.0603947   -0.0514944    0.0453646    0.0298084
 -0.113724     -0.0491788   -0.140719     0.199736    -0.125891     0.110374     -0.0925908    0.0545158  -0.0427883   -0.0257799    0.0104345   -0.0966204   -0.0175451   -0.0190177     0.136827     0.0311996    0.0162476    0.125834    -0.172148    -0.226271    -0.0317663    0.0928408    0.0740731   -0.167888    -0.0202576    0.0280997
  0.0817434    -0.0775818   -0.16659     -0.213003    -0.00856163  -0.0909373    -0.00622966   0.258985   -0.0309534    0.158501     0.0333966   -0.260662    -0.0901283   -0.0680076    -0.163909     0.111859    -0.0903945    0.017362     0.0818796    0.135391     0.0140833    0.158711    -0.167353     0.116419     0.0975983   -0.178758
 -0.000580334   0.040154    -0.0644594   -0.0510975    0.0443789    0.0355889     0.00801604   0.0356153  -0.102067     0.00474542  -0.0660454    0.074694     0.0324458    0.0140547     0.0875073   -0.0479083    0.210271     0.00333405   0.0863571    0.0508376   -0.0068338   -0.00948163  -0.0419601   -0.0130966    0.00920859   0.342696kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3996273223687203
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.399711
[ Info: iteration 2, average log likelihood -1.399628
[ Info: iteration 3, average log likelihood -1.398738
[ Info: iteration 4, average log likelihood -1.389622
[ Info: iteration 5, average log likelihood -1.372186
[ Info: iteration 6, average log likelihood -1.366191
[ Info: iteration 7, average log likelihood -1.363667
[ Info: iteration 8, average log likelihood -1.361607
[ Info: iteration 9, average log likelihood -1.360285
[ Info: iteration 10, average log likelihood -1.359462
[ Info: iteration 11, average log likelihood -1.358893
[ Info: iteration 12, average log likelihood -1.358462
[ Info: iteration 13, average log likelihood -1.358105
[ Info: iteration 14, average log likelihood -1.357796
[ Info: iteration 15, average log likelihood -1.357514
[ Info: iteration 16, average log likelihood -1.357228
[ Info: iteration 17, average log likelihood -1.356930
[ Info: iteration 18, average log likelihood -1.356656
[ Info: iteration 19, average log likelihood -1.356426
[ Info: iteration 20, average log likelihood -1.356247
[ Info: iteration 21, average log likelihood -1.356112
[ Info: iteration 22, average log likelihood -1.356003
[ Info: iteration 23, average log likelihood -1.355905
[ Info: iteration 24, average log likelihood -1.355814
[ Info: iteration 25, average log likelihood -1.355735
[ Info: iteration 26, average log likelihood -1.355666
[ Info: iteration 27, average log likelihood -1.355599
[ Info: iteration 28, average log likelihood -1.355526
[ Info: iteration 29, average log likelihood -1.355454
[ Info: iteration 30, average log likelihood -1.355384
[ Info: iteration 31, average log likelihood -1.355321
[ Info: iteration 32, average log likelihood -1.355271
[ Info: iteration 33, average log likelihood -1.355235
[ Info: iteration 34, average log likelihood -1.355210
[ Info: iteration 35, average log likelihood -1.355193
[ Info: iteration 36, average log likelihood -1.355181
[ Info: iteration 37, average log likelihood -1.355173
[ Info: iteration 38, average log likelihood -1.355168
[ Info: iteration 39, average log likelihood -1.355165
[ Info: iteration 40, average log likelihood -1.355162
[ Info: iteration 41, average log likelihood -1.355161
[ Info: iteration 42, average log likelihood -1.355160
[ Info: iteration 43, average log likelihood -1.355159
[ Info: iteration 44, average log likelihood -1.355159
[ Info: iteration 45, average log likelihood -1.355158
[ Info: iteration 46, average log likelihood -1.355158
[ Info: iteration 47, average log likelihood -1.355158
[ Info: iteration 48, average log likelihood -1.355158
[ Info: iteration 49, average log likelihood -1.355158
[ Info: iteration 50, average log likelihood -1.355158
┌ Info: EM with 100000 data points 50 iterations avll -1.355158
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.399711437449663
│     -1.3996281323200241
│      ⋮
└     -1.3551578030734541
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.355287
[ Info: iteration 2, average log likelihood -1.355151
[ Info: iteration 3, average log likelihood -1.354016
[ Info: iteration 4, average log likelihood -1.343402
[ Info: iteration 5, average log likelihood -1.322228
[ Info: iteration 6, average log likelihood -1.314210
[ Info: iteration 7, average log likelihood -1.311914
[ Info: iteration 8, average log likelihood -1.310749
[ Info: iteration 9, average log likelihood -1.309915
[ Info: iteration 10, average log likelihood -1.309160
[ Info: iteration 11, average log likelihood -1.308444
[ Info: iteration 12, average log likelihood -1.307803
[ Info: iteration 13, average log likelihood -1.307245
[ Info: iteration 14, average log likelihood -1.306755
[ Info: iteration 15, average log likelihood -1.306329
[ Info: iteration 16, average log likelihood -1.305971
[ Info: iteration 17, average log likelihood -1.305680
[ Info: iteration 18, average log likelihood -1.305452
[ Info: iteration 19, average log likelihood -1.305279
[ Info: iteration 20, average log likelihood -1.305154
[ Info: iteration 21, average log likelihood -1.305068
[ Info: iteration 22, average log likelihood -1.305012
[ Info: iteration 23, average log likelihood -1.304977
[ Info: iteration 24, average log likelihood -1.304956
[ Info: iteration 25, average log likelihood -1.304944
[ Info: iteration 26, average log likelihood -1.304937
[ Info: iteration 27, average log likelihood -1.304932
[ Info: iteration 28, average log likelihood -1.304929
[ Info: iteration 29, average log likelihood -1.304928
[ Info: iteration 30, average log likelihood -1.304927
[ Info: iteration 31, average log likelihood -1.304926
[ Info: iteration 32, average log likelihood -1.304926
[ Info: iteration 33, average log likelihood -1.304925
[ Info: iteration 34, average log likelihood -1.304925
[ Info: iteration 35, average log likelihood -1.304925
[ Info: iteration 36, average log likelihood -1.304925
[ Info: iteration 37, average log likelihood -1.304925
[ Info: iteration 38, average log likelihood -1.304925
[ Info: iteration 39, average log likelihood -1.304925
[ Info: iteration 40, average log likelihood -1.304925
[ Info: iteration 41, average log likelihood -1.304925
[ Info: iteration 42, average log likelihood -1.304925
[ Info: iteration 43, average log likelihood -1.304925
[ Info: iteration 44, average log likelihood -1.304925
[ Info: iteration 45, average log likelihood -1.304925
[ Info: iteration 46, average log likelihood -1.304925
[ Info: iteration 47, average log likelihood -1.304925
[ Info: iteration 48, average log likelihood -1.304925
[ Info: iteration 49, average log likelihood -1.304925
[ Info: iteration 50, average log likelihood -1.304925
┌ Info: EM with 100000 data points 50 iterations avll -1.304925
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3552868622711223
│     -1.3551505365785597
│      ⋮
└     -1.3049245991548684
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.305131
[ Info: iteration 2, average log likelihood -1.304941
[ Info: iteration 3, average log likelihood -1.304330
[ Info: iteration 4, average log likelihood -1.298339
[ Info: iteration 5, average log likelihood -1.279424
[ Info: iteration 6, average log likelihood -1.263497
[ Info: iteration 7, average log likelihood -1.257626
[ Info: iteration 8, average log likelihood -1.254405
[ Info: iteration 9, average log likelihood -1.252681
[ Info: iteration 10, average log likelihood -1.251719
[ Info: iteration 11, average log likelihood -1.251158
[ Info: iteration 12, average log likelihood -1.250868
[ Info: iteration 13, average log likelihood -1.250706
[ Info: iteration 14, average log likelihood -1.250586
[ Info: iteration 15, average log likelihood -1.250472
[ Info: iteration 16, average log likelihood -1.250350
[ Info: iteration 17, average log likelihood -1.250206
[ Info: iteration 18, average log likelihood -1.250019
[ Info: iteration 19, average log likelihood -1.249762
[ Info: iteration 20, average log likelihood -1.249402
[ Info: iteration 21, average log likelihood -1.248881
[ Info: iteration 22, average log likelihood -1.248136
[ Info: iteration 23, average log likelihood -1.247275
[ Info: iteration 24, average log likelihood -1.246625
[ Info: iteration 25, average log likelihood -1.246191
[ Info: iteration 26, average log likelihood -1.245884
[ Info: iteration 27, average log likelihood -1.245646
[ Info: iteration 28, average log likelihood -1.245445
[ Info: iteration 29, average log likelihood -1.245274
[ Info: iteration 30, average log likelihood -1.245129
[ Info: iteration 31, average log likelihood -1.244995
[ Info: iteration 32, average log likelihood -1.244849
[ Info: iteration 33, average log likelihood -1.244658
[ Info: iteration 34, average log likelihood -1.244386
[ Info: iteration 35, average log likelihood -1.244001
[ Info: iteration 36, average log likelihood -1.243521
[ Info: iteration 37, average log likelihood -1.243014
[ Info: iteration 38, average log likelihood -1.242510
[ Info: iteration 39, average log likelihood -1.242028
[ Info: iteration 40, average log likelihood -1.241577
[ Info: iteration 41, average log likelihood -1.241194
[ Info: iteration 42, average log likelihood -1.240911
[ Info: iteration 43, average log likelihood -1.240735
[ Info: iteration 44, average log likelihood -1.240639
[ Info: iteration 45, average log likelihood -1.240589
[ Info: iteration 46, average log likelihood -1.240562
[ Info: iteration 47, average log likelihood -1.240547
[ Info: iteration 48, average log likelihood -1.240538
[ Info: iteration 49, average log likelihood -1.240533
[ Info: iteration 50, average log likelihood -1.240530
┌ Info: EM with 100000 data points 50 iterations avll -1.240530
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3051307297711527
│     -1.3049414449042243
│      ⋮
└     -1.2405304730466256
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.240813
[ Info: iteration 2, average log likelihood -1.240501
[ Info: iteration 3, average log likelihood -1.238711
[ Info: iteration 4, average log likelihood -1.219498
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.182423
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.175618
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.157683
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.159833
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.159668
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.149536
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.151831
[ Info: iteration 12, average log likelihood -1.177471
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.154287
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     6
│     7
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.142529
[ Info: iteration 15, average log likelihood -1.166826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.148988
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.154520
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.152133
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.142391
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.157226
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.155655
[ Info: iteration 22, average log likelihood -1.153447
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.132009
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.156609
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.156723
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.149394
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.139267
[ Info: iteration 28, average log likelihood -1.153254
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.141082
[ Info: iteration 30, average log likelihood -1.169589
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.148609
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.142819
[ Info: iteration 33, average log likelihood -1.153058
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.130743
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.159170
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.155855
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.142287
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.137183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.144171
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.145430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.148735
[ Info: iteration 42, average log likelihood -1.155300
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.132351
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.134283
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.154730
[ Info: iteration 46, average log likelihood -1.141408
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.124580
[ Info: iteration 48, average log likelihood -1.160265
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.141847
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.146945
┌ Info: EM with 100000 data points 50 iterations avll -1.146945
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2408128900752593
│     -1.240501325188576
│      ⋮
└     -1.1469449402726066
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.148117
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.128599
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.119534
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.126410
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.084539
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     14
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074951
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      9
│     15
│      ⋮
│     20
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.087589
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     10
│     11
│     12
│      ⋮
│     21
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.086037
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     20
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079713
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     10
│     11
│     12
│      ⋮
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.071321
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     21
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.065115
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     10
│     11
│     12
│      ⋮
│     20
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.078997
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      9
│     15
│     16
│     17
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.080890
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      8
│     10
│     11
│      ⋮
│     21
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.064190
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      9
│     13
│      ⋮
│     20
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.061322
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│     11
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.070755
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      9
│     12
│      ⋮
│     21
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.060534
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     20
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087749
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     17
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.054140
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     21
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.076581
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     16
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.058266
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.078902
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.037716
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.089501
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     17
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.038595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     20
│     21
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.076323
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     15
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.062088
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     11
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065895
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.028967
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     12
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.070231
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.039283
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     11
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.080776
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.039832
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.077332
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.040788
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│     10
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.076620
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.033278
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     10
│     11
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.068002
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034637
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.070908
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.050022
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     11
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065799
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.029261
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     10
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079764
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.031864
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     11
│     17
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.064804
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.041689
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     10
│     26
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.074965
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.047937
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.065168
┌ Info: EM with 100000 data points 50 iterations avll -1.065168
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1481171993572055
│     -1.1285993779200123
│      ⋮
└     -1.0651681747796793
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3996273223687203
│     -1.399711437449663
│     -1.3996281323200241
│     -1.3987381157946597
│      ⋮
│     -1.0749651565267309
│     -1.0479371529302588
└     -1.0651681747796793
32×26 Array{Float64,2}:
  0.0463032     0.069287    -0.203595    -0.131397     0.0965317   -0.124486     0.0129283   -0.0827137    -0.0637709   -0.0278741   -0.0433137   -0.143188    -0.087503    -0.198334     -0.115495     0.301788     0.113254    0.0344765    0.0508522    -0.0523679   -0.0187938    0.0828488   -0.11595       0.238636     0.164313     0.0671782
 -0.0962836     0.0616161   -0.0715944   -0.0186649   -0.191316     0.0143375   -0.0551225   -0.00831935    0.0490754    0.00989998   0.132662    -0.0676669    0.0112656    0.049924      0.0814261    0.100509     0.132981    0.0109024    0.0135284     0.0933788   -0.123178     0.119761    -0.0726631     0.0204333   -0.0818242    0.0203389
  0.00618905    0.157002    -0.0721769   -0.0417853   -0.301854    -0.00747793  -0.0692253    0.0931537     0.106588     0.0837771   -0.0498142    0.0442085    0.07244      0.0919054     0.135304    -0.131911    -0.0789739  -0.0394223    0.0628253     0.0803672    0.198593     0.055607    -0.119758      0.0532859    0.0657869    0.0350279
  0.0170656    -0.0444687   -0.0157468    0.0447313   -0.00210789   0.0376275   -0.167165     0.109894     -0.0352197   -0.0886646   -0.105066    -0.193315    -0.0159672    0.129341     -0.135051     0.0057506   -0.0682437  -0.0614531    0.0954891     0.199023     0.0558439    0.305517    -0.138061      0.0181483    0.0555307    0.184276
  0.017859      0.00764236  -0.0810255   -0.0997196   -0.125581    -0.0469386    0.0998604    0.000261264  -0.035213     0.109476    -0.0113082   -0.194538    -0.0889791    0.0753159    -0.0478469    0.116541    -0.0853481   0.0232356    0.0054325    -0.0688941    0.119144     0.11982     -0.172672      0.109907    -0.0896333   -0.137441
  0.00680448    0.0643022    0.110988     0.0835291   -0.0200607   -0.0505157   -0.0497357   -0.0153535     0.0387561    0.0593864    0.108873    -0.0253502    0.0348079    0.12506      -0.0540211   -0.0107581    0.0610159  -0.018996    -0.0641773     0.00870793   0.0148237   -0.0176063    0.0286139    -0.00348947  -0.1338       0.0118488
 -0.0986098     0.0148784   -0.0456561    0.178556     0.0528801    0.0992633    0.0645823    0.143345     -0.0235177    0.1784      -0.0407477    0.0392689   -0.0374356   -0.0134337     0.0140194    0.00449955   0.0429884  -0.241011    -0.0417602     0.255428     0.0158415   -0.131888     0.0228266    -0.0875199    0.0161447    0.00158753
  0.0393452     0.0674174    0.0789062   -0.109281     0.0495471    0.210209     0.201279     0.0483354     0.070832     0.0249016   -0.131354    -0.00651097   0.0115795   -0.0264827    -0.0356395    0.0222322    0.132911   -0.128169    -0.111527      0.00757225  -0.100359    -0.038085     0.107236      0.0697397   -0.103585     0.0243624
 -0.0557155     0.180142    -0.00523454   0.00469493   0.118341    -0.0154688   -0.0590003    0.014796      0.0650905   -0.0171081   -0.0307577    0.0236083   -0.0152398   -0.005127      0.0231971   -0.160776    -0.045782   -0.788832     0.0160307     0.132464     0.306731     0.0215538    0.0836186     0.164812    -0.0104537   -0.00820589
  0.149799      0.191822     0.0854221   -0.0792853    0.128814    -0.0178108   -0.0606346    0.0735991     0.0644077   -0.00568548  -0.00408275  -0.111101    -0.0520654    0.0292878     0.0665951    0.00140684  -0.0462255  -0.0260199    0.0153228     0.129346    -0.032995     0.0161695   -0.000893971   0.163644     0.0101313   -0.0498329
  0.173376     -0.0732872   -0.187823     0.064855     0.0617665   -0.0858731   -0.0378191   -0.07169       0.0210094    0.0632086   -0.0160031   -0.0231362   -0.0962727    0.137256     -0.164432     0.0511261    0.0673366  -0.0547628    0.0671211     0.0507017   -0.0211536    0.166371     0.0860197    -0.150803     0.0269612   -0.00278342
 -0.205591      0.0436336    0.187292    -0.0135663   -0.0369085   -0.162153    -0.0250528   -0.0963352    -0.0292135   -0.04567     -0.127202    -0.02757      0.124471    -0.0111078    -0.00122413   0.0114684    0.0957444   0.0424272   -0.0204829     0.0802165   -0.00169525   0.00300666  -0.0491359    -0.162212     0.161069     0.108103
  0.0103364    -0.015691     0.0444425   -0.152275     0.0285267   -0.00619157  -0.169024     0.0579141    -0.00859488  -0.15613     -0.116585     0.0985956   -0.0190345    0.0028646    -0.106468    -0.0883947   -0.039313    0.00701543   0.0202847    -0.0350196   -0.00398734   0.0262744   -0.0351288    -0.0412476    0.0104827    0.136623
 -0.0509272    -0.0333182   -0.00435652   0.156006    -0.142241    -0.0672799    0.0464954   -0.118323      0.036953     0.0317735    0.118812     0.0105238    0.0112535    0.0742973     0.139696    -0.0492135    0.0102845   0.153121     0.174189      0.0821936   -0.0489215    0.080945     0.0619705    -0.0588823   -0.107824     0.137853
 -0.0486651     0.0307369   -0.0272206   -0.0127181    0.084644     0.0134064   -0.119742     0.0950964     0.134649     0.0333272    0.256418     0.150207     0.0435865   -0.199674     -0.00796839   0.184561     0.202686    0.0906303   -0.000112734   0.00761614   0.161044    -0.1506       0.0727747     0.0237396    0.0903275   -0.201827
 -0.0479741     0.0590127    0.0540314   -0.0370998    0.081947    -0.0171329   -0.121906     0.230716      0.239034     0.00259316  -0.038792     0.122721     0.134419     0.828422      0.00168783  -0.197989     0.197722    0.0791042   -0.00706175    0.0792649    0.163164     0.0179596    0.0305844     0.0245003    0.409895    -0.0360312
  0.0608464    -0.0496527   -0.167177    -0.0391278    0.0588372   -0.0867494   -0.19179     -0.136079     -0.156732     0.0466769    0.145247    -0.237238     0.0139549   -0.171991     -0.00322705   0.0346484    0.0151017   0.0819367   -0.107446      0.0385731   -0.101761     0.00793745  -0.41744      -0.00755194   0.119398    -0.0379957
  0.0822883    -0.0517796   -0.0747554   -0.0599631    0.0876922    0.116628     0.0692439   -0.126138     -0.0222163    0.0523892    0.151971     0.454781     0.0208115   -0.175684     -0.0476537    0.0481871    0.0151254   0.0410162   -0.106205      0.0206243    0.0201146   -0.00307191   0.0421544     0.061063     0.196198     0.00733207
  0.152811     -0.0118916    0.0306065   -0.0455467   -0.0446741    0.0793111   -0.057961    -0.0116765    -0.125764    -0.0800062   -0.0146586   -0.0782998   -0.164489     0.0202538     0.155807     0.0426993   -0.0272607   0.00305486   0.00446152    0.24373      0.140956    -0.18145     -0.0964527     0.0794989    0.0708132    0.109412
 -0.190113      0.00538884   0.106542     0.00803109   0.0209158    0.081464     0.00756569  -0.0506059    -0.142598    -0.101867    -0.0341939    0.0432046   -0.0806498    0.0310639    -0.0121604   -0.0116039   -0.0944384   0.0236443    0.071368      0.0821842   -0.0621387   -0.0514038    0.0570393     0.00609266  -0.0857605   -0.191584
  0.00341153    0.292198    -0.0062229    0.14095      0.129209    -0.215156    -0.0445116    0.0206697    -0.281968    -0.00230158   0.00969066  -0.0209546    0.105521    -0.0315289     0.0621681   -0.0534017   -0.231515   -0.0262482    0.11008      -0.104678     0.0137669    0.0923079   -0.0209061    -0.0503316    0.124795     0.10503
  0.0326318    -0.0209248    0.192821    -0.0692522   -0.0710122   -0.136103     0.199228    -0.00618814   -0.210273     0.00462233   0.0573094   -0.0195611   -0.0613272    0.0704808    -0.0481913   -0.0398611    0.122271    0.0981669    0.0839527    -0.0629759    0.005478     0.077646     0.0702511     0.0133569    0.104989     0.0519383
 -0.0254301     0.0343125    0.0621331   -0.128155     0.0412224    0.00908947  -0.0526981    0.20535      -0.00564859  -0.0351541    0.132296    -0.00741126   0.0706213   -0.12949      -0.0610517    0.0680618    0.200284    0.00184729  -0.0121436     0.0348288    0.077363    -0.0363031   -0.0617818    -0.0458162    0.0372235    0.0257215
  0.00185443    0.0316269   -0.0982141   -0.0511841    0.0503873    0.0411971    0.00968262   0.0344747    -0.102459     0.00229684  -0.0672271    0.0923575    0.00137881  -0.000207966   0.0849393   -0.0407592    0.222273    0.00867265   0.0667235     0.0358439    0.00638452  -0.0121566   -0.0461076    -0.00766307   0.0188439    0.349266
 -0.0893553    -0.0486884   -0.175963     0.195597    -0.140053     0.06675     -0.0702806    0.0531528    -0.0572361    0.0112201    0.0181659   -0.096931    -0.0168041   -0.0212744     0.122922     0.0369698    0.0477318   0.123298    -0.159714     -0.219205    -0.0389585    0.0889233    0.0698145    -0.17288     -0.0363022    0.0294269
 -0.0203798    -0.027628    -0.102609    -0.0103033   -0.013703    -0.226497    -0.0380205    0.065875      0.0964397   -0.0633981    0.00340135   0.0307499   -0.0665056    0.0903893     0.0699588    0.0530582    0.137334    0.0939016   -0.109705     -0.0271059    0.025598     0.0519392   -0.0327009    -0.0495072   -0.00826755  -0.00867709
 -0.0293192     0.0819353    0.0717038    0.0684148   -0.0796825   -0.0921426   -0.0372788    0.0148198    -0.0632713    0.0302893   -0.00706836   0.0416452   -0.173099     0.0940648    -0.00236187   0.0402391   -0.0852359  -0.0247992    0.0232654    -0.00939593  -0.0173795    0.0359187    0.00902864   -0.11179      0.143357    -0.0453835
  0.0645221    -0.0567344    0.0470899    0.0584253    0.0531955   -0.0371257   -0.0546966    0.175002      0.105453     0.0787845   -0.0655633   -0.0658465    0.0331764    0.123663     -0.10558      0.0148814    0.0125331  -0.115415     0.00915781    0.107457    -0.104174    -0.00648134  -0.0121487     0.00833401  -0.078772    -0.0195637
 -0.0363344    -0.0209554    0.0804839    0.0829774   -0.0847727    0.02619      0.140569     0.0402065     0.12103      0.00306154  -0.028185     0.114164    -0.0488471    0.00852731   -0.0819879    0.073134     0.0585912   0.106056     0.0510122    -0.0794094    0.0365839    0.349792     0.0509865    -0.0555829   -0.186311    -0.0613163
 -0.101297      0.03302      0.012202     0.0779781   -0.0224526    0.0272308    0.100494     0.229024      0.11999      0.0647619    0.0648715    0.0780952    0.00911103   0.00840954    0.0368286    0.0974101    0.0120106   0.096482    -0.0014343     0.0198548    0.0713237   -0.0174909    0.0779093     0.177259    -0.270887     0.0882412
  0.000765256   0.0329374   -0.246008    -0.0886142    0.0253717   -0.0358083    0.150427     0.227834      0.0704791   -0.0688866   -0.0615595   -0.00706675   0.282152     0.0785588    -0.00445437  -0.296655    -0.0958078  -0.0667064   -0.0820209     0.0551946    0.0860745   -0.0263272   -0.0142452    -0.083357    -0.168406    -0.162764
  0.106639     -0.0148875   -0.128436    -0.215275     0.0334927    0.0025034   -0.0520142   -0.0171607     0.0697825   -0.143502     0.0158694    0.006957     0.162092     0.0707899     0.0706094   -0.295906     1.12467     0.0880691   -0.154345      0.0528841    0.305611     0.0879888   -0.0527409    -0.0953503   -0.15833      0.405929[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.025731
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.012629
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.014790
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.003443
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.021128
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.006104
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.003555
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.001084
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     21
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.009103
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.991272
┌ Info: EM with 100000 data points 10 iterations avll -0.991272
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.397669e+05
      1       6.683916e+05      -1.713752e+05 |       32
      2       6.378736e+05      -3.051809e+04 |       32
      3       6.202885e+05      -1.758507e+04 |       32
      4       6.097324e+05      -1.055604e+04 |       32
      5       6.036116e+05      -6.120838e+03 |       32
      6       5.990713e+05      -4.540300e+03 |       32
      7       5.955125e+05      -3.558799e+03 |       32
      8       5.933581e+05      -2.154423e+03 |       32
      9       5.925458e+05      -8.122448e+02 |       32
     10       5.921423e+05      -4.035120e+02 |       32
     11       5.917380e+05      -4.043470e+02 |       32
     12       5.911115e+05      -6.264902e+02 |       32
     13       5.901908e+05      -9.206619e+02 |       32
     14       5.891004e+05      -1.090425e+03 |       32
     15       5.882801e+05      -8.203149e+02 |       32
     16       5.878579e+05      -4.221718e+02 |       32
     17       5.876167e+05      -2.412348e+02 |       32
     18       5.874360e+05      -1.807028e+02 |       32
     19       5.872946e+05      -1.413709e+02 |       32
     20       5.871069e+05      -1.876881e+02 |       32
     21       5.868858e+05      -2.211618e+02 |       32
     22       5.866160e+05      -2.697698e+02 |       32
     23       5.862431e+05      -3.728654e+02 |       32
     24       5.857038e+05      -5.393693e+02 |       32
     25       5.852775e+05      -4.262944e+02 |       32
     26       5.850851e+05      -1.923632e+02 |       32
     27       5.849285e+05      -1.566031e+02 |       32
     28       5.846895e+05      -2.389773e+02 |       31
     29       5.843359e+05      -3.536136e+02 |       31
     30       5.840742e+05      -2.616746e+02 |       31
     31       5.839560e+05      -1.181842e+02 |       32
     32       5.838918e+05      -6.419464e+01 |       31
     33       5.838607e+05      -3.110448e+01 |       31
     34       5.838463e+05      -1.446101e+01 |       28
     35       5.838382e+05      -8.131808e+00 |       27
     36       5.838309e+05      -7.276800e+00 |       27
     37       5.838242e+05      -6.706391e+00 |       28
     38       5.838178e+05      -6.348490e+00 |       26
     39       5.838097e+05      -8.163560e+00 |       26
     40       5.838004e+05      -9.290764e+00 |       28
     41       5.837927e+05      -7.697763e+00 |       29
     42       5.837845e+05      -8.141786e+00 |       30
     43       5.837779e+05      -6.674563e+00 |       24
     44       5.837721e+05      -5.780072e+00 |       27
     45       5.837667e+05      -5.365553e+00 |       24
     46       5.837598e+05      -6.946609e+00 |       26
     47       5.837536e+05      -6.138857e+00 |       30
     48       5.837466e+05      -7.041611e+00 |       26
     49       5.837404e+05      -6.228594e+00 |       25
     50       5.837342e+05      -6.173607e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 583734.1768990292)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290162
[ Info: iteration 2, average log likelihood -1.256400
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.230158
[ Info: iteration 4, average log likelihood -1.204784
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.150867
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.106055
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     17
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.108249
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.081485
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.077643
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     17
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.041904
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083767
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.072847
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.066689
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     17
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.045111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077165
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     11
│     16
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.036705
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.073167
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│     17
│     20
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.043455
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.080370
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     11
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.042070
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.051138
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     17
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.044964
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.078647
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     11
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.058300
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.046162
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     12
│     16
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.047183
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.097247
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067433
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.021200
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     12
│     20
│     27
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.022167
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.090475
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     11
│     17
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.038141
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.055272
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     27
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.037887
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.069479
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│     11
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.049624
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.041785
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     17
│     21
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.031245
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.082948
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     11
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.037842
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.054808
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.061807
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.049124
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     11
│      ⋮
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.998728
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     24
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.082264
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.104832
[ Info: iteration 48, average log likelihood -1.056716
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     18
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.992872
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.085086
┌ Info: EM with 100000 data points 50 iterations avll -1.085086
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.01855      0.199738     0.0366987    0.0929338    0.111819    -0.171019     0.00530188    0.0267556   -0.217763    -0.00742902  -0.0102407   -0.0074185    0.0809254   -0.0437576     0.0393474   -0.0229308   -0.189655    -0.0268596    0.0338628    -0.0646153   -0.0157438     0.0826269    0.00985856  -0.0217879    0.0677182    0.0586176
  0.100422     0.165231     0.0661541   -0.0581394    0.12106     -0.0167417   -0.0515842     0.0614207    0.0678936   -0.00587076  -0.00559453  -0.0816138   -0.0490281    0.0156543     0.0513075   -0.0136194   -0.0446131   -0.155732     0.00932748    0.121584     0.017656      0.0156821    0.0192795    0.15837     -0.0147643   -0.0400012
  0.00606348   0.16139     -0.0712857   -0.04095     -0.302881    -0.0114099   -0.0688371     0.0931039    0.105729     0.0834651   -0.0475719    0.0429567    0.0697787    0.0908295     0.135476    -0.132015    -0.0761303   -0.0373951    0.0610507     0.0801914    0.19939       0.0559844   -0.11914      0.0525978    0.065158     0.0373086
  0.138901    -0.0366169   -0.255088     0.00501794   0.0467396   -0.0784558    0.0246742     0.0604653    0.0838658    0.0197781    0.0446436   -0.0255135   -0.173689     0.145881     -0.121671     0.0536064    0.0806282    0.0197051   -0.0379531     0.0756551   -0.0279154     0.141938     0.0977237   -0.043579    -0.00297921  -0.0298154
 -0.0509852   -0.0342297   -0.00466128   0.154947    -0.142516    -0.0668379    0.0479116    -0.122674     0.0407525    0.0349156    0.124167     0.0136237    0.00980002   0.0717576     0.145878    -0.0466358    0.0145474    0.153934     0.175188      0.082084    -0.0520327     0.0806306    0.0499992   -0.0599183   -0.108534     0.136387
 -0.0572688   -0.0878837    0.184988     0.0248156    0.0680839   -0.0272589   -0.0910516     0.137336     0.189131     0.0301728   -0.0183994   -0.153068     0.00373577   0.106776     -0.143709     0.0399453    0.0607388   -0.167742    -0.0115172     0.0947397   -0.088884     -0.0895977    0.0677469   -0.0205965   -0.140052    -0.0219254
 -0.224863     0.00221436   0.120486    -0.0083751   -0.00997089   0.081097     0.0229381    -0.0851435   -0.152021    -0.111959    -0.0192705    0.0486853   -0.0796303    0.0375431    -0.0395654   -0.0161444   -0.0960367    0.0258073    0.0544667     0.0568298   -0.0694951    -0.0601332    0.105675     0.00562574  -0.221342    -0.225591
 -0.016628     0.0446052   -0.113172    -0.0514078    0.0521058    0.0289296   -0.00375668    0.0299307   -0.0940534    0.00218673  -0.0593506    0.0804588    0.00208466   0.00688891    0.0898792   -0.0354294    0.202942     0.011724     0.0534294     0.0250379    0.00643374   -0.00866888  -0.0414238   -0.0117983    0.029671     0.327531
 -0.0867555    0.0532949    0.0562783    0.0353404   -0.100952     0.114145     0.0176087     0.0411853   -0.0724781    0.0850822    0.173766    -0.0312638   -0.0798686    0.0733578    -0.0169234    0.0297775    0.129486     0.0801329   -0.0346708    -0.00600548  -0.0715301    -0.0320878   -0.0312715   -0.0614397   -0.26033      0.0337429
  0.0830794    0.0797837    0.194408     0.141883     0.0564316   -0.206814    -0.112371     -0.089664     0.150222     0.00709307   0.0852664   -0.00200391   0.123405     0.179749     -0.0871445   -0.0499702    0.00824151  -0.0971009   -0.119538     -0.00276528   0.101964      0.00504662   0.0888855    0.045185    -0.0456511    0.00863671
  0.0516888    0.0454393    0.115598    -0.127424     0.048068     0.211931     0.207509      0.0338806    0.108403     0.0175521   -0.143535     0.0204658    0.0218883   -0.0220327    -0.0470605   -0.00324165   0.287045    -0.133658    -0.098511      0.011416    -0.0995316    -0.0444757    0.107596     0.0550106   -0.115416     0.0174465
  0.0827061   -0.0823092   -0.170472    -0.213234    -0.0129188   -0.0909247   -0.000141493   0.247142    -0.0258301    0.205608     0.020338    -0.252774    -0.080976    -0.0701998    -0.173443     0.109558    -0.103073     0.0184432    0.107372      0.152621     0.0398626     0.158088    -0.201584     0.116192     0.0972791   -0.177367
 -0.100807     0.00551262   0.0504545    0.160716     0.0731842    0.0328809    0.106995     -1.45786      0.122197     0.0312587    0.0167884    0.0748278   -0.0987563    0.0636965    -0.0130378    0.08955      0.12515      0.089993     0.11392      -0.125973     0.0311857    -0.0902648    0.10338     -0.0586621   -0.253464     0.0761362
 -0.0258341    0.0349303    0.0643102   -0.127978     0.0412155    0.00950432  -0.0531807     0.202837    -0.00508061  -0.0348233    0.132099    -0.00738043   0.0705682   -0.130041     -0.0601583    0.0673538    0.199508     0.00122739  -0.0121258     0.0351038    0.0775864    -0.0362846   -0.061827    -0.0455723    0.0370177    0.0250061
  0.153676    -0.00719704  -0.0872561    0.109576     0.0116352   -0.0160661   -0.0327541     0.183363    -0.0250941    0.157485    -0.153219    -0.0194179    0.248007     0.21093      -0.107212    -0.0228855   -0.0871591   -0.0865905    0.0960952     0.07994     -0.0709052     0.0576722   -0.0320354    0.0628822    2.93901e-5  -0.0282991
 -0.0312164    0.06553     -0.131681    -0.0733853   -0.0531866   -0.0541732   -0.0213573    -0.0463618   -0.00583469  -0.00671263   0.0501255   -0.103279    -0.0387885   -0.0707473    -0.00891605   0.198448     0.123386     0.0248574    0.0273447     0.0213589   -0.0730999     0.100715    -0.0936255    0.125263     0.0369439    0.0424328
  0.0595392   -0.0582575   -0.102543    -0.0597158    0.0827064    0.0767359   -0.0209908    -0.151511    -0.056337     0.0238686    0.115347     0.195344    -0.0099545   -0.159017     -0.0358346    0.0344875    0.0255701    0.0598543   -0.0839448     0.0252812   -0.033035      0.00736774  -0.156937     0.031957     0.167368    -0.0297277
 -0.0479181   -0.0608657   -0.176015     0.00309237   0.0157054   -0.234341    -0.0405436     0.100058     0.137462    -0.0358502   -0.00906046   0.0180649   -0.0867686    0.11611       0.0699687    0.0592341    0.141314     0.0662326   -0.0794425     0.0316932    0.0120878     0.0256654   -0.0411158   -0.056229    -0.0671956   -0.016773
 -0.0836643    0.0214711    0.00682897   0.0330026   -0.0891704    0.0264012    0.114338      0.971115     0.119928     0.0499741    0.0473953    0.103384     0.0455753   -0.0132724     0.0275426    0.0863108   -0.0316439    0.103       -0.0407316     0.048355     0.076645      0.146221     0.0617208    0.200343    -0.252466     0.022305
  0.0646125   -0.0454985   -0.0851717    0.0506142    0.0247526   -0.0120842   -0.124276      0.0276193   -0.013682    -0.0434723   -0.0796818   -0.120925    -0.0363687    0.118543     -0.143281     0.029073    -0.0130734   -0.0672135    0.0929175     0.127066     0.0279135     0.243031    -0.0621737   -0.0611269    0.0504417    0.120463
 -0.254301     0.040692     0.188928    -0.032919    -0.048125    -0.139044    -0.0868706    -0.0971347   -0.0584958   -0.0436526   -0.125027    -0.00532344   0.121766     0.0526133     0.0368241   -0.0234047    0.0970519    0.088051     0.022566      0.0788036   -0.0782609     0.0438125   -0.0672782   -0.189183     0.145211     0.0949058
  0.0071099    0.0565737    0.0496384   -0.142509    -0.0914739   -0.140377     0.0137131    -0.0259992   -0.0821115   -0.0628123    0.0135855   -0.117821    -0.259206     0.0251255     0.0210248    0.122798    -0.0602355   -0.159208     0.041851      0.0309741    0.157793     -0.0953034    0.115383    -0.021852     0.129085     0.0429592
 -0.0431873    0.0563409   -0.0126446   -0.0258554   -0.2242      -0.0255136    0.178342     -0.187933    -0.0206029   -0.00795201  -0.0327169   -0.248637    -0.129227     0.184967      0.0582314    0.146548    -0.0289605    0.0354623   -0.0880208    -0.229706     0.182982      0.0866684   -0.123037     0.104833    -0.22266     -0.111925
  0.0165925   -0.0184993    0.043433    -0.14404      0.0283264   -0.00652253  -0.171722      0.0572242   -0.00402229  -0.156078    -0.111436     0.0997356   -0.0205872    0.00688493   -0.103508    -0.0933951   -0.0306251    0.0126618    0.0200613    -0.035234    -0.000756476   0.0321177   -0.0353511   -0.0432083    0.00172279   0.142846
  0.0305062    0.00516053  -0.00977747  -0.0930443   -0.0211755   -0.0811906    0.146167      0.0740184   -0.0747459   -0.0400866    0.0103965   -0.00687753   0.0895171    0.0700263    -0.0177569   -0.160901     0.172478     0.0289246   -0.010781     -0.0109999    0.0637407     0.0451883    0.0251167   -0.0327152   -0.0294725    0.0157483
 -0.174688     0.0484452    0.068459     0.212578    -0.111697    -0.0403585   -0.150184      0.00211474  -0.10018      0.0685845    0.0268336    0.133219     0.0354177    0.193218     -0.0155368   -0.0226823   -0.145097     0.0473087    0.0661593    -0.0263239   -0.173464      0.0880085   -0.0173323   -0.133645     0.131961    -0.175545
 -0.104629     0.00834504  -0.0459949    0.157849     0.0446805    0.106937     0.074651      0.129468    -0.0282643    0.137054    -0.0329482    0.044272    -0.0387542   -0.0112265     0.018373    -0.00878594   0.0433452   -0.21667     -0.0363989     0.221708     0.0129436    -0.131853     0.0249409   -0.0714161   -0.00304377   0.00490137
  0.112407     0.125919     0.173292     0.0759919    0.0188759   -0.0664613    0.0662046     0.0769319    0.0314791    0.0600444   -0.0881762    0.115018    -0.349821    -0.0283026    -0.0200279    0.0237554    0.0049602    0.0325714   -0.108796     -0.0153243   -0.0142311     0.0922753   -0.115687    -0.175044     0.110298     0.00339389
 -0.0920125   -0.0463969   -0.17177      0.185337    -0.136572     0.0351626   -0.0733127     0.0537057   -0.040221     0.00442001   0.0127617   -0.0909341   -0.0176551    0.000740586   0.129799     0.0369742    0.0487039    0.123402    -0.158591     -0.205647    -0.0344838     0.0864621    0.066845    -0.166341    -0.0303464    0.0269357
  0.152215    -0.0108957    0.0340412   -0.0470252   -0.0440546    0.0789241   -0.0571844    -0.0146584   -0.127004    -0.0776399   -0.0125723   -0.0733526   -0.160451     0.0250586     0.160521     0.0397315   -0.0304696    0.00481915   0.00655416    0.237701     0.14155      -0.183447    -0.0871125    0.0778648    0.0624242    0.109411
 -0.0487019    0.0376524    0.00583054  -0.0245556    0.0840478    0.00236157  -0.122421      0.144371     0.175809     0.0172957    0.149633     0.141386     0.073468     0.157475     -0.00513643   0.046742     0.20391      0.0895312   -0.000464703   0.0300424    0.157608     -0.0970938    0.0578271    0.0231687    0.203159    -0.140328
 -0.198693     0.0509729    0.196718    -0.005322    -0.0386905   -0.175183     0.0200387    -0.106362    -0.0212937   -0.0427184   -0.127855    -0.0355975    0.13114     -0.0286271    -0.0162396    0.0202979    0.0969257    0.0291345   -0.0337362     0.0818172    0.0141797    -0.00837122  -0.0428004   -0.15649      0.178763     0.114809[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.079846
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.019218
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.984229
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     17
│     18
│     21
│     27
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.033325
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.033813
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.973380
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     17
│     18
│     21
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.022397
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.027992
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│     11
│     12
│      ⋮
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.991010
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      6
│     17
│     21
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.024839
┌ Info: EM with 100000 data points 10 iterations avll -1.024839
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0865985   -0.0165739   -0.00968602    0.189798    -0.0788912    0.22724       0.15094      0.0262723   -0.10487     -0.21052     -0.0307424    0.0370552  -0.00364515    0.075717     -0.175614     0.0804576    -0.0213453    -0.091794     0.000710623   0.00456395  -0.00947049  -0.145916      0.0845806   -0.130472     0.0217422   -0.0226012
 -0.10453      0.0425381   -0.0235056    -0.0301045   -0.0232239   -0.00935567   -0.0577694    0.00651031  -0.119356    -0.193559     0.0237688   -0.0868827  -0.106128     -0.0741697     0.133864    -0.133106      0.053554      0.0220357    0.0891025    -0.0830711   -0.0690123   -0.151207      0.0309521    0.0746575   -0.15273      0.0802119
 -0.0990389   -0.0427022    0.15243      -0.00348585  -0.105126    -0.0214389     0.0507987    0.0780973    0.155734    -0.041132     0.11565     -0.0250628   0.123909      0.0994117     0.0171348    0.0443375    -0.377057     -0.0883298    0.0464533     0.0705124   -0.0747612   -0.0704711     0.0738895   -0.00838167   0.184124     0.021353
 -0.240161     0.0835717   -0.0122447    -0.0697802    0.0015394   -0.096774     -0.00893991   0.0361675   -0.158242     0.0562971    0.125675    -0.0432255  -0.0327676     0.0117743     0.147283     0.0860696    -0.0883387     0.0622958    0.0710628    -0.022787    -0.0944811   -0.0368094    -0.078114    -0.00756113   0.180201     0.141066
 -0.065625     0.0541206   -0.111946      0.0404757    0.0124516    0.0390579     0.13115     -0.00988033  -0.0837918   -0.152778    -0.0898535   -0.0662008   0.0209318     0.0244274     0.0194862    0.0375252     0.0500246     0.0449514   -0.0519783    -0.0507673    0.0423466    0.072658      0.00925182  -0.0839846    0.0629576   -0.00803271
 -0.0235812   -0.0535215    0.257266     -0.162079     0.0253567    0.0309626    -0.0768879   -0.0922067   -0.03669      0.015227    -0.0506611   -0.0435989  -0.1813       -0.0865747    -0.0822011    0.112375      0.111996     -0.0132457   -0.0442905     0.0555365   -0.13937      0.0302292    -0.219135     0.0242172   -0.0583067   -0.0539887
 -0.094359     0.0904089   -0.192551     -0.129339     0.0676405   -0.0684182    -0.0242831   -0.10222     -0.0300868   -0.113569     0.0976394    0.0107208  -0.235643      0.0331889     0.180603    -0.171431      0.16619       0.143312    -0.0505995    -0.09246     -0.169728     0.133046      0.0178297    0.0933374   -0.0457556   -0.045426
  0.0144333   -0.0992582   -0.152816      0.106965     0.031968     0.0188187    -0.0692702   -0.0150048    0.106102     0.0137417    0.0143195   -0.165624   -0.137318     -0.00396744    0.0641584    0.0285534     0.146808     -0.0553719    0.0891742    -0.132728     0.0683969    0.00684047    0.195458    -0.072125    -0.10156     -0.00596839
 -0.0303949    0.049289    -0.0979072    -0.145649     0.0164201   -0.100207      0.125008     0.104411     0.0157152    0.0695397   -0.00928982   0.0109915  -0.227756      0.0706972     0.0547781    0.0206142     0.181751     -0.0418959   -0.0998366    -0.032322    -0.0762056    0.118825      0.0858043    0.110642    -0.00275896  -0.0276461
  0.0458304    0.00228342  -0.0668175    -0.0744842    0.0177624    0.061382     -0.0314655   -0.150531    -0.0129414   -0.00470306  -0.0563301    0.0376429  -0.0306603    -0.0749072     0.185818    -0.0245893    -0.000107711   0.249232    -0.132976     -0.0796551   -0.0694784    0.0321593     0.0207314   -0.269995     0.00719819  -0.050598
  0.030118     0.0264931    0.000555018  -0.0863143    0.0445028   -0.0068103     0.19419      0.0610652   -0.0106835    0.00624579   0.0654313    0.0452463  -0.113856     -0.144652      7.72892e-5   0.000339785   0.120348     -0.0299261   -0.000916727  -0.0845619   -0.0261027   -0.113531      0.0847858   -0.0933163    0.036206     0.0371192
 -0.0710809   -0.00839277   0.149965     -0.00449341   0.147091     0.00317909    0.0490201   -0.113368    -0.0203857   -0.0431995   -0.125483    -0.12094     0.00632173   -0.0480764     0.199574     0.159412     -0.171205      0.106676     0.0393729    -0.0736514   -0.0203423   -0.0875403     0.171007    -0.323123    -0.0539602    0.189495
  0.113313    -0.035888    -0.0444593     0.152384    -0.00935493  -0.0906136    -0.0480568   -0.114695     0.0630776   -0.0121988    0.0217132   -0.149222   -0.0173766     0.0639983     0.0172921   -0.0125055     0.0545617     0.0358923   -0.155807     -0.0607907   -0.0979419    0.0268598    -0.160739    -0.0776019   -0.0295326    0.175491
 -0.0514894    0.140583     0.0598327     0.064801     0.0749016   -0.176389      0.234594    -0.0286225   -0.1877       0.00284414   0.0296914    0.257315   -0.147532      0.000828897   0.0124335   -0.0375528    -0.16194       0.0523105    0.13413       0.189486     0.0794216    0.0603843     0.0899077    0.0950758   -0.0776222   -0.0393138
  0.0380838   -0.15168     -0.0113106     0.171854     0.111349    -0.0794229    -0.0632988    0.0459239   -0.164754    -0.19384     -0.017458     0.0137439   0.0639671     0.15229      -0.0160585   -0.305155      0.011062      0.0790788   -0.270111     -0.0622373   -0.174692     0.000147139  -0.0314223   -0.0142722    0.126204     0.0677733
  0.0596204   -0.0365262    0.0602635     0.0188836   -0.00646964  -0.0619802    -0.09332      0.17061     -0.0401883    0.069962     0.184838    -0.0401341   0.102479     -0.0444852    -0.162359    -0.159447      0.0692083    -0.0718765   -0.183634      0.035176    -0.113861     0.117016      0.0602246   -0.0167308   -0.065552    -0.0010167
 -0.00823585   0.157512     0.0859056    -0.0553603   -0.117849    -0.125649     -0.0780153    0.114088    -0.00582753  -0.0671873   -0.0445584   -0.0726194  -0.0491512     0.223536      0.0614529    0.0116851     0.0994044    -0.133077    -0.0246413     0.0636603   -0.0431819    0.145512     -0.150147     0.0268421    0.119391    -0.052016
  0.00700762   0.00190062   0.0148951    -0.0671022   -0.00888029  -0.0475453     0.0917988    0.14461      0.0160467    0.148313    -0.0692838   -0.230649    0.205997      0.0214055    -0.0911607    0.0427345     0.0955869    -0.0287644   -0.0449728     0.0106717   -0.0698739    0.0852739     0.1563       0.178045    -0.0791325    0.160822
 -0.0787275    0.0372884    0.114742     -0.0100437   -0.0493015   -0.0912029    -0.186575    -0.0928835    0.00282314  -0.0766656    0.107208    -0.0277075   0.00523349   -0.0966125    -0.0673872   -0.00537973   -0.0165755     0.00638512   0.093766      0.116808     0.0414673    0.0785408     0.0367764   -0.00647064  -0.199938    -0.0613796
 -0.240627    -0.0929891    0.0346556    -0.134292     0.0230265    0.0956445     0.0443916   -0.211765     0.00318115   0.0118577    0.0646734    0.109463   -0.114065     -0.0689297    -0.06959     -0.000653774  -0.0470675    -0.0211112   -0.169586     -0.160286    -0.0174946   -0.0036517    -0.0435924    0.0693552    0.0827597   -0.27925
  0.208505    -0.0654399   -0.00401951    0.0288037   -0.0290065   -0.137132      0.0916422   -0.0376422    0.0974233    0.0609102   -0.0220001   -0.0929131   0.00277482   -0.0416589     0.0733904   -0.151616     -0.0908219    -0.00636549   0.0058287     0.101955     0.0167821    0.0631271     0.209863    -0.121489     0.0380884   -0.123862
 -0.0217472   -0.217073    -0.0932932    -0.071519     0.249551    -0.0534175     0.0683528   -0.0311764    0.070681    -0.0268066    0.0579747   -0.0541003   0.000147295   0.168698      0.0258535   -0.0593573     0.0118928     0.0127877    0.0513676     0.0589343   -0.0234134   -0.0912305    -0.0751303    0.147376     0.148241    -0.0752796
 -0.0110898    0.104423    -0.0503202     0.0176537    0.108218     0.093605     -0.0587993   -0.096643    -0.0777911   -0.057387     0.208875     0.0379703  -0.00472956    0.0264598    -0.0246132   -0.0631281     0.0182531    -0.00096357   0.187984     -0.0220628    0.0731275   -0.0286396    -0.0395894    0.185179    -0.0870208    0.235066
  0.103048     0.0806248   -0.0236605    -0.0267862    0.243858     0.0689609    -0.222248    -0.0658713   -0.0116246    0.196415    -0.0229739    0.149925   -0.127592      0.0640586     0.105953     0.0174472    -0.0616462    -0.144951    -0.0175442     0.040099    -0.0743063   -0.00868009   -0.0422054   -0.21847     -0.0165975    0.0031696
 -0.0190119    0.0481137   -0.0211153    -0.0622198    0.167478    -0.0675375    -0.0932687    0.0999968    0.0397958    0.10216     -0.123059    -0.0340746  -0.045771     -0.044201      0.0981546    0.35849      -0.171091      0.0163439   -0.0830795     0.0401948   -0.030501     0.0113264     0.189331     0.0412675    0.137381    -0.0204712
  0.0955906   -0.0630552    0.00688588   -0.0229176   -0.128826     0.0147907    -0.0633639    0.0519753   -0.0427768   -0.0494472    0.0711112   -0.0393909  -0.157539      0.056788      0.0195661    0.0749519     0.0751823     0.0769139    0.180899     -0.189852    -0.0521012   -0.0125909     0.0954815   -0.169158    -0.0354835    0.108372
 -0.0746005   -0.147874     0.0758631    -0.153931     0.0681259    0.066931     -0.113907     0.05382      0.0465765   -0.20857     -0.0960403   -0.0047261   0.0754047    -0.00333543   -0.018123    -0.0887483     0.13314       0.213703    -0.0739695    -0.018537     0.086823     0.0901682    -0.0954328   -0.0734424    0.107318     0.0693819
  0.0461005    0.0213382   -0.0971424    -0.131764     0.0420121    0.132024      0.00534006   0.00624385  -0.139722     0.019876    -0.0464998    0.0107187   0.0660329     0.0668269     0.0849149    0.130355     -0.0802883     0.00472096   0.0247161     0.0899294    0.0534099   -0.000653722  -0.0420221    0.0877154   -0.0162609    0.0501409
 -0.1166       0.0421282   -0.0487008     0.0881417   -0.186843    -0.000221481  -0.0336047    0.111416     0.00823236   0.0166879    0.156104    -0.0771517   0.0651515    -0.0112292    -0.0533412    0.059968     -0.219102     -0.0849404   -0.214788      0.0355928   -0.0839987   -0.0321207     0.0961795    0.121472     0.0884057   -0.144442
  0.0355977   -0.0543387   -0.0689633     0.0237457    0.0711808   -0.0353701     0.00606164  -0.0135713   -0.195698     0.0399683    0.11978      0.15213     0.0683948     0.0815872    -0.0127442   -0.0473907    -0.217873     -0.0508862    0.00464744    0.0652343   -0.0700377   -0.0596428    -0.0639345    0.0278235    0.272489     0.0576943
  0.0252392    0.0212462    0.062301      0.0147668   -0.165813    -0.096336      0.0216668   -0.0662437    0.0886993   -0.145487    -0.0951785    0.140762    0.0287252    -0.127933     -0.088918     0.121556      0.129682     -0.042206     0.123461      0.056571     0.00377288   0.00746365   -0.0702616    0.154722     0.0763249    0.0307595
 -0.198081    -0.0190325    0.136626      0.150003     0.042957     0.00995481   -0.0278058   -0.123151    -0.0478244   -0.0414828   -0.149763    -0.0860601   0.0324617    -0.0121888     0.00686      0.0420894    -0.0372672     0.0365981   -0.0762968    -0.124043     0.098623    -0.176274      0.0401262    0.151998     0.0765382    0.147135kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4257334877843315
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425752
[ Info: iteration 2, average log likelihood -1.425697
[ Info: iteration 3, average log likelihood -1.425656
[ Info: iteration 4, average log likelihood -1.425607
[ Info: iteration 5, average log likelihood -1.425546
[ Info: iteration 6, average log likelihood -1.425468
[ Info: iteration 7, average log likelihood -1.425367
[ Info: iteration 8, average log likelihood -1.425226
[ Info: iteration 9, average log likelihood -1.425002
[ Info: iteration 10, average log likelihood -1.424599
[ Info: iteration 11, average log likelihood -1.423897
[ Info: iteration 12, average log likelihood -1.422882
[ Info: iteration 13, average log likelihood -1.421823
[ Info: iteration 14, average log likelihood -1.421066
[ Info: iteration 15, average log likelihood -1.420669
[ Info: iteration 16, average log likelihood -1.420494
[ Info: iteration 17, average log likelihood -1.420421
[ Info: iteration 18, average log likelihood -1.420391
[ Info: iteration 19, average log likelihood -1.420378
[ Info: iteration 20, average log likelihood -1.420372
[ Info: iteration 21, average log likelihood -1.420370
[ Info: iteration 22, average log likelihood -1.420368
[ Info: iteration 23, average log likelihood -1.420367
[ Info: iteration 24, average log likelihood -1.420367
[ Info: iteration 25, average log likelihood -1.420366
[ Info: iteration 26, average log likelihood -1.420366
[ Info: iteration 27, average log likelihood -1.420366
[ Info: iteration 28, average log likelihood -1.420365
[ Info: iteration 29, average log likelihood -1.420365
[ Info: iteration 30, average log likelihood -1.420365
[ Info: iteration 31, average log likelihood -1.420365
[ Info: iteration 32, average log likelihood -1.420365
[ Info: iteration 33, average log likelihood -1.420365
[ Info: iteration 34, average log likelihood -1.420364
[ Info: iteration 35, average log likelihood -1.420364
[ Info: iteration 36, average log likelihood -1.420364
[ Info: iteration 37, average log likelihood -1.420364
[ Info: iteration 38, average log likelihood -1.420364
[ Info: iteration 39, average log likelihood -1.420364
[ Info: iteration 40, average log likelihood -1.420364
[ Info: iteration 41, average log likelihood -1.420364
[ Info: iteration 42, average log likelihood -1.420364
[ Info: iteration 43, average log likelihood -1.420364
[ Info: iteration 44, average log likelihood -1.420364
[ Info: iteration 45, average log likelihood -1.420364
[ Info: iteration 46, average log likelihood -1.420364
[ Info: iteration 47, average log likelihood -1.420363
[ Info: iteration 48, average log likelihood -1.420363
[ Info: iteration 49, average log likelihood -1.420363
[ Info: iteration 50, average log likelihood -1.420363
┌ Info: EM with 100000 data points 50 iterations avll -1.420363
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4257519018039804
│     -1.4256965850126249
│      ⋮
└     -1.4203634144653183
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420378
[ Info: iteration 2, average log likelihood -1.420322
[ Info: iteration 3, average log likelihood -1.420277
[ Info: iteration 4, average log likelihood -1.420224
[ Info: iteration 5, average log likelihood -1.420158
[ Info: iteration 6, average log likelihood -1.420077
[ Info: iteration 7, average log likelihood -1.419983
[ Info: iteration 8, average log likelihood -1.419880
[ Info: iteration 9, average log likelihood -1.419777
[ Info: iteration 10, average log likelihood -1.419680
[ Info: iteration 11, average log likelihood -1.419595
[ Info: iteration 12, average log likelihood -1.419525
[ Info: iteration 13, average log likelihood -1.419470
[ Info: iteration 14, average log likelihood -1.419427
[ Info: iteration 15, average log likelihood -1.419394
[ Info: iteration 16, average log likelihood -1.419368
[ Info: iteration 17, average log likelihood -1.419346
[ Info: iteration 18, average log likelihood -1.419327
[ Info: iteration 19, average log likelihood -1.419310
[ Info: iteration 20, average log likelihood -1.419295
[ Info: iteration 21, average log likelihood -1.419281
[ Info: iteration 22, average log likelihood -1.419268
[ Info: iteration 23, average log likelihood -1.419256
[ Info: iteration 24, average log likelihood -1.419245
[ Info: iteration 25, average log likelihood -1.419235
[ Info: iteration 26, average log likelihood -1.419226
[ Info: iteration 27, average log likelihood -1.419217
[ Info: iteration 28, average log likelihood -1.419209
[ Info: iteration 29, average log likelihood -1.419202
[ Info: iteration 30, average log likelihood -1.419195
[ Info: iteration 31, average log likelihood -1.419189
[ Info: iteration 32, average log likelihood -1.419184
[ Info: iteration 33, average log likelihood -1.419179
[ Info: iteration 34, average log likelihood -1.419174
[ Info: iteration 35, average log likelihood -1.419170
[ Info: iteration 36, average log likelihood -1.419166
[ Info: iteration 37, average log likelihood -1.419163
[ Info: iteration 38, average log likelihood -1.419159
[ Info: iteration 39, average log likelihood -1.419156
[ Info: iteration 40, average log likelihood -1.419154
[ Info: iteration 41, average log likelihood -1.419151
[ Info: iteration 42, average log likelihood -1.419149
[ Info: iteration 43, average log likelihood -1.419147
[ Info: iteration 44, average log likelihood -1.419145
[ Info: iteration 45, average log likelihood -1.419143
[ Info: iteration 46, average log likelihood -1.419141
[ Info: iteration 47, average log likelihood -1.419139
[ Info: iteration 48, average log likelihood -1.419138
[ Info: iteration 49, average log likelihood -1.419137
[ Info: iteration 50, average log likelihood -1.419135
┌ Info: EM with 100000 data points 50 iterations avll -1.419135
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4203783626104136
│     -1.4203218753387057
│      ⋮
└     -1.4191353309388401
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419145
[ Info: iteration 2, average log likelihood -1.419096
[ Info: iteration 3, average log likelihood -1.419054
[ Info: iteration 4, average log likelihood -1.419007
[ Info: iteration 5, average log likelihood -1.418949
[ Info: iteration 6, average log likelihood -1.418877
[ Info: iteration 7, average log likelihood -1.418791
[ Info: iteration 8, average log likelihood -1.418693
[ Info: iteration 9, average log likelihood -1.418590
[ Info: iteration 10, average log likelihood -1.418489
[ Info: iteration 11, average log likelihood -1.418394
[ Info: iteration 12, average log likelihood -1.418310
[ Info: iteration 13, average log likelihood -1.418238
[ Info: iteration 14, average log likelihood -1.418179
[ Info: iteration 15, average log likelihood -1.418131
[ Info: iteration 16, average log likelihood -1.418092
[ Info: iteration 17, average log likelihood -1.418061
[ Info: iteration 18, average log likelihood -1.418034
[ Info: iteration 19, average log likelihood -1.418012
[ Info: iteration 20, average log likelihood -1.417992
[ Info: iteration 21, average log likelihood -1.417975
[ Info: iteration 22, average log likelihood -1.417959
[ Info: iteration 23, average log likelihood -1.417944
[ Info: iteration 24, average log likelihood -1.417930
[ Info: iteration 25, average log likelihood -1.417918
[ Info: iteration 26, average log likelihood -1.417905
[ Info: iteration 27, average log likelihood -1.417894
[ Info: iteration 28, average log likelihood -1.417882
[ Info: iteration 29, average log likelihood -1.417872
[ Info: iteration 30, average log likelihood -1.417861
[ Info: iteration 31, average log likelihood -1.417851
[ Info: iteration 32, average log likelihood -1.417842
[ Info: iteration 33, average log likelihood -1.417832
[ Info: iteration 34, average log likelihood -1.417823
[ Info: iteration 35, average log likelihood -1.417815
[ Info: iteration 36, average log likelihood -1.417806
[ Info: iteration 37, average log likelihood -1.417798
[ Info: iteration 38, average log likelihood -1.417791
[ Info: iteration 39, average log likelihood -1.417784
[ Info: iteration 40, average log likelihood -1.417777
[ Info: iteration 41, average log likelihood -1.417770
[ Info: iteration 42, average log likelihood -1.417763
[ Info: iteration 43, average log likelihood -1.417757
[ Info: iteration 44, average log likelihood -1.417751
[ Info: iteration 45, average log likelihood -1.417746
[ Info: iteration 46, average log likelihood -1.417740
[ Info: iteration 47, average log likelihood -1.417735
[ Info: iteration 48, average log likelihood -1.417731
[ Info: iteration 49, average log likelihood -1.417726
[ Info: iteration 50, average log likelihood -1.417721
┌ Info: EM with 100000 data points 50 iterations avll -1.417721
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4191453000695096
│     -1.4190955880268084
│      ⋮
└     -1.4177214556103808
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417726
[ Info: iteration 2, average log likelihood -1.417669
[ Info: iteration 3, average log likelihood -1.417619
[ Info: iteration 4, average log likelihood -1.417562
[ Info: iteration 5, average log likelihood -1.417495
[ Info: iteration 6, average log likelihood -1.417414
[ Info: iteration 7, average log likelihood -1.417318
[ Info: iteration 8, average log likelihood -1.417210
[ Info: iteration 9, average log likelihood -1.417093
[ Info: iteration 10, average log likelihood -1.416973
[ Info: iteration 11, average log likelihood -1.416855
[ Info: iteration 12, average log likelihood -1.416743
[ Info: iteration 13, average log likelihood -1.416641
[ Info: iteration 14, average log likelihood -1.416551
[ Info: iteration 15, average log likelihood -1.416472
[ Info: iteration 16, average log likelihood -1.416404
[ Info: iteration 17, average log likelihood -1.416346
[ Info: iteration 18, average log likelihood -1.416296
[ Info: iteration 19, average log likelihood -1.416253
[ Info: iteration 20, average log likelihood -1.416214
[ Info: iteration 21, average log likelihood -1.416180
[ Info: iteration 22, average log likelihood -1.416148
[ Info: iteration 23, average log likelihood -1.416119
[ Info: iteration 24, average log likelihood -1.416092
[ Info: iteration 25, average log likelihood -1.416066
[ Info: iteration 26, average log likelihood -1.416042
[ Info: iteration 27, average log likelihood -1.416019
[ Info: iteration 28, average log likelihood -1.415996
[ Info: iteration 29, average log likelihood -1.415975
[ Info: iteration 30, average log likelihood -1.415955
[ Info: iteration 31, average log likelihood -1.415935
[ Info: iteration 32, average log likelihood -1.415917
[ Info: iteration 33, average log likelihood -1.415899
[ Info: iteration 34, average log likelihood -1.415882
[ Info: iteration 35, average log likelihood -1.415865
[ Info: iteration 36, average log likelihood -1.415849
[ Info: iteration 37, average log likelihood -1.415834
[ Info: iteration 38, average log likelihood -1.415819
[ Info: iteration 39, average log likelihood -1.415805
[ Info: iteration 40, average log likelihood -1.415791
[ Info: iteration 41, average log likelihood -1.415778
[ Info: iteration 42, average log likelihood -1.415765
[ Info: iteration 43, average log likelihood -1.415753
[ Info: iteration 44, average log likelihood -1.415741
[ Info: iteration 45, average log likelihood -1.415730
[ Info: iteration 46, average log likelihood -1.415719
[ Info: iteration 47, average log likelihood -1.415708
[ Info: iteration 48, average log likelihood -1.415698
[ Info: iteration 49, average log likelihood -1.415688
[ Info: iteration 50, average log likelihood -1.415678
┌ Info: EM with 100000 data points 50 iterations avll -1.415678
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4177257862587498
│     -1.4176694144950277
│      ⋮
└     -1.4156779005050424
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415677
[ Info: iteration 2, average log likelihood -1.415611
[ Info: iteration 3, average log likelihood -1.415549
[ Info: iteration 4, average log likelihood -1.415476
[ Info: iteration 5, average log likelihood -1.415387
[ Info: iteration 6, average log likelihood -1.415276
[ Info: iteration 7, average log likelihood -1.415144
[ Info: iteration 8, average log likelihood -1.414993
[ Info: iteration 9, average log likelihood -1.414829
[ Info: iteration 10, average log likelihood -1.414660
[ Info: iteration 11, average log likelihood -1.414493
[ Info: iteration 12, average log likelihood -1.414334
[ Info: iteration 13, average log likelihood -1.414188
[ Info: iteration 14, average log likelihood -1.414056
[ Info: iteration 15, average log likelihood -1.413939
[ Info: iteration 16, average log likelihood -1.413836
[ Info: iteration 17, average log likelihood -1.413747
[ Info: iteration 18, average log likelihood -1.413670
[ Info: iteration 19, average log likelihood -1.413602
[ Info: iteration 20, average log likelihood -1.413542
[ Info: iteration 21, average log likelihood -1.413489
[ Info: iteration 22, average log likelihood -1.413442
[ Info: iteration 23, average log likelihood -1.413398
[ Info: iteration 24, average log likelihood -1.413359
[ Info: iteration 25, average log likelihood -1.413322
[ Info: iteration 26, average log likelihood -1.413288
[ Info: iteration 27, average log likelihood -1.413256
[ Info: iteration 28, average log likelihood -1.413226
[ Info: iteration 29, average log likelihood -1.413197
[ Info: iteration 30, average log likelihood -1.413171
[ Info: iteration 31, average log likelihood -1.413145
[ Info: iteration 32, average log likelihood -1.413121
[ Info: iteration 33, average log likelihood -1.413098
[ Info: iteration 34, average log likelihood -1.413076
[ Info: iteration 35, average log likelihood -1.413055
[ Info: iteration 36, average log likelihood -1.413035
[ Info: iteration 37, average log likelihood -1.413016
[ Info: iteration 38, average log likelihood -1.412998
[ Info: iteration 39, average log likelihood -1.412981
[ Info: iteration 40, average log likelihood -1.412965
[ Info: iteration 41, average log likelihood -1.412949
[ Info: iteration 42, average log likelihood -1.412934
[ Info: iteration 43, average log likelihood -1.412920
[ Info: iteration 44, average log likelihood -1.412907
[ Info: iteration 45, average log likelihood -1.412894
[ Info: iteration 46, average log likelihood -1.412882
[ Info: iteration 47, average log likelihood -1.412871
[ Info: iteration 48, average log likelihood -1.412859
[ Info: iteration 49, average log likelihood -1.412849
[ Info: iteration 50, average log likelihood -1.412839
┌ Info: EM with 100000 data points 50 iterations avll -1.412839
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4156773543872205
│     -1.415611126494633
│      ⋮
└     -1.4128387428667317
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4257334877843315
│     -1.4257519018039804
│     -1.4256965850126249
│     -1.4256561318193388
│      ⋮
│     -1.41285949707946
│     -1.412848901786089
└     -1.4128387428667317
32×26 Array{Float64,2}:
  0.311756     0.188992   -0.0465709    0.0926917    0.411347    -0.413412     0.244685   -0.0902018    0.931381   -0.40634      0.403159    -0.420001   -0.885408   -0.204213    -0.106082   -0.249684   -0.179686     0.477034     0.136277    -0.0982421  -0.066812    -0.506252    0.551681    -0.668928    -0.313632   -0.334908
 -0.181627     0.28674    -0.0175381   -0.0944677    0.418226    -0.0398575    0.0202723  -0.338724    -0.0286083  -0.181995     0.14509     -0.33927     0.353439   -0.462437     0.71091    -0.22625    -0.170479     0.483579     0.19116      0.145043   -0.442201    -0.167048   -0.170047    -0.250759    -1.07723    -0.0337816
 -0.257627    -0.191336   -0.0699241    0.132354    -0.00448474   0.073787    -0.276903   -0.251466     0.165323   -0.457179    -0.225853    -0.543286    0.0215356   0.324354    -0.232801    0.124235    0.103845     0.12938     -0.55021      0.387411    0.802119    -0.277581   -0.102277     0.0721375    0.162943    0.0427914
  0.10321     -0.195299    0.132934    -0.531878     1.35039      0.424801     0.290647    0.171597    -0.630085   -0.393401    -0.434729    -0.479908    0.057751    0.261192     0.55279     0.425562    0.244355     0.0783024   -0.386738    -0.0962477   0.143762     0.0339775  -0.0819427   -0.519751    -0.0173713  -0.523185
 -0.704315    -0.188859    0.00767615   0.559551     0.314232    -0.126287    -0.351418    0.344469    -0.052958   -0.0563219    0.191412    -0.149596    0.525815   -0.723904    -0.0501226   0.779774   -0.0844717    0.760475    -0.20387     -0.408198   -0.385787    -0.603746    0.155967     0.15358      0.0127403  -0.713907
 -1.21628     -0.327597   -0.205219    -0.0124345   -0.23556      0.101095    -0.0129056  -0.470067     0.391197   -0.499157    -0.204984     0.132055   -0.222619   -0.329177    -0.568386    0.0265921   0.0874329    0.461384     0.152229    -0.875653   -0.426239     0.197734   -0.200167    -0.300158     0.468124   -0.542077
  0.101462     0.0331549  -0.0615746   -0.709405     0.226426     0.700506    -0.199186    0.423203    -0.182432   -0.181675     0.131038     0.132773   -0.0440546   0.0520021    0.528643   -0.277132   -0.123147     0.875804    -0.172309    -0.691654   -0.448216    -0.36821    -0.200509    -0.297014     0.72784    -0.534894
 -0.0670662    0.355474    0.419658     1.03631      0.0299734   -0.550066     0.247222   -0.359206     0.353179   -0.039437     0.419226     0.549489    0.0336033  -0.123856     0.185299   -0.156355   -0.129544     0.736122    -0.678591    -0.693233    0.302308     0.213462   -0.157078    -0.657272     0.387304   -0.635548
 -0.267104    -0.245554    0.816665    -0.0643354    0.138335    -0.0166155   -0.109127    0.408628    -0.126618    0.0801605    0.227596    -0.723036    0.0130921   0.201694    -0.40258    -0.396132    0.165501    -0.52558      0.266074    -0.394681   -0.197037     0.515854   -0.233652    -0.274258    -0.0969429  -0.175772
 -0.520321     0.0953518   0.782329    -0.145574     0.0841282   -0.00893474  -0.780028    0.342645     0.407822    0.376885    -0.17812      0.402474    0.218843    0.472536    -0.343342    0.508886    0.555305    -0.120408     0.12226      0.351786   -0.294384     0.279141   -0.715799     0.0644202   -0.145118    0.421541
 -0.372187     0.906814    0.307337    -0.247614    -0.0467488    0.541806    -0.76904    -0.211835    -0.346707    0.231872    -0.290267    -0.0570798  -0.221662   -0.0834298    0.313848   -0.116135    0.247612    -0.674732    -0.051402    -0.61648    -0.076952     0.211375    0.0219176    0.308261     0.549196    0.250671
  0.292064    -0.0999027  -0.140349    -0.585742    -0.042464     0.295207     0.116929   -0.104953    -0.6263      0.744867    -0.00431874   0.080543    0.298012    0.276398     0.67449     0.0284106   0.13462     -0.00319697  -0.477401    -0.0719483  -0.443274     0.318381   -0.275656     0.524562     0.0195757   0.0775228
 -0.320183     0.344744   -0.517825    -0.0435169   -0.267591    -0.191235    -0.30252    -0.505577     0.246217   -0.0597323   -0.632796     0.127578   -0.145424    0.110147     0.284203   -0.268593   -0.412729    -0.0731199   -0.00665328   0.373733   -0.0110818   -0.650175    0.416426     0.446712    -0.113875    0.672624
  0.608467     0.110536   -0.00412481  -0.443146    -0.0444427   -0.271778     0.261177    0.106319    -0.084485    0.371787    -0.0702052   -0.0355279  -0.407137    0.53799      0.128908   -0.504019   -0.0921623   -0.995346     0.345594     0.899835    0.337773     0.309704    0.187239     0.0419812   -0.119874    0.769198
 -0.0322643    0.0388948   0.112364     0.00343926  -0.305305     0.0866443    0.343202    0.134781    -0.123597    0.0748137   -0.0774534    0.445521   -0.559206   -0.530935    -0.172874   -0.0634414  -0.134044     0.0146609    0.350881    -0.233101   -0.159847     0.0111532   0.39332      0.101697     0.213851    0.338444
  0.42588      0.0125134  -0.454785     0.286045    -0.379599    -0.473932    -0.0934923   0.138944     0.146876    0.256067     0.66652      0.194847    0.535168    0.421673    -0.0323603  -0.137407    0.0453391   -0.345832    -0.0522202    0.178477   -0.590537     0.399734   -0.128243     0.332914     0.251007   -0.0683999
 -0.00621571  -0.0417358  -0.0352122   -0.057037     0.0321006   -0.04848     -0.0209001   0.0364007   -0.044508   -0.0639011   -0.13295     -0.0444561  -0.181501   -0.00736053   0.166316   -0.0130679  -0.0202072    0.0945908   -0.0175556   -0.0217959  -0.0763515   -0.295936    0.0647011   -0.0047472   -0.0133311   0.0188404
 -0.0913124    0.062521    0.075228    -0.0464368    0.046827     0.0524556   -0.0661005  -0.0516675   -0.0161876  -0.0242684    0.169988    -0.0986236   0.234917    0.103181    -0.151897    0.010863    0.00932174  -0.131668    -0.0255932   -0.0433808   0.00575809   0.436491   -0.12799     -0.0399512    0.042488   -0.0621022
 -0.360178    -0.187486   -0.104541    -0.199124     0.180546    -0.292938     0.0664268   0.243686    -0.507432   -0.0688369   -0.520393    -0.361451    0.108077    0.0942541    0.220602    0.973719   -0.306303    -0.386306     0.580296     0.593602   -0.248306    -0.27978    -0.0134503    0.188246     0.112296    0.0484441
  0.154829    -0.128929   -0.416079    -0.486152     0.258401     0.986322    -0.382812    0.136381    -0.305654   -0.0110475   -0.47033     -0.422639    0.152725   -0.220379    -0.325068    0.563894    0.299637    -0.154523     0.331295     0.581824    0.0966766    0.0375582   0.303218     0.65532     -0.154361    0.507742
 -0.0937058    0.0353143   0.434414     0.0592697   -0.0395231    0.0306354   -0.17839    -0.166803    -0.0671372   0.239731    -0.324666    -0.254704   -0.148148   -0.613583     0.272374    0.209143   -0.0599765    0.32392      0.00886832  -0.120058    0.26536      0.184181    0.644712    -0.44583      0.0484708   0.353631
  0.124288     0.484587   -0.0271911    0.0936496    0.0117194    0.167766     0.213231    0.00742851  -0.255948    0.093254     0.548338     0.761761   -0.229835   -0.651744    -0.0998397  -0.0734459   0.131698     0.080497     0.113245    -0.199614   -0.0339869    0.0142436   0.287859     0.3707       0.161777    0.281738
  0.0532832   -0.421909   -0.119948     0.251639    -0.464193     0.0404463   -0.225542    0.0792863    0.0289028   0.149923    -0.221249     0.0818048  -0.207205    0.531799    -0.368271    0.366402    0.00530181  -0.294885    -0.401169    -0.196946    0.5254       0.178976    0.109771     0.21052      0.909234    0.206268
 -0.00634008   0.137286   -0.444893     0.0483961   -0.060924     0.160535     0.0913971  -0.307721    -0.61445    -0.219433    -0.139263    -0.072777   -0.113932   -0.0165491    0.162475   -0.187591   -0.55859      0.0692207   -0.554313    -0.360253    0.397049    -0.102744    0.407416    -0.00833952   0.825108   -0.464299
 -0.13984      0.34403     0.0108395   -0.565488     0.28454      0.216966    -0.234519   -0.66555     -0.216285   -0.730282     0.199923    -0.264264   -0.140221    0.33034     -0.261039   -0.579539   -0.221521    -0.306339     0.620172     0.184951    0.410145    -0.253359   -0.557598    -0.429031    -0.411923    0.012081
 -0.494068     0.234367    0.59595     -0.287718    -0.336087    -0.739619     0.207532   -0.0560998   -0.34944    -0.272157     0.359247     0.254092   -0.518858   -0.0196491    0.533443   -0.156193   -0.231562    -0.392564     0.532279    -0.215279   -0.747787    -0.293913   -0.435298    -0.478882    -0.333805   -0.138191
  0.257079    -0.350338    0.495727    -0.144968    -0.286304    -0.378824     0.0803154   0.41347      0.460816   -0.00579004   0.208107    -0.0708566  -0.322566    0.254175    -0.0230857  -0.609488    0.501229     0.148601    -0.0534019   -0.567191   -0.527664     0.0473612  -0.00912312   0.0781563   -0.265828    0.167738
  0.186652    -0.122727   -0.294485     0.938486    -0.591699    -0.752582     0.552684   -0.238473     0.299743    0.136077     0.317195    -0.0362612   0.0659239  -0.078812     0.284072   -0.441458    0.157706    -0.31034     -0.0115591   -0.0905299  -0.196327     0.0846312   0.134586     0.20198     -0.758322    0.279529
  0.487539    -0.307081   -0.693001     0.4634      -0.0174263   -0.0909084    0.0896671   0.295729     0.402728   -0.0931665   -0.083961     0.602383   -0.1078     -0.255605    -0.161014    0.194927   -0.293827     0.265203     0.134675     0.332541    0.303069    -0.697838    0.0456837   -0.808458    -0.0569312   0.280581
  0.285188    -0.041685   -0.234365     0.576843     0.80626      0.0137752   -0.102336    0.217465     0.216581    0.0180498    0.166855     0.0912146   0.457362    0.528644     0.153072   -0.0142503   0.466954     0.0365165   -0.0891043    0.240184   -0.25411     -0.323739   -0.386316    -0.256092    -0.408513    0.0439237
  0.182202    -0.277767   -0.219544     0.0958447   -0.00192332  -0.559697     0.670795    0.0332444   -0.0760716  -0.692106     0.303383     0.138448    0.162095    0.25081     -0.238714    0.331381   -0.0377544    0.213732    -0.0579316    0.431502   -0.161699    -0.245317   -0.0223892    0.243866    -0.309999   -0.558955
 -0.0345735   -0.280637    0.0940978   -0.0933288    0.192729    -0.0829174    0.341543   -0.214792     0.543493    0.105367     0.127265     0.208825    0.267965    0.114189    -0.431506    0.0742999  -0.301933     0.440138    -0.29402      0.62585     0.379556     0.628183   -0.180144     0.230571    -0.220615   -0.205731[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412829
[ Info: iteration 2, average log likelihood -1.412820
[ Info: iteration 3, average log likelihood -1.412811
[ Info: iteration 4, average log likelihood -1.412802
[ Info: iteration 5, average log likelihood -1.412793
[ Info: iteration 6, average log likelihood -1.412785
[ Info: iteration 7, average log likelihood -1.412777
[ Info: iteration 8, average log likelihood -1.412769
[ Info: iteration 9, average log likelihood -1.412762
[ Info: iteration 10, average log likelihood -1.412754
┌ Info: EM with 100000 data points 10 iterations avll -1.412754
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.300343e+05
      1       7.150406e+05      -2.149937e+05 |       32
      2       6.985754e+05      -1.646514e+04 |       32
      3       6.926229e+05      -5.952519e+03 |       32
      4       6.898242e+05      -2.798706e+03 |       32
      5       6.880310e+05      -1.793249e+03 |       32
      6       6.867197e+05      -1.311289e+03 |       32
      7       6.856997e+05      -1.019951e+03 |       32
      8       6.847589e+05      -9.407846e+02 |       32
      9       6.839169e+05      -8.420608e+02 |       32
     10       6.831499e+05      -7.669470e+02 |       32
     11       6.824610e+05      -6.889257e+02 |       32
     12       6.818650e+05      -5.959805e+02 |       32
     13       6.813481e+05      -5.168882e+02 |       32
     14       6.809427e+05      -4.054746e+02 |       32
     15       6.806006e+05      -3.420910e+02 |       32
     16       6.803261e+05      -2.744506e+02 |       32
     17       6.800781e+05      -2.480373e+02 |       32
     18       6.798689e+05      -2.091986e+02 |       32
     19       6.796954e+05      -1.735177e+02 |       32
     20       6.795358e+05      -1.596113e+02 |       32
     21       6.793905e+05      -1.452825e+02 |       32
     22       6.792441e+05      -1.463815e+02 |       32
     23       6.791146e+05      -1.295102e+02 |       32
     24       6.790013e+05      -1.132541e+02 |       32
     25       6.789014e+05      -9.992550e+01 |       32
     26       6.788120e+05      -8.939084e+01 |       32
     27       6.787352e+05      -7.679194e+01 |       32
     28       6.786574e+05      -7.785162e+01 |       32
     29       6.785828e+05      -7.455172e+01 |       32
     30       6.785046e+05      -7.821202e+01 |       32
     31       6.784295e+05      -7.513728e+01 |       32
     32       6.783609e+05      -6.855338e+01 |       32
     33       6.782949e+05      -6.598009e+01 |       32
     34       6.782316e+05      -6.331006e+01 |       32
     35       6.781727e+05      -5.889555e+01 |       32
     36       6.781218e+05      -5.093127e+01 |       32
     37       6.780737e+05      -4.808845e+01 |       32
     38       6.780259e+05      -4.781298e+01 |       32
     39       6.779830e+05      -4.289167e+01 |       32
     40       6.779372e+05      -4.579237e+01 |       32
     41       6.778924e+05      -4.482690e+01 |       32
     42       6.778513e+05      -4.103528e+01 |       32
     43       6.778103e+05      -4.109582e+01 |       32
     44       6.777682e+05      -4.203235e+01 |       32
     45       6.777286e+05      -3.961709e+01 |       32
     46       6.776862e+05      -4.238436e+01 |       32
     47       6.776455e+05      -4.074270e+01 |       32
     48       6.776114e+05      -3.410489e+01 |       32
     49       6.775759e+05      -3.545364e+01 |       32
     50       6.775449e+05      -3.102581e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677544.8926265417)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425066
[ Info: iteration 2, average log likelihood -1.419984
[ Info: iteration 3, average log likelihood -1.418629
[ Info: iteration 4, average log likelihood -1.417637
[ Info: iteration 5, average log likelihood -1.416582
[ Info: iteration 6, average log likelihood -1.415574
[ Info: iteration 7, average log likelihood -1.414852
[ Info: iteration 8, average log likelihood -1.414436
[ Info: iteration 9, average log likelihood -1.414200
[ Info: iteration 10, average log likelihood -1.414050
[ Info: iteration 11, average log likelihood -1.413941
[ Info: iteration 12, average log likelihood -1.413853
[ Info: iteration 13, average log likelihood -1.413778
[ Info: iteration 14, average log likelihood -1.413712
[ Info: iteration 15, average log likelihood -1.413653
[ Info: iteration 16, average log likelihood -1.413598
[ Info: iteration 17, average log likelihood -1.413547
[ Info: iteration 18, average log likelihood -1.413499
[ Info: iteration 19, average log likelihood -1.413454
[ Info: iteration 20, average log likelihood -1.413412
[ Info: iteration 21, average log likelihood -1.413372
[ Info: iteration 22, average log likelihood -1.413335
[ Info: iteration 23, average log likelihood -1.413300
[ Info: iteration 24, average log likelihood -1.413268
[ Info: iteration 25, average log likelihood -1.413237
[ Info: iteration 26, average log likelihood -1.413209
[ Info: iteration 27, average log likelihood -1.413182
[ Info: iteration 28, average log likelihood -1.413156
[ Info: iteration 29, average log likelihood -1.413133
[ Info: iteration 30, average log likelihood -1.413110
[ Info: iteration 31, average log likelihood -1.413089
[ Info: iteration 32, average log likelihood -1.413069
[ Info: iteration 33, average log likelihood -1.413051
[ Info: iteration 34, average log likelihood -1.413033
[ Info: iteration 35, average log likelihood -1.413016
[ Info: iteration 36, average log likelihood -1.413000
[ Info: iteration 37, average log likelihood -1.412985
[ Info: iteration 38, average log likelihood -1.412971
[ Info: iteration 39, average log likelihood -1.412957
[ Info: iteration 40, average log likelihood -1.412944
[ Info: iteration 41, average log likelihood -1.412932
[ Info: iteration 42, average log likelihood -1.412920
[ Info: iteration 43, average log likelihood -1.412909
[ Info: iteration 44, average log likelihood -1.412898
[ Info: iteration 45, average log likelihood -1.412888
[ Info: iteration 46, average log likelihood -1.412878
[ Info: iteration 47, average log likelihood -1.412869
[ Info: iteration 48, average log likelihood -1.412860
[ Info: iteration 49, average log likelihood -1.412852
[ Info: iteration 50, average log likelihood -1.412843
┌ Info: EM with 100000 data points 50 iterations avll -1.412843
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.256276   -0.202261     0.496857    -0.0341553   -0.240693    -0.246593      0.0405581    0.365385    0.300903     0.0603881    0.259273    -0.121198    -0.247015    0.316957   -0.00617981  -0.755315     0.513223     0.00339654  -0.124008    -0.688495   -0.58137      0.0772713  -0.0455724    0.121347   -0.231322     0.182307
  0.0908395   0.079377    -0.0508493   -0.288235     0.214621     0.0426583     0.208434    -0.76227    -0.0745902    0.0772649   -0.0164512   -0.174479     0.394577   -0.250102    0.58847      0.0900637   -0.608604     0.112824     0.0971628    0.305446   -0.469863     0.738662   -0.0589764   -0.0726093  -0.663098     0.157897
 -0.452591   -0.236882    -0.124827    -0.0367046   -0.20013     -0.022456      0.116835    -0.174883    0.072238    -0.437229    -0.0156158   -0.18045     -0.0279127  -0.0440373  -0.180756     0.217797    -0.0470228    0.125861    -0.039427    -0.324051   -0.218352     0.179894   -0.268082    -0.0693404   0.0566467   -0.421769
 -0.233619    0.853235     0.14749     -0.0202335   -0.222304     0.512301     -0.308719    -0.225419   -0.463531    -0.00567177   0.0201581    0.344657    -0.369393   -0.667971    0.0772629    0.00969173   0.281788    -0.266344     0.156634    -0.454808    0.0335969    0.164442    0.246669     0.569702    0.482646     0.552533
  0.04196    -0.450115    -0.670251    -0.313819     0.0294063    0.698584     -0.61939      0.0316915  -0.187355    -0.0339596   -0.442539    -0.604432     0.353977   -0.279512   -0.347859     0.726089     0.32989     -0.228388     0.275869     0.695008    0.090343     0.0446008   0.140842     0.748835   -0.32965      0.601185
  0.32624     0.123125    -0.0809659   -0.572962     0.264282     0.544141     -0.202599    -0.0276276  -0.461766     0.366981    -0.172432     0.0211285   -0.0507521   0.256031    0.4751      -0.0934066   -0.0556892    0.142654    -0.496309    -0.109739   -0.0763474   -0.241953   -0.1884       0.341601    0.406222    -0.0702595
  0.171229   -0.661928     0.131927    -0.0516645    0.0843679   -0.445702      0.482906     0.180871    0.457911    -0.348802    -0.046115    -0.0527757    0.314732    0.318774   -0.103997     0.313735     0.0750691    0.336147    -0.139971     0.882328   -0.00580197  -0.169341   -0.227067     0.067419   -0.476995    -0.0857793
  0.160475   -0.221387     0.0120485   -0.632146     0.865288     0.469091      0.153745     0.259884   -0.505581    -0.394697    -0.132598    -0.530201     0.0803189   0.239814    0.439495     0.209041     0.106999     0.290492    -0.237576    -0.249134   -0.106953    -0.0438302  -0.10665     -0.419265    0.0166595   -0.734555
  0.214492   -0.120613     0.128582     0.348766    -0.191339    -0.0799742     0.0271366   -0.0525609   0.230912     0.741351     0.123094     0.39067     -0.150896   -0.53631    -0.00300217   0.195451    -0.00215748   0.423438    -0.188372    -0.157413    0.172073     0.380264    0.570021    -0.140795    0.164735     0.174709
 -0.494731   -0.0699779   -0.874926     0.141652     1.12397     -0.536193      0.576043    -0.0438469  -0.866623    -0.308422    -0.872761    -0.0691022    0.284241   -0.05977     0.540935     1.35686     -0.612671    -0.276755     0.623548     0.118642   -0.192541    -0.310341   -0.444493     0.453583    0.465392    -0.321069
  0.369495   -0.16508     -0.414944    -0.0495543   -0.123447     0.0269938     0.487399     0.0380347  -0.0866016   -0.343443     0.34289      0.642027    -0.654265   -0.605299   -0.158599     0.084789    -0.708737     0.074721     0.721305     0.34498     0.364145    -0.725631   -0.00703016  -0.376081   -0.242004     0.216474
 -0.46694    -0.145696    -0.109125     0.624113     0.234378    -0.22312      -0.262258     0.315654    0.168123    -0.00832134   0.338526     0.119238     0.43702    -0.736052    0.181856     0.490174    -0.125322     0.831254    -0.140503    -0.475966   -0.589323    -0.698575    0.0489211    0.0994479  -0.161857    -0.686443
  0.137867    0.0556486   -0.153271     0.0544009    0.00376125  -0.00375273    0.0926363   -0.0584621  -0.0536784   -0.0886616    0.11997      0.20278     -0.131358    0.0213606   0.0314955   -0.166876    -0.0362479    0.0446275   -0.24628     -0.0965063   0.191057    -0.0435575   0.0709562    0.0386315   0.19481      0.00857095
 -0.36061     0.468784    -0.506187    -0.108407    -0.232461    -0.206492     -0.325023    -0.460899    0.20163      0.190645    -0.661949     0.161988    -0.136348    0.205428    0.257606    -0.368579    -0.506831    -0.252678     0.160124     0.50636    -0.0985097   -0.574396    0.513344     0.583648   -0.11929      0.679346
  0.244422   -0.239239    -0.494649     0.248788    -0.447139    -0.463098      0.398663    -0.0512711  -0.0731829   -0.651859    -0.495419    -0.216002    -0.600144   -0.661922    0.582309    -0.0848218    0.0445275    0.556192    -0.443701     0.124549    0.0114535   -0.572644    0.585336    -0.16741     0.173963     0.318882
 -0.130054    0.20326      0.123591    -0.148796     0.427653     0.383272     -0.203607     0.106197    0.210809     0.374185     0.313226     0.0889072    0.414591    0.150294   -0.331493    -0.140917     0.092856    -0.196596     0.217036    -0.0240189  -0.0874698    0.430087   -0.339077     0.0689873  -0.11495     -0.00287546
 -0.0181315  -0.438015     0.367575     0.368233    -0.0660395   -0.477788      0.470141     0.128967    0.678676    -0.294042     0.432169     0.293568    -0.634393   -0.265868   -0.805539    -0.0858708   -0.1173       0.178228     0.367666    -0.0978568  -0.025992     0.485286    0.0483752   -0.26255    -0.0619761   -0.302555
 -0.225517    0.149535    -0.320702     0.485838     0.0628146    0.0963315    -0.462698    -0.0938759   0.602099    -0.41674     -0.532247     0.0791907   -0.384627    0.352428   -0.199609     0.560458    -0.267288     0.130715    -0.00886464  -0.0325937   0.485438    -0.943536    0.232639    -0.517407    0.174179     0.0156111
 -0.269867    0.52201     -0.223037     0.154315     0.387446     0.0939876     0.134788    -0.602115    0.0618798   -0.431011    -0.0890954    0.252208     0.425655   -0.172572   -0.233198    -0.160304    -0.303803     0.728844    -0.693098     0.210867    0.653433     0.175367    0.0832939    0.134445   -0.00187265  -0.354002
  0.140572   -0.00915097  -0.0923194    0.0089961   -0.174261     0.0406949    -0.146535    -0.0500806   0.0170958    0.210704     0.11047     -0.00771017   0.079164    0.103467    0.100189    -0.114023     0.0282655   -0.111756    -0.0615171    0.0467726  -0.118542     0.0554169  -0.0449993    0.173749    0.0895925    0.212996
 -0.461899    0.22244     -0.100145    -0.00900634  -0.267187     0.112262     -0.00314346  -0.0429101  -0.320597    -0.0594798   -0.204633     0.299263    -0.258659   -0.091323    0.159644    -0.347618    -0.361801     0.208716    -0.316965    -1.27201    -0.116369    -0.0424981   0.339983    -0.574728    1.05601     -0.673905
 -0.809952   -0.117516     0.844714    -0.168659     0.273988     0.289333     -0.257002     0.022919   -0.00249801   0.0912024   -0.580952    -0.894929    -0.298192   -0.584156    0.238283    -0.209429     0.192082     0.136814     0.085068    -0.30468     0.214607    -0.203641    0.0916485   -0.484173   -0.38481      0.273149
 -0.221986    0.514614     0.358815    -0.21236      0.16306     -0.315475      0.369978    -0.0702138  -0.223621    -0.288911     0.703192     0.0871934   -0.166051   -0.5222      0.375005    -0.5193       0.0249575    0.127765     0.504291    -0.321833   -0.653043    -0.237369   -0.0705765   -0.319638   -0.468686    -0.238096
  0.545745   -0.0376453   -0.347814     0.772946     0.650159    -0.0427869    -0.145799     0.251473    0.152979     0.098107     0.148296     0.211457     0.470269    0.307471    0.0821007   -0.0990068    0.365346     0.072016    -0.0879718    0.370804   -0.0863487   -0.444183   -0.203872    -0.538499   -0.36167      0.260956
  0.119101   -0.0982776   -0.169822     0.331232    -0.61467     -0.966057      0.513192    -0.0162114   0.0884168    0.317655     0.269392    -0.0695483   -0.0295808   0.291925    0.450097    -0.53936     -0.173392    -0.724588     0.329103     0.139285   -0.184113     0.0986032  -0.103034    -0.0100584  -0.51702      0.227263
 -0.0996987   0.276777     0.177259    -0.531387     0.342744     0.029734     -0.285908    -0.489137   -0.109292    -0.768734     0.077971    -0.37365     -0.254977    0.660006   -0.224804    -0.686487    -0.088836    -0.45453      0.625827     0.211342    0.467113    -0.163662   -0.592612    -0.45205    -0.34312      0.122002
  0.746414    0.27926     -0.989682     0.342759    -0.311375    -0.26156       0.281886    -0.0073043   0.00433497  -0.249945     0.877704     0.496068     0.208296    0.506899   -0.18709      0.141576     0.124956    -0.182718    -0.247097     0.432356   -0.376413     0.404906   -0.0597581    0.497957    0.268138    -0.142351
 -0.140723    0.04012      0.248885    -0.07652      0.0438791   -0.135645     -0.132424     0.0076522  -0.193088    -0.0739587   -0.155349    -0.229513    -0.0138601  -0.0441055   0.135521     0.188832    -0.0352764   -0.0746054    0.24095      0.131253   -0.183651    -0.0669545   0.159798    -0.0893995  -0.138631     0.106501
 -0.686384    0.0964678    0.805282    -0.177034    -0.0242686   -0.171973     -0.547948     0.323084   -0.060235     0.190846    -0.128866     0.140555     0.192123    0.538791    0.0121417    0.43275      0.530332    -0.402759    -0.0138315   -0.0123709  -0.511736     0.348782   -0.72638     -0.0575632   0.00837683   0.0869113
  0.11253    -0.193866     0.0958236   -0.209164    -0.386426     0.133052     -0.0233045    0.0130564  -0.155267     0.225894    -0.440514    -0.0217929   -0.283873    0.613596   -0.35933      0.213801    -0.18099     -0.67943     -0.110302     0.207604    0.494982     0.458334    0.184467     0.183398    0.772053     0.470606
 -0.273003   -0.449577     0.00480666   0.394351     0.00509365  -0.193633     -0.171897     0.0861554  -0.151746    -0.200801     0.307746    -0.54178      0.333707    0.269854   -0.327625     0.110926     0.0435435    0.103073    -0.662459    -0.15308     0.707218     0.155547    0.129363     0.0596558   0.558891    -0.390532
  0.249869    0.169996     0.0974214   -0.546381     0.359637     0.000874791   0.405131     0.594425   -0.74322      0.327285     0.00296203   0.0456288   -0.275655   -0.228312   -0.0707575    0.564903     0.129354    -0.405625     0.671349     0.725493   -0.0756589   -0.178104    0.787838     0.241082   -0.131682     0.367104[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412836
[ Info: iteration 2, average log likelihood -1.412829
[ Info: iteration 3, average log likelihood -1.412822
[ Info: iteration 4, average log likelihood -1.412815
[ Info: iteration 5, average log likelihood -1.412808
[ Info: iteration 6, average log likelihood -1.412802
[ Info: iteration 7, average log likelihood -1.412797
[ Info: iteration 8, average log likelihood -1.412791
[ Info: iteration 9, average log likelihood -1.412786
[ Info: iteration 10, average log likelihood -1.412780
┌ Info: EM with 100000 data points 10 iterations avll -1.412780
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
