Julia Version 1.5.0-DEV.162
Commit fba188c5ea (2020-01-28 03:57 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed LegacyStrings ────── v0.4.1
 Installed Compat ───────────── v2.2.0
 Installed PDMats ───────────── v0.9.11
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed DataAPI ──────────── v1.1.0
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
 Installed BinDeps ──────────── v1.0.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.9
 Installed Rmath ────────────── v0.6.0
 Installed Distances ────────── v0.8.2
 Installed FileIO ───────────── v1.2.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed HDF5 ─────────────── v0.12.5
 Installed JLD ──────────────── v0.9.1
 Installed StatsFuns ────────── v0.9.3
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed OrderedCollections ─ v1.1.0
 Installed Distributions ────── v0.22.3
 Installed NearestNeighbors ─── v0.4.4
 Installed ScikitLearnBase ──── v0.5.0
 Installed FillArrays ───────── v0.8.4
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_gFB3Z8/Project.toml`
 [no changes]
  Updating `/tmp/jl_gFB3Z8/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_X18EaC/Project.toml`
 [no changes]
  Updating `/tmp/jl_X18EaC/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_czl7BC/Project.toml`
 [no changes]
  Updating `/tmp/jl_czl7BC/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_LohYSh/Project.toml`
 [no changes]
  Updating `/tmp/jl_LohYSh/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_C0ARvn/Project.toml`
 [no changes]
  Updating `/tmp/jl_C0ARvn/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_C0ARvn/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.1946939434150166e6, [78003.05518832327, 21996.944811676738], [-839.2348008833982 13221.821695826207 25822.977538466806; 731.9685170937585 -13726.906436326859 -25927.247430061994], [[80060.12440273195 -151.6838780652633 344.7874529842887; -151.68387806526334 73057.28195450388 -9332.799023145257; 344.78745298428885 -9332.799023145257 58901.456866510816], [20223.682897366903 258.6293358372405 -466.7564350814414; 258.62933583724043 27278.269566772517 9112.561947433871; -466.7564350814412 9112.561947433871 40237.17639858047]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.521400e+03
      1       1.025596e+03      -4.958040e+02 |        8
      2       9.636991e+02      -6.189730e+01 |        5
      3       9.046964e+02      -5.900268e+01 |        2
      4       8.990476e+02      -5.648839e+00 |        0
      5       8.990476e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 899.0475820486931)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070822
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.844950
[ Info: iteration 2, lowerbound -3.743028
[ Info: iteration 3, lowerbound -3.634865
[ Info: iteration 4, lowerbound -3.508482
[ Info: iteration 5, lowerbound -3.375840
[ Info: iteration 6, lowerbound -3.248430
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.127395
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.999329
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.853332
[ Info: iteration 10, lowerbound -2.706203
[ Info: iteration 11, lowerbound -2.579246
[ Info: iteration 12, lowerbound -2.480652
[ Info: iteration 13, lowerbound -2.412908
[ Info: dropping number of Gaussions to 4
[ Info: iteration 14, lowerbound -2.364476
[ Info: iteration 15, lowerbound -2.334860
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.313968
[ Info: iteration 17, lowerbound -2.308191
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302916
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 29 10:45:57 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 29 10:46:04 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Wed Jan 29 10:46:07 2020: EM with 272 data points 0 iterations avll -2.070822
5.8 data points per parameter
, Wed Jan 29 10:46:08 2020: GMM converted to Variational GMM
, Wed Jan 29 10:46:16 2020: iteration 1, lowerbound -3.844950
, Wed Jan 29 10:46:16 2020: iteration 2, lowerbound -3.743028
, Wed Jan 29 10:46:16 2020: iteration 3, lowerbound -3.634865
, Wed Jan 29 10:46:16 2020: iteration 4, lowerbound -3.508482
, Wed Jan 29 10:46:16 2020: iteration 5, lowerbound -3.375840
, Wed Jan 29 10:46:16 2020: iteration 6, lowerbound -3.248430
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 7
, Wed Jan 29 10:46:16 2020: iteration 7, lowerbound -3.127395
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 6
, Wed Jan 29 10:46:16 2020: iteration 8, lowerbound -2.999329
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 5
, Wed Jan 29 10:46:16 2020: iteration 9, lowerbound -2.853332
, Wed Jan 29 10:46:16 2020: iteration 10, lowerbound -2.706203
, Wed Jan 29 10:46:16 2020: iteration 11, lowerbound -2.579246
, Wed Jan 29 10:46:16 2020: iteration 12, lowerbound -2.480652
, Wed Jan 29 10:46:16 2020: iteration 13, lowerbound -2.412908
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 4
, Wed Jan 29 10:46:16 2020: iteration 14, lowerbound -2.364476
, Wed Jan 29 10:46:16 2020: iteration 15, lowerbound -2.334860
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 3
, Wed Jan 29 10:46:16 2020: iteration 16, lowerbound -2.313968
, Wed Jan 29 10:46:16 2020: iteration 17, lowerbound -2.308191
, Wed Jan 29 10:46:16 2020: dropping number of Gaussions to 2
, Wed Jan 29 10:46:17 2020: iteration 18, lowerbound -2.302916
, Wed Jan 29 10:46:17 2020: iteration 19, lowerbound -2.299259
, Wed Jan 29 10:46:17 2020: iteration 20, lowerbound -2.299256
, Wed Jan 29 10:46:17 2020: iteration 21, lowerbound -2.299254
, Wed Jan 29 10:46:17 2020: iteration 22, lowerbound -2.299254
, Wed Jan 29 10:46:17 2020: iteration 23, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 24, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 25, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 26, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 27, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 28, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 29, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 30, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 31, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 32, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 33, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 34, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 35, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 36, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 37, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 38, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 39, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 40, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 41, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 42, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 43, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 44, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 45, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 46, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 47, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 48, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 49, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: iteration 50, lowerbound -2.299253
, Wed Jan 29 10:46:17 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601402, 95.95490777398597]
β = [178.04509222601402, 95.95490777398597]
m = [4.250300733269909 79.28686694436182; 2.000229257775369 53.851987172461286]
ν = [180.04509222601402, 97.95490777398597]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484835 -0.007644049042327522; 0.0 0.00858170516633356], [0.37587636119484313 -0.008953123827346126; 0.0 0.012748664777409524]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9749113826652611
avll from llpg:  -0.9749113826652609
avll direct:     -0.9749113826652611
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0009569494971757
avll from llpg:  -1.0009569494971757
avll direct:     -1.0009569494971757
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0750481    0.171288     0.0950846    -0.0437316   0.0444369    0.0620425  -0.076569   -0.0756883   -0.142631     0.190917     0.0680692   -0.0378072   -0.005322     0.219504    -0.0211148    0.0704969     0.0799937     0.062483    -0.0388766   -0.0780515  -0.0908523   -0.0285842    0.0303206   -0.131697     -0.0337082   -0.108996
 -0.142846     0.137098    -0.0113047     0.104827    0.0236377   -0.0354852  -0.0775531  -0.0882767    0.0184558   -0.164723    -0.0594462   -0.0341397   -0.063179     0.0883452   -0.0849592    0.0567047    -0.0416735     0.0170796    0.0706409   -0.0499503   0.00780022   0.054131    -0.0484437    0.0416399    -0.0182408   -0.202157
 -0.0700071    0.0978633   -0.101519      0.0720495   0.0361208    0.160506    0.0294399   0.086084     0.14903     -0.0608182    0.236181    -0.0135458   -0.102073     0.0691965    0.290912    -0.0143504     0.00571106    0.0841187   -0.050152    -0.143216   -0.00371743  -0.143964    -0.237156    -0.0414081    -0.0943308   -0.0781014
 -0.0655296    0.0774876    0.102828     -0.12461     0.00898124  -0.0980369   0.140539    0.0483478    0.11149      0.0729981   -0.02783     -0.0491505   -0.0319638   -0.0141488   -0.14066     -0.0623994    -0.0660391    -0.102739     0.0974904    0.0809297   0.114945     0.0386182    0.0572158   -0.0510715    -0.0132382    0.112027
 -0.0467849   -0.0768534   -0.141403      0.0174676  -0.111852    -0.126747   -0.150092    0.124054     0.00650398  -0.0269896    0.256992     0.145105     0.00107475   0.104412    -0.0531894    0.000794919   0.0725394    -0.0530239   -0.0254446    0.0062409   0.138944     0.0217172   -0.10837      0.00411254    0.118029     0.00557355
 -0.044925    -0.036663    -0.0917117    -0.14798    -0.0580578   -0.117546   -0.100531    0.194966     0.033649     0.00962627   0.0522875   -0.10779     -0.0360479   -0.0703617    0.0308579   -0.106176      0.0682876    -0.0499879   -0.060386     0.163309   -0.262117     0.044862    -0.0911486   -0.109022     -0.0622031    0.101107
 -0.0523131   -0.0564477   -0.0389137    -0.042546    0.112207     0.0259144  -0.084474   -0.0998823    0.0192166    0.0367488   -0.0371497   -0.159712    -0.323243    -0.057565    -0.243986    -0.0329233     0.0106875    -0.0987886   -0.0419438   -0.0652142  -0.00964213  -0.0301055    0.0423311   -0.0296601     0.0761194   -0.140051
 -0.122407    -0.0216828    0.00683767   -0.0533328   0.00193813   0.162675    0.141824    0.0798134   -0.0749522   -0.00259993   0.0100167   -0.0262277   -0.0970661   -0.10308      0.0430968   -0.119535     -0.147276     -0.0446405   -0.0666935   -0.013067    0.0759681    0.0759775   -0.101761     0.14593      -0.109785    -0.185608
  0.145521     0.119547     0.0173196     0.0056788  -0.0449543   -0.137       0.0606569   0.0809082    0.207489     0.035316     0.0315924    0.0384433   -0.00745282   0.0119926   -0.0640118   -0.015993     -0.0407395    -0.0115184   -0.09603     -0.141037   -0.00500783  -0.0543532   -0.0469055    0.00150982   -0.120552    -0.110523
 -0.124596     0.0337668    0.0821267     0.0165209  -0.0738293   -0.0769991   0.0623323  -0.0611633   -0.0181031   -0.0778423   -0.195864    -0.0294297   -0.0299004    0.0305921    0.0466695    0.00453282   -0.0112808     0.048646     0.0431356   -0.163203   -0.0106744   -0.0373172    0.0890736   -0.010438     -0.00582094   0.0898376
  0.123591    -0.0452808   -0.075744      0.0606305  -0.011193    -0.0487255  -0.0312126  -0.00357603   0.0950879   -0.0670581    0.0805942   -0.0486284   -0.0317285   -0.00292732   0.17297     -0.124019      0.0556534    -0.0134599   -0.0255521    0.10359     0.0528574    0.0373021   -0.0428809   -0.00536302    0.0797171   -0.0356276
 -0.0619986   -0.11544     -0.121158      0.0388751   0.0778778   -0.0179459   0.15801     0.011323    -0.191144     0.0690993    0.0777294   -0.0328718    0.241003    -0.0892018   -0.0582413   -0.0211319     0.0346021     0.0409812   -0.24496     -0.075657   -0.0662008    0.0107821    0.00717077  -0.060051      0.0345782   -0.0841175
  0.105027     0.00989705   0.0627818     0.0269892  -0.222457    -0.0887826  -0.0526489   0.0975902   -0.0239891   -0.061862    -0.0126937   -0.0952157   -0.182863     0.0102673   -0.0872388    0.127536      0.201229     -0.0111997    0.00715237  -0.0109902  -0.0349906   -0.097029     0.0491001   -0.159339     -0.0189836    0.128824
  0.109707    -0.196586    -0.0464026     0.0308793  -0.157547    -0.138352   -0.18756    -0.00472785   0.0112917    0.0577623    0.0901701   -0.0560545   -0.0415783   -0.0503969    0.0312149   -0.0596922     0.131694      0.0375165    0.0922542   -0.065221    0.0845398    0.0592378    0.00156903   0.000159756  -0.0621144   -0.0073302
  0.0559041   -0.134462     0.136676      0.14319     0.0812818    0.073192    0.0414487   0.0669746   -0.192387     0.0731154    0.0207744   -0.128212     0.0104784    0.0834075   -0.0295794    0.19471      -0.0319473     0.0917663   -0.048358    -0.0786117  -0.11294      0.0509269    0.0154144    0.00400274   -0.118916    -0.0210587
 -0.0367396   -0.032629     0.122814      0.12945    -0.0178323   -0.0792573  -0.0244738   0.0226248    0.236289     0.0143217   -0.0224265   -0.0667836   -0.111309     0.100322     0.0447406   -0.0674265     0.171083     -0.00938382   0.0440432   -0.176903    0.213313     0.0479382    0.228311    -0.142998     -0.0321372   -0.0509184
  0.00817896   0.118905    -0.0347421    -0.12902     0.0391434   -0.083637    0.0527903  -0.104333    -0.00586357   3.68217e-5  -0.222103     0.0853943   -0.0115137   -0.0999926    0.098391    -0.135924     -0.0806511    -0.176571     0.117224    -0.0260406  -0.1178       0.00350871  -0.0985346   -0.154057      0.00283128  -0.0264782
  0.070668    -0.0805147   -0.202931      0.0324218   0.0528803   -0.067358   -0.113496   -0.181183    -0.0919591   -0.138155    -0.00385475  -0.1506       0.00300338   0.0145381   -0.0206612    0.0389045     0.147769     -0.006673     0.131275     0.0933484  -0.00578427  -0.0657326   -0.0134212    0.164368     -0.0261383    0.125461
 -0.125722     0.173475     0.101266      0.0347336   0.182079     0.0745309   0.103132   -0.0886464    0.016277     0.0554085    0.0449822    0.0953455    0.121264    -0.0948201   -0.0618386    0.0122222    -0.275933     -0.204181    -0.186023     0.075659   -0.115733    -0.0384473   -0.162823     0.161687     -0.053555    -0.0501182
 -0.0343281    0.136159     0.0844881     0.113912    0.133692    -0.153177   -0.0719368   0.109495    -0.162137    -0.0421459    0.0322379   -0.00452359   0.190772    -0.00632696  -0.0667939    0.180225     -0.0756026     0.0753294   -0.100608     0.0573124  -0.0454714   -0.0551854    0.211351    -0.0772187    -0.0739263   -0.030181
  0.0711321   -0.0164282   -0.0136037    -0.0112715   0.0116642   -0.0530731  -0.169358    0.192462    -0.0787515   -0.102224    -0.107746     0.104767    -0.123141    -0.209688    -0.0405112   -0.187892      0.0754843    -0.0641662    0.0571983    0.014749    0.0889803   -0.0574515   -0.0328173   -0.128558     -0.0509417   -0.0189396
 -0.1514       0.208502    -0.0623842    -0.10288    -0.161487     0.028712    0.0658745   0.0979561   -0.129086     0.170193    -0.0589078    0.144741     0.0229351   -0.00279571   0.0877705    0.125484     -0.041098     -0.0107934    0.239083    -0.0189365   0.0960559    0.154396     0.104388    -0.251719     -0.0810969    0.00347533
 -0.116147     0.170335    -0.0652302     0.158124    0.0464539    0.103055    0.0907333  -0.0726888    0.0551083   -0.0597133    0.058781     0.225056    -0.028264     0.0331558   -0.029065     0.331964     -0.000568659  -0.0926859   -0.00840613   0.0323611   0.0214187   -0.0319912   -0.185816    -0.0812795    -0.0174793   -0.167154
 -0.013126     0.023014    -0.066652     -0.154651   -0.103011    -0.0764363  -0.0453391  -0.0819872    0.23513     -0.00156816   0.116193     0.2123      -0.0260727    0.0216041    0.0775114   -0.0289594    -0.14413       0.0728711   -0.118853    -0.0817773   0.108575    -0.138969    -0.0601489   -0.103918     -0.0749503    0.039922
 -0.0273007   -0.12255     -0.0312839     0.11259     0.0221251   -0.0857453   0.0621487   0.170383    -0.188598    -0.152072     0.073057     0.0800539   -0.183972     0.0836619    0.0739865    0.0538798    -0.0785394    -0.128381     0.139368     0.0852832   0.00739646   0.0872292    0.119275     0.00231313    0.1558      -0.0127
  0.0344952    0.121376     0.000275958   0.0687403   0.065116     0.0172919  -0.113734    0.0576712   -0.140898    -0.114545     0.258648    -0.0413423   -0.135349    -0.0404706    0.16904     -0.129188     -0.123459     -0.0261288    0.106651    -0.0227285  -0.102835    -0.101952     0.0653722   -0.110091      0.0997918    0.0842644
  0.138274    -0.0268658    0.0980705     0.0213666   0.147879     0.0170354  -0.0492331  -0.0154128   -0.0811937   -0.0652101    0.112415    -0.0875558    0.030585     0.0489319    0.279693     0.0753371    -0.126119     -0.0232898   -0.0728887    0.118939    0.0126573   -0.0188458   -0.0095579   -0.00458696    0.107441    -0.050943
  0.00258452   0.0574966    0.014571     -0.20324    -0.0405724    0.0543962   0.119383    0.186195    -0.275817    -0.042831     0.0366708    0.0473823    0.00840777   0.0686699   -0.00316995  -0.0997722     0.0658694     0.136208    -0.0534661    0.0315347   0.103072    -0.145643    -0.13716     -0.054932     -0.0107887   -0.0320719
  0.120218    -0.0363362    0.0130168     0.0234745   0.0408968   -0.0699843  -0.143714    0.0882626    0.0312352    0.233708    -0.01366      0.102052    -0.0987948   -0.00189783  -0.0367241   -0.0410191    -0.0754862     0.192984    -0.160828     0.128561    0.125767    -0.103679    -0.00941371   0.212529     -0.0213064    0.0574554
 -0.020451     0.143212     0.0703654     0.197849   -0.0593022   -0.0781044  -0.0318761  -0.0656162   -0.0914095   -0.0240151    0.0566319   -0.069825    -0.113766    -0.0358787   -0.00644458  -0.0522815    -0.0550518     0.0769027    0.11147     -0.137854    0.0906594    0.0738537    0.131815    -0.0129838    -0.0592248   -0.0203686
  0.0717813   -0.183727     0.0574212     0.0125655   0.0197866    0.0616028   0.122672   -0.181894    -0.0222679   -0.0396019   -0.221062     0.0497774    0.12068     -0.0244972    0.0491198   -0.0940619     0.00175721   -0.0197978    0.0266258    0.246912   -0.294068     0.00758524   0.0606918    0.141051      0.0273713   -0.0440605
  0.0415761   -0.118619    -0.183289      0.112887    0.0190573   -0.0308316  -0.0620403  -0.0322823    0.0950361   -0.0960161   -0.123755     0.0500619   -0.0200085   -0.259556     0.0435828    0.0601584    -0.234898     -0.193266     0.0333819   -0.125324   -0.0631137    0.209628    -0.00347585   0.0643407     0.142516    -0.0845013kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3895064480434198
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.389586
[ Info: iteration 2, average log likelihood -1.389505
[ Info: iteration 3, average log likelihood -1.388901
[ Info: iteration 4, average log likelihood -1.382961
[ Info: iteration 5, average log likelihood -1.369045
[ Info: iteration 6, average log likelihood -1.362939
[ Info: iteration 7, average log likelihood -1.361720
[ Info: iteration 8, average log likelihood -1.361222
[ Info: iteration 9, average log likelihood -1.360945
[ Info: iteration 10, average log likelihood -1.360765
[ Info: iteration 11, average log likelihood -1.360623
[ Info: iteration 12, average log likelihood -1.360480
[ Info: iteration 13, average log likelihood -1.360304
[ Info: iteration 14, average log likelihood -1.360093
[ Info: iteration 15, average log likelihood -1.359885
[ Info: iteration 16, average log likelihood -1.359691
[ Info: iteration 17, average log likelihood -1.359498
[ Info: iteration 18, average log likelihood -1.359296
[ Info: iteration 19, average log likelihood -1.359071
[ Info: iteration 20, average log likelihood -1.358827
[ Info: iteration 21, average log likelihood -1.358587
[ Info: iteration 22, average log likelihood -1.358357
[ Info: iteration 23, average log likelihood -1.358110
[ Info: iteration 24, average log likelihood -1.357802
[ Info: iteration 25, average log likelihood -1.357376
[ Info: iteration 26, average log likelihood -1.356782
[ Info: iteration 27, average log likelihood -1.356074
[ Info: iteration 28, average log likelihood -1.355201
[ Info: iteration 29, average log likelihood -1.353768
[ Info: iteration 30, average log likelihood -1.351198
[ Info: iteration 31, average log likelihood -1.349001
[ Info: iteration 32, average log likelihood -1.347779
[ Info: iteration 33, average log likelihood -1.347072
[ Info: iteration 34, average log likelihood -1.346647
[ Info: iteration 35, average log likelihood -1.346369
[ Info: iteration 36, average log likelihood -1.346180
[ Info: iteration 37, average log likelihood -1.346042
[ Info: iteration 38, average log likelihood -1.345941
[ Info: iteration 39, average log likelihood -1.345866
[ Info: iteration 40, average log likelihood -1.345814
[ Info: iteration 41, average log likelihood -1.345778
[ Info: iteration 42, average log likelihood -1.345754
[ Info: iteration 43, average log likelihood -1.345739
[ Info: iteration 44, average log likelihood -1.345729
[ Info: iteration 45, average log likelihood -1.345723
[ Info: iteration 46, average log likelihood -1.345719
[ Info: iteration 47, average log likelihood -1.345716
[ Info: iteration 48, average log likelihood -1.345714
[ Info: iteration 49, average log likelihood -1.345713
[ Info: iteration 50, average log likelihood -1.345712
┌ Info: EM with 100000 data points 50 iterations avll -1.345712
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.389586481341343
│     -1.3895049664725456
│      ⋮
└     -1.345711824676244
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.345819
[ Info: iteration 2, average log likelihood -1.345712
[ Info: iteration 3, average log likelihood -1.345219
[ Info: iteration 4, average log likelihood -1.340771
[ Info: iteration 5, average log likelihood -1.328497
[ Info: iteration 6, average log likelihood -1.319626
[ Info: iteration 7, average log likelihood -1.316064
[ Info: iteration 8, average log likelihood -1.314070
[ Info: iteration 9, average log likelihood -1.312472
[ Info: iteration 10, average log likelihood -1.311084
[ Info: iteration 11, average log likelihood -1.309739
[ Info: iteration 12, average log likelihood -1.308299
[ Info: iteration 13, average log likelihood -1.306652
[ Info: iteration 14, average log likelihood -1.305049
[ Info: iteration 15, average log likelihood -1.303751
[ Info: iteration 16, average log likelihood -1.302711
[ Info: iteration 17, average log likelihood -1.301930
[ Info: iteration 18, average log likelihood -1.301347
[ Info: iteration 19, average log likelihood -1.300926
[ Info: iteration 20, average log likelihood -1.300626
[ Info: iteration 21, average log likelihood -1.300402
[ Info: iteration 22, average log likelihood -1.300219
[ Info: iteration 23, average log likelihood -1.300053
[ Info: iteration 24, average log likelihood -1.299903
[ Info: iteration 25, average log likelihood -1.299772
[ Info: iteration 26, average log likelihood -1.299664
[ Info: iteration 27, average log likelihood -1.299577
[ Info: iteration 28, average log likelihood -1.299510
[ Info: iteration 29, average log likelihood -1.299457
[ Info: iteration 30, average log likelihood -1.299414
[ Info: iteration 31, average log likelihood -1.299378
[ Info: iteration 32, average log likelihood -1.299345
[ Info: iteration 33, average log likelihood -1.299314
[ Info: iteration 34, average log likelihood -1.299285
[ Info: iteration 35, average log likelihood -1.299257
[ Info: iteration 36, average log likelihood -1.299228
[ Info: iteration 37, average log likelihood -1.299198
[ Info: iteration 38, average log likelihood -1.299168
[ Info: iteration 39, average log likelihood -1.299137
[ Info: iteration 40, average log likelihood -1.299105
[ Info: iteration 41, average log likelihood -1.299072
[ Info: iteration 42, average log likelihood -1.299040
[ Info: iteration 43, average log likelihood -1.299008
[ Info: iteration 44, average log likelihood -1.298977
[ Info: iteration 45, average log likelihood -1.298947
[ Info: iteration 46, average log likelihood -1.298917
[ Info: iteration 47, average log likelihood -1.298887
[ Info: iteration 48, average log likelihood -1.298858
[ Info: iteration 49, average log likelihood -1.298829
[ Info: iteration 50, average log likelihood -1.298802
┌ Info: EM with 100000 data points 50 iterations avll -1.298802
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3458189449782405
│     -1.3457115743090227
│      ⋮
└     -1.2988018445965832
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298919
[ Info: iteration 2, average log likelihood -1.298729
[ Info: iteration 3, average log likelihood -1.297577
[ Info: iteration 4, average log likelihood -1.286357
[ Info: iteration 5, average log likelihood -1.261609
[ Info: iteration 6, average log likelihood -1.248533
[ Info: iteration 7, average log likelihood -1.243870
[ Info: iteration 8, average log likelihood -1.240992
[ Info: iteration 9, average log likelihood -1.238694
[ Info: iteration 10, average log likelihood -1.237301
[ Info: iteration 11, average log likelihood -1.236784
[ Info: iteration 12, average log likelihood -1.236540
[ Info: iteration 13, average log likelihood -1.236405
[ Info: iteration 14, average log likelihood -1.236329
[ Info: iteration 15, average log likelihood -1.236278
[ Info: iteration 16, average log likelihood -1.236237
[ Info: iteration 17, average log likelihood -1.236199
[ Info: iteration 18, average log likelihood -1.236158
[ Info: iteration 19, average log likelihood -1.236112
[ Info: iteration 20, average log likelihood -1.236058
[ Info: iteration 21, average log likelihood -1.235994
[ Info: iteration 22, average log likelihood -1.235923
[ Info: iteration 23, average log likelihood -1.235847
[ Info: iteration 24, average log likelihood -1.235771
[ Info: iteration 25, average log likelihood -1.235701
[ Info: iteration 26, average log likelihood -1.235640
[ Info: iteration 27, average log likelihood -1.235590
[ Info: iteration 28, average log likelihood -1.235550
[ Info: iteration 29, average log likelihood -1.235522
[ Info: iteration 30, average log likelihood -1.235503
[ Info: iteration 31, average log likelihood -1.235491
[ Info: iteration 32, average log likelihood -1.235483
[ Info: iteration 33, average log likelihood -1.235478
[ Info: iteration 34, average log likelihood -1.235475
[ Info: iteration 35, average log likelihood -1.235473
[ Info: iteration 36, average log likelihood -1.235472
[ Info: iteration 37, average log likelihood -1.235471
[ Info: iteration 38, average log likelihood -1.235470
[ Info: iteration 39, average log likelihood -1.235470
[ Info: iteration 40, average log likelihood -1.235470
[ Info: iteration 41, average log likelihood -1.235470
[ Info: iteration 42, average log likelihood -1.235470
[ Info: iteration 43, average log likelihood -1.235470
[ Info: iteration 44, average log likelihood -1.235470
[ Info: iteration 45, average log likelihood -1.235470
[ Info: iteration 46, average log likelihood -1.235470
[ Info: iteration 47, average log likelihood -1.235470
[ Info: iteration 48, average log likelihood -1.235470
[ Info: iteration 49, average log likelihood -1.235470
[ Info: iteration 50, average log likelihood -1.235470
┌ Info: EM with 100000 data points 50 iterations avll -1.235470
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2989193180973462
│     -1.2987288180585024
│      ⋮
└     -1.235469721938967
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.235654
[ Info: iteration 2, average log likelihood -1.235357
[ Info: iteration 3, average log likelihood -1.233001
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.212554
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.183023
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.171637
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.166740
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.160882
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.148815
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.154286
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.166848
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.159144
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.146346
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.158570
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.158782
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.165249
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.149009
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.153714
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.157997
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.154470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.152910
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.146197
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.159568
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.155041
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.159131
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.153112
[ Info: iteration 27, average log likelihood -1.162297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.150847
[ Info: iteration 29, average log likelihood -1.159075
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.142983
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.159115
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.156380
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.153541
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.152229
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.152712
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.171507
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.154560
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.146932
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.152506
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.154113
[ Info: iteration 41, average log likelihood -1.161593
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.141111
[ Info: iteration 43, average log likelihood -1.165863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.153187
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.149283
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.153385
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.164259
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.159157
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.146193
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.151127
┌ Info: EM with 100000 data points 50 iterations avll -1.151127
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2356540831320364
│     -1.2353572317605355
│      ⋮
└     -1.1511266598505305
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.166491
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.154795
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.143562
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     12
│     17
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.128243
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     11
│     12
│     15
│     19
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.080128
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     11
│     12
│     16
│     18
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078361
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.081786
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     10
│     11
│     12
│     18
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062255
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     11
│     12
│     15
│     16
│     17
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051332
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     11
│     12
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.058696
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     11
│     12
│     18
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.051494
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.038792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.076909
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.039025
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.044193
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.070843
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│     19
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.061298
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.050505
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.065611
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.049921
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.041173
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     10
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.046972
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.065701
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.043441
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     17
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.058049
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.054034
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.048847
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│     18
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.059634
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     19
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.046726
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     10
│     11
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.032469
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.083131
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     11
│     12
│     19
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.049422
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.029411
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060756
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     11
│     12
│     19
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066704
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.036257
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     17
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.050621
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     10
│     11
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.042476
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.034565
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.054588
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     11
│     12
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.046396
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.023162
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     11
│     12
│     24
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.064921
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     12
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.046818
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.017925
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.051700
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     11
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.051766
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.018336
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     11
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.058668
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     17
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.032948
┌ Info: EM with 100000 data points 50 iterations avll -1.032948
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1664910158528892
│     -1.1547949752493183
│      ⋮
└     -1.03294807322578
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3895064480434198
│     -1.389586481341343
│     -1.3895049664725456
│     -1.38890134056973
│      ⋮
│     -1.0183356929690717
│     -1.058668367345984
└     -1.03294807322578
32×26 Array{Float64,2}:
 -0.14804     -0.082017   -0.0208387   -0.0568758    0.105647     0.0131554  -0.0870574   -0.10478      0.00435943   0.0344807   -0.0373606    -0.134845   -0.331418    -0.0858065   -0.23017     -0.0387394   -0.00654231  -0.118237   -0.0383523   -0.103338    -0.00422469  -0.029775     0.043129    -0.0370514     0.0994171    -0.162869
 -0.0473705    0.0641713   0.0113413   -0.195366    -0.041887     0.0551653   0.0935231    0.188952    -0.287758    -0.0214326    0.00574621    0.0635461   0.0114503    0.0933103    0.00830695  -0.114732     0.0526393    0.115138   -0.0580731    0.0455823    0.0985916   -0.141771    -0.128065    -0.0885279    -0.00317014   -0.0343001
 -0.0623219    0.0230505  -0.0997682    0.104136     0.0157276   -0.0482077  -0.0674825   -0.0572335    0.0586412   -0.119374    -0.111118     -0.0240869  -0.0478306   -0.0613219   -0.0293276    0.0492319   -0.132998    -0.0840635   0.0495614   -0.0791979   -0.0140961    0.133624    -0.032608     0.0578405     0.0408306    -0.144994
 -0.0176678   -0.0263808  -0.0987652   -0.0821688   -0.116247    -0.102829   -0.0880405    0.0308381    0.124017     0.00772661   0.159158      0.183913    0.00558194   0.0903668    0.0260802    0.00120738  -0.0376195    0.0150896  -0.0529078   -0.0490133    0.13077     -0.0613378   -0.0828662   -0.0627337     0.0115144     0.0160576
  0.0779963   -0.09385    -0.277309     0.0178022    0.0502252   -0.0690019  -0.108534    -0.185786    -0.0931741   -0.130568    -0.00178853   -0.15112    -0.00104577   0.0161499   -0.0207057    0.0386157    0.140996    -0.0093581   0.128163     0.0764878    0.0114938   -0.0695047    0.0394326    0.148185     -0.0189571     0.131764
  0.12276     -0.031073    0.0744868    0.0290833    0.148794     0.0140062  -0.0721433   -0.0164809   -0.0809319   -0.0528485    0.133111     -0.0854213   0.0152228    0.0810892    0.265473     0.0627465   -0.122481     0.033269   -0.0738858    0.116095    -0.00593007  -0.00589634  -0.0628516    0.00620731    0.100479     -0.0533879
  0.11655     -0.0478544  -0.0207993    0.0395646    0.0155153   -0.0798996  -0.100184     0.044802     0.0637922    0.09209      0.0260129     0.0329651  -0.0704294    0.0162035    0.036205    -0.10651     -0.00261128   0.103583   -0.100181     0.133895     0.0780282   -0.0346707   -0.0113825    0.132158      0.00653982    0.0158258
 -0.147142     0.0290428   0.0169196    0.0338668   -0.0580028   -0.135655    0.0626416   -0.066661    -0.0165181   -0.0835195   -0.197935     -0.0285649  -0.0312273    0.0294928    0.0424936   -0.0291848   -0.012132     0.0338072   0.0760506   -0.133419    -0.0514411   -0.0595827    0.118806    -0.0133958     0.00836351    0.0902378
  0.077042     0.149163    0.0575389   -0.0415638    0.039112     0.0662992  -0.0718971   -0.0687445   -0.141051     0.183441     0.0743942    -0.0370808  -0.00643773   0.242526    -0.0127345    0.0699451    0.0952607    0.0807798  -0.0123922   -0.0662183   -0.0923201   -0.0336344    0.016233    -0.114904     -0.000665381  -0.108504
 -0.0497799    0.0081719  -0.0740152   -0.195103    -0.0792013   -0.0788075  -0.101697     0.194754     0.0355553    0.0071741    0.0507318    -0.0930419  -0.0349932   -0.0483559    0.0308771   -0.104629     0.0639158   -0.0392641  -0.0577332    0.145205    -0.261389     0.0644912   -0.0970897   -0.109779     -0.0592546     0.0945503
 -0.262194     0.0705854  -0.0987909   -0.0614883    0.0127317    0.166907    0.0371525    0.0138371    0.156794    -0.0606993    0.0858514    -0.0138074  -0.267042     0.0813158    0.289342    -0.0644112    4.34815e-5   0.066378   -0.0405803   -0.0885126    0.00848482  -0.119896    -0.238316    -0.0532511    -0.0909249    -0.0866892
  0.0666109    0.115126   -0.101006     0.0962842    0.0504134    0.154724    0.0346413    0.150754     0.130485    -0.060465     0.364769      0.0168162   0.0603541    0.0557919    0.289433     0.0531785    0.00133315   0.0729018  -0.0418932   -0.176396    -0.0448046   -0.193899    -0.273886    -0.0268477     0.0405954    -0.0583829
  0.0897876   -0.0242552   0.0632976    0.0291017   -0.280883    -0.0885092  -0.0578493    0.0975237   -0.0422704   -0.0747297    0.000179497  -0.0810546  -0.173819     0.0113848   -0.0734096    0.129699     0.208452    -0.0156247   0.00602641  -0.0105791   -0.0792685   -0.117271     0.0497173   -0.177996      0.0141556     0.118458
  0.0317306    0.0764658  -0.00761751   0.0414455    0.056844     0.0211624  -0.109454     0.0507907   -0.161314    -0.103264     0.261402     -0.0423892  -0.133764    -0.0366448    0.130512    -0.12561     -0.122728    -0.0313448   0.00441433  -0.0282082   -0.0859447   -0.104634     0.0633207   -0.107186      0.100231      0.0671917
 -0.0569851   -0.118853   -0.123638     0.0388776    0.0683084   -0.0128427   0.156249     0.00938465  -0.18738      0.076219     0.0783264    -0.0104448   0.237593    -0.0801308   -0.0433247   -0.0217641    0.0348868    0.0344798  -0.260308    -0.0865514   -0.0728308    0.020003     0.00912736  -0.0574291     0.0388657    -0.0872282
 -0.0292829   -0.091401   -0.0336802    0.112292     0.0178174   -0.0989052   0.0592245    0.120221    -0.211514    -0.151062     0.0765689     0.0701236  -0.182597     0.0807984    0.0424685    0.0515103   -0.0567678   -0.135346    0.140484     0.0814711    0.00669533   0.0910481    0.115012     0.00261842    0.166711     -0.0361975
  0.0292786   -0.153454    0.122297     0.147057     0.0818421    0.0640972   0.0343       0.0721897   -0.193104     0.079663     0.0137612    -0.117866    0.0087684    0.0833461   -0.0295038    0.191929    -0.0525553    0.114587   -0.0521444   -0.0687724   -0.11767      0.0394845    0.0200503   -0.0129412    -0.0934397    -0.00372459
 -0.123248     0.167078   -0.0709267    0.142762     0.0378051    0.132119    0.0942896   -0.0730827    0.0807461   -0.051912     0.0598615     0.226368   -0.0279536    0.022393    -0.028737     0.298611     0.0122723   -0.103419   -0.01317      0.00594694   0.0235954   -0.0146489   -0.195064    -0.0803614    -0.0288703    -0.168951
 -0.0277858   -0.0297886   0.103467     0.131931    -0.0159507   -0.0837048   0.00470594   0.021841     0.229394     0.0361105   -0.00286751   -0.0866279  -0.104779     0.105519     0.0446636   -0.0651907    0.193409    -0.0127091   0.0373361   -0.175875     0.211275     0.0497263    0.228425    -0.142941     -0.0302159    -0.072637
 -0.0357503    0.188698    0.0831189    0.111487     0.138847    -0.15377    -0.0664635    0.105098    -0.153001    -0.0235167    0.040295     -0.0370854   0.186036    -0.0054415   -0.0681354    0.179306    -0.0587677    0.0714855  -0.0807489    0.0556125   -0.0759327   -0.0468277    0.207422    -0.0815997    -0.0842679    -0.0341142
  0.0631315    0.0551511  -0.0082606   -0.00552783   0.00915018  -0.0572331  -0.209491     0.160527    -0.175482    -0.0809977   -0.168731      0.0833847  -0.122668    -0.684869    -0.0696745   -0.129357     0.0403746   -0.0822371   0.133222    -0.0917233    0.0892767    0.0115343   -0.0441992   -0.134022     -0.12232       0.0373867
  0.0579412   -0.0796245  -0.0131936   -0.0286877    0.00870932  -0.0282842  -0.0942706    0.195742     0.0247148   -0.0889106   -0.0460587     0.135454   -0.120831     0.404453    -0.017265    -0.244466     0.0918658   -0.0494954  -0.0633105    0.125962     0.121237    -0.101418     0.00232633  -0.123048      0.0352954     0.00768107
  0.00403595   0.13577    -0.0460424   -0.141954     0.0363687   -0.0996783   0.0684194   -0.102462    -0.0276011    0.0102007   -0.221724      0.0955007  -0.0118178   -0.111798     0.098065    -0.1393      -0.0754432   -0.182658    0.108225    -0.0234227   -0.126017     0.0251262   -0.112205    -0.163653      0.00195731   -0.020967
  0.110334    -0.139977   -0.0786611    0.0299845   -0.16107     -0.116382   -0.245368    -0.0130628   -0.00235084   0.0575233    0.101184     -0.0557857  -0.0397047   -0.0531323    0.0277222    0.0585039    0.146861     0.0242192   0.108008    -0.0646704    0.0430023    0.0577782    0.00254988  -0.000198595  -0.0402538    -0.00886643
  0.0971056   -0.102484    0.0495021    0.0203416    0.0235101   -0.0256209   0.189391    -0.137043     0.305435    -0.0370953   -0.182216      0.0574288   0.087443    -0.0266337    0.0228756   -0.0803568   -0.0457129   -0.0246305  -0.00300997   0.307719    -0.475219    -0.0323392   -0.0030026    0.115707      0.200462     -0.0246114
  0.18057      0.166625    0.0410181    0.0262873   -0.0379312   -0.153855    0.0300144    0.223286     0.278582     0.0547917    0.0113229     0.0359234  -0.0074697    0.0138276   -0.153757     0.0422318   -0.0589887    0.0357722  -0.0537416   -0.311999     0.348326    -0.0562344   -0.0647706   -0.0122445    -0.135703     -0.172026
 -0.0864582    0.0869238   0.094064    -0.0630872    0.0120822   -0.0583843   0.118706     0.0388564    0.129542     0.0696205   -0.0344724    -0.0439534  -0.0290529   -0.0150718   -0.139371    -0.075708    -0.0605953   -0.0883914   0.161424     0.100208     0.0966383    0.041379     0.0800922   -0.0898896    -0.0260508     0.104889
 -0.0643375    0.0345527   0.05886      0.169579    -0.0634603   -0.0361709  -0.047914    -0.245593    -0.447342    -0.105457    -0.0145102    -0.0650114  -0.0615441   -0.0276616    0.0721433   -0.0736334   -0.057393     0.0499313   0.0564305   -0.0993291    0.0345277    0.110519     0.181067     0.0540466    -0.152369     -0.00248818
 -0.114591     0.166479    0.0951455    0.030213     0.177484     0.077098    0.103902    -0.0473533    0.00735049   0.0576955    0.0560885     0.103525    0.118118    -0.0954351   -0.0574399    0.0120564   -0.342259    -0.204292   -0.186043     0.0812262   -0.142784    -0.049014    -0.166383     0.153224     -0.0527659    -0.0430485
 -0.142064     0.196589   -0.0642837   -0.0980277   -0.150341     0.0694526   0.0388587    0.0966654   -0.095444     0.170433    -0.0454815     0.10952     0.0430895   -0.00506228   0.0694147    0.132027    -0.0376463   -0.0121204   0.238461    -0.0199971    0.0828708    0.156351     0.149282    -0.251818     -0.0902329     0.00577463
 -0.0860964   -0.0273417   0.0263082   -0.0541985    0.00703279  -0.436168    0.11496     -0.0754279   -0.142435     0.0130011    0.0290755     0.012952   -0.0332752   -0.0933899    0.0358505   -0.133492    -0.160777    -0.0658647  -0.073801    -0.0143349    0.132041     0.0537705   -0.0509517    0.129147     -0.107079     -0.172076
 -0.168992    -0.0220525  -0.0121989   -0.0468296   -0.00357136   0.700805    0.140644     0.100972     0.0153879    0.0339589    0.000314193  -0.0566189  -0.161485    -0.12269      0.0500835   -0.0735747   -0.132014    -0.04145    -0.0626057   -0.00640354  -0.00269431   0.0769487   -0.151135     0.175248     -0.123895     -0.184092[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049715
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     10
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016663
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.004584
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     10
│     11
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.028164
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.027357
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     10
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.025892
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.021289
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│     10
│     11
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.019498
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035494
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     10
│     11
│     12
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028342
┌ Info: EM with 100000 data points 10 iterations avll -1.028342
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.288085e+05
      1       6.506505e+05      -1.781580e+05 |       32
      2       6.198055e+05      -3.084503e+04 |       32
      3       6.051813e+05      -1.462417e+04 |       32
      4       5.980804e+05      -7.100869e+03 |       32
      5       5.938100e+05      -4.270430e+03 |       32
      6       5.910416e+05      -2.768399e+03 |       32
      7       5.887519e+05      -2.289669e+03 |       32
      8       5.869692e+05      -1.782750e+03 |       32
      9       5.858736e+05      -1.095550e+03 |       32
     10       5.850910e+05      -7.826089e+02 |       32
     11       5.844444e+05      -6.466443e+02 |       32
     12       5.838491e+05      -5.953080e+02 |       32
     13       5.832037e+05      -6.453765e+02 |       32
     14       5.826259e+05      -5.778030e+02 |       32
     15       5.820953e+05      -5.305591e+02 |       32
     16       5.815040e+05      -5.913123e+02 |       32
     17       5.809256e+05      -5.784611e+02 |       32
     18       5.805809e+05      -3.446616e+02 |       32
     19       5.804537e+05      -1.271768e+02 |       32
     20       5.803854e+05      -6.829588e+01 |       32
     21       5.803266e+05      -5.879515e+01 |       32
     22       5.802506e+05      -7.607953e+01 |       32
     23       5.801643e+05      -8.629953e+01 |       32
     24       5.800740e+05      -9.029640e+01 |       32
     25       5.799757e+05      -9.830570e+01 |       32
     26       5.798639e+05      -1.117775e+02 |       32
     27       5.797312e+05      -1.326425e+02 |       32
     28       5.795991e+05      -1.320963e+02 |       32
     29       5.794907e+05      -1.084130e+02 |       32
     30       5.794052e+05      -8.555845e+01 |       32
     31       5.793421e+05      -6.309319e+01 |       32
     32       5.793035e+05      -3.853981e+01 |       32
     33       5.792734e+05      -3.017920e+01 |       31
     34       5.792500e+05      -2.337240e+01 |       30
     35       5.792302e+05      -1.981333e+01 |       31
     36       5.792063e+05      -2.392183e+01 |       32
     37       5.791805e+05      -2.579578e+01 |       30
     38       5.791557e+05      -2.475237e+01 |       31
     39       5.791202e+05      -3.550383e+01 |       31
     40       5.790650e+05      -5.523147e+01 |       30
     41       5.790019e+05      -6.310391e+01 |       31
     42       5.789254e+05      -7.649416e+01 |       31
     43       5.788548e+05      -7.053443e+01 |       31
     44       5.788187e+05      -3.613316e+01 |       32
     45       5.788042e+05      -1.448089e+01 |       29
     46       5.787995e+05      -4.770371e+00 |       24
     47       5.787969e+05      -2.586474e+00 |       24
     48       5.787950e+05      -1.854560e+00 |       19
     49       5.787934e+05      -1.585121e+00 |       14
     50       5.787920e+05      -1.460446e+00 |       11
K-means terminated without convergence after 50 iterations (objv = 578791.9695574158)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303589
[ Info: iteration 2, average log likelihood -1.272246
[ Info: iteration 3, average log likelihood -1.245590
[ Info: iteration 4, average log likelihood -1.214511
[ Info: iteration 5, average log likelihood -1.174039
[ Info: iteration 6, average log likelihood -1.115216
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.041008
[ Info: iteration 8, average log likelihood -1.129974
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.071143
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063304
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     13
│     19
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.048646
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.087825
[ Info: iteration 13, average log likelihood -1.087676
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.025883
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.008545
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.112358
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.086931
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     14
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.045455
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.063920
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066978
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     10
│     11
│     14
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.012452
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     12
│     17
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.096594
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.067066
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.037774
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.030961
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.105616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.077093
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.042721
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.058630
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     11
│     12
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.029271
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.067915
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     18
│     19
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.060327
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.084089
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     14
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.047422
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.048978
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     17
│     18
│     22
│     24
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.023950
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090154
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.059185
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.072478
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     22
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.040602
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      9
│     14
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.025962
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     17
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.059440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.087450
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.047708
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      9
│     14
│     18
│     19
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.017482
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.076091
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.077911
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     22
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.030272
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     14
│     18
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.033551
┌ Info: EM with 100000 data points 50 iterations avll -1.033551
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.147204     0.0293703    0.0151625    0.0395659  -0.060009    -0.132787      0.0613419   -0.066672    -0.0166192    -0.0829941   -0.196997     -0.0288001  -0.0279459    0.0294227     0.0462305   -0.0278696   -0.0122787    0.0262225    0.0739051   -0.132819    -0.0500622   -0.0551839    0.113392    -0.0133843     0.00927754   0.0902249
 -0.0702541   -0.168748    -0.0346704    0.115907    0.0206099   -0.0501424     0.0555822    0.112028    -0.186856     -0.152882     0.0784344     0.0698161  -0.169763     0.0895962    -0.00736565   0.0366795   -0.0211553   -0.109284     0.136587     0.0826982    0.0249485    0.0846479    0.113375    -0.00509372    0.0772141   -0.107603
  0.0621465   -0.00128325  -0.010695    -0.016104    0.00906528  -0.0408429    -0.154884     0.176379    -0.0792882    -0.0798221   -0.106085      0.105694   -0.121599    -0.187461     -0.0431918   -0.178516     0.0638025   -0.0663407    0.0393914    0.00513465   0.101302    -0.0414011   -0.0217371   -0.129267     -0.0454425    0.0251342
 -0.114783     0.167021     0.0944297    0.0300991   0.176477     0.0734936     0.103168    -0.0479551    0.00736754    0.0582278    0.0559706     0.102935    0.120205    -0.0949928    -0.0581181    0.0121788   -0.344978    -0.203945    -0.183887     0.0812956   -0.141365    -0.0491135   -0.163938     0.148903     -0.0528649   -0.0419748
  0.00885264  -0.0121108   -0.11085     -0.0352593   0.0327985   -0.0630807    -0.0187044   -0.0781221    0.00429798   -0.0433498   -0.0114173    -0.112505   -0.0109346    0.00339953   -0.0578989   -0.00417703   0.0581207   -0.0439612    0.128573     0.0686389    0.0555159   -0.0238156    0.0521315    0.0567603    -0.0171211    0.113475
 -0.122849     0.168271    -0.0707849    0.14318     0.0386699    0.13097       0.0942447   -0.0728538    0.0813353    -0.0516954    0.0607521     0.22638    -0.0271941    0.0222303    -0.0287359    0.294965     0.014831    -0.102913    -0.0143741    0.00658699   0.0240003   -0.0135362   -0.194599    -0.0813334    -0.0252119   -0.167422
 -0.0141069   -0.0771326   -0.0327437    0.112643    0.0227777   -0.105133      0.0614403    0.122156    -0.213644     -0.149954     0.0793414     0.068239   -0.186627     0.0805393     0.0551479    0.0508298   -0.0586003   -0.130278     0.138827     0.0837538    0.00437257   0.0910666    0.116297     0.00313066    0.17678     -0.0162725
  0.0289055    0.0761677   -0.00796252   0.0432958   0.0575008    0.0212234    -0.109166     0.0503936   -0.160348     -0.103515     0.261659     -0.0423277  -0.133829    -0.0366954     0.131641    -0.125625    -0.121745    -0.030758     0.00527389  -0.0278664   -0.0848361   -0.104415     0.0640308   -0.106802      0.102503     0.0664138
  0.0995601   -0.0178434    0.0117417    0.016385    0.0442486   -0.068104     -0.143211     0.0881705    0.0340282     0.230305    -0.0144319     0.109561   -0.11578      0.00162594   -0.0397921   -0.0834433   -0.0638989    0.205237    -0.175208     0.133339     0.125359    -0.104331    -0.0145887    0.230759     -0.0440132    0.0577124
 -0.0491768   -0.0690346   -0.128852    -0.0204127  -0.155845    -0.139841     -0.155273     0.104008    -0.00183349   -0.0464792    0.197251      0.134531   -0.0139059    0.113061     -0.0536972   -0.00531708   0.0509312   -0.0454131    0.0280969   -0.0172729    0.134105     0.0105917   -0.109237    -0.00225907    0.105972    -0.027641
  0.12174     -0.0608371   -0.0607542    0.0599499  -0.0200287   -0.0803937    -0.0415413   -0.00677036   0.0794742    -0.0695884    0.0873663    -0.0466812  -0.0174991    0.0583695     0.134213    -0.12229      0.0460982   -0.0128165   -0.00883694   0.126294     0.025403     0.0431994   -0.00659422  -0.0016606     0.0756422   -0.036388
 -0.0297441   -0.0200046    0.101045     0.132043   -0.0116503   -0.0899018     0.00600179   0.0218452    0.215916      0.0303336    0.000317703  -0.0817181  -0.101446     0.107663      0.0396325   -0.0551909    0.195717    -0.0114169    0.0389567   -0.165741     0.208492     0.0482964    0.227605    -0.141922     -0.03475     -0.0700269
 -0.033258     0.178407     0.0756468    0.10926     0.133773    -0.145741     -0.0601221    0.105009    -0.144843     -0.00417719   0.0296738    -0.0483775   0.186868    -0.0138644    -0.0731303    0.169393    -0.076446     0.0606665   -0.088627     0.052007    -0.0632356   -0.0423123    0.192204    -0.0743256    -0.0826919   -0.0374196
  0.0316604   -0.155398     0.125032     0.146743    0.0819759    0.0647015     0.0333027    0.069306    -0.191346      0.0843225    0.0131511    -0.117776    0.00918779   0.0839768    -0.0295582    0.194516    -0.0469278    0.116861    -0.0528899   -0.0696733   -0.118391     0.040484     0.0186202   -0.0131078    -0.0935279   -0.00501693
 -0.124503    -0.0221856    0.0080638   -0.0520137   0.00135124   0.121148      0.129419     0.0171264   -0.0530464     0.024708     0.0157463    -0.0214782  -0.0948589   -0.107718      0.0442227   -0.102305    -0.147606    -0.0492489   -0.0680478   -0.0102095    0.0703014    0.0638194   -0.0965748    0.150385     -0.115325    -0.17869
 -0.0484806    0.0695919    0.0105845   -0.19555    -0.0415206    0.0551536     0.0949104    0.188525    -0.287684     -0.0222083    0.00992275    0.0608577   0.0108672    0.0936917     0.0026853   -0.116272     0.0538702    0.11636     -0.0572622    0.0421537    0.0985949   -0.141906    -0.12589     -0.0861916    -0.00321572  -0.0355835
 -0.13738      0.168357    -0.00853185   0.138767    0.0268478   -0.108501     -0.038181    -0.0727488    0.0237179    -0.269721    -0.179142     -0.160873   -0.0728273    0.127832     -0.129729     0.0603255   -0.0530539    0.0139672    0.115024    -0.0430685    0.00953361   0.0518424   -0.0374904    0.0942681    -0.0417664   -0.156419
  0.110834    -0.143166    -0.0760246    0.0296557  -0.163801    -0.117541     -0.243839    -0.0127239   -0.000775161   0.0608958    0.101677     -0.0553987  -0.0398065   -0.0529412     0.028074     0.0608822    0.149697     0.0243871    0.107178    -0.0652464    0.0440871    0.054383     0.00201161   0.000125861  -0.036423    -0.00811027
  0.0683823   -0.182772     0.0567449    0.0238819   0.0366425    0.0599057     0.140614    -0.200873    -0.0173732    -0.0400935   -0.227854      0.0484234   0.0906588   -0.0270281     0.0508854   -0.0912804   -0.0188164   -0.00928415   0.0294643    0.279762    -0.279121     0.00119051   0.0560518    0.15407       0.0844203   -0.0494343
  0.0364701   -0.101427    -0.176209     0.115246    0.0317221   -0.000801717  -0.060945    -0.0255985    0.10861      -0.0825842   -0.15398       0.0538199  -0.0106893   -0.245775      0.035058     0.0570327   -0.220002    -0.191357     0.0463397   -0.110589    -0.0433772    0.202989     0.00397656   0.0595977     0.112414    -0.0815391
  0.00238155   0.133546    -0.0432963   -0.14032     0.0366924   -0.107161      0.0671978   -0.102506    -0.0283146     0.0112449   -0.220422      0.0964512  -0.0122168   -0.11244       0.0964406   -0.138001    -0.0776878   -0.179373     0.107746    -0.0230224   -0.128446     0.0245246   -0.1097      -0.163181      0.00170919  -0.0202958
  0.140832    -0.0201287    0.066594     0.0231966   0.198658     0.0416823    -0.0703555   -0.00825067  -0.0696011    -0.046744     0.174697     -0.0865904  -0.00750168   0.0891404     0.307643     0.0865812   -0.102261     0.046026    -0.0912883    0.0965735   -0.0060597   -0.00230843  -0.0414495    0.0157186     0.107675    -0.0704588
 -0.151715    -0.0842836   -0.0182921   -0.0582781   0.103818     0.0129455    -0.0877157   -0.106531     0.00124364    0.0335315   -0.0326199    -0.139457   -0.325821    -0.0828316    -0.225736    -0.0348214   -0.00647673  -0.117374    -0.0386392   -0.109161    -0.00442904  -0.0296982    0.042757    -0.0355431     0.104361    -0.162878
 -0.0057535    0.127794     0.0446405    0.184142   -0.0649143   -0.118507     -0.0104971   -0.05416     -0.238592     -0.039693     0.0503551    -0.0482933  -0.0704244   -0.0248881    -0.0353779   -0.0654811   -0.12024      0.0402837    0.107424    -0.142525     0.118387     0.0607013    0.146902    -0.0268572    -0.0684592   -0.0259966
 -0.142599     0.195529    -0.0625978   -0.0987155  -0.151596     0.0736957     0.0407957    0.0975339   -0.0955483     0.170253    -0.041698      0.107691    0.0425313   -0.00491917    0.0725912    0.132489    -0.0382464   -0.0126501    0.238645    -0.0248941    0.0828935    0.157312     0.145405    -0.253056     -0.0892939    0.00500523
  0.0541739    0.136697     0.0285102    0.0332294  -0.0815657   -0.225733      0.0147898    0.00308437   0.32643       0.0468034   -0.084967      0.0338188  -0.0226747    0.000282763  -0.197534    -0.0274814   -0.0474302    0.0226866   -0.068936    -0.142548     0.0242872    0.0198607   -0.0114705   -0.018525     -0.107344    -0.111651
 -0.0499059    0.00836447  -0.0740232   -0.195065   -0.0795786   -0.0783502    -0.101656     0.194799     0.0354523     0.00712898   0.0506887    -0.092825   -0.0349891   -0.0482982     0.030865    -0.104576     0.063887    -0.0393777   -0.0575975    0.145035    -0.261302     0.064334    -0.0972219   -0.109767     -0.0591375    0.0945724
 -0.058296    -0.117024    -0.121132     0.0405991   0.0706231   -0.0147439     0.156611     0.00777661  -0.18862       0.0757677    0.0787006    -0.0097805   0.236014    -0.0778848    -0.0402411   -0.0213296    0.0356486    0.0395057   -0.257275    -0.0875404   -0.0741613    0.0180241    0.0113849   -0.0582146     0.0365155   -0.0865672
  0.0732736    0.151356     0.0609599   -0.0432529   0.0402115    0.0727528    -0.0678748   -0.0677627   -0.144921      0.187106     0.0735156    -0.0389897  -0.00665499   0.240919     -0.0103022    0.0729632    0.0913709    0.0797175   -0.0130084   -0.0696517   -0.0897934   -0.0398424    0.0168219   -0.115924     -0.00758571  -0.108611
  0.0885071   -0.0248219    0.0640244    0.028599   -0.280057    -0.0884882    -0.0557961    0.0974167   -0.042042     -0.0749636   -0.000932113  -0.0814961  -0.173596     0.0114075    -0.0738812    0.129689     0.205191    -0.0156018    0.0057197   -0.0107107   -0.0783777   -0.117826     0.0496332   -0.179423      0.0113976    0.118415
 -0.104425     0.130381    -0.0683425    0.0240887   0.017397     0.173001      0.0290174    0.0703254    0.149464     -0.068051     0.234374      0.002128   -0.0978905    0.0668081     0.261485    -0.0027315   -0.0104106    0.0640443   -0.0435914   -0.164254    -0.0171256   -0.154701    -0.323506    -0.0395428    -0.0689242   -0.0846155
 -0.00485978   0.0263829   -0.0507713   -0.128079   -0.105014    -0.0930644    -0.0177897   -0.0523413    0.23135       0.0267185    0.114655      0.212303   -0.00385553   0.06795       0.0882593    0.00353474  -0.121235     0.0729615   -0.114407    -0.072419     0.108925    -0.118128    -0.057131    -0.108353     -0.0784688    0.0291475[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.084527
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     10
│     12
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028565
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      7
│     10
│     12
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.973786
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     11
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.053863
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     12
│     13
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.035257
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      7
│     10
│     12
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.986090
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     12
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.030016
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     10
│     11
│     12
│     13
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.011790
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│     12
│     13
│      ⋮
│     19
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.012844
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     10
│     12
│     17
│     26
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.025534
┌ Info: EM with 100000 data points 10 iterations avll -1.025534
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0931876    0.0744874    0.14324     0.0272209   0.198836     0.223649     0.00533311   0.214982     0.0400246    -0.0989365   0.0774827   -0.0304164   -0.156611    -0.103338    -0.0702746   -0.0915644   -0.0221058    0.0528961     0.110361    -0.0501638   0.0581986   -0.0246908   -0.0712242    0.0601608     0.0123931    0.131503
 -0.00662635  -0.103992    -0.203763   -0.125995    0.0816369    0.0353424    0.0888486   -0.0511982   -0.0515501     0.0827095  -0.0777636   -0.135223     0.0367263    0.0387453    0.0151073   -0.064246     0.0961091    0.091397     -0.0356656   -0.0461351  -0.0326266   -0.0353574   -0.118567     0.0574162    -0.0104253   -0.0316439
 -0.240228    -0.0944157    0.111478   -0.169183    0.254469     0.0395757   -0.0950568   -0.238739    -0.239839     -0.0379855   0.0724069    0.0191733   -0.169066     0.0318924    0.0138764   -0.0176744    0.0132758   -0.138404     -0.0635078    0.0787492   0.0827908   -0.0831376   -0.0965326    0.0369106     0.0180574    0.0479866
  0.0736986    0.00709071  -0.119437   -0.0343383   0.0148635   -0.0275918    0.0548847    0.0873184    0.0562282    -0.0774448  -0.00896553  -0.0266228   -0.0384627    0.0435821   -0.00140023   0.116959     0.0523281    0.0333608     0.148373    -0.164196   -0.00535291   0.0581914    0.098043     0.0273727     0.238953     0.0865391
  0.113263     0.0317859   -0.0822338  -0.0321952  -0.0460847   -0.158278    -0.0192691    0.0653142   -0.0630384     0.0837781  -0.0368984    0.0609386   -0.0856998    0.227317     0.0340078    0.0352601    0.00495044  -0.113879      0.0351618   -0.0638654   0.0395052   -0.188342    -0.168141    -0.0867361    -0.041392    -0.120505
 -0.0849317   -0.245473    -0.0029833   0.0601279  -0.0587733   -0.0767137   -0.0301522    0.13054     -0.0975328    -0.108586   -0.0419237   -0.00444577   0.0078063   -0.0273977   -0.118144     0.116358    -0.0936375   -0.000902477   0.119833     0.0321183   0.0411313   -0.0966892    0.05183     -0.0267921     0.100597    -0.034149
  0.019125     0.100205     0.0289468   0.0666718   0.11447      0.095956     0.039754    -0.154398     0.00468367   -0.0131695   0.0104174   -0.195442     0.117045     0.0186519   -0.0490542    0.098688     0.051063    -0.0848286     0.100463    -0.0701545  -0.0211417    0.0779794    0.0507465   -0.105746      0.152629    -0.147816
 -0.0487216   -0.0790393    0.100579   -0.204653   -0.0851275   -0.0696658    0.0369864   -0.295931     0.0680308    -0.16116     0.0938158   -0.0283111    0.102869    -0.170979     0.143181    -0.0608723   -0.137162     0.152869     -0.195414    -0.043193    0.214751    -0.00219601   0.0694608    0.084042     -0.00945761  -0.0831845
 -0.051052     0.00764793  -0.0563886  -0.0285152  -0.109204    -0.0773982    0.163982    -0.0255303    0.170311      0.097374   -0.0464485    0.131972    -0.0625694   -0.0725966    0.0166055    0.211497     0.172513     0.11738      -0.0315787    0.141722   -0.04008      0.0971151   -0.130534     0.155033      0.14383      0.0395481
 -0.0648426    0.0749936    0.0810156  -0.129098    0.0201993   -0.027495    -0.00726907   0.115461    -0.038265     -0.125296    0.114354     0.0184502    0.142143     0.0981558   -0.0335477   -0.0405612   -0.217607    -0.0695598    -0.0279346    0.0962444   0.141563    -0.00792883  -0.210318     0.0566412     0.190682     0.0248342
 -0.0556542    0.102573    -0.0601618  -0.0980431  -0.0377396    0.186159    -0.0979656   -0.112674     0.0577981     0.0814309  -0.0166554   -0.062266     0.0529916    0.102212     0.0356237    0.0236768   -0.117382     0.0544102     0.069829    -0.0811747   0.169574     0.0744194   -0.0344186   -0.0248686    -0.0386116    0.0105165
  0.190713     0.123172     0.0589871   0.105262   -0.0111204    0.0855026   -0.131694    -0.0553052    0.000832591   0.0865563   0.00529048  -0.12702      0.0249201   -0.0127639   -0.186714    -0.00337001   0.0375467   -0.0210197    -0.184446    -0.222851   -0.0696348   -0.0745243    0.127544     0.124852     -0.208808     0.115026
  0.0278114   -0.0823111    0.0339941  -0.159963    0.0211986   -0.169836    -0.0420827   -0.15365     -0.0618255     0.0291672  -0.0664691    0.154704    -0.121785    -0.0699277    0.0136446   -0.137502     0.049063    -0.00362577   -0.0746254    0.0455747   0.0408352   -0.0720718    0.00410289   0.10791      -0.137444    -0.120941
 -0.0241314    0.171314    -0.04484    -0.188025    0.0353367   -0.0221189    0.197482     0.0219669   -0.0689512    -0.140096    0.0461079   -0.0357245    0.0273663    0.0658384   -0.0509522    0.0395073    0.00847541  -0.0183175     0.0180033   -0.0979621  -0.0462251    0.178446     0.130732    -0.00921607    0.0440598    0.0351091
  0.0688466   -0.136634    -0.161965   -0.0726679   0.257177    -0.0462063    0.143052     0.141855    -0.142861     -0.0440191   0.103338    -0.0393492    0.0442471    0.0946372   -0.112104    -0.0278608   -0.0411504   -0.0234727     0.014604     0.1183      0.0737983    0.0788817   -0.276326    -0.00249514   -0.0117079    0.0437836
  0.0269237    0.0645305   -0.0170782  -0.108206    0.0996297   -0.177807    -0.00242312   0.1293       0.070822      0.061255   -0.00832291  -0.167041    -0.218701    -0.00907398   0.181541    -0.00653974  -0.00578968   0.000810355   0.0748505    0.188269    0.127817     0.0796195   -0.0279739    0.0569842     0.0459332   -0.060522
 -0.0571085    0.0390216    0.0309786   0.0183369   0.022465    -0.0445378   -0.100477    -0.0241288    0.112215     -0.0188996   0.153134    -0.051257     0.0111732   -0.191481    -0.155041     0.115436     0.018678     0.16601      -0.0646686   -0.0710921  -0.10899      0.0418896    0.128631     0.0630906     0.0884938   -0.0190846
  0.0364456   -0.0316671   -0.0261157  -0.042622   -0.113426    -0.0187264    0.117202    -0.0795656    0.128955      0.0191148   0.0105322   -0.152558     0.039082     0.164539    -0.0608621   -0.105046     0.0163562   -0.0582135    -0.196065    -0.0236562  -0.069248     0.00125841   0.151552    -0.0046304    -0.135983    -0.017267
 -0.2435       0.118005    -0.0332654   0.0554921   0.0468798   -0.0536634   -0.216945    -0.0527462   -0.126215      0.140495   -0.0487667    0.019023    -0.0307392   -0.00840057   0.0858245    0.0172085    0.0694205    0.173397     -0.00168118  -0.0952307  -0.0699835   -0.169474    -0.0444704   -0.0443581     0.0101807   -0.105255
  0.0863267   -0.111209    -0.0459745  -0.0330668   0.117299    -0.0737437    0.144731    -0.0777726   -0.00660756    0.0317945   0.122767    -0.0812789   -0.0966498    0.0226696    0.0594936    0.0821219    0.0333035    0.194676     -0.0981815    0.0596394   0.0347882    0.102623    -0.118922    -0.000283696   0.0138399    0.20431
  0.00501643   0.00430039  -0.119203   -0.120079    0.0669768    0.0791825    0.0765446   -0.0942337   -0.026387     -0.0802152   0.0474389   -0.015682     0.101273     0.0725376   -0.0705702    0.0304126   -0.00936931   0.0320668    -0.0653678   -0.129369    0.229516     0.0449009    0.00128512  -0.056816      0.0309161    0.164819
 -0.0781169    0.224476    -0.0404019   0.121153   -0.0139962   -0.0884124    0.0288805    0.11965      0.114218     -0.105731   -0.0962407   -0.0972971   -0.0699786   -0.028799    -0.00264582   0.0510806    0.0249388    0.0777412     0.0828086    0.0546971  -0.121049     0.0153053    0.151741    -0.096507     -0.0313465   -0.0194614
 -0.123046    -0.0117525   -0.0654412   0.0921855  -0.00998602  -0.00731274  -0.158438    -0.159622     0.0329632    -0.17005     0.0832402    0.162353    -0.0295785   -0.0640418   -0.0799639   -0.12111     -0.145164     0.0435884    -0.0945968   -0.0933397   0.0726912   -0.0230098    0.059811     9.08071e-5   -0.076579    -0.0486456
  0.0215397   -0.00550533   0.0497922   0.0602353   0.0728752    0.0714277    0.0128826   -0.163028     0.0943599     0.0781122  -0.0217485    0.0196893    0.173775     0.123121     0.0890352   -0.111339     0.0164609    0.182568      0.0723656   -0.0558701   0.0112552    0.0101276   -0.033529     0.124774     -0.178606    -0.217528
  0.0756265    0.019733     0.175283   -0.11717    -0.0109976    0.202977     0.0361542   -0.0092485    0.0301121     0.176925    0.0314245   -0.0196873    0.0302659    0.0120788    0.11917     -0.139573     0.0866746   -0.0502922    -0.100381     0.0311023   0.00232114   0.0519045   -0.0624247    0.0428341     0.0592115   -0.000877033
 -0.0748239    0.226197    -0.0374628  -0.0625615  -0.0549087    0.0924419   -0.120615    -0.0525514    0.0301717    -0.193045    0.18993     -0.106746    -0.212101    -0.112208    -0.103775     0.0311257   -0.0133715    0.107943      0.100942    -0.0437115   0.101945    -0.0780573   -0.109863     0.00615      -0.0178575    0.037094
 -0.0899177    0.0492183    0.199623   -0.0318736   0.047105    -0.0853974   -0.359934     0.0522687   -0.0612051    -0.135521   -0.0121053    0.100334     0.127026     0.0381608   -0.0235385   -0.127879     0.0281602   -0.0371116    -0.0045073   -0.0178266   0.0718876    0.102157     0.00686863  -0.0122421    -0.171901    -0.079089
  0.0711953    0.220703    -0.0823958   0.149995   -0.099305    -0.0899693    0.0551802   -0.101809     0.0429528     0.248252    0.0110532   -0.0879975    0.22764      0.0658345   -0.0641523    0.147465    -0.00755769  -0.0440312     0.0316578   -0.0984243   0.0677195   -0.0184676   -0.0687361    0.175183      0.0545211    0.00734729
  0.0725612   -0.057364     0.110378   -0.0795204  -0.0593361    0.025706     0.165181    -0.00219974  -0.0280133    -0.048376   -0.0307688    0.107686     0.0326169   -0.058941     0.128111     0.0798329    0.128146    -0.0490858    -0.0746123   -0.119829   -0.113159     0.0769572   -0.127149     0.0444522     0.039199     0.114197
 -0.00855036  -0.10354      0.0347013  -0.148044    0.164375     0.0604274    0.0563313   -0.116736    -0.097696      0.0100893  -0.156883     0.248486     0.0924152    0.0449804   -0.105029    -0.150005    -0.0230055    0.0108169    -0.0656693    0.0131528  -0.0345866    0.0109777    0.00440717   0.00241521   -0.152045    -0.123467
 -0.0656966    0.160956     0.0255947   0.0350848   0.135035     0.0612813    0.0320902   -0.0494189   -0.0226407     0.0861966  -0.0433395   -0.152928    -0.146047    -0.022764     0.124086    -0.0283653   -0.0555048   -0.197194      0.00080664   0.0599083   0.037017    -0.0650483   -0.11059     -0.131449     -0.0831703   -0.158399
 -0.0241861    0.102193     0.100154   -0.0170763   0.0260633    0.114982     0.11478      0.23258     -0.121845      0.0439235   0.0513961   -0.0828898    0.00549849  -0.0739464    0.0788531    0.0283166    0.0735542   -0.115297      0.0183848   -0.0456198  -0.0502933    0.0844541    0.0298857    0.120859     -0.0566198   -0.0636007kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4231889866055292
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423209
[ Info: iteration 2, average log likelihood -1.423142
[ Info: iteration 3, average log likelihood -1.423091
[ Info: iteration 4, average log likelihood -1.423031
[ Info: iteration 5, average log likelihood -1.422958
[ Info: iteration 6, average log likelihood -1.422871
[ Info: iteration 7, average log likelihood -1.422771
[ Info: iteration 8, average log likelihood -1.422653
[ Info: iteration 9, average log likelihood -1.422495
[ Info: iteration 10, average log likelihood -1.422234
[ Info: iteration 11, average log likelihood -1.421760
[ Info: iteration 12, average log likelihood -1.420960
[ Info: iteration 13, average log likelihood -1.419883
[ Info: iteration 14, average log likelihood -1.418871
[ Info: iteration 15, average log likelihood -1.418229
[ Info: iteration 16, average log likelihood -1.417924
[ Info: iteration 17, average log likelihood -1.417797
[ Info: iteration 18, average log likelihood -1.417745
[ Info: iteration 19, average log likelihood -1.417724
[ Info: iteration 20, average log likelihood -1.417715
[ Info: iteration 21, average log likelihood -1.417711
[ Info: iteration 22, average log likelihood -1.417709
[ Info: iteration 23, average log likelihood -1.417707
[ Info: iteration 24, average log likelihood -1.417706
[ Info: iteration 25, average log likelihood -1.417706
[ Info: iteration 26, average log likelihood -1.417705
[ Info: iteration 27, average log likelihood -1.417704
[ Info: iteration 28, average log likelihood -1.417704
[ Info: iteration 29, average log likelihood -1.417704
[ Info: iteration 30, average log likelihood -1.417703
[ Info: iteration 31, average log likelihood -1.417703
[ Info: iteration 32, average log likelihood -1.417703
[ Info: iteration 33, average log likelihood -1.417702
[ Info: iteration 34, average log likelihood -1.417702
[ Info: iteration 35, average log likelihood -1.417702
[ Info: iteration 36, average log likelihood -1.417702
[ Info: iteration 37, average log likelihood -1.417701
[ Info: iteration 38, average log likelihood -1.417701
[ Info: iteration 39, average log likelihood -1.417701
[ Info: iteration 40, average log likelihood -1.417701
[ Info: iteration 41, average log likelihood -1.417701
[ Info: iteration 42, average log likelihood -1.417701
[ Info: iteration 43, average log likelihood -1.417701
[ Info: iteration 44, average log likelihood -1.417701
[ Info: iteration 45, average log likelihood -1.417701
[ Info: iteration 46, average log likelihood -1.417700
[ Info: iteration 47, average log likelihood -1.417700
[ Info: iteration 48, average log likelihood -1.417700
[ Info: iteration 49, average log likelihood -1.417700
[ Info: iteration 50, average log likelihood -1.417700
┌ Info: EM with 100000 data points 50 iterations avll -1.417700
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.423208621661294
│     -1.423141986845116
│      ⋮
└     -1.4177002277953483
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417720
[ Info: iteration 2, average log likelihood -1.417650
[ Info: iteration 3, average log likelihood -1.417596
[ Info: iteration 4, average log likelihood -1.417531
[ Info: iteration 5, average log likelihood -1.417453
[ Info: iteration 6, average log likelihood -1.417363
[ Info: iteration 7, average log likelihood -1.417270
[ Info: iteration 8, average log likelihood -1.417184
[ Info: iteration 9, average log likelihood -1.417111
[ Info: iteration 10, average log likelihood -1.417053
[ Info: iteration 11, average log likelihood -1.417007
[ Info: iteration 12, average log likelihood -1.416967
[ Info: iteration 13, average log likelihood -1.416930
[ Info: iteration 14, average log likelihood -1.416893
[ Info: iteration 15, average log likelihood -1.416856
[ Info: iteration 16, average log likelihood -1.416817
[ Info: iteration 17, average log likelihood -1.416778
[ Info: iteration 18, average log likelihood -1.416739
[ Info: iteration 19, average log likelihood -1.416701
[ Info: iteration 20, average log likelihood -1.416666
[ Info: iteration 21, average log likelihood -1.416634
[ Info: iteration 22, average log likelihood -1.416607
[ Info: iteration 23, average log likelihood -1.416584
[ Info: iteration 24, average log likelihood -1.416565
[ Info: iteration 25, average log likelihood -1.416550
[ Info: iteration 26, average log likelihood -1.416538
[ Info: iteration 27, average log likelihood -1.416529
[ Info: iteration 28, average log likelihood -1.416522
[ Info: iteration 29, average log likelihood -1.416515
[ Info: iteration 30, average log likelihood -1.416511
[ Info: iteration 31, average log likelihood -1.416507
[ Info: iteration 32, average log likelihood -1.416503
[ Info: iteration 33, average log likelihood -1.416500
[ Info: iteration 34, average log likelihood -1.416498
[ Info: iteration 35, average log likelihood -1.416496
[ Info: iteration 36, average log likelihood -1.416494
[ Info: iteration 37, average log likelihood -1.416492
[ Info: iteration 38, average log likelihood -1.416491
[ Info: iteration 39, average log likelihood -1.416489
[ Info: iteration 40, average log likelihood -1.416488
[ Info: iteration 41, average log likelihood -1.416487
[ Info: iteration 42, average log likelihood -1.416486
[ Info: iteration 43, average log likelihood -1.416485
[ Info: iteration 44, average log likelihood -1.416484
[ Info: iteration 45, average log likelihood -1.416483
[ Info: iteration 46, average log likelihood -1.416482
[ Info: iteration 47, average log likelihood -1.416481
[ Info: iteration 48, average log likelihood -1.416480
[ Info: iteration 49, average log likelihood -1.416480
[ Info: iteration 50, average log likelihood -1.416479
┌ Info: EM with 100000 data points 50 iterations avll -1.416479
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417719655496095
│     -1.4176498275355127
│      ⋮
└     -1.4164789741600694
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416489
[ Info: iteration 2, average log likelihood -1.416431
[ Info: iteration 3, average log likelihood -1.416382
[ Info: iteration 4, average log likelihood -1.416325
[ Info: iteration 5, average log likelihood -1.416256
[ Info: iteration 6, average log likelihood -1.416172
[ Info: iteration 7, average log likelihood -1.416075
[ Info: iteration 8, average log likelihood -1.415971
[ Info: iteration 9, average log likelihood -1.415868
[ Info: iteration 10, average log likelihood -1.415773
[ Info: iteration 11, average log likelihood -1.415690
[ Info: iteration 12, average log likelihood -1.415619
[ Info: iteration 13, average log likelihood -1.415558
[ Info: iteration 14, average log likelihood -1.415505
[ Info: iteration 15, average log likelihood -1.415459
[ Info: iteration 16, average log likelihood -1.415418
[ Info: iteration 17, average log likelihood -1.415381
[ Info: iteration 18, average log likelihood -1.415348
[ Info: iteration 19, average log likelihood -1.415319
[ Info: iteration 20, average log likelihood -1.415293
[ Info: iteration 21, average log likelihood -1.415269
[ Info: iteration 22, average log likelihood -1.415247
[ Info: iteration 23, average log likelihood -1.415228
[ Info: iteration 24, average log likelihood -1.415210
[ Info: iteration 25, average log likelihood -1.415193
[ Info: iteration 26, average log likelihood -1.415178
[ Info: iteration 27, average log likelihood -1.415164
[ Info: iteration 28, average log likelihood -1.415151
[ Info: iteration 29, average log likelihood -1.415138
[ Info: iteration 30, average log likelihood -1.415127
[ Info: iteration 31, average log likelihood -1.415117
[ Info: iteration 32, average log likelihood -1.415107
[ Info: iteration 33, average log likelihood -1.415097
[ Info: iteration 34, average log likelihood -1.415089
[ Info: iteration 35, average log likelihood -1.415081
[ Info: iteration 36, average log likelihood -1.415073
[ Info: iteration 37, average log likelihood -1.415066
[ Info: iteration 38, average log likelihood -1.415060
[ Info: iteration 39, average log likelihood -1.415054
[ Info: iteration 40, average log likelihood -1.415048
[ Info: iteration 41, average log likelihood -1.415043
[ Info: iteration 42, average log likelihood -1.415038
[ Info: iteration 43, average log likelihood -1.415033
[ Info: iteration 44, average log likelihood -1.415028
[ Info: iteration 45, average log likelihood -1.415024
[ Info: iteration 46, average log likelihood -1.415020
[ Info: iteration 47, average log likelihood -1.415016
[ Info: iteration 48, average log likelihood -1.415012
[ Info: iteration 49, average log likelihood -1.415008
[ Info: iteration 50, average log likelihood -1.415005
┌ Info: EM with 100000 data points 50 iterations avll -1.415005
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4164892352298124
│     -1.4164305884695314
│      ⋮
└     -1.415004685316114
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415010
[ Info: iteration 2, average log likelihood -1.414962
[ Info: iteration 3, average log likelihood -1.414918
[ Info: iteration 4, average log likelihood -1.414868
[ Info: iteration 5, average log likelihood -1.414807
[ Info: iteration 6, average log likelihood -1.414732
[ Info: iteration 7, average log likelihood -1.414642
[ Info: iteration 8, average log likelihood -1.414537
[ Info: iteration 9, average log likelihood -1.414424
[ Info: iteration 10, average log likelihood -1.414308
[ Info: iteration 11, average log likelihood -1.414197
[ Info: iteration 12, average log likelihood -1.414096
[ Info: iteration 13, average log likelihood -1.414007
[ Info: iteration 14, average log likelihood -1.413930
[ Info: iteration 15, average log likelihood -1.413864
[ Info: iteration 16, average log likelihood -1.413807
[ Info: iteration 17, average log likelihood -1.413757
[ Info: iteration 18, average log likelihood -1.413713
[ Info: iteration 19, average log likelihood -1.413674
[ Info: iteration 20, average log likelihood -1.413639
[ Info: iteration 21, average log likelihood -1.413607
[ Info: iteration 22, average log likelihood -1.413579
[ Info: iteration 23, average log likelihood -1.413553
[ Info: iteration 24, average log likelihood -1.413529
[ Info: iteration 25, average log likelihood -1.413507
[ Info: iteration 26, average log likelihood -1.413487
[ Info: iteration 27, average log likelihood -1.413467
[ Info: iteration 28, average log likelihood -1.413449
[ Info: iteration 29, average log likelihood -1.413431
[ Info: iteration 30, average log likelihood -1.413413
[ Info: iteration 31, average log likelihood -1.413397
[ Info: iteration 32, average log likelihood -1.413380
[ Info: iteration 33, average log likelihood -1.413364
[ Info: iteration 34, average log likelihood -1.413347
[ Info: iteration 35, average log likelihood -1.413331
[ Info: iteration 36, average log likelihood -1.413315
[ Info: iteration 37, average log likelihood -1.413298
[ Info: iteration 38, average log likelihood -1.413282
[ Info: iteration 39, average log likelihood -1.413265
[ Info: iteration 40, average log likelihood -1.413248
[ Info: iteration 41, average log likelihood -1.413231
[ Info: iteration 42, average log likelihood -1.413214
[ Info: iteration 43, average log likelihood -1.413197
[ Info: iteration 44, average log likelihood -1.413179
[ Info: iteration 45, average log likelihood -1.413162
[ Info: iteration 46, average log likelihood -1.413144
[ Info: iteration 47, average log likelihood -1.413126
[ Info: iteration 48, average log likelihood -1.413109
[ Info: iteration 49, average log likelihood -1.413092
[ Info: iteration 50, average log likelihood -1.413075
┌ Info: EM with 100000 data points 50 iterations avll -1.413075
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4150103917680963
│     -1.414962116379965
│      ⋮
└     -1.4130754395019693
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413068
[ Info: iteration 2, average log likelihood -1.412991
[ Info: iteration 3, average log likelihood -1.412917
[ Info: iteration 4, average log likelihood -1.412831
[ Info: iteration 5, average log likelihood -1.412724
[ Info: iteration 6, average log likelihood -1.412591
[ Info: iteration 7, average log likelihood -1.412432
[ Info: iteration 8, average log likelihood -1.412252
[ Info: iteration 9, average log likelihood -1.412062
[ Info: iteration 10, average log likelihood -1.411873
[ Info: iteration 11, average log likelihood -1.411694
[ Info: iteration 12, average log likelihood -1.411530
[ Info: iteration 13, average log likelihood -1.411385
[ Info: iteration 14, average log likelihood -1.411257
[ Info: iteration 15, average log likelihood -1.411145
[ Info: iteration 16, average log likelihood -1.411048
[ Info: iteration 17, average log likelihood -1.410963
[ Info: iteration 18, average log likelihood -1.410888
[ Info: iteration 19, average log likelihood -1.410823
[ Info: iteration 20, average log likelihood -1.410765
[ Info: iteration 21, average log likelihood -1.410713
[ Info: iteration 22, average log likelihood -1.410667
[ Info: iteration 23, average log likelihood -1.410626
[ Info: iteration 24, average log likelihood -1.410589
[ Info: iteration 25, average log likelihood -1.410555
[ Info: iteration 26, average log likelihood -1.410523
[ Info: iteration 27, average log likelihood -1.410494
[ Info: iteration 28, average log likelihood -1.410468
[ Info: iteration 29, average log likelihood -1.410442
[ Info: iteration 30, average log likelihood -1.410419
[ Info: iteration 31, average log likelihood -1.410396
[ Info: iteration 32, average log likelihood -1.410375
[ Info: iteration 33, average log likelihood -1.410355
[ Info: iteration 34, average log likelihood -1.410335
[ Info: iteration 35, average log likelihood -1.410316
[ Info: iteration 36, average log likelihood -1.410298
[ Info: iteration 37, average log likelihood -1.410280
[ Info: iteration 38, average log likelihood -1.410263
[ Info: iteration 39, average log likelihood -1.410247
[ Info: iteration 40, average log likelihood -1.410231
[ Info: iteration 41, average log likelihood -1.410215
[ Info: iteration 42, average log likelihood -1.410200
[ Info: iteration 43, average log likelihood -1.410185
[ Info: iteration 44, average log likelihood -1.410171
[ Info: iteration 45, average log likelihood -1.410158
[ Info: iteration 46, average log likelihood -1.410145
[ Info: iteration 47, average log likelihood -1.410132
[ Info: iteration 48, average log likelihood -1.410120
[ Info: iteration 49, average log likelihood -1.410109
[ Info: iteration 50, average log likelihood -1.410098
┌ Info: EM with 100000 data points 50 iterations avll -1.410098
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4130677681432977
│     -1.4129912400035778
│      ⋮
└     -1.410097624558206
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4231889866055292
│     -1.423208621661294
│     -1.423141986845116
│     -1.4230911550301912
│      ⋮
│     -1.4101201564203572
│     -1.4101086427205243
└     -1.410097624558206
32×26 Array{Float64,2}:
  0.103515     0.035928     0.204622    0.323509    -0.856321    -0.387904    -0.126894      0.64117     -0.500378    0.0927194  -0.0202792     0.113707   -0.534296    0.0264506   0.286934    0.631303    0.139928    0.0981865    0.343992    -0.35453      0.195049     0.2701     -0.675138     0.118718   -0.171882    0.565575
 -0.375522     0.411415     0.0859718  -0.311243     0.400457    -0.0851315   -0.311573      0.483795    -0.421463   -0.172616    0.0752133     0.171347   -0.593566   -0.032667    0.0857366   0.602215   -0.39007    -0.0998512   -0.159864    -0.257504     0.569046     0.454818    0.099049     0.0297323   0.126631   -0.203573
 -0.314598    -0.347097     0.69995    -0.394279    -0.577432     0.0316025    0.375449      0.231887     0.0918664  -0.0922845  -0.978932      0.466209    0.400316   -0.143775   -0.427548    0.473861   -0.128308   -0.0282524   -0.221122     0.0349016    0.0905534   -0.0738839   0.363266    -0.266476    0.391521   -0.0552313
  0.267753    -0.289044     0.442642   -0.291568    -0.661177    -0.0433493    0.216527      0.502021    -0.114976    0.779022   -0.423551     -0.336916    0.454729    0.802468    0.377666    0.444941    0.0126204   0.135359     0.182402    -0.179839     0.31217      0.210573   -0.367369    -0.621087   -0.403501   -0.204625
  0.00713335   0.264368    -0.269592   -0.264599    -0.461842    -0.26276     -0.567412      0.315357     0.230502    0.0799474  -0.170064      0.653375   -0.157463    0.342231   -0.0649688  -0.0650276  -0.163932   -0.277122    -0.27593     -0.270254     0.0153851   -0.623708    0.380915    -0.0808607   0.394814   -0.39239
 -0.186201    -0.382484     0.0349929   0.0285198    0.312609    -0.171458     0.831909      0.315485    -0.0852463  -0.0666375   0.328941      0.901086   -0.159218    0.628041    0.321243   -0.460464    0.0415879  -0.0145402   -0.190901    -0.5877       0.00258697  -0.195688    0.16142     -0.206764    0.394716    0.433614
  0.237006     0.00613268   0.124379    0.352966     0.361639    -0.0527676   -0.601623     -0.171545    -0.137174   -0.589204    0.143941      0.681367   -0.52015     0.148956   -0.294242   -0.634011    0.466397   -0.464659     0.10179     -0.230344    -0.147454    -0.0267909   0.0586597   -0.336161   -0.888553   -0.24421
  0.624973     0.104302     0.678464   -0.245849    -0.192982     0.378166     0.149994     -0.175361     0.181568   -0.110773   -0.138503      0.176548   -0.381613    0.193298   -0.0307745  -0.506561    0.393434    0.762537    -0.295636    -0.121842    -0.31903      0.106756    0.00416825  -0.17807    -0.519813    0.675946
 -0.435767    -0.226674     0.297916   -0.145107    -0.250213    -0.0250478   -0.550637     -0.189501     0.0676825  -0.668206    0.342639     -0.293281    0.276077   -0.242792    0.157896   -0.196181   -0.324491    0.182256    -0.660201     0.118228    -0.365877    -0.460232    0.606021    -0.267226   -0.354062    0.316605
 -0.128143    -0.0508659   -0.38963    -0.265596     1.07615      0.311629    -0.209796     -0.54696      0.45071    -0.123343    0.269267     -0.0381713   1.05862    -0.0207505  -0.701335   -0.317373   -0.586938    0.0890795   -0.00911902   0.401744    -0.170153     0.0976548   0.966435     0.163718    0.276237   -0.745502
 -0.660445     0.0952218   -0.553037    0.153566    -0.0867194    0.209687    -0.378268     -0.282158    -0.61989    -0.142825    0.572933     -0.709699    0.33208    -0.721628    0.0928717  -0.0304973  -0.180762    0.247838     0.355543     0.115076     0.487126    -0.499787   -0.0361147    0.718907    0.474673   -0.906216
  0.507683     0.396903     0.265364   -0.0208498    0.165186    -0.566025    -0.0547005    -0.667817    -0.533349    0.170558   -0.080934     -0.472968   -0.0388153  -0.236652    0.0503216   0.323648    0.285967    0.472339     0.155244    -0.100497     0.239381    -0.305322    0.287968    -0.11081     0.176671   -0.434041
 -0.0318747    0.154342     0.0243591   0.0854292    0.0781373    0.18683     -0.0962783    -0.0554822    0.0437484  -0.0633529  -0.000512336  -0.194868   -0.0285512  -0.0424674  -0.0904068   0.127991   -0.0430356  -0.0673983   -0.251123     0.0802883    0.194882     0.149454   -0.0910391    0.125012    0.0390865  -0.138457
 -0.0561379   -0.355827    -0.469451   -0.0857975    0.258642    -0.180819     0.301168      0.0512407   -0.130019    0.147853    0.293488     -0.158295    0.0801723  -0.125143    0.180373   -0.164089    0.29586    -0.00560547   0.757266     0.130581    -0.411944     0.0242612  -0.367906     0.230088   -0.383101    0.10281
 -0.119459     0.22105     -0.173318   -0.0472178    0.296009     0.396191     0.687313      0.314527     0.128623   -0.712672   -0.073654      0.420284   -0.0408947   0.235899    0.131357   -0.203859   -0.0240092  -0.717767     0.776662     0.626058     0.138062     0.298339   -0.0467305    0.142352   -0.102297    0.847374
  0.281929     0.564715    -0.38594     0.453562     0.194482     0.122205     0.734995     -0.105206     0.163866    0.665969   -0.098103     -0.0401418  -0.0913565   0.64741    -0.169293   -0.0590231  -0.083516   -0.809708     0.329277     0.127312    -0.270912     0.459313   -0.227386    -0.41139    -0.110927    0.35825
  0.144912     0.419977     0.208345    0.607595    -0.0887012    0.0658002   -0.236239      0.156327     0.488639    0.441594   -0.0085098    -0.0700237   0.506592   -0.355534   -0.427423    0.190021   -0.431655   -0.543675    -0.368661     0.241231     0.716244     0.670226   -0.292738    -0.632985    0.48346    -0.797528
  0.107187     0.628808    -0.328933    0.0528302    0.00655343   0.0483605   -0.236715     -0.304091     0.0755191  -0.124264   -0.412434     -0.558052    0.0938162  -0.568233   -0.214057    0.504318    0.175007   -0.284818     0.11163      0.507569     0.406577     0.439044   -0.239584     0.519239   -0.0279744  -0.510751
 -0.158046     0.11891     -0.621018    0.00972412  -0.250071     0.349084    -0.130802      0.294029     0.669397    0.42122     0.490055     -0.396703    0.126594    0.205145   -0.526503   -0.519691   -0.734118   -0.255011    -0.350856    -0.0564618    0.0745507    0.25712    -0.385723     0.0329693  -0.0678304   0.053043
 -0.19285     -0.00248242  -0.227625   -0.237375    -0.277453     0.349355    -0.075812      0.43705      0.553897    0.251478   -0.0610262    -0.042844    0.141296   -0.401695    0.588374    0.174155   -0.356956   -0.221497     0.294938    -0.298464    -0.017868    -0.280262   -0.239608     0.349254    0.760479    0.149173
  0.30674      0.303028    -0.0761773  -0.164643    -0.307196    -0.150328    -0.640716     -0.197472    -0.219192   -0.353751   -0.0860567     0.257067   -0.0286462   0.308021   -0.0271365   0.0100852  -0.259964   -0.260891    -0.149597     0.0871915   -0.0385046   -0.259716    0.448005    -0.271927   -0.242382   -0.199647
  0.122882    -0.107518    -0.0703862   0.155999    -0.163367    -0.240224    -0.663106     -0.353115     0.170757    0.268474   -0.0763611    -0.570391   -0.0918727  -0.298731   -0.181498    0.157097   -0.137321    0.424254    -0.629448    -0.210865    -0.199571    -0.171953    0.0188441    0.13576    -0.106809   -0.800794
 -0.346721    -0.0439493   -0.108921   -0.0432272    0.19729     -0.178794     0.0870899     0.247397    -0.450462    0.280465    0.220433      0.247859   -0.0987601   0.498348   -0.451605    0.227504    0.0351418  -0.0301706    0.117912    -0.0256839    0.397747    -0.176294    0.0660232   -0.0213555  -0.0290782   0.00995274
 -0.0413116   -0.0298822   -0.0880072   0.0344251    0.0788514    0.0157058   -0.000754111   0.0439594    0.0423331   0.0180465   0.147453      0.0011366  -0.0119745   0.0143981   0.106014   -0.0213666  -0.0914951  -0.0833998    0.0692932   -0.0825646   -0.0126641    0.0579166  -0.0987379    0.0723484   0.0425563   0.0334642
  0.0349631    0.0415822    0.301561    0.01948      0.305832     0.108586     0.266587     -0.617424     0.233526   -0.190317   -0.236592      0.0388049   0.145442   -0.0203949  -0.136708   -0.398164    0.296119   -0.0588111   -0.42195     -0.0692014    0.104499    -0.238527    0.214577    -0.0835334   0.164084    0.0867089
 -0.084235     0.35287      0.211757   -0.406483    -0.229315     0.148054     0.0343912     0.302045     0.157928   -0.145137   -0.196725     -0.295823   -0.126369   -0.490487   -0.238747    0.0730505  -0.0783578   0.210981     0.0495732    0.155772     0.073866     0.331034   -0.0875035   -0.156345   -0.101471    0.191628
 -0.0570708   -0.315259    -0.357729   -0.673761     0.128253     0.0192411    0.305396      0.00423871  -0.152596    0.0230031   0.0945208    -0.0393892  -0.292565    0.0104682   0.411099   -0.157145    0.391359    0.302487     0.262176    -0.126352    -0.776469    -0.415604    0.155637     0.254106   -0.197666    0.589916
  0.504977    -1.31457e-5   0.199008   -0.147958    -0.0232651   -0.0946877    0.459652     -0.233874    -0.419677   -0.0457238  -0.227764     -0.190025    0.299788    0.201015    0.552116    0.137652    0.383644    0.471703     0.229318     0.105831     0.0986684    0.0736193  -0.0768295   -0.204859   -0.0551917  -0.124828
 -0.138125     0.107187    -0.317846    0.578232     0.479375    -0.270585     0.284757     -0.64335     -0.0143633  -0.215406    0.462406      0.331899   -0.56541    -0.344545   -0.180289    0.0096669  -0.201454   -0.11042     -0.203662    -0.0566594   -0.070883     0.30821    -0.0807662    1.09993     0.500811    0.0903874
  0.310853     0.177126    -0.362698    0.178339     0.512329     0.0983109   -0.455949     -0.537365    -0.170832   -0.105979    0.899023     -0.32062     0.270426    0.0445575   0.247401   -0.71544    -0.116365    0.433903     0.356761    -0.00723198   0.137435     0.22051    -0.294921     0.633774   -0.476845    0.0641939
 -0.320308    -0.718101     0.261795    0.288455     0.407672     0.291805    -0.109084     -0.120963     0.092912    0.203152   -0.192908     -0.0407533   0.117849   -0.0476151  -0.134001    0.0176614   0.548241   -0.115519     0.140426    -0.132683    -0.326415     0.181504   -0.865834     0.078769   -0.282495   -0.253411
 -0.340372    -0.693864     0.142256    0.094977     0.561157     0.00526339   1.02047      -0.154712     0.225137    0.0983591   0.163424     -0.799668    0.231568   -0.28093     0.196385    0.198766    0.20366     0.420475    -0.213723     0.330542     0.0831696    0.441716   -0.54643      0.443458    0.116533    0.419839[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410087
[ Info: iteration 2, average log likelihood -1.410077
[ Info: iteration 3, average log likelihood -1.410067
[ Info: iteration 4, average log likelihood -1.410058
[ Info: iteration 5, average log likelihood -1.410049
[ Info: iteration 6, average log likelihood -1.410041
[ Info: iteration 7, average log likelihood -1.410033
[ Info: iteration 8, average log likelihood -1.410025
[ Info: iteration 9, average log likelihood -1.410017
[ Info: iteration 10, average log likelihood -1.410010
┌ Info: EM with 100000 data points 10 iterations avll -1.410010
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.099704e+05
      1       7.084103e+05      -2.015600e+05 |       32
      2       6.921095e+05      -1.630081e+04 |       32
      3       6.859157e+05      -6.193851e+03 |       32
      4       6.830105e+05      -2.905138e+03 |       32
      5       6.812191e+05      -1.791377e+03 |       32
      6       6.800164e+05      -1.202718e+03 |       32
      7       6.791359e+05      -8.805729e+02 |       32
      8       6.784455e+05      -6.903401e+02 |       32
      9       6.778827e+05      -5.627887e+02 |       32
     10       6.773888e+05      -4.939670e+02 |       32
     11       6.769458e+05      -4.429993e+02 |       32
     12       6.765295e+05      -4.162824e+02 |       32
     13       6.761625e+05      -3.670199e+02 |       32
     14       6.758235e+05      -3.389433e+02 |       32
     15       6.755254e+05      -2.981488e+02 |       32
     16       6.752474e+05      -2.780100e+02 |       32
     17       6.750059e+05      -2.414860e+02 |       32
     18       6.747842e+05      -2.216543e+02 |       32
     19       6.745769e+05      -2.072857e+02 |       32
     20       6.744037e+05      -1.731822e+02 |       32
     21       6.742457e+05      -1.580004e+02 |       32
     22       6.740893e+05      -1.564573e+02 |       32
     23       6.739371e+05      -1.522151e+02 |       32
     24       6.737923e+05      -1.447672e+02 |       32
     25       6.736615e+05      -1.308260e+02 |       32
     26       6.735392e+05      -1.223217e+02 |       32
     27       6.734200e+05      -1.191671e+02 |       32
     28       6.733150e+05      -1.049443e+02 |       32
     29       6.732153e+05      -9.971342e+01 |       32
     30       6.731102e+05      -1.051225e+02 |       32
     31       6.730190e+05      -9.123704e+01 |       32
     32       6.729433e+05      -7.569308e+01 |       32
     33       6.728769e+05      -6.637569e+01 |       32
     34       6.728147e+05      -6.221327e+01 |       32
     35       6.727584e+05      -5.629414e+01 |       32
     36       6.727089e+05      -4.944924e+01 |       32
     37       6.726616e+05      -4.737373e+01 |       32
     38       6.726159e+05      -4.567844e+01 |       32
     39       6.725765e+05      -3.935663e+01 |       32
     40       6.725401e+05      -3.639054e+01 |       32
     41       6.725036e+05      -3.658169e+01 |       32
     42       6.724641e+05      -3.948572e+01 |       32
     43       6.724255e+05      -3.860255e+01 |       32
     44       6.723930e+05      -3.248073e+01 |       32
     45       6.723628e+05      -3.016840e+01 |       32
     46       6.723323e+05      -3.054855e+01 |       32
     47       6.723050e+05      -2.729155e+01 |       32
     48       6.722800e+05      -2.495008e+01 |       32
     49       6.722522e+05      -2.782792e+01 |       32
     50       6.722264e+05      -2.582115e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672226.3874541944)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421955
[ Info: iteration 2, average log likelihood -1.417048
[ Info: iteration 3, average log likelihood -1.415753
[ Info: iteration 4, average log likelihood -1.414778
[ Info: iteration 5, average log likelihood -1.413695
[ Info: iteration 6, average log likelihood -1.412634
[ Info: iteration 7, average log likelihood -1.411879
[ Info: iteration 8, average log likelihood -1.411462
[ Info: iteration 9, average log likelihood -1.411235
[ Info: iteration 10, average log likelihood -1.411092
[ Info: iteration 11, average log likelihood -1.410985
[ Info: iteration 12, average log likelihood -1.410898
[ Info: iteration 13, average log likelihood -1.410825
[ Info: iteration 14, average log likelihood -1.410761
[ Info: iteration 15, average log likelihood -1.410704
[ Info: iteration 16, average log likelihood -1.410654
[ Info: iteration 17, average log likelihood -1.410609
[ Info: iteration 18, average log likelihood -1.410568
[ Info: iteration 19, average log likelihood -1.410530
[ Info: iteration 20, average log likelihood -1.410495
[ Info: iteration 21, average log likelihood -1.410463
[ Info: iteration 22, average log likelihood -1.410433
[ Info: iteration 23, average log likelihood -1.410405
[ Info: iteration 24, average log likelihood -1.410378
[ Info: iteration 25, average log likelihood -1.410353
[ Info: iteration 26, average log likelihood -1.410329
[ Info: iteration 27, average log likelihood -1.410306
[ Info: iteration 28, average log likelihood -1.410285
[ Info: iteration 29, average log likelihood -1.410264
[ Info: iteration 30, average log likelihood -1.410245
[ Info: iteration 31, average log likelihood -1.410227
[ Info: iteration 32, average log likelihood -1.410209
[ Info: iteration 33, average log likelihood -1.410192
[ Info: iteration 34, average log likelihood -1.410176
[ Info: iteration 35, average log likelihood -1.410161
[ Info: iteration 36, average log likelihood -1.410146
[ Info: iteration 37, average log likelihood -1.410132
[ Info: iteration 38, average log likelihood -1.410118
[ Info: iteration 39, average log likelihood -1.410105
[ Info: iteration 40, average log likelihood -1.410093
[ Info: iteration 41, average log likelihood -1.410081
[ Info: iteration 42, average log likelihood -1.410069
[ Info: iteration 43, average log likelihood -1.410058
[ Info: iteration 44, average log likelihood -1.410047
[ Info: iteration 45, average log likelihood -1.410037
[ Info: iteration 46, average log likelihood -1.410027
[ Info: iteration 47, average log likelihood -1.410017
[ Info: iteration 48, average log likelihood -1.410008
[ Info: iteration 49, average log likelihood -1.409999
[ Info: iteration 50, average log likelihood -1.409990
┌ Info: EM with 100000 data points 50 iterations avll -1.409990
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0623539  -0.336589    0.291025   -0.099612    -0.366835     0.00396439  -0.0463096   0.162917    -0.169523    0.0115911   -0.145261    -0.0623836    0.121019    0.0739065   0.0908314    0.174293     0.0429685   0.105902     0.0453692   -0.0139592   -0.025962   -0.0208491  -0.0834657   -0.0968169   -0.217579    0.0199756
  0.208685    0.33553    -0.161172   -0.354702    -0.221498    -0.121028    -0.457155    0.0324462   -0.144456   -0.257333    -0.0422797    0.232045    -0.0949141   0.309148    0.0515262    0.0797428   -0.301374   -0.150916    -0.192825     0.038854     0.0821978  -0.175037    0.519753    -0.260137    -0.105828   -0.144469
  0.361935   -0.15403     0.35092    -0.137454    -0.233344     0.0163272    0.47996     0.0240504   -0.35563     0.353639    -0.340092    -0.521947     0.389689    0.265746    0.478547     0.314096     0.355743    0.452062     0.229045    -0.0782717    0.0503094   0.253052   -0.404612    -0.448489    -0.280039   -0.263131
  0.234173    0.298035   -0.268641    0.359697    -0.0744293    0.322716    -0.0888766   0.184342     0.663511    0.672969     0.091118    -0.411962     0.374245    0.0424182  -0.408877    -0.157577    -0.477849   -0.62149     -0.193925     0.128446     0.256325    0.587527   -0.578968    -0.37904      0.0422873  -0.331922
 -0.0519704  -0.0700664   0.187119   -0.150465     0.560655     0.224368     1.0702      0.431744    -0.193387   -0.185037     0.100818     0.470264     0.0250995   0.354838    0.397472    -0.252024     0.255021   -0.528773     0.764936     0.222597     0.608364    0.154153   -0.069751    -0.111418     0.334246    0.755613
 -0.296701   -0.873398    0.198889    0.186831     0.576338     0.018188     0.541378   -0.103829     0.430273   -0.106837     0.235382    -0.535958     0.100433   -0.37719     0.138852     0.0376872    0.286082    0.274706    -0.0975965    0.312594    -0.270525    0.426944   -0.718282     0.499575    -0.188537    0.528601
  0.0443879  -0.0328023   0.20108    -0.00771479   0.402058     0.0155887    0.185422   -0.232823     0.286816   -0.288551     0.235347     0.450586    -0.321015    0.114529    0.135051    -0.846042     0.14816     0.0134151   -0.282693    -0.672359    -0.243349   -0.315011    0.55012     -0.401867    -0.0681547   0.377614
  0.123069    0.567725    0.0846344  -0.572621    -0.520615    -0.366341    -0.525741   -0.096471    -0.178541    0.162534    -0.576543     0.470245    -0.0111233   0.216818   -0.234321    -0.0756325    0.225271   -0.182843    -0.00366375  -0.102636    -0.0045889  -0.753061    0.407517    -0.419739     0.124055   -0.55114
  0.0171976  -0.0449572   0.0621664  -0.0582608    0.183039     0.00796174   0.0938971  -0.060112    -0.0815257  -0.0120959    0.0940234   -0.0715885   -0.0500251   0.0624534   0.0241014   -0.0444576    0.119188    0.107824     0.0318092    0.0419559    0.026944    0.043934   -0.121302    -0.00933159  -0.171025    0.119574
 -0.157358    0.12151    -0.0590757   0.1163      -0.117384    -0.217143    -0.275339    0.492456    -0.413783    0.300589     0.225958     0.259649    -0.456204    0.233176   -0.00540248   0.457518    -0.174388   -0.0920354    0.237494    -0.323067     0.375613    0.218376   -0.485742     0.316231    -0.150492    0.202168
 -0.410765   -0.353848   -0.247093    0.232874    -0.294172    -0.0308372   -0.634206    0.463773     0.421635    0.0217935    0.247002     0.294042     0.0589853   0.136676    0.161697     0.107159    -0.39973    -0.4556      -0.422793    -0.497726     0.139675   -0.513017    0.0958851    0.176536     0.453494   -0.318659
 -0.368869   -0.184686    0.0857693  -0.0644193    0.563305     1.04215     -0.0833973  -0.349751     0.153182    0.10537     -0.241872     0.464963     0.0453709   0.23362    -0.357343    -0.582957     0.860186   -0.109789     0.308415    -0.32816     -0.181223    0.0581416  -0.820346     0.275877    -0.444628   -0.0670848
  0.712263    0.501304    0.102714    0.238923    -0.158797    -0.245056    -0.157682   -0.142864    -0.20858     0.218873    -0.189317    -0.156776     0.0646035  -0.149659    0.187011     0.659503    -0.225322    0.442792    -0.198551     0.00481317   0.892817   -0.0259417   0.325094    -0.00197314   0.923991   -0.672114
 -0.118015   -0.36398     0.547659    0.672807     0.17038     -0.346211    -0.52922    -0.16526     -0.35682    -0.199241     0.126829     0.24174     -0.0532254   0.258241   -0.925678    -0.0236252    0.114039   -0.411391    -0.0666688    0.161332     0.187014    0.10633     0.172498    -0.512814    -0.645852   -0.454133
  0.412912    0.543223   -0.35707     0.0328774    0.803558    -0.227486    -0.707136   -0.445695    -0.352252   -0.443165     0.544466    -0.611501    -0.0313058  -0.2453      0.400163     0.208484     0.042728   -0.209224     0.135316    -0.00602927  -0.011191    0.333359    0.00932057   0.283137    -0.465962   -0.143504
 -0.464186    0.242465    0.493421   -0.0882721   -0.821502     0.28209     -0.122239    0.373645     0.292062   -0.725273    -0.0446916   -0.232849     0.283789   -0.0186328  -0.135147    -0.597544    -0.586244    0.360947    -0.109783     0.291278    -0.512817    0.148644    0.266002    -0.433358    -0.615964    0.861176
  0.0645851   0.17164    -0.204093    0.404047     0.501962    -0.194284     0.919339   -0.448368     0.0101737   0.247696     0.236714    -0.477208    -0.205709   -0.315589   -0.00873846   0.0659257    0.0993063   0.162233     0.180451    -0.138729     0.302367    0.104797   -0.370023     0.452527     0.616894   -0.170706
  0.733697    0.358161    0.690322   -0.0553342   -0.506432     0.102221    -5.5281e-5   0.0196723    0.173518   -0.0865498   -0.642726     0.0775023   -0.62117    -0.0898691   0.144736     0.0663342    0.560484    0.254813    -0.0939989   -0.237223     0.0350943   0.197603   -0.245803    -0.145452    -0.409398    0.772323
  0.0731434  -0.0836295   0.296322    0.162874     0.152861    -0.0302636    0.331271   -0.765473     0.0684595  -0.365971    -0.310993    -0.00354056   0.469002   -0.0723436  -0.0758986   -0.216643     0.259311    0.00943694  -0.264377     0.177039     0.0757814  -0.181179    0.208393     0.135551     0.292828   -0.0788592
 -0.143719   -0.51648    -0.12252    -0.00353925   0.01113     -0.104101     0.699638    0.546355     0.0213095   0.299628     0.344838     0.884382    -0.140572    1.23191    -0.0180387   -0.181465    -0.113427   -0.0662726   -0.407209    -0.478708    -0.352922   -0.0290569  -0.0594328   -0.301424     0.224313    0.344502
  0.152403   -0.0467123  -0.010958    0.121446    -0.163636    -0.172718    -0.720471   -0.482669     0.215722    0.206482    -0.113363    -0.567225    -0.0660626  -0.336522   -0.209306     0.057252    -0.0809945   0.43907     -0.601889    -0.110654    -0.27336    -0.137272   -0.0421041    0.17255     -0.271247   -0.71674
  0.326913   -0.245438   -0.301507   -0.807803    -0.305385     0.140986     0.18346     0.0094799    0.216471    0.0701595    0.0689693    0.00168956  -0.0750374  -0.0838283   0.633768    -0.169793     0.308768    0.418437     0.36874     -0.0641463   -0.795989   -0.578578   -0.0372828    0.530113     0.0990931   0.698346
 -0.111015    0.180471   -0.26685     0.0370738   -0.110821     0.0695042    0.0204283   0.197987     0.282083    0.167759    -0.0157182   -0.0494013   -0.0324412  -0.161793   -0.034379     0.00569198  -0.21364    -0.277952     0.0993037   -0.1804       0.0265105   0.118279   -0.141505     0.151863     0.396617   -0.0682856
 -0.0217028   0.0441263  -0.186409   -0.191723     0.916031     0.303379    -0.29736    -0.633497     0.521102   -0.257128     0.235901    -0.0962772    0.786576   -0.199068   -0.644741    -0.459108    -0.371586    0.0388989   -0.244195     0.420901    -0.237475   -0.0127361   0.96254      0.192551     0.143259   -0.379222
 -0.467721   -0.0315112   0.484294   -0.440985    -0.0524008    0.231858     0.126515    0.42162      0.249533   -0.104143    -0.503005     0.00584438   0.145036   -0.484732   -0.192116     0.584093    -0.289317   -0.060885    -0.232384     0.0230368    0.231049    0.294382    0.12015     -0.328882     0.31548    -0.120776
  0.706483    0.294335   -0.213778    0.0889724    0.29346     -0.0266847   -0.274502   -0.220496    -0.330828   -0.215349     0.581328     0.265261    -0.591578    0.367531    0.123497    -1.06477      0.467358    0.47512      0.0661275    0.0591148   -0.0907786   0.183034   -0.348522    -0.0271428   -0.991999   -0.0082093
 -0.446891    0.519138   -0.103334   -0.130937    -0.320171     0.0686144   -0.796428   -0.146092    -0.37537    -0.505777    -0.298627    -0.788577     0.163986   -1.07685    -0.191237     0.47294      0.175743    0.0185199    0.278141     0.47125      0.72194     0.0448307  -0.375321     0.576738     0.063389   -0.440254
 -0.464368   -0.634608   -0.556638   -0.0449919    0.506548    -0.399622     0.146417    0.135684    -0.517414    0.371464    -0.0823451    0.118718     0.0725525  -0.300226    0.223124     0.537148     0.6112     -0.242447     0.52454     -0.0691238   -0.732223   -0.304756   -0.0212109    0.0884502   -0.0329021  -0.389044
 -0.688203    0.517673   -0.603277   -0.540445     0.0465685    0.227812     0.288897    0.47816      0.261068   -0.263847     0.140757     0.312077    -0.653056   -0.377783    0.270587    -0.165384    -0.538525   -0.0157902   -0.183361     0.0601447    0.27202     0.262346   -0.00710529   0.521154     0.327048    0.0743693
 -0.261236    0.0219233   0.328259   -0.430628     0.141144    -0.610517     0.297208   -0.00429801  -0.865596   -0.226244     0.00536805   0.0135983   -0.413828    0.139361   -0.0863435    0.403223     0.207855    0.531251     0.125379    -0.0727831    0.213848   -0.284688    0.476248     0.00714025   0.069221    0.149712
  0.176044    0.654282   -0.635408    0.291201    -0.00429245   0.233912     0.577441   -0.185603     0.099611   -0.00668391  -0.290675     0.197659    -0.0252959   0.332792   -0.362854     0.177898    -0.229064   -0.688974     0.372839     0.934471    -0.250767    0.299415   -0.100651     0.152169    -0.227673    0.557406
 -0.339878   -0.0229738  -0.567779    0.142034     0.212439     0.160287    -0.144587   -0.468445    -0.296453    0.0930763    0.957581    -0.331355     0.387975   -0.0983478  -0.0357061   -0.340472    -0.521117    0.244937     0.233654     0.00922306   0.173701   -0.0761536   0.0852737    0.586461     0.128062   -0.234852[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409982
[ Info: iteration 2, average log likelihood -1.409974
[ Info: iteration 3, average log likelihood -1.409966
[ Info: iteration 4, average log likelihood -1.409959
[ Info: iteration 5, average log likelihood -1.409952
[ Info: iteration 6, average log likelihood -1.409945
[ Info: iteration 7, average log likelihood -1.409938
[ Info: iteration 8, average log likelihood -1.409932
[ Info: iteration 9, average log likelihood -1.409925
[ Info: iteration 10, average log likelihood -1.409919
┌ Info: EM with 100000 data points 10 iterations avll -1.409919
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
