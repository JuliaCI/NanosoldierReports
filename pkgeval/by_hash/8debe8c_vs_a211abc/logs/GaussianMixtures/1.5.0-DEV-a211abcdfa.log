Julia Version 1.5.0-DEV.260
Commit a211abcdfa (2020-02-10 22:01 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed CMake ────────────── v1.1.2
  Installed Blosc ────────────── v0.5.1
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed BinaryProvider ───── v0.5.8
  Installed Missings ─────────── v0.4.3
  Installed Rmath ────────────── v0.6.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed LegacyStrings ────── v0.4.1
  Installed OrderedCollections ─ v1.1.0
  Installed HDF5 ─────────────── v0.12.5
  Installed DataAPI ──────────── v1.1.0
  Installed StaticArrays ─────── v0.12.1
  Installed StatsBase ────────── v0.32.0
  Installed Parameters ───────── v0.12.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed URIParser ────────── v0.4.0
  Installed FillArrays ───────── v0.8.4
  Installed Compat ───────────── v2.2.0
  Installed SpecialFunctions ─── v0.9.0
  Installed FileIO ───────────── v1.2.2
  Installed DataStructures ───── v0.17.9
  Installed StatsFuns ────────── v0.9.3
  Installed Distributions ────── v0.22.4
  Installed SortingAlgorithms ── v0.3.1
  Installed BinDeps ──────────── v1.0.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed ScikitLearnBase ──── v0.5.0
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ##O#- #                                                                       ###############################################################           87.5%######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.5%#####                                                                      7.6%#########                                                                 13.3%##############                                                            20.6%######################                                                    30.6%###############################                                           43.7%##########################################                                59.6%#######################################################                   77.3%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_jrVErq/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -977772.5089660538, [99699.88411656025, 300.1158834397464], [-229.20901847629685 28.025262297187908 212.34412127709703; 261.1891118772699 -100.34635703137324 -36.93265888734905], [[99569.12880568474 541.3595448149435 0.36296765352790317; 541.3595448149435 99312.44354067613 -304.03440784235704; 0.36296765352790317 -304.03440784235704 99825.82648146254], [287.72265223780624 -9.89626630511611 39.803474829628016; -9.896266305116107 290.1426934192557 -49.414772303152425; 39.803474829628016 -49.414772303152425 240.9550388171382]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.658345e+03
      1       1.235845e+03      -4.225000e+02 |        6
      2       1.139179e+03      -9.666565e+01 |        2
      3       1.064101e+03      -7.507761e+01 |        0
      4       1.064101e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1064.1013484498599)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.052256
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.733278
[ Info: iteration 2, lowerbound -3.625656
[ Info: iteration 3, lowerbound -3.509460
[ Info: iteration 4, lowerbound -3.361259
[ Info: iteration 5, lowerbound -3.182711
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.985582
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.782098
[ Info: iteration 8, lowerbound -2.600580
[ Info: iteration 9, lowerbound -2.465057
[ Info: iteration 10, lowerbound -2.380002
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.338154
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.318830
[ Info: dropping number of Gaussions to 2
[ Info: iteration 13, lowerbound -2.306586
[ Info: iteration 14, lowerbound -2.299269
[ Info: iteration 15, lowerbound -2.299260
[ Info: iteration 16, lowerbound -2.299256
[ Info: iteration 17, lowerbound -2.299254
[ Info: iteration 18, lowerbound -2.299254
[ Info: iteration 19, lowerbound -2.299253
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Feb 11 15:18:33 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Feb 11 15:18:41 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Feb 11 15:18:44 2020: EM with 272 data points 0 iterations avll -2.052256
5.8 data points per parameter
, Tue Feb 11 15:18:46 2020: GMM converted to Variational GMM
, Tue Feb 11 15:18:55 2020: iteration 1, lowerbound -3.733278
, Tue Feb 11 15:18:55 2020: iteration 2, lowerbound -3.625656
, Tue Feb 11 15:18:55 2020: iteration 3, lowerbound -3.509460
, Tue Feb 11 15:18:55 2020: iteration 4, lowerbound -3.361259
, Tue Feb 11 15:18:55 2020: iteration 5, lowerbound -3.182711
, Tue Feb 11 15:18:55 2020: dropping number of Gaussions to 7
, Tue Feb 11 15:18:55 2020: iteration 6, lowerbound -2.985582
, Tue Feb 11 15:18:55 2020: dropping number of Gaussions to 6
, Tue Feb 11 15:18:55 2020: iteration 7, lowerbound -2.782098
, Tue Feb 11 15:18:55 2020: iteration 8, lowerbound -2.600580
, Tue Feb 11 15:18:55 2020: iteration 9, lowerbound -2.465057
, Tue Feb 11 15:18:55 2020: iteration 10, lowerbound -2.380002
, Tue Feb 11 15:18:55 2020: dropping number of Gaussions to 5
, Tue Feb 11 15:18:55 2020: iteration 11, lowerbound -2.338154
, Tue Feb 11 15:18:55 2020: dropping number of Gaussions to 4
, Tue Feb 11 15:18:55 2020: iteration 12, lowerbound -2.318830
, Tue Feb 11 15:18:55 2020: dropping number of Gaussions to 2
, Tue Feb 11 15:18:55 2020: iteration 13, lowerbound -2.306586
, Tue Feb 11 15:18:55 2020: iteration 14, lowerbound -2.299269
, Tue Feb 11 15:18:55 2020: iteration 15, lowerbound -2.299260
, Tue Feb 11 15:18:55 2020: iteration 16, lowerbound -2.299256
, Tue Feb 11 15:18:55 2020: iteration 17, lowerbound -2.299254
, Tue Feb 11 15:18:55 2020: iteration 18, lowerbound -2.299254
, Tue Feb 11 15:18:55 2020: iteration 19, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 20, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 21, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 22, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 23, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 24, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 25, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 26, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 27, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 28, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 29, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 30, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 31, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 32, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 33, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 34, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 35, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 36, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 37, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 38, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 39, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 40, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 41, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 42, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 43, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 44, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 45, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 46, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 47, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 48, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 49, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: iteration 50, lowerbound -2.299253
, Tue Feb 11 15:18:55 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398618, 178.04509222601382]
β = [95.95490777398618, 178.04509222601382]
m = [2.000229257775371 53.8519871724613; 4.25030073326991 79.28686694436185]
ν = [97.95490777398618, 180.04509222601382]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484036 -0.008953123827345958; 0.0 0.01274866477740938], [0.18404155547484735 -0.007644049042327438; 0.0 0.008581705166333458]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9937147249303054
avll from llpg:  -0.9937147249303233
avll direct:     -0.9937147249303233
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9941939199349922
avll from llpg:  -0.9941939199349922
avll direct:     -0.9941939199349922
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.115414     0.0299734   -0.0705399    0.0783923   -0.0289525  -0.162938   -0.0831751    0.073869      0.169322    -0.00940395    0.0623354    0.110096   -0.00111681   0.0172291   -0.11401      0.082855    -0.0473142   -0.0477338    0.00873408  -0.148779     0.0991053    0.184412    0.0467846   -0.061821     -0.127775     0.065647
 -0.0991988    0.0472827    0.110934     0.153415    -0.0225902  -0.0500255   0.104622     0.0824041     0.0676106   -0.037552     -0.0181477    0.0680735  -0.0690774   -0.115995     0.0368454    0.0790165    0.0582695    0.074588     0.0105782    0.130138     0.053723     0.115503   -0.037455     0.148299      0.0423574   -0.062987
 -0.0379791   -0.185166     0.015897     0.0549094   -0.0983928   0.0153779   0.014871     0.0354119     0.0564519   -0.0427533    -0.0247529   -0.0185539   0.0479779   -0.0768066   -0.040513    -0.0127064   -0.0472769    0.0567257   -0.0221574   -0.0911387    0.0138735   -0.0592444   0.0785291   -0.0175588    -0.0138603    0.042271
  0.0253088    0.0826723    0.0855911    0.215245    -0.0665255   0.160422    0.088343     0.0633325    -0.106327    -0.146534     -0.0387921    0.0449947   0.0665062    0.0170053    0.0593672    0.102352     0.157889     0.0305277    0.0257582    0.0335311   -0.145271    -0.0290643  -0.0358547   -0.146027     -0.0614778   -0.0118751
  0.213897    -0.0735992    0.0330262   -0.0154032   -0.239417   -0.0238484   0.0164386   -0.0273158    -0.107834    -0.128038     -0.0692821   -0.129123   -0.116178    -0.0455367   -0.0877719    0.0215716    0.187596     0.136113     0.0653427   -0.0312002   -0.133909    -0.0925208  -0.00597383  -0.0213063    -0.0764576   -0.0043754
 -0.0182276    0.161133    -0.064473     0.0439392    0.0156574   0.0658825   0.0429787   -0.0863684    -0.0172932   -0.0424921    -0.130462     0.181351    0.0513977    0.0477338    0.0477513   -0.0622036   -0.0354738   -0.00121424  -0.17835     -0.0909641   -0.202968     0.0348289  -0.0499661    0.0732018    -0.0689508   -0.147144
 -0.144641    -0.0462228   -0.190843     0.0267514   -0.0392241  -0.0775909  -0.0164128   -0.0154803    -0.0801518   -0.0113151     0.107802     0.158291   -0.0341147   -0.0418194   -0.0212707   -0.148596    -0.0660919   -0.0109367   -0.0471808   -0.13645      0.00325837  -0.0871993   0.0687414    0.000385538   0.0969184    0.049646
  0.0232793   -0.0527462   -0.290321    -0.0970436    0.165977    0.051346   -0.00404157   0.0508324     0.242676    -0.140515     -0.0196235    0.0860525   0.0144279   -0.0459223   -0.0637703   -0.0842177    0.0569959    0.146851    -0.132657    -0.026126    -0.0165894   -0.110431    0.0999564    0.040443      0.0474705    0.00381247
 -0.150085     0.0205593    0.0248736   -0.0327149    0.0546134  -0.0437944  -0.104248     0.0223148     0.0278336   -0.256675      0.0105082    0.123157    0.104981     0.00708753  -0.208418    -0.0805348    0.0739454   -0.0718794    0.0160808   -0.0629722   -0.0510272   -0.252565    0.00843824   0.00254531   -0.104856     0.039149
 -0.124786    -0.16255     -0.150297    -0.0207199   -0.0464193   0.0871064  -0.0845754    0.141811      0.00229776  -0.0384884     0.107884     0.0644785   0.188509     0.139193    -0.0561548    0.060514     0.00221841   0.0971692    0.132366     0.0458611    0.172064    -0.0932462   0.0905772   -0.00409164    0.050731    -0.0201365
  0.0741191    0.0722789   -0.0313208    0.117845    -0.019427   -0.0217904   0.0346216   -0.181151      0.145669     0.0780615    -0.0674939    0.0322162  -0.0495622   -0.00554962   0.0575178   -0.0689052    0.0627053    0.0686493   -0.0720879   -0.121634    -0.177606    -0.0530207  -0.0162693    0.0155765     0.0439351   -0.0133247
  0.141402    -0.207801     0.0267918   -0.0574418   -0.0364376  -0.2287     -0.103366     0.123655     -0.0644228   -0.0832357    -0.0920563   -0.174704    0.0456868    0.094246     0.114143     0.0629899    0.180834     0.243664    -0.0534174   -0.208666    -0.1872       0.124184    0.0383057    0.212767      0.0374691   -0.0895737
  0.0924549   -0.123481     0.141393    -0.0342286    0.0061058   0.209426   -0.0628234   -0.0170279    -0.0734314   -0.0584508     0.0853307   -0.0386284  -0.0709274    0.0185003    0.0660631    0.013875    -0.0129623   -0.125697     0.0254605    0.0649185    0.109445     0.0497694  -0.0746289    0.048849     -0.0310399   -0.10087
  0.0888397   -0.00736578   9.87407e-5  -0.108484     0.0839113   0.0691957   0.101854     0.165141      0.0872995   -0.000992301  -0.013805     0.0929287   0.151002     0.137591    -0.0240664    0.0688568   -0.0911242   -0.0116623   -0.10724     -0.179428     0.0715733    0.0347455  -0.102942     0.0666986    -0.0504222   -0.0142983
  0.101808     0.0791807    0.0245577    0.17793      0.0762294  -0.0399674  -0.142206     0.0807654    -0.033774    -0.137961      0.108085    -0.107807    0.194246     0.194515     0.148909     0.0924505   -0.0916332    0.178022    -0.094636    -0.160506     0.127363    -0.0319523   0.0880978   -0.0617159     0.0374258   -0.00715717
  0.0645369   -0.06539     -0.0677147   -0.121889     0.0802284   0.0399747   0.0161754   -0.00476845    0.0231998    0.0319533    -0.119052     0.0289473  -0.0604318   -0.159173     0.0667522    0.02963      0.0202979    0.023315    -0.0195451    0.0938832    0.00681417  -0.0406752  -0.0412992   -0.121989     -0.0613314   -0.225898
 -0.0205514   -0.175608     0.0355021    0.0241659   -0.20341     0.0768648  -0.00485811  -0.0503172     0.0457293   -0.0440716    -0.0640643    0.06623     0.00553347  -0.0468052   -0.0837175    0.0244014    0.0602151   -0.0348818   -0.021574     0.00178961   0.162796     0.130736    0.0840567   -0.130821     -0.0706653    0.0585298
  0.0042113   -0.0783727    0.03836     -0.104705    -0.0421926  -0.0257534  -0.17528      0.0409085     0.135726    -0.182984     -0.0522671   -0.0243806   0.0472036   -0.00580077   0.00465452  -0.0572435   -0.074665    -0.0454541    0.0608056    0.127722    -0.0300289   -0.0525594  -0.0223305    0.147069      0.232775     0.0387139
  0.0937898   -0.0405135    0.0409197   -0.103725    -0.137227   -0.0674365   0.0388726    0.162482     -0.132848    -0.0402402    -0.0318775    0.117191    0.123644    -0.0551075   -0.0674849    0.0346732   -0.00544355  -0.0766635   -0.0730076    0.304829     0.0928569    0.113354    0.0701376   -0.0313747     0.0168269    0.0275139
 -0.102752    -0.0213171    0.102165    -0.0103256    0.0300891   0.0147212   0.114826     0.145395     -0.0906384    0.108683      0.0827183    0.0684131   0.00797951  -0.0376448   -0.032937    -0.0885313    0.0299084    0.234351     0.0014096   -0.0713476   -0.0660901   -0.0446548   0.0481509   -0.0560444    -0.0240144   -0.150572
  0.0586394   -0.0164484   -0.0358918   -0.0309729    0.184502    0.0868521  -0.102584    -0.0643935     0.130588     0.0897452    -0.0115073    0.0399346   0.0868022    0.0193028    0.115402    -0.072477     0.0709602    0.134842     0.00248546   0.0625906   -0.0440784   -0.0394099   0.00165561  -0.0996652    -0.00864451  -0.141465
 -0.0687606   -0.0469438    0.0699352   -0.00833888  -0.0765735   0.153614   -0.0456433   -0.0835177     0.109015    -0.030471      0.0132354   -0.0838252   0.0402907    0.0364829   -0.10853     -0.0760125    0.088574    -0.119778    -0.0252932   -0.00631989  -0.0248994   -0.0909104   0.00874909   0.0276218    -0.00079888   0.0742361
 -0.0480286   -0.133473     0.0303817    0.189997    -0.01364     0.0176814  -0.0370671    0.0137488    -0.0268288    0.162886      0.11655      0.196718   -0.0801541   -0.0300162    0.0366487    0.158327    -0.0811448    0.007465     0.00838003  -0.122442     0.0676989    0.0305997   0.0906574    0.226761     -0.170201    -0.02873
 -0.140188    -0.0982944    0.0797924   -0.100026    -0.121467   -0.0534433   0.0648911   -0.136291      0.130173    -0.0549214    -0.0184541   -0.0872823   0.0529557   -0.065355     0.0474054    0.00167093  -1.69935e-5  -0.00401818  -0.101446     0.0444995   -0.0997198    0.062134   -0.0176315   -0.165667      0.0464137    0.0733848
 -0.0859695    0.153473     0.18502      0.0214807   -0.0892602   0.199911    0.170835    -0.264447     -0.0393024   -0.0658682    -0.00837013   0.0836742   0.0615227   -0.0243179    0.0243842    0.146939     0.120913     0.0352335   -0.224399     0.0633997    0.00291034   0.0818386  -0.102696     0.0317598     0.101236    -0.133608
  0.149203    -0.0682853   -0.0190308   -0.0812019    0.0018666   0.042731    0.0573443    0.13808      -0.0350256   -0.010353      0.0279878   -0.0957825  -0.191885    -0.0680252    0.0445752   -0.0793184   -0.124621     0.0194562   -0.0967296    0.0697935   -0.0623775    0.0184407  -0.190086    -0.0240235    -0.0339616    0.0497539
 -0.186822     0.0567191   -0.00751219  -0.0120543   -0.124529    0.0393874  -0.0493558   -0.0428645     0.0961981    0.254739      0.0307019    0.0966838   0.0847842   -0.105874     0.0105323    0.127489     0.0753038    0.0272484    0.0443065   -0.0180717   -0.156281     0.0105348  -0.0715028   -0.034642     -0.0396373   -0.116401
 -0.0586952   -0.211756     0.0446946    0.0768022   -0.0558026   0.0570474  -0.0195492   -0.0415539     0.0161055    0.148289     -0.0864264   -0.133225   -0.00129916  -0.0718071    0.0350505    0.166659     0.0449321    0.0687349    0.00703598   0.11563     -0.0326814    0.1067     -0.216567     0.0694678    -0.114147    -0.0548479
  0.0285517    0.0832666   -0.0311548   -0.0253445   -0.0613918   0.144809   -0.0804714    0.017817     -0.184501     0.0603252    -0.0596097    0.0235759   0.0848699   -0.010247    -0.0366171   -0.0282758    0.0762771   -0.108023    -0.0348646   -0.0349605   -0.0836069   -0.114077    0.0719903   -0.0352364    -0.0639277   -0.189535
  0.0017778    0.0375023    0.0589054   -0.0728612   -0.0132703  -0.105432    0.103647     0.0112772    -0.127768     0.000110495  -0.058627     0.165161    0.18323      0.185499    -0.091066     0.0331457   -0.033692     0.00266591   0.122883     0.103556    -0.0451195    0.149857   -0.07827     -0.0756482    -0.141706     0.335209
 -0.00189123  -0.0062208   -0.103468     0.211147    -0.141895   -0.0202619  -0.19133     -0.000627879  -0.00480454  -0.0437635    -0.0981105    0.0235254  -0.00311229   0.0769417   -0.0607691   -0.192664     0.0559038   -0.0977255   -0.0967007    0.0128939    0.102923     0.142055   -0.0250553   -0.0929601     0.0248291    0.0120966
  0.0867432   -0.0862137    0.0384927   -0.235196     0.0482979   0.126735    0.052336     0.154724     -0.0552188   -0.0446369     0.0109501    0.0692013   0.103395     0.0415843    0.180508     0.0818516   -0.0516926    0.0234025    0.0149251    0.00955573   0.0292218   -0.133153   -0.152054    -0.172232      0.151918     0.0212387kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4098581573011641
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410018
[ Info: iteration 2, average log likelihood -1.409883
[ Info: iteration 3, average log likelihood -1.408901
[ Info: iteration 4, average log likelihood -1.399268
[ Info: iteration 5, average log likelihood -1.381399
[ Info: iteration 6, average log likelihood -1.375717
[ Info: iteration 7, average log likelihood -1.374407
[ Info: iteration 8, average log likelihood -1.373407
[ Info: iteration 9, average log likelihood -1.371975
[ Info: iteration 10, average log likelihood -1.370898
[ Info: iteration 11, average log likelihood -1.370256
[ Info: iteration 12, average log likelihood -1.369766
[ Info: iteration 13, average log likelihood -1.369274
[ Info: iteration 14, average log likelihood -1.368648
[ Info: iteration 15, average log likelihood -1.367640
[ Info: iteration 16, average log likelihood -1.366022
[ Info: iteration 17, average log likelihood -1.364834
[ Info: iteration 18, average log likelihood -1.364126
[ Info: iteration 19, average log likelihood -1.363620
[ Info: iteration 20, average log likelihood -1.363240
[ Info: iteration 21, average log likelihood -1.362957
[ Info: iteration 22, average log likelihood -1.362777
[ Info: iteration 23, average log likelihood -1.362681
[ Info: iteration 24, average log likelihood -1.362634
[ Info: iteration 25, average log likelihood -1.362611
[ Info: iteration 26, average log likelihood -1.362599
[ Info: iteration 27, average log likelihood -1.362592
[ Info: iteration 28, average log likelihood -1.362587
[ Info: iteration 29, average log likelihood -1.362584
[ Info: iteration 30, average log likelihood -1.362582
[ Info: iteration 31, average log likelihood -1.362581
[ Info: iteration 32, average log likelihood -1.362579
[ Info: iteration 33, average log likelihood -1.362579
[ Info: iteration 34, average log likelihood -1.362578
[ Info: iteration 35, average log likelihood -1.362577
[ Info: iteration 36, average log likelihood -1.362577
[ Info: iteration 37, average log likelihood -1.362577
[ Info: iteration 38, average log likelihood -1.362576
[ Info: iteration 39, average log likelihood -1.362576
[ Info: iteration 40, average log likelihood -1.362576
[ Info: iteration 41, average log likelihood -1.362576
[ Info: iteration 42, average log likelihood -1.362576
[ Info: iteration 43, average log likelihood -1.362576
[ Info: iteration 44, average log likelihood -1.362576
[ Info: iteration 45, average log likelihood -1.362576
[ Info: iteration 46, average log likelihood -1.362576
[ Info: iteration 47, average log likelihood -1.362576
[ Info: iteration 48, average log likelihood -1.362576
[ Info: iteration 49, average log likelihood -1.362576
[ Info: iteration 50, average log likelihood -1.362576
┌ Info: EM with 100000 data points 50 iterations avll -1.362576
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4100177242342848
│     -1.4098832270648205
│      ⋮
└     -1.3625756516483551
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.362784
[ Info: iteration 2, average log likelihood -1.362536
[ Info: iteration 3, average log likelihood -1.360938
[ Info: iteration 4, average log likelihood -1.350773
[ Info: iteration 5, average log likelihood -1.334273
[ Info: iteration 6, average log likelihood -1.325487
[ Info: iteration 7, average log likelihood -1.323012
[ Info: iteration 8, average log likelihood -1.322060
[ Info: iteration 9, average log likelihood -1.321574
[ Info: iteration 10, average log likelihood -1.321267
[ Info: iteration 11, average log likelihood -1.321031
[ Info: iteration 12, average log likelihood -1.320828
[ Info: iteration 13, average log likelihood -1.320628
[ Info: iteration 14, average log likelihood -1.320389
[ Info: iteration 15, average log likelihood -1.320062
[ Info: iteration 16, average log likelihood -1.319615
[ Info: iteration 17, average log likelihood -1.319041
[ Info: iteration 18, average log likelihood -1.318373
[ Info: iteration 19, average log likelihood -1.317674
[ Info: iteration 20, average log likelihood -1.317090
[ Info: iteration 21, average log likelihood -1.316663
[ Info: iteration 22, average log likelihood -1.316357
[ Info: iteration 23, average log likelihood -1.316121
[ Info: iteration 24, average log likelihood -1.315925
[ Info: iteration 25, average log likelihood -1.315738
[ Info: iteration 26, average log likelihood -1.315525
[ Info: iteration 27, average log likelihood -1.315244
[ Info: iteration 28, average log likelihood -1.314851
[ Info: iteration 29, average log likelihood -1.314292
[ Info: iteration 30, average log likelihood -1.313567
[ Info: iteration 31, average log likelihood -1.312719
[ Info: iteration 32, average log likelihood -1.311982
[ Info: iteration 33, average log likelihood -1.311533
[ Info: iteration 34, average log likelihood -1.311299
[ Info: iteration 35, average log likelihood -1.311161
[ Info: iteration 36, average log likelihood -1.311071
[ Info: iteration 37, average log likelihood -1.311008
[ Info: iteration 38, average log likelihood -1.310962
[ Info: iteration 39, average log likelihood -1.310926
[ Info: iteration 40, average log likelihood -1.310898
[ Info: iteration 41, average log likelihood -1.310875
[ Info: iteration 42, average log likelihood -1.310855
[ Info: iteration 43, average log likelihood -1.310838
[ Info: iteration 44, average log likelihood -1.310822
[ Info: iteration 45, average log likelihood -1.310808
[ Info: iteration 46, average log likelihood -1.310794
[ Info: iteration 47, average log likelihood -1.310781
[ Info: iteration 48, average log likelihood -1.310767
[ Info: iteration 49, average log likelihood -1.310753
[ Info: iteration 50, average log likelihood -1.310738
┌ Info: EM with 100000 data points 50 iterations avll -1.310738
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3627842564559858
│     -1.36253559790043
│      ⋮
└     -1.3107378042526536
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311011
[ Info: iteration 2, average log likelihood -1.310736
[ Info: iteration 3, average log likelihood -1.310210
[ Info: iteration 4, average log likelihood -1.305737
[ Info: iteration 5, average log likelihood -1.290217
[ Info: iteration 6, average log likelihood -1.276032
[ Info: iteration 7, average log likelihood -1.269955
[ Info: iteration 8, average log likelihood -1.266814
[ Info: iteration 9, average log likelihood -1.264713
[ Info: iteration 10, average log likelihood -1.263283
[ Info: iteration 11, average log likelihood -1.262246
[ Info: iteration 12, average log likelihood -1.261413
[ Info: iteration 13, average log likelihood -1.260664
[ Info: iteration 14, average log likelihood -1.260033
[ Info: iteration 15, average log likelihood -1.259585
[ Info: iteration 16, average log likelihood -1.259250
[ Info: iteration 17, average log likelihood -1.258941
[ Info: iteration 18, average log likelihood -1.258594
[ Info: iteration 19, average log likelihood -1.258147
[ Info: iteration 20, average log likelihood -1.257540
[ Info: iteration 21, average log likelihood -1.256725
[ Info: iteration 22, average log likelihood -1.255726
[ Info: iteration 23, average log likelihood -1.254593
[ Info: iteration 24, average log likelihood -1.253439
[ Info: iteration 25, average log likelihood -1.252453
[ Info: iteration 26, average log likelihood -1.251745
[ Info: iteration 27, average log likelihood -1.251350
[ Info: iteration 28, average log likelihood -1.251151
[ Info: iteration 29, average log likelihood -1.251046
[ Info: iteration 30, average log likelihood -1.250982
[ Info: iteration 31, average log likelihood -1.250939
[ Info: iteration 32, average log likelihood -1.250909
[ Info: iteration 33, average log likelihood -1.250888
[ Info: iteration 34, average log likelihood -1.250872
[ Info: iteration 35, average log likelihood -1.250860
[ Info: iteration 36, average log likelihood -1.250850
[ Info: iteration 37, average log likelihood -1.250842
[ Info: iteration 38, average log likelihood -1.250834
[ Info: iteration 39, average log likelihood -1.250828
[ Info: iteration 40, average log likelihood -1.250822
[ Info: iteration 41, average log likelihood -1.250816
[ Info: iteration 42, average log likelihood -1.250811
[ Info: iteration 43, average log likelihood -1.250806
[ Info: iteration 44, average log likelihood -1.250801
[ Info: iteration 45, average log likelihood -1.250797
[ Info: iteration 46, average log likelihood -1.250793
[ Info: iteration 47, average log likelihood -1.250789
[ Info: iteration 48, average log likelihood -1.250784
[ Info: iteration 49, average log likelihood -1.250780
[ Info: iteration 50, average log likelihood -1.250775
┌ Info: EM with 100000 data points 50 iterations avll -1.250775
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3110113928009022
│     -1.3107358843589743
│      ⋮
└     -1.2507752844352433
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251074
[ Info: iteration 2, average log likelihood -1.250705
[ Info: iteration 3, average log likelihood -1.248497
[ Info: iteration 4, average log likelihood -1.229459
[ Info: iteration 5, average log likelihood -1.192906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.167690
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.164178
[ Info: iteration 8, average log likelihood -1.159476
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.151071
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.156329
[ Info: iteration 11, average log likelihood -1.155730
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.149539
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.155774
[ Info: iteration 14, average log likelihood -1.155496
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.149440
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.155707
[ Info: iteration 17, average log likelihood -1.155482
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.149416
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.155656
[ Info: iteration 20, average log likelihood -1.155485
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.149397
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.155598
[ Info: iteration 23, average log likelihood -1.155492
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.149377
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.155536
[ Info: iteration 26, average log likelihood -1.155500
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.149357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.155472
[ Info: iteration 29, average log likelihood -1.155508
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.149337
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.155410
[ Info: iteration 32, average log likelihood -1.155516
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.149319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.155354
[ Info: iteration 35, average log likelihood -1.155522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.149303
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.155305
[ Info: iteration 38, average log likelihood -1.155528
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.149289
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.155265
[ Info: iteration 41, average log likelihood -1.155532
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.149278
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.155233
[ Info: iteration 44, average log likelihood -1.155536
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.149270
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.155207
[ Info: iteration 47, average log likelihood -1.155538
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.149263
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.155188
[ Info: iteration 50, average log likelihood -1.155540
┌ Info: EM with 100000 data points 50 iterations avll -1.155540
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2510740833953207
│     -1.250705086850719
│      ⋮
└     -1.1555404057281775
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.149684
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.146726
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.144677
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.118104
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│      ⋮
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.075790
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     12
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072457
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     21
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062327
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.058964
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     12
│     19
│     25
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.065187
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073372
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.047665
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     18
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072912
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.061124
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│     12
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.034139
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.089326
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     12
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.069402
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.045370
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     20
│     21
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.067976
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     19
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.069917
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│     12
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.056283
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     21
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062970
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     19
│     20
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060723
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│     14
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.065689
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.070713
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     19
│     21
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057986
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│     12
│     13
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.051544
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.078996
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     12
│     19
│     20
│     21
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.050764
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.061964
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.074717
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     19
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.054216
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     20
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.057799
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.066737
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     19
│     20
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.054288
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.052370
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.079775
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     19
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.067611
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│     12
│     13
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044943
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     21
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.075710
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     19
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063592
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│     13
│     14
│     17
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.054740
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     20
│     21
│     22
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.059378
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     17
│     19
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.069030
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.063943
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     17
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.060669
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     19
│     20
│     21
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.059925
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.057333
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.071669
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     19
│     21
│     22
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.047980
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│     12
│     13
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.046654
┌ Info: EM with 100000 data points 50 iterations avll -1.046654
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1496844317959902
│     -1.1467260422094188
│      ⋮
└     -1.0466540384150032
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4098581573011641
│     -1.4100177242342848
│     -1.4098832270648205
│     -1.408901227768029
│      ⋮
│     -1.0716691522545283
│     -1.0479795808916486
└     -1.0466540384150032
32×26 Array{Float64,2}:
 -0.186709     0.0524734   -0.0258247   -0.0123339  -0.119769      0.0399969  -0.0490893  -0.0432058    0.0845098    0.259848      0.0227651    0.0892731    0.0722348   -0.0921672    0.0211017    0.130169     0.0615694     0.0215418    0.00991633  -0.0179318  -0.15737      -0.00543997  -0.0803327   -0.0369421   -0.0469279   -0.101609
  0.204372    -0.0782148   -0.0263727   -0.0805868   0.0075484     0.0444711   0.0539801   0.154082    -0.0459621    0.0176179     0.0490722   -0.105279    -0.195462    -0.072741     0.0444025   -0.045775    -0.130416      0.0433148   -0.0693836    0.0683     -0.0553169     0.0186882   -0.188549    -0.0316263   -0.0242533    0.0595369
  0.209037    -0.0755717    0.0285256   -0.0136042  -0.228372     -0.0263862   0.0264987  -0.0444281   -0.0759174   -0.116721     -0.0858501   -0.106502    -0.105452    -0.0575826   -0.0774644    0.018138     0.17938       0.131455     0.0535936   -0.0316855  -0.129006     -0.0799269    0.00216428  -0.0219231   -0.0698163   -0.0240711
  0.00426798   0.0360852    0.0788954   -0.0532951  -0.000193345  -0.105535    0.10164    -0.00567242  -0.113452     0.00414886   -0.0538096    0.164453     0.175814     0.200283    -0.0878507    0.0626882   -0.0372446     0.00119106   0.114808     0.104126   -0.045451      0.16854     -0.0649703   -0.0721285   -0.13849      0.322225
 -0.150289     0.0111964    0.0252534   -0.0276126   0.0516282    -0.0467577  -0.0983813   0.00765645   0.0462024   -0.227736     -0.0014715    0.118117     0.102684    -0.00858766  -0.18263     -0.0433193    0.0824829    -0.0942408    0.00192069  -0.0658251  -0.05541      -0.27228     -0.00447591   0.00968652  -0.101342     0.0387187
  0.0581842    0.0659625   -0.0235642    0.11159    -0.0159817    -0.0161735   0.0409109  -0.175445     0.151287     0.173117     -0.0683415    0.0452351   -0.0522062   -0.00219139   0.027421    -0.0828661    0.0652243     0.0306524   -0.0542753   -0.123288   -0.180671     -0.053732    -0.00558605   0.0141326    0.041383    -0.0440781
  0.0281148    0.128257     0.00808015  -0.0281626  -0.0218389     0.134393   -0.112118    0.0932718   -0.251446     0.062943     -0.0578901    0.0208742    0.057858    -0.00936602  -0.0225431   -0.131159     0.0696343    -0.0975266   -0.0936222   -0.029333   -0.33347      -0.103138    -0.257015    -0.0436309   -0.077462    -0.176832
  0.0615855    0.0542103   -0.0510311   -0.0234124  -0.0682871     0.169652   -0.0864198  -0.028827    -0.12531      0.0533165    -0.103819     0.0366701    0.133851    -0.0126732   -0.06186      0.0442125    0.0817293    -0.144703    -0.00368312  -0.0373444   0.0282364    -0.127287     0.387066    -0.0154414   -0.0536755   -0.157544
 -0.108618     0.0339079   -0.0752299    0.125479   -0.030935     -0.169086   -0.0456407   0.013074     0.147009    -0.0450441     0.066111     0.116697    -0.6245       0.0173714   -0.130953    -0.0125922    0.0315206    -0.0970956    0.0478982   -0.127978   -0.0317075     0.19579     -0.0144902   -0.13251     -0.127735     0.0385879
 -0.132124     0.0292566   -0.0662421    0.0365825  -0.0268064    -0.157419   -0.155231    0.110131     0.181241     0.0189498     0.0582764    0.067799     0.574967     0.0124168   -0.10204      0.196819    -0.0832978    -0.0589409    0.0129351   -0.160431    0.159409      0.173567     0.0951486   -0.0205653   -0.124031     0.0190548
  0.0258431   -0.0545298   -0.308053    -0.0874328   0.178143      0.0525137   0.0110248   0.0507945    0.240695    -0.140888     -0.0371381    0.0857217    0.0137077   -0.0748966   -0.0579579   -0.0629235    0.0570597     0.128896    -0.131323    -0.022896   -0.0200744    -0.106978     0.118776     0.0452134    0.0429862   -0.00416708
 -0.108892    -0.00778018   0.0987776    0.0497129   0.0211306     0.0138941   0.105164    0.140662    -0.0873891    0.107467      0.071083     0.0634287    0.00314257  -0.0100607   -0.0156193   -0.0895886    0.0344649     0.22901      0.00132553  -0.0680853  -0.0414043    -0.0458993    0.0418185   -0.055055    -0.00393764  -0.173114
  0.0597857   -0.0227112   -0.0366154   -0.0325078   0.176151      0.0885983  -0.106767   -0.0678457    0.127388     0.0785317    -0.017814     0.0397403    0.0681674    0.0376233    0.13501     -0.0571666    0.0704437     0.144593     1.1296e-5    0.0538347  -0.0496325    -0.0138868   -0.00149511  -0.100315     0.00571481  -0.147463
  0.0902283   -0.0133572    0.00137465  -0.107969    0.0878727     0.0693597   0.0989464   0.122931     0.0806506    0.00328929   -0.0135638    0.0932289    0.197933     0.104116     0.00348771   0.0841148   -0.0909459    -0.0114345   -0.104373    -0.190319    0.0680104     0.0425755   -0.0818239    0.0648649   -0.0503626   -0.0135278
 -0.183371    -0.0534655   -0.160641     0.0201719  -0.0293888    -0.0671641  -0.00283     0.0077478   -0.0777921   -0.0258255     0.0943856    0.139979    -0.0323782   -0.0407473   -0.0185808   -0.153108    -0.0510029     0.0105062   -0.0623784   -0.100083   -0.0143595    -0.0746026    0.0895555   -0.012164     0.0802674    0.038837
  0.111228    -0.0531845    0.0300116    0.069988    0.0287469    -0.127618   -0.120247    0.0953493   -0.0471882   -0.108833     -0.00977958  -0.135513     0.119061     0.152232     0.118488     0.0635279    0.0712995     0.271413    -0.0829014   -0.168571   -0.0232047     0.0701256    0.0756585    0.0502997    0.0207308   -0.0446543
 -0.0655642   -0.0348579    0.14878     -0.0243504  -0.111887      0.160021    0.0710609  -0.0441307   -0.360473    -0.0258192    -0.00657341  -0.0845608    0.0538422    0.0460583   -0.0388611    0.129547     0.124668     -0.114543    -0.0449658   -0.0134488  -0.0999915    -0.15884      0.0103757    0.0550289   -0.248447     0.0873157
 -0.0758154   -0.0594187    0.0153667    0.0224111  -0.169993      0.142132   -0.117648   -0.160659     0.667433    -0.064092      0.0123976   -0.10121      0.0207829    0.00263918  -0.160612    -0.429601     0.0366572    -0.125614    -0.0178242    0.0424906   0.0131234    -0.0440076    0.0054419   -0.0370491    0.186471     0.041898
 -0.0348054   -0.182794    -0.0342885    0.0494808  -0.0978181     0.0337411   0.0262114   0.0467235    0.0614626   -0.0443109    -0.0322519   -0.00211234   0.0738378   -0.0689911   -0.0270056   -0.0211908   -0.0519268     0.0498221    0.0037405   -0.0956994   0.00744397   -0.0797145    0.0668558   -0.0207752   -0.0283507    0.041706
  0.0946277   -0.0870042    0.0361165   -0.107994   -0.129666     -0.0680954   0.0311588   0.150365    -0.133964    -0.000739757  -0.0289486    0.0982329    0.114366    -0.0521115    0.00387049  -0.00303011  -0.0184547    -0.0716666   -0.0969376    0.30748     0.0931045     0.100719     0.0708071   -0.0322275   -0.0214507    0.0274154
 -0.035709    -0.265277     0.0370142    0.0432425  -0.0434831     0.0553309  -0.0229263  -0.0605996    0.0454548    0.144477     -0.0811881   -0.155889    -0.0174465   -0.065088     0.102034     0.161243     0.0440365     0.0710257    0.0333368    0.111681   -0.00762707    0.119737    -0.213638     0.0594903   -0.0343907   -0.0460406
 -0.00267321   0.0269277    0.0790452    0.0880737  -0.127532      0.0878159   0.0827064  -0.0143689   -0.0103167   -0.0877413    -0.0237122   -0.0129192    0.0510923   -0.0160706    0.0659376    0.0583939    0.095943      0.0276375   -0.0401007    0.0481518  -0.141775      0.00669203  -0.0324834   -0.159781    -0.0270138   -0.00310709
  0.00220914   0.0547128   -0.0684676    0.103276   -0.0352267     0.0327033  -0.0622199  -0.061001    -0.0104693   -0.0393678    -0.106296     0.109832     0.0353492    0.0700678    0.00110005  -0.124378     0.000916262   0.00242933  -0.148555    -0.0491413  -0.0807546     0.112639    -0.0279456   -0.0220136    0.0176989   -0.0730577
 -0.091313     0.104589     0.147758     0.0914771  -0.0599223     0.0749839   0.111436   -0.109167     0.0245674   -0.0437351    -0.0143433    0.0650209   -0.0117517   -0.0795397    0.0367842    0.0833152    0.0808936     0.0631577   -0.0996915    0.101842    0.0343934     0.0985304   -0.0739011    0.0630518    0.0986692   -0.089036
 -0.125769    -0.157403    -0.145992    -0.0202902  -0.0422105     0.123635   -0.0824637   0.149017     0.00310815  -0.032965      0.102297     0.0919325    0.185311     0.0952365   -0.108613     0.0527381    0.0303461     0.128539     0.15105      0.0219191   0.160998     -0.0938396    0.0826276   -0.0214089    0.0580733   -0.0149339
  0.0260672   -0.0887482   -0.0118102   -0.111913    0.0347331    -0.012503   -0.107955    0.0773618    0.117441    -0.0770236    -0.101252     0.00201807  -0.0148086   -0.0957608    0.0331497   -0.0319634   -0.0179837    -0.0209576    0.0289865    0.103362    0.000915588  -0.0562475   -0.0354034    0.0139648    0.0934412   -0.0987803
  0.151783    -0.0772416    0.147199    -0.229833    0.0459569     0.104033    0.0572415   0.150946    -0.0649145   -0.0464534     0.0108922    0.0200499    0.118659     0.0509711    0.160278     0.0773447   -0.0621756     0.0141686   -0.120032     0.0112003   0.0262161    -0.140285    -0.148635    -0.140765     0.125062    -0.0464947
  0.0843301   -0.123304     0.131053    -0.0326068   0.00647753    0.21092    -0.071607   -0.0144145   -0.0733631   -0.0390751     0.077072    -0.0349776   -0.0749526    0.0253034    0.0676258    0.0161594   -0.0106241    -0.126275     0.020446     0.10109     0.0816049     0.0533971   -0.084846     0.0581975   -0.00688632  -0.0752522
  0.073845    -0.208117     0.0468941   -0.086996   -0.207293      0.189147   -0.14196    -0.0627778    0.0593377   -0.0264472    -0.084736     0.0894708   -0.0131896   -0.0223352   -0.144142     0.0513324    0.0428193    -0.00384702  -0.0818556    0.135525    0.180636      0.0907013    0.138614    -0.779394    -0.0690024    0.057038
 -0.113779    -0.158686     0.0225268    0.153749   -0.19845      -0.0044871   0.123495   -0.0304468    0.0273109   -0.0789748    -0.040517     0.0163294    0.0461673   -0.0978687   -0.00237318   0.023776     0.0641516    -0.0621952    0.0385012    0.0215142   0.113512      0.129571     0.10439      0.513485    -0.0601768    0.0584948
 -0.0985946   -0.124418     0.0320268    0.162199   -0.073013     -0.0227999  -0.1032      0.00445292  -0.0498699    0.104614      0.11774      0.181184    -0.00952048   0.0893274   -0.185574     0.154496    -0.0672527    -0.00311741   0.265496    -0.115949    0.179714      0.0163969    0.0911321   -0.0963824   -0.187557    -0.0234079
 -0.00903633  -0.136867     0.0315513    0.188056    0.0517042     0.0403695   0.0192635   0.00356113  -0.0030466    0.191462      0.116642     0.227808    -0.216842    -0.112116     0.282123     0.145749    -0.0950577     0.00572244  -0.34197     -0.148149   -0.0766418     0.0635077    0.116584     0.54432     -0.157579    -0.0238678[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     17
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.072458
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     12
│     17
│     19
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.037716
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.036955
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     12
│     17
│     19
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.045003
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     19
│     21
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.058989
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     12
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.035602
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     19
│     21
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054950
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     12
│     17
│     19
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.042069
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.047491
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     12
│     17
│     19
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.050027
┌ Info: EM with 100000 data points 10 iterations avll -1.050027
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.978408e+05
      1       6.864777e+05      -2.113631e+05 |       32
      2       6.488198e+05      -3.765796e+04 |       32
      3       6.288819e+05      -1.993781e+04 |       32
      4       6.173701e+05      -1.151188e+04 |       32
      5       6.122583e+05      -5.111768e+03 |       32
      6       6.097358e+05      -2.522468e+03 |       32
      7       6.085029e+05      -1.232927e+03 |       32
      8       6.077578e+05      -7.450770e+02 |       32
      9       6.071532e+05      -6.045884e+02 |       32
     10       6.064572e+05      -6.960543e+02 |       32
     11       6.056808e+05      -7.763716e+02 |       32
     12       6.049407e+05      -7.400909e+02 |       32
     13       6.042866e+05      -6.541221e+02 |       32
     14       6.035607e+05      -7.258895e+02 |       32
     15       6.028430e+05      -7.176782e+02 |       32
     16       6.024326e+05      -4.104620e+02 |       32
     17       6.021947e+05      -2.378804e+02 |       32
     18       6.020155e+05      -1.791654e+02 |       32
     19       6.018311e+05      -1.844673e+02 |       31
     20       6.016212e+05      -2.098906e+02 |       32
     21       6.014340e+05      -1.871858e+02 |       32
     22       6.013212e+05      -1.128047e+02 |       30
     23       6.012689e+05      -5.228804e+01 |       31
     24       6.012459e+05      -2.295862e+01 |       29
     25       6.012316e+05      -1.435381e+01 |       29
     26       6.012193e+05      -1.230223e+01 |       29
     27       6.012076e+05      -1.168172e+01 |       25
     28       6.012024e+05      -5.154446e+00 |       24
     29       6.011994e+05      -3.028930e+00 |       21
     30       6.011968e+05      -2.601599e+00 |       22
     31       6.011939e+05      -2.951764e+00 |       21
     32       6.011912e+05      -2.616581e+00 |       22
     33       6.011886e+05      -2.653603e+00 |       22
     34       6.011853e+05      -3.298820e+00 |       22
     35       6.011820e+05      -3.298244e+00 |       27
     36       6.011787e+05      -3.294373e+00 |       22
     37       6.011755e+05      -3.211441e+00 |       23
     38       6.011715e+05      -4.008977e+00 |       25
     39       6.011669e+05      -4.623467e+00 |       20
     40       6.011624e+05      -4.488656e+00 |       20
     41       6.011597e+05      -2.700091e+00 |       20
     42       6.011571e+05      -2.567839e+00 |       17
     43       6.011553e+05      -1.781317e+00 |       16
     44       6.011537e+05      -1.596917e+00 |       16
     45       6.011524e+05      -1.346877e+00 |       15
     46       6.011512e+05      -1.195458e+00 |       16
     47       6.011489e+05      -2.326026e+00 |       17
     48       6.011463e+05      -2.509986e+00 |       22
     49       6.011442e+05      -2.120354e+00 |       23
     50       6.011415e+05      -2.765858e+00 |       23
K-means terminated without convergence after 50 iterations (objv = 601141.4549669072)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311120
[ Info: iteration 2, average log likelihood -1.273785
[ Info: iteration 3, average log likelihood -1.244002
[ Info: iteration 4, average log likelihood -1.215418
[ Info: iteration 5, average log likelihood -1.173196
[ Info: iteration 6, average log likelihood -1.112444
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     10
│     15
│     16
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046056
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│      9
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.088378
[ Info: iteration 9, average log likelihood -1.133589
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.071466
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.021146
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.066458
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.101327
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.046127
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.035467
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.055763
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.063976
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.043379
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.040472
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.062458
[ Info: iteration 21, average log likelihood -1.089501
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.039420
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     10
│     18
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.021808
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.060104
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080017
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.042903
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.066323
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     16
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.032183
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.069653
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.040465
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     18
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.045133
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.058953
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.057280
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.041977
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.054964
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      6
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.047153
[ Info: iteration 37, average log likelihood -1.088726
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.044533
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.067986
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.050897
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.004756
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     10
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.054586
[ Info: iteration 43, average log likelihood -1.104442
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.051740
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      7
│      9
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.003650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     16
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.064905
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.089214
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.061601
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.040550
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     16
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.032672
┌ Info: EM with 100000 data points 50 iterations avll -1.032672
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.00756222   0.112461    -0.0432295    0.0348841    0.00884421    0.0605771     0.0317409   -0.0898875   -0.0184968   -0.0543842   -0.12436      0.180661    0.0595597    0.0529793    0.0619717   -0.0749896    -0.0375884    0.0602852   -0.183415     -0.096813    -0.227359     0.0803025   -0.0250452    0.0489341    -0.0167464   -0.138386
 -0.120728     0.0315403   -0.0707965    0.080643    -0.0287761    -0.163109     -0.103406     0.0635781    0.166832    -0.0120477    0.0619525    0.0932715  -0.0108012    0.0153872   -0.116235     0.0951063    -0.0285035   -0.0788838    0.0307848    -0.143824     0.0658408    0.184448     0.041849    -0.0732957    -0.126663     0.0277663
  0.0645849   -0.022979    -0.0364432   -0.0328764    0.175716      0.0889216    -0.105874    -0.0665531    0.126497     0.0795248   -0.0184666    0.0397426   0.0600732    0.0348535    0.135254    -0.0571474     0.0698832    0.141977    -0.000295966   0.0563152   -0.0489873   -0.0160207   -0.00455293  -0.100316      0.00448207  -0.144113
  0.342309    -0.118178     0.492428    -0.133725     0.0262724     0.26299       0.131723     0.185449    -0.0479428   -0.0711794    0.00725567   0.022879    0.130616     0.104496     0.122977     0.0544523    -0.073071    -0.00652206  -0.0899698    -0.0288809    0.0194718   -0.0990693   -0.0752131   -0.175978      0.112528     0.262128
 -0.0235434   -0.183053     0.03465      0.0376632   -0.202676      0.0876339    -0.0054122   -0.0460561    0.0429141   -0.053313    -0.0610318    0.0517809   0.0162301   -0.0616909   -0.0710432    0.0368497     0.0537557   -0.0340441   -0.0201321     0.0771892    0.147172     0.111783     0.121333    -0.113912     -0.0654421    0.0577574
 -0.00873875  -0.188948    -0.0754273    0.0442559   -0.112504     -0.0575074     0.0159344    0.0715897    0.0762065   -0.0411119   -0.0300311    0.0242907   0.0629943   -0.0593888   -0.0538482   -0.0261513    -0.0677947    0.0438864    0.0349475    -0.057054     0.0215422   -0.0606306    0.0561143   -0.00939837   -0.0519009    0.0261321
 -0.0491983   -0.0647293    0.0958031   -0.00396629  -0.135342      0.140205     -0.00676884  -0.0800993    0.077095    -0.0284335   -0.00795766  -0.0792373   0.050188     0.0138585   -0.0881829   -0.0995868     0.0680501   -0.0891915   -0.0234742     0.0192988   -0.0285743   -0.0924903    0.0216656    0.00835974   -0.0343299    0.06164
  0.00511029  -0.0153401   -0.0967789    0.174459    -0.117209     -0.0137692    -0.18125     -0.01086      0.00676116  -0.0302772   -0.0885882    0.0217885   0.00325433   0.0878899   -0.0718755   -0.190002      0.0579473   -0.0636459   -0.103749      0.0107766    0.101739     0.149761    -0.018378    -0.108476      0.0437466    0.0101672
  0.0750712   -0.106221    -0.0115203   -0.088479    -0.143688     -0.0803828     0.0252711    0.205512    -0.130641     0.0115708   -0.0282534    0.0848446   0.109852    -0.0580447    0.016438     0.000833011  -0.0394473   -0.0546767   -0.111149      0.249976     0.0859605    0.0952939    0.0657525   -0.0371888    -0.0374706    0.0316121
 -0.182217     0.0518344   -0.0266352   -0.0121502   -0.121328      0.0391374    -0.0492054   -0.0391621    0.0812485    0.257264     0.0199815    0.085244    0.0672217   -0.0952871    0.0254747    0.1271        0.0621349    0.0213005    0.0150637    -0.0173717   -0.157214    -0.00728063  -0.0805904   -0.0344177    -0.0432999   -0.102436
  0.0868206   -0.122768     0.13379     -0.0322154    0.00623145    0.210403     -0.0711418   -0.0133774   -0.0732029   -0.04026      0.0786288   -0.0340605  -0.0749866    0.0290547    0.0668228    0.0165366    -0.010495    -0.124022     0.0210831     0.0992285    0.0791283    0.0526046   -0.0860021    0.057988     -0.00717022  -0.0823762
  0.0450946    0.0940069   -0.0205153   -0.0253482   -0.046481      0.152811     -0.100851     0.0333345   -0.196086     0.0570065   -0.0804152    0.0284824   0.0978421   -0.0108388   -0.043106    -0.0477121     0.0762964   -0.122633    -0.0498679    -0.0343921   -0.157128    -0.115442     0.0550263   -0.0275838    -0.0657485   -0.169087
 -0.176737    -0.0633508   -0.17526      0.0275523   -0.0284338    -0.0733747    -0.00227207   0.0219671   -0.0797338   -0.0206569    0.115714     0.149269   -0.0373829   -0.0497008   -0.0182447   -0.170333     -0.0732812   -0.00424982  -0.0573985    -0.104966    -0.0153954   -0.0873755    0.0889224    0.000525926   0.0985364    0.046182
  0.0995031    0.0801378    0.0238317    0.192381     0.0965078    -0.0346707    -0.134577     0.0922143   -0.0416446   -0.138917     0.105236    -0.103749    0.198008     0.17958      0.136871     0.0905603    -0.053925     0.316438    -0.0968009    -0.155739     0.122466     0.00460874   0.0827902   -0.0749149     0.0303037    0.00714871
 -0.0887968    0.168573     0.195121     0.016979    -0.0836165     0.200299      0.167701    -0.266594    -0.0347198   -0.0452704   -0.00375428   0.0756759   0.0618115   -0.0198498    0.0502524    0.146195      0.114698     0.0754659   -0.222723      0.06641      0.00534041   0.0821671   -0.106323     0.0158723     0.110641    -0.139277
  0.0899096   -0.0127661    0.00111509  -0.108026     0.0882373     0.0693338     0.0995111    0.12472      0.08071      0.00341928  -0.0135075    0.0926969   0.199892     0.103524     0.00291312   0.0827221    -0.0910504   -0.0107916   -0.104353     -0.189857     0.0690926    0.0429635   -0.0832486    0.0650484    -0.0504344   -0.012026
  0.0621805    0.0691878   -0.0280754    0.114728    -0.0185426    -0.0199195     0.0402085   -0.173506     0.14912      0.164933    -0.0677665    0.0445451  -0.0506345   -0.00255034   0.0186505   -0.083011      0.0663331    0.0349303   -0.0525639    -0.123936    -0.180976    -0.0562248   -0.00408731   0.0159966     0.0430209   -0.0362687
 -0.0846886    0.00423748  -0.0358884   -0.013163    -0.0485288     0.0414606    -0.00671538  -0.0836863    0.081386     0.13317      0.0167306    0.046835    0.0125825   -0.190127     0.0498954    0.126933      0.0215563    0.0195519   -0.0584453     0.00520932  -0.0772543   -0.0397454   -0.0748684   -0.0453558    -0.0300156   -0.00874028
  0.0264449   -0.0540704   -0.307417    -0.0866379    0.177757      0.051751      0.00937108   0.0508621    0.24108     -0.140662    -0.036444     0.0868499   0.0137825   -0.074913    -0.0572611   -0.0652287     0.0563846    0.128171    -0.131608     -0.0230167   -0.0195376   -0.108118     0.118602     0.0465955     0.0433238   -0.00254924
 -0.0909988    0.0454702    0.108474     0.17107     -0.0248732    -0.0345825     0.0821879    0.0194913    0.0722704   -0.0328864   -0.0183678    0.0645435  -0.0871127   -0.132362     0.0378674    0.0302775     0.0502266    0.0611967    0.0183505     0.125655     0.0606904    0.114792    -0.0446833    0.115029      0.0858923   -0.0587984
  0.0118764   -0.107915     0.0391481   -0.100482    -0.0353366    -0.0248072    -0.201385     0.116763     0.197935    -0.175521    -0.0671879   -0.0262259   0.0440737   -0.0262935   -0.0241324   -0.075502     -0.0596998   -0.0542572    0.0653399     0.12691     -0.0212277   -0.0678667   -0.0266483    0.146501      0.238717     0.0314828
 -0.148282     0.0109834    0.0253868   -0.0253621    0.050635     -0.0527816    -0.0998575    0.0116005    0.0466518   -0.233951    -0.0011071    0.118217    0.10346     -0.0120955   -0.187176    -0.0467686     0.0818505   -0.0983372    0.00114193   -0.0643944   -0.052613    -0.274671    -0.00413907   0.0119454    -0.106718     0.0379292
  0.139175    -0.194049     0.0366455   -0.0520236   -0.00938206   -0.228092     -0.101361     0.110763    -0.0698018   -0.0831778   -0.119455    -0.178607    0.0538597    0.107982     0.117635     0.0483184     0.193549     0.254882    -0.0690995    -0.206861    -0.186219     0.12851      0.0726238    0.199106      0.0216835   -0.0942982
  0.0291594   -0.0701041    0.0607868    0.130607    -0.0807722     0.110283      0.0388959    0.00976676  -0.0446       0.0140049   -0.0523443   -0.0422589   0.0289334   -0.0168559    0.0932268    0.128827      0.106575     0.0476785    0.00868829    0.089729    -0.0879485    0.0440888   -0.123424    -0.0533991    -0.0601358   -0.0376441
  0.0220165   -0.0659283   -0.0735862   -0.108078     0.105616      0.00079354    0.0139985    0.0312424    0.0199419    0.0285825   -0.129972     0.0428421  -0.067585    -0.167665     0.0675481    0.0150364     0.02187      0.0145427   -0.00765698    0.0758995    0.0199858   -0.0495813   -0.0215893   -0.127061     -0.0671181   -0.219194
 -0.05453     -0.130237     0.0316885    0.173657    -0.0131608     0.00642935   -0.044316     0.00438221  -0.0270245    0.147342     0.117223     0.20359    -0.10856     -0.00631125   0.0354907    0.150372     -0.0802702    0.00100336  -0.0225155    -0.130776     0.057751     0.0389224    0.102889     0.208478     -0.173262    -0.0232913
  0.220384    -0.0794162    0.00228461  -0.045478    -0.119737      0.00787579    0.0402251    0.0538537   -0.0665157   -0.0624423   -0.0219971   -0.106933   -0.160542    -0.0602999   -0.0225939   -0.00572366    0.0353834    0.0962877    0.00155351    0.0151271   -0.0997266   -0.0369462   -0.0882711   -0.0250357    -0.0538476    0.0180969
 -0.123601    -0.156874    -0.147029    -0.020586    -0.0428265     0.121271     -0.0821381    0.140722     0.00251297  -0.0346934    0.099704     0.0888698   0.183817     0.097256    -0.0984122    0.0531991     0.0301476    0.120795     0.146788      0.0244444    0.164706    -0.0923701    0.0807155   -0.0222485     0.0587027   -0.0141871
  0.0024007    0.0356406    0.0787447   -0.0521373   -0.000176714  -0.106953      0.10144     -0.00574463  -0.112544     0.00242758  -0.0543153    0.164958    0.175819     0.196292    -0.0889955    0.0598368    -0.0383794    0.00113419   0.114827      0.102878    -0.0454603    0.166573    -0.0643922   -0.0714608    -0.140043     0.321554
 -0.10812     -0.00564059   0.101926     0.047661     0.0242668     0.0175131     0.104974     0.142016    -0.0876758    0.108679     0.0735441    0.0649659   0.00380397  -0.0128266   -0.0179406   -0.0949591     0.032824     0.233958     0.00384656   -0.0688056   -0.0400649   -0.0461021    0.0447907   -0.0555793    -0.00622179  -0.172459
  0.077646    -0.0676267    0.0463854   -0.23208      0.0472818     0.084011      0.0357711    0.147286    -0.0550414   -0.0374987    0.0111548    0.0152128   0.107741     0.0347908    0.16378      0.0809816    -0.0626827    0.0291211   -0.123173      0.0100952    0.0295332   -0.14697     -0.15035     -0.112866      0.118085    -0.125841
 -0.138702    -0.0958384    0.0741224   -0.0965028   -0.133331     -0.000470145   0.066636    -0.131285     0.124597    -0.0595233   -0.0207963   -0.0934684   0.036077    -0.0695451    0.0408122    0.00212394    0.00435189   0.0145787   -0.0904345     0.0396139   -0.104876     0.0491617   -0.0183871   -0.164627      0.0365358    0.0417435[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.080315
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.036118
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      7
│     18
│     25
│     26
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.000971
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     16
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.025059
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.047902
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     25
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007898
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     16
│     18
│     25
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.004381
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.027130
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      6
│     10
│     24
│     25
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.017404
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     16
│     18
│     25
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.013770
┌ Info: EM with 100000 data points 10 iterations avll -1.013770
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0990042    0.0286896   -0.0150844   -0.0856823   -0.14546    -0.0757288     0.0426333    0.181187     0.0718574   -0.195501     0.176773     0.107887   -0.0949392    -0.0109971   -0.109735     0.170874    -0.22759     -0.0988149   -0.023375     0.0631541   0.238691     0.129872     0.132241     0.163312    -0.0062487   -0.0118597
  0.1004      -0.202884     0.151988    -0.181599     0.118931   -0.163226     -0.0336253    0.130451     0.0408111    0.0175445    0.0869764   -0.167791   -0.0742504    -0.0948636    0.043571     0.0498379   -0.0501043   -0.0786417    0.182444     0.13065    -0.0300636    0.0775448   -0.0598644   -0.00527541   0.0549832    0.0701416
 -0.0111713   -0.0388247   -0.0926852    0.0710925    0.0705577  -0.0347981    -0.143218    -0.0127534    0.123081    -0.0713615    0.309155    -0.0337798   0.0774844     0.176616     0.0843537   -0.0247208    0.113885    -0.0753359    0.00707336   0.170511   -0.0616605   -0.132259     0.0994623    0.00383358  -0.0590919   -0.00615827
 -0.112906    -0.0919069   -0.130691     0.0462057   -0.213101    0.0655953    -0.366743    -0.0514427   -0.0502189   -0.0528867   -0.0384029    0.0086165   0.00566397    0.207699    -0.0567324   -0.0441637   -0.0642166   -0.0535564   -0.0194098    0.0290743   0.144951    -0.0814024    0.124033     0.00248051   0.00558855   0.111984
  0.105294     0.133403     0.110671     0.215257    -0.0173387  -0.000744588  -0.116551     0.0663736   -0.0151667    0.118119    -0.153832     0.111674   -0.0183129    -0.111487    -0.0520731   -0.0743511    0.0167918    0.0360384    0.0640048    0.0398222  -0.0558328    0.0332005    0.0489653    0.0589264    0.00893889   0.0103462
  0.0530613   -0.0489483   -0.0156708    0.0897691   -0.218666    0.122474      0.064119     0.0275892   -0.0328639   -0.0858619    0.0646296   -0.0119113  -0.0393035     0.0123511    0.0042983   -0.0302608    0.134472    -0.057018     0.0867248    0.173243    0.147355     0.0394446    0.147735    -0.0250763   -0.0606652   -0.000553934
 -0.025452     0.0727735    0.0423195   -0.0199235    0.0592184   0.179765      0.107313    -0.0142492    0.00549513  -0.116051     0.0589427    0.104485   -0.0309665    -0.0563714    0.121832     0.00407848   0.0249797   -0.0853871    0.102733    -0.120376    0.00503757   0.00801168  -0.110196     0.0404046   -0.0461101   -0.0693677
  0.0264102    0.00351682  -0.241937    -0.187631     0.0543997  -0.0113277    -0.0122882   -0.0799522   -0.0291397   -0.00286686   0.0400748    0.0513939  -0.117328     -0.18501      0.0400627    0.0680983    0.0468743    0.166967    -0.0277826   -0.0547028  -0.176093    -0.0569312   -0.0630917   -0.122595     0.0150578   -0.0694798
  0.129622     0.0635645    0.238457     0.00543247  -0.0291338   0.165394     -0.0824323   -0.040791    -0.172634     0.0362551   -0.00455439   0.150409   -0.0130722     0.0241236    0.00721582   0.135251     0.0699781    0.00481981   0.116514     0.158831    0.0927848    0.187654    -0.143208    -0.0521818   -0.0311749    0.00184997
 -0.066056    -0.0912307   -0.0212586   -0.17226      0.01037     0.0799678     0.131297     0.173753    -0.0323643   -0.0612309    0.012019     0.100766    0.0149185    -0.0244744    0.0105228    0.109933     0.0347674   -0.0123228   -0.0415652   -0.0837863  -0.0200743    0.0179159   -0.0593772   -0.055906    -0.088442     0.00708023
 -0.0311642   -0.0411297   -0.0767156   -0.0215683    0.0541444   0.0735309     0.137788     0.0137035    0.035171     0.0118015   -0.102536    -0.106574    0.00711387   -0.00213114  -0.0847754   -0.0768118    0.141264    -0.00247625  -0.129627    -0.0444516  -0.0533539    0.0251518   -0.0828717    0.182484    -0.0879876   -0.0147885
  0.0799855    0.156235     0.127119    -0.11457      0.152464   -0.0293899     0.0780748   -0.112954     0.036667     0.0972334   -0.143509    -0.0512669   0.0776736     0.0493731   -0.0196607    0.18094      0.042761     0.1224       0.025725     0.0367004   0.116862    -0.0653638   -0.0910522   -0.11945     -0.0672376    0.0139332
  0.114759     0.0938787   -0.137329    -0.210246    -0.135958   -0.0653336    -0.0195354    0.0727974   -0.0651243    0.0815727   -0.0137606   -0.160221   -0.0661579    -0.00565686   0.0428823    0.0675255    0.00549644  -0.0168428    0.182221     0.0197922   0.104178     0.0388521   -0.0747621    0.0300894    0.168157     0.152316
 -0.0118434   -0.0106117   -0.132614    -0.00440876  -0.0427584  -0.0835575     0.0365549   -0.108566    -0.0484396    0.065495     0.00584429  -0.112212    0.112944      0.0575598    0.0685504    0.0800301   -0.110349     0.0461583    0.00385736   0.0669807   0.0314386   -0.0571426   -0.169019    -0.101821     0.097043    -0.032797
 -0.100538    -0.185533     0.0823376    0.0136101    0.012054    0.026758     -0.120743     0.142582     0.167198     0.116235    -0.0124224   -0.0385786   0.112194     -0.112075     0.130714     0.107102     0.0896894   -0.0195785   -0.0520789    0.095298    0.0613938    0.132607    -0.0228511    0.0424278   -0.0925968    0.146413
 -0.0604993   -0.0185344   -0.105047     0.00520664  -0.05108    -0.0874551    -0.047346    -0.032756     0.0494482   -0.12366      0.251735    -0.0770295   0.0791963    -0.0189229   -0.0781774    0.176589     0.111103    -0.163693    -0.181455     0.0652659   0.0384301   -0.107949    -0.0446062   -0.0793383   -0.0132234   -0.0941786
 -0.0409364    0.009028     0.103578     0.0236596    0.100452   -0.0579547     0.0141022    0.0360453   -0.111666     0.0559913   -0.0208529   -0.176394   -0.000111782  -0.0897068    0.123878    -0.092801     0.0754768    0.0650481    0.0958923   -0.0728967   0.156637     0.0395172   -0.12438      0.0129724    0.104895    -0.0924281
 -0.0796301   -0.106228     0.00592926  -0.0270941    0.245331   -0.0275254     0.108609     0.151445     0.111921    -0.160361    -0.0599393    0.0687495   0.104835     -0.0209311   -0.2091       0.0896841    0.0632891   -0.0913413    0.0455253    0.261381    0.0235351    0.111337     0.0469591   -0.0952001   -0.0208586    0.0655027
  0.172307     0.00111715  -0.1949       0.0338694   -0.0913862  -0.169937      0.0374489   -0.0332674   -0.0551528   -0.048785    -0.108789    -0.0948359   0.0679947    -0.0135522   -0.0848779    0.0953502    0.124949     0.00681572   0.206876    -0.124028    0.166589    -0.0441776   -0.0510325    0.0712773    0.0391374    0.0376474
  0.0123994   -0.116463    -0.218741     0.0879821    0.0413753  -0.0434992     0.00797535   0.0901113    0.0206178    0.0489914    0.0309411   -0.0261896   0.104643     -0.00753625   0.199166     0.111912     0.175502     0.232891     0.0431224    0.0281256  -0.0157361   -0.00450567  -0.0269438   -0.0721914    0.153144     0.1162
 -0.0899743    0.0802147   -0.0421692    0.0337126    0.0524786   0.0374367    -0.117083     0.118367    -0.238098     0.0802122   -0.0305527   -0.066575    0.0492667     0.223201    -0.0138887    0.165521    -0.0399106   -0.228203     0.0336307    0.185834    0.0671519    0.0190341    0.147896    -0.0602397    0.0105296   -0.0665025
 -0.0160293    0.140338    -0.0294295    0.092847    -0.0240365  -0.146572      0.130443     0.110421     0.067552    -0.0251012   -0.00965571   0.0114631   0.0698747     0.176582     0.0517476    0.118438    -0.146657     0.179255     0.0607044    0.13409     0.0464869   -0.0473364    0.0699985   -0.213468    -0.20063     -0.0160065
  0.00296463   0.108382    -0.0476553   -0.0355294   -0.0124539  -0.181049      0.125993    -0.06204     -0.0612295    0.0447072   -0.0447235   -0.118961   -0.302933     -1.41004e-5   0.122034     0.125597     0.0590914   -0.0164754   -0.165773     0.0739726   0.00541043   0.0189113    0.0725109   -0.162741     0.15612     -0.248749
 -0.00818335   0.0543046    0.135995    -0.0225637   -0.108131    0.0750735     0.0318764    0.0678649   -0.0602639   -0.0413451   -0.0117241    0.098641    0.0439251     0.044416    -0.118856     0.0162627    0.00903619   0.11626      0.211183    -0.102384   -0.116084    -0.0557115   -0.0223285   -0.0629442   -0.200468    -0.0360208
  0.187074     0.0122232    0.143708    -0.0399737    0.0571338  -0.20324       0.0429825    0.12653      0.0565129   -0.114046    -0.0981711    0.133945   -0.0156752     0.0522023    0.0592336   -0.0652518    0.185736    -0.0198398   -0.0141381   -0.123803   -0.0930334   -0.109816    -0.00326261  -0.115394     0.21989     -0.006549
 -0.0888092   -0.0854448    0.0109515    0.0199002   -0.016359    0.0143109    -0.0096315    0.00327155   0.0292197   -0.119719     0.109841    -0.127052    0.200466      0.0557322    0.00872853  -0.119853     0.0527206    0.084073    -0.0384205   -0.0509273  -0.0352012    0.0842641   -0.0254937    0.0408776   -0.0117473    0.00656731
 -0.0269267   -0.0464052    0.0285327   -0.0438377    0.107601    0.0246101    -0.080354     0.066877    -0.0696659   -0.0133875    0.00227707  -0.0783329  -0.158628     -0.0106611    0.0155901   -0.0473152    0.043353     0.035837    -0.0559883   -0.137476   -0.0891477   -0.0296223    0.00333777   0.0695438    0.0627096   -0.0397454
  0.168999    -0.0148267   -0.00473748   0.0824257   -0.176206    0.0901846    -0.0321649   -0.00595047   0.0591312    0.0666988   -0.109532     0.190033   -0.0813256    -0.0165382    0.187273    -0.0014547    0.0521885   -0.168856     0.124595     0.229646    0.0674714    0.0106429   -0.0444513    0.073736    -0.0875305   -0.0262062
 -0.0149179   -0.215298     0.0943815    0.0895242    0.0246757  -0.195064     -0.0881585   -0.0689338    0.158251    -0.0928047    0.00222542  -0.0147148  -0.172538     -0.0842405   -0.091724     0.0430423    0.134473     0.0483703    0.0627433    0.0636895   0.0763043   -0.0840881   -0.0777048    0.0493002   -0.109027    -0.00754573
  0.0281319    0.0509051   -0.00953772   0.0533143    0.129145    0.174475     -0.0887967   -0.0526258    0.0818508    0.115687    -0.121855     0.0597619  -0.045748     -0.0310545   -0.115523    -0.0344992    0.0101656    0.0825767   -0.0412077   -0.0710121  -0.0102241    0.139611     0.095008    -0.123795     0.15179      0.0983269
  0.252106    -0.0182581    0.0719457   -0.122057    -0.0654579  -0.132734      0.0253673   -0.0763051   -0.0407307   -0.243964     0.204576    -0.0997506   0.146841     -0.0513692    0.0254648    0.227863    -0.0403765   -0.0146634    0.0536476    0.075793   -0.180417    -0.00217785   0.0907086    0.066872    -0.0954628   -0.0988211
  0.0998861    0.0507163   -0.126528    -0.148043    -0.158601   -0.0407606     0.1902      -0.231692     0.194459    -0.131406    -0.0199586    0.0209238   0.215687     -0.0175311    0.156665    -0.19479      0.186326    -0.123858     0.0192364   -0.0646319   0.144549    -0.0133586    0.103602     0.0577328   -0.0108805   -0.0660324kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4219651655085086
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421984
[ Info: iteration 2, average log likelihood -1.421931
[ Info: iteration 3, average log likelihood -1.421897
[ Info: iteration 4, average log likelihood -1.421857
[ Info: iteration 5, average log likelihood -1.421801
[ Info: iteration 6, average log likelihood -1.421711
[ Info: iteration 7, average log likelihood -1.421534
[ Info: iteration 8, average log likelihood -1.421152
[ Info: iteration 9, average log likelihood -1.420376
[ Info: iteration 10, average log likelihood -1.419164
[ Info: iteration 11, average log likelihood -1.417936
[ Info: iteration 12, average log likelihood -1.417166
[ Info: iteration 13, average log likelihood -1.416828
[ Info: iteration 14, average log likelihood -1.416701
[ Info: iteration 15, average log likelihood -1.416654
[ Info: iteration 16, average log likelihood -1.416635
[ Info: iteration 17, average log likelihood -1.416628
[ Info: iteration 18, average log likelihood -1.416625
[ Info: iteration 19, average log likelihood -1.416624
[ Info: iteration 20, average log likelihood -1.416623
[ Info: iteration 21, average log likelihood -1.416623
[ Info: iteration 22, average log likelihood -1.416622
[ Info: iteration 23, average log likelihood -1.416622
[ Info: iteration 24, average log likelihood -1.416622
[ Info: iteration 25, average log likelihood -1.416622
[ Info: iteration 26, average log likelihood -1.416622
[ Info: iteration 27, average log likelihood -1.416622
[ Info: iteration 28, average log likelihood -1.416621
[ Info: iteration 29, average log likelihood -1.416621
[ Info: iteration 30, average log likelihood -1.416621
[ Info: iteration 31, average log likelihood -1.416621
[ Info: iteration 32, average log likelihood -1.416621
[ Info: iteration 33, average log likelihood -1.416621
[ Info: iteration 34, average log likelihood -1.416621
[ Info: iteration 35, average log likelihood -1.416621
[ Info: iteration 36, average log likelihood -1.416621
[ Info: iteration 37, average log likelihood -1.416621
[ Info: iteration 38, average log likelihood -1.416621
[ Info: iteration 39, average log likelihood -1.416621
[ Info: iteration 40, average log likelihood -1.416621
[ Info: iteration 41, average log likelihood -1.416621
[ Info: iteration 42, average log likelihood -1.416621
[ Info: iteration 43, average log likelihood -1.416621
[ Info: iteration 44, average log likelihood -1.416621
[ Info: iteration 45, average log likelihood -1.416621
[ Info: iteration 46, average log likelihood -1.416621
[ Info: iteration 47, average log likelihood -1.416621
[ Info: iteration 48, average log likelihood -1.416621
[ Info: iteration 49, average log likelihood -1.416621
[ Info: iteration 50, average log likelihood -1.416621
┌ Info: EM with 100000 data points 50 iterations avll -1.416621
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4219844746498906
│     -1.421930992438696
│      ⋮
└     -1.4166206027930448
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416640
[ Info: iteration 2, average log likelihood -1.416583
[ Info: iteration 3, average log likelihood -1.416547
[ Info: iteration 4, average log likelihood -1.416507
[ Info: iteration 5, average log likelihood -1.416458
[ Info: iteration 6, average log likelihood -1.416400
[ Info: iteration 7, average log likelihood -1.416335
[ Info: iteration 8, average log likelihood -1.416267
[ Info: iteration 9, average log likelihood -1.416202
[ Info: iteration 10, average log likelihood -1.416146
[ Info: iteration 11, average log likelihood -1.416098
[ Info: iteration 12, average log likelihood -1.416060
[ Info: iteration 13, average log likelihood -1.416027
[ Info: iteration 14, average log likelihood -1.415999
[ Info: iteration 15, average log likelihood -1.415973
[ Info: iteration 16, average log likelihood -1.415950
[ Info: iteration 17, average log likelihood -1.415928
[ Info: iteration 18, average log likelihood -1.415908
[ Info: iteration 19, average log likelihood -1.415889
[ Info: iteration 20, average log likelihood -1.415870
[ Info: iteration 21, average log likelihood -1.415852
[ Info: iteration 22, average log likelihood -1.415835
[ Info: iteration 23, average log likelihood -1.415818
[ Info: iteration 24, average log likelihood -1.415801
[ Info: iteration 25, average log likelihood -1.415785
[ Info: iteration 26, average log likelihood -1.415769
[ Info: iteration 27, average log likelihood -1.415753
[ Info: iteration 28, average log likelihood -1.415737
[ Info: iteration 29, average log likelihood -1.415722
[ Info: iteration 30, average log likelihood -1.415707
[ Info: iteration 31, average log likelihood -1.415693
[ Info: iteration 32, average log likelihood -1.415679
[ Info: iteration 33, average log likelihood -1.415666
[ Info: iteration 34, average log likelihood -1.415654
[ Info: iteration 35, average log likelihood -1.415642
[ Info: iteration 36, average log likelihood -1.415631
[ Info: iteration 37, average log likelihood -1.415621
[ Info: iteration 38, average log likelihood -1.415612
[ Info: iteration 39, average log likelihood -1.415604
[ Info: iteration 40, average log likelihood -1.415596
[ Info: iteration 41, average log likelihood -1.415588
[ Info: iteration 42, average log likelihood -1.415582
[ Info: iteration 43, average log likelihood -1.415576
[ Info: iteration 44, average log likelihood -1.415570
[ Info: iteration 45, average log likelihood -1.415565
[ Info: iteration 46, average log likelihood -1.415560
[ Info: iteration 47, average log likelihood -1.415555
[ Info: iteration 48, average log likelihood -1.415551
[ Info: iteration 49, average log likelihood -1.415547
[ Info: iteration 50, average log likelihood -1.415544
┌ Info: EM with 100000 data points 50 iterations avll -1.415544
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416639661827779
│     -1.4165834250927638
│      ⋮
└     -1.415543891938318
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415551
[ Info: iteration 2, average log likelihood -1.415499
[ Info: iteration 3, average log likelihood -1.415456
[ Info: iteration 4, average log likelihood -1.415408
[ Info: iteration 5, average log likelihood -1.415349
[ Info: iteration 6, average log likelihood -1.415278
[ Info: iteration 7, average log likelihood -1.415194
[ Info: iteration 8, average log likelihood -1.415103
[ Info: iteration 9, average log likelihood -1.415010
[ Info: iteration 10, average log likelihood -1.414923
[ Info: iteration 11, average log likelihood -1.414847
[ Info: iteration 12, average log likelihood -1.414782
[ Info: iteration 13, average log likelihood -1.414727
[ Info: iteration 14, average log likelihood -1.414680
[ Info: iteration 15, average log likelihood -1.414641
[ Info: iteration 16, average log likelihood -1.414607
[ Info: iteration 17, average log likelihood -1.414578
[ Info: iteration 18, average log likelihood -1.414553
[ Info: iteration 19, average log likelihood -1.414531
[ Info: iteration 20, average log likelihood -1.414513
[ Info: iteration 21, average log likelihood -1.414497
[ Info: iteration 22, average log likelihood -1.414482
[ Info: iteration 23, average log likelihood -1.414470
[ Info: iteration 24, average log likelihood -1.414459
[ Info: iteration 25, average log likelihood -1.414449
[ Info: iteration 26, average log likelihood -1.414439
[ Info: iteration 27, average log likelihood -1.414431
[ Info: iteration 28, average log likelihood -1.414422
[ Info: iteration 29, average log likelihood -1.414414
[ Info: iteration 30, average log likelihood -1.414406
[ Info: iteration 31, average log likelihood -1.414398
[ Info: iteration 32, average log likelihood -1.414391
[ Info: iteration 33, average log likelihood -1.414383
[ Info: iteration 34, average log likelihood -1.414375
[ Info: iteration 35, average log likelihood -1.414367
[ Info: iteration 36, average log likelihood -1.414359
[ Info: iteration 37, average log likelihood -1.414351
[ Info: iteration 38, average log likelihood -1.414342
[ Info: iteration 39, average log likelihood -1.414334
[ Info: iteration 40, average log likelihood -1.414325
[ Info: iteration 41, average log likelihood -1.414315
[ Info: iteration 42, average log likelihood -1.414306
[ Info: iteration 43, average log likelihood -1.414295
[ Info: iteration 44, average log likelihood -1.414285
[ Info: iteration 45, average log likelihood -1.414274
[ Info: iteration 46, average log likelihood -1.414263
[ Info: iteration 47, average log likelihood -1.414251
[ Info: iteration 48, average log likelihood -1.414239
[ Info: iteration 49, average log likelihood -1.414227
[ Info: iteration 50, average log likelihood -1.414214
┌ Info: EM with 100000 data points 50 iterations avll -1.414214
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4155513725367455
│     -1.4154992469464096
│      ⋮
└     -1.4142144956973903
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414210
[ Info: iteration 2, average log likelihood -1.414156
[ Info: iteration 3, average log likelihood -1.414108
[ Info: iteration 4, average log likelihood -1.414053
[ Info: iteration 5, average log likelihood -1.413990
[ Info: iteration 6, average log likelihood -1.413915
[ Info: iteration 7, average log likelihood -1.413829
[ Info: iteration 8, average log likelihood -1.413734
[ Info: iteration 9, average log likelihood -1.413632
[ Info: iteration 10, average log likelihood -1.413528
[ Info: iteration 11, average log likelihood -1.413425
[ Info: iteration 12, average log likelihood -1.413325
[ Info: iteration 13, average log likelihood -1.413230
[ Info: iteration 14, average log likelihood -1.413143
[ Info: iteration 15, average log likelihood -1.413064
[ Info: iteration 16, average log likelihood -1.412994
[ Info: iteration 17, average log likelihood -1.412933
[ Info: iteration 18, average log likelihood -1.412880
[ Info: iteration 19, average log likelihood -1.412833
[ Info: iteration 20, average log likelihood -1.412793
[ Info: iteration 21, average log likelihood -1.412757
[ Info: iteration 22, average log likelihood -1.412725
[ Info: iteration 23, average log likelihood -1.412696
[ Info: iteration 24, average log likelihood -1.412670
[ Info: iteration 25, average log likelihood -1.412645
[ Info: iteration 26, average log likelihood -1.412622
[ Info: iteration 27, average log likelihood -1.412601
[ Info: iteration 28, average log likelihood -1.412580
[ Info: iteration 29, average log likelihood -1.412561
[ Info: iteration 30, average log likelihood -1.412542
[ Info: iteration 31, average log likelihood -1.412524
[ Info: iteration 32, average log likelihood -1.412507
[ Info: iteration 33, average log likelihood -1.412490
[ Info: iteration 34, average log likelihood -1.412474
[ Info: iteration 35, average log likelihood -1.412458
[ Info: iteration 36, average log likelihood -1.412442
[ Info: iteration 37, average log likelihood -1.412427
[ Info: iteration 38, average log likelihood -1.412413
[ Info: iteration 39, average log likelihood -1.412399
[ Info: iteration 40, average log likelihood -1.412385
[ Info: iteration 41, average log likelihood -1.412372
[ Info: iteration 42, average log likelihood -1.412359
[ Info: iteration 43, average log likelihood -1.412346
[ Info: iteration 44, average log likelihood -1.412334
[ Info: iteration 45, average log likelihood -1.412322
[ Info: iteration 46, average log likelihood -1.412310
[ Info: iteration 47, average log likelihood -1.412299
[ Info: iteration 48, average log likelihood -1.412288
[ Info: iteration 49, average log likelihood -1.412278
[ Info: iteration 50, average log likelihood -1.412268
┌ Info: EM with 100000 data points 50 iterations avll -1.412268
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414209597425614
│     -1.4141562910908185
│      ⋮
└     -1.4122677774982395
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412266
[ Info: iteration 2, average log likelihood -1.412202
[ Info: iteration 3, average log likelihood -1.412142
[ Info: iteration 4, average log likelihood -1.412071
[ Info: iteration 5, average log likelihood -1.411983
[ Info: iteration 6, average log likelihood -1.411873
[ Info: iteration 7, average log likelihood -1.411740
[ Info: iteration 8, average log likelihood -1.411588
[ Info: iteration 9, average log likelihood -1.411422
[ Info: iteration 10, average log likelihood -1.411251
[ Info: iteration 11, average log likelihood -1.411085
[ Info: iteration 12, average log likelihood -1.410929
[ Info: iteration 13, average log likelihood -1.410789
[ Info: iteration 14, average log likelihood -1.410665
[ Info: iteration 15, average log likelihood -1.410557
[ Info: iteration 16, average log likelihood -1.410463
[ Info: iteration 17, average log likelihood -1.410382
[ Info: iteration 18, average log likelihood -1.410311
[ Info: iteration 19, average log likelihood -1.410247
[ Info: iteration 20, average log likelihood -1.410191
[ Info: iteration 21, average log likelihood -1.410139
[ Info: iteration 22, average log likelihood -1.410093
[ Info: iteration 23, average log likelihood -1.410050
[ Info: iteration 24, average log likelihood -1.410011
[ Info: iteration 25, average log likelihood -1.409975
[ Info: iteration 26, average log likelihood -1.409941
[ Info: iteration 27, average log likelihood -1.409910
[ Info: iteration 28, average log likelihood -1.409881
[ Info: iteration 29, average log likelihood -1.409853
[ Info: iteration 30, average log likelihood -1.409828
[ Info: iteration 31, average log likelihood -1.409804
[ Info: iteration 32, average log likelihood -1.409781
[ Info: iteration 33, average log likelihood -1.409759
[ Info: iteration 34, average log likelihood -1.409738
[ Info: iteration 35, average log likelihood -1.409719
[ Info: iteration 36, average log likelihood -1.409700
[ Info: iteration 37, average log likelihood -1.409683
[ Info: iteration 38, average log likelihood -1.409666
[ Info: iteration 39, average log likelihood -1.409650
[ Info: iteration 40, average log likelihood -1.409634
[ Info: iteration 41, average log likelihood -1.409619
[ Info: iteration 42, average log likelihood -1.409605
[ Info: iteration 43, average log likelihood -1.409591
[ Info: iteration 44, average log likelihood -1.409578
[ Info: iteration 45, average log likelihood -1.409565
[ Info: iteration 46, average log likelihood -1.409552
[ Info: iteration 47, average log likelihood -1.409540
[ Info: iteration 48, average log likelihood -1.409528
[ Info: iteration 49, average log likelihood -1.409517
[ Info: iteration 50, average log likelihood -1.409505
┌ Info: EM with 100000 data points 50 iterations avll -1.409505
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4122661421909113
│     -1.4122022471624405
│      ⋮
└     -1.4095054054044422
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4219651655085086
│     -1.4219844746498906
│     -1.421930992438696
│     -1.4218968269681724
│      ⋮
│     -1.4095281341161225
│     -1.4095166134897723
└     -1.4095054054044422
32×26 Array{Float64,2}:
 -0.485262   -0.468631     0.41699     -0.596988   -0.215559   -0.231054   -0.18761     0.455784   -0.108615   -0.0373024     0.100466    -0.552765    -0.702906    -0.0186648   -0.542782    -0.644949     0.0364602  -0.212171      0.0152764   -0.216158   -0.289179    -0.0657371    0.319167    -0.106373     -0.469536   -0.316893
 -0.494839   -0.310617    -0.188177    -0.331876   -0.121236   -0.0207177  -0.13159     0.223876   -0.683801   -0.233799      0.565292     0.300008    -0.140601    -0.595007    -0.61056      0.109049     0.287971    0.213121      0.0823821    0.266287   -0.746       -0.23203      0.140548    -0.517362      0.616115   -0.0381647
  0.320903    0.0309564    0.143067     0.224956    0.247034    0.500925    0.289317    0.107861    0.361485   -0.00838718   -1.07445      0.588507    -0.050718     0.0237381    0.144174     0.0848028   -0.134761    0.000599689   0.173128    -0.417721   -0.168189     0.532564    -0.0718766    0.22611       0.173008   -0.141968
  0.0545866  -0.108458    -0.125692     0.0154697  -0.119422   -0.12321    -0.0106805  -0.024218   -0.0447765  -0.0155224     0.38167     -0.0869772    0.149565     0.0402834    0.0840677    0.0455765    0.126309    0.00327924    0.00818226   0.180839    0.00594783  -0.251042    -0.035758    -0.00300169   -0.0193836   0.0586807
  0.0639089  -1.13952      0.132905     0.350666   -0.255129    0.154105   -0.209793   -0.176082   -0.0107006   0.511178     -0.13698      0.597151    -0.428027     0.498111    -0.250173    -0.268172    -0.835972   -0.528172     -0.338937    -0.454917   -0.256036     0.305061    -0.187486     0.320538      0.295884    0.390109
  0.385397    0.181411     0.203045     0.224601    0.32571     0.0783925  -0.29474    -0.0577795   0.687611    0.298016     -0.543759    -0.538642     0.0240567    0.431903     0.229634    -0.0274814   -0.342098   -0.619911     -0.0236963   -0.452244    0.984627     0.468958     0.13323      0.541862     -0.50033     0.131462
 -0.0457369   0.742238     0.198538    -0.494531    1.01173     0.304153    0.32181     0.345378    0.362712   -0.766956     -0.00383595  -0.418426    -0.0120627   -0.406648    -0.556143     0.660394     0.519727   -0.0947405     0.104253    -0.353075    0.290625    -0.252547    -0.160476    -0.0937957    -0.463117    0.0964722
  0.0108161   0.226361     0.210656     0.0304826   0.200318   -0.0918098   0.140707   -0.0552318   0.222869   -0.0695635    -0.722294    -0.164597    -0.102245     0.0223578   -1.03578     -0.320164     0.0431353  -0.426119      0.463645    -0.137197    0.515977     0.712205     0.402022    -0.128431      0.0910621   0.0133601
 -0.607575   -0.281286     0.318532    -0.133111    0.712856    0.290023   -0.234146    0.196296    0.246163   -0.118028     -0.00145961  -0.00302015   0.0422714    0.00305365   0.44208      0.00249874  -0.552068    0.149505     -0.458026     1.07218     0.501804    -0.0273801   -0.552958    -0.426005     -0.425779   -0.144121
 -0.12234     0.152767     0.405549    -0.0655622   0.0564958  -0.0545539  -0.25377    -0.694124   -0.128252    0.117538      0.366228     0.10051      0.205669     0.0957208    0.0423852    0.810612    -0.105654   -0.033728      0.0120948    0.832601    0.225238    -0.0904989   -0.0309606   -0.0653641    -0.617226    0.808259
 -0.16631    -0.181205     0.0254884    0.0240629  -0.481362    0.0190243   0.162318    0.22244    -0.889273    0.911479     -0.292893    -0.449237    -0.00664468  -0.107852     0.661488     0.19726     -0.181287    0.297864     -0.38562      0.426851   -0.3754      -0.0118816    0.133362    -0.15688      -0.286933   -0.0424864
 -0.360701    0.927744     0.0827831    0.0647124   0.0633851   0.0190777   0.0594103   0.200208   -0.141813   -0.177523     -0.0151472   -0.627031     0.0884308   -0.548489     0.22876     -0.0392909    0.743338    0.531668     -0.0688009    0.623477    0.174845    -0.139584     0.531324    -0.43725      -0.25532    -0.501744
  0.401023   -0.0144774    0.106864    -0.362761   -0.272662   -0.963287   -0.508638   -0.174436    0.0749585  -0.56647       0.615428    -0.28338      0.0962504   -0.0769945    0.0848319    0.366779     0.463509    0.153847      0.324594     0.702299    0.220326    -0.374478    -0.295485    -0.441904      0.208601    0.146444
  0.582223    0.320346    -0.838365    -0.269793   -0.219108    0.625177   -0.333829   -0.184438    0.0651553  -0.271067      0.269118     0.423827    -0.18235     -0.634908     0.948529     0.882921    -0.295444   -0.0537701    -0.214551     0.565084    0.111866    -0.560362    -0.0411405    0.0320855     0.483991    0.118267
  0.0168558   0.00827037  -0.506318     0.109003   -0.207137   -0.418728    0.0986339  -0.983967   -0.48306     0.0701966     0.238845     0.084873     0.100865     0.00299341   0.275987     0.259865     0.645348    0.114192     -0.285197    -0.28108     0.449677     0.224689    -0.308228     0.297335      0.164008   -0.165793
 -0.214146   -0.19234     -0.410967     0.169935    0.505046    0.243653   -0.068102   -0.61534     0.62923    -0.854009      0.574761     0.231795     0.291299     0.184948    -0.371707    -0.243316     0.342927    0.129332      0.332312    -0.276752    0.766721    -0.0143933   -0.18856     -0.0981905     0.410632   -0.173956
  0.0187249   0.234818    -0.476734    -0.0355352  -0.980039   -0.140871    0.400219   -0.0629883  -0.149877    0.102685      0.00576893   0.0765789    0.256279    -0.422652    -0.117267    -0.0461711   -0.115174   -0.660909     -0.0198611   -0.0396701  -0.546219     0.161868     0.680053     0.81066      -0.340842    0.26021
 -0.206455    0.0944329   -0.413572     0.365956   -0.368404   -0.131921   -0.149537    0.196219    0.45853    -0.0771412     0.257597    -0.0475971    0.0780178   -0.265587     0.401286    -0.137381     0.0788998  -0.436624     -0.798577     0.248884    0.074759     0.435459     0.375127     0.224838      0.291744   -0.02402
 -0.271242   -0.358392    -0.123112     0.216491    0.529536    0.0575971   0.0712112   0.379169   -0.227449   -0.000108784  -0.0215081   -0.683924     0.45599     -0.320413    -0.283259     0.387144    -0.324147   -0.0273442     0.0785704   -0.15896    -0.00997572  -0.0645137    0.0764117    0.283743     -0.0169134   0.249244
 -0.134168   -0.109342    -0.18698      0.252789    0.18698     0.656102    0.551778    0.345459   -0.208429    0.405298     -0.0371678    0.467312     0.379214     0.0891219    0.0256733   -0.0773746   -0.269638    0.31417      -0.0363441   -0.137069   -0.417322     0.338093    -0.102575     0.1237        0.183407   -0.0532587
  0.153206   -0.529574    -0.240513    -0.0916537   0.184564   -0.29939     0.0545517   0.552185    0.237459   -0.250832     -0.201612     0.21078     -0.36395     -0.183027     0.140556    -0.175118     0.248735    0.0518735     0.0219296   -0.665499   -0.248181    -0.104348    -0.0884689   -0.000175227   0.459864   -0.46228
  0.348018    0.646602    -0.179046    -0.52079     0.0849075  -0.0194839   0.183785    0.0138665  -0.318077   -0.383413     -0.404477     0.401218    -0.716699    -0.0579855    0.552259    -0.183342     0.221861   -0.0753853    -0.267407    -0.230963   -0.404021    -0.00489863  -0.0592606   -0.331847     -0.407496   -0.298616
 -0.325347   -0.521662    -0.18472      0.225852    0.408509   -0.108053    0.148917    0.36113     0.322463   -0.139804     -0.266641     0.155086     0.696741     0.774706     0.00895108   0.250903     0.181863    0.403645     -0.373333    -0.174475   -0.35934      0.0513386    0.162677    -0.656175     -0.22816    -0.706625
  0.67041     0.722793     0.230492     0.349699    0.600821   -0.306089   -0.461195   -0.0639917   0.342721   -0.284345      0.069668     0.184833     0.48831      0.879522    -0.112313     0.076299     0.0712079   0.268766     -0.0828926   -0.183475   -0.127556    -0.328861    -0.176643    -0.154856      0.623327   -0.276831
  0.365461   -0.209568     0.243923    -0.469543   -0.0505885   0.0916936   0.0356921  -0.35816    -0.293217    0.269126     -0.267138     0.0296162   -0.443393     0.101559    -0.329604     0.222473    -0.228657   -0.034335      0.866171    -0.335082    0.488954    -0.20692     -0.4362       0.354967      0.0411159  -0.0563478
  0.354773    0.771081     0.545521    -0.151858   -0.333443    0.485519   -0.129437   -0.212085   -0.0727535  -0.152758     -0.0938751   -0.435344    -0.334871    -0.516581    -0.179643    -0.306839    -0.418656   -0.30362       0.431594     0.360171    0.403288     0.175564    -0.422292     0.416574      0.282977    0.710369
  0.237784   -0.203908     0.153059    -0.146821   -0.72805    -0.295808   -0.0488923  -0.335399    0.381811    0.369885      0.22314      0.636923    -0.229113     0.436709     0.394432    -0.45825      0.246496   -0.00106927    0.366842     0.193339    0.245838     0.220135    -0.185827    -0.198022      0.170782    0.00291769
  0.5375      0.0354033    0.327633     0.329617   -0.67639    -0.596977   -0.0900536   0.124982    0.138893    0.110848      0.1768      -0.195942     0.00891624   0.565337    -0.0970385   -0.0508445    0.419224   -0.125133      0.206232    -0.299024   -0.22912     -0.309654     0.563905    -0.0255046    -0.163729   -0.0286404
 -0.0775001   0.0390296   -0.00887769  -0.263061   -0.0501474  -0.229217   -0.162565   -0.0291403  -0.168201    0.0665201     0.122877    -0.214277    -0.0665591   -0.206158     0.116905     0.179284     0.109822    0.113923     -0.0426795    0.50393     0.084323    -0.203763     0.00890627  -0.105205     -0.172283    0.176237
  0.0307787   0.00746359   0.330477    -0.105018    0.0250537   0.335303    0.258331    0.415253    0.214016   -0.188397      0.0151937    0.0688552    0.125011     0.178169     0.0773181   -0.0566883   -0.0796398   0.0840776     0.369016     0.444058   -0.188815    -0.300824     0.0127976   -0.409229     -0.444741    0.0696239
  0.0259285  -0.255091    -0.00360391   0.185946   -0.0764852   0.0037426  -0.0226983   0.0296566  -0.0216014   0.16204      -0.113542    -0.0440233   -0.0322892    0.0908171    0.176173    -0.00440773  -0.0426346  -0.0867948    -0.12434     -0.172235   -0.0159499    0.0711529    0.0186508   -0.0189647    -0.0331602  -0.144442
  0.0569461   0.333604    -0.130426    -0.035904    0.042024   -0.0226669   0.0164757  -0.0951647   0.208182   -0.226718      0.0917514    0.0374707    0.123498    -0.0108839   -0.314798     0.0221259    0.120385    0.0744647     0.137576    -0.146191    0.199653     0.178893    -0.0146866    0.125387      0.227895    0.0813622[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409494
[ Info: iteration 2, average log likelihood -1.409484
[ Info: iteration 3, average log likelihood -1.409474
[ Info: iteration 4, average log likelihood -1.409464
[ Info: iteration 5, average log likelihood -1.409454
[ Info: iteration 6, average log likelihood -1.409444
[ Info: iteration 7, average log likelihood -1.409435
[ Info: iteration 8, average log likelihood -1.409426
[ Info: iteration 9, average log likelihood -1.409417
[ Info: iteration 10, average log likelihood -1.409409
┌ Info: EM with 100000 data points 10 iterations avll -1.409409
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.002782e+05
      1       7.098116e+05      -1.904666e+05 |       32
      2       6.924920e+05      -1.731955e+04 |       32
      3       6.865363e+05      -5.955782e+03 |       32
      4       6.835992e+05      -2.937064e+03 |       32
      5       6.818380e+05      -1.761183e+03 |       32
      6       6.806946e+05      -1.143366e+03 |       32
      7       6.797921e+05      -9.025423e+02 |       32
      8       6.790819e+05      -7.101869e+02 |       32
      9       6.784620e+05      -6.199647e+02 |       32
     10       6.779924e+05      -4.695409e+02 |       32
     11       6.776369e+05      -3.555217e+02 |       32
     12       6.773144e+05      -3.224756e+02 |       32
     13       6.770005e+05      -3.139070e+02 |       32
     14       6.767055e+05      -2.950189e+02 |       32
     15       6.764228e+05      -2.826996e+02 |       32
     16       6.761617e+05      -2.610509e+02 |       32
     17       6.759346e+05      -2.271902e+02 |       32
     18       6.757187e+05      -2.158352e+02 |       32
     19       6.755251e+05      -1.936243e+02 |       32
     20       6.753637e+05      -1.613474e+02 |       32
     21       6.752119e+05      -1.518889e+02 |       32
     22       6.750717e+05      -1.401405e+02 |       32
     23       6.749381e+05      -1.336486e+02 |       32
     24       6.748199e+05      -1.182003e+02 |       32
     25       6.747041e+05      -1.157263e+02 |       32
     26       6.746004e+05      -1.037803e+02 |       32
     27       6.745047e+05      -9.566625e+01 |       32
     28       6.744231e+05      -8.156034e+01 |       32
     29       6.743433e+05      -7.981693e+01 |       32
     30       6.742709e+05      -7.236861e+01 |       32
     31       6.742043e+05      -6.667611e+01 |       32
     32       6.741491e+05      -5.518124e+01 |       32
     33       6.740979e+05      -5.120869e+01 |       32
     34       6.740553e+05      -4.259658e+01 |       32
     35       6.740138e+05      -4.146401e+01 |       32
     36       6.739759e+05      -3.790817e+01 |       32
     37       6.739439e+05      -3.197280e+01 |       32
     38       6.739164e+05      -2.749142e+01 |       32
     39       6.738943e+05      -2.213958e+01 |       32
     40       6.738720e+05      -2.235247e+01 |       32
     41       6.738521e+05      -1.986515e+01 |       32
     42       6.738353e+05      -1.682272e+01 |       32
     43       6.738215e+05      -1.373570e+01 |       32
     44       6.738072e+05      -1.435053e+01 |       32
     45       6.737928e+05      -1.438713e+01 |       32
     46       6.737790e+05      -1.380133e+01 |       32
     47       6.737665e+05      -1.253138e+01 |       32
     48       6.737555e+05      -1.100143e+01 |       32
     49       6.737450e+05      -1.041779e+01 |       31
     50       6.737351e+05      -9.989597e+00 |       32
K-means terminated without convergence after 50 iterations (objv = 673735.0523586698)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421448
[ Info: iteration 2, average log likelihood -1.416412
[ Info: iteration 3, average log likelihood -1.415038
[ Info: iteration 4, average log likelihood -1.414027
[ Info: iteration 5, average log likelihood -1.412994
[ Info: iteration 6, average log likelihood -1.412044
[ Info: iteration 7, average log likelihood -1.411362
[ Info: iteration 8, average log likelihood -1.410957
[ Info: iteration 9, average log likelihood -1.410723
[ Info: iteration 10, average log likelihood -1.410574
[ Info: iteration 11, average log likelihood -1.410466
[ Info: iteration 12, average log likelihood -1.410381
[ Info: iteration 13, average log likelihood -1.410311
[ Info: iteration 14, average log likelihood -1.410249
[ Info: iteration 15, average log likelihood -1.410194
[ Info: iteration 16, average log likelihood -1.410145
[ Info: iteration 17, average log likelihood -1.410100
[ Info: iteration 18, average log likelihood -1.410058
[ Info: iteration 19, average log likelihood -1.410018
[ Info: iteration 20, average log likelihood -1.409982
[ Info: iteration 21, average log likelihood -1.409947
[ Info: iteration 22, average log likelihood -1.409914
[ Info: iteration 23, average log likelihood -1.409883
[ Info: iteration 24, average log likelihood -1.409853
[ Info: iteration 25, average log likelihood -1.409824
[ Info: iteration 26, average log likelihood -1.409797
[ Info: iteration 27, average log likelihood -1.409771
[ Info: iteration 28, average log likelihood -1.409746
[ Info: iteration 29, average log likelihood -1.409723
[ Info: iteration 30, average log likelihood -1.409700
[ Info: iteration 31, average log likelihood -1.409678
[ Info: iteration 32, average log likelihood -1.409657
[ Info: iteration 33, average log likelihood -1.409636
[ Info: iteration 34, average log likelihood -1.409617
[ Info: iteration 35, average log likelihood -1.409598
[ Info: iteration 36, average log likelihood -1.409580
[ Info: iteration 37, average log likelihood -1.409562
[ Info: iteration 38, average log likelihood -1.409545
[ Info: iteration 39, average log likelihood -1.409528
[ Info: iteration 40, average log likelihood -1.409512
[ Info: iteration 41, average log likelihood -1.409497
[ Info: iteration 42, average log likelihood -1.409482
[ Info: iteration 43, average log likelihood -1.409467
[ Info: iteration 44, average log likelihood -1.409453
[ Info: iteration 45, average log likelihood -1.409439
[ Info: iteration 46, average log likelihood -1.409426
[ Info: iteration 47, average log likelihood -1.409413
[ Info: iteration 48, average log likelihood -1.409400
[ Info: iteration 49, average log likelihood -1.409388
[ Info: iteration 50, average log likelihood -1.409377
┌ Info: EM with 100000 data points 50 iterations avll -1.409377
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.278214    0.120675     0.062262   -0.734454    -0.10636     0.112019     0.116906    0.00293456  -0.105069   -0.160603   -0.500999     0.166943   -0.875571    -0.492221    -0.17226    -0.306277    -0.0571135   -0.44462     0.296298   -0.0491884   0.125613     0.366129    -0.23401     -0.12206     0.244292     0.0271832
  0.574851    0.147511     0.142737   -0.187236     0.74454    -0.158269    -0.0205761   0.263438     0.289819   -0.171869   -0.614947     0.53277    -0.370902     0.347097     0.276837   -0.106309     0.269608     0.0679389   0.0513927  -0.799461   -0.34648      0.023615    -0.428731     0.0573354   0.118871    -0.63299
  0.090542   -0.217074     0.182148   -0.372078    -0.205543   -0.944978    -0.503635   -0.132602    -0.0494465  -0.201117    0.263173    -0.287626   -0.0697326   -0.0872555    0.0450846   0.21216      0.312281     0.208621    0.406626    0.567146    0.3466      -0.334945    -0.0996275   -0.331488   -0.00670403   0.0977659
  0.209928   -0.164777     0.516476   -0.0471001    0.101201   -0.156353    -0.375649    0.0370051   -0.505792    0.51249     0.41227     -0.0534522  -0.452204     1.10527     -0.659954   -0.920513    -0.638911    -0.197937   -0.31106    -0.0553545  -0.248628    -0.381173     0.259834    -0.0790612  -0.26309      0.00318414
 -0.124767   -0.00873586  -0.0247127   0.00901333  -0.396738    0.0531011    0.259138    0.20743     -0.959551    0.827618   -0.229838    -0.348506    0.0958127   -0.148995     0.720777    0.190225    -0.0266822    0.47171    -0.348126    0.44483    -0.503488    -0.119522     0.101737    -0.200467   -0.360909    -0.0360257
 -0.281352   -0.597597    -0.134136    0.0461432    0.501356    0.0137383    0.185245    0.596879    -0.264087   -0.0849001  -0.0716423   -0.651727    0.207997    -0.462682    -0.295874    0.264023    -0.321663    -0.114793    0.253025   -0.392949   -0.079114    -0.195727     0.0761818    0.168267   -0.0997114    0.218717
 -0.200586   -0.0964708   -0.268278    0.0935172    0.263658    0.338433     0.843926    0.255702    -0.310099    0.255032   -0.00710378   0.302234    0.479746     0.0864908   -0.427456   -0.0363558   -0.015123     0.531226    0.279414   -0.397458   -0.437131     0.627609    -0.0693942   -0.138059    0.280159    -0.210779
 -0.204845   -0.295993    -0.513156    0.227243     0.325884   -0.45545     -0.0850048   0.326556     0.0471003  -0.356475   -0.0123787    0.20489     0.286457     0.371364    -0.0607619   0.174294     0.203482     0.437235   -0.479642   -0.631627   -0.607278    -0.455574     0.282386    -0.166709    0.194337    -0.548472
  0.449264    0.257346    -0.785067   -0.324476    -0.104646    0.471355    -0.289313   -0.170457    -0.0406465  -0.35926     0.425817     0.454551   -0.0331925   -0.591987     0.66249     0.832705    -0.133199     0.0286128  -0.15948     0.548215    0.0937734   -0.594441    -0.158431    -0.0891643   0.521005     0.131018
 -0.550592   -0.214151     0.297258    0.0197622    0.818561    0.247743    -0.260705    0.107304     0.239206   -0.0651097  -0.0600744   -0.175211    0.119489     0.117316     0.506509    0.209572    -0.475035     0.300241   -0.623954    0.897806    0.633949     0.0108428   -0.455011    -0.442056   -0.428172    -0.139653
  0.115163    0.0376093    0.0838753   0.136731     0.115379    0.0113399   -0.118933   -0.0585566    0.169207    0.0266745  -0.00802893  -0.0609122   0.161162     0.110348    -0.350043    0.147038    -0.0505368    0.0815637   0.205144   -0.160906    0.266468     0.0620585   -0.0459401    0.152415    0.278255     0.0651509
 -0.262178   -0.0633823   -0.44365    -0.183791     0.022309    0.109679    -0.0365399   0.109419    -0.0913131  -0.040413    0.294766     0.374089    0.28493     -0.370511     0.0905986   0.141244    -0.167423    -0.103622   -0.327461    0.470092   -0.394213     0.0773407   -0.0603072    0.267279    0.227472     0.0872086
 -0.151581    0.0843187   -0.208949    0.0657445   -0.0467649   0.262995     0.197532    0.117872     0.148184    0.275447   -0.429564    -0.647617    0.180963    -0.0519826    0.447605   -0.161374    -0.346139    -0.432507   -0.256801   -0.502829    0.489979     0.883226     0.349549     0.697545   -0.24479     -0.515635
  0.0134498  -0.0123213    0.101616    0.97894      0.0865518   0.756224     0.250848   -0.25234      0.461196    0.118564   -0.99858      0.566356    0.37842      0.0447743   -0.0911867   0.160225    -0.00673372  -0.120582   -0.109075   -0.166104   -0.134841     0.715228    -0.0730118    0.515255    0.174727     0.280187
  0.0534295  -0.848658     0.0108016   0.503138    -0.751406    0.0250999   -0.547575   -0.158728     0.411777   -0.132815    1.07924      0.138487   -0.232627    -0.0247205   -0.202816   -0.337597     0.383039    -0.0949796  -0.102537    0.0523509  -0.0748297    0.119644    -0.200673     0.167997    0.407904     0.0246432
 -0.0285761  -0.145693     0.308612    0.225891     0.124201    0.415721     0.224044    0.541305     0.226004   -0.207068   -0.183998     0.084889    0.278643     0.371782     0.129913   -0.232561    -0.240323     0.16237     0.259506    0.382645   -0.357514    -0.30227      0.0743032   -0.577006   -0.334082    -0.217342
  0.589011   -0.0223779    0.110287   -0.174133    -0.708413   -0.270701     0.105415    0.0521129    0.621625    0.0340472  -0.0943302    0.689116    0.168149     0.481479     0.120135   -0.363065     0.291736     0.0767459   0.460194   -0.0935564   0.210288     0.175818     0.206449    -0.107412    0.329209    -0.373066
  0.641844    0.603952     0.229412   -0.160401    -0.453958    0.325363    -0.413406    0.126394    -0.595878   -0.327134   -0.489578     0.0695948  -0.756939     0.0767865    0.478809    0.256552    -1.42407     -0.285382    0.283049    0.193841   -0.337933     0.0130442    0.318888     0.206432   -0.190368     0.243828
  0.760145    0.82717      0.254609    0.109802     0.184083   -0.532972    -0.466127   -0.465373     0.19004    -0.495098    0.761361    -0.258605    0.427322     0.747572     0.0708349   0.450028     0.69078      0.0161551  -0.0569134   0.539362   -0.107797    -0.632462    -0.299216    -0.425981    0.142956    -0.175907
  0.112176   -0.0422231   -0.403995    0.0503699   -0.289103   -0.408509     0.0788716  -1.00922     -0.44827     0.113873    0.196532     0.196959   -0.00153656   0.0208342    0.30974     0.37576      0.640684     0.0259578  -0.155514   -0.259945    0.508994     0.206403    -0.354835     0.234522    0.0622331   -0.0577334
  0.624342    0.527351     0.427061    0.317139    -0.126701    0.104919    -0.237693   -0.375242     0.29915     0.163545   -0.21964     -0.622636   -0.283892     0.215024     0.205585   -0.247303    -0.058924     0.0108162   0.492251   -0.101262    1.16883     -0.00292741  -0.114592     0.266568   -0.101949     0.409651
 -0.270661    0.582835     0.158579    0.13156      0.0250681   0.0905227    0.0251388  -0.124201    -0.288012   -0.0896014   0.124997    -0.814375    0.454031    -0.52648     -0.403401    0.214141    -0.0500427   -0.0166306  -0.0608327   0.656131    0.231549     0.0764681    0.140452     0.0391301   0.0391638    0.432294
 -0.143824    0.33871     -0.227816    0.45311     -0.365149   -0.303204     0.0559771   0.210495     0.381419    0.0843405   0.208498    -0.2152      0.0820428    0.00443132   0.585068   -0.00227317   0.521044    -0.256734   -0.798801    0.324973   -0.0540327    0.207372     0.560802    -0.112947   -0.235544     0.152447
  0.44598     0.278418     0.0536335   0.0661056   -1.20796    -0.617094     0.125554    0.0666496   -0.20385     0.0512228   0.256211    -0.154249   -0.0121282   -0.0761052   -0.341917    0.0117155    0.388899    -0.675945    0.347905   -0.58356    -0.661801    -0.174587     0.60032      0.427754   -0.0848219    0.278702
 -0.148596   -0.148333     0.0278358  -0.1698      -0.0461044  -0.118934     0.0738634   0.0789582   -0.0304289  -0.0115935   0.0853451   -0.11555    -0.0328688   -0.0401801   -0.128123   -0.0764013    0.106171    -0.0180894   0.104906    0.0624893  -0.00661721  -0.0537254    0.0398219   -0.0981242  -0.0603149   -0.0497019
 -0.411508    0.311297     0.192838   -0.180956    -0.0348325   0.0885751   -0.162748    0.201101    -0.446874   -0.230387    0.025741    -0.254521   -0.666152    -0.47748     -0.132408   -0.458099     0.59573      0.485121    0.0420152   0.175483   -0.245229    -0.213959     0.569354    -0.388727    0.00430121  -0.813721
 -0.126858   -1.06432     -0.0245755   0.329282    -0.574438    0.00360115   0.0678433  -0.128087    -0.164499    0.704567   -0.300234     0.56551    -0.329985     0.294547     0.191727   -0.27025     -0.711844    -0.230145   -0.297722   -0.368739   -0.194406     0.216476    -0.10583      0.288398    0.379459     0.076093
 -0.104778    0.797073     0.103184   -0.447229     0.901194    0.270516     0.449551    0.368668     0.380547   -0.700611   -0.0619809   -0.442738   -0.00903632  -0.308728    -0.404865    0.507583     0.684522    -0.0208555   0.0987367  -0.259704    0.232377    -0.31177      0.0353077   -0.1677     -0.471876    -0.0244649
  0.488984   -0.0766603    0.107501    0.00842467   0.667842   -0.0853616   -0.445515    0.0343009    0.843819   -0.0399516  -0.381538    -0.0348531   0.0489753    0.398942    -0.614826    0.0445842   -0.599678    -1.05801     0.132065   -0.476501    0.632616     0.461508     0.13147      0.282103   -0.115866     0.607835
 -0.0899095  -0.0856372    0.497957   -0.459046    -0.0673748   0.301686     0.088908   -0.147951    -0.0364909   0.237016    0.184058     0.298388   -0.0377009    0.0498074   -0.0730236   0.444678    -0.103532     1.1838e-5   0.510412    0.598322   -0.0276819   -0.132714    -0.255031    -0.0731765  -0.615265     0.656305
  0.0502977   0.0381742   -0.0667085  -0.104694    -0.123583   -0.0796742    0.0601916   0.0266119   -0.0250623  -0.0176197  -0.0152766   -0.0527903  -0.12236     -0.0211668    0.23396    -0.00690617   0.144896    -0.0131935  -0.0435888   0.0330348  -0.00785423  -0.0361356    0.00998271  -0.0932485  -0.20021     -0.0325917
 -0.397208    0.0120344   -0.4345      0.174012     0.678391    0.233488     0.0376471  -0.695262     0.458984   -0.89649     0.462139     0.21954     0.227141     0.337292    -0.309755   -0.430438     0.341282     0.253896    0.286077   -0.376031    1.0154       0.0199085   -0.0267541   -0.213463    0.376268    -0.335684[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409366
[ Info: iteration 2, average log likelihood -1.409356
[ Info: iteration 3, average log likelihood -1.409346
[ Info: iteration 4, average log likelihood -1.409336
[ Info: iteration 5, average log likelihood -1.409327
[ Info: iteration 6, average log likelihood -1.409319
[ Info: iteration 7, average log likelihood -1.409310
[ Info: iteration 8, average log likelihood -1.409302
[ Info: iteration 9, average log likelihood -1.409295
[ Info: iteration 10, average log likelihood -1.409288
┌ Info: EM with 100000 data points 10 iterations avll -1.409288
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
