Julia Version 1.5.0-DEV.232
Commit f014071421 (2020-02-03 21:36 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed SortingAlgorithms ── v0.3.1
  Installed FillArrays ───────── v0.8.4
  Installed QuadGK ───────────── v2.3.1
  Installed BinDeps ──────────── v1.0.0
  Installed StatsFuns ────────── v0.9.3
  Installed HDF5 ─────────────── v0.12.5
  Installed StaticArrays ─────── v0.12.1
  Installed Arpack_jll ───────── v3.5.0+2
  Installed CMakeWrapper ─────── v0.2.3
  Installed Rmath ────────────── v0.6.0
  Installed CMake ────────────── v1.1.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed Missings ─────────── v0.4.3
  Installed SpecialFunctions ─── v0.9.0
  Installed Blosc ────────────── v0.5.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed LegacyStrings ────── v0.4.1
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsBase ────────── v0.32.0
  Installed Clustering ───────── v0.13.3
  Installed BinaryProvider ───── v0.5.8
  Installed FileIO ───────────── v1.2.1
  Installed Distributions ────── v0.22.4
  Installed PDMats ───────────── v0.9.11
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed URIParser ────────── v0.4.0
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed Compat ───────────── v2.2.0
#=#=#                                                                         ###############################################                           65.6%######################################################################## 100.0%
#=#=#                                                                                                                                                    0.4%##                                                                         4.0%#######                                                                    9.9%###########                                                               16.5%###################                                                       26.6%###########################                                               37.7%##################################                                        48.2%###############################################                           66.2%#############################################################             85.2%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_UFW2cS/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.758528048190625e7, [25690.828804281547, 74309.17119571845], [9194.858397035083 -1277.9453494456848 -1562.268068399598; -9797.259485991846 1242.6186905011173 1498.9042020196387], [[16114.233162720075 -5240.67457114548 -10592.034764651007; -5240.67457114548 22638.094135785603 -5190.739545607562; -10592.034764651007 -5190.739545607562 14611.59923554658], [84300.21335181544 4440.255777288258 10854.545181350737; 4440.255777288258 76848.67109865659 5553.441630593046; 10854.545181350737 5553.441630593046 86377.69487792019]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.377899e+03
      1       9.070246e+02      -4.708743e+02 |        7
      2       8.315965e+02      -7.542809e+01 |        3
      3       8.078919e+02      -2.370461e+01 |        0
      4       8.078919e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 807.8918590158628)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.046262
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.770547
[ Info: iteration 2, lowerbound -3.653990
[ Info: iteration 3, lowerbound -3.534158
[ Info: iteration 4, lowerbound -3.405658
[ Info: iteration 5, lowerbound -3.276939
[ Info: iteration 6, lowerbound -3.154378
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.039668
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.935511
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.843121
[ Info: iteration 10, lowerbound -2.783466
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.748357
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.719980
[ Info: iteration 13, lowerbound -2.691019
[ Info: iteration 14, lowerbound -2.659901
[ Info: iteration 15, lowerbound -2.623131
[ Info: iteration 16, lowerbound -2.581990
[ Info: iteration 17, lowerbound -2.538607
[ Info: iteration 18, lowerbound -2.495540
[ Info: iteration 19, lowerbound -2.454967
[ Info: iteration 20, lowerbound -2.417882
[ Info: iteration 21, lowerbound -2.384054
[ Info: iteration 22, lowerbound -2.353209
[ Info: iteration 23, lowerbound -2.327180
[ Info: iteration 24, lowerbound -2.310784
[ Info: iteration 25, lowerbound -2.308005
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302916
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Feb  4 05:07:47 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Feb  4 05:07:56 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Feb  4 05:07:59 2020: EM with 272 data points 0 iterations avll -2.046262
5.8 data points per parameter
, Tue Feb  4 05:08:01 2020: GMM converted to Variational GMM
, Tue Feb  4 05:08:10 2020: iteration 1, lowerbound -3.770547
, Tue Feb  4 05:08:10 2020: iteration 2, lowerbound -3.653990
, Tue Feb  4 05:08:10 2020: iteration 3, lowerbound -3.534158
, Tue Feb  4 05:08:10 2020: iteration 4, lowerbound -3.405658
, Tue Feb  4 05:08:10 2020: iteration 5, lowerbound -3.276939
, Tue Feb  4 05:08:10 2020: iteration 6, lowerbound -3.154378
, Tue Feb  4 05:08:10 2020: dropping number of Gaussions to 7
, Tue Feb  4 05:08:10 2020: iteration 7, lowerbound -3.039668
, Tue Feb  4 05:08:10 2020: dropping number of Gaussions to 6
, Tue Feb  4 05:08:10 2020: iteration 8, lowerbound -2.935511
, Tue Feb  4 05:08:10 2020: dropping number of Gaussions to 5
, Tue Feb  4 05:08:10 2020: iteration 9, lowerbound -2.843121
, Tue Feb  4 05:08:11 2020: iteration 10, lowerbound -2.783466
, Tue Feb  4 05:08:11 2020: dropping number of Gaussions to 4
, Tue Feb  4 05:08:11 2020: iteration 11, lowerbound -2.748357
, Tue Feb  4 05:08:11 2020: dropping number of Gaussions to 3
, Tue Feb  4 05:08:11 2020: iteration 12, lowerbound -2.719980
, Tue Feb  4 05:08:11 2020: iteration 13, lowerbound -2.691019
, Tue Feb  4 05:08:11 2020: iteration 14, lowerbound -2.659901
, Tue Feb  4 05:08:11 2020: iteration 15, lowerbound -2.623131
, Tue Feb  4 05:08:11 2020: iteration 16, lowerbound -2.581990
, Tue Feb  4 05:08:11 2020: iteration 17, lowerbound -2.538607
, Tue Feb  4 05:08:11 2020: iteration 18, lowerbound -2.495540
, Tue Feb  4 05:08:11 2020: iteration 19, lowerbound -2.454967
, Tue Feb  4 05:08:11 2020: iteration 20, lowerbound -2.417882
, Tue Feb  4 05:08:11 2020: iteration 21, lowerbound -2.384054
, Tue Feb  4 05:08:11 2020: iteration 22, lowerbound -2.353209
, Tue Feb  4 05:08:11 2020: iteration 23, lowerbound -2.327180
, Tue Feb  4 05:08:11 2020: iteration 24, lowerbound -2.310784
, Tue Feb  4 05:08:11 2020: iteration 25, lowerbound -2.308005
, Tue Feb  4 05:08:11 2020: dropping number of Gaussions to 2
, Tue Feb  4 05:08:11 2020: iteration 26, lowerbound -2.302916
, Tue Feb  4 05:08:11 2020: iteration 27, lowerbound -2.299259
, Tue Feb  4 05:08:11 2020: iteration 28, lowerbound -2.299256
, Tue Feb  4 05:08:11 2020: iteration 29, lowerbound -2.299254
, Tue Feb  4 05:08:11 2020: iteration 30, lowerbound -2.299254
, Tue Feb  4 05:08:11 2020: iteration 31, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 32, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 33, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 34, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 35, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 36, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 37, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 38, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 39, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 40, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 41, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 42, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 43, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 44, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 45, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 46, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 47, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 48, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 49, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: iteration 50, lowerbound -2.299253
, Tue Feb  4 05:08:11 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777392698, 178.04509222607317]
β = [95.95490777392698, 178.04509222607317]
m = [2.0002292577748713 53.85198717245867; 4.250300733269428 79.28686694435473]
ν = [97.95490777392698, 180.04509222607317]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611956681 -0.008953123827356203; 0.0 0.012748664777411739], [0.18404155547478057 -0.007644049042333621; 0.0 0.00858170516632435]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9701359629769448
avll from llpg:  -0.9701359629769444
avll direct:     -0.9701359629769445
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9765642793598371
avll from llpg:  -0.9765642793598371
avll direct:     -0.9765642793598371
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.100878      0.125446     -0.11831      0.148174     0.0937497    -0.154991      0.00837875  -0.159601    -0.0480104   -0.0130205     0.0128031   -0.134249     -0.0139047   -0.0590601   -0.0288756    0.210196     0.078948     0.101989     0.0654679   -0.0261824   -0.00271094  -0.067502     0.0892875    -0.0470763    0.0781655   -0.0805895
 -0.134094     -0.196823     -0.0371741    0.0313886   -0.0285606     0.0272756     0.0346746    0.133812    -0.11381     -0.00620322    0.0252245    0.0162458     0.0464755   -0.213479    -0.0485963    0.0816574   -0.00705307  -0.0446334    0.0720482    0.0331408   -0.0301942   -0.0749572   -0.13411       0.0612974   -0.241283     0.0331863
  0.0128385     0.000133313  -0.117214     0.165773    -0.105851      0.139205      0.0237362    0.189578    -0.0421479   -0.0630586     0.00165457   0.0220165    -0.076748    -0.0519544    0.106258    -0.0653423   -0.092632     0.0721132   -0.0365509   -0.0403728   -0.0352307    0.0420694    0.129377     -0.111899    -0.0436447   -0.0040941
  0.0936224     0.0333989     0.0535754    0.0403436    0.165427     -0.0710656    -0.0972041    0.0529842    0.069791    -0.0360151    -0.162264     0.0540749     0.166485    -0.0614102   -0.0957457    0.00177007   0.038358     0.0733941    0.0835596    0.0863377   -0.0184973    0.107644     0.041112     -0.112661     0.0525352   -0.184008
  0.0806695     0.185823      0.124885     0.083286     0.0559479    -0.0933819    -0.0452778   -0.00659854  -0.127138     0.0248548    -0.0389107   -0.0764374     0.130813     0.0229157   -0.13931     -0.0491252   -0.101544    -0.188747    -0.0742408    0.0205262   -0.127845     0.0823709   -0.187903      0.105538     0.0673042   -0.028435
 -0.19          0.263066     -0.220074    -0.164092    -0.0868334    -0.241827     -0.0111791    0.118001     0.00943306  -0.0433598    -0.0173199   -0.0739564     0.00387206  -0.14935     -0.0446845   -0.0450123   -0.0838639   -0.0236853    0.0116436   -0.071923     0.0330004    0.116927    -0.0347913    -0.147503     0.190779    -0.00124536
 -0.0705894    -0.0814251     0.00430874  -0.0070346    0.0506123     0.0439216     0.191768     0.0750871    0.0594925    0.0692644     0.0467548    0.00701019    0.094108     0.0531253    0.0352313    0.106248    -0.0779413    0.138112     0.01706      0.0842947   -0.094294     0.146564     0.132642     -0.129582     0.111897    -0.021871
 -0.0429606    -0.264046      0.195365     0.0783915   -0.111255      0.0428624    -0.0920128   -0.161218     0.217072     0.123984     -0.0358451   -0.0619054    -0.329123     0.120334    -0.0988455   -0.0547326    0.0475821   -0.0677161    0.0230119    0.149456    -0.259        0.176484    -0.019057     -0.0711472   -0.103607     0.0962649
  0.0856791     0.0736016    -0.0173882   -0.101496     0.00692344   -0.0756602    -0.0614913    0.0259904   -0.144545    -0.000518278  -0.17942      0.0212032     0.0155075    0.0639751   -0.00184835  -0.039035     0.0712642   -0.0280362    0.0497615   -0.0323441   -0.00280408  -0.0105208   -0.0560165     0.157048     0.209557    -0.0364992
  0.0228152     0.0214836    -0.0122128    0.0933846    0.0700504     0.0890584    -0.0749643   -0.0433748   -0.132012    -0.148083      0.120349     0.0206942     0.00569744   0.0974694   -0.0754998   -0.0744703   -0.077559    -0.0371193   -0.0629546   -0.161387     0.0446102    0.0253776   -0.00750529   -0.00256482  -0.112367     0.0243803
  0.207967      0.155311     -0.13352     -0.0313934   -0.0545271     0.108431     -0.0364799    0.11625     -0.101999    -0.0181999     0.178393     0.143839      0.216275     0.0714776   -0.124034    -0.0251375    0.0306156   -0.0227955   -0.0927866   -0.019469    -0.11352      0.119154     0.0225629    -0.0162652   -0.131279    -0.0459131
  0.0884082     0.0324209     0.104588    -0.0617631    0.0587509     0.0307885     0.110163     0.192028    -0.0331891   -0.0172614     0.110792     0.114413     -0.0207077    0.00804293  -0.0225819    0.206448     0.0661704    0.157345     0.0183743   -0.0137787    0.157318     0.0664403   -0.000495725  -0.0595817    0.13776     -0.031447
 -0.0601796     0.0515922     0.116956    -0.134089    -0.084576      0.0106624     0.0333008    0.112143    -0.141412    -0.0265678     0.128014     0.0517372    -0.0595728   -0.0839244   -0.0664228   -0.00831801   0.0927433    0.0032882   -0.00765637   0.0511337   -0.107889    -0.02758      0.110869     -0.0672056   -0.053263    -0.0149904
 -0.0449924    -0.012319     -0.0524223    0.0860124   -0.00765633   -0.0397256    -0.044532    -0.165311    -0.0809856   -0.0370102    -0.0227707    0.0263834     0.0844066    0.0606427    0.0386983   -0.131322     0.0314403    0.00951471   0.142307    -0.146696    -0.0414306    0.152429     0.00827869    0.0211228   -0.0228372    0.126997
 -0.0577286    -0.00177412   -0.0663499   -0.0172005    0.17989      -0.00506473    0.21632     -0.191493    -0.0249854   -0.104892      0.170969     0.0728622    -0.0888728   -0.0542496    0.0556777    0.0610501   -0.0165547    0.00129015  -0.0739806    0.137229    -0.196805     0.071871    -0.0142629     0.0207503   -0.0508426    0.198781
  0.0460938     0.180001      0.00251093   0.0648366    0.168385     -0.0670299     0.0481415   -0.0626766   -0.038123     0.0297664    -0.038799     0.107643      0.117184     0.0116461   -0.10552      0.0602871   -0.0364465    0.0956469   -0.125095    -0.037265     0.0787288   -0.152891    -0.0535383    -0.0803077    0.0353581    0.146516
  0.0800164    -0.030807     -0.0431022    0.0827289    0.000159589  -0.0835597     0.0207181   -0.0497455    0.0878116    0.0958083    -0.0243642   -0.207257     -0.084437    -0.0175775   -0.110379    -0.070259    -0.0709039    0.0877908    0.182158     0.049297     0.0662542    0.197177     0.0783388     0.119801     0.069611     0.297576
  0.087304     -0.0879642    -0.0562851   -0.0336385   -0.178394     -0.0270337    -0.0456995   -0.0285894   -0.0162201    0.0351197     0.0530287    0.0539041     0.0285582    0.0821803   -0.116923     0.079294     0.0913745   -0.107378     0.0453737    0.0188687   -0.125773    -0.0157422    0.0556102     0.00241267  -0.060993    -0.072631
 -0.0628416    -0.116822     -0.0821675   -0.0291639    0.0179433     0.0247586    -0.212752     0.0557008   -0.0683384    0.0143937     0.0432186   -0.0591937     0.153111    -0.0112779    0.116819     0.0711789   -0.0623195   -0.0232764    0.0617259    0.0183754    0.123152    -0.0289948   -0.0754514     0.0350953    0.163254    -0.0281128
 -0.150321     -0.0290488    -0.102469     0.0112503   -0.178903     -0.127636     -0.0703229   -0.0416755   -0.0589096    0.0276034    -0.0260192   -0.0288841    -0.0302196   -0.0450846   -0.143178     0.0559255    0.315771     0.12434     -0.0715999    0.0545831    0.124639    -0.0279792   -0.132923     -0.0510016    0.00788525   0.0703805
 -0.108771      0.0689834     0.246664    -0.0698387   -0.140277      0.00467846    0.0971135   -0.0979438    0.129793     0.0415367     0.161225    -0.105573      0.0203624   -0.0682945    0.0698099    0.0903501   -0.0469939   -0.0261953   -0.277275    -0.181448    -0.0455081    0.0745821    0.00400642   -0.13616      0.00979269  -0.116182
 -0.0272749     0.172195      0.0537836    0.0258386   -0.237746      0.000481594   0.049914    -0.174551    -0.126606    -0.029009     -0.0630632    0.0161876     0.00834101  -0.0934877   -0.0449227   -0.0463142   -0.111413    -0.0223093   -0.0330104    0.0743928    0.0600699   -0.11115      0.0745954     0.00846773   0.022699     0.113465
  0.147239      0.0561085    -0.0199471   -0.0850058    0.111571     -0.0789171    -0.352031    -0.149775     0.110585    -0.0438665     0.189141     0.129165      0.10736      0.0974836   -0.0651908   -0.0849241   -0.079963    -0.0829589   -0.0575612    0.00216751  -0.0923023    0.0248209   -0.0386408    -0.0636709   -0.0258231    0.114419
 -0.0649475     0.0937654     0.117091    -0.00107047  -0.0574669     0.204547     -0.110056    -0.0369461    0.0224504    0.137603     -0.00750459  -0.0983272    -0.0889444    0.121621     0.070495    -0.0185279    0.100255    -0.0950185   -0.0743732    0.0154036    0.00536789   0.0426006   -0.0380652    -0.0369579    0.0338154   -0.154868
  0.022258     -0.132217     -0.0314126   -0.00107943   0.153311      0.050306      0.0268451    0.0403565    0.155126    -0.0626351    -0.206431     0.00733599   -0.00340132   0.0218511    0.012241     0.0337077   -0.0996919   -0.163141    -0.00541122  -0.0631511    0.0182651    0.256099     0.00283339   -0.047114     0.186815     0.110417
  0.151497      0.0961253    -0.0139129    0.0397742    0.0318878     0.10888       0.0846994   -0.089501    -0.102317     0.0312094    -0.0592057    0.151973     -0.0862922   -0.0556939   -0.0271291    0.00621456  -0.127026    -0.0564767    0.199486    -0.0138179   -0.00493021  -0.00398392   0.122734     -0.120296     0.0297386   -0.0714106
  0.142834     -0.0291285    -0.0603929   -0.157681     0.13613      -0.0128576    -0.0473399   -0.0193192    0.0146183   -0.078365     -0.0403873   -0.00193762    0.0618211   -0.0451866    0.0591172   -0.0351016   -0.13571      0.0598749    0.0434055    0.00449818   0.0689032   -0.00983829   0.0893588     0.139605     0.13203     -0.029603
 -0.000633611   0.0400605     0.0186734   -0.0622312    0.0709633    -0.215012      0.0677272   -0.0557377   -0.00904932   0.0843997     0.0223078   -0.0698239    -0.0258311   -0.191004    -0.0462808   -0.0011376    0.179079    -0.0539592   -0.0595593    0.0751808    0.00127227  -0.0447094   -0.0835102     0.051048     0.0287569   -0.0412959
  0.0845422     0.0665686    -0.0553193   -0.0314894   -0.0356807    -0.012389      0.18962      0.0635694    0.0565893    0.0593077    -0.0093781   -0.000337611   0.0432562   -0.217982     0.0816962   -0.0591319    0.206811     0.111727     0.215206     0.064737    -0.0512415   -0.0122451   -0.0214772    -0.194128    -0.00256375   0.095444
  0.0280498     0.0229595    -0.0658086    0.0625638    0.0283644    -0.0753571     0.00586517  -0.188572     0.0148662   -0.0146514    -0.0274293    0.209538     -0.0543125    0.00764672   0.0367018    0.123235    -0.194626    -0.0173184    0.113631     0.241959    -0.0127217    0.036427    -0.102599     -0.0894452   -0.167078     0.0801915
 -0.000702716  -0.278026     -0.00106025  -0.0284212    0.0305364     0.119678     -0.0217419    0.134597     0.0445553    0.0758877     0.131206    -0.144491      0.0291499   -0.193327     0.247314    -0.0794443    0.0284269    0.15098      0.18498      0.115932    -0.110977    -0.118619    -0.125968      0.030037     0.106307     0.0485858
 -0.114527      0.0117525    -0.0752075    0.0683541   -0.0172299    -0.00753862   -0.12397     -0.0101734    0.0405588   -0.0441846     0.0567866   -0.157614     -0.151682     0.0515397    0.0582034    0.019226     0.173321     0.0434188    0.0302183   -0.151451     0.0664023   -0.090423    -0.118041     -0.11569      0.0178876   -0.127976kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3804749313903515
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.380539
[ Info: iteration 2, average log likelihood -1.380454
[ Info: iteration 3, average log likelihood -1.379462
[ Info: iteration 4, average log likelihood -1.370785
[ Info: iteration 5, average log likelihood -1.355211
[ Info: iteration 6, average log likelihood -1.350086
[ Info: iteration 7, average log likelihood -1.348529
[ Info: iteration 8, average log likelihood -1.347551
[ Info: iteration 9, average log likelihood -1.346797
[ Info: iteration 10, average log likelihood -1.346053
[ Info: iteration 11, average log likelihood -1.345211
[ Info: iteration 12, average log likelihood -1.344184
[ Info: iteration 13, average log likelihood -1.343003
[ Info: iteration 14, average log likelihood -1.341962
[ Info: iteration 15, average log likelihood -1.341211
[ Info: iteration 16, average log likelihood -1.340688
[ Info: iteration 17, average log likelihood -1.340342
[ Info: iteration 18, average log likelihood -1.340124
[ Info: iteration 19, average log likelihood -1.339993
[ Info: iteration 20, average log likelihood -1.339913
[ Info: iteration 21, average log likelihood -1.339862
[ Info: iteration 22, average log likelihood -1.339829
[ Info: iteration 23, average log likelihood -1.339807
[ Info: iteration 24, average log likelihood -1.339791
[ Info: iteration 25, average log likelihood -1.339779
[ Info: iteration 26, average log likelihood -1.339769
[ Info: iteration 27, average log likelihood -1.339762
[ Info: iteration 28, average log likelihood -1.339756
[ Info: iteration 29, average log likelihood -1.339751
[ Info: iteration 30, average log likelihood -1.339747
[ Info: iteration 31, average log likelihood -1.339744
[ Info: iteration 32, average log likelihood -1.339741
[ Info: iteration 33, average log likelihood -1.339739
[ Info: iteration 34, average log likelihood -1.339737
[ Info: iteration 35, average log likelihood -1.339735
[ Info: iteration 36, average log likelihood -1.339733
[ Info: iteration 37, average log likelihood -1.339732
[ Info: iteration 38, average log likelihood -1.339731
[ Info: iteration 39, average log likelihood -1.339730
[ Info: iteration 40, average log likelihood -1.339729
[ Info: iteration 41, average log likelihood -1.339729
[ Info: iteration 42, average log likelihood -1.339728
[ Info: iteration 43, average log likelihood -1.339727
[ Info: iteration 44, average log likelihood -1.339727
[ Info: iteration 45, average log likelihood -1.339727
[ Info: iteration 46, average log likelihood -1.339726
[ Info: iteration 47, average log likelihood -1.339726
[ Info: iteration 48, average log likelihood -1.339726
[ Info: iteration 49, average log likelihood -1.339725
[ Info: iteration 50, average log likelihood -1.339725
┌ Info: EM with 100000 data points 50 iterations avll -1.339725
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.380539267623878
│     -1.380453770924326
│      ⋮
└     -1.3397252099447252
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339809
[ Info: iteration 2, average log likelihood -1.339706
[ Info: iteration 3, average log likelihood -1.339000
[ Info: iteration 4, average log likelihood -1.333067
[ Info: iteration 5, average log likelihood -1.318144
[ Info: iteration 6, average log likelihood -1.308480
[ Info: iteration 7, average log likelihood -1.304806
[ Info: iteration 8, average log likelihood -1.302627
[ Info: iteration 9, average log likelihood -1.300936
[ Info: iteration 10, average log likelihood -1.299592
[ Info: iteration 11, average log likelihood -1.298505
[ Info: iteration 12, average log likelihood -1.297574
[ Info: iteration 13, average log likelihood -1.296689
[ Info: iteration 14, average log likelihood -1.295711
[ Info: iteration 15, average log likelihood -1.294508
[ Info: iteration 16, average log likelihood -1.293117
[ Info: iteration 17, average log likelihood -1.291697
[ Info: iteration 18, average log likelihood -1.290504
[ Info: iteration 19, average log likelihood -1.289755
[ Info: iteration 20, average log likelihood -1.289341
[ Info: iteration 21, average log likelihood -1.289104
[ Info: iteration 22, average log likelihood -1.288965
[ Info: iteration 23, average log likelihood -1.288883
[ Info: iteration 24, average log likelihood -1.288833
[ Info: iteration 25, average log likelihood -1.288801
[ Info: iteration 26, average log likelihood -1.288780
[ Info: iteration 27, average log likelihood -1.288767
[ Info: iteration 28, average log likelihood -1.288758
[ Info: iteration 29, average log likelihood -1.288752
[ Info: iteration 30, average log likelihood -1.288747
[ Info: iteration 31, average log likelihood -1.288744
[ Info: iteration 32, average log likelihood -1.288741
[ Info: iteration 33, average log likelihood -1.288739
[ Info: iteration 34, average log likelihood -1.288738
[ Info: iteration 35, average log likelihood -1.288736
[ Info: iteration 36, average log likelihood -1.288735
[ Info: iteration 37, average log likelihood -1.288734
[ Info: iteration 38, average log likelihood -1.288734
[ Info: iteration 39, average log likelihood -1.288733
[ Info: iteration 40, average log likelihood -1.288732
[ Info: iteration 41, average log likelihood -1.288732
[ Info: iteration 42, average log likelihood -1.288731
[ Info: iteration 43, average log likelihood -1.288731
[ Info: iteration 44, average log likelihood -1.288730
[ Info: iteration 45, average log likelihood -1.288730
[ Info: iteration 46, average log likelihood -1.288730
[ Info: iteration 47, average log likelihood -1.288730
[ Info: iteration 48, average log likelihood -1.288729
[ Info: iteration 49, average log likelihood -1.288729
[ Info: iteration 50, average log likelihood -1.288729
┌ Info: EM with 100000 data points 50 iterations avll -1.288729
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3398087882744887
│     -1.3397064866036148
│      ⋮
└     -1.2887287082175853
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.288857
[ Info: iteration 2, average log likelihood -1.288721
[ Info: iteration 3, average log likelihood -1.288075
[ Info: iteration 4, average log likelihood -1.281639
[ Info: iteration 5, average log likelihood -1.262094
[ Info: iteration 6, average log likelihood -1.247397
[ Info: iteration 7, average log likelihood -1.239902
[ Info: iteration 8, average log likelihood -1.235264
[ Info: iteration 9, average log likelihood -1.232228
[ Info: iteration 10, average log likelihood -1.229928
[ Info: iteration 11, average log likelihood -1.228141
[ Info: iteration 12, average log likelihood -1.226948
[ Info: iteration 13, average log likelihood -1.226261
[ Info: iteration 14, average log likelihood -1.225848
[ Info: iteration 15, average log likelihood -1.225574
[ Info: iteration 16, average log likelihood -1.225377
[ Info: iteration 17, average log likelihood -1.225230
[ Info: iteration 18, average log likelihood -1.225119
[ Info: iteration 19, average log likelihood -1.225034
[ Info: iteration 20, average log likelihood -1.224966
[ Info: iteration 21, average log likelihood -1.224910
[ Info: iteration 22, average log likelihood -1.224863
[ Info: iteration 23, average log likelihood -1.224821
[ Info: iteration 24, average log likelihood -1.224783
[ Info: iteration 25, average log likelihood -1.224747
[ Info: iteration 26, average log likelihood -1.224713
[ Info: iteration 27, average log likelihood -1.224681
[ Info: iteration 28, average log likelihood -1.224649
[ Info: iteration 29, average log likelihood -1.224616
[ Info: iteration 30, average log likelihood -1.224583
[ Info: iteration 31, average log likelihood -1.224546
[ Info: iteration 32, average log likelihood -1.224506
[ Info: iteration 33, average log likelihood -1.224463
[ Info: iteration 34, average log likelihood -1.224416
[ Info: iteration 35, average log likelihood -1.224368
[ Info: iteration 36, average log likelihood -1.224314
[ Info: iteration 37, average log likelihood -1.224256
[ Info: iteration 38, average log likelihood -1.224191
[ Info: iteration 39, average log likelihood -1.224124
[ Info: iteration 40, average log likelihood -1.224059
[ Info: iteration 41, average log likelihood -1.224003
[ Info: iteration 42, average log likelihood -1.223958
[ Info: iteration 43, average log likelihood -1.223923
[ Info: iteration 44, average log likelihood -1.223898
[ Info: iteration 45, average log likelihood -1.223880
[ Info: iteration 46, average log likelihood -1.223867
[ Info: iteration 47, average log likelihood -1.223858
[ Info: iteration 48, average log likelihood -1.223851
[ Info: iteration 49, average log likelihood -1.223846
[ Info: iteration 50, average log likelihood -1.223842
┌ Info: EM with 100000 data points 50 iterations avll -1.223842
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2888571189995053
│     -1.2887211064847255
│      ⋮
└     -1.2238415191795817
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.224010
[ Info: iteration 2, average log likelihood -1.223791
[ Info: iteration 3, average log likelihood -1.221974
[ Info: iteration 4, average log likelihood -1.203191
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.161884
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.151957
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.142157
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.144676
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.136777
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.139864
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.132154
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.136341
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.129836
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.134015
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.137763
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.137785
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.130758
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.135360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.129423
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.133784
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.127727
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.131834
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.136801
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.136931
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.130416
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.134745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.128964
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.122900
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.132902
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136095
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.137518
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.129861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.135326
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.128413
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.133813
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.126713
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.142396
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.131265
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.136049
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.129129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.134609
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.127603
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.132919
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.136170
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.137521
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.129879
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.135326
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.128413
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.133809
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.126713
┌ Info: EM with 100000 data points 50 iterations avll -1.126713
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2240103131921853
│     -1.2237913325754517
│      ⋮
└     -1.1267125437784915
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.142601
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.123306
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.134213
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.100893
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072473
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│     14
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.046945
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038419
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.039419
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.027562
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026449
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.039989
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.029884
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      7
│     13
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.015168
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.030114
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.031986
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.022854
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.027419
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.023193
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.029165
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│      ⋮
│     16
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.029170
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.030067
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│     11
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.015902
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.034778
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│      ⋮
│     16
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.022932
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.027964
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.022967
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.029461
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028895
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.029747
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.015762
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.026461
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│     14
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.036081
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.024885
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│     11
│      ⋮
│     16
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.013742
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.041736
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│     14
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.026291
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.021067
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     16
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.019940
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.036517
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.023750
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.028059
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.022802
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.029116
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│     14
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.029035
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.021921
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│     11
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.020804
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.036234
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│     11
│     12
│     13
│      ⋮
│     16
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.023800
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.027981
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.022973
┌ Info: EM with 100000 data points 50 iterations avll -1.022973
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1426011957809077
│     -1.123306106921402
│      ⋮
└     -1.02297253957948
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3804749313903515
│     -1.380539267623878
│     -1.380453770924326
│     -1.3794619097059686
│      ⋮
│     -1.023800148858003
│     -1.0279808862251434
└     -1.02297253957948
32×26 Array{Float64,2}:
 -0.118949    -0.185008    -0.035045      0.0847794    -0.0175967    0.0277096    0.0294424    0.125675    -0.106479    -0.0197852    0.0321605    0.00281502   0.047242   -0.214043     -0.0475023    0.079711    -0.0199638  -0.0336218    0.072209     0.0275343    0.0160367    -0.046418    -0.138684      0.108678    -0.265082     0.0520659
 -0.065357     0.120589    -0.119446      0.151725      0.0981229   -0.162685    -0.00796699  -0.177769    -0.0421631   -0.0241785    0.0157374   -0.115025     0.0112685  -0.0603243    -0.028802     0.210395     0.0814136   0.102218     0.0656316    0.00435909  -0.00904725   -0.00747113   0.0924348    -0.0454624    0.0657825   -0.0807701
  0.0167722    0.0419443    0.0201226    -0.0663923     0.0736224   -0.197939     0.0746149   -0.0540063   -0.0318963    0.0494239    0.023465    -0.0735271   -0.0181546  -0.194201     -0.0485125   -0.0364283    0.182136   -0.0432177   -0.0598722    0.0836925   -0.00619429   -0.0638316   -0.0938891     0.0505838    0.0546735   -0.0423848
 -0.0573805   -0.00262819  -0.0601473    -0.00972534    0.171813    -0.00949981   0.205607    -0.187883    -0.0390869   -0.082534     0.154707     0.0591813   -0.0982285  -0.0595589     0.0505702    0.0691152   -0.0149903  -0.0201183   -0.066105     0.130182    -0.202193      0.0819266   -0.0228217     0.00760301  -0.0627755    0.202106
 -0.201521     0.270056    -0.221317     -0.15934      -0.123906    -0.252471    -0.00577906   0.125332     0.00859119  -0.0605938   -0.0132513   -0.0715111   -0.0238754  -0.140162     -0.0324306   -0.064254    -0.0872449  -0.0138858    0.030169    -0.0730466    0.0409836     0.113334    -0.0470336    -0.156362     0.194711    -0.00296696
 -0.142868    -0.0418239   -0.102437     -0.047258     -0.1509      -0.125986    -0.0603797   -0.022238    -0.0572782    0.0336336   -0.0370307   -0.0313801   -0.0191286  -0.0437554    -0.142458     0.0497449    0.315589    0.126229    -0.0724445    0.0544789    0.124444     -0.0108304   -0.137378     -0.0463993    0.0238306    0.0763614
  0.00574941   0.0263412   -0.0675878     0.0620167     0.0624637   -0.0713237   -0.0330978   -0.182678     0.0120375   -0.0224058   -0.017533     0.206712     0.0225069   0.000611945   0.0315756    0.152406    -0.190719    0.0028611    0.0887556    0.241234    -0.011366      0.0361326   -0.0874013    -0.0910497   -0.165234     0.0330743
  0.0683906    0.1628       0.130297      0.0786658     0.033366    -0.0791381   -0.0322565   -0.00552773  -0.116297     0.0213094   -0.0377068   -0.0777592    0.128061    0.0501959    -0.133325    -0.0503315   -0.0914847  -0.179386    -0.0712279    0.0188559   -0.130042      0.086428    -0.183714      0.107872     0.0674944   -0.026786
 -0.0636166   -0.115486    -0.0168767     0.0205961     0.00405947   0.0521431   -0.207562    -0.00477553  -0.0199369   -0.185964     0.0392812   -0.0412119    0.174462   -0.00293476    0.0291674    0.0685502   -0.0686993  -0.0180886    0.111878    -0.021763     0.119955     -0.03706      0.0188346     0.0400873    0.187815    -0.291205
 -0.0631948   -0.117953    -0.109212     -0.0277971     0.0284474   -0.010342    -0.223225     0.110617    -0.122953     0.0634948    0.0517463   -0.0703452    0.147631   -0.0328522     0.149965     0.0721437   -0.0490657  -0.053876     0.0401732    0.0703298    0.124467     -0.0240805   -0.176131      0.0386807    0.145798     0.289184
 -0.0226431    0.0463308   -0.0428403     0.0856733    -0.0741591   -0.0511178   -0.080415    -0.195716    -0.0801774   -0.0442945   -0.0126633    0.0262672    0.105387    0.0132367     0.0356187   -0.130647     0.0293825   0.0140527    0.141115    -0.0696328   -0.0420726     0.184717     0.00816732    1.38147     -0.0847762    0.121948
 -0.0376715   -0.0393289   -0.0904172     0.0882328     0.0407232   -0.0312951   -0.0386902   -0.112089    -0.0808181   -0.0495663   -0.0354613    0.0265681    0.0963811   0.0719526     0.0383011   -0.13107      0.0223897   0.00646737   0.143433    -0.198345    -0.0415794     0.137447     0.000709571  -1.23915     -0.0649314    0.128618
  0.23617      0.0302807    0.0941407    -0.013454      0.163172    -0.176363     0.0697066    0.0517904   -0.0412449   -0.0427518   -0.140833     0.023375     0.192569   -0.213076     -0.095951     0.09755      0.0490516   0.121408     0.080907    -0.110787    -0.00924457    0.108671     0.177542     -0.342724     0.0527133   -0.10823
 -0.0551198    0.0313784   -0.0429659     0.111232      0.17199     -0.00152627  -0.198248     0.0530025    0.189117    -0.0247205   -0.160362     0.0956732    0.148171    0.0567494    -0.0956867   -0.0691542    0.041973    0.0219894    0.088885     0.240544    -0.0184594     0.108235    -0.107978      0.176065     0.0526018   -0.225123
 -1.52727      0.0403688    0.0972773    -0.0442983     0.053892     0.0503906    0.103284     0.383666    -0.0343483   -0.0972287    0.149993     0.116994    -0.0114772   0.00715303   -0.0203298    0.209225     0.0625958   0.152195     0.0184862   -0.0193473    0.166485      0.0469241    0.0269781    -0.0569146   -0.00494523  -0.0513789
  1.61488      0.0255737    0.100653     -0.0867855     0.0697227    0.0132428    0.097961    -0.0308376   -0.0339235    0.0346936    0.117752     0.118873    -0.0102506   0.0203335    -0.0267823    0.212858     0.0629971   0.157422     0.0181151   -0.0105139    0.151159      0.0674609   -0.0346373    -0.0595346    0.211072    -0.0341253
 -0.0352343    0.146409     0.0521207     0.0278239    -0.234449    -0.00336954   0.0505072   -0.166579    -0.129265    -0.0672509   -0.0656069    0.00376654  -0.010042   -0.13729      -0.106988    -0.0916654   -0.163104   -0.0173509   -0.0548483    0.0825236   -0.0412877    -0.104586     0.059151      0.0169399    0.0253156    0.111013
  0.0754793    0.0539253   -0.113943     -0.0325745    -0.06425     -0.0127344    0.192025     0.0630031    0.0839227    0.0584594   -0.0117871   -0.0331906    0.0299206  -0.213577      0.0772509   -0.0499486    0.223468    0.109892     0.208366     0.0658156   -0.0361645    -0.00189694  -0.0110289    -0.201614    -0.00152139   0.101367
  0.0811576    0.0382153   -0.0243584    -0.000939328   0.0907581    0.0875228    0.0535833   -0.0407401   -0.00530174  -0.00177871  -0.120587     0.0853683   -0.0535006  -0.0266204     0.00885506   0.0424899   -0.114876   -0.100989     0.0936922   -0.0241525    0.0143487     0.101362     0.0712797    -0.125411     0.101514     0.0012538
 -0.0676252   -0.0520384    0.00358638    0.0042783     0.0604601    0.0235435    0.190049     0.0793328    0.0634724    0.0614906    0.0409333    0.00917374   0.119118    0.068613      0.0345737    0.0913886   -0.0678377   0.138811    -0.0161592    0.0996005   -0.0529818     0.150092     0.0237293    -0.123631     0.113102    -0.0574538
  0.119178    -0.0483368   -0.0474784    -0.0515026     0.100345    -0.040879    -0.0074029   -0.0325345    0.0442755   -0.0145898   -0.0491763   -0.0769206   -0.0331341  -0.0268685    -0.0213697   -0.0423138   -0.104061    0.0701126    0.110877     0.0148339    0.0592516     0.100413     0.0834661     0.128929     0.122928     0.131073
 -0.0463036    0.0481501    0.117743      0.00375674   -0.0344818    0.0362473    0.017073    -0.0570608    0.0259221   -0.0460325    0.133871    -0.0352877    0.0546148  -0.0109904     0.00448309   0.00428772  -0.0443351  -0.0165491   -0.171434    -0.166509    -0.00146047    0.0173044    0.0262485    -0.0782046   -0.0643286   -0.0417991
  0.175988     0.107628    -0.0823492    -0.0606389     0.0243515    0.00983128  -0.175933     0.00111265   0.0179412   -0.0348883    0.192902     0.143178     0.166473    0.0692051    -0.0971758   -0.0400594    0.025275   -0.0481607   -0.0675534   -0.0184109   -0.12018       0.0744218   -0.00677515   -0.0264382   -0.069646     0.00847753
  0.0869802    0.0765532   -0.000293006  -0.129255     -0.00419624  -0.0909889   -0.0485709   -0.0118754   -0.170725    -0.00472347  -0.164205     0.00960092   0.0149671  -0.0430744    -0.00450595  -0.0301922    0.0776734  -0.0358858    0.0126259   -0.0322516   -0.000721021   0.0102793   -0.0487866     0.189732     0.206529    -0.0478017
 -0.0401373   -0.350041     0.203583      0.0634646    -0.113336     0.0479893   -0.093537    -0.154177     0.220657     0.140116    -0.0138289   -0.0601592   -0.317905    0.138534     -0.0831789   -0.0428727    0.0495735  -0.0785173    0.00635099   0.164271    -0.258826      0.168751    -0.0268119    -0.0705084   -0.11868      0.10642
 -0.00129166  -0.034197    -0.148565      0.163293     -0.122311     0.131482     0.0108288    0.194803    -0.0412729   -0.0629375    0.00164535   0.0233405   -0.0786131  -0.0438922     0.101815    -0.0625697   -0.0904014   0.0646117   -0.0195762   -0.0612879   -0.0220004     0.0301272    0.134203     -0.111119    -0.0545521    4.55532e-5
  0.043695     0.181791    -0.0240191     0.0519907     0.139848    -0.0699579    0.0515271   -0.0548424   -0.0423304    0.0206633   -0.0359242    0.10916      0.112827    0.0130323    -0.0847899    0.0235594   -0.020786    0.078917    -0.117953    -0.0303004    0.0552762    -0.148313    -0.0423844    -0.0793538    0.0287334    0.139177
 -0.0465966    0.0342475    0.114291     -0.11869      -0.108577     0.0325824    0.0376712    0.117035    -0.156782    -0.0247798    0.171553     0.0633161   -0.0684916  -0.0980634    -0.0723421    0.00365224   0.0865421   0.0353603    0.00602904   0.0621793   -0.109897     -0.0172671    0.149875     -0.0674069   -0.0629826   -0.0251483
 -0.0212356   -0.0550269   -0.0978669     0.0194492    -0.112381    -0.00822194  -0.0784588   -0.012773     0.0273002    0.00118473   0.0491958   -0.0397123   -0.0727927   0.0654808    -0.0174088    0.0346934    0.138603   -0.0263506    0.0356591   -0.0821514   -0.0236307    -0.0413308   -0.0362229    -0.0451855   -0.0067575   -0.126931
 -0.0452929    0.0905773    0.112186      0.000545746  -0.0664931    0.188652    -0.173931    -0.0344734    0.0373974    0.162201     0.0117637   -0.078452    -0.0723644   0.122342      0.0648742   -0.0369202    0.0847638  -0.0993271   -0.0767491    0.0181128   -0.0104426     0.0423016   -0.0529373    -0.0153858    0.00649592  -0.142425
 -0.0576432   -0.296265    -0.694486     -0.105008     -0.0246985    0.153043    -0.0722413    0.124057     0.044994     0.194298     0.0281599   -0.0728334    0.0305954  -0.193449      0.150682    -0.0338088    0.0457939   0.046531     0.182092     0.198177    -0.0375306    -0.117207    -0.127381      0.0703345    0.211809    -0.126267
  0.049916    -0.263606     0.56612       0.0258744     0.111442     0.0850639    0.00251509   0.208705     0.0432738    0.164019     0.267133    -0.167933     0.0274727  -0.193583      0.288744    -0.176649     0.0181286   0.15138      0.187318     0.0825824   -0.212164     -0.112984    -0.155073     -0.0134055    0.0121237    0.178547[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.029560
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      4
│      7
│     11
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.006791
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.022882
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.999651
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.029450
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      4
│      7
│     11
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007733
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.022857
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.999643
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     25
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.029449
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      4
│      7
│     11
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.007732
┌ Info: EM with 100000 data points 10 iterations avll -1.007732
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.182293e+05
      1       6.438703e+05      -1.743590e+05 |       32
      2       6.152091e+05      -2.866119e+04 |       32
      3       6.001047e+05      -1.510446e+04 |       32
      4       5.900308e+05      -1.007383e+04 |       32
      5       5.826561e+05      -7.374774e+03 |       32
      6       5.774056e+05      -5.250472e+03 |       32
      7       5.740467e+05      -3.358936e+03 |       32
      8       5.725533e+05      -1.493376e+03 |       32
      9       5.718757e+05      -6.775777e+02 |       32
     10       5.715435e+05      -3.321881e+02 |       32
     11       5.713105e+05      -2.329801e+02 |       32
     12       5.711153e+05      -1.951947e+02 |       32
     13       5.709552e+05      -1.600991e+02 |       32
     14       5.707895e+05      -1.657719e+02 |       32
     15       5.706293e+05      -1.601531e+02 |       32
     16       5.704225e+05      -2.068666e+02 |       32
     17       5.701937e+05      -2.287065e+02 |       32
     18       5.699364e+05      -2.573807e+02 |       32
     19       5.696823e+05      -2.540230e+02 |       32
     20       5.694612e+05      -2.211637e+02 |       32
     21       5.693281e+05      -1.330664e+02 |       32
     22       5.692408e+05      -8.726904e+01 |       32
     23       5.691888e+05      -5.202690e+01 |       32
     24       5.691514e+05      -3.740184e+01 |       32
     25       5.691216e+05      -2.978350e+01 |       31
     26       5.690957e+05      -2.595897e+01 |       32
     27       5.690731e+05      -2.261386e+01 |       31
     28       5.690558e+05      -1.727467e+01 |       32
     29       5.690390e+05      -1.681690e+01 |       29
     30       5.690236e+05      -1.539084e+01 |       28
     31       5.690061e+05      -1.751255e+01 |       29
     32       5.689859e+05      -2.012586e+01 |       29
     33       5.689624e+05      -2.357110e+01 |       29
     34       5.689405e+05      -2.188346e+01 |       30
     35       5.689132e+05      -2.731153e+01 |       32
     36       5.688833e+05      -2.983313e+01 |       29
     37       5.688584e+05      -2.489011e+01 |       32
     38       5.688411e+05      -1.735416e+01 |       29
     39       5.688273e+05      -1.383063e+01 |       31
     40       5.688153e+05      -1.199545e+01 |       30
     41       5.688046e+05      -1.067737e+01 |       29
     42       5.687924e+05      -1.220342e+01 |       28
     43       5.687836e+05      -8.806636e+00 |       30
     44       5.687717e+05      -1.190431e+01 |       28
     45       5.687541e+05      -1.754365e+01 |       32
     46       5.687304e+05      -2.375460e+01 |       31
     47       5.687036e+05      -2.682088e+01 |       30
     48       5.686732e+05      -3.032478e+01 |       30
     49       5.686347e+05      -3.857956e+01 |       31
     50       5.685877e+05      -4.696541e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 568587.6881004965)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.287918
[ Info: iteration 2, average log likelihood -1.253851
[ Info: iteration 3, average log likelihood -1.213013
[ Info: iteration 4, average log likelihood -1.161012
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.108959
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.071595
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.073648
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     18
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.044673
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058458
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     20
│     21
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.035702
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.058703
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.033288
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.037054
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     19
│     20
│     21
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.012137
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.058983
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.019795
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.034867
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.020617
[ Info: iteration 19, average log likelihood -1.085586
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.024047
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     11
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.020152
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     20
│     21
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.011800
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.077008
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.056204
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.015832
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     10
│     11
│     13
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.963755
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.098170
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.054063
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.028814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     18
│     20
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.018099
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073213
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.019745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.028255
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│     11
│     18
│     20
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.987948
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.072673
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.053350
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.010990
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│     11
│     19
│     20
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.990049
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.080330
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052652
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.006056
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      5
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.988788
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.103315
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.038895
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.017932
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     10
│     11
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.985973
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.062558
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.030502
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     10
│     14
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.999984
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.033666
┌ Info: EM with 100000 data points 50 iterations avll -1.033666
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.204912      0.156842    -0.138389     -0.042819    -0.0544012   0.100721    -0.0265574    0.119061    -0.0922152   -0.0216957    0.193296      0.147994     0.220484     0.0478216   -0.125103     0.00593849   0.0297792   -0.0268369  -0.0835361   -0.0137383   -0.112589      0.118094      0.0222273    -0.00971553  -0.104263    -0.0687571
 -0.0880901     0.0678545   -0.059236      0.0564576   -0.0234303   0.058844    -0.0966623    0.0238397    0.0484153   -0.0392533   -0.000185583  -0.0569689   -0.139568     0.0358709    0.0719722    0.0250217    0.133943     0.0538564   0.0375732   -0.178157     0.0575639    -0.0107524    -0.169682     -0.0791613    0.131899     0.0224465
 -0.138639     -0.194596    -0.0416438     0.0710209    0.0045562   0.0249047    0.0321605    0.110034    -0.116966    -0.0185566    0.0290402     0.00554272   0.0534115   -0.20729     -0.0417916    0.0842912   -0.0165461   -0.0506035   0.0651209    0.0276223    0.0189768    -0.0795557    -0.16719       0.121192    -0.315686     0.0561743
  0.0253333     0.00919751   0.000457171   0.0530403    0.0951052   0.045174    -0.0708105   -0.00294861  -0.138252    -0.128309     0.102464      0.0419227    0.0791098    0.106217    -0.0928883   -0.119578    -0.084844    -0.0382619  -0.0300093   -0.259083     0.0340705    -0.0067459     0.0215122     0.00580065  -0.0724183    0.0612606
 -0.0435563    -0.344975     0.193545      0.0746891   -0.10643     0.0426856   -0.0918005   -0.14745      0.211082     0.138601    -0.0150596    -0.0565544   -0.305902     0.129932    -0.0706598   -0.0460274    0.048675    -0.0822062   0.0107423    0.155321    -0.251504      0.165474     -0.0204269    -0.0715123   -0.146824     0.104703
 -0.0242795     0.0203566   -0.0161763    -0.0373343    0.123813   -0.0999725    0.136121    -0.115108    -0.0424315   -0.0235367    0.0916845    -0.00186115  -0.0592162   -0.129394     0.00610596   0.0215469    0.0910381   -0.0385906  -0.0645573    0.107696    -0.103012     -0.00505065   -0.0743072     0.0306736   -0.0110129    0.0701636
 -0.0684811    -0.0493601    0.00365632    0.00663418   0.063505    0.0228252    0.189808     0.0802658    0.0642118    0.0627589    0.0418229     0.00889803   0.119984     0.0677293    0.0329171    0.0905032   -0.0688138    0.139716   -0.021813     0.104034    -0.0515555     0.146528      0.0248725    -0.124858     0.111908    -0.0624813
  0.0864549     0.0750013   -0.00153357   -0.121837     0.0027806  -0.0852822   -0.0446846   -0.00913318  -0.161444    -0.00509206  -0.16389       0.0122395    0.0163071   -0.0413169   -0.00814866  -0.0309399    0.0771531   -0.0301439   0.0140166   -0.0319578    0.000406521   0.0106925    -0.0487052     0.190195     0.201297    -0.0550023
 -0.0637179    -0.116851    -0.0654107    -0.00388212   0.0143165   0.0202814   -0.215569     0.0543544   -0.0733137   -0.0591436    0.0455514    -0.0562103    0.159559    -0.0171128    0.0897918    0.0698567   -0.0578129   -0.0367002   0.0747152    0.0252298    0.122247     -0.0296461    -0.0837087     0.0398601    0.165106     0.00387227
 -0.0356731     0.0387481   -0.0754898     0.0560526    0.0862683  -0.0632614   -0.00711448  -0.174313     0.00132788  -0.0252676   -0.0160456     0.18128     -0.0276651    0.0196847    0.0459149    0.177788    -0.188138     0.0275223   0.0562548    0.264659    -0.000445711   0.0110328    -0.0872938    -0.0789955   -0.13842      0.0732314
 -0.0679061     0.121062    -0.119279      0.151166     0.100426   -0.162081    -0.00910068  -0.176929    -0.0422294   -0.0236387    0.0156077    -0.114706     0.00907245  -0.0594854   -0.0287763    0.212559     0.0813515    0.102051    0.0655417    0.00299778  -0.00909871   -0.00702664    0.0927197    -0.0456414    0.0659754   -0.0808738
  0.113158      0.167604    -0.0206438     0.023341     0.0298503   0.0923707    0.0641466   -0.0926818   -0.131394     0.036466    -0.0625268     0.152472    -0.0688642   -0.0733661   -0.0207834    0.0338395   -0.133514    -0.0540006   0.18601     -0.00331084   0.0197267    -0.0156546     0.118729     -0.155756     0.0285184   -0.0685196
 -0.0433099     0.0568156    0.112962     -0.0999402   -0.0816553   0.0151031    0.0401982    0.088258    -0.137039    -0.0197824    0.136435      0.0764367   -0.047255    -0.0798196   -0.0794921    0.00615554   0.0772853    0.0338883  -0.0142296    0.0441767   -0.107594     -0.0432568     0.124955     -0.0710618   -0.0519261   -0.000938658
  0.0372994     0.194444    -0.0614805     0.0673254    0.176153   -0.0512543    0.0395454   -0.0535017   -0.0412276    0.0106182   -0.0454713     0.0981238    0.103017     0.00967263  -0.128959     0.016358     0.00393077   0.110644   -0.0977468   -0.0590612    0.0844612    -0.17007      -0.0268112    -0.0760227    0.0398897    0.156666
  0.0944473    -0.0501487   -0.0438959     0.0877786    0.013659   -0.0899259    0.021488    -0.0728931    0.0798591    0.0538248   -0.020101     -0.196664    -0.143664    -0.0285659   -0.105758    -0.0626058   -0.0669483    0.103315    0.176898     0.0520852    0.0595836     0.219513      0.0791993     0.115329     0.0902521    0.297503
 -0.200451      0.271168    -0.22108      -0.156569    -0.121997   -0.255884    -0.00385656   0.123182     0.00855903  -0.0626177   -0.0130084    -0.0697434   -0.0213816   -0.138871    -0.0320597   -0.065911    -0.0862929   -0.0146256   0.0278979   -0.0739334    0.0392445     0.112679     -0.0487724    -0.154741     0.1928      -0.00279602
  0.138482     -0.0375698   -0.0688049    -0.156433     0.164526    0.00266711  -0.0233492   -0.00421542  -0.0196309   -0.0525015   -0.049556      0.00103599   0.0691213   -0.0533376    0.0512784   -0.0337732   -0.127309     0.0868968   0.0462634   -0.0212292    0.0483821    -0.000925432   0.0935695     0.13993      0.136617    -0.0157827
  0.0869463    -0.0827566   -0.0952664    -0.0385093   -0.191202   -0.026514    -0.0317374   -0.0285921   -0.00122231   0.0338615    0.051498      0.0623345    0.0354898    0.0843174   -0.11156      0.0613942    0.0819882   -0.107048    0.0305779    0.0103237   -0.117897      0.000222601   0.0522994    -0.00473239  -0.052126    -0.130215
  0.121588      0.0250561    0.01404       0.0555537    0.166316   -0.0775625   -0.07165      0.0102007    0.0958702   -0.0348766   -0.147672      0.0812877    0.227826    -0.133541    -0.0754444    0.0124785    0.0149537    0.0829971   0.0667229    0.213678    -0.00430208    0.0935917     0.0656953    -0.104823     0.0191733   -0.223238
 -0.1078        0.0820279    0.234772     -0.0457493   -0.137292   -0.00604446   0.0953906   -0.0984171    0.146003     0.0393278    0.159347     -0.0851296    0.050381    -0.0657256    0.0734188    0.0922852   -0.0168469   -0.0046618  -0.267369    -0.156175    -0.0360802     0.0433252     0.0452816    -0.136359    -0.0537046   -0.111001
  0.0342005     0.0186193    0.0161274     0.00769547   0.0253847  -0.00290628   0.0266051    0.0104223   -0.0568293   -0.0379841    0.0558609     0.0738112    0.0441187    0.0288614    0.0048705    0.0438338    0.0465868    0.082435    0.0778097   -0.0780589    0.0598573     0.107516     -0.000147826  -0.0349687    0.0145453    0.040865
  0.0510957    -0.109363    -0.030636     -0.0269108    0.164708    0.0611162    0.033759     0.025729     0.151758    -0.0670673   -0.192965      0.00875277  -0.0159499    0.0255929    0.0368374    0.0313291   -0.0998958   -0.159154   -0.00041808  -0.050172     0.00763332    0.235209      0.00668736   -0.0705412    0.180145     0.100757
 -0.0532993     0.099127     0.126095      0.0103901   -0.0670515   0.204533    -0.190282    -0.0348802    0.0447573    0.176673     0.0170253    -0.0847295   -0.0875509    0.12296      0.0729071   -0.0416407    0.0889284   -0.0964658  -0.076542     0.01847     -0.00128624    0.0448401    -0.0628626    -0.0234826    0.010914    -0.123388
  0.0747095     0.050793    -0.115669     -0.0323539   -0.0664184  -0.0127101    0.193572     0.0647873    0.0862199    0.060906    -0.0139999    -0.0360234    0.0274508   -0.215829     0.0790088   -0.0501981    0.224524     0.109953    0.210119     0.0668381   -0.0378205    -0.00323623   -0.0110625    -0.203029    -0.00205133   0.101315
  0.147302      0.0516359   -0.0201444    -0.0841511    0.110333   -0.0788228   -0.335006    -0.119013     0.136182    -0.0466591    0.192968      0.141744     0.10307      0.0930464   -0.0649795   -0.0849619    0.0149541   -0.0682126  -0.0615294   -0.0270553   -0.112215      0.0311393    -0.0393984    -0.0459701   -0.0285329    0.0964486
  0.0685208     0.166826     0.124433      0.080454     0.0417965  -0.0854752   -0.0240575   -0.00724959  -0.111045     0.0213709   -0.0387532    -0.0631798    0.128111     0.0471122   -0.137221    -0.0394449   -0.0849452   -0.154657   -0.0723572    0.0259951   -0.1107        0.0706648    -0.177146      0.0911073    0.0646556   -0.0183263
 -0.142691     -0.040743    -0.102593     -0.0497047   -0.151637   -0.125906    -0.0607102   -0.0219891   -0.0571301    0.0333557   -0.0376251    -0.0311434   -0.020211    -0.0444398   -0.142329     0.0496289    0.316005     0.125912   -0.0732164    0.0545056    0.124486     -0.0113476    -0.137363     -0.045816     0.0215547    0.0745703
 -0.0364439     0.144852     0.0538469     0.0261342   -0.236391   -0.00363965   0.0518508   -0.167011    -0.128997    -0.0671349   -0.0638629     0.00273012  -0.00929247  -0.140046    -0.0967059   -0.0889949   -0.159219    -0.0167104  -0.0579382    0.0810454   -0.0374369    -0.102921      0.0604254     0.0132868    0.0250905    0.111173
  0.0125214    -0.032648    -0.147437      0.172923    -0.111355    0.12444      0.00925531   0.190165    -0.0468744   -0.0702212   -0.00190004    0.0304288   -0.0721189   -0.0530316    0.0926596   -0.0535581   -0.0787233    0.077519   -0.0341214   -0.0529165   -0.0131459     0.016973      0.138776     -0.109518    -0.04311      0.00383655
 -0.000195947  -0.277699    -0.0343708    -0.0358858    0.0474115   0.115682    -0.0325726    0.169491     0.0441099    0.178357     0.153151     -0.121366     0.0288712   -0.193196     0.222628    -0.107241     0.0306133    0.0999862   0.183813     0.137316    -0.127953     -0.11454      -0.141086      0.0257336    0.108479     0.0331138
 -0.0968816     0.00512018  -0.0841663     0.0648104   -0.0386075  -0.0156822   -0.116184    -0.00928369   0.0805375   -0.0340344    0.0441023    -0.127605    -0.112625     0.0557174    0.0675832    0.0198758    0.166072     0.0561388   0.0405653   -0.188337     0.0413737    -0.0578841    -0.1461       -0.103659     0.0760851   -0.207082
 -0.029771      0.106633     0.00260364   -0.0323234    0.108038    0.0542085    0.0449595    0.0888634   -0.0333688   -0.0164246    0.0227315     0.221566    -0.0184056   -0.102654    -0.0347878    0.152374    -0.00484226   0.055654    0.0497244    0.00162608   0.108367      0.0480777    -0.0718563    -0.0713247    0.133825     0.0477905[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.045493
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     14
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.986092
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│     11
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.976543
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     10
│     14
│     18
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.001624
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.015545
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.959038
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.027782
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     18
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.974638
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│     14
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.984887
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     18
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.014910
┌ Info: EM with 100000 data points 10 iterations avll -1.014910
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.107346     0.0800772   -0.0273879     0.113049    -0.0124638   -0.030342    -0.0583978    0.134085    -0.0608688    0.0920329   -0.0386146   -0.087045     0.0737629    0.0964773    -0.225834     -0.0623917    -0.0335118   -0.0360771    0.112518     0.0051408    -0.0263596   -0.106677    -0.093953    -0.0898436    0.0723969    -0.0131025
  0.198682     0.132855     0.0753084    -0.0193507   -0.0658711    0.0358273    0.0197147    0.203329     0.00685157  -0.0841604   -0.0754135   -0.0638774   -0.12733      0.0186454    -0.00838958    0.00914733    0.195973    -0.0264781   -0.0115957   -0.00351038    0.150329     0.01159     -0.0669635   -0.0266927    0.100729      0.120833
  0.133703    -0.0860054    0.146095     -0.0691915    0.0212599    0.0415206    0.00288285   0.0303841   -0.169993     0.0393807   -0.0300465    0.072423     0.185806     0.0556269     0.0813162     0.0299337    -0.191994    -0.0508857    0.146523     0.0181141    -0.103323    -0.160103     0.0338471    0.0126805    0.0920373     0.0351112
  0.181802    -0.0373674   -0.00046713    0.00935775   0.0754471    0.0224137   -0.00127723   0.038225     0.0246006   -0.144196    -0.0590534   -0.0109267    0.118973     0.0282575    -0.140527      0.0161314    -0.119786    -0.301544    -0.0913705   -0.000436631   0.0619821    0.158679    -0.0750629   -0.0389129    0.0908636     0.0845407
 -0.0241666    0.075817     0.0809119     0.0423996    0.0010512   -0.0786662    0.0162967    0.107341     0.0544283    0.0514581    0.0813894   -0.117763    -0.0213514    0.0573916     0.117209     -0.0110546     0.0831052    0.0777072   -0.191668    -0.00815207    0.066251    -0.133876     0.0284109    0.122424    -0.196704      0.00198811
 -0.014674    -0.129447     0.0828332    -0.0565386    0.0910896   -0.0904632    0.0604871    0.0743229    0.089701    -0.121388     0.110997    -0.122778    -0.0480338   -0.0500244    -0.0629865    -0.0557781    -0.16075      0.212545    -0.0458475    0.110275     -0.00671276   0.152108     0.146941     0.169422    -0.0327499     0.143639
 -0.108157    -0.0289703    0.136413      0.038644    -0.0782544   -0.194283    -0.10015      0.0892626    0.00791288   0.155236    -0.0600679    0.0301523    0.099983    -0.0430023    -0.121934      0.0482463    -0.0695503    0.101226    -0.067755    -0.118309     -0.0341838    0.0345341    0.0876669    0.315701    -0.0285249     0.0531753
 -0.0361841    0.00829761   0.0267118     0.099288    -0.146848     0.110013     0.0553114    0.133032     0.014499    -0.115701     0.116093    -0.089094     0.0125037   -0.207965      0.0788817    -0.0226327     0.0816008   -0.022023    -0.118069     0.0167291     0.097919     0.122155    -0.0225091    0.0396025    0.259894      0.0648809
  0.067206     0.0762268    0.0997054     0.0812661    0.122022     0.00480606  -0.0630717    0.0328572    0.0425613   -0.0437282   -0.0709145   -0.0691063    0.124646    -0.065197     -0.192727      0.0880362     0.0449779    0.14161      0.0968874   -0.111879     -0.0587672    0.00318724  -0.0172781    0.0978334    0.121825      0.100751
  0.0518141    0.0406293   -0.0921393    -0.0842769   -0.0838854    0.0838254   -0.196093    -0.179972    -0.195597    -0.108754    -0.0138277   -0.14651      0.0914112    0.103835     -0.149387      0.00468055    0.181035    -0.0120757   -0.0210103    0.0263195     0.0137543   -0.0306648   -0.116737     0.0205039    0.0524616    -0.0456749
 -0.0810345    0.332756     0.0149004     0.195351     0.187121    -0.0557375    0.0946014    0.057655     0.0397097   -0.0374218   -0.0691477   -0.0791822   -0.0881644    0.000158816  -0.0108917     0.176866     -0.137041    -0.00350578  -0.155185    -0.0553148    -0.109318     0.0464958   -0.104545     0.0670189    0.00623059   -0.0334616
 -0.0176794    0.073848    -0.00511589    0.0629355   -0.135494    -0.139047    -0.0993171    0.0920034    0.0960108    0.0371501   -0.0217936   -0.0841271   -0.0838822    0.0951917    -0.0716306    -0.0560318     0.131305     0.0165868   -0.0824093    0.00624269    0.0681404   -0.129676     0.00206608   0.113398     0.0221305    -0.101721
  0.132436     0.0462877    0.0567872     0.0863228   -0.251927    -0.0635828   -0.178856    -0.0956909    0.0907426   -0.0441811    0.063094    -0.0241781   -0.0353197    0.0141359    -0.143073     -0.217311     -0.0217369    0.0313809   -0.00917062   0.102041     -0.00630123   0.00836673   0.102866    -0.0369128   -0.00125304    0.121807
  0.0573865   -0.0974671   -0.153768      0.151855     0.111021     0.0628103    0.101109     0.00869269  -0.00524949  -0.0200359    0.111742     0.0914206    0.109596    -0.166001     -0.0467717    -0.000877457   0.053847    -0.334926    -0.0818667   -0.0795346     0.137196     0.0177898    0.228817    -0.130052    -0.0595464    -0.0565758
 -0.0447616   -0.0132659   -0.0662255     0.0502429    0.147352    -0.0171731    0.144864    -0.095869     0.0572555   -0.0321889   -0.166524     0.0365164    0.0159818    0.000256597  -0.141147     -0.0355841     0.191896    -0.0803055    0.0161828   -0.0713683    -0.0649309    0.0115274   -0.0159367   -0.0234768    0.0172933     0.0956795
  0.108749    -0.0291588   -0.19225      -0.0566936    0.108103    -0.00199235  -0.105036    -0.00829658  -0.0247358    0.0217316    0.0110258    0.0233875   -0.0742289    0.200904     -0.189398      0.132862     -0.128767     0.0314461    0.17068      0.0186737    -0.0222496   -0.0115029   -0.0587908   -0.00457814  -0.121222      0.0353934
  0.0350394   -0.0808461   -0.0563796     0.0939203    0.0598213    0.0647364   -0.0735641    0.00693763  -0.0528644   -0.0407986   -0.0353141    0.143658     0.0391566    0.0631702     0.0257754     0.0225441     0.10348     -0.0103031    0.0716535    0.00265065    0.0222802    0.071555     0.104269    -0.166228     0.131115     -0.190745
  0.0649086    0.124182     0.205467     -0.0699604    0.0862479   -0.087635     0.11659     -0.101568    -0.0448817    0.0173707   -0.00497415   0.0234393    0.123482    -0.158067      0.0653263     0.0372843    -0.0539955   -0.00307295  -0.243662     0.00744899    0.040515     0.110171    -0.0611218   -0.0221192   -0.105962      0.00574432
 -0.0247503   -0.0390088   -0.00574187   -0.0997539   -0.00125405   0.131215    -0.0288026    0.00958477   0.024434    -0.00698189   0.0226575    0.154272     0.0201186   -0.0634782    -0.0063278    -0.0954784    -0.073326    -0.111849    -0.137664    -0.17555       0.00538041   0.0437614   -0.113607    -0.120867     0.119891     -0.220301
 -0.00534288  -0.00951789   0.0279613    -0.106895    -0.0169873    0.038832     0.0627539   -0.0425138   -0.0505464    0.0108092    0.154065     0.0781335   -0.117721    -0.0422302    -0.0473841     0.0474587     0.014269    -0.0567862    0.0637357   -0.108648      0.0543349    0.129638     0.0868952   -0.056259     0.161919      0.0429569
 -0.0266958    0.0136615    0.156644     -0.0438169   -0.0951123    0.11272      0.0214515    0.0411362    0.300011    -1.31037e-5  -0.0675714    0.0941701   -0.077698     0.0060922     0.126139     -0.0997105     0.0361678   -0.0561572   -0.0588703   -0.0559839     0.0064007    0.0733569    0.102544    -0.0175557    0.00597006    0.045972
 -0.283166     0.0132882    0.123301     -0.0734251    0.100978     0.00743992   0.0825687    0.0834884   -0.0122474    0.00370851   0.0442929    0.0768375   -0.0496639    0.0831149    -0.0474169    -0.0150101    -0.0234841    0.186381    -0.0964339   -0.0531961    -0.227959    -0.215538     0.0661069   -0.0174381   -0.0504729     0.0926715
  0.0165625   -0.073719    -0.0361668     7.79641e-5  -0.0775418   -0.0921173   -0.102434    -0.0411658    0.101866     0.165034     0.0483001    0.0289125   -0.00432728  -0.0377866     0.000173364   0.000579654  -0.0131545    0.0244457    0.00306263  -0.0145815     0.0212487    0.0588327   -0.0296438    0.25353      0.00550742   -0.0168869
  0.0361452    0.0169628    0.179469     -0.127895    -0.0915963   -0.00874753   0.00178473   0.0905668   -0.132802    -0.0290833   -0.00877188  -0.0528974   -0.225553    -0.0202818    -0.0840474     0.00809793    0.130797     0.0424173    0.0336407    0.122208     -0.205766     0.17367      0.00777099  -0.170594    -0.0516501     0.00354918
 -0.127744     0.0853674   -0.0605706     0.050999    -0.0854455    0.0115726   -0.0178988   -0.165835     0.0837838    0.0305082    0.00324077  -0.0463894   -0.125246     0.099892      0.0608354    -0.0308164     0.00375905   0.104067    -0.0345498   -0.130746      0.0240463    0.00721387   0.132594     0.0544986    0.0797342     0.0794894
  0.0389863   -0.00751276  -0.246958      0.082853     0.155914    -0.105322     0.0550226    0.0592802    0.0250273    0.00929012  -0.0388681   -0.134612     0.0177567   -0.0383557     0.0642931     0.161174     -0.0846205   -0.128993    -0.0868833    0.0978778    -0.0520677    0.0429508   -0.0281669   -0.0568545    0.100883     -0.0252939
 -0.0598225    0.0369146   -0.0400697     0.0693763   -0.102597     0.117542     0.078219    -0.0136127    0.0364544    0.0887059    0.198766    -0.0961105    0.00432821  -0.0185438    -0.0459505    -0.0108333    -0.0128299   -0.0687368    0.0873524   -0.080685     -0.153696    -0.0209992   -0.0577952   -0.0825226    0.000436996   0.0890234
  0.127509     0.108462    -0.000690511  -0.0491225    0.0244066   -0.0336585    0.0510933    0.121577    -0.0113132   -0.148693    -0.011262     0.00798585   0.136732     0.263443     -0.024987     -0.0467493     0.111023     0.0217565   -0.11548     -0.0988512     0.129989    -0.101431    -0.0272064    0.21178     -0.0649484     0.11804
 -0.0560478    0.10179      0.0367107     0.0607367   -0.0456354    0.0785653    0.268504     0.0940004   -0.0980799    0.0396018   -0.0877988    0.0469875    0.17014     -0.107191     -0.109108      0.0249998    -0.0883075    0.150472     0.023827    -0.145306      0.00289899   0.14425     -0.0951525    0.0486033    0.228413      0.100856
  0.0476123   -0.19502     -0.117516     -0.082452    -0.087594    -0.0109975   -0.0963195   -0.0661625   -0.0749469   -0.119162     0.136563     0.10431     -0.100239    -0.0183629    -0.131958     -0.198568     -0.019824    -0.112376    -0.00241776   0.0507799    -0.131488     0.187416     0.144788    -0.00967148  -0.0606099     0.0229704
  0.177698    -0.0410784    0.0213038     0.0662701    0.0386571   -0.0563477    0.0663885   -0.028949     0.0203693   -0.128423     0.239822     0.140289    -0.0666336    0.00532094   -0.137624     -0.108057     -0.167233     0.0689874   -0.0618876   -0.0635714     0.0489765    0.0673585    0.0982536   -0.128125     0.0513772    -0.105429
  0.0297395   -0.0995794    0.249126     -0.0385552   -0.0882818   -0.0970223   -0.00839609   0.193294     0.207846    -0.121302    -0.0747387    0.0743504   -0.116071     0.0788785     0.124732      0.0375569    -0.144542    -0.0766494    0.0306718    0.0753665     0.0949325    0.0562886    0.0651791   -0.0568245   -0.0771808     0.140743kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4178327646649942
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417852
[ Info: iteration 2, average log likelihood -1.417776
[ Info: iteration 3, average log likelihood -1.417710
[ Info: iteration 4, average log likelihood -1.417625
[ Info: iteration 5, average log likelihood -1.417515
[ Info: iteration 6, average log likelihood -1.417376
[ Info: iteration 7, average log likelihood -1.417204
[ Info: iteration 8, average log likelihood -1.416976
[ Info: iteration 9, average log likelihood -1.416636
[ Info: iteration 10, average log likelihood -1.416089
[ Info: iteration 11, average log likelihood -1.415270
[ Info: iteration 12, average log likelihood -1.414283
[ Info: iteration 13, average log likelihood -1.413416
[ Info: iteration 14, average log likelihood -1.412864
[ Info: iteration 15, average log likelihood -1.412586
[ Info: iteration 16, average log likelihood -1.412462
[ Info: iteration 17, average log likelihood -1.412409
[ Info: iteration 18, average log likelihood -1.412387
[ Info: iteration 19, average log likelihood -1.412377
[ Info: iteration 20, average log likelihood -1.412372
[ Info: iteration 21, average log likelihood -1.412370
[ Info: iteration 22, average log likelihood -1.412368
[ Info: iteration 23, average log likelihood -1.412367
[ Info: iteration 24, average log likelihood -1.412367
[ Info: iteration 25, average log likelihood -1.412366
[ Info: iteration 26, average log likelihood -1.412366
[ Info: iteration 27, average log likelihood -1.412366
[ Info: iteration 28, average log likelihood -1.412365
[ Info: iteration 29, average log likelihood -1.412365
[ Info: iteration 30, average log likelihood -1.412365
[ Info: iteration 31, average log likelihood -1.412364
[ Info: iteration 32, average log likelihood -1.412364
[ Info: iteration 33, average log likelihood -1.412364
[ Info: iteration 34, average log likelihood -1.412364
[ Info: iteration 35, average log likelihood -1.412364
[ Info: iteration 36, average log likelihood -1.412364
[ Info: iteration 37, average log likelihood -1.412363
[ Info: iteration 38, average log likelihood -1.412363
[ Info: iteration 39, average log likelihood -1.412363
[ Info: iteration 40, average log likelihood -1.412363
[ Info: iteration 41, average log likelihood -1.412363
[ Info: iteration 42, average log likelihood -1.412363
[ Info: iteration 43, average log likelihood -1.412363
[ Info: iteration 44, average log likelihood -1.412363
[ Info: iteration 45, average log likelihood -1.412363
[ Info: iteration 46, average log likelihood -1.412363
[ Info: iteration 47, average log likelihood -1.412363
[ Info: iteration 48, average log likelihood -1.412363
[ Info: iteration 49, average log likelihood -1.412363
[ Info: iteration 50, average log likelihood -1.412363
┌ Info: EM with 100000 data points 50 iterations avll -1.412363
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4178524620046782
│     -1.4177758779723513
│      ⋮
└     -1.41236255310877
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412382
[ Info: iteration 2, average log likelihood -1.412303
[ Info: iteration 3, average log likelihood -1.412233
[ Info: iteration 4, average log likelihood -1.412143
[ Info: iteration 5, average log likelihood -1.412031
[ Info: iteration 6, average log likelihood -1.411903
[ Info: iteration 7, average log likelihood -1.411778
[ Info: iteration 8, average log likelihood -1.411674
[ Info: iteration 9, average log likelihood -1.411599
[ Info: iteration 10, average log likelihood -1.411548
[ Info: iteration 11, average log likelihood -1.411512
[ Info: iteration 12, average log likelihood -1.411486
[ Info: iteration 13, average log likelihood -1.411464
[ Info: iteration 14, average log likelihood -1.411445
[ Info: iteration 15, average log likelihood -1.411428
[ Info: iteration 16, average log likelihood -1.411412
[ Info: iteration 17, average log likelihood -1.411396
[ Info: iteration 18, average log likelihood -1.411380
[ Info: iteration 19, average log likelihood -1.411365
[ Info: iteration 20, average log likelihood -1.411350
[ Info: iteration 21, average log likelihood -1.411335
[ Info: iteration 22, average log likelihood -1.411321
[ Info: iteration 23, average log likelihood -1.411307
[ Info: iteration 24, average log likelihood -1.411293
[ Info: iteration 25, average log likelihood -1.411280
[ Info: iteration 26, average log likelihood -1.411268
[ Info: iteration 27, average log likelihood -1.411257
[ Info: iteration 28, average log likelihood -1.411246
[ Info: iteration 29, average log likelihood -1.411235
[ Info: iteration 30, average log likelihood -1.411226
[ Info: iteration 31, average log likelihood -1.411216
[ Info: iteration 32, average log likelihood -1.411207
[ Info: iteration 33, average log likelihood -1.411198
[ Info: iteration 34, average log likelihood -1.411189
[ Info: iteration 35, average log likelihood -1.411180
[ Info: iteration 36, average log likelihood -1.411172
[ Info: iteration 37, average log likelihood -1.411163
[ Info: iteration 38, average log likelihood -1.411155
[ Info: iteration 39, average log likelihood -1.411146
[ Info: iteration 40, average log likelihood -1.411138
[ Info: iteration 41, average log likelihood -1.411130
[ Info: iteration 42, average log likelihood -1.411122
[ Info: iteration 43, average log likelihood -1.411115
[ Info: iteration 44, average log likelihood -1.411108
[ Info: iteration 45, average log likelihood -1.411101
[ Info: iteration 46, average log likelihood -1.411095
[ Info: iteration 47, average log likelihood -1.411089
[ Info: iteration 48, average log likelihood -1.411083
[ Info: iteration 49, average log likelihood -1.411078
[ Info: iteration 50, average log likelihood -1.411074
┌ Info: EM with 100000 data points 50 iterations avll -1.411074
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4123819896366863
│     -1.4123025053621319
│      ⋮
└     -1.411073825264677
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411079
[ Info: iteration 2, average log likelihood -1.411023
[ Info: iteration 3, average log likelihood -1.410975
[ Info: iteration 4, average log likelihood -1.410920
[ Info: iteration 5, average log likelihood -1.410855
[ Info: iteration 6, average log likelihood -1.410776
[ Info: iteration 7, average log likelihood -1.410684
[ Info: iteration 8, average log likelihood -1.410582
[ Info: iteration 9, average log likelihood -1.410474
[ Info: iteration 10, average log likelihood -1.410370
[ Info: iteration 11, average log likelihood -1.410274
[ Info: iteration 12, average log likelihood -1.410192
[ Info: iteration 13, average log likelihood -1.410124
[ Info: iteration 14, average log likelihood -1.410069
[ Info: iteration 15, average log likelihood -1.410026
[ Info: iteration 16, average log likelihood -1.409992
[ Info: iteration 17, average log likelihood -1.409964
[ Info: iteration 18, average log likelihood -1.409941
[ Info: iteration 19, average log likelihood -1.409922
[ Info: iteration 20, average log likelihood -1.409904
[ Info: iteration 21, average log likelihood -1.409889
[ Info: iteration 22, average log likelihood -1.409875
[ Info: iteration 23, average log likelihood -1.409861
[ Info: iteration 24, average log likelihood -1.409849
[ Info: iteration 25, average log likelihood -1.409836
[ Info: iteration 26, average log likelihood -1.409825
[ Info: iteration 27, average log likelihood -1.409813
[ Info: iteration 28, average log likelihood -1.409802
[ Info: iteration 29, average log likelihood -1.409791
[ Info: iteration 30, average log likelihood -1.409780
[ Info: iteration 31, average log likelihood -1.409769
[ Info: iteration 32, average log likelihood -1.409758
[ Info: iteration 33, average log likelihood -1.409747
[ Info: iteration 34, average log likelihood -1.409737
[ Info: iteration 35, average log likelihood -1.409727
[ Info: iteration 36, average log likelihood -1.409716
[ Info: iteration 37, average log likelihood -1.409706
[ Info: iteration 38, average log likelihood -1.409697
[ Info: iteration 39, average log likelihood -1.409687
[ Info: iteration 40, average log likelihood -1.409677
[ Info: iteration 41, average log likelihood -1.409668
[ Info: iteration 42, average log likelihood -1.409659
[ Info: iteration 43, average log likelihood -1.409650
[ Info: iteration 44, average log likelihood -1.409641
[ Info: iteration 45, average log likelihood -1.409633
[ Info: iteration 46, average log likelihood -1.409625
[ Info: iteration 47, average log likelihood -1.409617
[ Info: iteration 48, average log likelihood -1.409609
[ Info: iteration 49, average log likelihood -1.409602
[ Info: iteration 50, average log likelihood -1.409594
┌ Info: EM with 100000 data points 50 iterations avll -1.409594
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4110794669383688
│     -1.4110230323704687
│      ⋮
└     -1.4095942555558516
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409596
[ Info: iteration 2, average log likelihood -1.409529
[ Info: iteration 3, average log likelihood -1.409464
[ Info: iteration 4, average log likelihood -1.409386
[ Info: iteration 5, average log likelihood -1.409288
[ Info: iteration 6, average log likelihood -1.409166
[ Info: iteration 7, average log likelihood -1.409025
[ Info: iteration 8, average log likelihood -1.408871
[ Info: iteration 9, average log likelihood -1.408715
[ Info: iteration 10, average log likelihood -1.408567
[ Info: iteration 11, average log likelihood -1.408431
[ Info: iteration 12, average log likelihood -1.408311
[ Info: iteration 13, average log likelihood -1.408205
[ Info: iteration 14, average log likelihood -1.408115
[ Info: iteration 15, average log likelihood -1.408037
[ Info: iteration 16, average log likelihood -1.407972
[ Info: iteration 17, average log likelihood -1.407917
[ Info: iteration 18, average log likelihood -1.407871
[ Info: iteration 19, average log likelihood -1.407832
[ Info: iteration 20, average log likelihood -1.407799
[ Info: iteration 21, average log likelihood -1.407771
[ Info: iteration 22, average log likelihood -1.407746
[ Info: iteration 23, average log likelihood -1.407725
[ Info: iteration 24, average log likelihood -1.407705
[ Info: iteration 25, average log likelihood -1.407688
[ Info: iteration 26, average log likelihood -1.407672
[ Info: iteration 27, average log likelihood -1.407658
[ Info: iteration 28, average log likelihood -1.407644
[ Info: iteration 29, average log likelihood -1.407632
[ Info: iteration 30, average log likelihood -1.407620
[ Info: iteration 31, average log likelihood -1.407609
[ Info: iteration 32, average log likelihood -1.407598
[ Info: iteration 33, average log likelihood -1.407588
[ Info: iteration 34, average log likelihood -1.407579
[ Info: iteration 35, average log likelihood -1.407570
[ Info: iteration 36, average log likelihood -1.407561
[ Info: iteration 37, average log likelihood -1.407553
[ Info: iteration 38, average log likelihood -1.407545
[ Info: iteration 39, average log likelihood -1.407537
[ Info: iteration 40, average log likelihood -1.407530
[ Info: iteration 41, average log likelihood -1.407523
[ Info: iteration 42, average log likelihood -1.407515
[ Info: iteration 43, average log likelihood -1.407508
[ Info: iteration 44, average log likelihood -1.407502
[ Info: iteration 45, average log likelihood -1.407495
[ Info: iteration 46, average log likelihood -1.407489
[ Info: iteration 47, average log likelihood -1.407482
[ Info: iteration 48, average log likelihood -1.407476
[ Info: iteration 49, average log likelihood -1.407470
[ Info: iteration 50, average log likelihood -1.407463
┌ Info: EM with 100000 data points 50 iterations avll -1.407463
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4095958998742226
│     -1.409529091180696
│      ⋮
└     -1.4074634955373944
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407466
[ Info: iteration 2, average log likelihood -1.407395
[ Info: iteration 3, average log likelihood -1.407322
[ Info: iteration 4, average log likelihood -1.407228
[ Info: iteration 5, average log likelihood -1.407104
[ Info: iteration 6, average log likelihood -1.406947
[ Info: iteration 7, average log likelihood -1.406767
[ Info: iteration 8, average log likelihood -1.406575
[ Info: iteration 9, average log likelihood -1.406384
[ Info: iteration 10, average log likelihood -1.406200
[ Info: iteration 11, average log likelihood -1.406029
[ Info: iteration 12, average log likelihood -1.405876
[ Info: iteration 13, average log likelihood -1.405740
[ Info: iteration 14, average log likelihood -1.405622
[ Info: iteration 15, average log likelihood -1.405520
[ Info: iteration 16, average log likelihood -1.405431
[ Info: iteration 17, average log likelihood -1.405355
[ Info: iteration 18, average log likelihood -1.405288
[ Info: iteration 19, average log likelihood -1.405229
[ Info: iteration 20, average log likelihood -1.405177
[ Info: iteration 21, average log likelihood -1.405130
[ Info: iteration 22, average log likelihood -1.405088
[ Info: iteration 23, average log likelihood -1.405049
[ Info: iteration 24, average log likelihood -1.405013
[ Info: iteration 25, average log likelihood -1.404980
[ Info: iteration 26, average log likelihood -1.404949
[ Info: iteration 27, average log likelihood -1.404919
[ Info: iteration 28, average log likelihood -1.404892
[ Info: iteration 29, average log likelihood -1.404866
[ Info: iteration 30, average log likelihood -1.404841
[ Info: iteration 31, average log likelihood -1.404818
[ Info: iteration 32, average log likelihood -1.404795
[ Info: iteration 33, average log likelihood -1.404774
[ Info: iteration 34, average log likelihood -1.404754
[ Info: iteration 35, average log likelihood -1.404734
[ Info: iteration 36, average log likelihood -1.404716
[ Info: iteration 37, average log likelihood -1.404698
[ Info: iteration 38, average log likelihood -1.404681
[ Info: iteration 39, average log likelihood -1.404665
[ Info: iteration 40, average log likelihood -1.404649
[ Info: iteration 41, average log likelihood -1.404634
[ Info: iteration 42, average log likelihood -1.404620
[ Info: iteration 43, average log likelihood -1.404606
[ Info: iteration 44, average log likelihood -1.404592
[ Info: iteration 45, average log likelihood -1.404579
[ Info: iteration 46, average log likelihood -1.404567
[ Info: iteration 47, average log likelihood -1.404554
[ Info: iteration 48, average log likelihood -1.404542
[ Info: iteration 49, average log likelihood -1.404530
[ Info: iteration 50, average log likelihood -1.404519
┌ Info: EM with 100000 data points 50 iterations avll -1.404519
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4074661799817352
│     -1.407395408407797
│      ⋮
└     -1.40451875945062
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4178327646649942
│     -1.4178524620046782
│     -1.4177758779723513
│     -1.4177096203430006
│      ⋮
│     -1.404542064858067
│     -1.4045302849408932
└     -1.40451875945062
32×26 Array{Float64,2}:
  0.129986    0.0670083  -1.20699      0.431084   -0.0339163  -1.12336     -1.24543    -0.474241    0.252483   -0.0846949   -0.490057    0.753306    -0.112709    0.121729    0.588596   -0.79678     -0.130101      0.436148   -0.273595   -0.64584     1.07931     -0.664753   -0.141525     0.251092     0.907256    0.493365
  0.150547   -0.232846    0.329335     0.282717   -0.679767   -0.695058    -0.820321   -0.309548   -0.0481066   0.497181    -0.126365    0.142695    -0.485226   -0.481148    0.0111349  -0.408183    -0.196394      0.198058    0.221409   -0.324586   -0.336741    -0.341762   -0.52189      0.199263    -0.21346     0.0800961
  0.96132    -0.285268   -0.27266      0.751584   -0.251792   -0.339459     0.184205    0.21357    -0.349986   -0.572836     0.0358617   0.136099    -0.0796819  -0.331933   -0.73585    -0.485634    -0.243187      0.0944906  -0.0298878  -0.532255    0.405181    -0.0879936  -0.273914    -0.0648663    0.141339   -0.463022
  0.256615   -0.386645   -0.200956     0.490376   -0.226478   -0.109015     0.47901    -0.180009   -0.141111    0.471573     0.114678   -0.414204     0.280153   -0.158119   -0.282751    0.133212     0.351106      0.697315   -0.321187   -0.213537   -0.0692229    0.12053    -0.23951      0.0331568   -0.662064   -0.0869763
 -0.155656   -0.0279434   0.276927    -0.0430751  -0.0930367   0.382498    -0.0916094  -0.149661    0.865778   -0.101256    -0.422207    0.127634    -0.0798544   0.0799146   0.113266   -0.0720314    0.163922     -0.786297   -0.709751    0.049184    0.211562     0.146526    0.131985    -0.080146    -0.27085    -0.644098
 -0.520676   -0.277929   -0.217317     0.173483   -0.142275    0.185214     0.165713    0.215929    0.429444    0.124392     0.608542   -0.349374    -0.412289   -0.225621    0.0424654  -0.0554188   -0.266946     -0.82614    -0.652271   -0.121281   -0.591979    -0.0361306   0.267209     0.0733523    0.342493    0.0582725
 -0.317302    0.9404     -0.169        0.204662   -0.682393   -0.503885    -0.208356    0.668218   -0.366592    0.0886895    0.0488107   0.135506    -0.195986   -0.854179    0.397638    0.00499663   0.227815     -0.469301    0.02299    -0.902981   -0.116456    -0.382913    0.227692    -0.454154     0.165277   -0.296
  0.216135    0.678395    0.143048     0.291723    0.0697965   0.655772     0.0313612   0.361316    0.305033    0.0139768   -0.118215   -0.271291    -0.561348   -0.299062    0.257716    0.334089    -0.000818231  -0.312095    0.706711    0.0281948   0.0891944   -0.16559     0.187541    -0.0443135    0.212766   -0.488548
  0.335313   -0.543362    0.161084    -0.104963    0.495294    0.427169     0.0240777  -1.04821     0.0677184  -0.237299     0.0322366  -0.387288     0.0585378   0.427026    0.10857    -0.154533    -0.197828      0.743456    0.191629    0.504195   -0.423815    -0.247461   -0.355081     0.274557     0.0594328  -0.154549
  0.0448787  -0.80814     0.420191    -0.439529    0.135766    0.00983595  -0.402316   -0.0293188   0.113209   -0.388877    -0.0269986   0.165276     0.453118    0.63417    -0.463675   -0.548091    -0.0945269     0.400789    0.143362    0.0805452  -0.0511997    0.301564   -0.425533    -0.110049    -0.0713829   0.160229
  0.2444      0.417855   -0.594152    -0.393867    0.500593    0.0964211    0.453517   -0.0329541  -0.835897    0.011137     0.145699   -0.199332     0.103277    0.505404   -0.393789   -0.0464673    0.299889      0.754512    0.292577   -0.129865    0.168947    -0.0690353  -0.066894    -0.465425    -0.0809566   0.357766
 -0.71325     0.689907   -0.252594    -0.559848    0.19833    -0.67112     -0.0768073  -0.219737    0.322204   -0.37391      0.530107    0.290655     0.113538    0.0779571   0.171781    0.364087     0.00823431    1.04266     0.124269    0.402937    0.0320911   -0.107041    0.331113    -0.14813     -0.580538   -0.12556
 -0.0328818   0.120925    0.11159      0.354484    0.329063    0.247158    -0.398641    0.276469    0.229454   -0.207264    -0.10977    -0.117549    -0.268647    0.337378    0.292213    0.452797    -0.120562      0.103977    0.203972    0.221374   -0.356754    -0.593054   -0.87638      0.111916     0.350964    0.401136
 -0.196768   -0.123304   -0.0710454   -0.0370556   0.64737    -0.167759    -0.0468976   0.391064   -0.626763   -0.427711     0.104016    0.111523     0.151677    0.0621475  -0.306096    0.102914     0.0466519     0.0245421   0.0881052   0.154513   -0.353535    -0.179328    0.357015     0.337472     0.581953    1.10435
 -0.178822   -0.345747    0.0673751    0.0611351   0.197452   -0.543832    -0.154217   -0.155065   -0.2375     -0.0197076    0.0237951   0.235175    -0.207991    0.101547   -0.0334273  -0.238029    -0.15339       0.0526831   0.137697   -0.0675892  -0.228759     0.231771   -0.0686721    0.256651     0.0999033   0.309534
  0.23509    -0.0943182   0.548538    -0.28051    -0.0481253   0.425175     0.596459    0.367135    0.103447   -0.089384    -0.163992   -0.212854     0.833885    0.316758   -0.231317    0.374795    -0.265036     -0.18348    -0.16225     0.711294    0.0288444    0.211188    0.0371993    0.273988     0.0437211   0.505332
 -0.531665    0.171364    0.00101829   0.0782001   0.0178913  -0.0958711   -0.22466    -0.0162037   0.368219   -0.00793582  -0.164159    0.170455    -0.510349   -0.213819    0.116893    0.105468    -0.0692956    -0.331373    0.0270171  -0.0290821  -0.1228       0.295609    0.258831     0.0551017    0.113708   -0.149963
  0.19503    -0.211345    0.106356     0.375678   -0.3575      0.0706968   -0.0264222   0.202508    0.223058   -0.222669    -0.0397153   0.0118089   -0.0151492  -0.090156    0.224103   -0.0590303    0.102358     -0.16675    -0.193676    0.0824056   0.0497337   -0.21662    -0.20815     -0.0868541    0.0706045  -0.224932
 -0.129465    0.0702421  -0.31783      0.141351   -0.128158   -0.328433     0.0431512   0.119523   -0.373115   -0.00171036   0.439503   -0.276938    -0.128006   -0.520386   -0.109951    0.253398     0.0677698     0.353673    0.17825    -0.0832572  -0.0625752   -0.313267    0.163717    -0.0506783   -0.0907205   0.279077
  0.0851553  -0.048571    0.00931415  -0.0966391   0.0991357  -0.0497581    0.027622   -0.0413502  -0.137473    0.0846061    0.0421444   0.0402265    0.070844    0.17734    -0.215497   -0.0861062    0.00713813    0.0785294  -0.0519608  -0.111759    0.00524722   0.109967   -0.0409281   -0.00317029  -0.0379244   0.0784929
  0.24891     0.432248    0.0488109    0.264909   -0.0223549  -0.822822     0.234624   -0.822212   -0.288527    0.248554    -0.188909   -0.203767     0.0636724  -0.479609    0.461483   -0.0246111   -0.772064      0.0387397  -0.289395   -0.218168   -0.20222      0.313369    0.835834     0.391676     0.0423125   0.0902566
 -0.0276168  -0.253046    0.306801     0.0503686  -0.192306   -0.790511    -0.13114     0.141083   -0.0375814  -0.0656783   -0.248246    0.475021     0.634066    0.0716858   0.347027   -0.111172    -0.450936      0.0620263  -0.263613    0.121793    0.0676419    0.415047   -0.00911399   0.764791     0.0145145   0.248613
 -0.223726   -0.0448753   0.220378    -0.644718   -0.346487   -0.427675    -0.0224207   0.064173   -0.262587    0.739545     0.25516     0.392768     0.0541521   0.0133374  -0.271335   -0.222306    -0.178783     -0.351531    0.0332152  -0.754135    0.31756      0.404388    0.438866    -0.371256    -0.398999    0.139209
 -0.117466   -0.234148    0.43072     -0.352086   -0.619631    0.0918562   -0.110221    0.226205   -0.152301   -0.206296    -0.046068    0.359114     0.27508    -0.502772    0.013202   -0.272837     0.314014     -0.168935    0.183379    0.42199     0.247164     0.186195    0.887978     0.0968157    0.147176    0.0976724
  0.0508133   0.571976   -0.115131    -0.227589   -0.424608    0.690939     0.141441    0.273098    0.135729   -0.115224     0.116175   -0.311778    -0.0169975   0.12446     0.198015    0.241595     0.450386      0.0989913  -0.112048   -0.032172    0.819477    -0.53265     0.0342069   -0.56991     -0.310955   -0.631063
  0.287787    0.557471   -0.518588     0.0440918  -0.310183    0.356492     0.180416    0.0662883   0.324106   -0.492735    -0.0383384  -0.169277     0.561406   -0.114124    0.0232425   0.129917    -0.197236      0.201097   -0.275044    0.391276    0.317557     0.609881    0.0900047   -0.382713     0.607224    0.138816
 -0.635877   -0.165707   -0.588591    -0.201494   -0.419674    0.534599    -0.380632    0.274162    0.487269   -0.360635     0.748864    0.12946     -0.69248    -0.0461296  -0.323406   -0.120588     0.909504      0.291817    0.591803    0.179679    0.0576379    0.179828   -0.357375    -0.870083     0.575176    0.297267
  0.183591   -0.21869    -0.536641     0.311435    0.793913    0.601468    -0.0920653  -0.174766    0.199913   -0.68991      0.0787722   0.301216    -0.187437    0.535889   -0.609035    0.376017     0.42018      -0.159032   -0.763061    0.302942    0.395561     0.0272951  -0.340603     0.164397     0.203117    0.060421
  0.316088    0.398231   -0.262588     0.240621    0.341967   -0.0853134    0.348175   -0.53936     0.0821833   0.532174     0.139409   -0.0350748   -0.355336    0.123953    0.26596     0.0135058   -0.0111018    -0.136028    0.100005   -0.596105   -0.677546    -0.0570182  -0.309419    -0.147525     0.282174   -0.418735
  0.425414    0.0192192   0.374843     0.314996    0.106413    0.338429     0.116982    0.367967   -0.148024    0.307322    -0.556219   -0.0550146   -0.180025    0.189711   -0.325584   -0.275857     0.251978     -0.731788   -0.133449   -0.477748   -0.169492     0.107462   -0.24396      0.0250392    0.327352   -0.117168
 -0.111059    0.326097    0.342687    -0.609953    0.510991    0.445398     0.142685    0.144171    0.203616    0.121308    -0.113821    0.00759199  -0.253171    0.544044   -0.0353229   0.154675    -0.0409275    -0.175869    0.390377    0.567974    0.0881196    0.140862    0.0955777    0.0705706   -0.0652065   0.148956
  0.242444   -0.0154313   0.347217    -0.505008    0.407613    0.404652     0.550677    0.0215263   0.0785982   0.16061      0.132683   -0.30309      0.894828    0.171971   -0.115615    0.181279    -0.0275288    -0.138708   -0.290949   -0.0580654   0.00155797   0.164355    0.299092     0.272349    -0.166431    0.0111985[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404507
[ Info: iteration 2, average log likelihood -1.404496
[ Info: iteration 3, average log likelihood -1.404485
[ Info: iteration 4, average log likelihood -1.404475
[ Info: iteration 5, average log likelihood -1.404464
[ Info: iteration 6, average log likelihood -1.404454
[ Info: iteration 7, average log likelihood -1.404444
[ Info: iteration 8, average log likelihood -1.404433
[ Info: iteration 9, average log likelihood -1.404423
[ Info: iteration 10, average log likelihood -1.404414
┌ Info: EM with 100000 data points 10 iterations avll -1.404414
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.230234e+05
      1       6.881358e+05      -2.348876e+05 |       32
      2       6.787328e+05      -9.403010e+03 |       32
      3       6.747121e+05      -4.020739e+03 |       32
      4       6.724377e+05      -2.274363e+03 |       32
      5       6.709634e+05      -1.474278e+03 |       32
      6       6.699149e+05      -1.048489e+03 |       32
      7       6.690829e+05      -8.320231e+02 |       32
      8       6.683826e+05      -7.002992e+02 |       32
      9       6.677499e+05      -6.327158e+02 |       32
     10       6.672187e+05      -5.311548e+02 |       32
     11       6.667305e+05      -4.882470e+02 |       32
     12       6.663209e+05      -4.096130e+02 |       32
     13       6.659634e+05      -3.574941e+02 |       32
     14       6.656404e+05      -3.229564e+02 |       32
     15       6.653523e+05      -2.881753e+02 |       32
     16       6.650845e+05      -2.677799e+02 |       32
     17       6.648095e+05      -2.749931e+02 |       32
     18       6.645701e+05      -2.393836e+02 |       32
     19       6.643478e+05      -2.222694e+02 |       32
     20       6.641464e+05      -2.013836e+02 |       32
     21       6.639570e+05      -1.894508e+02 |       32
     22       6.637741e+05      -1.828637e+02 |       32
     23       6.636095e+05      -1.646741e+02 |       32
     24       6.634518e+05      -1.576338e+02 |       32
     25       6.632826e+05      -1.692382e+02 |       32
     26       6.631127e+05      -1.698790e+02 |       32
     27       6.629657e+05      -1.470491e+02 |       32
     28       6.628419e+05      -1.237283e+02 |       32
     29       6.627214e+05      -1.204852e+02 |       32
     30       6.626010e+05      -1.204873e+02 |       32
     31       6.624861e+05      -1.148642e+02 |       32
     32       6.623773e+05      -1.088248e+02 |       32
     33       6.622816e+05      -9.563294e+01 |       32
     34       6.622099e+05      -7.175956e+01 |       32
     35       6.621462e+05      -6.366577e+01 |       32
     36       6.620847e+05      -6.150871e+01 |       32
     37       6.620271e+05      -5.755005e+01 |       32
     38       6.619713e+05      -5.583312e+01 |       32
     39       6.619158e+05      -5.556001e+01 |       32
     40       6.618693e+05      -4.641768e+01 |       32
     41       6.618243e+05      -4.505666e+01 |       32
     42       6.617712e+05      -5.310766e+01 |       32
     43       6.617124e+05      -5.872693e+01 |       32
     44       6.616521e+05      -6.030205e+01 |       32
     45       6.615996e+05      -5.255018e+01 |       32
     46       6.615570e+05      -4.255029e+01 |       32
     47       6.615184e+05      -3.863468e+01 |       32
     48       6.614812e+05      -3.717997e+01 |       32
     49       6.614434e+05      -3.780287e+01 |       32
     50       6.614055e+05      -3.790296e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 661405.5221165069)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416398
[ Info: iteration 2, average log likelihood -1.411368
[ Info: iteration 3, average log likelihood -1.410023
[ Info: iteration 4, average log likelihood -1.408990
[ Info: iteration 5, average log likelihood -1.407856
[ Info: iteration 6, average log likelihood -1.406795
[ Info: iteration 7, average log likelihood -1.406079
[ Info: iteration 8, average log likelihood -1.405696
[ Info: iteration 9, average log likelihood -1.405494
[ Info: iteration 10, average log likelihood -1.405371
[ Info: iteration 11, average log likelihood -1.405284
[ Info: iteration 12, average log likelihood -1.405216
[ Info: iteration 13, average log likelihood -1.405159
[ Info: iteration 14, average log likelihood -1.405111
[ Info: iteration 15, average log likelihood -1.405069
[ Info: iteration 16, average log likelihood -1.405031
[ Info: iteration 17, average log likelihood -1.404996
[ Info: iteration 18, average log likelihood -1.404965
[ Info: iteration 19, average log likelihood -1.404936
[ Info: iteration 20, average log likelihood -1.404909
[ Info: iteration 21, average log likelihood -1.404883
[ Info: iteration 22, average log likelihood -1.404860
[ Info: iteration 23, average log likelihood -1.404837
[ Info: iteration 24, average log likelihood -1.404816
[ Info: iteration 25, average log likelihood -1.404796
[ Info: iteration 26, average log likelihood -1.404777
[ Info: iteration 27, average log likelihood -1.404759
[ Info: iteration 28, average log likelihood -1.404742
[ Info: iteration 29, average log likelihood -1.404725
[ Info: iteration 30, average log likelihood -1.404709
[ Info: iteration 31, average log likelihood -1.404694
[ Info: iteration 32, average log likelihood -1.404679
[ Info: iteration 33, average log likelihood -1.404665
[ Info: iteration 34, average log likelihood -1.404651
[ Info: iteration 35, average log likelihood -1.404638
[ Info: iteration 36, average log likelihood -1.404625
[ Info: iteration 37, average log likelihood -1.404612
[ Info: iteration 38, average log likelihood -1.404600
[ Info: iteration 39, average log likelihood -1.404588
[ Info: iteration 40, average log likelihood -1.404577
[ Info: iteration 41, average log likelihood -1.404566
[ Info: iteration 42, average log likelihood -1.404555
[ Info: iteration 43, average log likelihood -1.404545
[ Info: iteration 44, average log likelihood -1.404534
[ Info: iteration 45, average log likelihood -1.404524
[ Info: iteration 46, average log likelihood -1.404514
[ Info: iteration 47, average log likelihood -1.404505
[ Info: iteration 48, average log likelihood -1.404495
[ Info: iteration 49, average log likelihood -1.404486
[ Info: iteration 50, average log likelihood -1.404477
┌ Info: EM with 100000 data points 50 iterations avll -1.404477
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.212186    -0.196487    -0.111312   -0.309114    0.176149      0.883208     -0.132326     0.0503655    0.746917   -0.606014   -0.059262   -0.179851    0.0281435    0.644018   -0.123644   -0.112867    0.47566     0.11022    -0.309221     0.716644    0.76113     0.0437168   -0.183256   -0.273485   -0.22419    -0.257986
 -0.173668     0.338804     0.177621   -0.0789675  -0.415773     -0.23091       0.109805    -0.0720244    0.28597     0.374255   -0.239448   -0.176673    0.0232123   -0.264111    0.198116   -0.212173   -0.244307   -0.238057   -0.191106    -0.483164    0.453975    0.513381     0.508202   -0.254414   -0.585405   -0.77243
 -0.0264096    0.606795     0.0611987   0.327238   -0.667665     -0.648046     -0.383713     0.21759     -0.403915    0.221913   -0.030326   -0.0331305  -0.372386    -0.948492    0.280553    0.0137977  -0.0638976  -0.173154    0.334022    -0.676479   -0.490538   -0.450022    -0.0325907  -0.0472456   0.112229    0.0822829
  0.660216     0.276459    -0.367889   -0.0422084  -0.0255736     0.482736      0.397154    -0.0481173   -0.509178    0.153184    0.141154   -0.351225    0.200729     0.0456377  -0.257673    0.185389    0.415901    0.820028    0.171045    -0.260106    0.226845   -0.33708     -0.215347   -0.471861   -0.242755    0.00937261
  0.379553    -0.197143     1.07092    -0.603013   -0.245855      0.0598115    -0.0930707    0.564613     0.101802   -0.346683   -0.282525    0.274853    0.877598     0.183504    0.222087   -0.284418   -0.4222      0.145326    0.200665     0.313474    0.394763    0.141353     0.233593    0.288165    0.0986594   0.286785
 -0.258867     0.371826    -0.266242   -0.173675    0.166465     -0.54918       0.0299332   -0.409488    -0.553186   -0.211592   -0.559424    0.312111    0.398611     0.0285898  -0.0955916  -0.026959    0.127606    0.578438   -0.128355     0.156502    0.198516    0.423466     0.397748    0.272458    0.0675009   0.780445
 -0.452885     0.224455    -0.924428    0.407687    0.204489     -0.17633       0.510314    -0.397042     0.138812    0.601622    0.425229   -0.381978   -0.682775    -0.184193    0.121843    0.45546     0.0262537  -0.158237   -0.439692    -0.58633    -0.772525   -0.125578     0.0851998   0.0140447   0.212791   -0.00810692
 -0.680951     0.387686     0.275421    0.115347    0.148083     -0.000257934  -0.655255    -0.0888474    0.413683    0.0881841  -0.305451    0.117642   -0.41867      0.255143    0.598194    0.623078   -0.245407    0.0215895  -0.00644645   0.134209   -0.382034   -0.246327    -0.317725    0.233681    0.291367    0.501066
  0.00219616  -0.508796    -0.538488   -0.416351   -0.0228711    -0.302798      0.0366533   -0.299194    -0.0953435  -0.0766471   0.424544   -0.0847483   0.309701     0.665718   -0.699846   -0.470889   -0.493209    0.584601    0.0471681    0.447501   -0.401108    0.260597    -0.333983   -0.177729    0.194676    0.481209
 -0.101201    -0.250964    -0.448854    0.142351   -0.602572      0.184902     -0.374474     0.541342    -0.369256    0.131599   -0.756095   -0.20847    -0.0959353   -0.0900489  -0.651777    0.038865    0.0953442  -0.75567    -0.611504     0.0205582   0.69382     0.226113     0.17874     0.1588     -0.0997704   0.994396
  0.0589576   -0.327316     0.505726    0.39451    -0.332122      0.542713     -0.146011     0.488117     0.350578    0.0205038   0.176468   -0.17089    -0.145029    -0.457987    0.323549    0.0608341   0.093931   -0.837205   -0.245732    -0.190925   -0.104077   -0.410834     0.206994   -0.0835895   0.0874628  -0.536102
  0.0489971    0.683912    -0.155083    0.217472   -0.214506      0.53899       0.0863632    0.268422     0.309472   -0.0610789  -0.0678146  -0.0688362  -0.403007    -0.156096    0.121705    0.219793    0.334174   -0.231874    0.0677397   -0.104312    0.239217   -0.194603     0.0703228  -0.407346    0.0812263  -0.653693
 -0.51732      0.794026    -0.344725   -0.430883    0.183261     -0.627338      0.0701157   -0.190195     0.225647   -0.401559    0.58684     0.214305    0.172952    -0.0810545   0.240315    0.441261    0.0952841   1.11371     0.0649948    0.271557    0.0636296  -0.201267     0.341716   -0.120837   -0.627551   -0.19493
  0.292617     0.30413     -0.490847    0.481526   -0.0273332     0.0652093     0.428282     0.174524     0.0336767  -0.386305    0.580656   -0.852554    0.337354    -0.703457    0.145951    0.360336   -0.473443    0.151758   -0.247649     0.214561    0.0655598   0.14329      0.252128    0.0382054   0.421407    0.443846
  0.381585     0.620208     0.044179    0.0207064  -0.0189899     0.583905      0.334994     0.184004     0.271439    0.078892   -0.641291    0.182095    0.0942985    0.257268   -0.214715   -0.082998    0.298459   -0.406052   -0.157552    -0.151848    0.188988    0.494081    -0.235138   -0.230749    0.46944    -0.158981
  0.0681853   -0.332445    -0.211659    0.203765    0.72243       0.294338     -0.0653062    0.344771    -0.377617   -0.562875    0.103585    0.250381    0.0546354    0.433373   -0.507492    0.288934    0.396596   -0.0128568  -0.222478     0.207366   -0.301531   -0.476147    -0.209829    0.408698    0.811308    0.830889
 -0.148724    -0.0743921   -0.13368     0.171606   -0.503391      0.102967     -0.00111557   0.360029    -0.154023   -0.306589    0.141497    0.13008    -0.0844806   -0.20819    -0.0971357   0.0503587   0.461477    0.141007    0.182994     0.230134    0.266481   -0.146843     0.107283   -0.347296    0.257267    0.101724
  0.139064     0.0670867   -0.0766705   0.251391   -0.00232718    0.159947     -0.0321785    0.150182     0.355904   -0.0957089   0.0375057  -0.0202484  -0.28255      0.11022     0.124097   -0.0124904  -0.0392433  -0.265552   -0.172526    -0.0645349  -0.0811262  -0.201977    -0.385077   -0.169877   -0.010168   -0.369473
  0.534365    -0.0205729    0.339265    0.136091    0.235031     -0.260808      0.318912    -0.543366    -0.393514    0.607313   -0.279687    0.0875986   0.16174      0.122134    0.121655   -0.42574    -0.333047   -0.346485   -0.0826898   -0.568821   -0.417886    0.0952989    0.328525    0.372038    0.333448   -0.137394
  0.273827    -0.303825     0.0897085  -0.259309    0.549205      0.372198      0.53158     -0.0401902    0.0551393  -0.0908834   0.221039   -0.144171    0.684017     0.696564   -0.547172    0.254069    0.0392008  -0.222273   -0.511929    -0.0202879   0.383313    0.262331     0.166152    0.088766   -0.341347   -0.00351319
 -0.62733     -0.34146     -0.301643   -0.187832    0.0105989     0.176104     -0.469942    -0.350177     0.677191   -0.0370516   0.438887    0.393413   -0.940695    -0.295138   -0.266967   -0.105494    0.461735   -0.152034    0.389436    -0.0684201  -0.467595    0.482839     0.124728   -0.508619    0.530342    0.0149979
 -0.121174    -0.207817     0.36504    -0.0548588  -0.00998532   -0.459481     -0.0376399   -0.0472979    0.0555992  -0.0443034  -0.154202    0.305914    0.202917     0.0404792   0.116618   -0.149886   -0.460027   -0.352158   -0.222319     0.0626675  -0.186902    0.411555     0.162929    0.391235    0.186136    0.317969
  0.48623      0.00428973  -0.623903    0.718194   -0.155238     -0.618255     -0.537112    -0.129112    -0.012125   -0.263823   -0.234743    0.296292   -0.383606    -0.0595108  -0.121012   -0.599625   -0.159667    0.258231   -0.145639    -0.606333    0.651874   -0.312718    -0.326669   -0.0544289   0.41577    -0.145234
  0.137819    -0.592544     0.0130937   0.471495   -0.385688     -0.6527       -0.17168     -0.252209     0.20136    -0.0230416  -0.0601202   0.22924     0.407978    -0.318858    0.232539   -0.0468067  -0.0910373   0.195665   -0.509334     0.169032   -0.241813    0.120527    -0.373       0.58845    -0.283599   -0.0369562
 -0.113974     0.149676     0.650853   -0.777823    0.126238      0.615422      0.776609    -0.00531557   0.069374    0.569182    0.171546   -0.290092    0.394456     0.138542   -0.12972     0.538207    0.276469   -0.0851054   0.0799127    0.517321   -0.572991    0.12497      0.185266    0.225751   -0.374913    0.14692
  0.61384     -0.192648     0.398141    0.403411    0.533113      0.451189      0.151424    -0.199002     0.379525   -0.248805   -0.513609   -0.268485   -0.105045     0.351831   -0.0520315  -0.0377079  -0.184059   -0.108922    0.103473     0.205654   -0.555922   -0.0893778   -0.715583    0.275376    0.0939279  -0.229403
 -0.301564     0.163379    -0.0722305  -0.91513    -0.330899     -0.373323      0.0532917    0.295074    -0.63246     0.572213    0.76696     0.476215    0.119982    -0.367111   -0.265837   -0.365776    0.11389    -0.284392   -0.0223393   -0.722472    0.401793   -0.187286     0.31231    -0.410607   -0.14826     0.280425
 -0.243416     0.0770002    0.133924   -0.225867   -0.000333499  -0.104812     -0.0783191   -0.0185095    0.260526   -0.134352   -0.0465181   0.254193   -0.00228874  -0.287034    0.0204388  -0.0621636  -0.162563   -0.327436   -0.033363     0.295325   -0.0118071   0.374378     0.547384    0.281935    0.272765    0.0827452
 -0.267645     0.683652    -0.0332735  -0.46611     0.628754      0.217662     -0.0200886    0.430333    -0.231209   -0.107145    0.27987    -0.341172   -0.46678      0.522937    0.113929    0.221732   -0.384959   -0.193205    0.842388     0.440868    0.0734761  -0.134317     0.187806   -0.179189    0.266801    0.230017
  0.0555362   -0.104835     0.0377862  -0.0307079   0.120011     -0.0917213     0.0405273   -0.00172858  -0.230545    0.0982051   0.125561   -0.112531    0.0638784    0.0575895  -0.160262    0.032667    0.0244902   0.165125    0.0256001   -0.128861   -0.0537113  -0.00337479  -0.0294556   0.0456209  -0.135135    0.16094
  0.101179    -0.782354     0.235632    0.282707    0.0689341    -0.481616     -0.0352879   -0.0403385   -0.605335    0.0820164   0.37122    -0.303392   -0.227058    -0.265891   -0.198064   -0.31251     0.119723    0.461184    0.406365    -0.297553   -0.303434   -0.0386337   -0.291525    0.189718   -0.382065    0.230418
 -0.270883    -0.487801     0.730166   -0.485028    0.107411     -0.338432     -0.72054      0.0243653   -0.0568102   0.225522   -0.229035    0.901382   -0.232191     0.686571   -0.424881   -0.352524    0.163205   -0.0467203   0.304336    -0.464578   -0.0576526   0.131125     0.0200561  -0.111787   -0.269012   -0.348713[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404468
[ Info: iteration 2, average log likelihood -1.404460
[ Info: iteration 3, average log likelihood -1.404451
[ Info: iteration 4, average log likelihood -1.404443
[ Info: iteration 5, average log likelihood -1.404435
[ Info: iteration 6, average log likelihood -1.404426
[ Info: iteration 7, average log likelihood -1.404418
[ Info: iteration 8, average log likelihood -1.404410
[ Info: iteration 9, average log likelihood -1.404402
[ Info: iteration 10, average log likelihood -1.404394
┌ Info: EM with 100000 data points 10 iterations avll -1.404394
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
