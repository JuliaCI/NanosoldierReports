Julia Version 1.5.0-DEV.225
Commit 2c43528f39 (2020-02-03 15:22 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed SortingAlgorithms ── v0.3.1
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed URIParser ────────── v0.4.0
  Installed Distances ────────── v0.8.2
  Installed Compat ───────────── v2.2.0
  Installed CMake ────────────── v1.1.2
  Installed FileIO ───────────── v1.2.1
  Installed JLD ──────────────── v0.9.2
  Installed PDMats ───────────── v0.9.11
  Installed CMakeWrapper ─────── v0.2.3
  Installed Parameters ───────── v0.12.0
  Installed QuadGK ───────────── v2.3.1
  Installed Rmath ────────────── v0.6.0
  Installed NearestNeighbors ─── v0.4.4
  Installed Arpack_jll ───────── v3.5.0+2
  Installed ScikitLearnBase ──── v0.5.0
  Installed Arpack ───────────── v0.4.0
  Installed BinDeps ──────────── v1.0.0
  Installed LegacyStrings ────── v0.4.1
  Installed Missings ─────────── v0.4.3
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed HDF5 ─────────────── v0.12.5
  Installed StatsFuns ────────── v0.9.3
  Installed Clustering ───────── v0.13.3
  Installed StatsBase ────────── v0.32.0
  Installed StaticArrays ─────── v0.12.1
  Installed Blosc ────────────── v0.5.1
  Installed BinaryProvider ───── v0.5.8
  Installed DataAPI ──────────── v1.1.0
  Installed FillArrays ───────── v0.8.4
  Installed DataStructures ───── v0.17.9
  Installed OrderedCollections ─ v1.1.0
  Installed SpecialFunctions ─── v0.9.0
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%####                                                                       6.1%#######                                                                   10.7%############                                                              17.4%##################                                                        25.4%##########################                                                37.5%######################################                                    53.3%##################################################                        70.8%######################################################################    98.1%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_F1oSry/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -777938.9521464445, [99992.33922705984, 7.66077294015104], [625.2217295843074 116.82206075628591 135.4500306204639; -14.98977957507875 -14.333510915494136 21.87364924110797], [[100223.40163734116 91.15740950742412 309.9104350531773; 91.15740950742412 100357.10136576899 49.560284580358996; 309.9104350531773 49.560284580358996 99849.9956918071], [31.27046503218886 26.470689779947246 -42.98296977420679; 26.470689779947246 29.503224846088564 -40.26562414915034; -42.98296977420679 -40.26562414915034 62.898471728999795]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.164996e+03
      1       8.076752e+02      -3.573208e+02 |        2
      2       7.906716e+02      -1.700363e+01 |        0
      3       7.906716e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 790.6715829285872)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.056204
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.752668
[ Info: iteration 2, lowerbound -3.603036
[ Info: iteration 3, lowerbound -3.441827
[ Info: iteration 4, lowerbound -3.267864
[ Info: iteration 5, lowerbound -3.104874
[ Info: iteration 6, lowerbound -2.976184
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.889782
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.827725
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.779838
[ Info: iteration 10, lowerbound -2.757355
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.739795
[ Info: iteration 12, lowerbound -2.717546
[ Info: iteration 13, lowerbound -2.693256
[ Info: iteration 14, lowerbound -2.662882
[ Info: iteration 15, lowerbound -2.626749
[ Info: iteration 16, lowerbound -2.586063
[ Info: iteration 17, lowerbound -2.542877
[ Info: iteration 18, lowerbound -2.499736
[ Info: iteration 19, lowerbound -2.458893
[ Info: iteration 20, lowerbound -2.421482
[ Info: iteration 21, lowerbound -2.387366
[ Info: iteration 22, lowerbound -2.356192
[ Info: iteration 23, lowerbound -2.329489
[ Info: iteration 24, lowerbound -2.311862
[ Info: iteration 25, lowerbound -2.307688
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302918
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Feb  4 10:59:29 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Feb  4 10:59:38 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Tue Feb  4 10:59:40 2020: EM with 272 data points 0 iterations avll -2.056204
5.8 data points per parameter
, Tue Feb  4 10:59:42 2020: GMM converted to Variational GMM
, Tue Feb  4 10:59:50 2020: iteration 1, lowerbound -3.752668
, Tue Feb  4 10:59:50 2020: iteration 2, lowerbound -3.603036
, Tue Feb  4 10:59:50 2020: iteration 3, lowerbound -3.441827
, Tue Feb  4 10:59:50 2020: iteration 4, lowerbound -3.267864
, Tue Feb  4 10:59:50 2020: iteration 5, lowerbound -3.104874
, Tue Feb  4 10:59:50 2020: iteration 6, lowerbound -2.976184
, Tue Feb  4 10:59:51 2020: dropping number of Gaussions to 7
, Tue Feb  4 10:59:51 2020: iteration 7, lowerbound -2.889782
, Tue Feb  4 10:59:51 2020: dropping number of Gaussions to 5
, Tue Feb  4 10:59:51 2020: iteration 8, lowerbound -2.827725
, Tue Feb  4 10:59:51 2020: dropping number of Gaussions to 4
, Tue Feb  4 10:59:51 2020: iteration 9, lowerbound -2.779838
, Tue Feb  4 10:59:51 2020: iteration 10, lowerbound -2.757355
, Tue Feb  4 10:59:51 2020: dropping number of Gaussions to 3
, Tue Feb  4 10:59:51 2020: iteration 11, lowerbound -2.739795
, Tue Feb  4 10:59:51 2020: iteration 12, lowerbound -2.717546
, Tue Feb  4 10:59:51 2020: iteration 13, lowerbound -2.693256
, Tue Feb  4 10:59:51 2020: iteration 14, lowerbound -2.662882
, Tue Feb  4 10:59:51 2020: iteration 15, lowerbound -2.626749
, Tue Feb  4 10:59:51 2020: iteration 16, lowerbound -2.586063
, Tue Feb  4 10:59:51 2020: iteration 17, lowerbound -2.542877
, Tue Feb  4 10:59:51 2020: iteration 18, lowerbound -2.499736
, Tue Feb  4 10:59:51 2020: iteration 19, lowerbound -2.458893
, Tue Feb  4 10:59:51 2020: iteration 20, lowerbound -2.421482
, Tue Feb  4 10:59:51 2020: iteration 21, lowerbound -2.387366
, Tue Feb  4 10:59:51 2020: iteration 22, lowerbound -2.356192
, Tue Feb  4 10:59:51 2020: iteration 23, lowerbound -2.329489
, Tue Feb  4 10:59:51 2020: iteration 24, lowerbound -2.311862
, Tue Feb  4 10:59:51 2020: iteration 25, lowerbound -2.307688
, Tue Feb  4 10:59:51 2020: dropping number of Gaussions to 2
, Tue Feb  4 10:59:51 2020: iteration 26, lowerbound -2.302918
, Tue Feb  4 10:59:51 2020: iteration 27, lowerbound -2.299259
, Tue Feb  4 10:59:51 2020: iteration 28, lowerbound -2.299256
, Tue Feb  4 10:59:51 2020: iteration 29, lowerbound -2.299254
, Tue Feb  4 10:59:51 2020: iteration 30, lowerbound -2.299254
, Tue Feb  4 10:59:51 2020: iteration 31, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 32, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 33, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 34, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 35, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 36, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 37, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 38, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 39, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 40, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 41, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 42, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 43, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 44, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 45, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 46, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 47, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 48, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 49, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: iteration 50, lowerbound -2.299253
, Tue Feb  4 10:59:51 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260783, 95.9549077739219]
β = [178.0450922260783, 95.9549077739219]
m = [4.250300733269385 79.2868669443541; 2.000229257774829 53.85198717245846]
ν = [180.0450922260783, 97.9549077739219]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547477435 -0.007644049042334219; 0.0 0.008581705166323606], [0.3758763611957352 -0.008953123827356852; 0.0 0.012748664777411852]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9961604145625379
avll from llpg:  -0.9961604145625012
avll direct:     -0.9961604145625012
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0119436967862143
avll from llpg:  -1.0119436967862143
avll direct:     -1.0119436967862143
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0402196   -0.146534      0.102857     0.0597665     0.095527     0.0479766   0.0868647   -0.0923634    0.0716248    0.165525     0.0796586   -0.0241       0.0289908    0.0179567    0.0672187   -0.0687261   -0.0804758    0.100678    -0.100867   -0.0732625   -0.0390887    0.119333     0.135076    -0.035042     0.0935222   -0.0336924
 -0.250024     0.0550858    -0.0279632    0.110682      0.066939    -0.0747733  -0.019671     0.0297042   -0.0814329    0.160693     0.0736166   -0.0886135   -0.073261    -0.00764095  -0.105884     0.151007     0.0406238   -0.0215602    0.0793068   0.0187003   -0.0485768   -0.0321177    0.0362732   -0.116584     0.00166361   0.172524
  0.0826746    0.150938      0.0111484   -0.0373244     0.241933     0.132074    0.00265329  -0.220065     0.163394     0.0665252   -0.129398     0.0351317   -0.147553    -0.0913839    0.0405482    0.13206     -0.168182    -0.0112279   -0.0437243  -0.150861    -0.0812998   -0.10053      0.055769    -0.0598446   -0.0629223   -0.115486
  0.00177926   0.073201     -0.134749    -0.0410199    -0.0347752    0.18102    -0.152894     0.13247      0.112333    -0.0515041   -0.0539318   -0.0759856   -0.0934306   -0.125775     0.0270729   -0.180363    -0.135434    -0.198459    -0.0735878   0.0154622   -0.0320521    0.0487509   -0.15458      0.150409     0.0340341   -0.00885904
  0.0807353   -0.049714      0.104732     0.0555995     0.108857    -0.191226    0.0440018    0.100568    -0.241401    -0.0367178    0.0194291    0.140219    -0.105863    -0.0888761   -0.0490652    0.0126487    0.121585    -0.0982475    0.248811   -0.163932    -0.0949688    0.00244826   0.156945     0.181997    -0.207045    -0.211414
 -0.114622    -0.0696176    -0.126149    -0.052128     -0.014694     0.312304    0.0306449   -0.0792276   -0.094306    -0.0142218    0.149118     0.0306932    0.045248    -0.176472    -0.0787935   -0.0874982   -0.0574136   -0.043283     0.0680648  -0.17134      0.0512228   -0.00508897   0.0613273   -0.00773011  -0.0612436   -0.137359
 -0.0480263    0.0103884     0.0557689    0.027038      0.0879455   -0.0502514  -0.0165845   -0.0497247   -0.0298059   -0.0283913   -0.189328     0.117904     0.0873427   -0.0123431   -0.164336    -0.0621776   -0.0619717   -0.0213528    0.0849903   0.0531119    0.165201     0.184405     0.130928     0.0927616   -0.112437     0.0568593
 -0.0267853    0.0330207    -0.225689     0.0420075     0.0663267   -0.0549938   0.159025     0.11397      0.114841    -0.0420211    0.109889    -0.126266    -0.0615506    0.0650226   -0.0859437    0.0057008   -0.241859    -0.111228    -0.146895    0.115768     0.0769642    0.171873     0.0191581   -0.0361876    0.0491988   -0.0447794
  0.0711296   -0.03667       0.075352     0.0698549    -0.0109855    0.0173973  -0.0195272    0.187688     0.0350485    0.0482121    0.0151003   -0.0903668   -0.0926829   -0.0133311    0.199702    -0.0146287   -0.149173    -0.243832    -0.0155548   0.103534    -0.073152    -0.00922024   0.128185    -0.0109843    0.0970608   -0.117468
  0.0186401    0.132107      0.00789802   0.0359008     0.0919793    0.0357445  -0.10911     -0.13381     -0.102115    -0.125255    -0.0863068   -0.0627161    0.0296402   -0.131924    -0.0905968    0.0982331    0.186117     0.100275    -0.127867   -0.0425262   -0.0391704    0.0352699   -0.0427569   -0.00396701  -0.0806079   -0.131586
 -0.0399728   -0.279942      0.192521     0.0679758     0.0889156   -0.101325   -0.0667568   -0.02511     -0.0160075   -0.0205271   -0.0776836    0.146755     0.00134592   0.0361807   -0.0076907    0.0768054   -0.0117709   -0.0636993   -0.0923852   0.0664416   -0.15567     -0.00132268  -0.105446    -0.139504    -0.0351037   -0.0653659
  0.0248026    0.139376     -0.0182592   -0.0797117    -0.134858     0.039562    0.180488    -0.0629997    0.0683083    0.0386391   -0.0698121    0.12336      0.0615931   -0.118358     0.0998532   -0.190694    -0.0420097    0.182096    -0.0609411  -0.0800447   -0.0503294   -0.0283033    0.049523     0.00131207  -0.184571    -0.028764
  0.153958    -0.115699      0.0849406   -0.0285729     0.0971544    0.0292274  -0.0217418   -0.00796476  -0.0365182    0.105431     0.0855442   -0.106494     0.0314717    0.00848324   0.0705295    0.0493147   -0.0540179    0.24562      0.0229882  -0.0701283   -0.0722055    0.189576    -0.133832    -0.183632    -0.131038     0.0201157
 -0.355296    -0.121345      0.187041    -0.0662003     0.049364    -0.17831     0.192231     0.104542    -0.0600562    0.0340023    0.0124197   -0.126868     0.0374295   -0.00384375  -0.178845     0.0719433   -0.0181918    0.0563543   -0.0396094   0.0770852   -0.0576738    0.0425857   -0.0943626   -0.106884    -0.0322768    0.224222
  0.203877    -0.0275837    -0.0976654   -0.0159765     0.0601515   -0.0666839   0.00982733   0.0522569   -0.0363036   -0.209771    -0.0474925   -0.0181687    0.126406     0.0871256   -0.00670254  -0.0839953   -0.170197    -0.121806    -0.190738    0.0789878    0.153467     0.131972     0.00252738   0.0113564    0.17699      0.0150194
  0.0679249    0.118635     -0.0105171   -0.000494111  -0.127133    -0.0364567  -0.0800888    0.110913    -0.213874     0.219428    -0.0649799   -0.0348419   -0.0829791   -0.114267    -0.219487    -0.100741     0.0918004    0.0313751   -0.113454   -0.199516     0.189696     0.0292628    0.0879643   -0.061386    -0.0441417    0.155536
  0.0548121   -0.107729      0.280624     0.0833878    -0.13202      0.0253936   0.0264021   -0.108545    -0.0375516   -0.0239487    0.0628924   -0.0106683    0.0445881   -0.231406     0.106558     0.115381    -0.170428    -0.0880945   -0.10567     0.180929    -0.00797563  -0.0824169   -0.200271    -0.0313237    0.0974648   -0.0440886
  0.117959     0.0535775    -0.114207    -0.0426244    -0.133236    -0.0140569  -0.0022638   -0.064436     0.0859988   -0.0871657   -0.0284867   -0.134024    -0.0283683   -0.0314074    0.13224     -0.135222     0.0336406    0.0697087   -0.0316982   0.026162     0.109005     0.0979388    0.0275466    0.0603242   -0.0335831    0.159277
 -0.236455     0.152555      0.318411     0.0333556     0.0289381   -0.03931    -0.0808171   -0.112599     0.168665    -0.196995     0.122936     0.136222     0.0127712    0.02203     -0.154128     0.00439742   0.0498323    0.0942342   -0.196789   -0.0698488   -0.00598022  -0.058926    -0.178967     0.0942678   -0.0314974   -0.140005
 -0.0860725    0.0227807     0.0533884    0.0198373     0.119753    -0.0126958   0.127428    -0.0653895    0.0474178    0.241226     0.172195    -0.133887     0.102478     0.282485    -0.137064     0.0926854   -0.0480143   -0.00715444  -0.104553   -0.0429313   -0.0955231    0.0980217    0.114972    -0.160229    -0.0712631    0.0681663
  0.168668     0.0262425     0.00425215  -0.0263418    -0.116215    -0.127814   -0.0197607   -0.00988205   0.142263     0.0526406   -0.187787     0.0550607    0.0720877   -0.0906566   -0.0367681   -0.0237505   -0.233816    -0.100591    -0.152717   -0.0442397    0.135046     0.0565123    0.0509227   -0.00516908  -0.0111349    0.000276786
 -0.0551058    0.00781228   -0.00252396  -0.0937731    -0.0518855   -0.0601177   0.203014    -0.047995    -0.00769822  -0.136231    -0.0802459   -0.00145007  -0.0773811    0.117138     0.0524357   -0.0092396   -0.0798042   -0.235624     0.122601   -0.0391863   -0.0595216   -0.126638     0.0254687   -0.0645637   -0.0800715    0.0362059
 -0.10234      0.0996576    -0.0656226   -0.124937      0.0248429   -0.0697052   0.103737     0.19435      0.00471401  -0.26947     -0.00598672  -0.0167515   -0.0909467   -0.0463574    0.0430603   -0.0653378   -0.0383568   -0.110398     0.0327872   0.112234    -0.0565732   -0.135256    -0.137083    -0.08286      0.00736783   0.0734246
 -0.0716338    0.10273       0.0144221    0.00628055    0.116706    -0.204737    0.180244     0.0317821    0.0670026   -0.00888135   0.0192211   -0.188388     0.0407295    0.0787306   -0.022674    -0.073404    -7.24579e-5   0.0354322   -0.111913    0.1162      -0.0577246   -0.243814     0.0725807    0.0356448   -0.0789646   -0.000280962
  0.106037     0.0455438     0.0301856   -0.0267622    -0.0908842   -0.0179718   0.168345    -0.177232     0.0212301   -0.0908236    0.137489     0.0296446   -0.0162303    0.0812343    0.184698     0.00317777   0.0311456   -0.0756672    0.0561494   0.00162082   0.0368033    0.180448    -0.043933     0.212772     0.138516     0.0244493
  0.120935     0.0860836     0.0285024    0.0099965    -0.0316927   -0.0187564  -0.0778364   -0.0967597    0.23948      0.0469674   -0.122501     0.0499898   -0.0359647   -0.210096    -0.0215422    0.0284843    0.00960826   0.020075    -0.0680394   0.177187    -0.039459     0.222336    -0.144564     0.0827497   -0.177609    -0.0513482
 -0.012746    -0.0165806    -0.110408     0.180654     -0.0356887    0.130377   -0.0966173   -0.204511     0.038041    -0.203805    -0.0436084   -0.0634622   -0.157575    -0.115574     0.0504342    0.190026     0.0373856   -0.0339906    0.179658    0.0421828    0.0162817    0.122079     0.0569047   -0.0388998   -0.0480663   -0.147349
  0.00577047   0.000509437   0.029233     0.0951644    -0.192871     0.0891091   0.129843     0.0103287   -0.0713711   -0.15574     -0.150598     0.0463536    0.0877384    0.12149     -0.126725    -0.0864629   -0.0261278    0.0162294    0.0705997   0.268992     0.0161978   -0.0795657    0.154609     0.172267    -0.104806    -0.131811
 -0.0450738    0.0658718     0.0304596    0.0862291    -0.106737    -0.0870809   0.110791     0.0565006    0.110756    -0.0099922   -0.275693     0.111963     0.0122316   -0.0989982   -0.300335     0.0193707   -0.0488198   -0.0162344    0.15301    -0.0447678    0.14344      0.0636204    0.0417285    0.132704     0.141528    -0.108991
 -0.0305149   -0.0796966    -0.102661     0.207345      0.00132347   0.0966992   0.10916     -0.127279     0.122547    -0.0239246   -0.035607    -0.00963077  -0.137031    -0.07862     -0.129423     0.193939     0.063469    -0.0162274   -0.118573   -0.17779     -0.103675     0.038228    -0.0792627    0.0157868    0.0745018    0.131286
  0.0667314   -0.113036      0.193648    -0.127727     -0.0556441   -0.0792031  -0.170977     0.190521    -0.0609048    0.0273186   -0.147228     0.018636     0.0328114   -0.0412343   -0.119388    -0.120787    -0.112934     0.051098     0.0403065   0.0058934   -0.0445063    0.0157377    0.0485216   -0.160277     0.00328788  -0.0383109
  0.0968715    0.108524      0.0869214   -0.00331886   -0.0514822    0.0748433  -0.0843317    0.0437893   -0.00282707  -0.00501605   0.0515271    0.0188065   -0.100219     0.0919485   -0.107201     0.0201732   -0.131176    -0.0278152   -0.0741221  -0.0222828    0.137623    -0.0222179   -0.23549     -0.0529644   -0.00520268  -0.0873579kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.424684810830926
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424805
[ Info: iteration 2, average log likelihood -1.424681
[ Info: iteration 3, average log likelihood -1.423919
[ Info: iteration 4, average log likelihood -1.417199
[ Info: iteration 5, average log likelihood -1.402209
[ Info: iteration 6, average log likelihood -1.395742
[ Info: iteration 7, average log likelihood -1.393706
[ Info: iteration 8, average log likelihood -1.392142
[ Info: iteration 9, average log likelihood -1.390674
[ Info: iteration 10, average log likelihood -1.389317
[ Info: iteration 11, average log likelihood -1.388035
[ Info: iteration 12, average log likelihood -1.386591
[ Info: iteration 13, average log likelihood -1.384952
[ Info: iteration 14, average log likelihood -1.383706
[ Info: iteration 15, average log likelihood -1.383077
[ Info: iteration 16, average log likelihood -1.382801
[ Info: iteration 17, average log likelihood -1.382677
[ Info: iteration 18, average log likelihood -1.382617
[ Info: iteration 19, average log likelihood -1.382586
[ Info: iteration 20, average log likelihood -1.382569
[ Info: iteration 21, average log likelihood -1.382559
[ Info: iteration 22, average log likelihood -1.382553
[ Info: iteration 23, average log likelihood -1.382549
[ Info: iteration 24, average log likelihood -1.382547
[ Info: iteration 25, average log likelihood -1.382545
[ Info: iteration 26, average log likelihood -1.382544
[ Info: iteration 27, average log likelihood -1.382543
[ Info: iteration 28, average log likelihood -1.382543
[ Info: iteration 29, average log likelihood -1.382543
[ Info: iteration 30, average log likelihood -1.382543
[ Info: iteration 31, average log likelihood -1.382542
[ Info: iteration 32, average log likelihood -1.382542
[ Info: iteration 33, average log likelihood -1.382542
[ Info: iteration 34, average log likelihood -1.382542
[ Info: iteration 35, average log likelihood -1.382542
[ Info: iteration 36, average log likelihood -1.382542
[ Info: iteration 37, average log likelihood -1.382542
[ Info: iteration 38, average log likelihood -1.382542
[ Info: iteration 39, average log likelihood -1.382542
[ Info: iteration 40, average log likelihood -1.382542
[ Info: iteration 41, average log likelihood -1.382542
[ Info: iteration 42, average log likelihood -1.382542
[ Info: iteration 43, average log likelihood -1.382542
[ Info: iteration 44, average log likelihood -1.382542
[ Info: iteration 45, average log likelihood -1.382542
[ Info: iteration 46, average log likelihood -1.382542
[ Info: iteration 47, average log likelihood -1.382542
[ Info: iteration 48, average log likelihood -1.382542
[ Info: iteration 49, average log likelihood -1.382542
[ Info: iteration 50, average log likelihood -1.382542
┌ Info: EM with 100000 data points 50 iterations avll -1.382542
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.424805380428013
│     -1.424680590366809
│      ⋮
└     -1.382542158322766
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382703
[ Info: iteration 2, average log likelihood -1.382549
[ Info: iteration 3, average log likelihood -1.381872
[ Info: iteration 4, average log likelihood -1.375108
[ Info: iteration 5, average log likelihood -1.355919
[ Info: iteration 6, average log likelihood -1.342910
[ Info: iteration 7, average log likelihood -1.339390
[ Info: iteration 8, average log likelihood -1.338425
[ Info: iteration 9, average log likelihood -1.338090
[ Info: iteration 10, average log likelihood -1.337951
[ Info: iteration 11, average log likelihood -1.337884
[ Info: iteration 12, average log likelihood -1.337847
[ Info: iteration 13, average log likelihood -1.337825
[ Info: iteration 14, average log likelihood -1.337809
[ Info: iteration 15, average log likelihood -1.337798
[ Info: iteration 16, average log likelihood -1.337789
[ Info: iteration 17, average log likelihood -1.337781
[ Info: iteration 18, average log likelihood -1.337773
[ Info: iteration 19, average log likelihood -1.337765
[ Info: iteration 20, average log likelihood -1.337757
[ Info: iteration 21, average log likelihood -1.337748
[ Info: iteration 22, average log likelihood -1.337738
[ Info: iteration 23, average log likelihood -1.337725
[ Info: iteration 24, average log likelihood -1.337708
[ Info: iteration 25, average log likelihood -1.337684
[ Info: iteration 26, average log likelihood -1.337653
[ Info: iteration 27, average log likelihood -1.337612
[ Info: iteration 28, average log likelihood -1.337560
[ Info: iteration 29, average log likelihood -1.337496
[ Info: iteration 30, average log likelihood -1.337415
[ Info: iteration 31, average log likelihood -1.337312
[ Info: iteration 32, average log likelihood -1.337186
[ Info: iteration 33, average log likelihood -1.337037
[ Info: iteration 34, average log likelihood -1.336880
[ Info: iteration 35, average log likelihood -1.336745
[ Info: iteration 36, average log likelihood -1.336647
[ Info: iteration 37, average log likelihood -1.336581
[ Info: iteration 38, average log likelihood -1.336536
[ Info: iteration 39, average log likelihood -1.336505
[ Info: iteration 40, average log likelihood -1.336483
[ Info: iteration 41, average log likelihood -1.336466
[ Info: iteration 42, average log likelihood -1.336454
[ Info: iteration 43, average log likelihood -1.336445
[ Info: iteration 44, average log likelihood -1.336438
[ Info: iteration 45, average log likelihood -1.336432
[ Info: iteration 46, average log likelihood -1.336428
[ Info: iteration 47, average log likelihood -1.336425
[ Info: iteration 48, average log likelihood -1.336422
[ Info: iteration 49, average log likelihood -1.336421
[ Info: iteration 50, average log likelihood -1.336419
┌ Info: EM with 100000 data points 50 iterations avll -1.336419
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3827025500143912
│     -1.3825487769776734
│      ⋮
└     -1.3364190503368494
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336672
[ Info: iteration 2, average log likelihood -1.336414
[ Info: iteration 3, average log likelihood -1.335726
[ Info: iteration 4, average log likelihood -1.330455
[ Info: iteration 5, average log likelihood -1.315394
[ Info: iteration 6, average log likelihood -1.302200
[ Info: iteration 7, average log likelihood -1.295988
[ Info: iteration 8, average log likelihood -1.291105
[ Info: iteration 9, average log likelihood -1.286908
[ Info: iteration 10, average log likelihood -1.284182
[ Info: iteration 11, average log likelihood -1.282693
[ Info: iteration 12, average log likelihood -1.281988
[ Info: iteration 13, average log likelihood -1.281622
[ Info: iteration 14, average log likelihood -1.281357
[ Info: iteration 15, average log likelihood -1.281116
[ Info: iteration 16, average log likelihood -1.280867
[ Info: iteration 17, average log likelihood -1.280612
[ Info: iteration 18, average log likelihood -1.280365
[ Info: iteration 19, average log likelihood -1.280114
[ Info: iteration 20, average log likelihood -1.279869
[ Info: iteration 21, average log likelihood -1.279649
[ Info: iteration 22, average log likelihood -1.279464
[ Info: iteration 23, average log likelihood -1.279314
[ Info: iteration 24, average log likelihood -1.279197
[ Info: iteration 25, average log likelihood -1.279107
[ Info: iteration 26, average log likelihood -1.279041
[ Info: iteration 27, average log likelihood -1.278992
[ Info: iteration 28, average log likelihood -1.278957
[ Info: iteration 29, average log likelihood -1.278931
[ Info: iteration 30, average log likelihood -1.278913
[ Info: iteration 31, average log likelihood -1.278899
[ Info: iteration 32, average log likelihood -1.278888
[ Info: iteration 33, average log likelihood -1.278879
[ Info: iteration 34, average log likelihood -1.278872
[ Info: iteration 35, average log likelihood -1.278866
[ Info: iteration 36, average log likelihood -1.278861
[ Info: iteration 37, average log likelihood -1.278857
[ Info: iteration 38, average log likelihood -1.278854
[ Info: iteration 39, average log likelihood -1.278851
[ Info: iteration 40, average log likelihood -1.278848
[ Info: iteration 41, average log likelihood -1.278846
[ Info: iteration 42, average log likelihood -1.278844
[ Info: iteration 43, average log likelihood -1.278843
[ Info: iteration 44, average log likelihood -1.278842
[ Info: iteration 45, average log likelihood -1.278841
[ Info: iteration 46, average log likelihood -1.278840
[ Info: iteration 47, average log likelihood -1.278839
[ Info: iteration 48, average log likelihood -1.278839
[ Info: iteration 49, average log likelihood -1.278838
[ Info: iteration 50, average log likelihood -1.278838
┌ Info: EM with 100000 data points 50 iterations avll -1.278838
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.336672095787272
│     -1.3364144757009977
│      ⋮
└     -1.2788379002357575
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.279173
[ Info: iteration 2, average log likelihood -1.278793
[ Info: iteration 3, average log likelihood -1.277149
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.263333
[ Info: iteration 5, average log likelihood -1.239318
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.217760
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.213637
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.213224
[ Info: iteration 9, average log likelihood -1.211180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.201526
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.212036
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.209609
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.204908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.205144
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.201320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.204147
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.200566
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.204422
[ Info: iteration 19, average log likelihood -1.209953
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.196941
[ Info: iteration 21, average log likelihood -1.207614
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.195924
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.193077
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.202445
[ Info: iteration 25, average log likelihood -1.217457
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.200647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.195588
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.199637
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.197644
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.196045
[ Info: iteration 31, average log likelihood -1.214869
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.199705
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.198113
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.199408
[ Info: iteration 35, average log likelihood -1.205169
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.192414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.203626
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.203039
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.199110
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.208234
[ Info: iteration 41, average log likelihood -1.202520
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.191496
[ Info: iteration 43, average log likelihood -1.202754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.192639
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.210602
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.206014
[ Info: iteration 47, average log likelihood -1.202703
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.191947
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.202709
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.199928
┌ Info: EM with 100000 data points 50 iterations avll -1.199928
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2791734712113774
│     -1.2787927945840327
│      ⋮
└     -1.1999284051527868
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.197416
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.190618
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.190836
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.150794
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106729
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110081
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.068264
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.110717
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076368
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     10
│     11
│     12
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.086523
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.067170
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     10
│     13
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.103511
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      8
│     11
│     12
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.077773
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071153
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      8
│     13
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.092788
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.097826
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.063070
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     12
│     13
│     16
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.098076
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      8
│     11
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.087253
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.086513
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      8
│     11
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.084463
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     16
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.092618
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.068270
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     13
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102356
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      8
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.086392
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.069625
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     12
│     13
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.094517
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.100348
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.059578
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     12
│     13
│     16
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.100379
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.093993
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.078045
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.087274
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     16
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.094528
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.063721
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.110103
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      8
│     11
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.084156
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.071422
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     13
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.094632
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     11
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.097221
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.062962
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│     11
│     13
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.098722
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      8
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.094653
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079370
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      8
│     12
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.077885
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     16
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.100471
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065707
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     17
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.102851
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      8
│     12
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.079564
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.076879
┌ Info: EM with 100000 data points 50 iterations avll -1.076879
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.197415936357653
│     -1.1906176169877611
│      ⋮
└     -1.0768793357567072
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.424684810830926
│     -1.424805380428013
│     -1.424680590366809
│     -1.4239194975166607
│      ⋮
│     -1.1028509982013233
│     -1.0795639927007887
└     -1.0768793357567072
32×26 Array{Float64,2}:
  0.00503928   0.108168     0.0364781    0.0218426    0.139593     0.0157425   -0.114345    -0.144086    -0.831305    -0.14451     -0.0868976    -0.0190004    0.129972    -0.100979    -0.000193154   0.0977031     0.155684      0.0460983   -0.127153    -0.0416602   -0.047852     0.254046     -0.0321455   -0.155688    -0.0950435    0.0185455
  0.0412602    0.156668    -0.013696     0.0637898    0.100895     0.0561774   -0.115268    -0.126517     0.437787    -0.104752    -0.105225     -0.0482783   -0.0744456   -0.165798    -0.19021       0.158145      0.229415      0.144188    -0.150083    -0.0540174   -0.0765761   -0.10855      -0.050188     0.0923456   -0.067729    -0.377553
 -0.0186701   -0.0413114   -0.115593     0.183146    -0.0400442    0.123154    -0.0538279   -0.201946     0.0249633   -0.204679    -0.0429366    -0.109247    -0.145045    -0.130093     0.0493329     0.163294      0.0364229    -0.0365052    0.176607    -0.0094671   -0.0032266    0.158131      0.0604887   -0.181324    -0.0483518   -0.187341
  0.321095     0.00630943  -0.300968    -0.0336044    0.120597     0.0437874   -0.0767687    0.397955     0.35858     -0.230025    -0.0516789     0.125374     0.13789      0.0470145    0.0394325     0.152822      0.0409734    -0.011244     0.302386    -0.00463233   0.0174006    0.107856      0.0707911    0.489279    -0.0477444    0.226418
  0.00528844  -0.129171     0.105538     0.00374414  -0.0132173   -0.0756071    0.0498927   -0.0967052    0.00159569  -0.0898653    0.0295475     0.0810147   -0.0168123    0.0507536    0.0792471     0.0396907     0.0132215    -0.068579    -0.0103746    0.0481438   -0.0695031    0.0969658    -0.0750735    0.0478924    0.0544864   -0.0296585
  0.0406992    0.0281767    0.00776084   0.0183517   -0.00632335  -0.0876676    0.0472989   -0.0406649    0.0787991    0.136835     0.0034677    -0.0417015    0.0837525    0.10273     -0.0888042     0.0307792    -0.152941     -0.063207    -0.138682    -0.0619943    0.0241264    0.0758331     0.0912645   -0.0702946   -0.0413361    0.0337043
 -0.250645     0.165058     0.323012     0.0302472    0.0244257    0.00943541  -0.0409517   -0.106078     0.158551    -0.230399     0.137873      0.137447     0.0111467    0.011265    -0.159517      0.000122111   0.0502773     0.0758051   -0.195129    -0.0529885    0.0194612   -0.0777896    -0.183486     0.0973032   -0.0253068   -0.1245
  0.00831242   0.0699488   -0.121135    -0.0406043   -0.0171783    0.176021    -0.153048     0.124344     0.109298    -0.0491319   -0.048516     -0.0732328   -0.0866586   -0.11402      0.0360317    -0.177329     -0.146124     -0.199411    -0.0836714    0.0173844   -0.0312591    0.0490038    -0.17164      0.149682     0.0436652   -0.016915
 -0.067825    -0.0355795   -0.130224    -0.0520334   -0.00124601   0.314774     0.0305202   -0.0662238   -0.092227    -0.0122753    0.152552      0.038091     0.0451962   -0.169531    -0.0647323    -0.0443531    -0.0549942    -0.0551762    0.0659006   -0.19619      0.0505118   -0.0026371     0.0384933    0.0611984   -0.0604856   -0.131816
 -0.0656888    0.00465904   0.0540181    0.0214495    0.0777465   -0.0568221   -0.0164199   -0.0690013   -0.0542862   -0.0519077   -0.189443      0.129442     0.0715502   -0.0268928   -0.165859     -0.0631958    -0.0007067    -0.0221275    0.0790614    0.0562712    0.155765     0.178999      0.112471     0.0855513   -0.117874     0.0665187
  0.0812024    0.165261     0.0829489   -0.0428057    0.23968      0.103858    -0.00350363  -0.253875     0.182002     0.0744717   -0.126641      0.0365598   -0.153562    -0.0828432    0.0359258     0.128133     -0.174431     -0.00615334  -0.0414767   -0.150115    -0.0787217   -0.100419      0.0535885   -0.0547332   -0.0691959   -0.126521
 -0.00916656  -0.0560172    0.0101287   -0.0523172    0.0986754    0.0644158    0.0643406   -0.127589     0.0480704   -0.146804    -0.10752       0.0230546   -0.187208     0.00138055   0.0692297     0.0394396    -0.16001      -0.0885363   -0.0155625   -0.0659756   -0.0971522   -0.0898756     0.00231609  -0.0695612   -0.0307075   -0.0219511
 -0.0354017    0.0568731    0.0511205    0.0854582   -0.109684    -0.0863854    0.116443     0.0571455    0.124415    -0.0114626   -0.255063      0.106663     0.00824323  -0.0985556   -0.297403      0.020759     -0.0431245    -0.0640706    0.0985529   -0.0298605    0.13338      0.0671668     0.0384092    0.128232     0.138794    -0.129254
 -0.251669     0.0618038   -0.0405196    0.112864     0.0874941   -0.067676    -0.0230192    0.0641445   -0.0528131    0.173896     0.0546434    -0.0848443   -0.066478    -0.0115842   -0.106218      0.132152      0.0414772    -0.0397706    0.0726631    0.018252    -0.0551016   -0.0249485     0.0326022   -0.1248       0.00664319   0.180042
 -0.1251      -0.118711     0.166726    -0.127222    -0.01274     -0.123575     0.00368255   0.17786     -0.0529648    0.0485111   -0.0717218    -0.0430235    0.0430518   -0.0163603   -0.16506      -0.0288654    -0.0535624     0.0465401   -0.00656392   0.0354737   -0.052328     0.0422141    -0.0211558   -0.1372      -0.00867778   0.0955324
  0.0681076    0.169935    -0.0127104    0.0169784   -0.12945     -0.0246924   -0.0649668    0.130946    -0.213538     0.231126    -0.0650646    -0.0449438   -0.096542    -0.129396    -0.213654     -0.108859      0.0933698    -0.0205082   -0.0996091   -0.185054     0.207957     0.0325801     0.0848983   -0.0469511   -0.0539166    0.138662
  0.117746     0.0960268    0.0265466   -0.0487167   -0.0330518   -0.0194202    0.00597279  -0.0928688    0.248309     0.0528177   -0.116288      0.0672146   -0.0155944   -0.196793    -0.0188718     0.0293182     0.000839432   0.0135977   -0.0819338    0.177114    -0.0164582    0.220554     -0.146591     0.0759388   -0.160588    -0.0533412
  0.128462     0.0607525   -0.117577    -0.0430722   -0.12972     -0.0359207    0.00813338  -0.0638013    0.089498    -0.0851134   -0.0439718    -0.115757    -0.0232713   -0.0257003    0.132429     -0.1341       -0.0283183     0.074494    -0.0713838    0.0205133    0.0995784    0.108069      0.0462205    0.0537366    0.0631877    0.163237
  0.105165    -0.0352589    0.0738316    0.0557393   -0.133362    -0.122556     0.215034     0.184686     0.00352931   0.0570027   -0.0259105    -0.0552825   -0.0911403   -0.0559221    0.199549     -0.00163455   -0.149772     -0.170811    -0.551888     0.091778    -0.0749789   -0.0381822     0.0543151   -0.00196079  -0.0215472   -0.10731
  0.0152815   -0.034783     0.0746902    0.0855224    0.157016     0.0640937   -0.228232     0.186997     0.0282293    0.0381647    0.000974907  -0.102925    -0.0921277    0.0833914    0.199483     -0.0332288    -0.153035     -0.36315      0.311461     0.108471    -0.077196     0.0574016     0.252465    -0.00868266   0.278249    -0.110825
 -0.111934     0.044196    -0.061541    -0.142994     0.0170677   -0.0553619    0.110904     0.199613     0.018556    -0.282093    -0.00705891   -0.0484941   -0.110638    -0.0471567    0.0546937    -0.0595305    -0.0405765    -0.196693     0.0510803    0.110093    -0.129647    -0.139369     -0.0998338   -0.0651827    0.00654484   0.0727439
 -0.0312088    0.0239982   -0.205236     0.0431091    0.077414    -0.112361     0.158651     0.0986826    0.109358    -0.0426183    0.130972     -0.16478     -0.0757277    0.0906846   -0.0786051     0.00692554   -0.258876     -0.100774    -0.145187     0.121962     0.0571701    0.174767      0.0245464   -0.0384163    0.0489123   -0.0316242
  0.150976    -0.157721     0.110902    -0.0351927    0.0906328    0.0260499   -0.00488848  -0.0147649   -0.0798398    0.0850545    0.0889531    -0.0993727    0.0297984    0.0455627    0.0559554     0.0506052    -0.0428747     0.243436     0.034068    -0.0766737   -0.0941122    0.166518     -0.148464    -0.215665    -0.139274     0.0298391
  0.0896951    0.0221868   -0.0534775   -0.0404631    0.00561393  -0.0482797    0.101395     0.0245104   -0.0331593   -0.187782    -0.0499372    -0.0125073    0.0577814    0.102255     0.0221177    -0.0534356    -0.128398     -0.168958    -0.0500068    0.0175155    0.058721     0.000455143   0.0173722   -0.0193255    0.0401481    0.0432142
  0.00431898   0.0212578    0.0286594    0.131335    -0.210658     0.0693189    0.137571     0.00941193  -0.0622772   -0.08614     -0.138784      0.0511928    0.087492     0.140908    -0.0880619    -0.112448     -0.00734664    0.035963     0.0800676    0.267553     0.00513031  -0.0822647     0.15537      0.182259    -0.107667    -0.126133
  0.0530864   -0.114336     0.287896     0.0866721   -0.141159     0.0282114    0.00846085  -0.10917     -0.029465    -0.0196288    0.0677287    -0.00747653   0.0414849   -0.235159     0.103227      0.126211     -0.147356     -0.11414     -0.0916105    0.180526    -0.00770874  -0.10621      -0.201987    -0.00177006   0.153725    -0.0501999
  0.0322341   -0.00321821   0.0467194   -0.0155878   -0.0181464    0.0549302    0.130585    -0.0747323    0.0812806    0.099891     0.00472772    0.0468126    0.0356421   -0.0451557    0.0893253    -0.153607     -0.073918      0.132849    -0.059233    -0.0769376   -0.0364949    0.0518933     0.108599    -0.0331786   -0.0558835   -0.0177377
  0.0602223   -0.056566     0.11942      0.0269973    0.102838    -0.202711     0.0446257    0.0702363   -0.244974    -0.0364657    0.0200912     0.139078    -0.119994    -0.0940873   -0.0385916     0.0146022     0.10292      -0.119936     0.303079    -0.153855    -0.0960714   -0.00217581    0.147498     0.173485    -0.224367    -0.168661
 -0.0691097    0.0582984    0.0156112   -0.00336113   0.115443    -0.198627     0.178152     0.0600559    0.0607735    0.0310669    0.0193892    -0.185467     0.0693089    0.0949637   -0.0120789    -0.132806      0.00708044    0.0328883   -0.115435     0.115595    -0.0201037   -0.230355      0.0831532    0.0454798   -0.0735746   -0.0216924
  0.0983665    0.113364     0.092242    -0.00614373  -0.0504389    0.0670104   -0.0925924    0.06071     -0.00637213  -0.0208698    0.0479055     0.0238425   -0.105223     0.173669    -0.0965061     0.0945337    -0.1424       -0.0391014   -0.0754473   -0.0229673    0.159745    -0.0365165    -0.24266     -0.0618397   -0.0714124   -0.144111
 -0.0321145   -0.0415405   -0.100929     0.204392     0.00184578   0.0226853    0.107189    -0.133615     0.132426    -0.00230317   0.0393204    -0.263636    -0.157438     0.00993709  -0.110467      0.0514433     0.102367      0.0403753   -0.10178     -0.228456    -0.105044    -0.0398022    -0.153274     0.328943    -0.224158     0.110394
 -0.0306052   -0.145121    -0.0263002    0.211872    -0.00994182   0.142095     0.106402    -0.105017     0.154038    -0.0672676   -0.102784      0.280563    -0.0764237   -0.194698    -0.163544      0.255766      0.0126239    -0.087754    -0.119318    -0.123286    -0.102925     0.130988     -0.0100266   -0.285456     0.334142     0.156337[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     13
│     19
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.091461
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.061898
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.062131
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      8
│     11
│     13
│     17
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.079417
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072994
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.050350
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.076621
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      8
│     11
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.063528
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.042461
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063221
┌ Info: EM with 100000 data points 10 iterations avll -1.063221
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.903265e+05
      1       6.984722e+05      -1.918543e+05 |       32
      2       6.654968e+05      -3.297544e+04 |       32
      3       6.456571e+05      -1.983967e+04 |       32
      4       6.336512e+05      -1.200587e+04 |       32
      5       6.266210e+05      -7.030225e+03 |       32
      6       6.235184e+05      -3.102640e+03 |       32
      7       6.220899e+05      -1.428436e+03 |       32
      8       6.213049e+05      -7.850589e+02 |       32
      9       6.207819e+05      -5.229698e+02 |       32
     10       6.203996e+05      -3.823105e+02 |       32
     11       6.200789e+05      -3.206635e+02 |       32
     12       6.198610e+05      -2.179405e+02 |       32
     13       6.196695e+05      -1.915076e+02 |       32
     14       6.194979e+05      -1.715958e+02 |       32
     15       6.193430e+05      -1.548917e+02 |       32
     16       6.192041e+05      -1.389349e+02 |       32
     17       6.190850e+05      -1.190829e+02 |       32
     18       6.189847e+05      -1.002732e+02 |       32
     19       6.188838e+05      -1.008908e+02 |       32
     20       6.187785e+05      -1.052882e+02 |       32
     21       6.186832e+05      -9.527503e+01 |       31
     22       6.185934e+05      -8.985435e+01 |       30
     23       6.185233e+05      -7.006435e+01 |       32
     24       6.184693e+05      -5.405294e+01 |       29
     25       6.184188e+05      -5.049635e+01 |       29
     26       6.183694e+05      -4.935788e+01 |       32
     27       6.183199e+05      -4.951232e+01 |       31
     28       6.182586e+05      -6.133729e+01 |       30
     29       6.181632e+05      -9.539712e+01 |       31
     30       6.179632e+05      -2.000186e+02 |       32
     31       6.175344e+05      -4.287697e+02 |       32
     32       6.170231e+05      -5.112316e+02 |       32
     33       6.166242e+05      -3.989811e+02 |       31
     34       6.164016e+05      -2.225471e+02 |       31
     35       6.162846e+05      -1.170023e+02 |       30
     36       6.162117e+05      -7.289652e+01 |       31
     37       6.161581e+05      -5.366072e+01 |       31
     38       6.161187e+05      -3.936318e+01 |       31
     39       6.160785e+05      -4.023385e+01 |       31
     40       6.160511e+05      -2.731777e+01 |       28
     41       6.160259e+05      -2.524648e+01 |       27
     42       6.160032e+05      -2.273528e+01 |       30
     43       6.159867e+05      -1.649231e+01 |       24
     44       6.159731e+05      -1.356441e+01 |       26
     45       6.159646e+05      -8.550955e+00 |       26
     46       6.159579e+05      -6.622901e+00 |       29
     47       6.159504e+05      -7.554881e+00 |       27
     48       6.159452e+05      -5.192259e+00 |       24
     49       6.159399e+05      -5.306161e+00 |       26
     50       6.159334e+05      -6.509488e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 615933.3712967248)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329996
[ Info: iteration 2, average log likelihood -1.300950
[ Info: iteration 3, average log likelihood -1.271901
[ Info: iteration 4, average log likelihood -1.239138
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.197632
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.153200
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123369
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     17
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081524
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     16
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.090414
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     14
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.115202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.118304
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.088941
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.096879
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.048665
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.126355
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.120879
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.094657
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.069363
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.047623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.143669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.092249
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.074142
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      7
│     10
│      ⋮
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.045438
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.145096
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120787
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.091467
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     10
│     14
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.021162
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.119151
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│     11
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.123045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.126422
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     14
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.066773
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.061196
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     16
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.058828
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.134809
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.084525
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.082777
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      6
│     11
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.062693
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     16
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090692
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.093737
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     14
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.105717
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.070856
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     12
│     16
│      ⋮
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.024495
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     14
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.091915
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.132240
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.106358
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.057399
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│     19
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.059501
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     16
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098834
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.110133
┌ Info: EM with 100000 data points 50 iterations avll -1.110133
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0598961    -0.0244899  -0.121604     -0.0439284    -0.00901904   0.287405     0.035071     -0.0609067   -0.0684912   -0.0108161     0.154629    0.0326711    0.046926     -0.149804    -0.0593065   -0.045537    -0.0595111   -0.0563525    0.0418356  -0.177268     0.0503703    0.00474169   0.0386695    0.0618611   -0.0523899    -0.12273
  0.0941012     0.0409807   0.00740135   -0.0456547    -0.0933153   -0.0302563    0.173814     -0.163301     0.00803565  -0.169902      0.136248    0.0269936   -0.0323766     0.0598344    0.189518     0.00411729   0.0344272   -0.0783729    0.0548289   0.0319337    0.0303308    0.180085    -0.0408789    0.211845     0.14355       0.0192724
 -0.0585241    -0.280064    0.188862      0.0571385     0.083077    -0.102088    -0.0722023    -0.0210627   -0.00740077  -0.0327552    -0.0810808   0.145595    -0.000742636   0.0391493   -0.0367843    0.0690558   -0.0123302   -0.064974    -0.0820347   0.0611194   -0.162901     0.00936276  -0.106202    -0.124425    -0.0357233    -0.0880173
  0.00432076    0.0212868   0.028637      0.131703     -0.210808     0.0693284    0.137477      0.00942112  -0.062549    -0.086018     -0.138753    0.0510802    0.0874628     0.140642    -0.0879861   -0.112182    -0.00726175   0.0361027    0.0800877   0.267514     0.00543929  -0.0823918    0.155394     0.182168    -0.107674     -0.126022
  0.000900291   0.0700752   0.0711484     0.0860462    -0.142554    -0.103108     0.105819      0.0766666    0.122129    -0.000211717  -0.290283    0.12045      0.0102591    -0.124887    -0.28423      0.00749691  -0.0560894   -0.0460591    0.0587747  -0.032159     0.141071     0.0634821    0.0484616    0.108533     0.114376     -0.133297
 -0.0529397     0.0300803   0.0462246     0.0132128     0.0744327   -0.0440853   -0.00928456   -0.0473644   -0.128109    -0.0651102    -0.165275    0.15455      0.0723858    -0.0304385   -0.19142     -0.0672313    0.0207016   -0.0213003    0.0668231   0.0806694    0.18118      0.166996     0.127058     0.138134    -0.10965       0.0882391
  0.107813      0.0887305   0.0190926    -0.0520711    -0.0314365   -0.0135374    0.0144418    -0.0806089    0.237529     0.0435466    -0.0995127   0.0517528   -0.0241048    -0.19489     -0.017346     0.0285051   -0.0136012    0.00404632  -0.082941    0.173356    -0.0149305    0.217777    -0.139846     0.07055     -0.143514     -0.0529795
 -0.25093       0.0619155  -0.0418482     0.113005      0.0863472   -0.0674062   -0.0230543     0.0666986   -0.052072     0.173276      0.0540677  -0.082139    -0.0661663    -0.011754    -0.106308     0.131834     0.0414278   -0.040035     0.0707809   0.0183208   -0.0547532   -0.0246908    0.0326815   -0.124561     0.00591949    0.180022
  0.0565971    -0.10569     0.125158     -0.147965     -0.055223    -0.0756569   -0.144402      0.204209    -0.0507449    0.0829784    -0.145359    0.0309788    0.0363687    -0.0362388   -0.114219    -0.114692    -0.0949036    0.0337681    0.0328979  -0.00983963  -0.0500256    0.0368464    0.0705403   -0.145584     0.000654316  -0.0177847
  0.130989     -0.190776    0.0887235    -0.0322912     0.0816981    0.0473949   -0.0370585     0.0130303   -0.0608316    0.0834047     0.055973   -0.0886812    0.000441674   0.016887     0.0504743    0.0313936   -0.0608906    0.336907     0.0220992  -0.0751097   -0.099659     0.189765    -0.182286    -0.168762    -0.101039      0.0329416
  0.06577       0.11952     0.0695001    -0.0410386     0.207014     0.0941543    0.0104714    -0.231591     0.169076     0.0477437    -0.127511    0.0351098   -0.134657     -0.0458608    0.0190567    0.109922    -0.165751    -0.0177922   -0.0315736  -0.143025    -0.064087    -0.0899639    0.0436922   -0.057586    -0.0689914    -0.0956593
 -0.219998      0.15704     0.28588       0.0225532     0.0172841    0.0275466   -0.0559267    -0.0804646    0.150855    -0.206034      0.114193    0.116149     0.00855413   -0.00192443  -0.151839    -0.0228612    0.0450603    0.0566768   -0.18818    -0.0453172    0.0132415   -0.0680538   -0.180032     0.103343    -0.0195671    -0.113723
 -0.0678267     0.0223087   0.0168203     0.0376971     0.0989651   -0.00185748   0.1256       -0.0565621    0.0187662    0.20868       0.162068   -0.127275     0.093667      0.252632    -0.132744     0.084014    -0.0508075   -0.0439013   -0.120417   -0.0500435   -0.0855465    0.106173     0.102496    -0.127358    -0.0638552     0.0805401
  0.120231      0.0295293  -0.0341615    -0.0168822    -0.105259    -0.296037     0.0141377    -0.0183635    0.135339     0.00155615   -0.300783    0.042039     0.055186     -0.0692116   -0.0201344   -0.0207748   -0.314596    -0.134193    -0.102111   -0.0563275    0.109405     0.0302601    0.124199    -0.02136     -0.00922535    0.00775943
  0.0523036    -0.116547    0.284101      0.0871217    -0.141048     0.030583     0.00789571   -0.109157    -0.0275597   -0.0209962     0.0653195  -0.00952901   0.0415134    -0.233498     0.103584     0.12721     -0.146321    -0.116764    -0.0910815   0.180441    -0.00826096  -0.104665    -0.201662    -0.00132803   0.152763     -0.0495638
  0.00777184   -0.0319677  -0.109547      0.188477     -0.0523393    0.100601    -0.0541168    -0.132905     0.00439336  -0.147368     -0.0472892  -0.163275    -0.152811     -0.124535     0.00167522   0.103558     0.0481008   -0.0380552    0.14596    -0.0581417    0.0347703    0.135835     0.0522855   -0.235596    -0.0736389    -0.128556
  0.0591005    -0.0343896   0.0735796     0.0677195     0.00596331  -0.0238045   -0.00321753    0.185522     0.0167835    0.049002     -0.0133966  -0.0772064   -0.0922728     0.0101114    0.198354    -0.019664    -0.15231     -0.271756    -0.133188    0.0992869   -0.0770553    0.0067966    0.147257    -0.00300091   0.123151     -0.108384
  0.0232904     0.139074    0.00285375    0.0487996     0.112948     0.0368521   -0.117417     -0.131898    -0.172362    -0.11838      -0.0970986  -0.0368967    0.0147093    -0.139729    -0.0990108    0.126262     0.177013     0.0932133   -0.128682   -0.0491761   -0.0542376    0.0726271   -0.035085     0.00186835  -0.0763516    -0.184404
  0.00360392    0.135903   -0.000495042  -0.0927369    -0.0306503   -0.0457373    0.161765     -0.0372567   -0.0296095   -0.0814552    -0.0200765  -0.0210636   -0.0489862     0.108848     0.0622758    0.00547238  -0.053654    -0.314755     0.0849445  -0.0236456   -0.0355164   -0.113495     0.0227907   -0.0997974   -0.150231      0.0884681
  0.126388      0.0636624  -0.119914     -0.0421645    -0.132814    -0.0326985    0.00676025   -0.0613804    0.0902977   -0.0836626    -0.0388904  -0.120134    -0.0255524    -0.0216923    0.13245     -0.132301    -0.03228      0.0721052   -0.075432    0.0217439    0.0916986    0.111706     0.0509663    0.0528149    0.0700818     0.161004
  0.0214494     0.117193   -0.0261986    -0.0544768    -0.114812     0.0571818    0.146991     -0.044287     0.0912575    0.0238722    -0.0673446   0.0919378    0.0317942    -0.115286     0.104471    -0.194076    -0.0681396    0.129816    -0.0113704  -0.0713709   -0.0357128   -0.0202875    0.0316629    0.0147297   -0.157674      0.00987319
 -0.0289158    -0.0924518  -0.0757815     0.208917     -0.00265002   0.0745388    0.102016     -0.115755     0.137742    -0.0308886    -0.040066    0.0818882   -0.138321     -0.0992188   -0.143678     0.145275     0.06033     -0.0421268   -0.122571   -0.193738    -0.0871768    0.0554532   -0.0579036    0.153592     0.101993      0.146106
  0.00994558    0.0785931   0.0472964     0.000111127   0.0383854   -0.0697433    0.0525558     0.0539724    0.0328124    0.000508299   0.0320429  -0.08359     -0.0206475     0.131948    -0.0543818   -0.0232455   -0.0613063   -0.00233802  -0.0943751   0.0469642    0.0539219   -0.1287      -0.0744644    0.00148574  -0.065318     -0.0678583
  0.0610523    -0.10388    -0.00613149    0.0432245     0.00649136  -0.0357511    0.0382981    -0.00255     -0.0110911   -0.0749512    -0.101561   -0.01806     -0.0651235     0.097634     0.115113     0.0452717   -0.167264    -0.168687    -0.0302342   0.0380214   -0.0706577    0.00648831  -0.182152     0.0787762    0.000561405   0.068927
 -0.107645      0.0435501  -0.0619014    -0.137353      0.0176819   -0.0553994    0.112206      0.196325     0.0209424   -0.276579      0.0011508  -0.0507395   -0.10825      -0.0463563    0.0555116   -0.0574666   -0.0467071   -0.19024      0.0460307   0.109965    -0.118715    -0.132955    -0.102012    -0.0665073    0.0117917     0.0728802
  0.0342714    -0.136717    0.0909234     0.0421477     0.0947508    0.0578613    0.0846839    -0.0865678    0.0784233    0.150736      0.0726028  -0.0298112    0.0253106     0.0232882    0.0605682   -0.0920141   -0.102967     0.0854317   -0.103489   -0.0695142   -0.0264632    0.120963     0.151869    -0.0458736    0.0841072    -0.0192272
  0.00615117    0.106244   -0.162273     -0.0347608    -0.0700907    0.130596    -0.162859      0.126514     0.13072     -0.0566493    -0.0788026  -0.0449693   -0.115914     -0.148567    -0.0125797   -0.152087    -0.121661    -0.483807    -0.100457   -0.00380067   0.0616931    0.0248647   -0.229417     0.162326     0.0564415    -0.0130418
  0.0525687    -0.0556939   0.111355      0.0233826     0.0992705   -0.195842     0.0506478     0.07056     -0.232779    -0.0396154     0.0211182   0.131663    -0.117026     -0.0847729   -0.0371546    0.0145244    0.0899583   -0.125617     0.292018   -0.150698    -0.091171    -0.00378659   0.149648     0.17516     -0.217942     -0.158708
  0.0409631     0.23408    -0.0307074     0.00320001   -0.142013    -0.0135474   -0.0555312     0.168641    -0.160043     0.283861     -0.0748816  -0.071042    -0.123886     -0.125765    -0.22461     -0.0982496    0.0804276    0.00824748  -0.141847   -0.16408      0.215193     0.0528029    0.0699733   -0.0506634   -0.0603919     0.128612
  0.200025     -0.0263525  -0.0871469    -0.00252658    0.0561756   -0.0496878    0.000859329   0.0616124   -0.0443463   -0.237228     -0.0398405  -0.0240854    0.178339      0.0880323   -0.0196952   -0.0839033   -0.16969     -0.114257    -0.20613     0.0683276    0.154207     0.130562     0.00866135  -0.00141759   0.170226      0.0184126
 -0.308779     -0.114918    0.182308     -0.0995918     0.0198882   -0.164459     0.177031      0.128446    -0.0609845    0.029962      0.0163302  -0.109513     0.0446591    -0.00162661  -0.201769     0.0701706    0.00271156   0.0484529   -0.0438478   0.0743526   -0.0521915    0.0490434   -0.118807    -0.113165    -0.0202982     0.230365
 -0.025429      0.0466037  -0.233891      0.0596943     0.136922    -0.0967167    0.13048       0.105772     0.100589    -0.0425546     0.262106   -0.210132    -0.0811772     0.192456    -0.0773987   -0.0064511   -0.261139    -0.117142    -0.132206    0.109017     0.0639011    0.150909     0.0179435   -0.0370119    0.0330448    -0.0218413[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     12
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.065619
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.001248
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     17
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.031121
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.002210
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     12
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.054125
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.990990
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     11
│     12
│     17
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.043507
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.991683
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     12
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.056359
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.999609
┌ Info: EM with 100000 data points 10 iterations avll -0.999609
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0302217     0.119932    -0.0598563   -0.21844      0.0517952   -0.138023    -0.0298054    0.0690443    0.00541712  -0.093774     0.0569081   -0.0840566   -0.0374298    0.0179385    0.0254343    0.127533     0.0337251    0.0515829   -0.0107491   -0.0668465     0.182206     -0.0752472   -0.292299      0.0436696    0.0859668     0.115523
  0.170042     -0.111751     0.0479037   -0.00164567  -0.0179372   -0.00362215   0.00123393   0.0770382   -0.0722723    0.0165873   -0.0709995   -0.244007     0.00030253  -0.0354892    0.0234867   -0.183657     0.0753807   -0.0299977    0.112963    -0.0071239    -0.00867753    0.0340544   -0.220095      0.00720255  -0.120505     -0.0398541
 -0.0551763    -0.0121956   -0.0329115   -0.0733553    0.144342    -0.155239     0.114454    -0.0416222   -0.00539406  -0.00777661   0.0309652    0.0407787    0.0313985    0.19835     -0.00246918   0.148446    -0.0260119    0.0292635    0.0779093    0.0290213     0.243399      0.0211785    0.0698097    -0.165351     0.0726624     0.126111
  0.123762      0.161354    -0.0409313    0.0742767   -0.164114     0.0495994    0.015153     0.206057     0.0326008    0.0418951    0.0252504    0.0706528    0.0652636    0.09176     -0.140067    -0.106659     0.178678     0.0853951    0.0621701    0.100711      0.115268      0.00922777   0.0817097     0.0162455    0.0309637    -0.0342202
  0.0888627    -0.17644     -0.00637707  -0.0437008    0.00650464   0.0631765    0.0758421    0.0148765    0.130513     0.0971189   -0.115662    -0.0697342   -0.00160386   0.0652885    0.0304757   -0.0452827    0.0896162    0.121269     0.14257      0.124034     -0.00422156    0.254006     0.0888283    -0.0104224    0.168437      0.0158115
  0.0759256     0.238613    -0.106188     0.00909396   0.0742923    0.0109841   -0.121597    -0.158925     0.12381      0.0270747    0.0802826    0.0126465   -0.0828987   -0.181991     0.272486     0.0968411   -0.0555034    0.0983255   -0.137682     0.00324218    0.121548      0.0194797   -0.049628     -0.031806     0.0411745     0.0263028
 -0.00483911    0.0563621   -0.0638455   -0.0793673   -0.0565349   -0.272468     0.0558912   -0.0287728   -0.102117    -0.0227845   -0.298999    -0.0221604    0.130913     0.0838004   -0.0118176   -0.0174239    0.166932    -0.0435351    0.0183822    0.144588      0.00318953    0.0582567    0.0261941    -0.01735      0.115663      0.2863
  0.0786079    -0.126958     0.083685     0.114032     0.0545725   -0.107235     0.00596482   0.0677526    0.0221063   -0.00313098  -0.16443      0.0328008    0.0727522    0.164359     0.0323591    0.0116741    0.0381161    0.0917032    0.141573    -0.0319264     0.139384      0.0534543    0.12009       0.157912     0.0510023    -0.0202123
 -0.0140755    -0.184973    -0.16523      0.0201318   -0.110972     0.0857888   -0.0750181    0.101349    -0.0926498    0.117125    -0.0241246    0.0029111    0.0621276   -0.0159942    0.156417    -0.0900443   -0.018063     0.138278     0.00370185   0.133014      0.0275422     0.0611191   -0.013226      0.0192721   -0.0136617    -0.0998874
 -0.121863     -0.010468     0.0164144   -0.111405     0.0655028    0.0603154    0.165166     0.076607     0.11039      0.0984522   -0.0724159    0.0111537   -0.0855047    0.114141     0.0796497   -0.174541     0.0162164    0.062635    -0.0367437   -0.113995      0.205455      0.0863073   -0.117759      0.120751     0.0920773     0.0593138
  0.0598339    -0.00451176   0.0255974   -0.104323     0.0644057   -0.074456    -0.180434     0.046963     0.149728    -0.209588    -0.00873011  -0.219178     0.132633    -0.0190464    0.188704    -0.120084     0.0788173    0.0695658    0.0013729   -0.246558     -0.0764691    -0.21537     -0.0570801     0.114502     0.0230148     0.051827
  0.0598492    -0.086015     0.097336    -0.0535867    0.133605     0.0982462    0.0161102   -0.244186     0.0505403    0.057499     0.156485    -0.0362288   -0.00795223   0.0658135   -0.100735    -0.112186    -0.070481    -0.239957     0.0381284   -0.201364     -0.0313346    -0.0870279   -0.189269      0.13779     -0.0149128    -0.0823111
 -0.193927     -0.0519146   -0.00675124   0.105745    -0.168212    -0.127777     0.0375446    0.00586914  -0.145532    -0.0337548   -0.0670965    0.0630847    0.0572149   -0.0869756   -0.018425     0.0421875    0.0188769    0.0993256    0.147812    -0.083424     -0.110996     -0.0600779   -0.0900775    -0.0133942    0.0631566    -0.00326295
  0.0285519     0.0266464   -0.0563913   -0.0286264    0.251206     0.156616    -0.0870478   -0.0604172    0.141113    -0.0287342    0.104493     0.0370782    0.0212451    0.380623     0.0078792    0.129861    -0.103512     0.0226482   -0.123676     0.175123     -0.0496898     0.0125994    0.211682     -0.169443     0.112512     -0.186391
  0.178787      0.120994    -0.125224    -0.0390194   -0.0564708   -0.113769    -0.165875    -0.0433069    0.204516    -0.125892    -0.0451297    0.0741485    0.0296773   -0.00749129   0.0323638   -0.0331286    0.00126449   0.0616842   -0.00272292   0.041337     -0.134892      0.194511    -0.0390051    -0.0759842   -0.0904192    -0.128006
  0.0287351     0.0312168    0.152177    -0.0570134   -0.0778715   -0.00376864   0.054515    -0.228048     0.14556      0.0635461    0.035005    -0.0523007    0.0302369   -0.0791517   -0.0916161   -0.160656    -0.0433662    0.0559147   -0.17178     -0.0852373    -0.13999       0.022676     0.131246      0.120709     0.0553027    -0.0364571
  0.0549007    -0.00200837   0.0306636   -0.26066     -0.0653644    0.237008    -0.010171     0.108214     0.108909     0.0181914    0.0918865    0.00706119  -0.0760431    0.154501    -0.0544609   -0.105602     0.046736    -0.105086    -0.202837     0.096759     -0.12323       0.0483014    0.0418095    -0.001101    -0.17507       0.271347
 -0.0700588     0.0489384   -0.0827682   -0.258506    -0.13676      0.149247     0.150381    -0.0962871    0.0311999   -0.0372295    0.119303     0.0890162    0.0693343   -0.0731727   -0.0338561   -0.0839841   -0.0930382   -0.131083     0.132327    -0.0484179     0.0642089    -0.0887312    0.0393487    -0.0882037    0.0343332     0.00332688
  0.0472212     0.0148597   -0.00852194   0.160818     0.0890678    0.0362291   -0.117579     0.140669    -0.0333062    0.0347775   -0.0383949    0.0229968   -0.100804    -0.00315768  -0.0486205    0.117634     0.028159    -0.114861    -0.245352     0.0563873     0.000105275  -0.00267085   0.0671302     0.133517    -0.0334054     0.150802
  0.213749     -0.00208398   0.0838975   -0.0525936    0.0244902   -0.119146     0.00438351   0.157373    -0.0556239    0.087416    -0.0660167    0.0298291   -0.0707975    0.104916    -0.131826     0.0273747   -0.0278773   -2.64048e-5  -0.0264032   -0.0392145     0.161659      0.0134679    0.257402     -0.00640322   0.138572     -0.0617858
  0.0109405    -0.0746462    0.20611     -0.011482    -0.135395    -0.0919211    0.0619091   -0.168893     0.0564352    0.042046    -0.0620621   -0.0522792    0.150179    -0.0195087    0.142532    -0.137325    -0.0500789    0.047935     0.0728559   -0.118521      0.109809     -0.0798995    0.0734985    -0.0815314   -0.120425      0.112771
  0.000788138  -0.0428392   -0.0208163   -0.189979     0.0515367    0.0912136   -0.0393691   -0.0348132    0.0131096    0.122031     0.20699     -0.054439    -0.20134     -0.0735348    0.102727     0.00130614  -0.0397099    0.131059     0.0611605    0.0591251     0.130632     -0.100659     0.039816     -0.0896965    0.00485447    0.249291
 -0.0415547     0.325426     0.045151     0.00807948   0.134311     0.0934385   -0.0509511    0.00957589   0.107285    -0.0879671   -0.0528057   -0.0272461    0.144296    -0.0490673    0.040228     0.11923      0.0421523    0.0174974   -0.0074044   -0.0211624     0.0387673    -0.00623434  -0.0734217     0.244691    -0.153952     -0.0310795
  0.0686062     0.108964    -0.136407     0.0269287   -0.00272687   0.0727472   -0.085587     0.0224627    0.145558     0.0404889    0.0466445    0.26226      0.00502138  -0.0331577   -0.151943    -0.0192441   -0.0467921    0.00240207   0.10622     -0.0364918     0.0819557    -0.091568     0.0290632     0.0996508   -0.0106452    -0.0976532
 -0.0368317    -0.0204183   -0.133916    -0.0440387   -0.0217568    0.0199724   -0.00372556   0.0593891   -0.0466733    0.0756814    0.237422    -0.142595    -0.0529293   -0.0171768   -0.0689642    0.027731     3.11375e-5  -0.108123    -0.04871     -0.159638      0.0268846     0.179049     0.136694     -0.0382232   -0.059896     -0.00355979
 -0.00733828   -0.0143077   -0.168851     0.0192745    0.0438927   -0.215336    -0.18719     -0.02721      0.0524629   -0.0227736   -0.109021     0.0925691    0.0272135   -0.0763488   -0.0676212   -0.0954561    0.0313581   -0.0799368   -0.167005    -0.000793378   0.236854     -0.0496978    0.0991445    -0.00211369  -0.184228     -0.0576819
 -0.0661383     0.0648568   -0.078019    -0.00591865  -0.0786608   -0.048024     0.0810299    0.0496918    0.0581462   -0.0757675    0.0341541   -0.0382898   -0.00361567   0.183147     0.120071    -0.0942632    0.058299    -0.107135     0.0359899    0.16449      -0.0116926     0.110039    -0.110322      0.0374953   -0.000557431   0.0154569
  0.0313117     0.20006      0.125539     0.128907    -0.103628    -0.0134807    0.0369208    0.0219409   -0.0293297    0.153327    -0.0163836    0.054827     0.131882    -0.0135172   -0.222809    -0.0186192   -0.00567642   0.146321     0.0507461    0.0109938    -0.0442851    -0.0394168    0.000218464  -0.00316858  -0.0178439     0.0668951
  0.13959      -0.142473     0.0332305    0.0126565   -0.137438    -0.0232267    0.150834    -0.051908    -0.118726     0.0326633    0.162493     0.0367464   -0.0630984   -0.0729472   -0.0120834    0.0146676   -0.164869     0.0198872    0.11145     -0.0918552    -0.0137842    -0.191069     0.101149      0.0081271    0.0173924     0.0513773
  0.0190995    -0.100692     0.00769572  -0.0527027    0.175932     0.00435085   0.160051    -0.0830866    0.0755261   -0.0153502   -0.0289533    0.161181    -0.0446527   -0.0512014    0.103166    -0.0384417    0.0188194   -0.0781384    0.127577     0.0475348     0.0483837     0.0132775    0.149778      0.219427     0.105797      0.00576369
  0.21004       0.173892     0.186227     0.0615595   -0.0188234    0.103816    -0.0688028    0.0428938    0.078439    -0.0480791   -0.117127     0.064726    -0.0143916    0.0256373   -0.139378    -0.170589    -0.0355762   -0.119675     0.0433901   -0.152095     -0.033015     -0.0061297    0.0489654    -0.0821543    0.0186821    -0.106067
  0.0772135    -0.0247491   -0.0798505   -0.0548288   -0.0299706    0.136518    -0.0315273   -0.182498    -0.218852     0.00733191  -0.0272811   -0.020671     0.0716803   -0.118417     0.0567758   -0.0306965    0.168918    -0.181819     0.108162     0.163726      0.187414     -0.0141536    0.00752337   -0.00214505  -0.0555841    -0.216079kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4285845025830026
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428603
[ Info: iteration 2, average log likelihood -1.428540
[ Info: iteration 3, average log likelihood -1.428502
[ Info: iteration 4, average log likelihood -1.428464
[ Info: iteration 5, average log likelihood -1.428424
[ Info: iteration 6, average log likelihood -1.428377
[ Info: iteration 7, average log likelihood -1.428315
[ Info: iteration 8, average log likelihood -1.428216
[ Info: iteration 9, average log likelihood -1.428018
[ Info: iteration 10, average log likelihood -1.427601
[ Info: iteration 11, average log likelihood -1.426808
[ Info: iteration 12, average log likelihood -1.425650
[ Info: iteration 13, average log likelihood -1.424526
[ Info: iteration 14, average log likelihood -1.423836
[ Info: iteration 15, average log likelihood -1.423538
[ Info: iteration 16, average log likelihood -1.423428
[ Info: iteration 17, average log likelihood -1.423388
[ Info: iteration 18, average log likelihood -1.423373
[ Info: iteration 19, average log likelihood -1.423367
[ Info: iteration 20, average log likelihood -1.423364
[ Info: iteration 21, average log likelihood -1.423363
[ Info: iteration 22, average log likelihood -1.423362
[ Info: iteration 23, average log likelihood -1.423361
[ Info: iteration 24, average log likelihood -1.423361
[ Info: iteration 25, average log likelihood -1.423360
[ Info: iteration 26, average log likelihood -1.423360
[ Info: iteration 27, average log likelihood -1.423359
[ Info: iteration 28, average log likelihood -1.423359
[ Info: iteration 29, average log likelihood -1.423359
[ Info: iteration 30, average log likelihood -1.423359
[ Info: iteration 31, average log likelihood -1.423358
[ Info: iteration 32, average log likelihood -1.423358
[ Info: iteration 33, average log likelihood -1.423358
[ Info: iteration 34, average log likelihood -1.423358
[ Info: iteration 35, average log likelihood -1.423358
[ Info: iteration 36, average log likelihood -1.423358
[ Info: iteration 37, average log likelihood -1.423357
[ Info: iteration 38, average log likelihood -1.423357
[ Info: iteration 39, average log likelihood -1.423357
[ Info: iteration 40, average log likelihood -1.423357
[ Info: iteration 41, average log likelihood -1.423357
[ Info: iteration 42, average log likelihood -1.423357
[ Info: iteration 43, average log likelihood -1.423357
[ Info: iteration 44, average log likelihood -1.423357
[ Info: iteration 45, average log likelihood -1.423357
[ Info: iteration 46, average log likelihood -1.423357
[ Info: iteration 47, average log likelihood -1.423357
[ Info: iteration 48, average log likelihood -1.423357
[ Info: iteration 49, average log likelihood -1.423357
[ Info: iteration 50, average log likelihood -1.423357
┌ Info: EM with 100000 data points 50 iterations avll -1.423357
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4286031514584538
│     -1.42854024276842
│      ⋮
└     -1.4233565826231163
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423372
[ Info: iteration 2, average log likelihood -1.423305
[ Info: iteration 3, average log likelihood -1.423256
[ Info: iteration 4, average log likelihood -1.423204
[ Info: iteration 5, average log likelihood -1.423144
[ Info: iteration 6, average log likelihood -1.423075
[ Info: iteration 7, average log likelihood -1.422998
[ Info: iteration 8, average log likelihood -1.422917
[ Info: iteration 9, average log likelihood -1.422837
[ Info: iteration 10, average log likelihood -1.422766
[ Info: iteration 11, average log likelihood -1.422708
[ Info: iteration 12, average log likelihood -1.422664
[ Info: iteration 13, average log likelihood -1.422632
[ Info: iteration 14, average log likelihood -1.422610
[ Info: iteration 15, average log likelihood -1.422595
[ Info: iteration 16, average log likelihood -1.422583
[ Info: iteration 17, average log likelihood -1.422575
[ Info: iteration 18, average log likelihood -1.422568
[ Info: iteration 19, average log likelihood -1.422562
[ Info: iteration 20, average log likelihood -1.422557
[ Info: iteration 21, average log likelihood -1.422552
[ Info: iteration 22, average log likelihood -1.422548
[ Info: iteration 23, average log likelihood -1.422544
[ Info: iteration 24, average log likelihood -1.422541
[ Info: iteration 25, average log likelihood -1.422537
[ Info: iteration 26, average log likelihood -1.422534
[ Info: iteration 27, average log likelihood -1.422532
[ Info: iteration 28, average log likelihood -1.422529
[ Info: iteration 29, average log likelihood -1.422527
[ Info: iteration 30, average log likelihood -1.422524
[ Info: iteration 31, average log likelihood -1.422522
[ Info: iteration 32, average log likelihood -1.422520
[ Info: iteration 33, average log likelihood -1.422519
[ Info: iteration 34, average log likelihood -1.422517
[ Info: iteration 35, average log likelihood -1.422516
[ Info: iteration 36, average log likelihood -1.422514
[ Info: iteration 37, average log likelihood -1.422513
[ Info: iteration 38, average log likelihood -1.422512
[ Info: iteration 39, average log likelihood -1.422511
[ Info: iteration 40, average log likelihood -1.422510
[ Info: iteration 41, average log likelihood -1.422509
[ Info: iteration 42, average log likelihood -1.422508
[ Info: iteration 43, average log likelihood -1.422507
[ Info: iteration 44, average log likelihood -1.422507
[ Info: iteration 45, average log likelihood -1.422506
[ Info: iteration 46, average log likelihood -1.422506
[ Info: iteration 47, average log likelihood -1.422505
[ Info: iteration 48, average log likelihood -1.422505
[ Info: iteration 49, average log likelihood -1.422504
[ Info: iteration 50, average log likelihood -1.422504
┌ Info: EM with 100000 data points 50 iterations avll -1.422504
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4233716423948701
│     -1.4233046858141964
│      ⋮
└     -1.4225036608797261
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422515
[ Info: iteration 2, average log likelihood -1.422463
[ Info: iteration 3, average log likelihood -1.422420
[ Info: iteration 4, average log likelihood -1.422371
[ Info: iteration 5, average log likelihood -1.422310
[ Info: iteration 6, average log likelihood -1.422234
[ Info: iteration 7, average log likelihood -1.422142
[ Info: iteration 8, average log likelihood -1.422035
[ Info: iteration 9, average log likelihood -1.421920
[ Info: iteration 10, average log likelihood -1.421806
[ Info: iteration 11, average log likelihood -1.421700
[ Info: iteration 12, average log likelihood -1.421611
[ Info: iteration 13, average log likelihood -1.421538
[ Info: iteration 14, average log likelihood -1.421480
[ Info: iteration 15, average log likelihood -1.421434
[ Info: iteration 16, average log likelihood -1.421397
[ Info: iteration 17, average log likelihood -1.421365
[ Info: iteration 18, average log likelihood -1.421338
[ Info: iteration 19, average log likelihood -1.421315
[ Info: iteration 20, average log likelihood -1.421294
[ Info: iteration 21, average log likelihood -1.421275
[ Info: iteration 22, average log likelihood -1.421257
[ Info: iteration 23, average log likelihood -1.421242
[ Info: iteration 24, average log likelihood -1.421227
[ Info: iteration 25, average log likelihood -1.421214
[ Info: iteration 26, average log likelihood -1.421202
[ Info: iteration 27, average log likelihood -1.421191
[ Info: iteration 28, average log likelihood -1.421181
[ Info: iteration 29, average log likelihood -1.421171
[ Info: iteration 30, average log likelihood -1.421162
[ Info: iteration 31, average log likelihood -1.421154
[ Info: iteration 32, average log likelihood -1.421145
[ Info: iteration 33, average log likelihood -1.421137
[ Info: iteration 34, average log likelihood -1.421130
[ Info: iteration 35, average log likelihood -1.421122
[ Info: iteration 36, average log likelihood -1.421115
[ Info: iteration 37, average log likelihood -1.421108
[ Info: iteration 38, average log likelihood -1.421101
[ Info: iteration 39, average log likelihood -1.421094
[ Info: iteration 40, average log likelihood -1.421086
[ Info: iteration 41, average log likelihood -1.421079
[ Info: iteration 42, average log likelihood -1.421071
[ Info: iteration 43, average log likelihood -1.421064
[ Info: iteration 44, average log likelihood -1.421056
[ Info: iteration 45, average log likelihood -1.421048
[ Info: iteration 46, average log likelihood -1.421040
[ Info: iteration 47, average log likelihood -1.421032
[ Info: iteration 48, average log likelihood -1.421023
[ Info: iteration 49, average log likelihood -1.421014
[ Info: iteration 50, average log likelihood -1.421006
┌ Info: EM with 100000 data points 50 iterations avll -1.421006
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4225150726398241
│     -1.4224630057395145
│      ⋮
└     -1.4210055973953897
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421005
[ Info: iteration 2, average log likelihood -1.420947
[ Info: iteration 3, average log likelihood -1.420894
[ Info: iteration 4, average log likelihood -1.420836
[ Info: iteration 5, average log likelihood -1.420769
[ Info: iteration 6, average log likelihood -1.420690
[ Info: iteration 7, average log likelihood -1.420599
[ Info: iteration 8, average log likelihood -1.420498
[ Info: iteration 9, average log likelihood -1.420392
[ Info: iteration 10, average log likelihood -1.420286
[ Info: iteration 11, average log likelihood -1.420183
[ Info: iteration 12, average log likelihood -1.420087
[ Info: iteration 13, average log likelihood -1.419998
[ Info: iteration 14, average log likelihood -1.419917
[ Info: iteration 15, average log likelihood -1.419844
[ Info: iteration 16, average log likelihood -1.419779
[ Info: iteration 17, average log likelihood -1.419721
[ Info: iteration 18, average log likelihood -1.419670
[ Info: iteration 19, average log likelihood -1.419624
[ Info: iteration 20, average log likelihood -1.419584
[ Info: iteration 21, average log likelihood -1.419549
[ Info: iteration 22, average log likelihood -1.419517
[ Info: iteration 23, average log likelihood -1.419488
[ Info: iteration 24, average log likelihood -1.419462
[ Info: iteration 25, average log likelihood -1.419439
[ Info: iteration 26, average log likelihood -1.419416
[ Info: iteration 27, average log likelihood -1.419396
[ Info: iteration 28, average log likelihood -1.419376
[ Info: iteration 29, average log likelihood -1.419358
[ Info: iteration 30, average log likelihood -1.419340
[ Info: iteration 31, average log likelihood -1.419323
[ Info: iteration 32, average log likelihood -1.419307
[ Info: iteration 33, average log likelihood -1.419291
[ Info: iteration 34, average log likelihood -1.419276
[ Info: iteration 35, average log likelihood -1.419262
[ Info: iteration 36, average log likelihood -1.419247
[ Info: iteration 37, average log likelihood -1.419233
[ Info: iteration 38, average log likelihood -1.419220
[ Info: iteration 39, average log likelihood -1.419207
[ Info: iteration 40, average log likelihood -1.419194
[ Info: iteration 41, average log likelihood -1.419181
[ Info: iteration 42, average log likelihood -1.419168
[ Info: iteration 43, average log likelihood -1.419156
[ Info: iteration 44, average log likelihood -1.419144
[ Info: iteration 45, average log likelihood -1.419132
[ Info: iteration 46, average log likelihood -1.419121
[ Info: iteration 47, average log likelihood -1.419109
[ Info: iteration 48, average log likelihood -1.419098
[ Info: iteration 49, average log likelihood -1.419087
[ Info: iteration 50, average log likelihood -1.419076
┌ Info: EM with 100000 data points 50 iterations avll -1.419076
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.421004645213371
│     -1.4209470029090592
│      ⋮
└     -1.4190762365504643
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419073
[ Info: iteration 2, average log likelihood -1.419008
[ Info: iteration 3, average log likelihood -1.418947
[ Info: iteration 4, average log likelihood -1.418876
[ Info: iteration 5, average log likelihood -1.418790
[ Info: iteration 6, average log likelihood -1.418685
[ Info: iteration 7, average log likelihood -1.418557
[ Info: iteration 8, average log likelihood -1.418411
[ Info: iteration 9, average log likelihood -1.418254
[ Info: iteration 10, average log likelihood -1.418093
[ Info: iteration 11, average log likelihood -1.417937
[ Info: iteration 12, average log likelihood -1.417792
[ Info: iteration 13, average log likelihood -1.417662
[ Info: iteration 14, average log likelihood -1.417546
[ Info: iteration 15, average log likelihood -1.417443
[ Info: iteration 16, average log likelihood -1.417353
[ Info: iteration 17, average log likelihood -1.417273
[ Info: iteration 18, average log likelihood -1.417202
[ Info: iteration 19, average log likelihood -1.417138
[ Info: iteration 20, average log likelihood -1.417081
[ Info: iteration 21, average log likelihood -1.417028
[ Info: iteration 22, average log likelihood -1.416981
[ Info: iteration 23, average log likelihood -1.416936
[ Info: iteration 24, average log likelihood -1.416896
[ Info: iteration 25, average log likelihood -1.416857
[ Info: iteration 26, average log likelihood -1.416821
[ Info: iteration 27, average log likelihood -1.416787
[ Info: iteration 28, average log likelihood -1.416755
[ Info: iteration 29, average log likelihood -1.416724
[ Info: iteration 30, average log likelihood -1.416695
[ Info: iteration 31, average log likelihood -1.416667
[ Info: iteration 32, average log likelihood -1.416640
[ Info: iteration 33, average log likelihood -1.416615
[ Info: iteration 34, average log likelihood -1.416591
[ Info: iteration 35, average log likelihood -1.416567
[ Info: iteration 36, average log likelihood -1.416545
[ Info: iteration 37, average log likelihood -1.416523
[ Info: iteration 38, average log likelihood -1.416503
[ Info: iteration 39, average log likelihood -1.416483
[ Info: iteration 40, average log likelihood -1.416464
[ Info: iteration 41, average log likelihood -1.416446
[ Info: iteration 42, average log likelihood -1.416429
[ Info: iteration 43, average log likelihood -1.416412
[ Info: iteration 44, average log likelihood -1.416396
[ Info: iteration 45, average log likelihood -1.416381
[ Info: iteration 46, average log likelihood -1.416366
[ Info: iteration 47, average log likelihood -1.416352
[ Info: iteration 48, average log likelihood -1.416338
[ Info: iteration 49, average log likelihood -1.416324
[ Info: iteration 50, average log likelihood -1.416311
┌ Info: EM with 100000 data points 50 iterations avll -1.416311
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4190734595147252
│     -1.4190084034197288
│      ⋮
└     -1.4163108351395215
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4285845025830026
│     -1.4286031514584538
│     -1.42854024276842
│     -1.4285018306002146
│      ⋮
│     -1.4163376819996454
│     -1.4163240759068736
└     -1.4163108351395215
32×26 Array{Float64,2}:
  0.0876034    -0.0883815   -0.10592     -0.125913    -0.114057     0.267741    0.256326    0.0313679  -0.201598     0.00795822  -0.209804      0.235872    -0.235372    -0.175753     0.00140374   0.0160986   -0.562164    0.103764     0.184849   -0.081276     0.185035   -0.320016    -0.104163    -0.198901     0.18986      -0.0527367
 -0.014342      0.136501     0.0439128   -0.00616074   0.0101372   -0.0289603   0.106552    0.133255    0.0809508    0.118925     0.175688      0.0466176    0.018745    -0.0671074    0.221984     0.0795769    0.167914   -0.27951     -0.347868    0.114686     0.275235    0.0390088    0.097038     0.0614532    0.0843638     0.0724389
  0.227273      0.00675166  -0.464439     0.202413    -0.185759    -0.177665   -0.0895064  -0.210714   -0.0987722   -0.482291     0.0275229    -0.0585085    0.289709     0.23879      0.206715    -0.297701     0.249921    0.263259     0.113118   -0.0617087   -0.109007   -0.227788    -0.0103799   -0.154587    -0.0838615    -0.162069
  0.00149557    0.0330174    0.219561    -0.14415      0.128192    -0.107361   -0.154096   -0.0397952   0.185619     0.0982567   -0.0543292    -0.121449     0.107213     0.0923914   -0.281112    -0.22924      0.110967    0.0755462    0.112263    0.0126948   -0.281406    0.189535     0.00821151   0.106799    -0.155216      0.0983245
 -0.673106     -0.441695     0.262627     0.179174    -0.0233026   -0.104451    0.0204841   0.252241    0.421881    -0.412272    -0.648326     -0.3973      -0.21408     -0.33713      0.302479    -0.446546    -0.131542   -0.186699    -0.203668    0.164161     0.232813    0.141112    -0.19091     -0.0712887   -0.251654     -0.336478
 -0.0219564    -0.332559    -0.0899119   -0.145389    -0.123075    -0.493268   -0.23365    -0.153235    0.268241     0.165687    -0.564207      0.492621    -0.207569     0.225113    -0.069426    -0.431223    -0.290363    0.248369     0.086741    0.241301     0.314077   -0.268243     0.16187     -0.346507    -0.547132     -0.648289
 -0.445614     -0.0621539   -0.0568076   -0.0715367   -0.348435    -0.128751   -0.128977    0.414796   -0.361332     0.210067    -0.155853     -0.0225479   -0.16801      0.196092     0.181208     0.779323     0.458468    0.0845897   -0.0847151  -0.40003      0.522415    0.196729     0.327763    -0.0507277   -0.386139     -0.242567
  0.311506     -0.0771855   -0.685289    -0.677766     0.640807     0.0423848   0.251003    0.605077    0.00589539   0.138225    -0.583189      0.205374     0.554181     0.632006     0.467631    -0.185614    -0.182291   -0.00413913   0.289547   -0.545765     0.205664    0.725806    -0.175124     0.348596    -0.243615     -0.557137
  0.374513     -0.0632531    0.460242     0.179971    -0.272957     0.319946    0.14273    -0.639944    0.357219    -0.345847    -0.328406     -0.363074     0.0664931    0.19348      0.0112924   -0.137349    -1.07966    -0.207787    -0.233147   -0.507505    -0.203888   -0.20389      0.233833     0.063383     0.123877     -0.0297214
  0.450202     -0.22318      0.245347     0.389422    -0.149867     0.240175   -0.354842   -0.192014    0.480226    -0.402144     0.0624627    -0.209216    -0.135509    -0.0676483   -0.201895     0.00302729   0.589533   -0.0584076    0.189604   -0.579034    -0.0331583   0.65373      0.333169     0.375319    -0.401386      0.124403
  0.152053     -0.0163226    0.13534      0.0167131    0.254121     0.190174    0.580134    0.143575    0.623764    -0.211274     0.418248     -0.0243525   -0.00615842  -0.0513952    0.536918    -0.587806     0.215231    0.272721    -0.917417   -0.525912    -0.504821   -0.30317     -0.00159112  -0.325943    -0.64583       0.0815973
  0.376965     -0.0322796    0.0959788    0.0800118    0.0438822    0.101186    0.67652    -0.276913    0.442027     0.210139     0.715322      0.00348576   0.0716242   -0.0622839    0.154329    -0.32579      0.282709    0.208114     0.335115   -0.287226    -0.430669    0.599519    -0.218482    -0.322408    -0.189259      0.587094
  0.0130683     0.513402    -0.344949    -0.667557     0.280803    -0.331848    0.390571    0.246908   -0.0416806    0.545382     0.144596      0.2379       0.339593     0.00525008  -0.0761742   -0.49109      0.0546358  -0.216129    -0.299456    0.565735    -0.174663   -0.271213    -0.0411495   -0.44034      0.13138      -0.238473
 -0.381638      0.222224     0.619389    -0.652481    -0.00921401   0.158357    0.316532    0.117855    0.547683     0.695349    -0.0947444     0.0685621    0.214507    -0.0142836    0.189069    -0.123069    -0.328439   -0.559832    -0.274659    0.305645     0.190539    0.365557    -0.0638574    0.540008    -0.243491      0.0305631
  0.0304289     0.0835185   -0.00116966   0.276007     0.310102    -0.110767   -0.107619    0.0839941   0.536012     0.472118     0.646902      0.236081     0.0904036   -0.0338945   -0.204832     0.142733     0.624557   -0.119492    -0.265758    0.371857     0.367959    0.0313111   -0.0595334    0.399746    -0.743023      0.129969
 -0.0871646     0.196062     0.417195     0.199952     0.158828    -0.144369   -0.109244   -0.223477   -0.172011     0.136701     0.663421      0.15075     -0.0222973   -0.303993    -0.365166    -0.0100138    0.407418   -0.290274    -0.359469    0.303669    -0.0121227  -0.141932     0.0239615    0.319235     0.446674      0.997157
  0.703079      0.609544     0.443824     0.118011    -0.936528     0.274117    0.297396   -0.250204    0.495218    -0.296281    -0.00794394    0.291518    -0.403312    -0.675591    -0.236315    -0.325117    -0.374684   -0.253021     0.307488    0.69298      0.368213   -0.388638     0.321899    -0.0736738    0.428484      0.174209
 -0.425056     -0.106656     0.146517     0.194414    -0.407636    -0.172593   -0.284057    0.14394    -0.474021     0.301158    -0.380492      0.210534    -0.00906898  -0.407612    -0.378722     0.272666    -0.371313    0.19759      0.4039      0.722327     0.0582614  -1.02357      0.112729     0.302924     0.408241      0.239704
 -0.0433425    -0.679351     0.178122    -0.157695     0.548583     0.304321    0.304347   -0.426716    0.464214     0.350616     0.235987      0.164608    -0.555438    -0.512023    -0.386888     0.810679    -0.62942     0.157542    -0.060002   -0.426276     0.516156   -0.0613227    0.314621     0.118036     0.283214     -0.00210436
  0.000504218  -0.349213    -0.256558     0.613588     0.612758     0.529209   -0.273636    0.292441   -0.668333    -0.219997     0.255369     -0.112449    -0.22714     -0.219858    -0.0204696    0.413955     0.156612    0.184077    -0.177527   -0.516773    -0.155551   -0.408108     0.368024    -0.256113     0.378209     -0.0900271
  0.0342073    -0.824736    -0.477391     0.170347     0.24336      0.152916   -0.0449466  -0.141932   -0.529685     0.147767    -0.341167     -0.38809     -0.0754401    0.298246    -0.519088     0.0375185   -0.144557    0.769665     0.980508   -0.360308    -0.390516   -0.467468    -0.177976     0.0337667   -0.414555      0.00744411
  0.150011      0.200167     0.109108    -0.133944     0.287677    -0.09261    -0.701492   -0.035905   -0.45047     -0.618845    -0.232105     -0.191991     0.0939427    0.481693    -0.453971    -0.392958     0.886216    0.358299    -0.110531   -0.0817439   -0.20084    -0.122883    -0.391729     0.0748243   -0.501081     -0.0671238
  0.526118      0.352459    -0.352964     0.0703444   -0.00852022   0.256734   -0.616922    0.190619   -0.347194    -0.203434    -0.686689     -0.770861     0.467397     0.671874     0.199954    -0.260319     0.130901   -0.365724     0.222614   -0.0517418   -0.809352    0.217586     0.58583      0.146943     0.843792      0.0469183
  0.113043      0.882326     0.0979467   -0.543747     0.285144     0.0771152   0.0446601   0.0634837   0.110282    -0.383048    -0.0533407    -0.505387     0.176802     0.124386    -0.296306     0.343422    -0.0306431   0.181138    -0.0114754  -0.00654277  -0.104959   -0.387979    -0.212497     0.260655     0.454205     -0.20625
  0.157904      0.0117608   -0.334091    -0.284172    -0.0560434   -0.147137   -0.679067   -0.0925929  -0.499383     0.282632    -0.244803     -0.0207104   -0.0576582   -0.0715091   -0.442909     0.383131    -0.135727   -0.589319     0.765314    0.556397     0.665349    0.374253    -0.211172     0.392916     0.617595     -0.22851
 -0.139587     -0.722274    -0.0681444    0.0502842   -0.0498586    0.292115   -0.535396   -0.14544    -0.271858    -0.240262     0.282168      0.123305     0.079238     0.405287     0.227918    -0.234048    -0.202278    0.447521     0.388128   -0.0218197    0.374642    0.746131    -0.482496     0.0377481    0.388421      0.314951
  0.59995      -0.0337559   -0.546865     0.333156    -0.846444    -0.303395    0.483271   -0.286124    0.174744     0.451627     0.599446      0.445803    -0.164731     0.0798945    0.499698     0.254498    -0.186748   -0.116536     0.389243    0.02267      0.157949    0.00880133   0.541162    -0.424072     0.14774       0.0667815
 -0.201879      0.180676    -0.362831     0.3366      -0.735718    -0.771404    0.128205   -0.0550866  -0.00407516   0.386974    -0.181938      0.047438     0.00835315  -0.177224    -0.0854002    0.166565     0.21427    -0.139641     0.278663    0.161206    -0.309944    0.327568     0.664331    -0.0616675   -0.283795      0.996179
  0.304916      0.340116    -0.135018    -0.045559     0.234055     0.258007    0.259766    0.304783    0.0773631    0.0137487   -0.000976268  -0.117233    -0.100522    -0.0673057   -0.177284    -0.129672    -0.0240297   0.161274    -0.13259     0.0291389   -0.345899   -0.701408    -0.0703864    0.0455554   -0.118926     -0.0175573
 -0.112781     -0.251026     0.0969034   -0.105475    -0.0740202   -0.0749955  -0.0928211  -0.0816697   0.0444256    0.112697     0.0906815     0.0665382   -0.0554724    0.0981382    0.0642786   -0.0207279   -0.0772121  -0.10133      0.174226    0.00274229   0.401959    0.723167    -0.0815841    0.00783705  -0.000846151   0.00180429
 -0.354098      0.789269     0.0707356    0.246838    -0.18669     -0.131173    0.0696912  -0.128937    0.0245004   -0.616133     0.0137188     0.190941     0.950682     0.388288     0.73448     -0.232444     0.847538    0.0497775   -0.210488   -0.0223331   -0.580438    0.402365     0.0422029   -0.1461       0.552432      0.0263674
 -0.154369      0.331426     0.0474618   -0.174195    -0.226328    -0.0917232  -0.2105      0.0618343  -0.325024    -0.583154    -0.281734      0.32782     -0.159793     0.0266675    0.596797     0.243432    -0.259891   -0.380662    -0.548859   -0.0384454    1.003      -0.270241    -0.320769     0.086884     0.57414      -0.464415[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416298
[ Info: iteration 2, average log likelihood -1.416285
[ Info: iteration 3, average log likelihood -1.416273
[ Info: iteration 4, average log likelihood -1.416261
[ Info: iteration 5, average log likelihood -1.416249
[ Info: iteration 6, average log likelihood -1.416238
[ Info: iteration 7, average log likelihood -1.416227
[ Info: iteration 8, average log likelihood -1.416216
[ Info: iteration 9, average log likelihood -1.416205
[ Info: iteration 10, average log likelihood -1.416195
┌ Info: EM with 100000 data points 10 iterations avll -1.416195
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.948162e+05
      1       7.145966e+05      -1.802197e+05 |       32
      2       6.994190e+05      -1.517756e+04 |       32
      3       6.938494e+05      -5.569578e+03 |       32
      4       6.912422e+05      -2.607188e+03 |       32
      5       6.897068e+05      -1.535424e+03 |       32
      6       6.886687e+05      -1.038143e+03 |       32
      7       6.878982e+05      -7.705241e+02 |       32
      8       6.872659e+05      -6.322699e+02 |       32
      9       6.867570e+05      -5.089074e+02 |       32
     10       6.863230e+05      -4.339525e+02 |       32
     11       6.859544e+05      -3.686098e+02 |       32
     12       6.856342e+05      -3.202095e+02 |       32
     13       6.853573e+05      -2.769191e+02 |       32
     14       6.850843e+05      -2.729938e+02 |       32
     15       6.848307e+05      -2.536038e+02 |       32
     16       6.846005e+05      -2.301406e+02 |       32
     17       6.844035e+05      -1.970544e+02 |       32
     18       6.842314e+05      -1.721395e+02 |       32
     19       6.840709e+05      -1.604881e+02 |       32
     20       6.839239e+05      -1.469330e+02 |       32
     21       6.837884e+05      -1.354963e+02 |       32
     22       6.836458e+05      -1.426383e+02 |       32
     23       6.835269e+05      -1.189354e+02 |       32
     24       6.834066e+05      -1.202492e+02 |       32
     25       6.832945e+05      -1.121384e+02 |       32
     26       6.831882e+05      -1.062695e+02 |       32
     27       6.830932e+05      -9.505199e+01 |       32
     28       6.830101e+05      -8.302073e+01 |       32
     29       6.829296e+05      -8.055023e+01 |       32
     30       6.828572e+05      -7.236604e+01 |       32
     31       6.827878e+05      -6.942435e+01 |       32
     32       6.827294e+05      -5.840610e+01 |       32
     33       6.826780e+05      -5.140738e+01 |       32
     34       6.826233e+05      -5.471514e+01 |       32
     35       6.825694e+05      -5.390498e+01 |       32
     36       6.825219e+05      -4.744798e+01 |       32
     37       6.824688e+05      -5.311897e+01 |       32
     38       6.824271e+05      -4.164871e+01 |       32
     39       6.823873e+05      -3.988161e+01 |       32
     40       6.823505e+05      -3.676183e+01 |       32
     41       6.823145e+05      -3.601410e+01 |       32
     42       6.822742e+05      -4.033264e+01 |       32
     43       6.822354e+05      -3.874974e+01 |       32
     44       6.822034e+05      -3.202313e+01 |       32
     45       6.821699e+05      -3.343877e+01 |       32
     46       6.821343e+05      -3.560981e+01 |       32
     47       6.821005e+05      -3.386218e+01 |       32
     48       6.820681e+05      -3.235476e+01 |       32
     49       6.820356e+05      -3.248981e+01 |       32
     50       6.820100e+05      -2.565180e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 682009.9734914573)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428215
[ Info: iteration 2, average log likelihood -1.423097
[ Info: iteration 3, average log likelihood -1.421750
[ Info: iteration 4, average log likelihood -1.420786
[ Info: iteration 5, average log likelihood -1.419782
[ Info: iteration 6, average log likelihood -1.418832
[ Info: iteration 7, average log likelihood -1.418147
[ Info: iteration 8, average log likelihood -1.417747
[ Info: iteration 9, average log likelihood -1.417521
[ Info: iteration 10, average log likelihood -1.417376
[ Info: iteration 11, average log likelihood -1.417271
[ Info: iteration 12, average log likelihood -1.417187
[ Info: iteration 13, average log likelihood -1.417116
[ Info: iteration 14, average log likelihood -1.417054
[ Info: iteration 15, average log likelihood -1.416999
[ Info: iteration 16, average log likelihood -1.416949
[ Info: iteration 17, average log likelihood -1.416904
[ Info: iteration 18, average log likelihood -1.416862
[ Info: iteration 19, average log likelihood -1.416824
[ Info: iteration 20, average log likelihood -1.416788
[ Info: iteration 21, average log likelihood -1.416755
[ Info: iteration 22, average log likelihood -1.416724
[ Info: iteration 23, average log likelihood -1.416695
[ Info: iteration 24, average log likelihood -1.416667
[ Info: iteration 25, average log likelihood -1.416641
[ Info: iteration 26, average log likelihood -1.416616
[ Info: iteration 27, average log likelihood -1.416593
[ Info: iteration 28, average log likelihood -1.416570
[ Info: iteration 29, average log likelihood -1.416548
[ Info: iteration 30, average log likelihood -1.416527
[ Info: iteration 31, average log likelihood -1.416507
[ Info: iteration 32, average log likelihood -1.416487
[ Info: iteration 33, average log likelihood -1.416468
[ Info: iteration 34, average log likelihood -1.416449
[ Info: iteration 35, average log likelihood -1.416431
[ Info: iteration 36, average log likelihood -1.416413
[ Info: iteration 37, average log likelihood -1.416395
[ Info: iteration 38, average log likelihood -1.416378
[ Info: iteration 39, average log likelihood -1.416361
[ Info: iteration 40, average log likelihood -1.416344
[ Info: iteration 41, average log likelihood -1.416327
[ Info: iteration 42, average log likelihood -1.416311
[ Info: iteration 43, average log likelihood -1.416295
[ Info: iteration 44, average log likelihood -1.416279
[ Info: iteration 45, average log likelihood -1.416263
[ Info: iteration 46, average log likelihood -1.416248
[ Info: iteration 47, average log likelihood -1.416233
[ Info: iteration 48, average log likelihood -1.416219
[ Info: iteration 49, average log likelihood -1.416204
[ Info: iteration 50, average log likelihood -1.416191
┌ Info: EM with 100000 data points 50 iterations avll -1.416191
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.766775     0.191301     -0.415612   -0.333002    0.126685     0.504771    0.440275     0.48726    -0.0490333   -0.0126003   -0.468996   -0.427159   -0.280696    0.0234645   -0.696223    -0.622819     0.503889    0.579592    0.307539   -0.0683119  -0.989997    -0.822026    -0.226277    0.446167   -0.523055      0.165363
  0.120226    -0.160083     -0.02417    -0.255723    0.00959942   0.131221   -0.424936    -0.198311    0.31411     -0.1751      -0.267389   -0.348485    0.460023    0.388585    -0.299675    -0.317011    -0.087733    0.159173    0.735845    0.0184399   0.112458     0.703355    -0.377134    0.298004   -0.00151513   -0.250983
 -0.0539924   -0.263503     -0.214459    0.596767    0.918592     0.540359   -0.132384     0.310362   -0.689257    -0.102393     0.615428   -0.0803908  -0.0516314  -0.159035     0.226188     0.276384     0.353385    0.090984   -0.341192   -0.399504   -0.354212    -0.398962     0.287774   -0.294095    0.292682     -0.166229
  0.481612     0.461327     -0.205276    0.0759873   0.0705996    0.247286   -0.650103     0.17794    -0.36932     -0.26635     -0.619046   -0.722112    0.436792    0.645826     0.0526758   -0.192088     0.192273   -0.2271      0.200592   -0.0707703  -0.916424     0.205057     0.598143    0.235518    0.79105       0.177802
 -0.531373    -0.274443      0.289496   -0.0810629  -0.0580733    0.0460513   0.303676     0.0636307   0.796083     0.297128     0.156326    0.226578   -0.0782325  -0.408893     0.197608    -0.441833    -0.329032   -0.165145    0.13951     0.403117    0.254996     0.160809    -0.586937    0.229741   -0.486336     -0.00297526
 -0.366925    -0.0565002    -0.49335    -0.854965    0.348722    -0.273042    0.259644     0.408887   -0.542708     0.709557    -0.324371    0.0616878   0.180424    0.7355       0.565257     0.368965     0.0100418   0.390247    0.172386   -0.58684     0.146214     0.213233     0.0292722   0.42077    -0.237287      0.101321
 -0.427327    -0.956711     -0.200051    0.357251    0.326024    -0.0526141  -0.503657     0.0320265  -0.879471     0.0586443   -0.289049   -0.173864    0.11052     0.327107    -0.538521     0.0953803    0.0380382   0.78822     0.659894   -0.220095   -0.151633    -0.353909    -0.151892    0.0298175  -0.167174      0.106984
 -0.34637     -0.181342      0.625874   -0.447259    0.643455     0.190702   -0.172072     0.049403   -0.10459     -0.617358    -0.222886    0.0228923  -0.0785853   0.346048     0.17236     -0.364813     0.0702489   0.124046   -0.773924   -0.123866    0.20645      0.0322537   -0.768237   -0.0168346   0.0913062    -0.234669
  0.0318744    0.0153924    -0.204854   -0.262337   -0.0231521   -0.566616    0.174009     0.172641   -0.0792185    0.731053    -0.0657664   0.631436   -0.0397871   0.149333    -0.103462    -0.164586    -0.0939494   0.126249   -0.0320131   0.486386    0.0944989   -0.338731     0.212145   -0.39674    -0.216098     -0.094192
 -0.208287    -0.458937     -0.101935    0.199054   -0.229833     0.0423711  -0.0486947   -0.0240773  -0.138018    -0.143258    -0.272274   -0.0178775  -0.200528   -0.0104518    0.314323    -0.1329      -0.155989    0.105329    0.0490154  -0.25978     0.22403      0.00782335   0.0310417  -0.352314   -0.282615     -0.26987
  0.327861     0.000956371   0.106742   -0.0240638   0.364289     0.0187999  -0.00994792  -0.141292    0.574237     0.0235238    0.263583   -0.0774052   0.0149654   0.0915721   -0.0471301   -0.423456     0.430097    0.219641   -0.14531    -0.352821   -0.48039      0.208993     0.263554   -0.0314382  -0.67273       0.0654998
  0.433524     0.0593636     0.220489    0.179778   -0.231027     0.533386    0.24064     -0.600739   -0.0659077   -0.502354    -0.217892   -0.21559     0.0873816   0.394745     0.232087     0.146676    -0.87553    -0.014264   -0.140151   -1.00269     0.0983315   -0.469461     0.0422635   0.0012673   0.166844     -0.235817
  0.430424     0.345797     -0.573085    0.400692   -0.152841    -0.565122   -0.297976    -0.146393   -0.166837    -0.95171      0.176518   -0.0374905   0.291753    0.4118       0.0446641   -0.188632     0.455172    0.43535     0.0196518   0.170963   -0.13138     -0.595004    -0.16395    -0.187392   -0.0765044    -0.0256002
  0.218825    -0.420061      0.160898    0.877447   -0.295751     0.0735609  -0.456627     0.0533257   0.463786    -0.493857    -0.106106   -0.155432   -0.3963     -0.20986     -0.0700601    0.102644     0.444688    0.033444   -0.194517   -0.491048    0.243194     0.123652     0.190273    0.267993   -0.523195      0.19034
 -0.688017    -0.0862043     0.109143   -0.36054     0.206239    -0.100573   -0.18356      0.553098   -0.0142416    0.15373     -0.720747   -0.610023   -0.149127   -0.488568    -0.40677      0.209417    -0.0282362  -0.21761    -0.456739    0.162332    0.0114475   -0.373662     0.321505    0.319052    0.0389994    -0.128458
  0.0371373    0.0195292    -0.247087   -0.273177   -0.167516    -0.174953   -0.781622    -0.119634   -0.665414     0.143715    -0.372059    0.15274    -0.183869   -0.0661637   -0.225729     0.46118     -0.310061   -0.506726    0.571219    0.536389    0.87282      0.033688    -0.254187    0.383394    0.638026     -0.378686
  0.0914463   -0.41766       0.239997   -0.0232219   0.502786     0.228462    0.143551    -0.579465    0.384434     0.185988     0.27409     0.0662601  -0.366379   -0.679137    -0.688721     0.732053    -0.404009    0.139692    0.148629   -0.457367    0.220628    -0.0518894    0.244926    0.179486    0.269952      0.202428
  0.217553    -0.0342569    -0.152424   -0.387153   -0.0464811    0.385769    0.561881     0.216174    0.14097      0.0787294    0.13955     0.203678   -0.352286   -0.0597624    0.54046      0.404417    -0.427888    0.165576   -0.0656016  -0.183052    0.470562    -0.380469     0.375604   -0.19471     0.177312     -0.321061
  0.0319502    0.310936      0.293178    0.615353   -0.675695     0.102374    0.0741186   -0.171715   -0.0705671    0.0279559    0.299209    0.320676   -0.437575   -0.718394    -0.189546     0.106761    -0.124538    0.0156156   0.11555     0.588916    0.10754     -0.8767       0.398466    0.0302934   0.468262      0.556614
 -0.370748     0.757641     -0.199969   -0.0824956  -0.450163    -0.294309    0.0912379   -0.22209    -0.233221    -0.190025     0.0583596   0.164432    0.764991    0.160534     0.607078    -0.305599     0.743639   -0.39065    -0.582204   -0.163911    0.150762     0.410066     0.121451   -0.142258    0.457598      0.132477
  0.554118    -0.459199     -0.104881    0.232415   -0.107289     0.300972    0.0179254   -0.213552   -0.23052     -0.049095     0.612186    0.283233   -0.119437    0.343598     0.254066    -0.039667     0.17458     0.183372    0.533296   -0.18635     0.175585     0.805757    -0.0151718   0.011095    0.298297      0.716011
  0.0676565    0.0249507    -0.559931    0.52601    -0.700271    -0.59003     0.328065    -0.121213    0.00494938   0.660629     0.0648461  -0.128703    0.0112678  -0.309278    -0.0781036    0.389228    -0.188007   -0.43708     0.754626    0.210532   -0.148105     0.286354     0.805783   -0.150116    0.0405869     0.494905
 -0.101822     0.425506      0.14063    -0.234492   -0.00792719  -0.365151   -0.256397    -0.197886   -0.312571     0.439205     0.444019   -0.111754    0.24261     0.0475356   -0.700321     0.048676     0.748674   -0.0276615  -0.0338296   0.253422    0.0419699    0.18019     -0.513131    0.377571   -0.179983      0.888316
  0.301704     0.402184      0.460148   -0.34998    -0.315281    -0.186566    0.320844    -0.294926    0.605498    -0.017289    -0.276338   -0.216503    0.0997185   0.0460973    0.109109    -0.716062    -0.51703    -0.367417   -0.232446    0.505068   -0.254321    -0.175036     0.194808    0.0946618   0.10382       0.168777
  0.0131061    0.971588     -0.0938693  -0.591365    0.391378     0.0699975  -0.0186854    0.142308    0.0412217    0.0134791    0.0872456  -0.0211665   0.219316    0.0947347   -0.149045     0.15409     -0.141788   -0.0229412  -0.192087    0.36612     0.0451087   -0.570924    -0.367649   -0.128133    0.244057     -0.398355
  0.15641      0.135734     -0.124842   -0.163536   -0.118213     0.269       0.0480984    0.0648517  -0.292033    -0.229194    -0.299485    0.109885   -0.0313925  -0.181805    -0.208782    -0.0412545   -0.360898    0.140024    0.332325    0.0615038  -0.00214383  -0.261243    -0.169193   -0.0417651   0.419521     -0.0265435
 -0.487147     0.0631367    -0.052884    0.339446   -0.467323    -0.250809   -0.56338      0.0412409  -0.0975696   -0.391573    -0.184508    0.112614    0.0107273   0.513784     0.404702     0.239978     0.532036    0.228967    0.18913     0.189066   -0.102621     0.516429     0.277623   -0.0792064  -0.306424     -0.597174
 -0.0868905   -0.289785      0.128161   -0.0703917  -0.101552    -0.0413562  -0.0860928   -0.105517    0.0886421    0.0487248   -0.0519717   0.171988   -0.155642    0.00350281   0.0473566   -0.115562    -0.259695   -0.0335346   0.0417292   0.0877906   0.404332     0.258218    -0.0124247  -0.058504   -0.000926747  -0.114167
  0.343304     0.257067      0.0240651   0.0703668  -0.0389599   -0.0298494   0.860079    -0.114724    0.704128    -0.00805737   0.610422   -0.0654493   0.22912    -0.230035     0.336245    -0.420708     0.347451    0.246519   -0.321442   -0.443147   -0.656521     0.135494    -0.0955764  -0.433153   -0.304868      0.362215
  0.00441434   0.119836      0.0607901  -0.0288843   0.0357615   -0.0754264   0.0127738    0.0280292   0.0849108    0.0914579    0.150516   -0.0572943   0.113336    0.0183303    0.00328913  -0.00817829   0.173923   -0.106825   -0.129578    0.0621811   0.0293735    0.0740097    0.0408913   0.0945464   0.0110387     0.123659
  0.558195    -0.179303     -0.605074   -0.276063    0.319602     0.138207    0.439973     0.816757    0.300322    -0.285307    -0.647866    0.0433856   0.522736    0.546099     0.477159    -0.453152     0.106057   -0.510204    0.0339441  -0.479912    0.193164     0.724252    -0.126039    0.177698   -0.115204     -1.00879
 -0.163788     0.336503      0.35392    -0.164388    0.271632     0.0575083   0.125059     0.3641      0.447649     0.504258     0.407157    0.186318    0.0911716  -0.123953    -0.00672432   0.423042     0.303925   -0.822327   -0.715356    0.23776     0.492602     0.335806     0.265477    0.45106    -0.0690302     0.088017[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416177
[ Info: iteration 2, average log likelihood -1.416164
[ Info: iteration 3, average log likelihood -1.416152
[ Info: iteration 4, average log likelihood -1.416140
[ Info: iteration 5, average log likelihood -1.416128
[ Info: iteration 6, average log likelihood -1.416117
[ Info: iteration 7, average log likelihood -1.416106
[ Info: iteration 8, average log likelihood -1.416096
[ Info: iteration 9, average log likelihood -1.416086
[ Info: iteration 10, average log likelihood -1.416076
┌ Info: EM with 100000 data points 10 iterations avll -1.416076
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
