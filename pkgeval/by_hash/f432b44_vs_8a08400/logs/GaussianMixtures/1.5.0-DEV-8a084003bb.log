Julia Version 1.5.0-DEV.222
Commit 8a084003bb (2020-02-02 21:40 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed SortingAlgorithms ── v0.3.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed GaussianMixtures ─── v0.3.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed Blosc ────────────── v0.5.1
  Installed Arpack ───────────── v0.4.0
  Installed HDF5 ─────────────── v0.12.5
  Installed StaticArrays ─────── v0.12.1
  Installed CMake ────────────── v1.1.2
  Installed StatsBase ────────── v0.32.0
  Installed JLD ──────────────── v0.9.2
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed BinaryProvider ───── v0.5.8
  Installed FileIO ───────────── v1.2.1
  Installed DataStructures ───── v0.17.9
  Installed QuadGK ───────────── v2.3.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed BinDeps ──────────── v1.0.0
  Installed SpecialFunctions ─── v0.9.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Distances ────────── v0.8.2
  Installed Missings ─────────── v0.4.3
  Installed Compat ───────────── v2.2.0
  Installed PDMats ───────────── v0.9.11
  Installed DataAPI ──────────── v1.1.0
  Installed Distributions ────── v0.22.4
  Installed StatsFuns ────────── v0.9.3
  Installed LegacyStrings ────── v0.4.1
  Installed Rmath ────────────── v0.6.0
  Installed NearestNeighbors ─── v0.4.4
  Installed Arpack_jll ───────── v3.5.0+2
  Installed URIParser ────────── v0.4.0
  Installed FillArrays ───────── v0.8.4
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         #                                                                          2.6%######                                                                     8.5%###########                                                               16.0%##################                                                        26.3%############################                                              39.2%#######################################                                   55.2%################################################                          67.6%#################################################################         91.2%######################################################################## 100.0%
#=#=#                                                                         ##############################                                            42.5%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       #######################################                                   54.7%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_h0eBYd/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -5.387585450016642e6, [5561.657133183781, 94438.34286681622], [6428.846991773292 4321.610150974792 -2520.211410899063; -6043.756082735275 -4177.63357783026 2299.901646124941], [[9931.032579384642 2423.7936610860634 -1916.1456730054224; 2423.7936610860634 6881.925805589206 -1180.4888427208325; -1916.1456730054226 -1180.4888427208325 6434.677843507607], [89970.9253939188 -2035.9979636542064 2550.122412189409; -2035.9979636542064 93663.46289170466 1345.6312464318344; 2550.1224121894093 1345.6312464318346 94036.3959181819]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.893124e+02
      1       8.907871e+02      -9.852531e+01 |        2
      2       8.835116e+02      -7.275453e+00 |        0
      3       8.835116e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 883.5116259381402)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.083242
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.899215
[ Info: iteration 2, lowerbound -3.778541
[ Info: iteration 3, lowerbound -3.625901
[ Info: iteration 4, lowerbound -3.428814
[ Info: iteration 5, lowerbound -3.220742
[ Info: iteration 6, lowerbound -3.042579
[ Info: iteration 7, lowerbound -2.922586
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.858189
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.808036
[ Info: iteration 10, lowerbound -2.772295
[ Info: iteration 11, lowerbound -2.759718
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.741682
[ Info: iteration 13, lowerbound -2.715192
[ Info: iteration 14, lowerbound -2.680254
[ Info: iteration 15, lowerbound -2.630688
[ Info: iteration 16, lowerbound -2.567834
[ Info: iteration 17, lowerbound -2.499419
[ Info: iteration 18, lowerbound -2.436735
[ Info: iteration 19, lowerbound -2.386796
[ Info: iteration 20, lowerbound -2.349551
[ Info: iteration 21, lowerbound -2.323208
[ Info: iteration 22, lowerbound -2.309136
[ Info: iteration 23, lowerbound -2.308841
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302915
[ Info: iteration 25, lowerbound -2.299259
[ Info: iteration 26, lowerbound -2.299256
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Feb  3 10:46:22 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Feb  3 10:46:30 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Mon Feb  3 10:46:33 2020: EM with 272 data points 0 iterations avll -2.083242
5.8 data points per parameter
, Mon Feb  3 10:46:35 2020: GMM converted to Variational GMM
, Mon Feb  3 10:46:43 2020: iteration 1, lowerbound -3.899215
, Mon Feb  3 10:46:43 2020: iteration 2, lowerbound -3.778541
, Mon Feb  3 10:46:43 2020: iteration 3, lowerbound -3.625901
, Mon Feb  3 10:46:43 2020: iteration 4, lowerbound -3.428814
, Mon Feb  3 10:46:43 2020: iteration 5, lowerbound -3.220742
, Mon Feb  3 10:46:43 2020: iteration 6, lowerbound -3.042579
, Mon Feb  3 10:46:43 2020: iteration 7, lowerbound -2.922586
, Mon Feb  3 10:46:43 2020: dropping number of Gaussions to 7
, Mon Feb  3 10:46:43 2020: iteration 8, lowerbound -2.858189
, Mon Feb  3 10:46:43 2020: dropping number of Gaussions to 4
, Mon Feb  3 10:46:43 2020: iteration 9, lowerbound -2.808036
, Mon Feb  3 10:46:43 2020: iteration 10, lowerbound -2.772295
, Mon Feb  3 10:46:43 2020: iteration 11, lowerbound -2.759718
, Mon Feb  3 10:46:43 2020: dropping number of Gaussions to 3
, Mon Feb  3 10:46:43 2020: iteration 12, lowerbound -2.741682
, Mon Feb  3 10:46:43 2020: iteration 13, lowerbound -2.715192
, Mon Feb  3 10:46:43 2020: iteration 14, lowerbound -2.680254
, Mon Feb  3 10:46:43 2020: iteration 15, lowerbound -2.630688
, Mon Feb  3 10:46:43 2020: iteration 16, lowerbound -2.567834
, Mon Feb  3 10:46:43 2020: iteration 17, lowerbound -2.499419
, Mon Feb  3 10:46:43 2020: iteration 18, lowerbound -2.436735
, Mon Feb  3 10:46:43 2020: iteration 19, lowerbound -2.386796
, Mon Feb  3 10:46:43 2020: iteration 20, lowerbound -2.349551
, Mon Feb  3 10:46:43 2020: iteration 21, lowerbound -2.323208
, Mon Feb  3 10:46:43 2020: iteration 22, lowerbound -2.309136
, Mon Feb  3 10:46:43 2020: iteration 23, lowerbound -2.308841
, Mon Feb  3 10:46:43 2020: dropping number of Gaussions to 2
, Mon Feb  3 10:46:43 2020: iteration 24, lowerbound -2.302915
, Mon Feb  3 10:46:43 2020: iteration 25, lowerbound -2.299259
, Mon Feb  3 10:46:44 2020: iteration 26, lowerbound -2.299256
, Mon Feb  3 10:46:44 2020: iteration 27, lowerbound -2.299254
, Mon Feb  3 10:46:44 2020: iteration 28, lowerbound -2.299254
, Mon Feb  3 10:46:44 2020: iteration 29, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 30, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 31, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 32, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 33, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 34, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 35, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 36, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 37, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 38, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 39, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 40, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 41, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 42, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 43, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 44, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 45, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 46, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 47, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 48, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 49, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: iteration 50, lowerbound -2.299253
, Mon Feb  3 10:46:44 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549077739752, 178.04509222602476]
β = [95.9549077739752, 178.04509222602476]
m = [2.000229257775279 53.85198717246081; 4.250300733269822 79.28686694436054]
ν = [97.9549077739752, 180.04509222602476]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611949952 -0.008953123827347855; 0.0 0.012748664777409728], [0.18404155547483392 -0.0076440490423285; 0.0 0.00858170516633191]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -1.0080640179273241
avll from llpg:  -1.0080640179273228
avll direct:     -1.0080640179273228
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9890997543601429
avll from llpg:  -0.9890997543601429
avll direct:     -0.9890997543601429
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.134601    -0.0997537    -0.091115   -0.0240413   -0.18323      0.0790422   -0.316202     0.0167833   -0.0497697   -0.141023    -0.0942429   -0.0295715    0.0451247   -0.061881    0.0812403    0.00491252    0.0134391     0.110471   -0.0364013    0.03885     0.108443    -0.0514158    0.109281      0.00520352   0.0699026    0.127973
 -0.144052     0.153568     -0.18275    -0.160363    -0.154059    -0.0543864   -0.075468     0.132448     0.0265757    0.0855337    0.101809    -0.0325957    0.0139943   -0.0313198  -0.0740907   -0.000441779   0.0164001     0.150254   -0.111365     0.0458142  -0.106751    -0.0145225    0.084193      0.165891     0.0697277   -0.110081
 -0.155698     0.0833162     0.0252407  -0.0438913    0.0943137    0.0199347    0.0134      -0.108323    -0.0970193   -0.23634     -0.059932     0.0216429   -0.114805     0.144656   -0.0308741   -0.072066     -0.0703124    -0.101652    0.0910333    0.0812655   0.0085126    0.24192     -0.0550558    -0.0809646    0.156561    -0.156558
  0.0547045   -0.0847311     0.194868   -0.176485     0.0118046    0.0351756    0.0149836   -0.0457445    0.138323    -0.204496     0.11328     -0.00894177  -0.093893    -0.0390006   0.0599119   -0.180956      0.204568      0.172362    0.048627    -0.0997592  -0.027173     0.0795864   -0.00875523   -0.119499     0.15782     -0.0632944
  0.0681795    0.0181291     0.0857165  -0.103171     0.144784    -0.0128548    0.0572332    0.00501845  -0.0392504   -0.063323    -0.0408499   -0.0148672    0.0182263    0.061058    0.175452     0.0215696     0.0835        0.1842     -0.108616    -0.140437    0.0597865   -0.0776786   -0.142086     -0.0158166   -0.0302233    0.0512087
 -0.0157036   -0.0612446     0.0960199  -0.055169     0.0590555    0.0163452   -0.0628042    0.00198026  -0.111716     0.0228709    0.0334571   -0.129805    -0.0269715    0.149638    0.281258     0.0234623     0.0584074     0.133754    0.110187    -0.0392703  -0.198295    -0.151591    -0.184168     -0.0937362   -0.0686411   -0.0217152
  0.150502     0.0590515    -0.0972043   0.14547     -0.0567235    0.0310199    0.0212226   -0.0877937   -0.0131474   -0.0557882   -0.0573617    0.0113734    0.19067     -0.0657827  -0.0849175   -0.0250879     0.0375717     0.124424   -0.00303315  -0.200575   -0.124952     0.00258381  -0.0162346    -0.17882     -0.0389121    0.114993
 -0.0468611    0.0262789     0.0889108  -0.0555751    0.0829364   -0.114722     0.0735826   -0.0240715   -0.0191063    0.0486118   -0.00408659  -0.159291    -0.093861    -0.0115788   0.110488     0.0512798    -0.00277877    0.0353143   0.00218863   0.0631188   0.00839505  -0.0700479   -0.0190566     0.0230686   -0.075959    -0.0130951
  0.00267816  -0.00899592    0.0658876  -0.0465752   -0.111353    -0.0524539   -0.0822179    0.0709117    0.0364108   -0.0640385    0.079663     0.143849    -0.0448865   -0.10903    -0.130718     0.0350363    -0.00102274   -0.0454906   0.00473934  -0.128204   -0.0224141   -0.100348     0.0129352    -0.0184212    0.163075     0.148824
 -0.162684    -0.130768     -0.0687307  -0.0672887   -0.129416     0.0342321   -0.0717497   -0.0449902   -0.120987    -0.0764202    0.0781888    0.0811273    0.114594     0.115611    0.0212272    0.0228161     0.10819      -0.038566   -0.00407952   0.0328623   0.111271     0.0299531   -0.226331     -0.0494985    0.249362     0.00393861
 -0.115067     0.0533089     0.0412599   0.0198213    0.0597899    0.191593     0.227368    -0.0775434    0.0121766   -0.218883     0.109658     0.00846944   0.0275462    0.097982    0.30035     -0.0988738     0.0996101     0.0743703   0.0488541    0.116623    0.0341265    0.0512163   -0.110503      0.161166     0.0396121    0.0364543
 -0.171936     0.0364937     0.144457    0.0446418   -0.188681     0.0419946   -0.135824     0.00733199   0.0342617   -0.246565     0.175759     0.0506976    0.078702    -0.0554856   0.00822057  -0.127123      0.0433795    -0.236424   -0.112993     0.116939    0.187555    -0.13089      0.0151724    -0.0904825    0.0979781   -0.0420893
 -0.0689966   -0.041955     -0.0608138   0.0296288    0.125307    -0.207229    -0.162441    -0.0319654    0.0404157   -0.0786286    0.0463782    0.050071    -0.0685288    0.0204553  -0.105364     0.0295945    -0.0938071     0.0954862   0.122881    -0.0125814  -0.053445     0.0616771   -0.140508      0.0595295   -0.0064498   -0.0941191
  0.101584    -0.000273056  -0.107185    0.111366    -0.207632    -0.0556281   -0.0803965   -0.127887    -0.143011    -0.0685108   -0.202917    -0.0138323   -0.098682    -0.1959     -0.0270753    0.0367823    -0.198236     -0.007059    0.0910278    0.1038      0.0328576   -0.127235    -0.0517215    -0.0465093   -0.0660657    0.012588
 -0.117198     0.0906782    -0.127167    0.0882693   -0.0014313    0.0663585    0.00738017  -0.21507     -0.151632     0.109163     0.102252     0.133053    -0.0983486    0.0442512   0.0911573    0.0564914     0.000434495  -0.0336867  -0.0315194    0.0492703   0.115116    -0.106274    -0.0836097     0.0820108    0.0138675   -0.181862
 -0.0271977    0.0357279    -0.0412508  -0.00236348   0.00631252   0.0354723    0.095249     0.00236161  -0.0803442   -0.11958     -0.0843884    0.0933614    0.00739669  -0.0141351   0.097789    -0.127763     -0.0159232    -0.16839    -0.00626319   0.0220588   0.203857     0.0639465   -0.0406743    -0.0978796   -0.0441756   -0.163317
  0.165517    -0.151467     -0.147834    0.26553     -0.0867271   -0.0347092   -0.0722656    0.104723    -0.0179216    0.123304    -0.0759096   -0.054705    -0.145077     0.0661021  -0.124601    -0.0518949    -0.120583      0.0236482  -0.0349825    0.139857    0.117133     0.0477533    0.189394      0.056072    -0.214955    -0.124748
  0.0227499   -0.048671     -0.0808201   0.0742595   -0.170355    -0.0559759   -0.00372412   0.13784     -0.0589301   -0.131493    -0.00881843  -0.0271387   -0.0349331   -0.0220334  -0.0521662    0.0986651     0.0562135    -0.211015   -0.208561     0.0607646  -0.149457    -0.114598     0.0640398    -0.0224812   -0.0886027    0.0234797
  0.112978     0.082856      0.0310934   0.146873     0.0786085    0.0573581   -0.120873     0.234812    -0.106238    -0.0803869   -0.0839922   -0.0752588    0.00938055   0.082857   -0.0971851    0.141811     -0.0241903     0.107045   -0.0330313    0.0138989  -0.0756944   -0.0621765   -0.202775     -0.152918     0.0744119    0.063033
 -0.0366273    0.054942      0.013144   -0.0094542   -0.0695181   -0.00780159   0.133388    -0.0989505    0.0673343   -0.0201016    0.00997042  -0.09194      0.0252827    0.127626    0.0670846   -0.0626663    -0.0480295     0.130405    0.0208475    0.125892   -0.0538371    0.01303     -0.125645     -0.0508998    0.017847    -0.0167955
  0.0367546   -0.124387     -0.165149    0.0871747   -0.0268682   -0.00292972   0.0710564    0.160428     0.0441777   -0.0394508   -0.146697    -0.110373     0.00773316  -0.0913488  -0.0975589    0.265753      0.155869     -0.0594495  -0.213864    -0.184276   -0.0823653    0.144546    -0.0143299     0.0465039    0.00476704  -0.0203401
 -0.0671736    0.0314314    -0.0942452  -0.0932929    0.15993     -0.166842    -0.0512539   -0.0206668   -0.022946     0.0648217    0.0682023    0.0474462    0.0960898   -0.10489     0.0408207    0.106679     -0.159452     -0.0738036  -0.0551168   -0.09004    -0.0922967   -0.0361004   -0.166267     -0.0268839   -0.15102     -0.136933
  0.0544172    0.0433187    -0.0343333  -0.26694     -0.0978966   -0.0829206    0.0224038    0.0521442    0.0440833    0.0169358   -0.0259948   -0.0375767    0.193528    -0.0303944  -0.0048029    0.0925244     0.117793      0.0363655   0.0308204   -0.171778   -0.131519     0.0457237    0.126716      0.0762948    0.235194    -0.159953
 -0.0472722    0.140642     -0.0140558  -0.110142    -0.0684454   -0.104374    -0.0854653    0.0346632    0.0265275    0.00954695  -0.0749699    0.0367701    0.108221    -0.192465    0.0972032    0.157094     -0.139616     -0.116871   -0.00243066  -0.0149131  -0.146979     0.139217    -0.0286699    -0.0848523    0.0318789   -0.0183816
  0.0189309    0.00398011   -0.0694602  -0.00608247   0.127858     0.0118207   -0.0926669    0.0680019   -0.22371     -0.00619332  -0.0512133    0.0336627   -0.0588098    0.0458499   0.111883    -0.0993468    -0.00356446   -0.0299128   0.0558698    0.245023   -0.0696134    0.19126      0.000840702  -0.0987264    0.0615094   -0.0613971
 -0.0661501    0.00626822    0.149391   -0.140485     0.0362373   -0.0444698   -0.0820764   -0.286116     0.0710022   -0.0965587   -0.169655    -0.0627637    0.131066     0.112409    0.162016     0.0159908    -0.138608     -0.0049995  -0.0311812    0.182508    0.217668     0.0417884    0.0597046     0.0391882    0.0156883   -0.0451396
 -0.0958557   -0.0478567    -0.068179    0.188575    -0.0671572   -0.0117272    0.00674935   0.00110863   0.0842451   -0.0211365    0.273287    -0.119404    -0.0748993   -0.0302877  -0.072263     0.0106523     0.257285     -0.025593    0.00295803  -0.209264    0.0655078   -0.0160027    0.0539048     0.0198412    0.131559    -0.0726886
 -0.161075    -0.0616967    -0.0487382   0.0989335   -0.206613     0.125649    -0.181514    -0.0480251   -0.0340465    0.0931924   -0.0746906   -0.0456381    0.0761994   -0.0069641   0.156725    -0.239353     -0.0798424     0.0503611   0.0249475    0.0238561   0.0193317   -0.0196892   -0.0520633     0.0367142    0.133063     0.0731522
 -0.170487    -0.121083      0.139502   -0.222036    -0.0665528    0.0393858   -0.122477    -0.0269769   -0.0255347    0.0157972    0.0357523    0.0582484   -0.0706685    0.190644   -0.00893914  -0.0501833     0.152769      0.0708594  -0.110471    -0.0717168   0.0885865    0.184308    -0.103544      0.0738408    0.0678268    0.131515
  0.131252    -0.0463343    -0.020541    0.0590479   -0.0311351   -0.0215365    0.0764871    0.024234     0.00256214   0.0203762   -0.0422552   -0.0252583   -0.0666066   -0.0475951  -0.0960012   -0.0269011    -0.0328468    -0.0764199  -0.00238724  -0.172609   -0.196199     0.0363784   -0.0189123     0.0666934   -0.0324916   -0.0484905
  0.0414522    0.252207     -0.084438   -0.0829782    0.00954123  -0.189292     0.192452     0.237113    -0.0834678   -0.115411     0.112109     0.159958     0.134413    -0.0508249  -0.0297461   -0.145792      0.0948652     0.215177   -0.215803     0.0304268  -0.107692    -0.187482    -0.0780583    -0.090256     0.0445699    0.000566811
 -0.0691441    0.129558     -0.0663878   0.0459608   -0.163438     0.0823024    0.0213697    0.0336511    0.00165641  -0.00521147   0.00463188  -0.0140981   -0.05972     -0.187504    0.0178038    0.0463044     0.0295548     0.196461   -0.054204     0.0425052  -0.162825    -0.14981     -0.100562     -0.0797475    0.0999059   -0.0688758kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4203855524700215
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420471
[ Info: iteration 2, average log likelihood -1.420383
[ Info: iteration 3, average log likelihood -1.419680
[ Info: iteration 4, average log likelihood -1.413026
[ Info: iteration 5, average log likelihood -1.397494
[ Info: iteration 6, average log likelihood -1.391164
[ Info: iteration 7, average log likelihood -1.390020
[ Info: iteration 8, average log likelihood -1.389543
[ Info: iteration 9, average log likelihood -1.389243
[ Info: iteration 10, average log likelihood -1.389006
[ Info: iteration 11, average log likelihood -1.388765
[ Info: iteration 12, average log likelihood -1.388464
[ Info: iteration 13, average log likelihood -1.388041
[ Info: iteration 14, average log likelihood -1.387427
[ Info: iteration 15, average log likelihood -1.386787
[ Info: iteration 16, average log likelihood -1.386256
[ Info: iteration 17, average log likelihood -1.385855
[ Info: iteration 18, average log likelihood -1.385580
[ Info: iteration 19, average log likelihood -1.385401
[ Info: iteration 20, average log likelihood -1.385279
[ Info: iteration 21, average log likelihood -1.385194
[ Info: iteration 22, average log likelihood -1.385134
[ Info: iteration 23, average log likelihood -1.385091
[ Info: iteration 24, average log likelihood -1.385062
[ Info: iteration 25, average log likelihood -1.385041
[ Info: iteration 26, average log likelihood -1.385026
[ Info: iteration 27, average log likelihood -1.385015
[ Info: iteration 28, average log likelihood -1.385006
[ Info: iteration 29, average log likelihood -1.384998
[ Info: iteration 30, average log likelihood -1.384991
[ Info: iteration 31, average log likelihood -1.384984
[ Info: iteration 32, average log likelihood -1.384977
[ Info: iteration 33, average log likelihood -1.384968
[ Info: iteration 34, average log likelihood -1.384957
[ Info: iteration 35, average log likelihood -1.384943
[ Info: iteration 36, average log likelihood -1.384928
[ Info: iteration 37, average log likelihood -1.384911
[ Info: iteration 38, average log likelihood -1.384891
[ Info: iteration 39, average log likelihood -1.384868
[ Info: iteration 40, average log likelihood -1.384843
[ Info: iteration 41, average log likelihood -1.384815
[ Info: iteration 42, average log likelihood -1.384784
[ Info: iteration 43, average log likelihood -1.384749
[ Info: iteration 44, average log likelihood -1.384708
[ Info: iteration 45, average log likelihood -1.384659
[ Info: iteration 46, average log likelihood -1.384598
[ Info: iteration 47, average log likelihood -1.384521
[ Info: iteration 48, average log likelihood -1.384433
[ Info: iteration 49, average log likelihood -1.384332
[ Info: iteration 50, average log likelihood -1.384212
┌ Info: EM with 100000 data points 50 iterations avll -1.384212
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4204710702283851
│     -1.4203828781405181
│      ⋮
└     -1.384212393759659
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.384204
[ Info: iteration 2, average log likelihood -1.383930
[ Info: iteration 3, average log likelihood -1.383463
[ Info: iteration 4, average log likelihood -1.380089
[ Info: iteration 5, average log likelihood -1.365460
[ Info: iteration 6, average log likelihood -1.351593
[ Info: iteration 7, average log likelihood -1.347798
[ Info: iteration 8, average log likelihood -1.346375
[ Info: iteration 9, average log likelihood -1.345515
[ Info: iteration 10, average log likelihood -1.344932
[ Info: iteration 11, average log likelihood -1.344531
[ Info: iteration 12, average log likelihood -1.344258
[ Info: iteration 13, average log likelihood -1.344067
[ Info: iteration 14, average log likelihood -1.343917
[ Info: iteration 15, average log likelihood -1.343780
[ Info: iteration 16, average log likelihood -1.343636
[ Info: iteration 17, average log likelihood -1.343471
[ Info: iteration 18, average log likelihood -1.343271
[ Info: iteration 19, average log likelihood -1.343010
[ Info: iteration 20, average log likelihood -1.342659
[ Info: iteration 21, average log likelihood -1.342224
[ Info: iteration 22, average log likelihood -1.341694
[ Info: iteration 23, average log likelihood -1.341123
[ Info: iteration 24, average log likelihood -1.340646
[ Info: iteration 25, average log likelihood -1.340312
[ Info: iteration 26, average log likelihood -1.340103
[ Info: iteration 27, average log likelihood -1.339974
[ Info: iteration 28, average log likelihood -1.339891
[ Info: iteration 29, average log likelihood -1.339838
[ Info: iteration 30, average log likelihood -1.339805
[ Info: iteration 31, average log likelihood -1.339785
[ Info: iteration 32, average log likelihood -1.339772
[ Info: iteration 33, average log likelihood -1.339764
[ Info: iteration 34, average log likelihood -1.339759
[ Info: iteration 35, average log likelihood -1.339756
[ Info: iteration 36, average log likelihood -1.339753
[ Info: iteration 37, average log likelihood -1.339752
[ Info: iteration 38, average log likelihood -1.339751
[ Info: iteration 39, average log likelihood -1.339750
[ Info: iteration 40, average log likelihood -1.339749
[ Info: iteration 41, average log likelihood -1.339749
[ Info: iteration 42, average log likelihood -1.339749
[ Info: iteration 43, average log likelihood -1.339748
[ Info: iteration 44, average log likelihood -1.339748
[ Info: iteration 45, average log likelihood -1.339748
[ Info: iteration 46, average log likelihood -1.339748
[ Info: iteration 47, average log likelihood -1.339748
[ Info: iteration 48, average log likelihood -1.339747
[ Info: iteration 49, average log likelihood -1.339747
[ Info: iteration 50, average log likelihood -1.339747
┌ Info: EM with 100000 data points 50 iterations avll -1.339747
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3842039109219586
│     -1.3839299853123055
│      ⋮
└     -1.3397473495274177
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339943
[ Info: iteration 2, average log likelihood -1.339742
[ Info: iteration 3, average log likelihood -1.339020
[ Info: iteration 4, average log likelihood -1.332915
[ Info: iteration 5, average log likelihood -1.315543
[ Info: iteration 6, average log likelihood -1.303813
[ Info: iteration 7, average log likelihood -1.299875
[ Info: iteration 8, average log likelihood -1.297998
[ Info: iteration 9, average log likelihood -1.296585
[ Info: iteration 10, average log likelihood -1.295249
[ Info: iteration 11, average log likelihood -1.293860
[ Info: iteration 12, average log likelihood -1.292361
[ Info: iteration 13, average log likelihood -1.291051
[ Info: iteration 14, average log likelihood -1.290085
[ Info: iteration 15, average log likelihood -1.289386
[ Info: iteration 16, average log likelihood -1.288864
[ Info: iteration 17, average log likelihood -1.288496
[ Info: iteration 18, average log likelihood -1.288240
[ Info: iteration 19, average log likelihood -1.288055
[ Info: iteration 20, average log likelihood -1.287909
[ Info: iteration 21, average log likelihood -1.287782
[ Info: iteration 22, average log likelihood -1.287660
[ Info: iteration 23, average log likelihood -1.287532
[ Info: iteration 24, average log likelihood -1.287396
[ Info: iteration 25, average log likelihood -1.287265
[ Info: iteration 26, average log likelihood -1.287154
[ Info: iteration 27, average log likelihood -1.287062
[ Info: iteration 28, average log likelihood -1.286986
[ Info: iteration 29, average log likelihood -1.286925
[ Info: iteration 30, average log likelihood -1.286877
[ Info: iteration 31, average log likelihood -1.286841
[ Info: iteration 32, average log likelihood -1.286814
[ Info: iteration 33, average log likelihood -1.286793
[ Info: iteration 34, average log likelihood -1.286778
[ Info: iteration 35, average log likelihood -1.286767
[ Info: iteration 36, average log likelihood -1.286758
[ Info: iteration 37, average log likelihood -1.286752
[ Info: iteration 38, average log likelihood -1.286747
[ Info: iteration 39, average log likelihood -1.286744
[ Info: iteration 40, average log likelihood -1.286741
[ Info: iteration 41, average log likelihood -1.286739
[ Info: iteration 42, average log likelihood -1.286737
[ Info: iteration 43, average log likelihood -1.286736
[ Info: iteration 44, average log likelihood -1.286735
[ Info: iteration 45, average log likelihood -1.286735
[ Info: iteration 46, average log likelihood -1.286734
[ Info: iteration 47, average log likelihood -1.286734
[ Info: iteration 48, average log likelihood -1.286733
[ Info: iteration 49, average log likelihood -1.286733
[ Info: iteration 50, average log likelihood -1.286733
┌ Info: EM with 100000 data points 50 iterations avll -1.286733
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3399426980336848
│     -1.3397418259742477
│      ⋮
└     -1.2867325302436408
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.286969
[ Info: iteration 2, average log likelihood -1.286688
[ Info: iteration 3, average log likelihood -1.285168
[ Info: iteration 4, average log likelihood -1.269681
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.238311
[ Info: iteration 6, average log likelihood -1.220163
[ Info: iteration 7, average log likelihood -1.203185
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.194139
[ Info: iteration 9, average log likelihood -1.194248
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.185651
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.198290
[ Info: iteration 12, average log likelihood -1.197023
[ Info: iteration 13, average log likelihood -1.190823
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.186045
[ Info: iteration 15, average log likelihood -1.187295
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.178497
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191281
[ Info: iteration 18, average log likelihood -1.190237
[ Info: iteration 19, average log likelihood -1.183892
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.179038
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.180764
[ Info: iteration 22, average log likelihood -1.190825
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.182237
[ Info: iteration 24, average log likelihood -1.184737
[ Info: iteration 25, average log likelihood -1.178328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.172411
[ Info: iteration 27, average log likelihood -1.193915
[ Info: iteration 28, average log likelihood -1.184175
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.178944
[ Info: iteration 30, average log likelihood -1.181710
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.174433
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.188130
[ Info: iteration 33, average log likelihood -1.187570
[ Info: iteration 34, average log likelihood -1.180965
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.175786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.177669
[ Info: iteration 37, average log likelihood -1.189947
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.181509
[ Info: iteration 39, average log likelihood -1.183970
[ Info: iteration 40, average log likelihood -1.177478
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.171518
[ Info: iteration 42, average log likelihood -1.193016
[ Info: iteration 43, average log likelihood -1.183332
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.178079
[ Info: iteration 45, average log likelihood -1.180849
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.173615
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.187222
[ Info: iteration 48, average log likelihood -1.186760
[ Info: iteration 49, average log likelihood -1.180198
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.175160
┌ Info: EM with 100000 data points 50 iterations avll -1.175160
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.286968924751073
│     -1.2866883774256728
│      ⋮
└     -1.1751598383367874
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.177445
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.173526
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.167110
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.140920
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      9
│     10
│     17
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.091760
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     13
│     17
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.062460
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.089109
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078682
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      9
│     10
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035608
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     10
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.106266
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.067833
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     13
│     17
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.057406
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      9
│     10
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.091982
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     17
│     18
│     21
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.076277
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.047093
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     17
│     18
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.098595
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074805
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     13
│     17
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.057557
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      9
│     10
│      ⋮
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.082366
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087451
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     19
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.052436
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.089778
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071559
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     10
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.063864
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.096860
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.066451
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.050449
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.081768
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.062493
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     10
│     13
│      ⋮
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.053302
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.070424
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.070676
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│     17
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.063230
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.073151
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.059633
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     10
│     13
│      ⋮
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.061748
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.082989
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.062219
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.050887
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     17
│     18
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.062502
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│     10
│     13
│      ⋮
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.053339
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.070495
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.070680
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.063233
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.073165
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.059649
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│     10
│     13
│      ⋮
│     21
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.061754
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     17
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.082984
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     10
│     17
│     18
│     21
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.062218
┌ Info: EM with 100000 data points 50 iterations avll -1.062218
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1774446998093324
│     -1.1735263989511113
│      ⋮
└     -1.062217900289923
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4203855524700215
│     -1.4204710702283851
│     -1.4203828781405181
│     -1.419680012418043
│      ⋮
│     -1.061754225559826
│     -1.0829836409462517
└     -1.062217900289923
32×26 Array{Float64,2}:
 -0.0611561    0.0278755   -0.0895272   -0.122791     0.146643    -0.159842    -0.0360374    -0.0374579    -0.0372073    0.0647727    0.0673959    0.0345722    0.107065     -0.149687     0.0467876    0.104061     -0.149864     -0.070131    -0.0649519    -0.110138    -0.0853379   -0.055817   -0.160018    -0.085426    -0.149232   -0.145039
 -0.0601125    0.0400288    4.49107e-5  -0.00379362  -0.0391956   -0.00979398   0.162115     -0.0843724     0.0641072   -0.0392786    0.00245966  -0.0914654    0.0211897     0.141959     0.061221    -0.0527817    -0.0333716     0.117023     0.0148074     0.11263     -0.0532783    0.0151835  -0.126527    -2.98594e-5   0.0150688  -0.0160115
  0.0573977   -0.023683    -0.0464174    0.0280544    0.0366964   -0.00177513   0.000548417   0.0347095    -0.107936     0.00646662  -0.0656212    0.0234468   -0.0475288    -0.00205625   0.00121706  -0.0677927    -0.0247001    -0.055391     0.0238154     0.00616124  -0.119198     0.111593   -0.0245568   -0.00101136   0.0217431  -0.0397118
 -0.0255129   -0.0810494    0.0877968   -0.0584027   -0.0896327    0.0780198   -0.0609229    -0.0489359     0.0784059   -0.0777801    0.0405511   -0.0216635   -0.0153164    -0.0233324    0.145241    -0.224185      0.0648761     0.120425     0.0463881    -0.0300661    0.0103918    0.0571476  -0.0345079   -0.0880215    0.17456    -0.0180871
 -0.060998     0.0374794    0.0896064   -0.0424959    0.0785693   -0.11622      0.0607913    -0.0194902    -0.0112264    0.0519169   -0.00796207  -0.111488    -0.0952428    -0.00545779   0.0950147    0.0279206     0.000567081   0.0295625    0.0154805     0.103351     0.0106056   -0.126       0.0121287    0.0276041   -0.0786521  -0.00515283
  0.101969     0.00215547  -0.106989     0.111198    -0.208748    -0.0568963   -0.100644     -0.139698     -0.111404    -0.0797413   -0.193509    -0.0168831   -0.0874804    -0.189744    -0.0272821    0.0465166    -0.20339      -0.00746557   0.130627      0.10048      0.0358826   -0.119648   -0.0511499   -0.0314079   -0.0650822  -0.014355
 -0.159784     0.0349324   -0.0763827   -0.0279128    0.00776732   0.03772      0.119896     -0.155859     -0.215278    -0.0853724   -0.160817     0.0940821    0.0256165     0.0223799    0.113911    -0.170041     -0.0263607    -0.187216    -0.00361228    0.0415829    0.210541    -0.0438137  -0.0107625   -0.0289058   -0.036519   -0.437882
  0.180088     0.041865     0.0179354   -0.0259861    0.0223247    0.0351813    0.0412225     0.174101      0.0221993   -0.146093     0.0181852    0.0902879    5.24161e-5   -0.103614     0.091292    -0.111993     -0.0196329    -0.175824    -0.00907395   -0.026455     0.199366     0.182203   -0.0487484   -0.196485    -0.0708053   0.141373
 -0.0916744   -0.0682386   -0.0698029    0.198036    -0.100302    -0.0137369    0.0149597    -0.00355322    0.0810337   -0.00516904   0.279105    -0.127371    -0.0742118    -0.0324638   -0.0784118    0.0142508     0.256531     -0.0380856    0.0073444    -0.195382     0.0597823   -0.0143236   0.018233     0.0243044    0.150465   -0.0903124
  0.0415794    0.248817    -0.085456    -0.0899952    0.0285356   -0.186226     0.191815      0.235397     -0.0810228   -0.143187     0.102459     0.172683     0.135089     -0.0573648   -0.0483182   -0.178538      0.0958237     0.215883    -0.217012      0.0105364   -0.118426    -0.19019    -0.12398     -0.0880167    0.0433012   0.0140745
 -0.130507    -0.105626    -0.105456    -0.0237133   -0.178062     0.0559636   -0.309026      0.00868653   -0.0502483   -0.145525    -0.098838    -0.0409904    0.0529177    -0.0738678    0.083609     0.00964053    0.0277929     0.116016    -0.0195822     0.0638347    0.106309    -0.0192825   0.0762768    0.0023865    0.0652767   0.173439
 -0.0766968   -0.133606    -0.00472876  -0.076827    -0.0451737    0.0105415   -0.0325964     0.0728417     0.0173367   -0.00926472  -0.0358568    0.0116464   -0.0323702     0.0554377   -0.0713656    0.113288      0.1529        0.00906678  -0.129647     -0.10551     -0.00548922   0.146784   -0.0620189    0.0258086    0.0378422   0.065896
 -0.0106873   -0.0038286    0.0896681   -0.0529396    0.0274787    0.0136733   -0.0590758     0.000665933  -0.117506     0.0241797    0.0335769   -0.129066    -0.0353098     0.149333     0.275564     0.0512667     0.0299253     0.135615     0.0792841    -0.00789448  -0.168348    -0.144121   -0.181161    -0.083062    -0.0662533  -0.0197568
 -0.0134347    0.0895521   -0.0578142   -0.103943    -0.133885     0.014142     0.0387089     0.0643519     0.0195576    0.00317102  -0.0119406   -0.0243032    0.0869046    -0.117138    -0.0152635    0.0664449     0.0694784     0.124158    -0.0225437    -0.0415931   -0.143032    -0.069281    0.00315901  -0.00976559   0.232127   -0.0960094
 -0.143672     0.135813    -0.153185    -0.185163    -0.162996    -0.0542145   -0.113656      0.103047      0.0255673    0.0669317    0.101457    -0.0139947    0.0324967    -0.0351823   -0.162129    -0.000538317   0.0158105     0.135186    -0.138483      0.0449663   -0.118568     0.0079002   0.0770943    0.177032     0.068348   -0.11164
  0.00239567  -0.00933454   0.0653721    0.00813358  -0.115716    -0.0526008   -0.0879963     0.0533933     0.0408575   -0.0644166    0.0759501    0.132072    -0.0585787    -0.102175    -0.11533      0.0141084    -0.00298613   -0.0186043   -0.000488685  -0.124751    -0.0186653   -0.104609    0.0144083   -0.0136698    0.140915    0.102275
 -0.0873946   -0.00865938   0.171898    -0.154225     0.0439852   -0.18485     -0.0992482    -0.276317      0.0893574   -0.0453023   -0.16996      0.319178     0.130592      0.0994812    0.158517     0.174112      0.126671     -0.00461688   0.000137634   0.180734    -0.148623     0.0912238   0.0141457    0.0448259    0.0156275  -0.151983
 -0.0578119    0.00469265   0.0893833   -0.124441     0.0232304    0.0345875   -0.0584826    -0.302342      0.0980831   -0.135153    -0.169697    -0.294991     0.118874      0.139215     0.13105     -0.127991     -0.441405     -0.00472856  -0.0512409     0.192104     0.402769     0.016151    0.107796     0.0385208    0.0155691   0.110632
 -0.100085     0.109494    -0.128305     0.0575154   -0.00249186   0.0653034    0.000375934  -0.205575     -0.15066      0.100267     0.112182     0.158354    -0.0951161     0.0650501    0.0891172    0.0591637     0.0146831    -0.0247984   -0.00938494    0.0473621    0.125454    -0.103972   -0.0962601    0.0771032    0.0320555  -0.17258
  0.0915492    0.0149606    0.107632    -0.102542     0.144832    -0.0339884    0.0495798     0.0207035    -0.0376356   -0.0633975   -0.0404216   -0.00631383   0.00954688    0.0397408    0.179716     0.0215704     0.156995      0.179611    -0.135744     -0.138712     0.0678218   -0.0801038  -0.144219    -0.041413    -0.0167284   0.0505094
 -0.0617735   -0.0439977   -0.0340835   -0.0323495    0.125105    -0.231131    -0.177388     -0.0308334     0.0403729   -0.0566819    0.0302429    0.0284417   -0.0669967     0.00155719  -0.0968042   -0.0216732    -0.0986129     0.0842082    0.110659      0.0015973   -0.0483573    0.0561521  -0.147997     0.0552091   -0.0585625  -0.0938216
 -0.0531689    0.133609    -0.0151934   -0.112442    -0.0632288   -0.0967004   -0.0938856     0.0339966     0.0187924    0.0043022   -0.0676286    0.0315788    0.1243       -0.172175     0.0570314    0.147426     -0.154205     -0.117416    -0.0153204    -0.0139805   -0.160013     0.137747   -0.0127288   -0.0830179    0.0141116  -0.017038
 -0.130973    -0.122       -0.0700839   -0.104097    -0.0787298    0.0402429   -0.069938     -0.0612175    -0.111297    -0.0845795    0.0589256    0.0692256    0.106339      0.103697     0.00566091   0.00601076    0.105015     -0.0622103    0.00110222    0.0269518    0.105467     0.0253129  -0.213836    -0.00777713   0.23524     0.00317287
 -0.151556     0.0835162    0.0320866   -0.0253381    0.0983942    0.0108587    0.0156347    -0.0835555    -0.0951452   -0.229533    -0.0507758    0.0245769   -0.12001       0.143242    -0.0125168   -0.0784966    -0.0684614    -0.128075     0.0782017     0.0531489    0.0713488    0.23315    -0.0579034   -0.078854     0.15387    -0.156282
  0.126691     0.0691449   -0.114065     0.148032    -0.164555     0.0136346    0.0367901     0.00308661    0.0254419   -0.078928    -0.0893016   -0.0117491    0.153572     -0.0779491   -0.0839841   -0.0238095    -0.612574      0.146307     0.164919     -0.311326    -0.124563    -0.126883    0.0016839   -0.181393    -0.0385736   0.16835
  0.169338     0.0471642   -0.0950961    0.241175    -0.00551093  -0.00314851   0.0084068    -0.161916     -0.0615018   -0.0268532    0.0326751    0.0269807    0.15538      -0.0641891   -0.0852909   -0.0268334     0.472165      0.11619     -0.17685      -0.143341    -0.124035     0.0843299  -0.0242943   -0.150658    -0.0422401   0.131465
  0.0189575   -0.010492    -0.0559031    0.0831978   -0.134392    -0.0983597   -0.0417155     0.119944     -0.0531715   -0.156151    -0.0679083   -0.180947    -0.0419773    -0.0279382   -0.0578909    0.132135      0.139325     -0.142913    -0.206646     -1.25179     -0.16603     -0.12486     0.0348519   -0.0228683   -0.0850244  -0.0662166
  0.0219817   -0.0360094   -0.145852     0.146091    -0.182725    -0.00535024   0.00753836    0.149461     -0.0530152   -0.0973723    0.0370024    0.167696    -0.0362844    -0.0166745   -0.0518805    0.0685691    -0.0471386    -0.282493    -0.208208      1.40642     -0.136116    -0.111993    0.151104    -0.020083    -0.0929328   0.108271
  0.205234    -0.156754    -0.160488     0.266026    -0.111328    -0.0247952   -0.071518      0.0963981    -0.0249527    0.122412    -0.11473     -0.0480028   -0.131643      0.0411123   -0.144801    -0.0454299    -0.121027     -0.00526448  -0.0857015     0.160469     0.121142     0.0553611   0.230966     0.0648358   -0.212568   -0.141263
  0.114208     0.0820234    0.0583321    0.146946     0.105976     0.0734512   -0.126679      0.222018     -0.107053    -0.0805131   -0.0839424   -0.0574362    0.000656344   0.0999246   -0.104605     0.156797     -0.0241498     0.107707    -0.0270221     0.0145894   -0.0812263   -0.0405218  -0.196645    -0.152542     0.0679415   0.0408957
 -0.18326      0.0344403    0.145325     0.0583155   -0.173231     0.0437121   -0.141218      0.0157133     0.0378393   -0.24824      0.176471     0.0377751    0.0809339    -0.0435775    0.0151443   -0.129372      0.0540982    -0.234148    -0.117361      0.106364     0.187092    -0.1147      0.0450308   -0.0903982    0.0816129  -0.0460374
 -0.068504     0.0454966    0.0387219    0.017672     0.0649273    0.196584     0.218048     -0.0746478     0.00327563  -0.216542     0.115754     0.0157173    0.0207101     0.106795     0.292929    -0.0953813     0.101534      0.0673709    0.0491296     0.139087     0.0437305    0.0443247  -0.127327     0.163222     0.0500762   0.0365694[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.050896
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.027637
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.050845
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.027419
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.050844
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.027404
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.050838
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.027408
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.050839
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.027400
┌ Info: EM with 100000 data points 10 iterations avll -1.027400
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.649433e+05
      1       6.954184e+05      -1.695249e+05 |       32
      2       6.612023e+05      -3.421620e+04 |       32
      3       6.422125e+05      -1.898972e+04 |       32
      4       6.316620e+05      -1.055049e+04 |       32
      5       6.269091e+05      -4.752951e+03 |       32
      6       6.241140e+05      -2.795108e+03 |       32
      7       6.216879e+05      -2.426092e+03 |       32
      8       6.192109e+05      -2.476985e+03 |       32
      9       6.173895e+05      -1.821378e+03 |       32
     10       6.163438e+05      -1.045702e+03 |       32
     11       6.155953e+05      -7.485423e+02 |       32
     12       6.148060e+05      -7.893197e+02 |       32
     13       6.140581e+05      -7.478831e+02 |       32
     14       6.134325e+05      -6.255832e+02 |       32
     15       6.128423e+05      -5.901883e+02 |       32
     16       6.121721e+05      -6.702548e+02 |       32
     17       6.115557e+05      -6.163728e+02 |       32
     18       6.111387e+05      -4.169516e+02 |       32
     19       6.109861e+05      -1.525921e+02 |       32
     20       6.109249e+05      -6.128563e+01 |       32
     21       6.108934e+05      -3.146505e+01 |       31
     22       6.108707e+05      -2.268595e+01 |       30
     23       6.108512e+05      -1.948151e+01 |       29
     24       6.108383e+05      -1.296391e+01 |       24
     25       6.108275e+05      -1.075588e+01 |       27
     26       6.108217e+05      -5.851134e+00 |       29
     27       6.108172e+05      -4.428139e+00 |       25
     28       6.108127e+05      -4.478462e+00 |       27
     29       6.108064e+05      -6.395117e+00 |       31
     30       6.108014e+05      -4.910394e+00 |       26
     31       6.107961e+05      -5.308206e+00 |       30
     32       6.107893e+05      -6.852723e+00 |       27
     33       6.107800e+05      -9.291468e+00 |       29
     34       6.107686e+05      -1.136521e+01 |       29
     35       6.107553e+05      -1.331298e+01 |       30
     36       6.107442e+05      -1.111419e+01 |       29
     37       6.107308e+05      -1.337053e+01 |       29
     38       6.107194e+05      -1.138850e+01 |       30
     39       6.107103e+05      -9.100907e+00 |       28
     40       6.106998e+05      -1.054662e+01 |       29
     41       6.106867e+05      -1.311547e+01 |       30
     42       6.106721e+05      -1.453483e+01 |       29
     43       6.106608e+05      -1.135179e+01 |       28
     44       6.106495e+05      -1.131694e+01 |       32
     45       6.106339e+05      -1.556039e+01 |       29
     46       6.106173e+05      -1.662865e+01 |       29
     47       6.106007e+05      -1.661854e+01 |       32
     48       6.105812e+05      -1.947430e+01 |       32
     49       6.105620e+05      -1.919984e+01 |       31
     50       6.105483e+05      -1.364383e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 610548.3449238754)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332047
[ Info: iteration 2, average log likelihood -1.301755
[ Info: iteration 3, average log likelihood -1.274808
[ Info: iteration 4, average log likelihood -1.243157
[ Info: iteration 5, average log likelihood -1.201641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.151946
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     13
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.117948
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106819
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.125777
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.092539
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     13
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.074293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083060
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.073803
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     18
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065972
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     15
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.073015
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.085530
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     16
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.066505
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.098031
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     13
│     15
│     18
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.038606
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     22
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.086492
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.097417
[ Info: iteration 22, average log likelihood -1.078154
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.024152
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.124692
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.081893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.067373
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     13
│     15
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.047974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.102605
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     16
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.063117
[ Info: iteration 30, average log likelihood -1.091043
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     13
│     15
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.028837
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.092155
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093854
[ Info: iteration 34, average log likelihood -1.074255
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.020523
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.122876
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.082243
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.067919
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     13
│     15
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.048269
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.102382
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     16
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063125
[ Info: iteration 42, average log likelihood -1.090764
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     13
│     15
│     18
│     20
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.026124
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     21
│     22
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.081677
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102346
[ Info: iteration 46, average log likelihood -1.084510
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│      ⋮
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.031981
[ Info: iteration 48, average log likelihood -1.117455
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.060847
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     13
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.070872
┌ Info: EM with 100000 data points 50 iterations avll -1.070872
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.144187     0.136235    -0.151281    -0.188637    -0.162125    -0.0542944   -0.112739     0.102625      0.0260553    0.0674317    0.101592    -0.0147026    0.031564     -0.0355739   -0.159821    -0.000733223   0.0153339    0.135194    -0.139334     0.0455844   -0.116405     0.00809745   0.0767896    0.174884      0.0719754   -0.110036
 -0.0733205   -0.00131268   0.129817    -0.138114     0.0343332   -0.0786575   -0.0768813   -0.289739      0.0920089   -0.0894146   -0.169523     0.0144202    0.124766      0.118074     0.144724     0.0241375    -0.154616    -0.00403594  -0.0267489    0.186365     0.126602     0.0527621    0.0607073    0.041804      0.0157371   -0.021293
  0.0207234   -0.0224262   -0.0983696    0.114124    -0.157897    -0.0528091   -0.0176946    0.13352      -0.0522186   -0.126086    -0.0149339   -0.0115247   -0.039103     -0.0222351   -0.0552625    0.10233       0.0502774   -0.208823    -0.207259     0.0380034   -0.14979     -0.118163     0.0941317   -0.0215834    -0.0863435    0.0185884
  0.0486557    0.148049    -0.0587881   -0.179359    -0.0427268   -0.132822     0.0885246    0.152634     -0.0266498   -0.0617022    0.0385554    0.0517124    0.158949     -0.041657    -0.0347888   -0.0349774     0.116035     0.11401     -0.0828877   -0.0805585   -0.128519    -0.0740734    0.00789343   0.0103356     0.166863    -0.071043
 -0.0621053    0.0446215    0.0873095   -0.0407332    0.0844848   -0.119496     0.0627835   -0.0191803    -0.00839326   0.0510994   -0.00268575  -0.116409    -0.0938846    -0.00418654   0.0947982    0.0227505     0.00561489   0.0305921    0.0170248    0.102415     0.0121476   -0.131728     0.0115454    0.0319383    -0.0785318   -0.00408053
 -0.0504441    0.127225    -0.0160712   -0.109364    -0.0619521   -0.0948903   -0.0902803    0.0327418     0.0198404    0.00240778  -0.0568461    0.0280702    0.121504     -0.161682     0.054609     0.132007     -0.133022    -0.119723    -0.013733    -0.0200233   -0.148498     0.129835    -0.0243036   -0.0825768     0.0202252   -0.0182669
 -0.0637314    0.0254228   -0.084651    -0.118258     0.143999    -0.15652     -0.0306419   -0.0401476    -0.0330287    0.0658371    0.0671615    0.0335711    0.109927     -0.144434     0.0483085    0.104085     -0.154026    -0.0674977   -0.0609158   -0.113035    -0.0830642   -0.0539461   -0.164061    -0.0845862    -0.147998    -0.139867
  0.0897555    0.0170544    0.104776    -0.102608     0.144903    -0.0313761    0.0470163    0.018602     -0.0382351   -0.0625638   -0.0432649   -0.00673172   0.00819571    0.0408498    0.176722     0.0231788     0.158209     0.179353    -0.134414    -0.136647     0.0680559   -0.0805207   -0.143932    -0.0403736    -0.0148872    0.0491577
  0.150444     0.0569866   -0.103651     0.200701    -0.0751236    0.00373732   0.0208768   -0.0890251    -0.0233719   -0.0495781   -0.020147     0.0100805    0.155471     -0.0701866   -0.0846752   -0.0256223    -0.00651386   0.129189    -0.0262597   -0.217567    -0.124248    -0.00879218  -0.0129582   -0.164225     -0.0406917    0.148264
  0.105752     0.0736153    0.026266     0.160195     0.121426     0.104409    -0.116574     0.213757     -0.0957923   -0.0468374   -0.0758654   -0.0576382   -0.00630534    0.095417    -0.109102     0.13938      -0.0320666    0.116537    -0.0392171    0.0346701   -0.0479072   -0.0321741   -0.181169    -0.128397      0.0421226    0.0293589
 -0.129358    -0.107058    -0.101463    -0.0230803   -0.176335     0.0553493   -0.298901     0.0169753    -0.0461032   -0.140366    -0.0862389   -0.0449847    0.0492658    -0.0695702    0.079703     0.0211495     0.0317532    0.115931    -0.0203921    0.0480493    0.107526    -0.02188      0.0845275   -0.000161015   0.0654724    0.176012
 -0.185609    -0.0850803   -0.0597663    0.100258    -0.211259     0.132214    -0.165116    -0.0515038    -0.023943     0.0930994   -0.0720073   -0.0448188    0.0857675    -0.00276079   0.180409    -0.233004     -0.120265     0.0520961    0.0385947    0.0347272    0.036674    -0.0201368   -0.0511662   -0.000399984   0.119844     0.0621949
 -0.103918     0.109068    -0.127306     0.0611251   -0.00330508   0.0633546    0.00318254  -0.205788     -0.148886     0.101388     0.117211     0.155892    -0.0941296     0.0617992    0.0905378    0.0571405     0.0184576   -0.0281779   -0.00851667   0.0479697    0.124202    -0.104403    -0.0975197    0.0771689     0.0368746   -0.174009
  0.0304397   -0.126838    -0.154084     0.0935143   -0.0182311   -0.00694928   0.0596966    0.181573      0.0447568   -0.0348922   -0.131243    -0.0952706   -0.000145589  -0.0929617   -0.0993638    0.278418      0.155097    -0.0624156   -0.210554    -0.17984     -0.0935031    0.123535    -0.0147712   -0.0159239     0.00242426  -0.00887025
  0.223508    -0.202367    -0.156824     0.280253    -0.192727    -0.0870741   -0.0723278    0.063947     -0.0252368    0.112841    -0.128128    -0.0404756   -0.134384      0.0498855   -0.153183    -0.0551501    -0.111728    -0.0500005   -0.0721731    0.164465     0.118026     0.0631331    0.263177     0.0696681    -0.210633    -0.158914
 -0.13529     -0.0743182   -0.0626558    0.467624    -0.126243    -0.00433332  -0.0152718    0.00450567    0.0442214   -0.0176916    0.299173    -0.08117     -0.0425875    -0.0177581   -0.101182     0.0460482     0.228567    -0.0414968    0.00311568  -0.18726      0.0783124   -0.0125315    0.0178142    0.022843      0.171567    -0.0810761
 -0.183441     0.034461     0.145342     0.0582551   -0.173703     0.0437294   -0.141041     0.0159298     0.0374522   -0.248369     0.176514     0.0378438    0.0809012    -0.0437511    0.0154806   -0.129642      0.0542734   -0.234303    -0.117313     0.106035     0.187197    -0.11456      0.045312    -0.0903966     0.0813303   -0.0461578
 -0.07068      0.0490225    0.0289338    0.012561     0.0641131    0.173523     0.195133    -0.0752746    -0.00418247  -0.211802     0.12935      0.0136219    0.0194531     0.101372     0.273981    -0.0843474     0.109945     0.0595735    0.0440722    0.105221     0.0510698    0.0421455   -0.138674     0.157021      0.075789     0.0296528
 -0.0682556    0.126412    -0.067804     0.0352614   -0.166266     0.0946741    0.0746144    0.0458362     0.00768052  -0.0182393    0.00992752  -0.0134135    0.00526913   -0.187378     0.00146159   0.0481202     0.0325681    0.199692    -0.0629015    0.0457774   -0.152148    -0.145539    -0.100532    -0.0787083     0.177165    -0.0621076
  0.00594154   0.0303968   -0.0206648   -0.0776364   -0.00917116   1.88006      0.0122368   -0.0622358    -0.159026    -0.233313    -0.0320263    0.0280156   -0.0980502     0.148843    -0.0409817   -0.0809459    -0.0580887   -0.107296     0.0670181    0.067493     0.193855     0.223301    -0.0731108   -0.101646      0.313311    -0.138902
  0.103891    -0.039847    -0.00732275   0.0446953   -0.0155019   -0.0343189    0.0811477    0.00254835    0.0014532   -0.0303602   -0.0922594    0.0198033   -0.0282959    -0.0438209   -0.069818    -0.0263924    -0.0238215   -0.053742    -0.00603505  -0.144142    -0.205119     0.0295074   -0.0786368    0.0368076    -0.0160282   -0.0323194
 -0.209761    -0.158681    -0.0521004   -0.235328    -0.108056     0.0293836   -0.0657278   -0.0595836    -0.0576431   -0.0763565    0.0634504    0.0444779    0.130738      0.0693108    0.0166989    0.042243      0.118669    -0.0963034    5.76502e-5   0.0422303    0.102566     0.0128525   -0.250617    -0.00527994    0.263467    -0.000911198
 -0.239848     0.0753396    0.049342    -0.0335905    0.143003    -0.821349     0.0148512   -0.0842714    -0.0574329   -0.234799    -0.0537683    0.0285466   -0.114614      0.145156    -0.00130479  -0.0789183    -0.0537142   -0.148302     0.0808564    0.0370266    0.0289184    0.223689    -0.0641682   -0.0862023     0.0888456   -0.147676
  0.117361    -0.0741537    0.148524    -0.272715    -0.0166207    0.025744     0.0271213   -0.0493068     0.117887    -0.172243     0.161945    -0.0353271   -0.105395     -0.0387687    0.0551598   -0.229071      0.227595     0.165792     0.0441015   -0.108589     0.00587052   0.0969158   -0.0103276   -0.110527      0.236337    -0.0796748
  0.00216935  -0.00677254   0.0636871    0.00962862  -0.114816    -0.0534011   -0.0862804    0.0551434     0.0385361   -0.0646266    0.0772208    0.132637    -0.0570522    -0.101334    -0.116338     0.0140202    -0.00071363  -0.0172258   -0.00201248  -0.124391    -0.0190028   -0.104765     0.0132958   -0.0185284     0.14204      0.102882
 -0.0588426   -0.00103532  -0.0152594   -0.0266861    0.0483459   -0.116364    -0.0105767   -0.0623383     0.0443111   -0.0504345    0.0181395   -0.0207189   -0.0266366     0.0795059   -0.0270319   -0.0449686    -0.055738     0.113864     0.0603871    0.0618939   -0.0499082    0.0391213   -0.143073     0.0192653    -0.0152126   -0.055403
  0.00592739   0.0389386   -0.031317    -0.025159     0.0117685    0.0354983    0.0804405    0.00384707   -0.0971624   -0.115809    -0.0692509    0.0917244    0.0117535    -0.0387129    0.100226    -0.140771     -0.0204291   -0.177851    -0.00564378   0.00747236   0.201701     0.06383     -0.0249927   -0.110896     -0.0520104   -0.151357
  0.103778     0.00326573  -0.106995     0.108986    -0.20732     -0.0563502   -0.10139     -0.140817     -0.10929     -0.0834536   -0.193934    -0.0178287   -0.0865928    -0.191917    -0.0276434    0.0463099    -0.203209    -0.00681841   0.131278     0.0989044    0.0356275   -0.125861    -0.051171    -0.0319039    -0.0639843   -0.0138941
  0.151075    -0.039498    -0.0364427    0.06825      0.0104392   -0.0236385    0.0769852   -0.000399065   0.0176966   -0.0286331    0.0192743    0.00897518  -0.101069     -0.0551073   -0.0955343   -0.0351008    -0.00835613  -0.0161347   -0.0271919   -0.175708    -0.143467     0.0117509   -0.0169477    0.0627521    -0.104755    -0.0437859
  0.0174095    0.0104256   -0.0712049   -0.00918566   0.119875     0.00482654  -0.0572176    0.0829715    -0.203838    -0.00449369  -0.0461       0.0650111   -0.0454134     0.0468344    0.105855    -0.116088     -0.00355983  -0.0350108    0.0415303    0.203783    -0.0552261    0.187162    -0.0120467   -0.0862236     0.0724835   -0.0525711
 -0.179062    -0.152337     0.1394      -0.23034     -0.0663836    0.0178441   -0.1191      -0.0306165    -0.00780321   0.0150527    0.0678072    0.116446    -0.064223      0.192545    -0.0444625   -0.0362112     0.150059     0.0716223   -0.0582651   -0.0286205    0.086279     0.168735    -0.103713     0.056098      0.071824     0.130525
 -0.0125613    0.00162985   0.0851958   -0.0534589    0.0378408    0.0129819   -0.0538366    0.00172614   -0.111699     0.0250676    0.0329831   -0.129617    -0.0488564     0.150046     0.277169     0.0491776     0.0324385    0.13764      0.0840023   -0.00591337  -0.161234    -0.151218    -0.179629    -0.0901527    -0.0716455   -0.0230663[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.087277
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     18
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.032989
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│      ⋮
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.003753
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     15
│     16
│     18
│     21
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.068228
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     15
│     18
│     20
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.040495
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│     10
│     13
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.996128
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     16
│     18
│     21
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062102
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     10
│     15
│     18
│     20
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.037396
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.003642
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     15
│     16
│     18
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.071037
┌ Info: EM with 100000 data points 10 iterations avll -1.071037
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.104807   -0.0728837    0.168213   -0.0767401   -0.066595     0.0550397  -0.191244      0.0987158    0.106475    -0.0968567     0.00203036   -0.120574     0.0914534  -0.0382886   -0.0133454  -0.164933    -0.0548453   -0.177257    0.0862954    0.218003     0.0162091     0.0163107   -0.0691387  -0.0572462    0.00259494   0.113865
 -0.155592   -0.031412     0.0587034   0.127429    -0.00648909   0.0347744  -0.0558517     0.220241    -0.117507    -0.0416569    -0.178031     -0.0701183    0.0582047  -0.04797      0.123387    0.0309933   -0.0756473    0.136738    0.0762871    0.067387     0.0973327    -0.107667     0.0174049   0.0769005   -0.0392494   -0.131586
 -0.0695285   0.135328    -0.0394884  -0.144638    -0.218499    -0.195578   -0.0846988     0.158104     0.131726    -0.0185889     0.116069     -0.0603712    0.0378918  -0.169908     0.170289   -0.07049      0.0661228    0.142223    0.0182033    0.0193501    0.157508      0.080739     0.196479   -0.08698     -0.183865    -0.144042
 -0.186171    0.0464627   -0.135624    0.121546    -0.156008     0.0530929   0.219376      0.0508308    0.0562739    0.000815594  -0.0779402    -0.21976     -0.110835    0.158726    -0.0896982   0.162174     0.0346775   -0.147379   -0.024847     0.0502663   -0.00636664    0.0569029    0.206765    0.093825     0.213686     0.0105966
 -0.0725706  -0.00744594   0.035607    0.00699494   0.0646563   -0.048507    0.170829     -0.0982848   -0.0542281    0.0181727    -0.156941      0.0531309    0.0320578   0.0452026   -0.0902091  -0.150877     0.00607314  -0.0756766   0.0196698   -0.119491    -0.114645      0.0238163    0.0413634  -0.107131     0.0272415   -0.0872043
 -0.20578     0.109184    -0.0274322  -0.143576    -0.0759922    0.202161   -0.0694238     0.242528     0.0619678   -0.0568169     0.0913612    -0.0964099   -0.0165488  -0.0448283   -0.124003   -0.149029     0.036551    -0.0483113   0.019422    -0.20053      0.0827197    -0.0618719   -0.123257   -0.11429      0.168825     0.00402252
  0.106323   -0.10834      0.0769262  -0.0423954    0.0650941    0.0619038  -0.101743      0.0485829    0.0981305   -0.0861322    -0.118442     -0.0878486   -0.0990638   0.0577566   -0.111838    0.0709643    0.0389955   -0.078605   -0.0953831    0.12596     -0.0226299    -0.189394    -0.0136857  -0.0299806   -0.17092      0.0693906
 -0.0276196  -0.121994     0.0782415  -0.180757    -0.0975749   -0.0708283  -0.0236485     0.0179042   -0.0778773   -0.0651845    -0.000980925   0.0694049    0.0199741   0.0893482   -0.106811    0.0996772    0.0933903    0.183922   -0.158675    -0.195302    -0.0117637    -0.132456    -0.145071   -0.0130758   -0.0666097    0.107795
 -0.0927031  -0.0537185   -0.142222   -0.105197     0.00617694   0.0587905  -0.11227       0.0264975    0.0695497    0.0334157     0.00464744   -0.0703351   -0.0937662  -0.110404     0.0732489   0.165085     0.0101539    0.159388   -0.119807     0.0180386    0.0559241    -0.0935575    0.0961784  -0.304345     0.0171088    0.108632
  0.203551   -0.0206324    0.06755    -0.0960861    0.0153685    0.113366   -0.000960806   0.132206     0.0385176   -0.0877668     0.0285214     0.0725063    0.128303    0.00154203  -0.0245448  -0.0276515    0.0521437    0.140284   -0.127193     0.0726155   -0.052418      0.0814929    0.268897   -0.00353575   0.184771     0.0205805
 -0.0428049   0.133644     0.0926353  -0.228917     0.0502954   -0.207735    0.0381508     0.163479     0.0603289    0.0210042     0.031515     -0.0581981    0.058915   -0.0825902    0.0915539   0.0567158   -0.0937788    0.107743    0.0809446   -0.0554686   -0.0728074     0.142569    -0.0992278  -0.194946     0.128775     0.0476932
  0.0720647   0.0279782    0.0585569   0.170214    -0.00495404  -0.0569223   0.157975      0.00910047  -0.00986545   0.066339     -0.0502007     0.191567     0.0561835  -0.0521971   -0.0620852   0.0893165   -0.0910275    0.187969   -0.04391      0.0908527    0.0704444     0.0554732    0.137119    0.00482264   0.0988939   -0.0525252
  0.0630093   0.0605048   -0.129655    0.0946152   -0.0648601    0.0215664  -0.0528023    -0.0519973   -0.0129947   -0.0860437    -0.121793     -0.00931921  -0.0458061   0.0732822    0.134169    0.19804      0.153753    -0.11891     0.21121     -0.194407    -0.0458596    -0.0739524   -0.134218   -0.0480775    0.0182299    0.160926
 -0.181542    0.18685     -0.211139   -0.208474    -0.0502819    0.0795066  -0.0561229    -0.157226    -0.0790842   -0.0271396    -0.0644843     0.0111678   -0.0604295   0.0825846    0.0121689   0.0567758   -0.209461    -0.023914    0.00719898   0.128421     0.0979266     0.0256838    0.0514744   0.0160315    0.0801647   -0.0701272
  0.0706186  -0.1687      -0.034794    0.0125424    0.0773351    0.0241742  -0.0702326     0.19547     -0.14349      0.0780191     0.0520044    -0.0158864   -0.0741416   0.138501    -0.0669262   0.0270577    0.0286136   -0.0975389  -0.138744    -0.0565052   -0.205399     -0.032407    -0.0875121   0.109037    -0.0326781   -0.0974277
 -0.0631535  -0.068949     0.0668039   0.078888     0.143621     0.014886    0.0695962     0.0357651    0.0272012    0.0252904     0.00292078   -0.0438316    0.161863   -0.0403323   -0.0065731   0.15693     -0.22126     -0.145816   -0.106515     0.0180869    0.0614114     0.062282    -0.218241    0.00978882  -0.0645622   -0.0336671
  0.0147229  -0.133681     0.113222    0.122607     0.0654252   -0.0693896   0.0730956     0.111776     0.124006    -0.0470151     0.0816853    -0.131144    -0.0105539   0.210667     0.0448986   0.142049    -0.0221017   -0.0408691  -0.0411319    0.0354463    0.141254     -0.143356    -0.087648    0.0638113   -0.156861     0.120736
  0.0932042   0.1411      -0.114327   -0.0559542    0.0333212    0.0976534  -0.0490223    -0.00678522  -0.1311      -0.0373004    -0.0371383     0.0590637    0.0312314  -0.131976    -0.0749582   0.0155345    0.0067394   -0.0507637   0.00217945   0.0610995    0.0643762     0.0429957    0.073151    0.0298361   -0.13974      0.0707675
  0.101824   -0.175191     0.15498     0.00986142   0.0584555   -0.104206    0.218935     -0.0686802   -0.0786935    0.0101219     0.124327      0.0627521   -0.0743574  -0.0389259    0.197102    0.00104609  -0.134984    -0.0502462   0.18029     -0.0232363   -0.194956      0.00865312   0.0417146  -0.0486152    0.0815048    0.0629182
 -0.106178   -0.0612612   -0.12015     0.0128722   -0.0810008    0.156299   -0.0602971     0.0620881    0.0186733   -0.0533941     0.0169722    -0.118295    -0.0259178  -0.162192    -0.22131    -0.119076     0.040902     0.142563   -0.0147843   -0.155016    -0.0102626     0.0449738   -0.141773    0.0766793   -0.0968226   -0.0216405
  0.0773571   0.00724526   0.0270192   0.0227222    0.0282751    0.113516    0.091397     -0.0424718    0.0885828   -0.213236      0.028617     -0.267957     0.117008    0.0715677   -0.0836772   0.090931    -0.214455     0.0791469  -0.0196983    0.0465762   -0.0250081     0.0754869   -0.0277088   0.122686     0.0482426   -0.145053
 -0.0272599   0.112753    -0.138236   -0.0812467    0.0322082    0.130241   -0.0751238    -0.0432522    0.19708      0.0624114     0.0952135     0.11782     -0.147141   -0.0419157   -0.135998   -0.079448    -0.0441369    0.0193648   0.129313     0.0699046   -0.0115991    -0.172608     0.295469   -0.133685     0.109302     0.0274428
  0.0841303   0.00643178   0.101271    0.193993    -0.0296137   -0.0132533   0.00850144    0.0806774    0.0661416    0.0725842    -0.150833      0.0820602   -0.0754838   0.109869     0.184371    0.180448     0.0222812   -0.143127    0.0699828    0.0781698    0.000958637  -0.00699309  -0.0476032  -0.0514365    0.0444075    0.120918
 -0.0705084   0.117264     0.0476239   0.102053     0.0838293   -0.193452    0.0297205    -0.00989026   0.0365008    0.0569976    -0.00338032   -0.0260386   -0.131847    0.062255     0.13112    -0.131479     0.00422995   0.0651722  -0.0601779    0.12159     -0.0823321     0.0823599    0.18168     0.097539     0.0887584   -0.0247748
 -0.0165619  -0.150238    -0.0157567   0.133735     0.0437038    0.0206915   0.0428943     0.0497139   -0.220827     0.107744      0.144262      0.0784643    0.159882    0.0937545   -0.0463118   0.11908      0.133259    -0.0943922  -0.109233    -0.00206256  -0.0125021     0.0453181   -0.015383   -0.0656466   -0.0802908   -0.147166
  0.0316283  -0.170662     0.107198    0.173885    -0.065245    -0.102565   -0.0307629    -0.120944    -0.0410282   -0.0541253     0.0368732     0.0550362    0.118357    0.00324301   0.203646   -0.0907175   -0.156491    -0.0961078   0.296966     0.0549653   -0.0234585     0.0696926   -0.0424218  -0.08682      0.147595     0.0925311
 -0.14971     0.0612058   -0.05796     0.234992    -0.0248635   -0.099574   -0.0191537     0.0853489   -0.289739    -0.0862061    -0.201728      0.0830736    0.0452671  -0.0766402   -0.162652   -0.0980078   -0.026524    -0.0604023   0.0520155   -0.05722     -0.0393148     0.0722259    0.052635    0.0350447    0.0417862    0.0428692
 -0.326101    0.00677289  -0.103171   -0.23296     -0.0865424    0.0130528  -0.155598      0.15426     -0.076623     0.0894346     0.060828     -0.0285285    0.0484525   0.291881     0.116082   -0.102383     0.214282     0.135099   -0.0130129   -0.0252507    0.0214047    -0.212613    -0.0156214  -0.00715417  -0.0133686   -0.0278448
 -0.0753052  -0.107597    -0.0106024   0.217671     0.038814     0.0240596  -0.092665      0.0840745   -0.0269603    0.0749023    -0.0806744    -0.14513      0.0256214  -0.19144      0.111892    0.0390722   -0.13019     -0.0357732   0.00265296  -0.172684     0.064996     -0.0901197   -0.130473   -0.0611798   -0.16797      0.114855
  0.127815    0.0914364    0.128596   -0.00709564   0.084775    -0.075539   -0.151953      0.119324    -0.00274349   0.072414      0.00491287    0.019747    -0.182257   -0.0118538   -0.123699   -0.0245701    0.0920465    0.0131334   0.25477     -0.0229261   -0.0175863     0.148865     0.258683    0.0049089   -0.0542701   -0.124393
  0.0101403  -0.0892735   -0.200857    0.0737393    0.087013    -0.0876183   0.0757682    -0.18891     -0.15594     -0.119886     -0.0212119     0.064693     0.196805   -0.0748494   -0.0732778   0.128733     0.213952    -0.192711   -0.0554085    0.198318     0.165092     -0.0258638   -0.0440175   0.114773    -0.0886628   -0.099603
 -0.116831   -0.0991027    0.0336341  -0.120603    -0.07687      0.122633    0.0995769     0.0479239    0.133814    -0.0616402    -0.130665     -0.066691    -0.0639892   0.0235425    0.0110959   0.161068    -0.00470947   0.0222164   0.0578398   -0.12234      0.0891374    -0.014547    -0.0139694   0.00746611  -0.106223    -0.0494368kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4201436441133626
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420163
[ Info: iteration 2, average log likelihood -1.420084
[ Info: iteration 3, average log likelihood -1.420020
[ Info: iteration 4, average log likelihood -1.419947
[ Info: iteration 5, average log likelihood -1.419861
[ Info: iteration 6, average log likelihood -1.419764
[ Info: iteration 7, average log likelihood -1.419652
[ Info: iteration 8, average log likelihood -1.419510
[ Info: iteration 9, average log likelihood -1.419290
[ Info: iteration 10, average log likelihood -1.418894
[ Info: iteration 11, average log likelihood -1.418189
[ Info: iteration 12, average log likelihood -1.417140
[ Info: iteration 13, average log likelihood -1.416014
[ Info: iteration 14, average log likelihood -1.415205
[ Info: iteration 15, average log likelihood -1.414797
[ Info: iteration 16, average log likelihood -1.414630
[ Info: iteration 17, average log likelihood -1.414566
[ Info: iteration 18, average log likelihood -1.414542
[ Info: iteration 19, average log likelihood -1.414532
[ Info: iteration 20, average log likelihood -1.414528
[ Info: iteration 21, average log likelihood -1.414526
[ Info: iteration 22, average log likelihood -1.414525
[ Info: iteration 23, average log likelihood -1.414525
[ Info: iteration 24, average log likelihood -1.414524
[ Info: iteration 25, average log likelihood -1.414524
[ Info: iteration 26, average log likelihood -1.414524
[ Info: iteration 27, average log likelihood -1.414523
[ Info: iteration 28, average log likelihood -1.414523
[ Info: iteration 29, average log likelihood -1.414523
[ Info: iteration 30, average log likelihood -1.414523
[ Info: iteration 31, average log likelihood -1.414522
[ Info: iteration 32, average log likelihood -1.414522
[ Info: iteration 33, average log likelihood -1.414522
[ Info: iteration 34, average log likelihood -1.414522
[ Info: iteration 35, average log likelihood -1.414522
[ Info: iteration 36, average log likelihood -1.414522
[ Info: iteration 37, average log likelihood -1.414522
[ Info: iteration 38, average log likelihood -1.414521
[ Info: iteration 39, average log likelihood -1.414521
[ Info: iteration 40, average log likelihood -1.414521
[ Info: iteration 41, average log likelihood -1.414521
[ Info: iteration 42, average log likelihood -1.414521
[ Info: iteration 43, average log likelihood -1.414521
[ Info: iteration 44, average log likelihood -1.414521
[ Info: iteration 45, average log likelihood -1.414521
[ Info: iteration 46, average log likelihood -1.414521
[ Info: iteration 47, average log likelihood -1.414521
[ Info: iteration 48, average log likelihood -1.414521
[ Info: iteration 49, average log likelihood -1.414521
[ Info: iteration 50, average log likelihood -1.414521
┌ Info: EM with 100000 data points 50 iterations avll -1.414521
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201626329757822
│     -1.4200835224765553
│      ⋮
└     -1.4145209360261664
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414537
[ Info: iteration 2, average log likelihood -1.414462
[ Info: iteration 3, average log likelihood -1.414396
[ Info: iteration 4, average log likelihood -1.414320
[ Info: iteration 5, average log likelihood -1.414229
[ Info: iteration 6, average log likelihood -1.414129
[ Info: iteration 7, average log likelihood -1.414028
[ Info: iteration 8, average log likelihood -1.413935
[ Info: iteration 9, average log likelihood -1.413855
[ Info: iteration 10, average log likelihood -1.413787
[ Info: iteration 11, average log likelihood -1.413729
[ Info: iteration 12, average log likelihood -1.413679
[ Info: iteration 13, average log likelihood -1.413638
[ Info: iteration 14, average log likelihood -1.413604
[ Info: iteration 15, average log likelihood -1.413577
[ Info: iteration 16, average log likelihood -1.413556
[ Info: iteration 17, average log likelihood -1.413540
[ Info: iteration 18, average log likelihood -1.413527
[ Info: iteration 19, average log likelihood -1.413517
[ Info: iteration 20, average log likelihood -1.413508
[ Info: iteration 21, average log likelihood -1.413500
[ Info: iteration 22, average log likelihood -1.413492
[ Info: iteration 23, average log likelihood -1.413486
[ Info: iteration 24, average log likelihood -1.413480
[ Info: iteration 25, average log likelihood -1.413474
[ Info: iteration 26, average log likelihood -1.413469
[ Info: iteration 27, average log likelihood -1.413465
[ Info: iteration 28, average log likelihood -1.413460
[ Info: iteration 29, average log likelihood -1.413456
[ Info: iteration 30, average log likelihood -1.413453
[ Info: iteration 31, average log likelihood -1.413450
[ Info: iteration 32, average log likelihood -1.413446
[ Info: iteration 33, average log likelihood -1.413444
[ Info: iteration 34, average log likelihood -1.413441
[ Info: iteration 35, average log likelihood -1.413439
[ Info: iteration 36, average log likelihood -1.413437
[ Info: iteration 37, average log likelihood -1.413435
[ Info: iteration 38, average log likelihood -1.413433
[ Info: iteration 39, average log likelihood -1.413431
[ Info: iteration 40, average log likelihood -1.413429
[ Info: iteration 41, average log likelihood -1.413428
[ Info: iteration 42, average log likelihood -1.413426
[ Info: iteration 43, average log likelihood -1.413425
[ Info: iteration 44, average log likelihood -1.413424
[ Info: iteration 45, average log likelihood -1.413423
[ Info: iteration 46, average log likelihood -1.413422
[ Info: iteration 47, average log likelihood -1.413421
[ Info: iteration 48, average log likelihood -1.413420
[ Info: iteration 49, average log likelihood -1.413419
[ Info: iteration 50, average log likelihood -1.413418
┌ Info: EM with 100000 data points 50 iterations avll -1.413418
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145365311692955
│     -1.414461511743981
│      ⋮
└     -1.4134181316018997
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413427
[ Info: iteration 2, average log likelihood -1.413373
[ Info: iteration 3, average log likelihood -1.413326
[ Info: iteration 4, average log likelihood -1.413272
[ Info: iteration 5, average log likelihood -1.413208
[ Info: iteration 6, average log likelihood -1.413131
[ Info: iteration 7, average log likelihood -1.413041
[ Info: iteration 8, average log likelihood -1.412940
[ Info: iteration 9, average log likelihood -1.412834
[ Info: iteration 10, average log likelihood -1.412726
[ Info: iteration 11, average log likelihood -1.412623
[ Info: iteration 12, average log likelihood -1.412529
[ Info: iteration 13, average log likelihood -1.412446
[ Info: iteration 14, average log likelihood -1.412376
[ Info: iteration 15, average log likelihood -1.412319
[ Info: iteration 16, average log likelihood -1.412271
[ Info: iteration 17, average log likelihood -1.412232
[ Info: iteration 18, average log likelihood -1.412199
[ Info: iteration 19, average log likelihood -1.412171
[ Info: iteration 20, average log likelihood -1.412147
[ Info: iteration 21, average log likelihood -1.412125
[ Info: iteration 22, average log likelihood -1.412105
[ Info: iteration 23, average log likelihood -1.412087
[ Info: iteration 24, average log likelihood -1.412070
[ Info: iteration 25, average log likelihood -1.412055
[ Info: iteration 26, average log likelihood -1.412040
[ Info: iteration 27, average log likelihood -1.412027
[ Info: iteration 28, average log likelihood -1.412015
[ Info: iteration 29, average log likelihood -1.412004
[ Info: iteration 30, average log likelihood -1.411994
[ Info: iteration 31, average log likelihood -1.411984
[ Info: iteration 32, average log likelihood -1.411976
[ Info: iteration 33, average log likelihood -1.411968
[ Info: iteration 34, average log likelihood -1.411960
[ Info: iteration 35, average log likelihood -1.411953
[ Info: iteration 36, average log likelihood -1.411947
[ Info: iteration 37, average log likelihood -1.411941
[ Info: iteration 38, average log likelihood -1.411936
[ Info: iteration 39, average log likelihood -1.411931
[ Info: iteration 40, average log likelihood -1.411926
[ Info: iteration 41, average log likelihood -1.411921
[ Info: iteration 42, average log likelihood -1.411917
[ Info: iteration 43, average log likelihood -1.411913
[ Info: iteration 44, average log likelihood -1.411909
[ Info: iteration 45, average log likelihood -1.411905
[ Info: iteration 46, average log likelihood -1.411901
[ Info: iteration 47, average log likelihood -1.411897
[ Info: iteration 48, average log likelihood -1.411894
[ Info: iteration 49, average log likelihood -1.411890
[ Info: iteration 50, average log likelihood -1.411887
┌ Info: EM with 100000 data points 50 iterations avll -1.411887
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4134270841199947
│     -1.413372903718924
│      ⋮
└     -1.4118870267780388
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411893
[ Info: iteration 2, average log likelihood -1.411836
[ Info: iteration 3, average log likelihood -1.411785
[ Info: iteration 4, average log likelihood -1.411728
[ Info: iteration 5, average log likelihood -1.411660
[ Info: iteration 6, average log likelihood -1.411578
[ Info: iteration 7, average log likelihood -1.411484
[ Info: iteration 8, average log likelihood -1.411381
[ Info: iteration 9, average log likelihood -1.411274
[ Info: iteration 10, average log likelihood -1.411169
[ Info: iteration 11, average log likelihood -1.411068
[ Info: iteration 12, average log likelihood -1.410976
[ Info: iteration 13, average log likelihood -1.410892
[ Info: iteration 14, average log likelihood -1.410816
[ Info: iteration 15, average log likelihood -1.410747
[ Info: iteration 16, average log likelihood -1.410684
[ Info: iteration 17, average log likelihood -1.410628
[ Info: iteration 18, average log likelihood -1.410576
[ Info: iteration 19, average log likelihood -1.410530
[ Info: iteration 20, average log likelihood -1.410489
[ Info: iteration 21, average log likelihood -1.410451
[ Info: iteration 22, average log likelihood -1.410418
[ Info: iteration 23, average log likelihood -1.410387
[ Info: iteration 24, average log likelihood -1.410360
[ Info: iteration 25, average log likelihood -1.410335
[ Info: iteration 26, average log likelihood -1.410312
[ Info: iteration 27, average log likelihood -1.410291
[ Info: iteration 28, average log likelihood -1.410272
[ Info: iteration 29, average log likelihood -1.410254
[ Info: iteration 30, average log likelihood -1.410237
[ Info: iteration 31, average log likelihood -1.410221
[ Info: iteration 32, average log likelihood -1.410206
[ Info: iteration 33, average log likelihood -1.410192
[ Info: iteration 34, average log likelihood -1.410178
[ Info: iteration 35, average log likelihood -1.410165
[ Info: iteration 36, average log likelihood -1.410152
[ Info: iteration 37, average log likelihood -1.410139
[ Info: iteration 38, average log likelihood -1.410127
[ Info: iteration 39, average log likelihood -1.410116
[ Info: iteration 40, average log likelihood -1.410104
[ Info: iteration 41, average log likelihood -1.410093
[ Info: iteration 42, average log likelihood -1.410082
[ Info: iteration 43, average log likelihood -1.410071
[ Info: iteration 44, average log likelihood -1.410061
[ Info: iteration 45, average log likelihood -1.410050
[ Info: iteration 46, average log likelihood -1.410040
[ Info: iteration 47, average log likelihood -1.410030
[ Info: iteration 48, average log likelihood -1.410021
[ Info: iteration 49, average log likelihood -1.410011
[ Info: iteration 50, average log likelihood -1.410002
┌ Info: EM with 100000 data points 50 iterations avll -1.410002
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4118929852360147
│     -1.4118361853296262
│      ⋮
└     -1.4100019810642066
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410000
[ Info: iteration 2, average log likelihood -1.409938
[ Info: iteration 3, average log likelihood -1.409875
[ Info: iteration 4, average log likelihood -1.409801
[ Info: iteration 5, average log likelihood -1.409708
[ Info: iteration 6, average log likelihood -1.409592
[ Info: iteration 7, average log likelihood -1.409454
[ Info: iteration 8, average log likelihood -1.409298
[ Info: iteration 9, average log likelihood -1.409131
[ Info: iteration 10, average log likelihood -1.408960
[ Info: iteration 11, average log likelihood -1.408794
[ Info: iteration 12, average log likelihood -1.408639
[ Info: iteration 13, average log likelihood -1.408497
[ Info: iteration 14, average log likelihood -1.408369
[ Info: iteration 15, average log likelihood -1.408255
[ Info: iteration 16, average log likelihood -1.408152
[ Info: iteration 17, average log likelihood -1.408061
[ Info: iteration 18, average log likelihood -1.407979
[ Info: iteration 19, average log likelihood -1.407907
[ Info: iteration 20, average log likelihood -1.407842
[ Info: iteration 21, average log likelihood -1.407783
[ Info: iteration 22, average log likelihood -1.407731
[ Info: iteration 23, average log likelihood -1.407683
[ Info: iteration 24, average log likelihood -1.407640
[ Info: iteration 25, average log likelihood -1.407601
[ Info: iteration 26, average log likelihood -1.407565
[ Info: iteration 27, average log likelihood -1.407531
[ Info: iteration 28, average log likelihood -1.407500
[ Info: iteration 29, average log likelihood -1.407472
[ Info: iteration 30, average log likelihood -1.407445
[ Info: iteration 31, average log likelihood -1.407419
[ Info: iteration 32, average log likelihood -1.407396
[ Info: iteration 33, average log likelihood -1.407373
[ Info: iteration 34, average log likelihood -1.407352
[ Info: iteration 35, average log likelihood -1.407332
[ Info: iteration 36, average log likelihood -1.407313
[ Info: iteration 37, average log likelihood -1.407294
[ Info: iteration 38, average log likelihood -1.407277
[ Info: iteration 39, average log likelihood -1.407260
[ Info: iteration 40, average log likelihood -1.407243
[ Info: iteration 41, average log likelihood -1.407227
[ Info: iteration 42, average log likelihood -1.407212
[ Info: iteration 43, average log likelihood -1.407197
[ Info: iteration 44, average log likelihood -1.407183
[ Info: iteration 45, average log likelihood -1.407168
[ Info: iteration 46, average log likelihood -1.407155
[ Info: iteration 47, average log likelihood -1.407141
[ Info: iteration 48, average log likelihood -1.407128
[ Info: iteration 49, average log likelihood -1.407115
[ Info: iteration 50, average log likelihood -1.407102
┌ Info: EM with 100000 data points 50 iterations avll -1.407102
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410000246060995
│     -1.4099377902790213
│      ⋮
└     -1.4071023964123313
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4201436441133626
│     -1.4201626329757822
│     -1.4200835224765553
│     -1.4200196288225544
│      ⋮
│     -1.4071279672466404
│     -1.4071150430871746
└     -1.4071023964123313
32×26 Array{Float64,2}:
 -0.61185     0.226241    -0.753628   -0.0399788    0.18025      0.155703    -0.0917543   0.245964      0.347256     0.67138    -0.334674    -0.652296    -0.4981      -0.083899   -0.20528     -0.221968    0.110214    -0.113214    -0.623109    -1.15755       0.587482    -0.278388    0.468317   -0.100149   -0.997555     0.241717
 -0.520506    0.174269    -0.216275   -0.190529     0.103964     0.0772164   -0.323771    0.531294      0.0303182   -0.0887643   0.122644    -0.239632    -0.344752    -0.05487    -0.510479    -0.285786    0.273025    -0.73354     -0.275349    -0.875287      0.0394733   -0.299103   -0.445632   -0.341672    0.211155     0.312263
 -0.388954    0.15091     -0.0206667   0.212367     0.393211    -0.131647     0.027353   -0.15117       0.0880915    0.245739    0.00968228   0.0136478   -1.29602     -0.287653   -0.38483     -0.508948    0.0918959   -0.621623     0.286115     0.590528      0.108386    -0.306329   -0.0857066  -0.1378     -0.160662    -0.0463796
 -0.493505   -0.0968748    0.14759     0.0211555   -0.461301    -0.441983    -0.415219   -0.206762      0.00901399   0.814267   -0.0758432   -0.240702     0.0298428   -0.207048   -0.233974    -0.0710206   0.0241585   -0.337418     0.469592    -0.072246      0.0437464   -0.415608    0.182047    0.672726   -0.429079    -0.633279
  0.0947653  -0.17682     -0.197857   -0.0226161    0.0568609    0.191845     0.29291    -0.289392      0.200862    -0.17097     0.467598     0.369966     0.00425816  -0.629238   -0.163731     0.184592    0.696093    -0.102594    -0.232076     0.0980549     0.149739    -1.21108    -0.482631    0.468897   -0.108982    -0.21794
  0.751329   -0.308125     0.38859    -0.0247279    0.0352306   -0.511365    -0.133258    0.457486      0.328674    -0.340408    0.147477     0.249521    -0.261693     0.0031959  -0.281958     0.362925    0.39187     -0.0479502    0.110916     0.539181     -0.584178    -0.237625   -0.257976    0.148817    0.575807    -0.471882
  0.597918    0.0331213    0.0839819  -0.449845    -0.371012     0.0116467   -0.147757    0.242291     -0.391629    -0.0146651  -0.278367     0.0464862   -0.426675     0.153067   -0.221398    -0.12679     0.300901     0.00549419  -0.0963633    0.268304     -0.0594167    0.921505   -0.281726   -0.79231     0.167364    -0.1031
  0.247405    0.441247     0.481696   -0.0183527    0.961988     0.0462493   -0.0949247   0.315531     -0.222025     0.560014    0.156639    -0.348311    -0.358465     0.0868627   0.378118    -0.0559635   0.224951     0.0243943   -0.769907     0.243546     -0.588395    -0.0977285  -0.708274   -0.335485   -0.0105469   -0.444547
 -0.297149    0.222069     0.208838    0.43911      0.232823    -0.0335113   -0.344447    0.201801     -0.387069    -0.462832    0.213141     0.356108     0.576823     0.319584   -0.304643    -0.181714   -0.233861     0.449789     0.556367    -0.405603      0.343405    -0.391179   -0.148126   -0.435607    0.460328     0.725469
  0.105156    0.0498782   -0.106692    0.0438461    0.0804453   -0.0011684    0.01065     0.0341725     0.0626468   -0.17014     0.145157    -0.135819     0.0826671   -0.193312   -0.00298601   0.144658    0.0487629   -0.0212672    0.0264742    0.0444107    -0.0936987    0.0353342   0.0625051   0.127546   -0.0915849   -0.061899
 -0.52206    -0.567679    -0.572287    0.762843    -0.720992    -0.143809     0.736065   -0.39781      -0.165558    -0.458499    0.200914     0.0345058    0.457443     0.294567    0.365012     0.146953    0.220043    -0.591501     0.564756    -0.140715      0.642989     0.396838    0.148026   -0.302816   -0.0324345    0.438455
  0.0279466   0.533026    -0.576194    0.229437     0.985437     0.307526     0.159993    0.595259      0.127591    -0.372581    0.335834     0.332331     0.192774    -0.338469    0.40757     -0.0234293   0.590087     0.0412573   -0.0558227    0.174726      0.341937     0.345539    0.398398   -0.268797   -0.0701683    0.0716001
 -0.319427    0.00928647   0.399664   -0.440813    -0.501562     0.464102     0.544928    0.0347831    -0.256379     0.134784   -0.702645    -0.0079469    0.0460712    0.630637   -0.0411844   -0.452881   -0.312868    -0.152066    -0.425089     0.000293828   0.0611671   -0.537906    0.103917    0.0036183   0.436465     0.169088
 -0.4463      0.317623     0.259631    0.314033    -0.137557     0.0245499    0.0579205   0.458521     -0.156584     0.192597   -0.704205    -0.296661    -0.162252     0.805814    0.318783    -0.160266   -0.789245     0.0421903    0.205862    -0.113878     -0.424715     0.342066    0.433708   -0.0951343   0.125847    -0.130548
 -0.361375   -0.0439986    0.222146    0.0831994   -0.244314     0.00703563   0.0909612  -0.000344448   0.43362     -0.351929    0.138462    -0.230728     0.371429     0.0602558   0.244612     0.397655   -0.886424    -0.11779     -0.0110209   -0.284004     -0.207185    -0.388375    0.181358    0.460981    0.0722848    0.68611
  0.434242   -0.370603     0.535556    0.40917     -0.422316    -0.11615      0.379046   -0.421218     -0.260435    -0.0859584  -0.439503     0.311291     0.490228     0.0613303   0.453448     0.59602    -0.704195     0.649351     0.236046     0.241116     -0.358178     0.0399987   0.413105    0.397577    0.175061    -0.35037
 -0.477245   -0.352329     0.223295    0.0522887   -0.220689     0.223583     0.370361   -0.117573     -0.0398366    0.120092   -0.534709    -0.122634    -0.246509     0.244019    0.0312124   -0.0322338  -0.0980183   -0.636105    -0.234721    -0.279863      0.261668    -0.255662   -0.0714108  -0.138401   -0.0191985    0.0529194
  0.0753913  -0.384752     0.155871   -0.35691     -0.0514529   -0.264879     0.285404    0.0197203     0.0957084    0.309728   -0.619296    -0.0200776   -0.302295     0.0710393   0.0390973    0.123362   -0.206393     0.276447    -0.321857    -0.171669     -0.0275672   -0.221644   -0.27337     0.241149   -0.227432     0.331487
  0.164915   -0.0961046   -0.0104364  -0.167763    -0.0220591   -0.0289741   -0.139058    0.115667     -0.0248249    0.043419   -0.0133246    0.0213545   -0.0822454   -0.0650481  -0.0464442    0.0341063   0.120836     0.0642757   -0.00504277   0.0158568     0.0627072    0.143956   -0.0612787  -0.0894682   0.00100066  -0.0236309
 -0.220178    0.287841     0.0561964   0.334493     0.0832724   -0.14993      0.366219    0.258289     -0.0273245    0.127995   -0.149599     0.0959174   -0.101908     0.0957347   0.194687     0.102077   -0.136668    -0.0555663   -0.0574461    0.157676     -0.323026    -0.261914    0.269025    0.102798    0.0915544   -0.231556
  0.2955     -0.450715     0.626994   -0.00982158  -0.452062    -0.198297     0.0664296  -0.760687      0.0672197    0.177115    0.180839    -0.56434      0.24349      0.265497   -0.66937     -0.0481332  -0.338312    -0.261534    -0.0700361   -0.0584385     0.449428     0.147837   -0.15663     0.132865   -0.0103085    0.0956573
  0.482575   -0.163688    -0.28176    -0.314193    -0.522364    -0.241272     0.178347    0.336289     -0.0328677   -0.28633     0.245507    -0.75087      0.218995    -0.192538   -0.0954892   -0.493485    0.386891    -0.23726      0.792451    -0.26929      -0.00317786   0.0270002  -0.0150919   0.682014   -0.395397    -0.166912
  0.103426    0.109036     0.127394    0.221891    -0.0964582    0.23779     -0.290801   -0.160136      0.096812    -0.157735    0.266197    -0.352586     0.019882    -0.228675   -0.395827    -0.326955    0.00655561  -0.400464     0.330521     0.140752     -0.0355838   -0.103122   -0.508278    0.0575516  -0.220146    -0.0322176
 -0.126063   -0.0139589   -0.22787     0.147696     0.159237     0.0801763   -0.173243   -0.250686      0.164286    -0.251674    0.474037    -0.101785     0.425605    -0.123786   -0.0258585    0.0832641  -0.186231    -0.0490378    0.322481     4.59591e-5    0.323109     0.182633    0.386547   -0.0690294  -0.00559595   0.0326896
  0.012973    0.063191     0.145753    0.151843     0.181708     0.0555558   -0.830076    0.231248     -0.097258    -0.24354    -0.0851222    0.557233     0.117116    -0.750882    0.295792     0.291502    0.167261    -0.120639    -0.11938     -0.33698      -0.125298    -0.309158    0.355411   -0.290166    0.594645    -0.466256
 -0.271605    0.13891      0.391724    0.0418427    0.0374144    0.194252    -0.140927    0.251292     -0.3922       0.0577745  -0.184718     0.430895     0.460315     0.306564    0.256887    -0.434293    0.296082     0.264361    -0.205024    -0.321494      0.399272    -0.155979    0.409629    0.200226    0.315019    -0.19242
 -0.112267    0.0827934   -0.223358   -0.105593    -0.0294551    0.251807    -0.22126     0.653547     -0.557836    -0.512239    0.135393     0.0682247   -0.1784       0.206268    0.382998    -0.379948    0.118314     0.526542     0.120605     0.242176     -0.540505    -0.171039   -0.515694   -0.300963    0.276134     0.401243
 -0.0508105   0.255456    -0.669662   -0.158623     0.00571283   0.238473     0.260062    0.147548      0.327006    -0.109842   -0.0579809    0.00930271  -0.193955     0.143079   -0.289293    -0.224103   -0.275344     0.111216     0.684676     0.667094     -0.13522      0.150869   -0.287497   -0.455395   -0.213384     0.24305
  0.186686   -0.533647    -0.0865456  -0.605094    -0.151235    -0.0880507   -0.994261   -0.147724      0.236916    -0.0199054   0.280467    -0.0801713    0.590996     0.0475369   0.18135      0.305406    0.182079     0.776812     0.171823    -0.0842162     0.102004     0.947123   -0.0255354  -0.0823608  -0.182419     0.323318
  0.27055    -0.054381    -0.406355   -0.170371     0.0644184   -0.240984     0.485558    0.0922179    -0.0940447   -0.195962    0.273195    -0.0231449    0.303455     0.311313    0.195488     0.450582   -0.0109292    0.53115     -0.348463    -0.058712     -0.0770272    0.363946    0.134069   -0.0637497  -0.0182912    0.362499
 -0.666244   -0.0241014   -0.17044     0.302982     0.647168     0.310009    -0.237535   -0.743058     -0.261956     0.177584   -0.0729263    0.618556    -0.364825    -0.19544     0.263861     1.01511    -0.293058     0.188002    -0.669264     0.499923      0.252453     0.108069   -0.104524   -0.484724   -0.157188     0.208424
  0.0859713   0.186317    -0.348033   -0.0158867    0.170838    -0.00284482   0.0080065  -0.203262      0.385067     0.42908     0.116004    -0.174559    -0.2364      -0.425723   -0.0232608    0.632874    0.285214    -0.00620103  -0.212273     0.616482      0.0348599    0.573213    0.511829    0.107028   -0.290825    -0.804378[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407090
[ Info: iteration 2, average log likelihood -1.407078
[ Info: iteration 3, average log likelihood -1.407066
[ Info: iteration 4, average log likelihood -1.407055
[ Info: iteration 5, average log likelihood -1.407043
[ Info: iteration 6, average log likelihood -1.407032
[ Info: iteration 7, average log likelihood -1.407021
[ Info: iteration 8, average log likelihood -1.407011
[ Info: iteration 9, average log likelihood -1.407000
[ Info: iteration 10, average log likelihood -1.406990
┌ Info: EM with 100000 data points 10 iterations avll -1.406990
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.152411e+05
      1       7.031984e+05      -2.120427e+05 |       32
      2       6.888598e+05      -1.433861e+04 |       32
      3       6.830156e+05      -5.844224e+03 |       32
      4       6.799294e+05      -3.086187e+03 |       32
      5       6.779377e+05      -1.991748e+03 |       32
      6       6.765378e+05      -1.399855e+03 |       32
      7       6.755264e+05      -1.011449e+03 |       32
      8       6.746880e+05      -8.383315e+02 |       32
      9       6.740260e+05      -6.620256e+02 |       32
     10       6.734682e+05      -5.578557e+02 |       32
     11       6.729918e+05      -4.764014e+02 |       32
     12       6.725684e+05      -4.233979e+02 |       32
     13       6.721671e+05      -4.012450e+02 |       32
     14       6.718322e+05      -3.349047e+02 |       32
     15       6.715283e+05      -3.038884e+02 |       32
     16       6.712607e+05      -2.676065e+02 |       32
     17       6.710192e+05      -2.415004e+02 |       32
     18       6.707906e+05      -2.285734e+02 |       32
     19       6.705693e+05      -2.213151e+02 |       32
     20       6.703716e+05      -1.977407e+02 |       32
     21       6.702138e+05      -1.577789e+02 |       32
     22       6.700749e+05      -1.389088e+02 |       32
     23       6.699376e+05      -1.373193e+02 |       32
     24       6.698065e+05      -1.310473e+02 |       32
     25       6.696801e+05      -1.264303e+02 |       32
     26       6.695678e+05      -1.122477e+02 |       32
     27       6.694708e+05      -9.701457e+01 |       32
     28       6.693821e+05      -8.877228e+01 |       32
     29       6.693094e+05      -7.270839e+01 |       32
     30       6.692456e+05      -6.370602e+01 |       32
     31       6.691827e+05      -6.291532e+01 |       32
     32       6.691192e+05      -6.357659e+01 |       32
     33       6.690499e+05      -6.924969e+01 |       32
     34       6.689805e+05      -6.941811e+01 |       32
     35       6.689162e+05      -6.426283e+01 |       32
     36       6.688515e+05      -6.467687e+01 |       32
     37       6.687948e+05      -5.675258e+01 |       32
     38       6.687378e+05      -5.700042e+01 |       32
     39       6.686831e+05      -5.466190e+01 |       32
     40       6.686334e+05      -4.970614e+01 |       32
     41       6.685892e+05      -4.425482e+01 |       32
     42       6.685436e+05      -4.559033e+01 |       32
     43       6.684964e+05      -4.714188e+01 |       32
     44       6.684543e+05      -4.211640e+01 |       32
     45       6.684176e+05      -3.671256e+01 |       32
     46       6.683788e+05      -3.881993e+01 |       32
     47       6.683426e+05      -3.617239e+01 |       32
     48       6.683079e+05      -3.476408e+01 |       32
     49       6.682712e+05      -3.667433e+01 |       32
     50       6.682362e+05      -3.501424e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668236.1636976182)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418924
[ Info: iteration 2, average log likelihood -1.413816
[ Info: iteration 3, average log likelihood -1.412348
[ Info: iteration 4, average log likelihood -1.411200
[ Info: iteration 5, average log likelihood -1.410043
[ Info: iteration 6, average log likelihood -1.409075
[ Info: iteration 7, average log likelihood -1.408465
[ Info: iteration 8, average log likelihood -1.408134
[ Info: iteration 9, average log likelihood -1.407943
[ Info: iteration 10, average log likelihood -1.407816
[ Info: iteration 11, average log likelihood -1.407720
[ Info: iteration 12, average log likelihood -1.407641
[ Info: iteration 13, average log likelihood -1.407573
[ Info: iteration 14, average log likelihood -1.407513
[ Info: iteration 15, average log likelihood -1.407459
[ Info: iteration 16, average log likelihood -1.407410
[ Info: iteration 17, average log likelihood -1.407365
[ Info: iteration 18, average log likelihood -1.407323
[ Info: iteration 19, average log likelihood -1.407284
[ Info: iteration 20, average log likelihood -1.407247
[ Info: iteration 21, average log likelihood -1.407213
[ Info: iteration 22, average log likelihood -1.407180
[ Info: iteration 23, average log likelihood -1.407149
[ Info: iteration 24, average log likelihood -1.407119
[ Info: iteration 25, average log likelihood -1.407091
[ Info: iteration 26, average log likelihood -1.407064
[ Info: iteration 27, average log likelihood -1.407039
[ Info: iteration 28, average log likelihood -1.407015
[ Info: iteration 29, average log likelihood -1.406992
[ Info: iteration 30, average log likelihood -1.406970
[ Info: iteration 31, average log likelihood -1.406950
[ Info: iteration 32, average log likelihood -1.406930
[ Info: iteration 33, average log likelihood -1.406911
[ Info: iteration 34, average log likelihood -1.406894
[ Info: iteration 35, average log likelihood -1.406877
[ Info: iteration 36, average log likelihood -1.406860
[ Info: iteration 37, average log likelihood -1.406845
[ Info: iteration 38, average log likelihood -1.406830
[ Info: iteration 39, average log likelihood -1.406816
[ Info: iteration 40, average log likelihood -1.406802
[ Info: iteration 41, average log likelihood -1.406788
[ Info: iteration 42, average log likelihood -1.406775
[ Info: iteration 43, average log likelihood -1.406763
[ Info: iteration 44, average log likelihood -1.406751
[ Info: iteration 45, average log likelihood -1.406740
[ Info: iteration 46, average log likelihood -1.406728
[ Info: iteration 47, average log likelihood -1.406718
[ Info: iteration 48, average log likelihood -1.406707
[ Info: iteration 49, average log likelihood -1.406698
[ Info: iteration 50, average log likelihood -1.406688
┌ Info: EM with 100000 data points 50 iterations avll -1.406688
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -1.89832e-5  -0.311833    0.710299     0.18557    -0.635088    0.00870197   0.012935    -0.391523     0.12669     0.176309     0.229807    -0.898551     0.131356    0.33704     -0.49718    -0.222223   -0.162983   -0.385222   -0.0655006   -0.0304355    0.184279    -0.0816148   -0.431812     0.218294   -0.105476    0.236326
  0.131769     0.350869   -0.172388     0.393479    0.800075    0.16137      0.363802     0.137663     0.279001   -0.159507     0.15981      0.133848    -0.309221   -0.22658      0.392658    0.525548    0.591091   -0.348963   -0.910291     0.0755561   -0.309591    -0.427609    -0.259133    -0.201621    0.0404015  -0.296269
 -0.660492     0.0606306  -0.469528    -0.0273654   0.113129    0.114087    -0.104951     0.364362     0.190691    0.467837    -0.345148    -0.499445    -0.529644   -0.0134455   -0.261307   -0.17632     0.19068    -0.333347   -0.578024    -1.12033      0.253499    -0.419029     0.156469    -0.184647   -0.496775    0.125754
 -0.471037    -0.069011    0.256185    -0.023368   -0.367172   -0.343094    -0.829967    -0.0884715   -0.222127    0.872334    -0.136809     0.00158346   0.15259    -0.262499    -0.10569    -0.186088    0.0165464  -0.189055    0.55335     -0.200179     0.00475464  -0.342614     0.242405     0.566347   -0.292363   -0.65397
 -0.395831    -0.0400964  -0.15179     -0.426113   -0.108332    0.157222     0.548305    -0.453671     0.346382    0.366703    -0.349002     0.0988199   -0.57296    -0.0226714   -0.0262306   0.200811   -0.029306   -0.0976512   0.00679102   0.426016     0.515848    -0.622643    -0.00865085   0.570942   -0.729254   -0.00716228
  0.23467     -0.640193   -0.112349    -0.739892   -0.230491   -0.105442    -0.961095    -0.202121     0.240704   -0.00104535   0.253823    -0.0700556    0.58577     0.0704958    0.195772    0.317056    0.218783    0.835015    0.132042    -0.127231     0.0728509    1.01038     -0.0207295   -0.0624243  -0.215221    0.285448
  0.433776     0.161614    0.432243    -0.157692    0.225306   -0.012528     0.028202     0.372438     0.0273074   0.373618    -0.075105     0.125366    -0.301006    0.0586173   -0.394635   -0.258252    0.411128   -0.0524913  -0.37178      0.53408     -0.386718    -1.08652     -0.0442941    0.791869    0.470621   -0.489303
  0.244232    -0.508866    0.587425     0.401603   -0.260158   -0.123975     0.386903    -0.403949    -0.396893    0.0907865   -0.374928     0.328658     0.596003    0.0586411    0.562564    0.693897   -0.737362    0.483038    0.0294527    0.00793745  -0.339283     0.0470314    0.436663     0.513859   -0.0477881  -0.330556
 -0.545136     0.043381   -0.143434     0.149009    0.672499    0.175429    -0.243663    -0.548479    -0.0846416   0.422879    -0.132362     0.418269    -0.362864   -0.112603     0.264002    0.95815    -0.42365     0.202232   -0.56894      0.453326     0.203595     0.382302     0.121706    -0.458778   -0.0244952   0.0545384
 -0.296691    -0.300681   -0.203506     0.498327   -0.200564   -0.148342     0.238585    -0.207724    -0.312379   -0.531416     0.188126     0.241907     0.51946     0.348101    -0.0764272   0.170725   -0.0672814   0.111502    0.437271    -0.262547     0.630892     0.00772486  -0.0717396   -0.20051    -0.0954485   1.03545
 -0.261948     0.364038    0.0370909   -0.0774373  -0.115731    0.118897     0.192279     0.253652     0.283693   -0.087754     0.0629266   -0.290372     0.837631    0.607483     0.436177    0.264903   -0.552741    0.32435    -0.100187    -0.410453    -0.0665853   -0.289989     0.434132     0.43269     0.169128    0.380897
  0.0885238   -0.0208198  -0.429679     0.523309    0.0953175   0.523918    -0.62505     -0.372425    -0.0583615  -0.500382     0.821262     0.105473     0.391923   -0.921309     0.130106    0.608213    0.281166    0.199067    0.331151     0.222444    -0.195596    -0.135746    -0.337009    -0.58303    -0.0584997  -0.430452
 -0.481548     0.380533    0.141238     0.379663   -0.201637    0.16778      0.152781     0.0369891    0.0574034   0.0623587   -0.46754     -0.096932    -0.578463    0.344739    -0.0267445  -0.0923301  -0.990734   -0.218755    0.395151     0.476828    -0.697942    -0.0556296    0.180241    -0.223176    0.0883033  -0.271329
  0.0415001   -0.323742    0.107424     0.345996    0.402264   -0.13496     -0.0367446   -0.0399918   -0.354161    0.313741    -0.34834      0.189029    -1.06089    -0.41772     -0.130762   -0.301142    0.610906   -0.43988     0.155147     0.504667    -0.102785     0.226276    -0.597233    -0.405307   -0.0103714  -0.319167
  0.87513      0.116431   -0.0634607   -0.251968    0.28931    -0.244652    -0.095851    -0.0611709    0.0356725   0.233231     0.27376     -0.635806    -0.36943    -0.131538    -0.241943   -0.21053     0.19795     0.0386093   0.0299398    0.403196    -0.231664     0.469939    -0.44922      0.0700304  -0.804909    0.0698749
 -0.320569     0.578262   -0.399602    -0.735775    0.396657    0.504004    -0.241982     0.520622     0.0402437  -0.0542712    0.264321    -0.108033    -0.102484    0.356877    -0.104673   -0.440052    0.140142   -0.277212   -0.0857633    0.136205     0.0786692    0.553113    -0.264173    -1.00066    -0.0731812   0.403282
 -0.0876256    0.130052   -0.219749    -0.0487031   0.0809279   0.140482    -0.0561785    0.604125    -0.390406   -0.450368     0.107248     0.120308    -0.182054    0.259867     0.331851   -0.288107    0.072684    0.556248    0.0903771    0.249546    -0.463414    -0.152787    -0.475032    -0.288601    0.254213    0.478183
  0.0802676   -0.243361   -0.0506611   -0.208115    0.0959583  -0.118513     0.042257    -0.0593905    0.0311456   0.0863625    0.00342017  -0.0855918   -0.0190623   0.0272002   -0.0529537   0.153452    0.0121538   0.0151408  -0.208813    -0.186757     0.140543     0.0329828   -0.135544     0.0493283  -0.184861    0.159405
  0.500376    -0.111686   -0.00763892  -0.487146   -0.441272   -0.253603     0.28452      0.319694    -0.0622383   0.177848    -0.363417    -0.0466126   -0.369409    0.136535     0.0883198   0.390838    0.0454501   0.17551    -0.309039     0.292388    -0.496063     0.405207    -0.18787     -0.239482    0.0742376  -0.180783
 -0.309479    -0.398491    0.399236    -0.240057   -0.298263    0.199149     0.39615      0.0828444   -0.310986   -0.064143    -0.75259      0.0997256   -0.0213073   0.234118     0.127123   -0.284346   -0.681898   -0.159033   -0.332748    -0.512594    -0.184083    -0.521888    -0.316617    -0.0626367   0.380154    0.663581
 -0.686637     0.688555   -0.160682     0.136533    0.55075    -0.161012    -0.180545    -0.00875268   0.397646   -0.0880089    0.720563     0.164874    -0.42835    -0.660522    -0.507542   -0.866369    0.129582   -0.543362    0.236281     0.0615701    0.643965    -0.615431     0.168527    -0.201482    0.371687    0.371356
  0.0286508    0.113265   -0.261016    -0.0363245  -0.0468055   0.29449     -0.104802    -0.0090771    0.0754741  -0.159881     0.160553    -0.138564     0.0596855  -0.048673    -0.272816   -0.302666   -0.15329    -0.192295    0.532508     0.233245    -0.00462166   0.0606788   -0.171816    -0.107933   -0.1565      0.0292798
  0.47506      0.170087    0.287921    -0.0913405   0.0340815  -0.145408    -0.42691      0.395525    -0.334136   -0.512014     0.429106     0.298049     0.445698   -0.0869731   -0.0701094  -0.0290976   0.103839    0.266331    0.00346699   0.134063    -0.599777     0.150927     0.0263144   -0.381286    1.14963    -0.453841
 -0.0825237   -0.0127525  -0.347794     0.478735    0.130253   -0.21816      0.167998    -0.161603     0.444288   -0.117038     0.69066     -0.645145    -0.0814235  -0.376087    -0.0122187   0.535728   -0.0415687  -0.389989    0.193017     0.0121768   -0.0352361    0.406109     0.455037     0.313302   -0.419268   -0.272524
  0.226695     0.281313   -0.494327     0.0536166   0.563835    0.0787227   -0.00744164   0.465875     0.0225124  -0.253306     0.119407     0.663736     0.380695   -0.400965     0.319325    0.156693    0.660195    0.48001    -0.0396936    0.295753     0.405401     0.402052     0.471323    -0.0151686  -0.0762055  -0.0583254
  0.20552     -0.283635   -0.348307    -0.245846   -0.542211   -0.201388     0.227849     0.246794     0.247293   -0.526242     0.362354    -0.48618      0.267978   -0.467752    -0.211263   -0.395855    0.516691   -0.357979    0.78381     -0.369117    -0.0531453   -0.503629    -0.184652     0.635609   -0.237986   -0.390807
 -0.180048     0.248488   -0.300186    -0.0128193  -0.492036    0.472009     0.931416    -0.168089    -0.707254    0.0632167   -0.357599    -0.126819     0.355224    0.698207    -0.289755   -0.220072    0.660279   -0.145194   -0.166129     0.212622     0.648738     0.351711     0.355459    -0.377739    0.401836   -0.725324
  0.611029    -0.299647    0.155795    -0.201186   -0.421787   -0.660988     0.103562    -0.793787     0.846562   -0.360181    -0.132586     0.182521     0.289387   -0.205766    -0.379654    0.239609   -0.597078    0.220972    0.330502     0.228203     0.367392     0.356893     0.375319    -0.144391    0.511421    0.135237
 -0.193871     0.170838    0.0555226    0.290846    0.0743403  -0.0497592    0.123661     0.217032    -0.0331752   0.0768136   -0.0877206    0.165395     0.0548032   0.00735668   0.188858    0.0707655  -0.0158558   0.043561   -0.0105063    0.120922    -0.151418    -0.104846     0.337546     0.0104438   0.148213   -0.232089
 -0.164361    -0.103529    0.0990321    0.205461   -0.0808038   0.0205068    0.0254718    0.0451337    0.0196761  -0.109441    -0.0643363    0.0168815    0.0526399  -0.0260787    0.0161746   0.0805026  -0.0779731  -0.0583332   0.0840809   -0.129955     0.104717    -0.182584     0.127714     0.111981    0.0707083   0.117292
 -0.116666    -0.0432943   0.52516      0.0892027   0.0256719   0.21739     -0.566202     0.112023    -0.137789   -0.215967    -0.249745     0.410855     0.0270007  -0.167781     0.04041    -0.153455    0.190793   -0.200502   -0.168574    -0.418867     0.382472    -0.226915     0.104457    -0.203086    0.461211   -0.235101
 -0.0534535   -0.0673308   0.234336    -0.11226    -0.0976876  -0.516249    -0.189605     0.847736    -0.439915    0.195632    -0.596693    -0.723085    -0.0178487   0.922644     0.307113   -0.54446    -0.231306    0.0400331   0.269017    -0.328416     0.271516     0.707356     0.543032     0.251256    0.0386151   0.221588[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406679
[ Info: iteration 2, average log likelihood -1.406670
[ Info: iteration 3, average log likelihood -1.406662
[ Info: iteration 4, average log likelihood -1.406654
[ Info: iteration 5, average log likelihood -1.406646
[ Info: iteration 6, average log likelihood -1.406638
[ Info: iteration 7, average log likelihood -1.406631
[ Info: iteration 8, average log likelihood -1.406624
[ Info: iteration 9, average log likelihood -1.406618
[ Info: iteration 10, average log likelihood -1.406611
┌ Info: EM with 100000 data points 10 iterations avll -1.406611
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
