Julia Version 1.5.0-DEV.224
Commit ebe261c797 (2020-02-02 23:40 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed CMakeWrapper ─────── v0.2.3
  Installed CMake ────────────── v1.1.2
  Installed Rmath ────────────── v0.6.0
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed Arpack ───────────── v0.4.0
  Installed OrderedCollections ─ v1.1.0
  Installed Blosc ────────────── v0.5.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed FillArrays ───────── v0.8.4
  Installed DataAPI ──────────── v1.1.0
  Installed Missings ─────────── v0.4.3
  Installed ScikitLearnBase ──── v0.5.0
  Installed FileIO ───────────── v1.2.1
  Installed SpecialFunctions ─── v0.9.0
  Installed Distributions ────── v0.22.4
  Installed JLD ──────────────── v0.9.2
  Installed URIParser ────────── v0.4.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed QuadGK ───────────── v2.3.1
  Installed BinDeps ──────────── v1.0.0
  Installed Compat ───────────── v2.2.0
  Installed StaticArrays ─────── v0.12.1
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed Parameters ───────── v0.12.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed LegacyStrings ────── v0.4.1
  Installed DataStructures ───── v0.17.9
  Installed SortingAlgorithms ── v0.3.1
  Installed HDF5 ─────────────── v0.12.5
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         #                                                                          2.1%####                                                                       5.6%#######                                                                   10.7%###########                                                               16.6%##################                                                        25.1%#########################                                                 35.4%###############################                                           43.4%###########################################                               60.2%#########################################################                 79.7%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_OWXC8z/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.26271192657869e6, [91210.36834198899, 8789.631658011034], [-2725.0720568621655 11197.766074415878 -4458.983202070246; 2203.4618586629686 -10984.474945632322 3885.66039818688], [[85119.48521951228 4642.878658618217 8123.08825019822; 4642.878658618217 80242.1771016997 1164.2447237755346; 8123.08825019822 1164.2447237755346 82397.02008406384], [14525.216741081374 -4691.29611804204 -7612.004718998135; -4691.29611804204 19728.380259294507 -1104.803228956699; -7612.004718998136 -1104.803228956699 17584.84538184954]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.358242e+03
      1       1.001730e+03      -3.565119e+02 |        7
      2       9.205790e+02      -8.115131e+01 |        2
      3       9.167738e+02      -3.805206e+00 |        2
      4       9.118660e+02      -4.907853e+00 |        2
      5       9.026108e+02      -9.255221e+00 |        2
      6       9.016850e+02      -9.257196e-01 |        0
      7       9.016850e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 901.6850330463103)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.085384
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.811066
[ Info: iteration 2, lowerbound -3.686582
[ Info: iteration 3, lowerbound -3.563713
[ Info: iteration 4, lowerbound -3.421399
[ Info: iteration 5, lowerbound -3.264120
[ Info: iteration 6, lowerbound -3.107474
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.970679
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.858967
[ Info: iteration 9, lowerbound -2.795085
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.771506
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.743230
[ Info: iteration 12, lowerbound -2.709679
[ Info: iteration 13, lowerbound -2.670527
[ Info: iteration 14, lowerbound -2.616679
[ Info: iteration 15, lowerbound -2.551085
[ Info: iteration 16, lowerbound -2.482977
[ Info: iteration 17, lowerbound -2.423190
[ Info: iteration 18, lowerbound -2.376674
[ Info: iteration 19, lowerbound -2.342224
[ Info: iteration 20, lowerbound -2.318602
[ Info: iteration 21, lowerbound -2.307862
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.303037
[ Info: iteration 23, lowerbound -2.299263
[ Info: iteration 24, lowerbound -2.299258
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Feb  3 13:51:06 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Feb  3 13:51:13 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Mon Feb  3 13:51:15 2020: EM with 272 data points 0 iterations avll -2.085384
5.8 data points per parameter
, Mon Feb  3 13:51:16 2020: GMM converted to Variational GMM
, Mon Feb  3 13:51:24 2020: iteration 1, lowerbound -3.811066
, Mon Feb  3 13:51:24 2020: iteration 2, lowerbound -3.686582
, Mon Feb  3 13:51:24 2020: iteration 3, lowerbound -3.563713
, Mon Feb  3 13:51:24 2020: iteration 4, lowerbound -3.421399
, Mon Feb  3 13:51:24 2020: iteration 5, lowerbound -3.264120
, Mon Feb  3 13:51:24 2020: iteration 6, lowerbound -3.107474
, Mon Feb  3 13:51:24 2020: dropping number of Gaussions to 7
, Mon Feb  3 13:51:24 2020: iteration 7, lowerbound -2.970679
, Mon Feb  3 13:51:24 2020: dropping number of Gaussions to 6
, Mon Feb  3 13:51:24 2020: iteration 8, lowerbound -2.858967
, Mon Feb  3 13:51:24 2020: iteration 9, lowerbound -2.795085
, Mon Feb  3 13:51:24 2020: dropping number of Gaussions to 5
, Mon Feb  3 13:51:24 2020: iteration 10, lowerbound -2.771506
, Mon Feb  3 13:51:24 2020: dropping number of Gaussions to 3
, Mon Feb  3 13:51:24 2020: iteration 11, lowerbound -2.743230
, Mon Feb  3 13:51:24 2020: iteration 12, lowerbound -2.709679
, Mon Feb  3 13:51:24 2020: iteration 13, lowerbound -2.670527
, Mon Feb  3 13:51:24 2020: iteration 14, lowerbound -2.616679
, Mon Feb  3 13:51:24 2020: iteration 15, lowerbound -2.551085
, Mon Feb  3 13:51:24 2020: iteration 16, lowerbound -2.482977
, Mon Feb  3 13:51:24 2020: iteration 17, lowerbound -2.423190
, Mon Feb  3 13:51:24 2020: iteration 18, lowerbound -2.376674
, Mon Feb  3 13:51:24 2020: iteration 19, lowerbound -2.342224
, Mon Feb  3 13:51:24 2020: iteration 20, lowerbound -2.318602
, Mon Feb  3 13:51:24 2020: iteration 21, lowerbound -2.307862
, Mon Feb  3 13:51:24 2020: dropping number of Gaussions to 2
, Mon Feb  3 13:51:24 2020: iteration 22, lowerbound -2.303037
, Mon Feb  3 13:51:24 2020: iteration 23, lowerbound -2.299263
, Mon Feb  3 13:51:24 2020: iteration 24, lowerbound -2.299258
, Mon Feb  3 13:51:24 2020: iteration 25, lowerbound -2.299255
, Mon Feb  3 13:51:24 2020: iteration 26, lowerbound -2.299254
, Mon Feb  3 13:51:24 2020: iteration 27, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 28, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 29, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 30, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 31, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 32, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 33, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 34, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 35, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 36, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 37, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 38, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 39, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 40, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 41, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 42, lowerbound -2.299253
, Mon Feb  3 13:51:24 2020: iteration 43, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 44, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 45, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 46, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 47, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 48, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 49, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: iteration 50, lowerbound -2.299253
, Mon Feb  3 13:51:25 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601774, 95.9549077739822]
β = [178.04509222601774, 95.9549077739822]
m = [4.25030073326988 79.2868669443614; 2.0002292577753376 53.85198717246113]
ν = [180.04509222601774, 97.9549077739822]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547483983 -0.007644049042327452; 0.0 0.008581705166333024], [0.375876361194897 -0.008953123827346893; 0.0 0.012748664777409718]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -1.0026891111886738
avll from llpg:  -1.0026891111886729
avll direct:     -1.002689111188673
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.010702597881059
avll from llpg:  -1.010702597881059
avll direct:     -1.010702597881059
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0243488    0.00120445  -0.143269    -0.0154252    -0.172507    0.0882225    0.00533885   0.119668    0.0195398    0.00521425   0.186384     0.15132     -0.0931268     0.230706     0.136503     0.102567     0.248436     0.1288       0.158916     0.0205155     0.049489     0.180976     0.013       -0.0285993   -0.0765053   0.126339
 -0.0340973    0.00562334  -0.120192     0.124783     -0.159902    0.159134    -0.120812    -0.0577007  -0.0661101    0.197223    -0.115579     0.0247949    0.141343      0.0546903    0.050492     0.00635103   0.0557231   -0.200009     0.121891    -0.278083      0.0161108    0.0696042    0.0335314    0.167452    -0.103185    0.0547499
  0.0196707    0.0417784    0.0298405   -0.128746     -0.0120407  -0.309314    -0.00101726   0.0303959   0.00501461   0.0610794   -0.0582418   -0.0210767   -0.0865083    -0.00374794  -0.014403     0.0331667    0.087348     0.124056    -0.00849133   0.108209      0.189917     0.0836987    0.13156      0.0583153    0.112381    0.0863373
 -0.0915676   -0.149065    -0.0216792   -0.058646     -0.0163587  -0.107038    -0.0379291   -0.195387    0.0466206    0.0445965    0.00807194   0.125499     0.169375      0.0656607   -0.0641583    0.19957      0.0194928   -0.0499892    0.0262307   -0.0192527    -0.0853498    0.0419901   -0.135305    -0.0172329    0.0501936   0.205472
  0.101164    -0.0579367    0.0277159    0.0344259    -0.103224   -0.0745543    0.0152735   -0.0194905   0.0360373   -0.0124056    0.0711842   -0.056738    -0.198191      0.067995    -0.029602    -0.0754247   -0.269688     0.0508246   -0.107481     0.0371244    -0.0628962   -0.0291274   -0.0797053   -0.0926837    0.017096    0.138555
 -0.118303     0.0880366    0.0819647   -0.00942585    0.0462376  -0.0810548    0.00212379   0.110654   -0.0760091    0.102488     0.00101264   0.115556    -0.006091     -0.0371973    0.062436     0.10625      0.0665225    0.0382303    0.0223524   -0.0406425    -0.0104909   -0.224835    -0.02991      0.0784579    0.0451132  -0.0570128
 -0.0025342   -0.115623    -0.0253655    0.194696     -0.118294    0.1317       0.0130995   -0.165157   -0.0358157    0.135715    -0.0526732    0.0533121   -0.0902707    -0.057778     0.0779061    0.0480084    0.0890126   -0.0279965   -0.0866601   -0.00374122   -0.136416     0.0632962    0.053366    -0.00303805  -0.0118342  -0.0859871
  0.213335    -0.0476367   -0.0718402   -0.00168935    0.0746443  -0.0297107   -0.0515278   -0.114788    0.00197612   0.0760061   -0.0271804   -0.0396148   -0.0607082    -0.17239      0.107991     0.0292819   -0.322772     0.0189904   -0.00153852   0.0701592    -0.022972     0.15044      0.0563965   -0.0367435   -0.0669936  -0.00057274
 -0.0297675    0.011148     0.00814333  -0.000105555   0.0549038   0.0216154   -0.00167606  -0.0910488   0.0199153    0.182239    -0.109053     0.0963975    0.0637701     0.0328644   -0.0929966    0.00841474  -0.108903    -0.02149     -0.230554    -0.000254694  -0.0164287    0.0258719    0.0474896    0.0511813   -0.169433   -0.0648612
 -0.0288608    0.125993    -0.153095     0.0657742     0.0585808  -0.0288467    0.0166584   -0.301447   -0.0607135   -0.0907477    0.183277     0.034434    -0.113394      0.0849178    0.180481     0.125173     0.0535703    0.0234134    0.0361503   -0.118388     -0.0642026   -0.248374     0.0025287   -0.121776    -0.102408   -0.0213547
 -0.250207     0.0733377   -0.0458491   -0.0617878    -0.037396    0.038117    -0.15089      0.151401    0.095788    -0.180023     0.00457507   0.0481887   -0.0318477    -0.00599275  -0.183103    -0.0273603   -0.0691266    0.00393484  -0.0589094    0.0129306    -0.125405     0.0564788   -0.0845042   -0.0488293   -0.0542381  -0.146735
 -0.162942    -0.156702     0.04584     -0.00629462    0.0278337   0.0787183    0.0691648    0.0143259   0.0731531   -0.12098     -0.251481     0.0935595    0.0773545    -0.0648488   -0.0425565    0.0277866    0.0865577   -0.0154154   -0.0212912    0.0562158    -0.015267    -0.0242128    0.00519229  -0.156759     0.04985    -0.00102508
  0.0754149   -0.0551865    0.0231796    0.0508534     0.048479   -0.0456804   -0.0549524    0.0777751   0.0825118    0.0834348    0.222427    -0.072207    -0.153069      0.124565    -0.0627678   -0.0180764   -0.121153     0.11139      0.215779    -0.00628154    0.0233063    0.072024     0.0296212    0.171126    -0.132348    0.0372443
  0.0537404    0.0310757    0.0664665   -0.0179265     0.0504104   0.0255047   -0.0574745    0.118709    0.0553811   -0.0222788    0.232409    -0.147929    -0.131887     -0.0804257    0.0295358    0.211325    -0.0553834    0.0720573    0.0773424   -0.104689      0.098526     0.0243864    0.043428    -0.0265275    0.0113904  -0.130183
  0.0124015   -0.0801558    0.1061      -0.0929495    -0.1113      0.00459716  -0.105662     0.0606739   0.173166    -0.189359    -0.107603    -0.00218541  -0.000566999  -0.117846     0.102509     0.0209791    0.00241229  -0.0164738   -0.0190118    0.0193603     0.0820828   -0.00897814   0.0407399    0.108787     0.0236102   0.0380128
  0.0284706   -0.0916567    0.128236    -0.146737     -0.052567   -0.102152     0.0114666   -0.0283103   0.14423     -0.132161     0.0405906   -0.0436031    0.12809      -0.133188     0.051035     0.0253167    0.11274     -0.0290836    0.11296      0.0912322     0.205604    -0.0443517   -0.0128798   -0.246963     0.101485   -0.159526
  0.147253     0.02999      0.112056     0.0546136     0.114542   -0.0348361   -0.00616354   0.0638734   0.0105103   -0.0741951   -0.0552021    0.0199567   -0.126573      0.0358019    0.0938912   -0.010433     0.0776494   -0.0909671   -0.00830905  -0.245514      0.0339828   -0.125432     0.0187915   -0.0438554    0.134807    0.0951171
  0.0693801   -0.00155229   0.0262009   -0.000683821  -0.0517258   0.107574    -0.0616429   -0.0799571   0.0243625    0.153442     0.0877855    0.0746001   -0.0804815     0.0144083    0.00139609   0.173783     0.0504986   -0.148218    -0.0137981   -0.133011     -0.0188027    0.13957     -0.0111401   -0.124657     0.108416   -0.111786
  0.0425972   -0.161323     0.0164878    0.119297     -0.0817279  -0.107227    -0.0046957    0.0451154  -0.0524282   -0.124564     0.0360018    0.20625     -0.00780907    0.078694     0.120513     0.117591    -0.07605      0.0140126    0.0686907   -0.154533      0.128628     0.0617628   -0.0744082    0.0201481    0.0363682   0.0699109
  0.075554    -0.0327734   -0.0127379   -0.0418624     0.108343   -0.100474     0.0315908   -0.174379   -0.139623    -0.0930438    0.184897    -0.112879    -0.0768974     0.0639264    0.0291673   -0.0877045   -0.00838436   0.228467     0.063762    -0.0641198    -0.0558499    0.0138604    0.162462     0.124764    -0.0970949  -0.0461542
 -0.0761242    0.196562    -0.104652    -0.030881     -0.0274996  -0.0790824    0.123158    -0.179984   -0.0961021    0.163606    -0.0578678    0.0247304   -0.0069242    -0.0435579    0.143413     0.0337128    0.0673995    0.123933    -0.193332    -0.102637      0.0718333    0.0168043   -0.0798442    0.1721       0.140601    0.0113894
  0.218259     0.0039293    0.033072    -0.0507443    -0.186654   -0.0262019   -0.315151    -0.0128917   0.0708733    0.0116102   -0.178454     0.0773944   -0.0656934     0.0221851    0.0984793    0.0690422    0.0144553   -0.123716     0.28085     -0.00306632    0.149638     0.0335053   -0.0320195    0.0658312    0.0210711  -0.134831
 -0.109374    -0.0169315    0.042642    -0.0866904    -0.105074   -0.106539     0.0809079    0.0580019   0.0488365    0.262775     0.0916087    0.0917131    0.144331      0.079842     0.061968    -0.0702362   -0.171402     0.0472478    0.102147     0.0465521    -0.00508348  -0.0990854   -0.0720713   -0.0153175    0.12384     0.00371038
  0.147208     0.0429849   -0.0795245   -0.105796     -0.0484192  -0.240758     0.147776    -0.173463   -0.0652941    0.018242     0.0043051   -0.0621491   -0.123037      0.0466584   -0.0408903    0.107692     0.0968663    0.0834245    0.082942     0.0340756    -0.033898     0.0294943    0.0869212   -0.0480419    0.0302322  -0.147494
 -0.111115     0.00625683  -0.0713914    0.0846047     0.0485621  -0.0399631   -0.0569731    0.104973   -0.024533     0.0360888   -0.031056    -0.0194466    0.0190593     0.00619379   0.0408452    0.175813    -0.0497202   -0.0565795   -0.031528     0.0327676     0.136296     0.243669    -0.0982152   -0.10909     -0.0584583  -0.0359136
 -0.10006      0.0402883    0.0605084    0.0602677    -0.0161813  -0.209706    -0.058596     0.0590636   0.0108273    0.0900742    0.202295     0.103044     0.0731689     0.0536982    0.0546392    0.128072    -0.0891706   -0.0707648    0.0250146   -0.0425705    -0.0470239    0.0117422   -0.0596914    0.0501666    0.111578   -0.177737
  0.00267646  -0.0123225   -0.0950787   -0.0129625    -0.0305874  -0.145134    -0.0145878    0.0350697   0.202611     3.29312e-5  -0.0515539    0.161535     0.213549     -0.0311262    0.0730308   -0.0616436    0.0181372    0.175242    -0.00792718   0.192937      0.0798578   -0.0602504    0.0325218    0.0936158    0.143544    0.10975
 -0.0235554   -0.036966    -0.0130054    0.189636     -0.0195658   0.168591     0.183657    -0.115198    0.0366395   -0.166066    -0.25215     -0.00961689   0.131053      0.0885541   -0.0565737    0.217565     0.047557     0.0171515    0.0273882    0.0520368    -0.202602     0.180765    -0.0334553   -0.0896033   -0.0662369  -0.0899409
 -0.0833906    0.0311881   -0.0573584    0.0316402     0.045336    0.162596     0.0728707   -0.0857987   0.0438172   -0.113097     0.0508878   -0.13183     -0.0658465     0.239406     0.137282     0.0919807    0.0183352   -0.262639     0.192253    -0.130889      0.0837728   -0.0406434   -0.027449    -0.0501076   -0.0868023   0.0932741
  0.0114824   -0.103794     0.0020797    0.0774595     0.0447229   0.192244    -0.0285522    0.157536   -0.164203    -0.0978319   -0.0257632    0.051065    -0.0055226     0.029981     0.0638272    0.106299     0.0926373    0.0459958    0.0272112   -0.0809693     0.0110002   -0.10754     -0.229103     0.112226    -0.123849   -0.104252
  0.0277997    0.0255094   -0.0421095   -0.0424161    -0.0961461  -0.0178556   -0.0781433   -0.178306    0.023891    -0.12616      0.143286     0.00318308  -0.0108703     0.0292259    0.165249     0.116712     0.0238605   -0.00494272  -0.179789     0.0151393     0.19878      0.164802     0.02322     -0.109145    -0.267336   -0.00446005
 -0.0544951    0.124996     0.0555111    0.172761     -0.109315    0.104662    -0.137929    -0.0577267  -0.0623646    0.0786633    0.0838633   -0.0179748    0.104959     -0.136395     0.144489     0.117612     0.108634    -0.139924    -0.145025     0.18207      -0.160612     0.0359954    0.0695663   -0.0558566   -0.154383   -0.112164kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.38626767195778
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.386402
[ Info: iteration 2, average log likelihood -1.386297
[ Info: iteration 3, average log likelihood -1.385879
[ Info: iteration 4, average log likelihood -1.381327
[ Info: iteration 5, average log likelihood -1.366848
[ Info: iteration 6, average log likelihood -1.357259
[ Info: iteration 7, average log likelihood -1.354264
[ Info: iteration 8, average log likelihood -1.352653
[ Info: iteration 9, average log likelihood -1.351703
[ Info: iteration 10, average log likelihood -1.351112
[ Info: iteration 11, average log likelihood -1.350702
[ Info: iteration 12, average log likelihood -1.350375
[ Info: iteration 13, average log likelihood -1.350082
[ Info: iteration 14, average log likelihood -1.349807
[ Info: iteration 15, average log likelihood -1.349550
[ Info: iteration 16, average log likelihood -1.349316
[ Info: iteration 17, average log likelihood -1.349111
[ Info: iteration 18, average log likelihood -1.348933
[ Info: iteration 19, average log likelihood -1.348775
[ Info: iteration 20, average log likelihood -1.348629
[ Info: iteration 21, average log likelihood -1.348494
[ Info: iteration 22, average log likelihood -1.348374
[ Info: iteration 23, average log likelihood -1.348277
[ Info: iteration 24, average log likelihood -1.348202
[ Info: iteration 25, average log likelihood -1.348144
[ Info: iteration 26, average log likelihood -1.348098
[ Info: iteration 27, average log likelihood -1.348059
[ Info: iteration 28, average log likelihood -1.348025
[ Info: iteration 29, average log likelihood -1.347993
[ Info: iteration 30, average log likelihood -1.347965
[ Info: iteration 31, average log likelihood -1.347939
[ Info: iteration 32, average log likelihood -1.347916
[ Info: iteration 33, average log likelihood -1.347895
[ Info: iteration 34, average log likelihood -1.347876
[ Info: iteration 35, average log likelihood -1.347859
[ Info: iteration 36, average log likelihood -1.347845
[ Info: iteration 37, average log likelihood -1.347832
[ Info: iteration 38, average log likelihood -1.347821
[ Info: iteration 39, average log likelihood -1.347812
[ Info: iteration 40, average log likelihood -1.347804
[ Info: iteration 41, average log likelihood -1.347796
[ Info: iteration 42, average log likelihood -1.347790
[ Info: iteration 43, average log likelihood -1.347785
[ Info: iteration 44, average log likelihood -1.347780
[ Info: iteration 45, average log likelihood -1.347777
[ Info: iteration 46, average log likelihood -1.347773
[ Info: iteration 47, average log likelihood -1.347771
[ Info: iteration 48, average log likelihood -1.347768
[ Info: iteration 49, average log likelihood -1.347766
[ Info: iteration 50, average log likelihood -1.347764
┌ Info: EM with 100000 data points 50 iterations avll -1.347764
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.386402302793776
│     -1.3862965330614716
│      ⋮
└     -1.3477644268859215
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.347938
[ Info: iteration 2, average log likelihood -1.347798
[ Info: iteration 3, average log likelihood -1.347507
[ Info: iteration 4, average log likelihood -1.344925
[ Info: iteration 5, average log likelihood -1.333492
[ Info: iteration 6, average log likelihood -1.319532
[ Info: iteration 7, average log likelihood -1.312743
[ Info: iteration 8, average log likelihood -1.309636
[ Info: iteration 9, average log likelihood -1.307909
[ Info: iteration 10, average log likelihood -1.306826
[ Info: iteration 11, average log likelihood -1.306009
[ Info: iteration 12, average log likelihood -1.305306
[ Info: iteration 13, average log likelihood -1.304683
[ Info: iteration 14, average log likelihood -1.304145
[ Info: iteration 15, average log likelihood -1.303690
[ Info: iteration 16, average log likelihood -1.303307
[ Info: iteration 17, average log likelihood -1.302991
[ Info: iteration 18, average log likelihood -1.302744
[ Info: iteration 19, average log likelihood -1.302553
[ Info: iteration 20, average log likelihood -1.302400
[ Info: iteration 21, average log likelihood -1.302272
[ Info: iteration 22, average log likelihood -1.302161
[ Info: iteration 23, average log likelihood -1.302062
[ Info: iteration 24, average log likelihood -1.301972
[ Info: iteration 25, average log likelihood -1.301889
[ Info: iteration 26, average log likelihood -1.301811
[ Info: iteration 27, average log likelihood -1.301734
[ Info: iteration 28, average log likelihood -1.301659
[ Info: iteration 29, average log likelihood -1.301583
[ Info: iteration 30, average log likelihood -1.301509
[ Info: iteration 31, average log likelihood -1.301437
[ Info: iteration 32, average log likelihood -1.301363
[ Info: iteration 33, average log likelihood -1.301288
[ Info: iteration 34, average log likelihood -1.301211
[ Info: iteration 35, average log likelihood -1.301132
[ Info: iteration 36, average log likelihood -1.301053
[ Info: iteration 37, average log likelihood -1.300972
[ Info: iteration 38, average log likelihood -1.300890
[ Info: iteration 39, average log likelihood -1.300803
[ Info: iteration 40, average log likelihood -1.300708
[ Info: iteration 41, average log likelihood -1.300600
[ Info: iteration 42, average log likelihood -1.300479
[ Info: iteration 43, average log likelihood -1.300343
[ Info: iteration 44, average log likelihood -1.300190
[ Info: iteration 45, average log likelihood -1.300038
[ Info: iteration 46, average log likelihood -1.299910
[ Info: iteration 47, average log likelihood -1.299815
[ Info: iteration 48, average log likelihood -1.299747
[ Info: iteration 49, average log likelihood -1.299692
[ Info: iteration 50, average log likelihood -1.299643
┌ Info: EM with 100000 data points 50 iterations avll -1.299643
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3479375432449472
│     -1.3477981527379088
│      ⋮
└     -1.2996433980473407
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.299823
[ Info: iteration 2, average log likelihood -1.299539
[ Info: iteration 3, average log likelihood -1.298491
[ Info: iteration 4, average log likelihood -1.290273
[ Info: iteration 5, average log likelihood -1.270605
[ Info: iteration 6, average log likelihood -1.257474
[ Info: iteration 7, average log likelihood -1.252498
[ Info: iteration 8, average log likelihood -1.250076
[ Info: iteration 9, average log likelihood -1.248487
[ Info: iteration 10, average log likelihood -1.247340
[ Info: iteration 11, average log likelihood -1.246488
[ Info: iteration 12, average log likelihood -1.245754
[ Info: iteration 13, average log likelihood -1.245035
[ Info: iteration 14, average log likelihood -1.244288
[ Info: iteration 15, average log likelihood -1.243485
[ Info: iteration 16, average log likelihood -1.242625
[ Info: iteration 17, average log likelihood -1.241815
[ Info: iteration 18, average log likelihood -1.241192
[ Info: iteration 19, average log likelihood -1.240806
[ Info: iteration 20, average log likelihood -1.240573
[ Info: iteration 21, average log likelihood -1.240417
[ Info: iteration 22, average log likelihood -1.240296
[ Info: iteration 23, average log likelihood -1.240201
[ Info: iteration 24, average log likelihood -1.240125
[ Info: iteration 25, average log likelihood -1.240065
[ Info: iteration 26, average log likelihood -1.240016
[ Info: iteration 27, average log likelihood -1.239974
[ Info: iteration 28, average log likelihood -1.239937
[ Info: iteration 29, average log likelihood -1.239902
[ Info: iteration 30, average log likelihood -1.239866
[ Info: iteration 31, average log likelihood -1.239827
[ Info: iteration 32, average log likelihood -1.239781
[ Info: iteration 33, average log likelihood -1.239725
[ Info: iteration 34, average log likelihood -1.239661
[ Info: iteration 35, average log likelihood -1.239593
[ Info: iteration 36, average log likelihood -1.239515
[ Info: iteration 37, average log likelihood -1.239416
[ Info: iteration 38, average log likelihood -1.239290
[ Info: iteration 39, average log likelihood -1.239137
[ Info: iteration 40, average log likelihood -1.238967
[ Info: iteration 41, average log likelihood -1.238786
[ Info: iteration 42, average log likelihood -1.238598
[ Info: iteration 43, average log likelihood -1.238389
[ Info: iteration 44, average log likelihood -1.238122
[ Info: iteration 45, average log likelihood -1.237823
[ Info: iteration 46, average log likelihood -1.237576
[ Info: iteration 47, average log likelihood -1.237434
[ Info: iteration 48, average log likelihood -1.237361
[ Info: iteration 49, average log likelihood -1.237320
[ Info: iteration 50, average log likelihood -1.237292
┌ Info: EM with 100000 data points 50 iterations avll -1.237292
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2998226691346564
│     -1.2995389508105368
│      ⋮
└     -1.2372923700917506
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.237537
[ Info: iteration 2, average log likelihood -1.237275
[ Info: iteration 3, average log likelihood -1.236395
[ Info: iteration 4, average log likelihood -1.223333
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.186341
[ Info: iteration 6, average log likelihood -1.178606
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.154251
[ Info: iteration 8, average log likelihood -1.161733
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.146727
[ Info: iteration 10, average log likelihood -1.158343
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.144412
[ Info: iteration 12, average log likelihood -1.155961
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.142164
[ Info: iteration 14, average log likelihood -1.154120
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.140767
[ Info: iteration 16, average log likelihood -1.153312
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.140326
[ Info: iteration 18, average log likelihood -1.153103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.140182
[ Info: iteration 20, average log likelihood -1.152998
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.140064
[ Info: iteration 22, average log likelihood -1.152849
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.139805
[ Info: iteration 24, average log likelihood -1.152341
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.138650
[ Info: iteration 26, average log likelihood -1.150257
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.136196
[ Info: iteration 28, average log likelihood -1.148598
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.135635
[ Info: iteration 30, average log likelihood -1.148535
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.135613
[ Info: iteration 32, average log likelihood -1.148522
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.135601
[ Info: iteration 34, average log likelihood -1.148512
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.135590
[ Info: iteration 36, average log likelihood -1.148503
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.135581
[ Info: iteration 38, average log likelihood -1.148495
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.135572
[ Info: iteration 40, average log likelihood -1.148488
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.135563
[ Info: iteration 42, average log likelihood -1.148481
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.135555
[ Info: iteration 44, average log likelihood -1.148474
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.135548
[ Info: iteration 46, average log likelihood -1.148467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.135540
[ Info: iteration 48, average log likelihood -1.148460
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.135532
[ Info: iteration 50, average log likelihood -1.148453
┌ Info: EM with 100000 data points 50 iterations avll -1.148453
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2375374005731548
│     -1.2372752123458122
│      ⋮
└     -1.1484525458960748
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.135829
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.135406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     5
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.133489
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.115006
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.069153
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.045523
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.041154
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052578
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035264
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.035469
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     14
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.041791
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.046077
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.040640
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.038277
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     14
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.034808
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.037393
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.047862
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.048395
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.028230
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     17
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.050971
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.049991
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.034810
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.025325
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.044175
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.056340
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.033761
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.034329
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.042526
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.050885
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.031108
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.024570
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     17
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.043107
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.051068
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     14
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.040999
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.040317
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.036672
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.033476
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.040357
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.049501
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.036945
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.030741
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.060937
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.034917
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     14
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.034913
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.034247
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.050990
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.038198
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.053509
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.037037
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.025063
┌ Info: EM with 100000 data points 50 iterations avll -1.025063
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1358288470857032
│     -1.1354063452693484
│      ⋮
└     -1.0250626936939442
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.38626767195778
│     -1.386402302793776
│     -1.3862965330614716
│     -1.3858793447968019
│      ⋮
│     -1.053509431970474
│     -1.0370369277088014
└     -1.0250626936939442
32×26 Array{Float64,2}:
  0.00883907  -0.148033      0.131222     -0.0164874   -0.162021    -0.028606    -0.0856904     0.0481986   0.159973    -0.478416    -0.10834     -0.0266254    0.0280438   -0.132218     0.0353239   0.0188781    0.00177467  -0.0127043   -0.0195741    0.0688321     0.0263647    0.0454942    0.0841534    0.0563883    0.156246     0.0600294
  0.0107309   -0.0581043     0.0133066    -0.204369    -0.103433     0.046569    -0.133203      0.0647254   0.175445    -0.0810585   -0.107399     0.0399007   -0.0270764   -0.123665     0.184341    0.00614622   0.00528119  -0.040975    -0.0161605   -0.0186237     0.130955    -0.012648     0.0162628    0.154315    -0.101603     0.0239801
 -0.00687123  -0.0900364     0.095671     -0.121484    -0.112366    -0.135987     0.00906627   -0.0262587   0.151744     0.0658232    0.0125597   -0.0371091   -0.355909    -0.154795     0.0697587   0.0802755    0.100271     0.0634579    0.0499205    0.0913091     0.194311    -0.0627193   -0.0148551   -0.236542     0.172843    -0.223746
  0.0843391   -0.104494      0.110954     -0.258213    -0.0210749   -0.0909083    0.0124028    -0.0312599   0.148639    -0.351055     0.115337    -0.0491134    0.64712     -0.123048     0.0427012  -0.0313506    0.124904    -0.105266     0.165782     0.0928227     0.215013    -0.0323538   -0.0120858   -0.259583     0.0241762   -0.0916476
  0.0644991   -0.0585586     0.0212787     0.0513526    0.111678    -0.0457846   -0.057345      0.0768541   0.0824806    0.0506327    0.222849    -0.0774447   -0.18301      0.123057    -0.0641949  -0.639372    -0.19523      0.123099     0.21727      0.0131077     0.335303     0.0735726   -0.155139     0.171349    -0.449158     0.0507787
  0.0842624   -0.0668831     0.0231896     0.0501885    0.0151034   -0.0636104   -0.0556911     0.0776477   0.0828485    0.0224796    0.222846    -0.0693378   -0.167012     0.119005    -0.0644913   0.455539     0.00242025   0.0960937    0.217005     0.00633481   -0.221075     0.070454     0.204595     0.162135     0.234854     0.037132
  0.00167045  -0.0772902    -0.0384553     0.0734934   -0.107875     0.188948    -0.293857     -0.0560747  -0.0663627    0.238426    -0.107178     0.060305     0.100907     0.0530554   -0.0575349   0.0146803    0.0910062   -0.234429    -0.0899587   -0.330476      0.0135941    0.105405     0.0650759    0.183275    -0.0946396    0.0564021
 -0.0792408    0.104217     -0.202648      0.177033    -0.20749      0.188096     0.0932473    -0.0588614  -0.0661279    0.187385    -0.117388    -0.043236     0.1241       0.115577     0.197723   -0.0228091    0.00125951  -0.146423     0.342768    -0.171743      0.0170103    0.00631865   0.0111135    0.151447    -0.110141     0.0418789
 -0.0521017    0.175639     -0.111341     -0.0366456   -0.0907665   -0.113309     0.155123     -0.200864   -0.068127     0.133894    -0.0358765    0.0248313   -0.0412476   -0.0298101    0.126345    0.0288506    0.0735116    0.124823    -0.194192    -0.0681627     0.0779564    0.00311938  -0.0399458    0.171315     0.128631     0.00983102
  0.0401544    0.054546      0.059296     -0.018389     0.0893841    0.0210322   -0.0479568     0.121074    0.0444348   -0.00965142   0.266487    -0.140088    -0.127484    -0.0767992    0.0300546   0.190058    -0.0583918    0.073514     0.0686673   -0.0929927     0.0862265    0.032779     0.0694995   -0.030741     0.0102547   -0.115558
 -0.25071      0.0735194    -0.0597193    -0.0583096   -0.0376013    0.0443922   -0.156983      0.124687    0.0953745   -0.198622     0.0133869    0.0489334    0.0199522    0.00263483  -0.181845    0.0104407   -0.0542255    0.00378271  -0.0870025    0.0208094    -0.10652      0.0577024   -0.0777902   -0.0478822   -0.0492993   -0.150582
 -0.0443832    0.123106      0.0478796     0.169886    -0.0956747    0.106182    -0.129395     -0.0556702  -0.0605931    0.0858099    0.0796131   -0.0161472    0.105171    -0.134755     0.139505    0.0911113    0.105435    -0.124861    -0.109669     0.166529     -0.159754     0.0238621    0.0746148   -0.0783576   -0.186794    -0.111542
 -0.0819301    0.0717448    -0.056602      0.0314506    0.0735539    0.166663     0.0823751    -0.110613    0.0607186   -0.123985     0.0442925   -0.136464    -0.0428367    0.238994     0.146991    0.105137     0.0306973   -0.241654     0.194516    -0.121232      0.0787475   -0.0582896   -0.0436457   -0.103514    -0.0951275    0.0831127
  0.136763    -0.000557822   0.123714      0.0519329    0.119871    -0.00251536  -0.00938165    0.061912    0.004581    -0.0721898   -0.0553414    0.00498777  -0.132858     0.0174273    0.101925   -0.010589     0.0812921   -0.0865155   -0.0117615   -0.250217      0.0302291   -0.0826024   -0.0213144   -0.0330311    0.148095     0.102612
 -0.0252641    0.0826774    -0.0785879    -0.0220514    0.0132425   -0.169956     0.0171114    -0.168104   -0.0102267   -0.0309424    0.0812165    0.00982826  -0.106711     0.0298685    0.0673872   0.0837124    0.0719464    0.0749389    0.0156579   -0.011197      0.0679032   -0.0899304    0.0677469   -0.0243613    0.0301191    0.0268591
 -0.0764975    0.0204825    -0.000218563   0.00167104  -7.92961e-5  -0.0749837   -0.0138208     0.0924482   0.064621     0.0391657   -0.0305015    0.154909     0.110663    -0.0467392    0.0597874   0.0140085    0.0504405    0.105205     0.0127862    0.0783966     0.0358444   -0.122804     0.00803178   0.0665855    0.0917551    0.0170972
 -0.0186907   -0.0451062    -0.117627      0.155258    -0.0363584    0.161805     0.171004     -0.104911    0.0110364   -0.147132    -0.237442     0.0095635    0.117218     0.10517     -0.0465757   0.213133     0.0550711    0.0198003    0.0339037    0.0400346    -0.185716     0.210225    -0.0212489   -0.0806545   -0.0744145   -0.0675784
 -0.00153216  -0.11468      -0.0436361     0.192547    -0.117055     0.143508     0.0105984    -0.165432   -0.0221591    0.159229    -0.0571684    0.0587946   -0.086292    -0.0313237    0.0656965  -0.0158938    0.101141     0.0115769   -0.0678449    0.0187103    -0.109309     0.0698062    0.0511872   -0.0284651   -0.00835362  -0.0566349
 -0.110686    -0.0229251     0.0336908    -0.0784714   -0.0994885   -0.106927     0.0682087     0.0598418   0.0499563    0.263043     0.0911115    0.0843224    0.139489     0.0803767    0.062108    0.0225768   -0.167462     0.0378355    0.110507     0.0667918    -0.00274777  -0.0967368   -0.0878186   -0.0198178    0.111138    -0.00138488
  0.0527733   -0.0650502    -0.0101719    -0.057389    -0.114217    -0.0497149   -0.163117     -0.0755935   0.0636042    0.0188914   -0.098591     0.0909482    0.0304022    0.0335435    0.0234593   0.138835     0.0294775   -0.063404     0.17887     -0.00182512    0.0496091    0.0441198   -0.0674306    0.00922708   0.0422261    0.0437127
  0.253885    -0.0710431     0.118492     -0.0718823    0.0851296   -0.0272919   -0.0779203    -0.0958278   0.0432028    0.0307732    0.00354806  -0.0232397   -0.0669628   -0.555739     0.0536235  -0.182263    -0.319762     0.0771634   -0.00498517   0.0615053    -0.293623     0.294972     0.0572597   -0.0761332   -0.067004     0.0369989
  0.158087    -0.0503306    -0.252284      0.0378118    0.0624958   -0.0471804   -0.043194     -0.146209   -0.0323614    0.115532    -0.0373005   -0.0534964   -0.0474405    0.297903     0.126136    0.141248    -0.317027    -0.0759768    0.00562326   0.0796545     0.293294    -0.00954136  -0.0077792   -0.0104774   -0.0672098   -0.0162968
 -0.109335    -0.00389294   -0.0824359     0.107381     0.0482721   -0.0263769   -0.0567241     0.113762   -0.0195446    0.0337226   -0.0142783   -0.0172373    0.0193311    0.00680376   0.0428948   0.15646     -0.0299829   -0.0565397   -0.0308006    0.0368422     0.142124     0.240438    -0.0810292   -0.0958405   -0.056044    -0.0290412
 -0.0292016    0.004841      0.0094106    -0.0993872    0.0541505    0.0298919    0.000218746  -0.102488    0.0173936    0.18809     -0.0993545    0.0892923    0.0599356    0.0109447   -0.0915354   0.00607267  -0.110226    -0.0194083   -0.242289     0.0139551    -0.0162004    0.0159273    0.0466395    0.0349011   -0.16773     -0.0631269
 -0.150328     0.0396453     0.126661      0.146974    -0.00615331  -0.220093    -0.0195309     0.0710884   0.00228705   0.0845526   -0.168202     0.113208     0.0538824    0.0568816    0.077621    0.117923     0.085534    -0.056176     0.0187721   -0.0406146    -0.0455231    0.0571712   -0.0675547   -0.0248879    0.158923    -0.198963
  0.0151359    0.0408278     0.0809185     0.0281074   -0.0277175   -0.193399    -0.0983209     0.0431675   0.0681696    0.0687086    0.592341     0.14181      0.0707909    0.0553414    0.0199577   0.135497    -0.336059    -0.0723498    0.0110817   -0.0433432    -0.0475484   -0.036775    -0.0535086    0.14487      0.0964666   -0.159377
  0.146802    -0.161084      0.0150367    -0.631586    -0.0772355   -0.0976888    0.120054      0.113906   -0.0634129   -0.0975154    0.0355434    0.275599     0.0291524    0.0753673    0.209163    0.162718    -0.00889125   0.0144011    0.178485    -0.136286      0.126771     0.0699649   -0.131642     0.0479597    0.0321776   -0.00982308
 -0.0904      -0.153391     -0.0316257     0.637744    -0.0819213   -0.113604    -0.114046     -0.0227506   0.0225927   -0.142241     0.0363684    0.0632327   -0.0112553    0.0687511    0.114237    0.0589211   -0.145817     0.015154     0.0506001   -0.189487      0.136531     0.0666193   -0.0540745    0.00806666   0.0400793    0.0742359
 -0.0110353   -0.0032939    -0.0244064    -0.0414194   -0.0732975   -0.0193933   -0.0606382    -0.180753    0.0363964   -0.120024     0.0618237    0.00927364   0.00954648  -0.0375889    0.111722    0.113722     0.0213      -0.0102116   -0.165347     0.0290522     0.147451     0.147452     0.0880254   -0.125661    -0.210985     0.0266644
  0.00122978  -0.109711      0.00854142    0.0801      -0.0300316    0.165864     0.0234399     0.131247   -0.123528    -0.102871    -0.0562565    0.0567519   -0.00629091   0.0210067    0.0445958   0.0936523    0.0979524    0.0538561    0.0167093   -0.0687187    -0.0172779   -0.109009    -0.208323     0.104043    -0.0895072   -0.0720459
  0.110669     0.0202354    -0.025701     -0.045063    -0.0373685   -0.0574161    0.0606881    -0.124233   -0.0195133    0.0811129    0.0963105   -0.00891524  -0.105891     0.0164402    0.017023    0.136824     0.0884729   -0.0214343    0.0358405   -0.0350738    -0.00894014   0.0872931    0.0388368   -0.0882094    0.0733337   -0.132597
  0.0683372   -0.0463817    -0.0186165    -0.00543658  -0.0238662   -0.0386957    0.0216855    -0.0276841  -0.0185391   -0.0288724    0.146161    -0.0399684   -0.124967     0.109408     0.0161335  -0.0484761   -0.0606448    0.12823     -0.0111868    0.000349245  -0.0386847    0.0335258    0.0248234   -0.00442553  -0.0392667    0.0929566[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.040323
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.017311
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.023458
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.017413
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.018614
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.020786
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     12
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.033656
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.011966
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.017810
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028960
┌ Info: EM with 100000 data points 10 iterations avll -1.028960
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.751443e+05
      1       6.471985e+05      -2.279458e+05 |       32
      2       6.169435e+05      -3.025498e+04 |       32
      3       6.034245e+05      -1.351898e+04 |       32
      4       5.962752e+05      -7.149316e+03 |       32
      5       5.918576e+05      -4.417638e+03 |       32
      6       5.883234e+05      -3.534181e+03 |       32
      7       5.851770e+05      -3.146431e+03 |       32
      8       5.825404e+05      -2.636537e+03 |       32
      9       5.810144e+05      -1.526069e+03 |       32
     10       5.801460e+05      -8.683809e+02 |       32
     11       5.795355e+05      -6.104370e+02 |       32
     12       5.790329e+05      -5.026789e+02 |       32
     13       5.785830e+05      -4.498632e+02 |       32
     14       5.779934e+05      -5.895629e+02 |       32
     15       5.773538e+05      -6.396706e+02 |       32
     16       5.768675e+05      -4.862760e+02 |       32
     17       5.765135e+05      -3.539617e+02 |       32
     18       5.762226e+05      -2.909438e+02 |       32
     19       5.760029e+05      -2.196599e+02 |       32
     20       5.757860e+05      -2.169257e+02 |       32
     21       5.754894e+05      -2.966038e+02 |       32
     22       5.751039e+05      -3.854509e+02 |       32
     23       5.746922e+05      -4.117120e+02 |       32
     24       5.744335e+05      -2.587462e+02 |       32
     25       5.742322e+05      -2.013121e+02 |       32
     26       5.740645e+05      -1.676785e+02 |       32
     27       5.739026e+05      -1.619122e+02 |       32
     28       5.737111e+05      -1.914674e+02 |       32
     29       5.734842e+05      -2.269608e+02 |       32
     30       5.731813e+05      -3.028229e+02 |       32
     31       5.728675e+05      -3.137910e+02 |       32
     32       5.726397e+05      -2.278791e+02 |       32
     33       5.725446e+05      -9.508305e+01 |       32
     34       5.725046e+05      -3.999334e+01 |       32
     35       5.724826e+05      -2.198624e+01 |       31
     36       5.724687e+05      -1.393713e+01 |       32
     37       5.724592e+05      -9.501402e+00 |       30
     38       5.724520e+05      -7.128403e+00 |       28
     39       5.724467e+05      -5.312156e+00 |       27
     40       5.724408e+05      -5.892285e+00 |       28
     41       5.724344e+05      -6.417310e+00 |       28
     42       5.724303e+05      -4.157648e+00 |       26
     43       5.724258e+05      -4.449151e+00 |       24
     44       5.724224e+05      -3.433690e+00 |       22
     45       5.724196e+05      -2.793351e+00 |       22
     46       5.724174e+05      -2.224254e+00 |       25
     47       5.724139e+05      -3.471841e+00 |       23
     48       5.724107e+05      -3.169781e+00 |       23
     49       5.724064e+05      -4.311773e+00 |       26
     50       5.724017e+05      -4.683940e+00 |       27
K-means terminated without convergence after 50 iterations (objv = 572401.7202571683)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290043
[ Info: iteration 2, average log likelihood -1.256990
[ Info: iteration 3, average log likelihood -1.223141
[ Info: iteration 4, average log likelihood -1.190053
[ Info: iteration 5, average log likelihood -1.142715
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.067853
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044099
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     20
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.045138
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052896
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047929
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.044591
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.028990
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     15
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.016828
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.060137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.042615
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.025669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.031293
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     16
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.032348
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058616
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.033468
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.037030
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.031600
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.054279
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     19
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.034947
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.047291
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.016978
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.052625
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     19
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.034763
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.039990
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.043404
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.052138
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     17
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.012426
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     19
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046869
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.049399
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.037704
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     19
│     20
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.019793
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.064323
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     15
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.020128
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.023038
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.054481
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.067619
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.023094
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     19
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.008237
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079666
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.048606
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     16
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.002935
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      8
│     19
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.035768
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.071646
[ Info: iteration 49, average log likelihood -1.057906
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     13
│     16
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.011227
┌ Info: EM with 100000 data points 50 iterations avll -1.011227
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.00972377  -0.0911985    0.0637907   -0.123133     -0.12864     0.0158174   -0.112409     0.0588939    0.170195    -0.260026    -0.107953     0.010778    -0.00712347   -0.132678      0.125614    0.00842019    0.00362996  -0.0286852   -0.0175219     0.0208967    0.0888454     0.0111262    0.0465849    0.113555    0.0107496    0.0353583
 -0.0373684    0.185134    -0.110805    -0.0320918    -0.0988067  -0.113394     0.16152     -0.197399    -0.0768746    0.145024    -0.0292782    0.0249092   -0.0359613    -0.0334848     0.125083    0.0305888     0.0742987    0.123407    -0.198231     -0.0666396    0.0727254     0.00978161  -0.0392169    0.182576    0.124756    -0.000155617
  0.214722     0.0078231    0.0348029   -0.0492902    -0.196685   -0.0201667   -0.312011    -0.0111454    0.0900771    0.0109262   -0.218097     0.0279698   -0.0667493    -0.015217      0.10652     0.0719397     0.00887875  -0.118015     0.290223     -0.014484     0.182688      0.032407    -0.0322142    0.0650235   0.0466686   -0.122412
  0.0359747   -0.0968177    0.102252    -0.182931     -0.0705229  -0.115551     0.0105461   -0.0286063    0.150332    -0.127542     0.0604378   -0.0424899    0.109582     -0.140198      0.0571746   0.0286263     0.111583    -0.0151563    0.102673      0.0918016    0.203338     -0.0493219   -0.0135326   -0.247457    0.103335    -0.16263
 -0.110282    -0.0218928    0.032409    -0.0764758    -0.0996622  -0.102429     0.0768038    0.060223     0.0467892    0.260277     0.089043     0.0832546    0.13899       0.0780753     0.0619246   0.0246258    -0.168874     0.0383681    0.108825      0.068701    -0.00393039   -0.0986723   -0.0879613   -0.0251727   0.111129    -0.00358823
  0.0664251   -0.0560255    0.0215791    0.0530872     0.0516592  -0.04702     -0.0580352    0.0784633    0.0801029    0.0566074    0.214545    -0.0671628   -0.158944      0.113052     -0.0580974  -0.0753219    -0.0945494    0.098709     0.207123      0.0129668    0.0499877     0.0697719    0.0230173    0.16737    -0.11425      0.0387134
 -0.0243404    0.0394415   -0.0770777    0.0581687     0.10571    -0.0595398    0.0213615    0.0364891   -0.00217643   0.277235     0.034297     0.0906821   -0.0544685     0.0978833     0.0308842  -0.0424022     0.0379322   -0.0869587   -0.0356013     0.0822871   -0.0056192    -0.0927234    0.215013     0.0474626   0.0591537   -0.0837005
  0.0093883    0.0356683    0.00101305  -0.126895     -0.0162539  -0.296579     0.019235    -0.0108276   -0.00991689   0.0801304   -0.0586569   -0.0134849   -0.0841837    -0.0308711    -0.0321504   0.0340216     0.0984282    0.115067     0.0104199     0.104927     0.187524      0.103742     0.14456      0.0613125   0.196101     0.0847097
  0.0953069   -0.0275857   -0.0401096   -0.0534711     0.0637203  -0.00723707  -0.0364253   -0.102132     0.00491264   0.129531    -0.0556695    0.0134061   -0.0039956    -0.0505624     0.0133347   0.00978736   -0.230021    -0.0192917   -0.115443      0.0463089    0.0189349     0.101132     0.0233586   -0.0078591  -0.10623     -0.0225293
  0.0271453    0.0238077   -0.0373418   -0.0524541    -0.0900486  -0.0466973   -0.0855737   -0.202881     0.0250351   -0.115062     0.093841    -0.0173266   -0.00434023   -0.0151602     0.133095    0.112857      0.0250015    0.00329985  -0.188747      0.0220062    0.202407      0.14996      0.0640806   -0.106637   -0.248186     0.0170363
  0.0424784    0.0541752    0.0571991   -0.0170132     0.0887093   0.0201196   -0.0544741    0.122152     0.0409691   -0.00917994   0.268445    -0.140519    -0.128809     -0.079096      0.0301223   0.189532     -0.0580732    0.0735264    0.0702005    -0.0924964    0.0874691     0.0334269    0.0698559   -0.030281    0.0100013   -0.119714
 -0.106379    -0.159731    -0.033309    -0.0572147    -0.0178108  -0.112645    -0.0448337   -0.186643     0.0452004    0.0431294   -0.00366726   0.130346     0.148467      0.0626724    -0.07721     0.21603       0.0192481   -0.0451555    0.0191416    -0.00808756  -0.0849488     0.0288987   -0.135425    -0.0329287   0.0426674    0.204524
  0.152852     0.0450511   -0.0791257   -0.0905431    -0.0327413  -0.222903     0.173181    -0.175857    -0.0629655    0.012162     0.0879119   -0.0533449   -0.133093      0.0553507    -0.0363051   0.108294      0.0945353    0.088227     0.0849174     0.0452621   -0.0138976     0.0302601    0.0853251   -0.0455655   0.0292085   -0.153394
 -0.103478     0.0876441    0.0852336    0.00598555    0.034616   -0.0649628   -0.0155757    0.0914121   -0.0686074    0.0966021    0.0434079    0.151543    -0.00270327   -0.0567469     0.0555241   0.0941105     0.0613706    0.0460119    0.000823981  -0.0431461   -0.00367321   -0.22431     -0.045369     0.0609255   0.0291733   -0.0571689
 -0.17389     -0.00192705  -0.0837161    0.151601      0.0477697  -0.0224601   -0.0522174    0.131202    -0.0110421    0.039751    -0.0111191   -0.0103353    0.0272251     0.000894876   0.0307341   0.160238     -0.0157      -0.0553954   -0.0309296     0.0443898    0.168147      0.254257    -0.109576    -0.153841   -0.0544665   -0.00898413
 -0.251412     0.0736386   -0.0592061   -0.0568337    -0.0366409   0.045205    -0.157072     0.12216      0.0951527   -0.19269      0.0123995    0.049422     0.0208114    -0.000394121  -0.180711    0.00889554   -0.0585638    0.00352026  -0.0880573     0.0227561   -0.107979      0.05835     -0.0762317   -0.0499627  -0.0519377   -0.151041
 -0.0578891    0.126816    -0.142678     0.0773577     0.0550688  -0.0499599    0.0237815   -0.312322    -0.0241561   -0.121963     0.216984     0.037298    -0.129539      0.0674205     0.163288    0.126713      0.0490072    0.0426965    0.0264466    -0.11692     -0.0438371    -0.243975     0.00133666  -0.0986515  -0.102807    -0.0210789
  0.0245592    0.00652386  -0.143904    -0.00400445   -0.167964    0.0872081    0.00885054   0.111736     0.013832     0.0114621    0.191082     0.150659    -0.092182      0.232112      0.123431    0.125245      0.245309     0.133556     0.158532      0.0342468    0.000493062   0.185339     0.00904354  -0.0285309  -0.0759778    0.143573
  0.138674     0.00146602   0.133647     0.0512114     0.117604   -0.00319035  -0.00946306   0.0631513    0.00340404  -0.0744055   -0.0520011   -0.00111444  -0.132478      0.01366       0.106087   -0.0108092     0.0810503   -0.0863526   -0.012147     -0.255169     0.0295037    -0.0847261   -0.0226693   -0.0301847   0.144847     0.10657
 -0.00760926  -0.00436317  -0.0896491   -0.0112085    -0.03185    -0.125369    -0.0200312    0.0746699    0.185284     0.0101281   -0.0697455    0.143577     0.216277     -0.0275402     0.0702413  -0.0587206     0.0236783    0.166823     0.0209716     0.187562     0.0836022    -0.0549648    0.0636053    0.0928191   0.13234      0.095723
  0.0909807   -0.0778053    0.0278545    0.0308911    -0.0968579  -0.0580099    0.015762     0.014104     0.0482747    0.0193983    0.105101    -0.0562702   -0.192569      0.0974326    -0.03304    -0.0643943    -0.261141     0.0504094   -0.108369      0.032097    -0.050183     -0.0321226   -0.0902922   -0.0875762   0.00191395   0.155898
 -0.177845    -0.152916     0.040762    -0.000728773   0.0055771   0.08058      0.0670132    0.0371077    0.0741978   -0.110548    -0.291075     0.0961558    0.0738036    -0.0548171    -0.0425247   0.0484297     0.0860957   -0.0174643   -0.0225845     0.0703366   -0.0392394    -0.0259952    0.030212    -0.138461    0.071127     0.00118505
 -0.0233368   -0.0418058   -0.118525     0.180076     -0.0238593   0.168003     0.180546    -0.133037     0.0173101   -0.158813    -0.290335    -0.0136998    0.13595       0.0902418    -0.0636798   0.207276      0.0159772    0.0173354    0.02762       0.0437242   -0.189037      0.214486    -0.0241773   -0.0866803  -0.0763048   -0.0879852
 -0.0834041    0.0732087   -0.0570727    0.0315447     0.0760592   0.169254     0.0813297   -0.11114      0.0612304   -0.125618     0.044531    -0.136578    -0.0426877     0.238199      0.146701    0.105905      0.0295196   -0.246074     0.195496     -0.122476     0.0775896    -0.0638172   -0.0428669   -0.10141    -0.0960123    0.079218
 -0.0343326    0.00526156  -0.114535     0.123658     -0.151542    0.190347    -0.117217    -0.0570724   -0.066229     0.218216    -0.112959     0.0119952    0.115687      0.0782791     0.0596462   0.000118386   0.0457595   -0.199152     0.100559     -0.263245     0.0168738     0.0580395    0.0438514    0.171558   -0.107521     0.0449931
 -0.0608524    0.0777979    0.0728743    0.130137     -0.0443911  -0.0563937   -0.0938696    0.00314398  -0.00990816   0.0782227    0.129745     0.0541837    0.0830271    -0.0367601     0.0954481   0.106597      0.00056616  -0.091387    -0.0505445     0.0595723   -0.0998322     0.0242735    0.00647527  -0.0163576  -0.0249512   -0.150162
  0.0544998    0.0631381   -0.0296496   -0.0465149    -0.110345    0.0983583   -0.0412373   -0.219055     0.0423994   -0.167301     0.33337     -0.00216339   0.016174     -0.252177      0.178231    0.125812      0.0200504   -0.161206    -0.218577      0.00736348   0.0331323     0.174794     0.0389607   -0.14536    -0.292663     0.0511126
  0.0202242   -0.155532    -0.0109498    0.0356898    -0.0777712  -0.106752    -0.0054445    0.0423037   -0.0188361   -0.119361     0.0358718    0.159989     0.00877318    0.0696766     0.156045    0.11147      -0.0817877    0.0146853    0.104957     -0.163537     0.133708      0.0700153   -0.0890705    0.0291967   0.0345048    0.0284978
  0.019607    -0.0903364    0.00299828   0.0837986    -0.0457301   0.181835    -0.0335821    0.155774    -0.171356    -0.113051    -0.0251971    0.0483153   -0.000492919   0.0203412     0.0619188   0.0945827     0.0887272    0.0354655    0.0150702    -0.0807976    0.000974714  -0.0844629   -0.228462     0.158705   -0.122297    -0.0830407
  0.0681407   -0.0301925   -0.0118008   -0.0269938     0.136046   -0.0724182    0.0228798   -0.152463    -0.104471    -0.0908638    0.170527    -0.102011    -0.0673764     0.071287      0.031475   -0.0770918     0.00210514   0.191902     0.0500474    -0.0540787   -0.0504604     0.0396144    0.144653     0.10326    -0.0881321   -0.0340227
 -0.00273938  -0.112513    -0.0410461    0.194115     -0.111932    0.143265     0.00961178  -0.159248    -0.0225688    0.156489    -0.0591262    0.0546606   -0.0842838    -0.0383705     0.0704861  -0.0173341     0.0871981    0.002845    -0.0729604     0.0149236   -0.102244      0.0688258    0.0536544   -0.0304799  -0.00943497  -0.06545
  0.0698279   -0.00065377   0.028056     0.000823742  -0.0510381   0.0885499   -0.0536654   -0.0750958    0.0228078    0.14483      0.113585     0.035655    -0.0832925    -0.0260708     0.0568029   0.166495      0.0702399   -0.128406    -0.0172969    -0.120266    -0.0167561     0.139439    -0.00882065  -0.129406    0.123843    -0.116998[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     10
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.026271
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     15
│      ⋮
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.975469
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     10
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.957188
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     15
│      ⋮
│     20
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.998345
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     10
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.991392
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.941384
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     10
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.013931
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     15
│      ⋮
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.982166
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.958967
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      8
│     10
│     15
│     19
│     20
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.993482
┌ Info: EM with 100000 data points 10 iterations avll -0.993482
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.267644    -0.0744796    0.12962       0.220634    -0.0676966   -0.0975555   -0.171694    0.0785308  -0.028022    -0.0842415   -0.106866    -0.111912    -0.081954    0.06819     -0.0979866    0.00375654   0.0533184   -0.116863    0.0793126    0.0831084    -0.122407     0.224558    -0.0963429    0.0569781   -0.172994    -0.00400422
  0.112745     0.00945904  -0.0978024    -0.135334    -0.0738984    0.101231    -0.0500041  -0.053481    0.154277     0.0857057    0.0543656   -0.165318    -0.0389656   0.0340849   -0.022507    -0.013295     0.108064     0.068609   -0.0573251    0.204999     -0.00929066  -0.0394114    0.126714     0.0512726   -0.00881544  -0.0585066
 -0.056817    -0.0782405    0.144759     -0.0408372    0.0540074   -0.0738185    0.20028    -0.0937039   0.0169495   -0.14589      0.0287166    0.253845    -0.0814017  -0.102606     0.0179827   -0.0291971   -0.0279076    0.0860988   0.0271487   -0.0457787     0.0660168   -0.100065    -0.0935152    0.206716     0.112479     0.0333827
  0.0712678   -0.138034    -0.249447     -0.0707946   -0.00451543   0.0330122    0.0195644   0.0717241   0.0923207    0.0779572   -0.090818     0.011233    -0.259697   -0.124612    -0.0387491    0.159287     0.0308397    0.0291962  -0.0794323   -0.18881       0.0760805   -0.0474504    0.0115038    0.122165    -0.13962      0.0204854
 -0.081151    -0.0136434    0.0786057    -0.0250322   -0.0310056    0.0416525    0.0925397   0.0240234   0.0401207   -0.0248895    0.0753341    0.161047    -0.0692238  -0.0808615    0.0287395    0.00682123   0.0600879   -0.0247089  -0.00388562   0.0854998    -0.0481775   -0.233362     0.00456545  -0.212982    -0.125542    -0.0350713
 -0.0330453    0.0652194   -0.0586802    -0.0802194    0.011952    -0.00553297  -0.099966    0.0246064   0.0151144    0.0474522    0.0208976   -0.0230203   -0.0696068   0.113455     0.0209884   -0.0597658   -0.0155515   -0.013852    0.00263468  -0.0946136    -0.110892    -0.0372555    0.0396962   -0.0618689    0.0368071   -0.000768888
 -0.0602558   -0.150271     0.0457202     0.0493288   -0.0940292    0.189328     0.0889519   0.0292144   0.088665    -0.0175139   -0.0521163    0.00284013   0.0464522  -0.00775368   0.0240463   -0.0214851   -0.0687555   -0.0304854  -0.179831     0.0418272    -0.0747921   -0.0890225   -0.0430065   -0.0786032    0.0658468    0.0887619
  0.197397    -0.174276    -0.0312015    -0.0160877    0.0533011   -0.0367155    0.0663229   0.0792854  -0.156381    -0.0596145   -0.0733193    0.00334535   0.267796   -0.043951    -0.0575929    0.0224076   -0.0804516   -0.0648353  -0.18084     -0.0293708     0.0228988   -0.0537543   -0.16951     -0.0412246   -0.123005    -0.123441
  0.112972    -0.0809684    0.0151447     0.164716    -0.189995     0.0452697    0.334018    0.0509225   0.0557344    0.0498561   -0.039919     0.140732     0.15986     0.153626    -0.056317     0.135452    -0.168899     0.126766    0.0261272    0.0114485    -0.023085    -0.124978    -0.104421    -0.152503    -0.0264349   -0.145706
 -0.018988     0.0823171   -0.0401203    -0.00029944  -0.0402834   -0.131347     0.0326774   0.200164    0.147154    -0.0884828    0.117609     0.00476271   0.060951   -0.165369    -0.0971784    0.0117468   -0.113879    -0.16232     0.0901956    0.100939      0.0572823   -0.148099    -0.137083    -0.1064       0.185789    -0.000402755
 -0.0815317    0.0997166   -0.000584801  -0.132403     0.136539    -0.127935    -0.0783538  -0.107098    0.0111134    0.0164788   -0.102143    -0.0285248    0.141998    0.089155    -0.0680203   -0.0693138   -0.042789    -0.189582    0.226758    -0.0065383    -0.00136629  -0.0296214   -0.161756     0.12649     -0.0682911   -0.0618651
 -0.0635172    0.127184     0.000732423   0.0919247   -0.102726    -0.0896153    0.0506106   0.175454    0.117875    -0.109786    -0.0114242   -0.0117569   -0.0286685   0.013021     0.0498477   -0.115124     0.00143814   0.0144583  -0.0384513    0.100031     -0.0145442    0.0729538   -0.159899     0.00268066   0.0121422    0.00365051
 -0.0568831    0.0239405    0.0278081    -0.0146275    0.0824254    0.091499    -0.139669   -0.10821    -0.0667464    0.0145115    0.083844     0.116201    -0.0223553  -0.00803585   0.134428     0.148557     0.0212756   -0.0612001  -0.130697    -0.00179284   -0.00954087   0.0329194    0.0837915    0.0179252    0.080089    -0.106262
  0.154698    -0.0776341    0.184921      0.154761    -0.0589626   -0.184991    -0.154262   -0.0355806   0.0983983   -0.0386087    0.0343806    0.115547     0.0416619   0.151227     0.0452619    0.0390263   -0.0908993    0.0737441  -0.0324072   -0.187771      0.0643412    0.0265325   -0.131387    -0.104355     0.115642     0.0381211
 -0.0350671   -0.0251029   -0.098806      0.0688081   -0.266399     0.00854334   0.137804   -0.0806524   0.0814093   -0.0608377    0.0928454    0.0667134    0.120563   -0.136667     0.0118442   -0.0807049   -0.0460349    0.0608096  -0.00799811  -0.0448394    -0.114761     0.0756602    0.0639206   -0.0328998    0.0963602    0.00125519
  0.0567387    0.101802    -0.052959     -0.0365555   -0.0172997   -0.11086     -0.0486919  -0.0550902   0.119371     0.0176315    0.0131113    0.169335    -0.0827066  -0.0417823   -0.0586649   -0.02702      0.0520777    0.0983062  -0.0390969   -0.177995      0.115065    -0.0369697   -0.150992    -0.0942683    0.112017    -0.0639946
  0.104902    -0.0188327    0.0476996     0.0204006    0.0257138    0.0923026    0.194164    0.197159    0.0178254   -0.00555234   0.150995     0.136404     0.0910782   0.0488908    0.0252305    0.0364281    0.00121954   0.183419   -0.00809401   0.0413059     0.0786635   -0.0881678   -0.113131    -0.153608     0.0912399    0.0591894
 -0.0902428    0.17214      0.128321      0.132302     0.0813282   -0.204168    -0.162015   -0.0604616  -0.0146826    0.0290593   -0.228458    -0.0234272    0.100092    0.194247    -0.0186338    0.0476575   -0.0951605   -0.142132   -0.110988    -0.193807     -0.0276999   -0.0920918    0.0760294   -0.0785414   -0.0620253   -0.0194762
  0.226639    -0.0481199   -0.0519919     0.0113774   -0.019602    -0.0600021   -0.17126    -0.0755628  -0.00697782  -0.0655539   -0.0422323    0.164222    -0.0538132   0.0095644   -0.0105303    0.112058    -0.0721704   -0.0747057  -0.159065    -0.000983957  -0.038492     0.0849905    0.199491     0.0558882    0.162576    -0.206052
  0.0118006    0.156555     0.0226448     0.0906582    0.100649     0.123504     0.151714    0.0282204  -0.100071    -0.0721291    0.058851    -0.0271913   -0.0771055  -0.0571141    0.0614177   -0.10449     -0.0564352    0.105323   -0.130825    -0.129706      0.296732    -0.160945     0.0235043   -0.1002      -0.0826484    0.0349129
 -0.101456     0.14724     -0.0127142    -0.0188703   -0.0593472    0.200972    -0.0652992   0.0593025   0.0769876   -0.143882    -0.233934    -0.0423332    0.0219809  -0.0261798   -0.0643207    0.159013     0.0551195    0.234877    0.041851    -0.0820807    -0.0436777   -0.0308928   -0.0435042   -0.0761953    0.00581816   0.0596982
  0.0717449   -0.157735    -0.0173239     0.0322741    0.0603045   -0.0148209    0.263579    0.0633995  -0.0687805   -0.0461142   -0.108333    -0.172904     0.0661547  -0.0728369    0.088969     0.274199    -0.0167183   -0.195483   -0.0811634    0.0180393    -0.0488597   -0.107777    -0.107993    -0.116558    -0.0366922   -0.134791
  0.00522389   0.0232015   -0.0308755    -0.137719     0.0219853   -0.00818255  -0.071311   -0.0787067   0.0525968   -0.0802296   -0.0835713    0.0452183    0.0361725  -0.100992     0.00176034   0.0808893    0.0455989   -0.0619556  -0.11954     -0.064218      0.0141047   -0.125218     0.0673484   -0.0120458   -0.0305768    0.0847218
 -0.0140001   -0.0596768    0.0113572    -0.0700912   -0.106047    -0.0223985    0.018804   -0.0424028   0.184503     0.0422545    0.0417269    0.0742973   -0.20229     0.0948825   -0.0911851   -0.0524247    0.150798    -0.0377404  -0.249916     0.14102      -0.0478476    0.00903298   0.0472553   -0.0699276    0.147441     0.0491351
  0.0932113    0.222929     0.0397228    -0.0839504   -0.00102493   0.027453    -0.155931   -0.0376161  -0.0385811   -0.0832031    0.0425453   -0.0742753    0.315281   -0.136344    -0.171691    -0.108363     0.0770087   -0.0830398   0.109056     0.10925      -0.172846     0.0955197   -0.0577262    0.0787625    0.0748402   -0.214162
 -0.0244782    0.114291    -0.0615459    -0.0870095    0.167087     0.106983    -0.0821627  -0.148893    0.0206882   -0.0898905    0.0790199   -0.0589956   -0.110459   -0.0488972   -0.104255    -0.0358768    0.0476246    0.122784    0.19435     -0.0492066    -0.0876688    0.0950489   -0.121744     0.0108981    0.108777    -0.105202
  0.166577    -0.0237481   -0.0318        0.00937347  -0.118264     0.0574122   -0.0921134   0.0366878  -0.0254425   -0.0227237    0.00438482  -0.101671    -0.0736954  -0.0248178    0.02692     -0.107943    -0.142573     0.149001   -0.0789486   -0.089944      0.128332     0.0174569   -0.122818    -0.0410332    0.0679175   -0.110134
  0.00455267   0.208231    -0.0881462     0.0186606    0.0224009   -0.0811535   -0.0297836   0.308996   -0.069281     0.0576807   -0.00297813  -0.0268739    0.177316    0.102444    -0.175186    -0.0258939    0.0908806   -0.108523    0.105154    -0.133643      0.0398149    0.0741394    0.0177879   -0.111929    -0.087874    -0.196216
  0.131077     0.00962455   0.00775222    0.0729159    0.00811917  -0.0504635    0.152908   -0.0629046  -0.0459873   -0.124448     0.13664     -0.0184872    0.0850807   0.133018     0.134617    -0.12577      0.164616     0.0239984  -0.0480057   -0.0832563     0.102746    -0.210151    -0.0901423   -0.0884951   -0.0321155   -0.174928
  0.0331498    0.0418073    0.235968     -0.011142    -0.0327523   -0.0596985   -0.21437    -0.0107667  -0.0470297   -0.190191     0.232149    -0.0107665   -0.0042741  -0.10957      0.0466258   -0.0667653   -0.00667758  -0.103671   -0.0479739    0.0342135     0.069889    -0.0693437    0.0272814   -0.232058     0.0163482   -0.159141
 -0.128368     0.0181547   -0.0786312    -0.101441     0.0319054   -0.0881767    0.0373027  -0.0915908   0.0761917    0.125116    -0.235496     0.0500135    0.202739    0.0469508    0.0317912   -0.0095707   -0.0718198    0.0377483  -0.205613     0.0534013    -0.0181639   -0.00791064   0.00602505  -0.176834     0.0995816   -0.0829891
 -0.031087    -0.0209099    0.0608039     0.124267    -0.101519     0.0114149    0.0637052  -0.189072    0.00750474  -0.0551534    0.0262858    0.21062      0.0556096   0.0745953    0.0287682   -0.15007     -0.0397929   -0.0255101   0.0293782   -0.103919      0.0030344    0.0177659    0.0219298   -0.00894187   0.203102    -0.00103153kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4207264418448082
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420745
[ Info: iteration 2, average log likelihood -1.420678
[ Info: iteration 3, average log likelihood -1.420625
[ Info: iteration 4, average log likelihood -1.420557
[ Info: iteration 5, average log likelihood -1.420459
[ Info: iteration 6, average log likelihood -1.420303
[ Info: iteration 7, average log likelihood -1.420026
[ Info: iteration 8, average log likelihood -1.419505
[ Info: iteration 9, average log likelihood -1.418614
[ Info: iteration 10, average log likelihood -1.417446
[ Info: iteration 11, average log likelihood -1.416400
[ Info: iteration 12, average log likelihood -1.415764
[ Info: iteration 13, average log likelihood -1.415470
[ Info: iteration 14, average log likelihood -1.415349
[ Info: iteration 15, average log likelihood -1.415301
[ Info: iteration 16, average log likelihood -1.415282
[ Info: iteration 17, average log likelihood -1.415274
[ Info: iteration 18, average log likelihood -1.415271
[ Info: iteration 19, average log likelihood -1.415270
[ Info: iteration 20, average log likelihood -1.415269
[ Info: iteration 21, average log likelihood -1.415269
[ Info: iteration 22, average log likelihood -1.415269
[ Info: iteration 23, average log likelihood -1.415269
[ Info: iteration 24, average log likelihood -1.415268
[ Info: iteration 25, average log likelihood -1.415268
[ Info: iteration 26, average log likelihood -1.415268
[ Info: iteration 27, average log likelihood -1.415268
[ Info: iteration 28, average log likelihood -1.415268
[ Info: iteration 29, average log likelihood -1.415268
[ Info: iteration 30, average log likelihood -1.415268
[ Info: iteration 31, average log likelihood -1.415268
[ Info: iteration 32, average log likelihood -1.415268
[ Info: iteration 33, average log likelihood -1.415268
[ Info: iteration 34, average log likelihood -1.415268
[ Info: iteration 35, average log likelihood -1.415268
[ Info: iteration 36, average log likelihood -1.415268
[ Info: iteration 37, average log likelihood -1.415268
[ Info: iteration 38, average log likelihood -1.415268
[ Info: iteration 39, average log likelihood -1.415268
[ Info: iteration 40, average log likelihood -1.415268
[ Info: iteration 41, average log likelihood -1.415268
[ Info: iteration 42, average log likelihood -1.415268
[ Info: iteration 43, average log likelihood -1.415268
[ Info: iteration 44, average log likelihood -1.415268
[ Info: iteration 45, average log likelihood -1.415268
[ Info: iteration 46, average log likelihood -1.415268
[ Info: iteration 47, average log likelihood -1.415268
[ Info: iteration 48, average log likelihood -1.415268
[ Info: iteration 49, average log likelihood -1.415268
[ Info: iteration 50, average log likelihood -1.415268
┌ Info: EM with 100000 data points 50 iterations avll -1.415268
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420744958318803
│     -1.4206780648783526
│      ⋮
└     -1.4152679941606938
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415283
[ Info: iteration 2, average log likelihood -1.415222
[ Info: iteration 3, average log likelihood -1.415171
[ Info: iteration 4, average log likelihood -1.415108
[ Info: iteration 5, average log likelihood -1.415028
[ Info: iteration 6, average log likelihood -1.414932
[ Info: iteration 7, average log likelihood -1.414829
[ Info: iteration 8, average log likelihood -1.414730
[ Info: iteration 9, average log likelihood -1.414646
[ Info: iteration 10, average log likelihood -1.414577
[ Info: iteration 11, average log likelihood -1.414519
[ Info: iteration 12, average log likelihood -1.414468
[ Info: iteration 13, average log likelihood -1.414422
[ Info: iteration 14, average log likelihood -1.414379
[ Info: iteration 15, average log likelihood -1.414338
[ Info: iteration 16, average log likelihood -1.414301
[ Info: iteration 17, average log likelihood -1.414267
[ Info: iteration 18, average log likelihood -1.414236
[ Info: iteration 19, average log likelihood -1.414207
[ Info: iteration 20, average log likelihood -1.414181
[ Info: iteration 21, average log likelihood -1.414157
[ Info: iteration 22, average log likelihood -1.414135
[ Info: iteration 23, average log likelihood -1.414115
[ Info: iteration 24, average log likelihood -1.414098
[ Info: iteration 25, average log likelihood -1.414083
[ Info: iteration 26, average log likelihood -1.414070
[ Info: iteration 27, average log likelihood -1.414059
[ Info: iteration 28, average log likelihood -1.414050
[ Info: iteration 29, average log likelihood -1.414042
[ Info: iteration 30, average log likelihood -1.414036
[ Info: iteration 31, average log likelihood -1.414031
[ Info: iteration 32, average log likelihood -1.414026
[ Info: iteration 33, average log likelihood -1.414022
[ Info: iteration 34, average log likelihood -1.414019
[ Info: iteration 35, average log likelihood -1.414017
[ Info: iteration 36, average log likelihood -1.414014
[ Info: iteration 37, average log likelihood -1.414012
[ Info: iteration 38, average log likelihood -1.414010
[ Info: iteration 39, average log likelihood -1.414009
[ Info: iteration 40, average log likelihood -1.414007
[ Info: iteration 41, average log likelihood -1.414006
[ Info: iteration 42, average log likelihood -1.414004
[ Info: iteration 43, average log likelihood -1.414003
[ Info: iteration 44, average log likelihood -1.414002
[ Info: iteration 45, average log likelihood -1.414001
[ Info: iteration 46, average log likelihood -1.414000
[ Info: iteration 47, average log likelihood -1.413999
[ Info: iteration 48, average log likelihood -1.413998
[ Info: iteration 49, average log likelihood -1.413997
[ Info: iteration 50, average log likelihood -1.413996
┌ Info: EM with 100000 data points 50 iterations avll -1.413996
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152827871893097
│     -1.4152218688555152
│      ⋮
└     -1.4139959244832703
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414005
[ Info: iteration 2, average log likelihood -1.413955
[ Info: iteration 3, average log likelihood -1.413912
[ Info: iteration 4, average log likelihood -1.413863
[ Info: iteration 5, average log likelihood -1.413805
[ Info: iteration 6, average log likelihood -1.413735
[ Info: iteration 7, average log likelihood -1.413652
[ Info: iteration 8, average log likelihood -1.413561
[ Info: iteration 9, average log likelihood -1.413466
[ Info: iteration 10, average log likelihood -1.413372
[ Info: iteration 11, average log likelihood -1.413285
[ Info: iteration 12, average log likelihood -1.413206
[ Info: iteration 13, average log likelihood -1.413136
[ Info: iteration 14, average log likelihood -1.413075
[ Info: iteration 15, average log likelihood -1.413024
[ Info: iteration 16, average log likelihood -1.412980
[ Info: iteration 17, average log likelihood -1.412943
[ Info: iteration 18, average log likelihood -1.412911
[ Info: iteration 19, average log likelihood -1.412884
[ Info: iteration 20, average log likelihood -1.412860
[ Info: iteration 21, average log likelihood -1.412839
[ Info: iteration 22, average log likelihood -1.412821
[ Info: iteration 23, average log likelihood -1.412804
[ Info: iteration 24, average log likelihood -1.412788
[ Info: iteration 25, average log likelihood -1.412773
[ Info: iteration 26, average log likelihood -1.412760
[ Info: iteration 27, average log likelihood -1.412747
[ Info: iteration 28, average log likelihood -1.412735
[ Info: iteration 29, average log likelihood -1.412723
[ Info: iteration 30, average log likelihood -1.412713
[ Info: iteration 31, average log likelihood -1.412702
[ Info: iteration 32, average log likelihood -1.412693
[ Info: iteration 33, average log likelihood -1.412683
[ Info: iteration 34, average log likelihood -1.412674
[ Info: iteration 35, average log likelihood -1.412666
[ Info: iteration 36, average log likelihood -1.412658
[ Info: iteration 37, average log likelihood -1.412650
[ Info: iteration 38, average log likelihood -1.412642
[ Info: iteration 39, average log likelihood -1.412635
[ Info: iteration 40, average log likelihood -1.412628
[ Info: iteration 41, average log likelihood -1.412621
[ Info: iteration 42, average log likelihood -1.412614
[ Info: iteration 43, average log likelihood -1.412607
[ Info: iteration 44, average log likelihood -1.412601
[ Info: iteration 45, average log likelihood -1.412595
[ Info: iteration 46, average log likelihood -1.412588
[ Info: iteration 47, average log likelihood -1.412582
[ Info: iteration 48, average log likelihood -1.412576
[ Info: iteration 49, average log likelihood -1.412570
[ Info: iteration 50, average log likelihood -1.412565
┌ Info: EM with 100000 data points 50 iterations avll -1.412565
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4140050892481335
│     -1.4139546970966888
│      ⋮
└     -1.4125645245950744
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412567
[ Info: iteration 2, average log likelihood -1.412508
[ Info: iteration 3, average log likelihood -1.412456
[ Info: iteration 4, average log likelihood -1.412398
[ Info: iteration 5, average log likelihood -1.412328
[ Info: iteration 6, average log likelihood -1.412244
[ Info: iteration 7, average log likelihood -1.412146
[ Info: iteration 8, average log likelihood -1.412036
[ Info: iteration 9, average log likelihood -1.411919
[ Info: iteration 10, average log likelihood -1.411801
[ Info: iteration 11, average log likelihood -1.411685
[ Info: iteration 12, average log likelihood -1.411576
[ Info: iteration 13, average log likelihood -1.411476
[ Info: iteration 14, average log likelihood -1.411385
[ Info: iteration 15, average log likelihood -1.411304
[ Info: iteration 16, average log likelihood -1.411234
[ Info: iteration 17, average log likelihood -1.411173
[ Info: iteration 18, average log likelihood -1.411119
[ Info: iteration 19, average log likelihood -1.411072
[ Info: iteration 20, average log likelihood -1.411031
[ Info: iteration 21, average log likelihood -1.410994
[ Info: iteration 22, average log likelihood -1.410960
[ Info: iteration 23, average log likelihood -1.410928
[ Info: iteration 24, average log likelihood -1.410899
[ Info: iteration 25, average log likelihood -1.410871
[ Info: iteration 26, average log likelihood -1.410845
[ Info: iteration 27, average log likelihood -1.410819
[ Info: iteration 28, average log likelihood -1.410795
[ Info: iteration 29, average log likelihood -1.410771
[ Info: iteration 30, average log likelihood -1.410748
[ Info: iteration 31, average log likelihood -1.410725
[ Info: iteration 32, average log likelihood -1.410703
[ Info: iteration 33, average log likelihood -1.410682
[ Info: iteration 34, average log likelihood -1.410662
[ Info: iteration 35, average log likelihood -1.410642
[ Info: iteration 36, average log likelihood -1.410623
[ Info: iteration 37, average log likelihood -1.410604
[ Info: iteration 38, average log likelihood -1.410587
[ Info: iteration 39, average log likelihood -1.410570
[ Info: iteration 40, average log likelihood -1.410554
[ Info: iteration 41, average log likelihood -1.410538
[ Info: iteration 42, average log likelihood -1.410524
[ Info: iteration 43, average log likelihood -1.410510
[ Info: iteration 44, average log likelihood -1.410496
[ Info: iteration 45, average log likelihood -1.410483
[ Info: iteration 46, average log likelihood -1.410470
[ Info: iteration 47, average log likelihood -1.410458
[ Info: iteration 48, average log likelihood -1.410447
[ Info: iteration 49, average log likelihood -1.410435
[ Info: iteration 50, average log likelihood -1.410424
┌ Info: EM with 100000 data points 50 iterations avll -1.410424
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412567019165898
│     -1.4125082326093725
│      ⋮
└     -1.4104242173660257
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410422
[ Info: iteration 2, average log likelihood -1.410355
[ Info: iteration 3, average log likelihood -1.410290
[ Info: iteration 4, average log likelihood -1.410212
[ Info: iteration 5, average log likelihood -1.410112
[ Info: iteration 6, average log likelihood -1.409984
[ Info: iteration 7, average log likelihood -1.409826
[ Info: iteration 8, average log likelihood -1.409645
[ Info: iteration 9, average log likelihood -1.409450
[ Info: iteration 10, average log likelihood -1.409257
[ Info: iteration 11, average log likelihood -1.409076
[ Info: iteration 12, average log likelihood -1.408915
[ Info: iteration 13, average log likelihood -1.408776
[ Info: iteration 14, average log likelihood -1.408657
[ Info: iteration 15, average log likelihood -1.408555
[ Info: iteration 16, average log likelihood -1.408468
[ Info: iteration 17, average log likelihood -1.408393
[ Info: iteration 18, average log likelihood -1.408328
[ Info: iteration 19, average log likelihood -1.408271
[ Info: iteration 20, average log likelihood -1.408220
[ Info: iteration 21, average log likelihood -1.408174
[ Info: iteration 22, average log likelihood -1.408133
[ Info: iteration 23, average log likelihood -1.408096
[ Info: iteration 24, average log likelihood -1.408062
[ Info: iteration 25, average log likelihood -1.408030
[ Info: iteration 26, average log likelihood -1.408001
[ Info: iteration 27, average log likelihood -1.407973
[ Info: iteration 28, average log likelihood -1.407947
[ Info: iteration 29, average log likelihood -1.407923
[ Info: iteration 30, average log likelihood -1.407899
[ Info: iteration 31, average log likelihood -1.407876
[ Info: iteration 32, average log likelihood -1.407855
[ Info: iteration 33, average log likelihood -1.407834
[ Info: iteration 34, average log likelihood -1.407814
[ Info: iteration 35, average log likelihood -1.407794
[ Info: iteration 36, average log likelihood -1.407775
[ Info: iteration 37, average log likelihood -1.407757
[ Info: iteration 38, average log likelihood -1.407739
[ Info: iteration 39, average log likelihood -1.407722
[ Info: iteration 40, average log likelihood -1.407705
[ Info: iteration 41, average log likelihood -1.407688
[ Info: iteration 42, average log likelihood -1.407672
[ Info: iteration 43, average log likelihood -1.407657
[ Info: iteration 44, average log likelihood -1.407641
[ Info: iteration 45, average log likelihood -1.407626
[ Info: iteration 46, average log likelihood -1.407612
[ Info: iteration 47, average log likelihood -1.407597
[ Info: iteration 48, average log likelihood -1.407583
[ Info: iteration 49, average log likelihood -1.407570
[ Info: iteration 50, average log likelihood -1.407557
┌ Info: EM with 100000 data points 50 iterations avll -1.407557
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410421936715676
│     -1.4103553564162263
│      ⋮
└     -1.407556918251303
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4207264418448082
│     -1.420744958318803
│     -1.4206780648783526
│     -1.4206250278515364
│      ⋮
│     -1.4075834471296822
│     -1.4075699815515859
└     -1.407556918251303
32×26 Array{Float64,2}:
 -0.313032    0.181199   -0.338991    0.517775   -0.612971    -0.353804    0.276228     0.517566     0.0647177   -0.887127    0.229259     0.52885    -0.328531   -0.279198    0.427913    -0.234489   -0.109121    -0.12727     -0.199506     -0.669413    -0.50456    -0.610584    0.459928   -0.545281    0.226267     0.470541
 -0.453498   -0.0401935  -0.0787102   0.542115    0.221134     0.0723953   0.213431     0.934658     0.324027    -0.57258    -0.211753    -0.445915    0.18228    -0.92193     0.148843    -0.458308    0.0322573    0.309478     0.411374      0.209776    -0.572809   -0.3982      0.56111    -0.3599      0.67448      0.475227
  0.227393    0.557429   -0.409796   -0.113994    0.561561     0.160035    0.265593     0.544514     0.0560022    0.0334379  -0.330506    -0.330758    0.675601    0.246971    0.312107     0.343239    0.00537281  -0.0828214    0.349597     -0.0829523   -0.036361   -0.384321    0.767906   -0.0634734  -0.35212      0.33201
 -0.0936746  -0.193228    0.223883    0.456642   -0.112386    -0.053478    0.58857     -0.0300628    0.424684     0.754024    0.336768    -0.360869    0.626413    0.349969    0.328066    -0.147459    0.282207    -0.286896     0.163345     -0.0113524    0.279696   -0.230944    0.520804   -0.511914   -0.3926      -0.0745913
 -0.146289   -0.156763   -0.702856   -0.141735   -0.304242     0.0323179  -0.0510188   -0.0417974    0.371356    -0.247357   -0.481283    -0.293318   -0.113504   -0.0120928  -0.0867315   -0.0331937  -0.114911     0.1121      -0.0928836    -0.0790013   -0.0148241  -0.20461     0.209436   -0.307267    0.200591     0.0983898
  0.220101    0.208953    0.658335    0.0409989   0.160709     0.0319641   0.0681238   -0.102736    -0.0106654    0.0185253   0.19945      0.0660568  -0.0573288  -0.136335   -0.0435817    0.0680205   0.167443    -0.0195915   -0.0686765     0.0793836   -0.115954    0.155995   -0.091257    0.205666   -0.174517    -0.240204
 -0.273872   -0.180355   -0.224919    0.179645    0.493523     0.346521   -0.502643     0.380068     0.357688    -0.60028     0.572842     0.258099   -0.298498   -0.277798   -0.254686    -0.484582   -0.730762     0.203107     0.171896      0.179805     0.481538   -0.237207   -0.662446   -0.388458    0.0915757   -0.000263019
 -0.228002   -0.0461678  -0.0442821   0.300209   -0.50398     -0.291373   -0.398544    -0.0354299    0.182814    -0.12699     0.622478     0.612354    0.223269   -0.416826   -0.302212     0.502405    0.0102227   -0.131458    -0.740904      0.128206     0.021617    0.200862   -0.553362    0.104644    0.764804     0.057965
  0.193486   -0.187934   -0.0203907  -0.0807265   0.0747445   -0.465644   -0.0544232    0.607163    -0.232926     0.692813    0.205835    -0.138196    0.0135896   0.599204   -0.181226    -0.534474    0.227851    -0.492723     0.0405806    -0.983235     0.463681   -0.815911   -0.463931    0.110154    0.178761    -0.0397479
 -0.0297326  -0.317343    0.0661927  -0.0134722   0.524288    -0.0376864   0.751488    -0.111366    -0.462644    -0.0763994   0.682333     0.646921   -0.17645     0.791366   -0.0313352   -0.109824    0.0810603    0.161608    -0.0412941    -1.05079      0.500673    0.0263587  -0.478166    0.0218069  -0.643348     0.587606
  0.17781    -0.637428   -1.23955     0.39568     0.237927    -0.270089   -0.131627     0.00978861  -0.724677     0.407386   -0.451921     0.429957   -0.176831    0.350223    0.215475    -0.111192   -0.185263     0.530271    -0.388445      0.218308     0.0623974   0.138444    0.627176    1.14638     0.273095     0.298695
  0.226919   -0.280107    0.155075   -0.157981   -0.00295852  -0.0900369   0.263021     0.499224    -0.820955     0.629613    0.0714074    0.0571193   0.135564    0.131074    0.758626    -0.223372   -0.213762     0.160842    -0.0389403     0.588965     0.41208     0.265899   -0.202673    0.163518    0.19186     -0.135878
  0.638141   -0.411705    0.2242      0.0397825  -0.412739    -0.451977    0.0990883   -0.788372    -0.202024     0.243852    0.402849     0.384988    0.141206    0.278765   -0.252986     0.0448606  -0.263428    -0.257976     0.219786     -0.573484    -0.730014    0.170221   -0.295994   -0.103934    0.0814213   -0.55301
  0.0135954   0.0989434  -0.519179   -0.266572   -0.737139     0.475445    0.43646     -0.469232    -0.197632     0.11231     0.0195609    0.212584    0.497414    0.803029   -0.272233     0.366391   -0.580087    -0.0856268    0.477705     -0.0248233   -0.246434    1.17853    -0.225376   -0.39913    -0.208511     0.362685
 -0.299835   -0.0452145   0.515875   -0.473687   -0.31082      0.38971    -0.064475    -0.370478    -0.192731    -0.115481    0.0507664    0.90316    -0.0851116  -0.0652285   0.082659     0.26315     0.0251564    0.570587     0.0863441     0.346614     0.532552   -0.0950284  -0.740268   -0.976753    0.00800166  -0.786948
  0.823146   -0.0762227   0.0618281  -0.646694    0.0292864    0.0961347  -0.221999    -1.09853     -0.450035     0.554183   -0.0605811    0.393283    0.441976    0.756973    0.0172416    0.595693   -0.129633    -0.311108    -0.590301     -0.0205141    0.85522     0.364368   -0.59448     0.26813    -0.796106    -0.70612
 -0.0834004  -0.734107    0.350658    0.315417    0.430392    -0.920878   -0.251162     0.00243693  -0.12316     -0.393022   -0.0370167   -0.278398    0.168225   -0.514443    0.176707     0.295975    0.0898275   -0.4223      -0.0460012    -0.107345     0.144614   -0.858544    0.134111    0.241837    0.574947    -0.317456
 -0.227899   -0.3408      0.118158   -0.431181   -0.0398227   -0.604452   -0.494456     0.0636801   -0.840717    -0.175541   -0.276955    -0.469537    0.858423   -0.070533    0.487449    -0.104888    0.477983    -0.120602     0.165829     -0.00740676   0.188797    0.221524    0.280686    0.293707    0.11163      0.0673598
  0.0333802   0.163247   -0.0467334   0.281378    0.199602     0.022611   -0.106934    -0.357984     0.536548    -0.90892     0.224917     0.079021    0.11062    -0.0823776  -0.409383     0.405627    0.16226     -0.454156     0.363904     -0.72677     -0.232426   -0.527479   -0.205972   -0.11819    -0.198028    -0.0469352
  0.165329    0.390818    0.188061    0.0204726   0.425399     0.0461556   0.117133    -0.0910108    0.29713      0.377514   -0.190653    -0.321687    0.304936    0.102304   -0.558357     0.288288    0.291508    -0.20204      0.00438233   -0.494779    -0.425409   -0.107156    0.0999743   0.0969955  -0.169016    -0.203939
 -0.163473    0.615719    0.225654    0.105699    0.134368     0.0929512  -0.358847     0.0224421    0.593985     0.0678534  -0.731792    -0.290042   -0.254338   -0.327727    0.114719     0.0788503   0.198965    -0.116484    -0.319507      0.585965     0.0301263   0.0976631   0.630924    0.0647365   0.461084    -0.0565258
  0.15782     0.520168   -0.0468073  -0.0648197  -0.0717375    0.136078   -0.00181038  -0.419565    -0.201789    -0.223966    0.192602     0.166442    0.0772756  -0.0486773   0.46296      0.502296    0.272708    -0.146595    -0.304073      0.222352    -0.331477    0.417167    0.666961    0.192878   -0.00736892  -0.0532151
  0.305508    0.386312    0.191099   -0.112396   -0.177606     0.113688   -0.625215    -0.0220836    0.497744    -0.137429   -0.200191    -0.309983    0.623633   -0.568366    0.013194     0.319382    0.0646542    0.0939158    0.123542      0.904272    -0.225403    0.102688   -0.111637   -0.413049    0.394406    -0.604864
  0.17606    -0.102061   -0.116336   -0.212549   -0.193776     0.282371    0.491537    -0.00866389  -0.137585     0.102014   -0.321653    -0.0994899   0.652536   -0.665335    0.0515156    0.265176    0.390314    -0.00313039  -0.0678013    -0.0871751    0.539914    0.0526639  -0.509868   -0.304893    0.120587     0.241693
  0.274981    0.345496   -0.113031   -0.244216    0.360076     0.255109    0.122886     0.101564    -0.187928    -0.333309   -0.19377      0.29264    -1.15477    -0.13202    -0.409565    -0.941554   -0.100702     0.225307     0.11893      -0.195541    -0.208567   -0.0967005   0.0191517   0.395592   -0.297035     0.252802
  0.284346    0.0831348   0.0777886  -0.52472    -0.2792      -0.0589417  -0.0749111   -0.131081    -0.381802    -0.433068   -0.177857     0.322178   -0.740325   -0.0868611  -0.18235     -0.0832443   0.0193856    0.265164    -0.092293      0.262102     0.0448868   0.767567   -0.54118     0.607112    0.253528    -0.359118
  0.056793   -0.0581483  -0.0919602  -0.660188   -0.452199    -0.127404   -0.173209     0.42054      0.209401     0.25035    -0.639282    -0.255136   -0.268724   -0.0319508  -0.453825     0.0191362  -0.152598     0.184917    -0.330904     -0.121505    -0.0302845  -0.241567   -0.365224   -0.159017    0.560695     0.132835
  0.302316   -0.603375   -0.231358    0.382403   -0.0124806    0.233251    0.425499     0.266474    -0.240826    -0.328103    0.0722828   -0.452474   -0.576055   -0.0821751  -0.268714    -0.198926   -0.548167     0.120666    -0.170038     -0.107288    -0.31633    -0.162721   -0.722285    0.294744   -0.219205    -0.0806566
 -0.642394   -0.185693   -0.0328019   0.414654   -0.171187    -0.206526   -0.709716    -0.342428     0.337905    -0.110979    0.125319     0.248406   -0.0765085   0.495454   -0.0543336   -0.0975612  -0.387271     0.0794287    0.000415801   0.0962818   -0.150841   -0.0504109   0.296626   -0.23805    -0.206623    -0.112839
 -0.0489314   0.214384    0.104589   -0.0253126  -0.0430168    0.239618    0.243155    -0.144333     0.326199     0.370097    0.00343991   0.184627   -0.210836    0.553016   -0.0752529   -0.511146    0.158534     0.449486     0.047691     -0.0181945    0.0640904   0.171121   -0.0425974  -0.316568   -0.691975    -0.0735758
 -0.0453754   0.0289917   0.0541002  -0.140207    0.00276488  -0.27495    -0.065479     0.00980001   0.00767694   0.0729057  -0.0749156    0.0696131   0.153164   -0.0120238   0.0263848   -0.0822591   0.20279      0.0280032   -0.0848806    -0.13002      0.0896918   0.0624085  -0.0337126  -0.0412489   0.0589552   -0.0484224
  0.0679196  -0.127098   -0.0887738   0.231674   -0.0282222    0.245156    0.121748     0.101445    -0.00932836  -0.131919    0.121703    -0.0344301  -0.110136    0.0334246  -0.00330333   0.0686681  -0.319677    -0.100119     0.0449311     0.177867    -2.1969e-5  -0.160248   -0.0343009  -0.0388777   0.0934993   -0.00645345[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407544
[ Info: iteration 2, average log likelihood -1.407532
[ Info: iteration 3, average log likelihood -1.407520
[ Info: iteration 4, average log likelihood -1.407509
[ Info: iteration 5, average log likelihood -1.407498
[ Info: iteration 6, average log likelihood -1.407487
[ Info: iteration 7, average log likelihood -1.407477
[ Info: iteration 8, average log likelihood -1.407468
[ Info: iteration 9, average log likelihood -1.407459
[ Info: iteration 10, average log likelihood -1.407450
┌ Info: EM with 100000 data points 10 iterations avll -1.407450
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.035678e+05
      1       6.994985e+05      -2.040692e+05 |       32
      2       6.875653e+05      -1.193327e+04 |       32
      3       6.827523e+05      -4.812975e+03 |       32
      4       6.801404e+05      -2.611932e+03 |       32
      5       6.784222e+05      -1.718150e+03 |       32
      6       6.771940e+05      -1.228229e+03 |       32
      7       6.762815e+05      -9.125211e+02 |       32
      8       6.754948e+05      -7.866342e+02 |       32
      9       6.748415e+05      -6.532932e+02 |       32
     10       6.743188e+05      -5.227175e+02 |       32
     11       6.738806e+05      -4.381846e+02 |       32
     12       6.735057e+05      -3.749719e+02 |       32
     13       6.731997e+05      -3.059257e+02 |       32
     14       6.729570e+05      -2.427761e+02 |       32
     15       6.727436e+05      -2.133662e+02 |       32
     16       6.725519e+05      -1.917366e+02 |       32
     17       6.723702e+05      -1.816105e+02 |       32
     18       6.722104e+05      -1.598273e+02 |       32
     19       6.720539e+05      -1.564969e+02 |       32
     20       6.719098e+05      -1.440837e+02 |       32
     21       6.717769e+05      -1.329364e+02 |       32
     22       6.716576e+05      -1.193175e+02 |       32
     23       6.715558e+05      -1.017572e+02 |       32
     24       6.714696e+05      -8.617991e+01 |       32
     25       6.713851e+05      -8.455477e+01 |       32
     26       6.713130e+05      -7.204923e+01 |       32
     27       6.712450e+05      -6.803822e+01 |       32
     28       6.711804e+05      -6.464739e+01 |       32
     29       6.711171e+05      -6.328780e+01 |       32
     30       6.710597e+05      -5.740232e+01 |       32
     31       6.710049e+05      -5.474464e+01 |       32
     32       6.709574e+05      -4.751816e+01 |       32
     33       6.709159e+05      -4.149610e+01 |       32
     34       6.708779e+05      -3.805266e+01 |       32
     35       6.708478e+05      -3.008492e+01 |       32
     36       6.708210e+05      -2.676593e+01 |       32
     37       6.707991e+05      -2.194311e+01 |       32
     38       6.707799e+05      -1.916872e+01 |       32
     39       6.707581e+05      -2.177199e+01 |       32
     40       6.707371e+05      -2.104406e+01 |       32
     41       6.707171e+05      -1.995027e+01 |       32
     42       6.706994e+05      -1.775231e+01 |       32
     43       6.706837e+05      -1.565623e+01 |       32
     44       6.706645e+05      -1.917995e+01 |       32
     45       6.706432e+05      -2.129662e+01 |       32
     46       6.706208e+05      -2.244596e+01 |       32
     47       6.706014e+05      -1.939105e+01 |       32
     48       6.705813e+05      -2.012057e+01 |       32
     49       6.705616e+05      -1.972086e+01 |       32
     50       6.705449e+05      -1.670952e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670544.8536632757)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419802
[ Info: iteration 2, average log likelihood -1.414685
[ Info: iteration 3, average log likelihood -1.413221
[ Info: iteration 4, average log likelihood -1.412097
[ Info: iteration 5, average log likelihood -1.410992
[ Info: iteration 6, average log likelihood -1.410090
[ Info: iteration 7, average log likelihood -1.409526
[ Info: iteration 8, average log likelihood -1.409215
[ Info: iteration 9, average log likelihood -1.409032
[ Info: iteration 10, average log likelihood -1.408906
[ Info: iteration 11, average log likelihood -1.408809
[ Info: iteration 12, average log likelihood -1.408729
[ Info: iteration 13, average log likelihood -1.408659
[ Info: iteration 14, average log likelihood -1.408596
[ Info: iteration 15, average log likelihood -1.408540
[ Info: iteration 16, average log likelihood -1.408488
[ Info: iteration 17, average log likelihood -1.408440
[ Info: iteration 18, average log likelihood -1.408395
[ Info: iteration 19, average log likelihood -1.408352
[ Info: iteration 20, average log likelihood -1.408312
[ Info: iteration 21, average log likelihood -1.408275
[ Info: iteration 22, average log likelihood -1.408239
[ Info: iteration 23, average log likelihood -1.408204
[ Info: iteration 24, average log likelihood -1.408172
[ Info: iteration 25, average log likelihood -1.408140
[ Info: iteration 26, average log likelihood -1.408109
[ Info: iteration 27, average log likelihood -1.408080
[ Info: iteration 28, average log likelihood -1.408051
[ Info: iteration 29, average log likelihood -1.408024
[ Info: iteration 30, average log likelihood -1.407996
[ Info: iteration 31, average log likelihood -1.407970
[ Info: iteration 32, average log likelihood -1.407945
[ Info: iteration 33, average log likelihood -1.407920
[ Info: iteration 34, average log likelihood -1.407896
[ Info: iteration 35, average log likelihood -1.407873
[ Info: iteration 36, average log likelihood -1.407851
[ Info: iteration 37, average log likelihood -1.407829
[ Info: iteration 38, average log likelihood -1.407809
[ Info: iteration 39, average log likelihood -1.407790
[ Info: iteration 40, average log likelihood -1.407771
[ Info: iteration 41, average log likelihood -1.407753
[ Info: iteration 42, average log likelihood -1.407735
[ Info: iteration 43, average log likelihood -1.407719
[ Info: iteration 44, average log likelihood -1.407703
[ Info: iteration 45, average log likelihood -1.407687
[ Info: iteration 46, average log likelihood -1.407672
[ Info: iteration 47, average log likelihood -1.407657
[ Info: iteration 48, average log likelihood -1.407643
[ Info: iteration 49, average log likelihood -1.407629
[ Info: iteration 50, average log likelihood -1.407616
┌ Info: EM with 100000 data points 50 iterations avll -1.407616
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.338555     0.185017     0.547784     -0.294482     0.0659214    0.033762    -0.197518    -0.610295    -0.121212     0.227273     0.347592     0.387655     0.365399     0.233324   -0.0577123   0.790452    0.169653    -0.0357093  -0.302104    0.319862    0.630928    0.29445    -0.51432    -0.133635    -0.419687    -0.651877
 -0.127359     0.0270986   -0.191969      0.440805     0.354588     0.168831    -0.2232       0.13274      0.578116    -0.763174    -0.0661781   -0.488348     0.352842    -0.270287   -0.176591    0.06966    -0.114409    -0.296756    0.392327   -0.338249   -0.0347808  -0.716634    0.139168   -0.555044     0.0100636    0.214814
  0.284352     0.350464     0.034909     -0.373176     0.315133     0.158329     0.096047     0.00760816  -0.178198    -0.0865164   -0.232521     0.265963    -1.01708      0.0953747  -0.179667   -1.15941     0.00904659   0.430778    0.30829    -0.203166   -0.245314    0.0793788   0.177497    0.320415    -0.600578     0.328637
  0.214121    -0.142469    -0.543648     -0.362972    -0.611909     0.134242     0.324418    -0.64489     -0.170162     0.222686    -0.328094     0.151981     0.00441132   0.644352   -0.305725    0.0302793  -0.391249     0.150983    0.206454    0.136319   -0.253536    1.15284    -0.216371   -0.216697    -0.475901    -0.179561
  0.139184    -0.0446871    0.483029     -0.117945     0.0375579    0.655479    -0.0227551   -0.764414     0.504774    -0.198198     0.249324     0.87349     -0.301434    -0.512035   -0.54061    -0.478323   -0.312149     0.194265    0.380385    0.11595    -0.107289   -0.523865   -0.760235   -0.883261    -0.153533    -0.681135
 -0.561987     0.205022    -0.362961      0.176344     0.103029     0.0717965   -0.259162     0.101627     0.277553     0.00886312  -0.309497     0.209789    -0.273076     0.0135931  -0.0122803  -0.348191   -0.0233095    0.229078   -0.403845    0.250162    0.337904    0.0292683   0.480145   -0.0286729    0.0462699    0.557191
  0.334147     0.219361    -0.155777     -0.163986    -0.34974      0.231388     0.73091      0.0657919   -0.161983     0.111599    -0.307915     0.208856     0.506567    -0.755636    0.064481    0.372079    0.694647     0.0676988  -0.119165   -0.260556    0.22871     0.0975626  -0.356856   -0.264677     0.283015     0.565777
  0.143394     0.00111965  -0.746381     -0.126531     0.0890696   -0.377478     0.127961     0.538645    -0.340295     0.106746    -0.185879    -0.543827     0.316318     0.737523    0.504546    0.540254    0.408172    -0.0448854  -0.296036   -0.366891    0.121099    0.0176004   0.749853    0.642981    -0.0632841    0.469022
 -0.0175854    0.433885     0.160981      0.0748923   -0.0830867   -0.238968     0.0843014   -0.00414963   0.151988     0.456924     0.159311     0.241509     0.565086     0.442542    0.557684   -0.0800306   0.25724     -0.145653    0.195875   -0.0894042   0.0559492  -0.297835    0.92293    -0.545201    -0.267688    -0.023531
 -0.187167     0.201359     0.251168     -0.244148    -0.0102553    0.0776       0.00535496  -0.089767     0.149836    -0.201473    -0.510301    -0.603629     0.835416    -0.504822    0.349812    0.016099    0.392249     0.0631475   0.688875    0.695729   -0.0846378   0.320074    0.490988   -0.488703    -0.135841    -0.307241
  0.0497136    0.0897663    0.162541     -0.0670594    0.110713    -0.238824     0.0247272   -0.0760943    0.28881      0.108143    -0.192515    -0.162152     0.24172      0.0861989  -0.463697    0.253962    0.275071    -0.106975    0.18388    -0.524145   -0.231808   -0.241876   -0.135829   -0.160259    -0.0430571   -0.216231
  0.0487955   -0.144273    -0.150807      0.303951     0.3449      -0.0964291    0.672907    -0.175322    -0.0974306   -0.430592     0.62182      0.562508    -0.20679      0.455495   -0.210702    0.0185759   0.0151199   -0.0226908   0.0888906  -1.15515     0.0171138  -0.100835   -0.40427     0.0222841   -0.545771     0.448269
  0.062436     1.31093      0.397093      0.118962    -0.281946     0.661841     0.582351     0.381392     0.926321     0.403058    -0.242179    -0.17001     -0.624848     0.709714   -0.0452524  -0.371268    0.159814     0.168855   -0.133528    0.0829029  -0.086061    0.430712   -0.507158   -0.627235    -0.669598    -0.174965
  0.139046    -0.477531    -0.301903     -0.294918     0.099098    -0.293132    -0.211458    -0.204084    -0.26413     -0.677358    -0.0217935    0.0773928   -0.51563     -0.533603   -0.268212   -0.54799     0.145094     0.240373   -0.0696252  -0.0929104   0.396414    0.105727   -0.60811     0.49493      0.27678     -0.371998
  0.115385     0.553069     0.699518     -0.700251    -0.124707     0.141157    -0.0148632    0.261335    -0.655275    -0.221535     0.00862048   0.644787    -0.574307    -0.0653906  -0.0447524   0.0826412   0.213148     0.326481   -0.0377762   0.331805    0.0887613   0.6845     -0.547945    0.730697     0.369148    -0.33358
 -0.568295     0.077313    -0.0799574     0.0796432   -0.451715    -0.334154    -0.862395    -0.0936792    0.394286     0.0795595    0.400576     0.725238     0.182068     0.0536573  -0.284379    0.102334   -0.119426     0.225644   -0.386103   -0.0850115  -0.139301    0.131867   -0.580856   -0.180746     0.186727    -0.113163
  0.269955    -0.456373     0.200315     -0.402683     0.0920258    0.0971465    0.0148287   -0.185476    -0.53914      0.498137    -0.122336    -0.00818501   0.464455     0.21443     0.44228     0.0789378   0.0447756    0.13874    -0.140926    0.38639     0.693118    0.27916    -0.398086    0.0193356   -0.134065    -0.401912
  0.847375    -0.11384      0.000394476   0.0363957   -0.259769    -0.412206    -0.174535    -0.423207    -0.37022      0.375008     0.444129     0.493192     0.214313     0.471008   -0.180109    0.340442   -0.357727    -0.239977   -0.229149   -0.614283   -0.353354   -0.0658801  -0.477548    0.32899      0.406233    -0.356301
  0.229128    -0.731538    -0.119158      0.423603    -0.310524     0.0294321    0.769194     0.554352    -0.128406     0.580885     0.0406223   -0.595401    -0.0333302   -0.0608833   0.0130612  -0.878322   -0.344042    -0.0298335  -0.0663727  -0.102344   -0.124318   -0.0682088  -0.173328   -0.281491     0.125648    -0.075058
 -0.10161      0.00293474  -0.054214      0.203292     0.123255    -0.0778834    0.0182291    0.265042     0.169531    -0.222769    -0.209136    -0.122386    -0.0747731   -0.213728    0.146186   -0.161117   -0.0300628    0.0896062   0.0822731  -0.0136642  -0.19756    -0.28915     0.293544   -0.0484627    0.132873     0.0883211
  0.481888     0.623251     0.384416     -0.103088     0.343292     0.00196192  -0.0277988   -0.427838     0.307212     0.58151     -0.511401    -0.765056     0.280624    -0.349429   -0.214165   -0.0586022   0.629933    -0.36154    -0.325066   -0.266977   -0.216614    0.301634    0.316014    0.62262     -0.223172    -0.312361
  0.202899     0.0128486   -0.3415        0.264757     0.220595     0.351598     0.391453     0.647902    -0.128663    -0.580757    -0.0519798   -0.307541    -0.557269    -0.299281   -0.431439   -0.0499844  -0.53747      0.0660083  -0.0822209  -0.117586   -0.350727   -0.26487    -0.485681    0.279085     0.0865935    0.0408747
 -0.00656222   0.07612      0.155223      0.0574085    0.00811041  -0.132754    -0.11905      0.395324    -0.0857874   -0.163578    -0.172427    -0.293675     0.260566    -0.328774    0.342788    0.225489    0.062792    -0.150367   -0.0480054   0.231107    0.0258614  -0.088242    0.071452    0.0721698    0.469506    -0.00695779
  0.120278    -0.276155     0.0866292    -0.262682     0.150719    -0.431123    -0.0655431    0.418682    -0.246582     0.731807     0.0649418   -0.0658029   -0.0864781    0.535398   -0.235904   -0.67792     0.217547    -0.428131   -0.051898   -0.8115      0.636789   -0.728469   -0.52718    -0.00846407   0.00531204   0.0283015
  0.0468885   -0.069384    -0.0840336     0.00070466  -0.0984549    0.0628344    0.0941702   -0.0461085   -0.00809649   0.0424483    0.0908959    0.130299    -0.0766821    0.111554   -0.0544953  -0.137204   -0.10181      0.0770764  -0.0223263   0.01691     0.0234728   0.0396586  -0.0985422  -0.0775072   -0.0691824   -0.0216229
 -0.0185845   -0.885138     0.018877     -0.563001    -0.935405     0.244861     0.0943927   -0.184271     0.377826    -0.406707    -0.103995    -0.21455     -0.554969    -0.237387   -0.648268    0.271244   -0.113295    -0.289527   -0.799378   -0.158039    0.290925    0.177729   -0.192307    0.0502806    0.594769     0.302889
 -0.180779    -0.343008     0.248102      0.3846       0.164745     0.309342     0.613836    -0.0431187    0.184434     0.621444     0.654449    -0.177591     0.492725     0.58228    -0.112532   -0.177177    0.0635992   -0.127358    0.349993   -0.0179972   0.211058    0.0453945   0.11985    -0.176955    -0.719743     0.177348
  0.0774618    0.764882    -0.0473939    -0.0298747    0.0262487    0.306277    -0.180173    -0.426114     0.0777755   -0.296103     0.20163      0.270512    -5.02139e-5  -0.217121    0.214501    0.570726    0.0294118    0.0141486  -0.25858     0.342858   -0.475016    0.581729    0.408285    0.0642822   -0.04419     -0.17707
  0.0321053   -0.334728     0.356874      0.468779     0.119286    -0.0424975   -0.136906    -0.477215    -0.00849352  -0.267388     0.131336    -0.0109914   -0.387179     0.393409    0.0519986   0.147798   -0.285697    -0.364042   -0.0754799   0.184408   -0.313595   -0.224725    0.348411    0.25646     -0.108145    -0.331101
 -0.339892    -0.32403     -0.37733       0.0769823   -0.290086     0.156939    -0.160128     0.415833    -0.160093    -0.538358     0.361369     0.637674    -0.240874     0.205563    0.390251   -0.0327351  -0.639346     0.505457    0.133842    0.281815    0.263925   -0.269002   -0.448564   -0.569012     0.156361     0.0583842
  0.229094     0.47605     -0.114501     -0.141535    -0.263418    -0.0147611   -0.775207     0.206953     0.659425     0.136394    -0.588986    -0.439538    -0.105188    -0.528843   -0.286649    0.181363   -0.115924     0.0427651  -0.363354    0.711108   -0.200113   -0.248439    0.123069   -0.194681     1.07464     -0.337296
 -0.610271    -0.603858     0.0456764     0.319283    -0.230259    -1.01283     -0.229346    -0.0756231   -0.28088     -0.468053     0.492678     0.248838     0.66848     -0.80875     0.249911    0.544335    0.134474    -0.493886   -0.291969    0.037918   -0.0741727  -0.309014    0.300441    0.12349      0.726184     0.0300385[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407603
[ Info: iteration 2, average log likelihood -1.407590
[ Info: iteration 3, average log likelihood -1.407578
[ Info: iteration 4, average log likelihood -1.407566
[ Info: iteration 5, average log likelihood -1.407554
[ Info: iteration 6, average log likelihood -1.407543
[ Info: iteration 7, average log likelihood -1.407532
[ Info: iteration 8, average log likelihood -1.407521
[ Info: iteration 9, average log likelihood -1.407511
[ Info: iteration 10, average log likelihood -1.407501
┌ Info: EM with 100000 data points 10 iterations avll -1.407501
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
