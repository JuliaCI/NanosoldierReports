Julia Version 1.3.2-pre.0
Commit 2e6715c045 (2019-12-31 00:49 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed GaussianMixtures ─── v0.3.0
 Installed Blosc ────────────── v0.5.1
 Installed CMake ────────────── v1.1.2
 Installed StatsFuns ────────── v0.9.3
 Installed SpecialFunctions ─── v0.9.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Parameters ───────── v0.12.0
 Installed URIParser ────────── v0.4.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed PDMats ───────────── v0.9.10
 Installed BinaryProvider ───── v0.5.8
 Installed BinDeps ──────────── v1.0.0
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.22.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed StaticArrays ─────── v0.12.1
 Installed Arpack ───────────── v0.4.0
 Installed FillArrays ───────── v0.8.2
 Installed Clustering ───────── v0.13.3
 Installed FileIO ───────────── v1.2.1
 Installed LegacyStrings ────── v0.4.1
 Installed Rmath ────────────── v0.6.0
 Installed DataStructures ───── v0.17.7
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed StatsBase ────────── v0.32.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed QuadGK ───────────── v2.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed Distances ────────── v0.8.2
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_IEoqOZ/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.7
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -2.9717045509291384e6, [99904.87054031987, 95.12945968012578], [503.65378936901885 -569.6008590711567 435.353212417216; 46.12692384342771 254.59790115983213 14.46776116774965], Array{Float64,2}[[99810.54372030818 -116.55864060792922 613.732451639057; -116.55864060792922 99191.25500972809 -142.83218880096757; 613.732451639057 -142.83218880096757 99594.34193467721], [69.40318644018666 114.36911367895256 27.32962260835756; 114.36911367895257 689.5474453794584 16.23385578857274; 27.32962260835756 16.233855788572743 66.29477411084913]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.044185e+03
      1       9.512051e+02      -9.297973e+01 |        4
      2       9.382757e+02      -1.292948e+01 |        2
      3       9.377786e+02      -4.970938e-01 |        0
      4       9.377786e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 937.7785660287145)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.071331
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.832893
[ Info: iteration 2, lowerbound -3.716929
[ Info: iteration 3, lowerbound -3.597054
[ Info: iteration 4, lowerbound -3.455985
[ Info: iteration 5, lowerbound -3.304582
[ Info: iteration 6, lowerbound -3.162249
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.037216
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.936232
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.865776
[ Info: iteration 10, lowerbound -2.826870
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.802117
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.784206
[ Info: iteration 13, lowerbound -2.765734
[ Info: iteration 14, lowerbound -2.745189
[ Info: iteration 15, lowerbound -2.717362
[ Info: iteration 16, lowerbound -2.681481
[ Info: iteration 17, lowerbound -2.638025
[ Info: iteration 18, lowerbound -2.589081
[ Info: iteration 19, lowerbound -2.538111
[ Info: iteration 20, lowerbound -2.488975
[ Info: iteration 21, lowerbound -2.444520
[ Info: iteration 22, lowerbound -2.405641
[ Info: iteration 23, lowerbound -2.371604
[ Info: iteration 24, lowerbound -2.341954
[ Info: iteration 25, lowerbound -2.319112
[ Info: iteration 26, lowerbound -2.307990
[ Info: dropping number of Gaussions to 2
[ Info: iteration 27, lowerbound -2.303051
[ Info: iteration 28, lowerbound -2.299262
[ Info: iteration 29, lowerbound -2.299257
[ Info: iteration 30, lowerbound -2.299255
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan  9 23:39:03 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan  9 23:39:10 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Jan  9 23:39:12 2020: EM with 272 data points 0 iterations avll -2.071331
5.8 data points per parameter
, Thu Jan  9 23:39:13 2020: GMM converted to Variational GMM
, Thu Jan  9 23:39:22 2020: iteration 1, lowerbound -3.832893
, Thu Jan  9 23:39:22 2020: iteration 2, lowerbound -3.716929
, Thu Jan  9 23:39:22 2020: iteration 3, lowerbound -3.597054
, Thu Jan  9 23:39:22 2020: iteration 4, lowerbound -3.455985
, Thu Jan  9 23:39:22 2020: iteration 5, lowerbound -3.304582
, Thu Jan  9 23:39:23 2020: iteration 6, lowerbound -3.162249
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 7
, Thu Jan  9 23:39:23 2020: iteration 7, lowerbound -3.037216
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 6
, Thu Jan  9 23:39:23 2020: iteration 8, lowerbound -2.936232
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 5
, Thu Jan  9 23:39:23 2020: iteration 9, lowerbound -2.865776
, Thu Jan  9 23:39:23 2020: iteration 10, lowerbound -2.826870
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 4
, Thu Jan  9 23:39:23 2020: iteration 11, lowerbound -2.802117
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 3
, Thu Jan  9 23:39:23 2020: iteration 12, lowerbound -2.784206
, Thu Jan  9 23:39:23 2020: iteration 13, lowerbound -2.765734
, Thu Jan  9 23:39:23 2020: iteration 14, lowerbound -2.745189
, Thu Jan  9 23:39:23 2020: iteration 15, lowerbound -2.717362
, Thu Jan  9 23:39:23 2020: iteration 16, lowerbound -2.681481
, Thu Jan  9 23:39:23 2020: iteration 17, lowerbound -2.638025
, Thu Jan  9 23:39:23 2020: iteration 18, lowerbound -2.589081
, Thu Jan  9 23:39:23 2020: iteration 19, lowerbound -2.538111
, Thu Jan  9 23:39:23 2020: iteration 20, lowerbound -2.488975
, Thu Jan  9 23:39:23 2020: iteration 21, lowerbound -2.444520
, Thu Jan  9 23:39:23 2020: iteration 22, lowerbound -2.405641
, Thu Jan  9 23:39:23 2020: iteration 23, lowerbound -2.371604
, Thu Jan  9 23:39:23 2020: iteration 24, lowerbound -2.341954
, Thu Jan  9 23:39:23 2020: iteration 25, lowerbound -2.319112
, Thu Jan  9 23:39:23 2020: iteration 26, lowerbound -2.307990
, Thu Jan  9 23:39:23 2020: dropping number of Gaussions to 2
, Thu Jan  9 23:39:23 2020: iteration 27, lowerbound -2.303051
, Thu Jan  9 23:39:23 2020: iteration 28, lowerbound -2.299262
, Thu Jan  9 23:39:23 2020: iteration 29, lowerbound -2.299257
, Thu Jan  9 23:39:23 2020: iteration 30, lowerbound -2.299255
, Thu Jan  9 23:39:23 2020: iteration 31, lowerbound -2.299254
, Thu Jan  9 23:39:23 2020: iteration 32, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 33, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 34, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 35, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 36, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 37, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 38, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 39, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 40, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 41, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 42, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 43, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 44, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 45, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 46, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 47, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 48, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 49, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: iteration 50, lowerbound -2.299253
, Thu Jan  9 23:39:23 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777377118, 178.0450922262289]
β = [95.95490777377118, 178.0450922262289]
m = [2.0002292577735665 53.8519871724519; 4.250300733268165 79.28686694433614]
ν = [97.95490777377118, 180.0450922262289]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611978457 -0.008953123827381372; 0.0 0.012748664777418506], [0.18404155547460566 -0.007644049042350031; 0.0 0.008581705166300843]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -1.003058978801462
avll from llpg:  -1.0030589788014619
avll direct:     -1.0030589788014619
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.98564993168748
avll from llpg:  -0.9856499316874798
avll direct:     -0.9856499316874798
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0689742    0.0613895    0.0945955   -0.0544065    0.097105     0.21923      -0.0455829   -0.076226    -0.111818     0.0257974    0.0167896    0.146901     0.0128468   -0.0044437    0.00422974   0.145677    -0.00851837  -0.00986064   0.01237     -0.0670365     0.0688624    0.0517176   -0.0929378    0.0396846    -0.0756126     0.0835389 
 -0.102504    -0.142137    -0.0526387    0.175239     0.0754552    0.0336969     0.00141725   0.23568     -0.0271983    0.0879517   -0.0824646   -0.0269084   -0.0187093    0.022079    -0.0247558    0.0846119    0.203409    -0.048275     0.0607286   -0.0630295     0.0192511    0.0594387   -0.0620119    0.0709088     0.0208484     0.0279952 
  0.0511431    0.0267414    0.0338705   -0.0574385    0.00603453   0.0438447     0.027666     0.183522     0.124324     0.0247929   -0.109202    -0.171323    -0.1731      -0.00463363  -0.167773     0.0564812    0.0817075   -0.0152721    0.082609     0.00105629   -0.139533    -0.0350082    0.0229714   -0.109215     -0.0305782    -0.00560889
  0.0242648    0.00634472   0.0623335    0.0687297    0.0971646   -0.00852607   -0.00104979   0.0530283   -0.111935     0.0751259    0.0758571    0.0138478   -0.102189     0.0439184    0.0754937    0.0624508   -0.0784422   -0.0302241   -0.0295768    0.0812349    -0.0336122   -0.0195668    0.108323     0.0500423     0.104623      0.0308692 
  0.149052     0.0868295   -0.0717762   -0.0975768   -0.0403577    0.00388233   -0.0534951   -0.149018     0.0202826    0.0287118    0.00526891   0.00959763   0.0584633    0.245271     0.0405044   -0.12523     -0.065028    -0.0116729    0.0707424    0.164809      0.058278     0.140652    -0.09098     -0.00483304   -0.0129559    -0.170757  
 -0.123365     0.0707854   -0.162615    -0.111231    -0.0966742    0.144944      0.0744271   -0.173676     0.0026973   -0.0608118   -0.00999487  -0.0833294    0.120065    -0.0287426    0.118706    -0.0433429    0.0149878   -0.0129898    0.105165    -0.0182063    -0.154951     0.0441935   -0.110466     0.0880772    -0.000933395  -0.0659908 
 -0.0889569   -0.066369    -0.202895     0.0120375   -0.0863197    0.113904      0.00139084   0.0762668   -0.0422456    0.0128046    0.0396179    0.0987142    0.0946703    0.184921    -0.0589538   -0.150081    -0.0552104   -0.129115    -0.221841    -0.126245      0.104814    -0.0142318   -0.257307    -0.0290366     0.108344     -0.0926538 
 -0.0386444    0.0504974   -0.0223283    0.0451261    0.0227267   -0.0313897     0.11423      0.0412345   -0.245477    -0.0784575    0.0771699    0.0853006    0.0149988   -0.0775169   -0.00377183   0.0185998   -0.114747    -0.108732     0.0507537   -0.0785452     0.0111739    0.0660392    0.0552322   -0.099806      0.0782747     0.130262  
  0.0475968    0.130004     0.132614    -0.0228269    0.0445755    0.0871476    -0.0116191   -0.1418      -0.0504342    0.0587701   -0.0957584    0.09542     -0.0756438    0.158284    -0.0153784   -0.097726     0.206011    -0.0032602   -0.00487301   0.077754      0.184738     0.0029377   -0.0310105    0.0376504    -0.0295643    -0.0398178 
  0.0424082    0.0635375   -0.118114    -0.0270599    0.0119572   -0.0562484    -0.0741684    0.076019     0.0341588    0.00954235   0.0728483    0.141877     0.132367     0.101306    -0.0256595    0.0246417    0.018148     0.0467903    0.125581    -0.0764526    -0.101864     0.238614    -0.0449616    0.0551204    -0.252111      0.163036  
 -0.090876    -0.0152397    0.0423589    0.0559497    0.0398626    0.0167988    -0.0599435   -0.0233311    0.172582     0.172964     0.0178639   -0.00653986   0.0205248    0.0539775    0.0487301   -0.0266678    0.0258721   -0.0741323   -0.0729633   -0.0291456     0.0863956    0.0792081    0.0593868    0.0230152     0.0733718     0.02474   
 -0.0388878    0.10262     -0.0328733    0.130952    -0.231938    -0.0267703    -0.0653822   -0.014659     0.0142097   -0.0574392    0.0237955    0.0969059   -0.0332961    0.169435     0.0394777   -0.00293712  -0.0488368   -0.103796    -0.0679838    0.000287118  -0.138734     0.00946974  -0.0490478   -0.261972      0.127862      0.041588  
 -0.0887108   -0.119078     0.139607     0.0269169    0.0242117   -0.0907523    -0.110422     0.110284     0.0836628   -0.0830932   -0.186657    -0.0805678    0.111885     0.109711     0.0517276    0.00730659  -0.082355     0.112633    -0.080732     0.025854      0.0105575   -0.0508994    0.180421     0.00422762   -0.0866533     0.135421  
 -0.0806764   -0.0136188    0.00184648  -0.0153109   -0.174524    -0.0338972     0.0321162    0.0219856    0.0484497   -0.033992    -0.0134705    0.0371748   -0.121416    -0.177358     0.161381    -0.091061    -0.0761457   -0.0677474    0.0373356    0.00329639   -0.171828    -0.00686488  -0.129502     0.0410133     0.0242251     0.0740937 
 -0.0140952    0.173654    -0.0321625    0.047071     0.095477    -0.187928      0.0386431   -0.0669728    0.0150579    0.0980885    0.0303604   -0.0453786   -0.155211    -0.0565874    0.0541027   -0.208575     0.0362987    0.0404692    0.0870741    0.169429      0.124657     0.0308775   -0.014438     0.0715309     0.0588136    -0.0933543 
  0.111773    -0.167983     0.0188924    0.0861558    0.010558     0.0783739     0.0232688    0.0861267    0.0370891    0.0077696    0.0478409    0.0567858    0.0930448   -0.0937726   -0.0393569    0.0432911    0.0417958   -0.0560802   -0.00558655   0.119277     -0.0934078    0.0410237    0.00934635  -0.258446      0.0473491     0.0236523 
  0.0902447    0.152954     0.108993    -0.083283     0.0523372   -0.127252      0.0318776    0.134954    -0.00580324  -0.105473     0.207899    -0.15373     -0.0903993   -0.0760266    0.023845     0.163336    -0.0233991    0.12384      0.0834786    0.0677011    -0.00433895   0.185282    -0.11883     -0.0530557     0.0322161     0.0506227 
  0.0542726    0.0685107   -0.0543776    0.0342254    0.120968     0.0118693     0.155115     0.0457235   -0.0597281    0.140671     0.0563793   -0.00152325   0.122504    -0.183151     0.107144    -0.00174877  -0.0635603   -0.187567     0.14539      0.168932      0.0695385   -0.0988052   -0.0487054   -0.0867504    -0.120302      0.0864174 
  0.0940804    0.0627919    0.050108    -0.00868809   0.0769896    0.0287529    -0.0266679    0.169125    -0.0808082    0.0686072   -0.139466     0.124262     0.127448    -0.0386013    0.0117002   -0.1621      -0.0419442    0.0503564    0.0536983   -0.145573      0.00763677  -0.0255776    0.0897723   -0.0979792     0.0230667    -0.189052  
  0.0250899    0.0451127    0.118545    -0.0979266   -0.0565185    0.169951      0.0171335    0.110135    -0.0265223   -0.04836      0.0942519   -0.105584     0.035849     0.087663    -0.0757765    0.062797    -0.0635812    0.0167058    0.0859326   -0.142381      0.0143876    0.166385    -0.14088     -0.0366187    -0.125061     -0.0349838 
  0.0574001    0.0154194    0.204314    -0.261976     0.0801221   -0.0157042     0.110777    -0.219011    -0.0426423   -0.0202799    0.0841946   -0.0151861    0.00110984   0.180729    -0.151154    -0.0106002   -0.130943     0.0564867   -0.182979    -0.0536541     0.00848468  -0.106583     0.0012614    0.0722188     0.0952574     0.0223714 
 -0.19175     -0.0158987    0.170542     0.0592936   -0.0403503    0.0873941    -0.150346    -0.0615639    0.222947    -0.117019     0.0582394    0.0519602   -0.0901457   -0.0183514    0.0118873   -0.114027     0.105549    -0.00841723   0.0475939    0.0535573     0.0891908    0.0661209    0.0883831    0.0266528    -0.0102679    -0.0681151 
 -0.169466     0.164825     0.0088339   -0.102898    -0.0596736    0.0744184     0.0282771   -0.148448     0.0756072   -0.10305      0.179893    -0.0746415   -0.0610291   -0.150683    -0.200242     0.0311934    0.134868    -0.0342926    0.178489     0.0637625     0.00992478  -0.0739432   -0.028264    -0.000523719  -0.00484855    0.00381193
 -0.0526767   -0.0370956   -0.0351481   -0.100763     0.0675393    0.0661635    -0.120694    -0.0230809    0.101208    -0.105819     0.0877086    0.074639     0.0913913   -0.213325    -0.011706     0.00734209  -0.0859301   -0.180617    -0.0304619    0.00679214    0.0390095   -0.120657     0.0484702   -0.190627     -0.160932     -0.103863  
  0.0958909    0.00572391  -0.106677     0.0927693    0.169366     0.0839379    -0.0376534    0.0404431    0.102184     0.0545518    0.208296     0.00367321  -0.111109     0.145835    -0.125515     0.00334402  -0.0374465   -0.0228008   -0.00623969   0.0777824     0.145583    -0.0167533    0.097586    -0.0352126     0.099876     -0.094802  
  0.021299    -0.0603809   -0.119294     0.045132    -0.0670604   -0.000914978  -0.00960169   0.0480891    0.0817994    0.156873     0.301097    -0.0365915   -0.20474      0.122183     0.109323     0.080571    -0.018777     0.0343127    0.124632     0.0666678    -0.00562932  -0.0668921   -0.00820761   0.138663      0.094672      0.0876093 
  0.0139383    0.0343087    0.0504934    0.0653895   -0.00769803   0.081958     -0.146601     0.0729291    0.121516     0.0102218    0.0498042    0.0927099    0.0114207   -0.0328429   -0.24421     -0.034987    -0.00143501   0.0755129   -0.153962     0.00600657    0.134484     0.034169     0.00236528   0.0544269     0.0233704     0.0214832 
 -0.0020806   -0.158382    -0.162149    -0.0327517   -0.0467466    0.112995      0.00724665  -0.0456139    0.170535    -0.0608855    0.0198935   -0.0983148    0.10108     -0.0680793   -0.146801     0.0460314   -0.0195096    0.0763281   -0.00745905   0.0119243    -0.0250696    0.0460297   -0.0158912    0.0411097     0.0280282     0.113963  
  0.00291315   0.0668536   -0.017783    -0.131166    -0.0122082   -0.0330306    -0.0500828   -0.00680705   0.0060291    0.06768     -0.204329     0.0460866   -0.110604     0.0511033    0.0322725    0.05137      0.00276198  -0.0120712   -0.16129      0.193943      0.292308     0.051183     0.118477     0.0623955     0.0351658     0.0343476 
  0.0669398    0.1471      -0.00593759  -0.0494406    0.323718    -0.139659      0.0855479   -0.0879345   -0.134149     0.184101     0.0769994   -0.0116343    0.0612917    0.201374     0.0548361    0.0471122   -0.093991     0.0415572    0.0554791    0.0604017    -0.12091     -0.0924202    0.170782    -0.038378     -0.0453654    -0.132639  
  0.101505     0.0713018   -0.14493      0.0204133   -0.150148     0.024608      0.0641769    0.11665     -0.00126209  -0.116326     0.16301      0.252139    -0.206579    -0.011177    -0.125993     0.108978     0.143763    -0.196785    -0.0719368   -0.0622729     0.035371     0.0304724   -0.011371     0.0989155     0.000936217   0.153461  
  0.0640637   -0.0180388   -0.0170176   -0.028662     0.0614174    0.121693      0.0345299    0.0608017    0.0612948   -0.0378914   -0.0122057    0.108785     0.133647    -0.075066    -0.0112645   -0.168579     0.0630572   -0.27656      0.0297864   -0.126373     -0.157786     0.0441121   -0.0644648    0.131106      0.142522      0.0654144 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4308981221729395
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.431017
[ Info: iteration 2, average log likelihood -1.430916
[ Info: iteration 3, average log likelihood -1.430337
[ Info: iteration 4, average log likelihood -1.424372
[ Info: iteration 5, average log likelihood -1.408262
[ Info: iteration 6, average log likelihood -1.400557
[ Info: iteration 7, average log likelihood -1.398223
[ Info: iteration 8, average log likelihood -1.397133
[ Info: iteration 9, average log likelihood -1.396627
[ Info: iteration 10, average log likelihood -1.396370
[ Info: iteration 11, average log likelihood -1.396230
[ Info: iteration 12, average log likelihood -1.396150
[ Info: iteration 13, average log likelihood -1.396098
[ Info: iteration 14, average log likelihood -1.396063
[ Info: iteration 15, average log likelihood -1.396037
[ Info: iteration 16, average log likelihood -1.396016
[ Info: iteration 17, average log likelihood -1.396000
[ Info: iteration 18, average log likelihood -1.395987
[ Info: iteration 19, average log likelihood -1.395975
[ Info: iteration 20, average log likelihood -1.395966
[ Info: iteration 21, average log likelihood -1.395957
[ Info: iteration 22, average log likelihood -1.395949
[ Info: iteration 23, average log likelihood -1.395941
[ Info: iteration 24, average log likelihood -1.395934
[ Info: iteration 25, average log likelihood -1.395927
[ Info: iteration 26, average log likelihood -1.395921
[ Info: iteration 27, average log likelihood -1.395914
[ Info: iteration 28, average log likelihood -1.395908
[ Info: iteration 29, average log likelihood -1.395901
[ Info: iteration 30, average log likelihood -1.395895
[ Info: iteration 31, average log likelihood -1.395889
[ Info: iteration 32, average log likelihood -1.395883
[ Info: iteration 33, average log likelihood -1.395877
[ Info: iteration 34, average log likelihood -1.395871
[ Info: iteration 35, average log likelihood -1.395866
[ Info: iteration 36, average log likelihood -1.395861
[ Info: iteration 37, average log likelihood -1.395856
[ Info: iteration 38, average log likelihood -1.395851
[ Info: iteration 39, average log likelihood -1.395847
[ Info: iteration 40, average log likelihood -1.395843
[ Info: iteration 41, average log likelihood -1.395839
[ Info: iteration 42, average log likelihood -1.395836
[ Info: iteration 43, average log likelihood -1.395832
[ Info: iteration 44, average log likelihood -1.395829
[ Info: iteration 45, average log likelihood -1.395826
[ Info: iteration 46, average log likelihood -1.395823
[ Info: iteration 47, average log likelihood -1.395820
[ Info: iteration 48, average log likelihood -1.395818
[ Info: iteration 49, average log likelihood -1.395815
[ Info: iteration 50, average log likelihood -1.395812
┌ Info: EM with 100000 data points 50 iterations avll -1.395812
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4310171362747883
│     -1.4309157766168585
│      ⋮                 
└     -1.395812195762503 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395971
[ Info: iteration 2, average log likelihood -1.395836
[ Info: iteration 3, average log likelihood -1.395543
[ Info: iteration 4, average log likelihood -1.392682
[ Info: iteration 5, average log likelihood -1.380259
[ Info: iteration 6, average log likelihood -1.366224
[ Info: iteration 7, average log likelihood -1.360729
[ Info: iteration 8, average log likelihood -1.358395
[ Info: iteration 9, average log likelihood -1.356888
[ Info: iteration 10, average log likelihood -1.355728
[ Info: iteration 11, average log likelihood -1.354752
[ Info: iteration 12, average log likelihood -1.353993
[ Info: iteration 13, average log likelihood -1.353444
[ Info: iteration 14, average log likelihood -1.353029
[ Info: iteration 15, average log likelihood -1.352719
[ Info: iteration 16, average log likelihood -1.352480
[ Info: iteration 17, average log likelihood -1.352299
[ Info: iteration 18, average log likelihood -1.352164
[ Info: iteration 19, average log likelihood -1.352062
[ Info: iteration 20, average log likelihood -1.351983
[ Info: iteration 21, average log likelihood -1.351918
[ Info: iteration 22, average log likelihood -1.351862
[ Info: iteration 23, average log likelihood -1.351813
[ Info: iteration 24, average log likelihood -1.351770
[ Info: iteration 25, average log likelihood -1.351731
[ Info: iteration 26, average log likelihood -1.351693
[ Info: iteration 27, average log likelihood -1.351654
[ Info: iteration 28, average log likelihood -1.351616
[ Info: iteration 29, average log likelihood -1.351581
[ Info: iteration 30, average log likelihood -1.351551
[ Info: iteration 31, average log likelihood -1.351527
[ Info: iteration 32, average log likelihood -1.351506
[ Info: iteration 33, average log likelihood -1.351489
[ Info: iteration 34, average log likelihood -1.351475
[ Info: iteration 35, average log likelihood -1.351462
[ Info: iteration 36, average log likelihood -1.351452
[ Info: iteration 37, average log likelihood -1.351442
[ Info: iteration 38, average log likelihood -1.351433
[ Info: iteration 39, average log likelihood -1.351424
[ Info: iteration 40, average log likelihood -1.351416
[ Info: iteration 41, average log likelihood -1.351407
[ Info: iteration 42, average log likelihood -1.351399
[ Info: iteration 43, average log likelihood -1.351390
[ Info: iteration 44, average log likelihood -1.351380
[ Info: iteration 45, average log likelihood -1.351370
[ Info: iteration 46, average log likelihood -1.351358
[ Info: iteration 47, average log likelihood -1.351345
[ Info: iteration 48, average log likelihood -1.351331
[ Info: iteration 49, average log likelihood -1.351315
[ Info: iteration 50, average log likelihood -1.351299
┌ Info: EM with 100000 data points 50 iterations avll -1.351299
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3959708155934254
│     -1.3958360638324367
│      ⋮                 
└     -1.3512988885878585
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.351486
[ Info: iteration 2, average log likelihood -1.351262
[ Info: iteration 3, average log likelihood -1.350567
[ Info: iteration 4, average log likelihood -1.344248
[ Info: iteration 5, average log likelihood -1.324609
[ Info: iteration 6, average log likelihood -1.310125
[ Info: iteration 7, average log likelihood -1.303588
[ Info: iteration 8, average log likelihood -1.299650
[ Info: iteration 9, average log likelihood -1.296373
[ Info: iteration 10, average log likelihood -1.293325
[ Info: iteration 11, average log likelihood -1.290668
[ Info: iteration 12, average log likelihood -1.288436
[ Info: iteration 13, average log likelihood -1.286658
[ Info: iteration 14, average log likelihood -1.285341
[ Info: iteration 15, average log likelihood -1.284538
[ Info: iteration 16, average log likelihood -1.284050
[ Info: iteration 17, average log likelihood -1.283612
[ Info: iteration 18, average log likelihood -1.283141
[ Info: iteration 19, average log likelihood -1.282629
[ Info: iteration 20, average log likelihood -1.282106
[ Info: iteration 21, average log likelihood -1.281627
[ Info: iteration 22, average log likelihood -1.281241
[ Info: iteration 23, average log likelihood -1.280968
[ Info: iteration 24, average log likelihood -1.280789
[ Info: iteration 25, average log likelihood -1.280670
[ Info: iteration 26, average log likelihood -1.280589
[ Info: iteration 27, average log likelihood -1.280530
[ Info: iteration 28, average log likelihood -1.280486
[ Info: iteration 29, average log likelihood -1.280452
[ Info: iteration 30, average log likelihood -1.280423
[ Info: iteration 31, average log likelihood -1.280397
[ Info: iteration 32, average log likelihood -1.280376
[ Info: iteration 33, average log likelihood -1.280357
[ Info: iteration 34, average log likelihood -1.280343
[ Info: iteration 35, average log likelihood -1.280331
[ Info: iteration 36, average log likelihood -1.280322
[ Info: iteration 37, average log likelihood -1.280314
[ Info: iteration 38, average log likelihood -1.280308
[ Info: iteration 39, average log likelihood -1.280303
[ Info: iteration 40, average log likelihood -1.280298
[ Info: iteration 41, average log likelihood -1.280295
[ Info: iteration 42, average log likelihood -1.280291
[ Info: iteration 43, average log likelihood -1.280288
[ Info: iteration 44, average log likelihood -1.280286
[ Info: iteration 45, average log likelihood -1.280283
[ Info: iteration 46, average log likelihood -1.280281
[ Info: iteration 47, average log likelihood -1.280278
[ Info: iteration 48, average log likelihood -1.280276
[ Info: iteration 49, average log likelihood -1.280273
[ Info: iteration 50, average log likelihood -1.280269
┌ Info: EM with 100000 data points 50 iterations avll -1.280269
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3514858827446963
│     -1.3512616133098938
│      ⋮                 
└     -1.2802694495558695
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.280531
[ Info: iteration 2, average log likelihood -1.280262
[ Info: iteration 3, average log likelihood -1.279505
[ Info: iteration 4, average log likelihood -1.271237
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.243362
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.228000
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.235353
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.225898
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.217785
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.226500
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.227566
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.216928
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.223307
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.215639
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.218896
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.224501
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.225638
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.214701
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.220534
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.212710
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.207023
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.216636
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.227366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.213218
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.219566
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.211816
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.205979
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.216423
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.218609
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.208171
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.215265
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.216543
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.207143
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.217306
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.219417
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.218378
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.219235
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.209305
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.201967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.209881
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.227082
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.224552
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.215158
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.224466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.225331
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.214300
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.220579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.222132
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.211024
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.219195
┌ Info: EM with 100000 data points 50 iterations avll -1.219195
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2805305292798177
│     -1.2802622714587493
│      ⋮                 
└     -1.2191945483087467
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.221258
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.208545
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.209149
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│     12
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.199483
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.179646
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.135866
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     20
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.136008
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.124677
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.126173
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.111087
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123878
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.108835
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│     22
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.128277
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.109421
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.108971
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     10
│     12
│     13
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.122001
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.126988
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097918
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.123757
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.112671
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.120495
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.116717
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.113949
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.106966
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.137307
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.106758
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.108010
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│     12
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.124139
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.127232
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.101358
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.125795
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│     12
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.112419
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.118938
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.110374
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.126323
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.093673
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.137053
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│     12
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.112178
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.114561
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.107810
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.128131
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.103518
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     25
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.132376
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.099127
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.100279
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     10
│     13
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.110505
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.111894
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.085708
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.111812
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│     10
│     13
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.097951
┌ Info: EM with 100000 data points 50 iterations avll -1.097951
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2212582716980043
│     -1.2085448058170007
│      ⋮                 
└     -1.0979506421367795
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4308981221729395
│     -1.4310171362747883
│     -1.4309157766168585
│     -1.4303371756028147
│      ⋮                 
│     -1.0857082953482522
│     -1.1118115638064707
└     -1.0979506421367795
32×26 Array{Float64,2}:
 -0.0391141    0.0541984    0.013295    -0.184122     0.00395654   0.0737007    0.0754991   -0.161801   -0.0301562   -0.0308004    0.0333128   -0.0504497    0.0802103    0.0684773   -0.010136    -0.0438659    -0.0597352    0.0350715   -0.0289558   -0.0458852   -0.0616117    -0.0295057   -0.0468328    0.0719061   0.0441982   -0.028491  
  0.0561162    0.0808305   -0.00101342  -0.0775602    0.0164267    0.00625345  -0.0572705    0.0570986  -0.0287284    0.0553773   -0.164217     0.0672084    0.0247127    0.0126839    0.0277197   -0.0608421    -0.0267874    0.0130337   -0.0705618    0.0560335    0.14042       0.0193296    0.111407    -0.0073623   0.0290893   -0.0706648 
 -0.0717574    0.0629397    0.0493397    0.016024     0.0307425   -0.0307872   -0.0591106   -0.039175    0.131745    -0.0141694    0.0277896    0.0188173   -0.0677295   -0.0416222    0.0281955   -0.15933       0.0707176   -0.00432557   0.0733059    0.0765349    0.0668015     0.0207812    0.0432521    0.0874319   0.058441    -0.0818821 
  0.0630002    0.148292     0.0325548   -0.0424556    0.316327    -0.132448     0.0910223   -0.086006   -0.13515      0.181761     0.154814    -0.011684     0.0804859    0.210806     0.0431392    0.0478004    -0.0918898    0.0602495    0.0588448    0.0688581   -0.129831     -0.0843427    0.171867    -0.0322161  -0.0418604   -0.131042  
  0.110259     0.151703     0.107639    -0.0841133    0.00699432  -0.120542    -0.0460757    0.107513   -0.0414013   -0.122775     0.21439     -0.139142    -0.0995233   -0.0760831    0.0202478    0.157654     -0.0217625    0.123347     0.0811341    0.0647852   -0.0059028     0.22089     -0.135394    -0.0515473   0.0409695    0.0368014 
  0.0590039    0.011841     0.00816451  -0.103471     0.00495424   0.0557312    0.0575469    0.188419    0.135717     0.0226477   -0.103602    -0.156779    -0.140456     0.00671045  -0.16483      0.0507468     0.0887301   -0.0155601    0.103856    -0.0130238   -0.134501     -0.0253025    0.007057    -0.105753   -0.0511351   -0.00776335
  0.11829      0.0661776   -0.140251     0.0145968   -0.127144     0.0352329    0.0837757    0.104517    0.0207279   -0.109076     0.161237     0.242158    -0.231297     0.0098182   -0.125734     0.10642       0.140147    -0.229729    -0.0661386   -0.0599449    0.0288627     0.0345773   -0.016852     0.11648     0.0350199    0.148047  
  0.0343562   -0.0599124   -0.119474     0.0597951   -0.0923657    0.0243337    0.0141655    0.0373577   0.0794691    0.157432     0.321808    -0.0427716   -0.204152     0.12748      0.105929     0.0750698    -0.00630028   0.034404     0.0983189    0.0817555   -0.00474947   -0.0721481    0.00216221   0.13303     0.0913038    0.0855249 
 -0.0902437   -0.0335575    0.0103159   -0.0163799   -0.188689    -0.046313     0.0485112    0.0126389   0.0675215   -0.0582605   -0.0108436    0.0235308   -0.117978    -0.183911     0.148858    -0.0869605    -0.0755056   -0.0674348    0.0384755    0.00525556  -0.18752      -0.0586285   -0.141616     0.0395038   0.0313032    0.0729853 
  0.0242592    0.0340603    0.120892    -0.0990247   -0.0459079    0.168415     0.0200799    0.101835   -0.0239605   -0.0338549    0.0938698   -0.0958873    0.0037463    0.0665412   -0.0764713    0.0586744    -0.0900174    0.0189321    0.0863926   -0.137679     0.0301569     0.163053    -0.156118    -0.0313716  -0.125889    -0.0412653 
 -0.0298776    0.0523131    0.043849     0.0910314    0.0428477   -0.0433091    0.128859     0.0270283  -0.161512    -0.0940116    0.0743842    0.125402     0.0201633   -0.809092     0.0523335   -0.0128041    -0.114558    -0.0959567    0.0357083    0.276209     0.173304      0.0946691    0.0162321   -0.203373    0.151649     0.134475  
 -0.0221991    0.0334791   -0.121764    -0.00335682  -0.00839687  -0.0179423    0.105878     0.0814503  -0.245061    -0.0717883    0.0693086    0.0759264    0.0206044    0.819084    -0.0186551    0.0249572    -0.0868796   -0.154833     0.103134    -0.451912    -0.0852468     0.0773879    0.0414183    0.0317478  -0.00478913   0.121149  
  0.146258     0.0889461   -0.0798499   -0.112935    -0.0373104    0.00305804  -0.0660143   -0.164405    0.00681112   0.0200004    0.00574468   0.0164527    0.00699816   0.224027     0.0215993   -0.133407     -0.0638645   -0.0129445    0.0703991    0.151357     0.0650582     0.139067    -0.0879349   -0.0220866  -0.0376883   -0.138908  
  0.112677    -0.165005     0.0296563    0.0887719   -0.0273721    0.0787728    0.0273975    0.0638631   0.0313719    1.69407e-5   0.0470516    0.0395801    0.0924641   -0.0872505   -0.0438486    0.0465018     0.029973    -0.0622129   -0.0312861    0.120229    -0.0908654     0.039619     0.0113388   -0.256364    0.0341405    0.0647837 
  0.0880919    0.0721162    0.154328    -0.0361645    0.0770497    0.141085    -0.0323335   -0.105291   -0.085705     0.032235    -0.036447     0.109072    -0.0417316    0.0667898   -0.00749351   0.0181099     0.0903971   -0.00259442   0.0081369    0.00212367   0.132476      0.0272736   -0.0683474    0.0398087  -0.0394467    0.0302486 
 -0.0505481   -0.0886411   -0.0745281    0.0055048   -0.035289     0.0962333   -0.0188514    0.0195509   0.0915273    0.0293253    0.0210393    0.00364997   0.0953309    0.0457427   -0.0492346   -0.0539216    -0.0186655   -0.0512      -0.0953725   -0.0620017    0.0669797     0.0335032   -0.0757306    0.008255    0.0597086    0.0214755 
 -0.0657363   -0.0701075   -0.00763529  -0.0862666    0.0638599    0.0675327   -0.147022    -0.0529284   0.119777    -0.114125     0.0766823    0.0601344   -0.031261    -0.273172     0.114491    -0.0595556     0.0837061   -0.162605    -0.00597975   0.0254473    0.0855659    -0.117187     0.0618814   -0.201146   -0.626421    -0.118747  
 -0.0341433    0.04923     -0.0674676   -0.117038    -0.0663375    0.0665128   -0.105882    -0.0165243   0.0829213   -0.0707228    0.0812668    0.0480802    0.167476    -0.140199    -0.18583      0.0988777    -0.221241    -0.172084    -0.0624912   -0.0293459   -0.0406821    -0.11392      0.0413334   -0.179319    0.193211    -0.137848  
  0.0510632    0.0689662   -0.0484009    0.0449899    0.124985     0.00762894   0.151383     0.0565463  -0.071019     0.146432     0.0568763   -0.0139958    0.127754    -0.18294      0.117065     0.00222966   -0.0529751   -0.231099     0.146414     0.20801      0.0705668    -0.111341    -0.0665592   -0.0865904  -0.0912421    0.0824084 
  0.072412    -0.0442155   -0.0323128   -0.0377057    0.0731452    0.116259     0.0420855    0.0426358   0.0805301   -0.0219447   -0.0411936    0.084434     0.11192     -0.0808149   -0.0180297   -0.148082      0.104639    -0.271389     0.0442019   -0.102936    -0.133789      0.0547709   -0.0306805    0.150401    0.109661     0.070258  
 -0.0853587   -0.125259     0.134256     0.0293457   -0.0125984   -0.0877649   -0.10076      0.107681    0.0865925   -0.0720622   -0.199038    -0.0800328    0.10108      0.125264     0.0351795    0.0064145    -0.095098     0.111742    -0.0690414    0.00310132   0.0160814    -0.0395091    0.170052    -0.0157536  -0.0867021    0.14757   
  0.0520677    0.0682031   -0.11518     -0.0246249    0.0290351   -0.0597374   -0.0640288    0.0717384   0.0283283    0.00903097   0.0635553    0.138656     0.133689     0.0989896   -0.0547445   -0.000806596   0.0156094    0.0441573    0.150875    -0.0844404   -0.0992682     0.250095    -0.0688233    0.0540136  -0.22986      0.146257  
 -0.0933931   -0.121593    -0.0541187    0.176564     0.0657035    0.0442338    0.0273326    0.227904   -0.0130244    0.0861786   -0.100034    -0.0083663   -0.0249784    0.0164136    0.0393906    0.070876      0.172584    -0.0412844    0.0582806   -0.103244     0.000236667   0.0893387   -0.0667167    0.0674608   0.0221599    0.0294712 
  0.0971055    0.00763661  -0.114581     0.0933044    0.19743      0.0884397   -0.0521217    0.0593254   0.101736     0.0595448    0.210687     0.00446714  -0.105138     0.140667    -0.114992    -0.00606213   -0.016676    -0.00209239  -0.0115447    0.0715548    0.111592     -0.0271145    0.0969782   -0.0629447   0.0811696   -0.0930627 
  0.00944631   0.0520368    0.0817695    0.0672114    0.0404693    0.0748146   -0.147083     0.33037     0.214662    -0.180051     0.128254     0.68268      0.0169224    0.0386388   -0.263212    -1.37198      -0.292853     0.435476    -0.187618     0.0166904    0.137232      0.0309578    0.00107527   0.017106    0.00789076   0.0924725 
  0.0380326    0.0425414    0.133985     0.0616736    0.0723581    0.295293    -0.149853    -0.0283942   0.196418    -0.0486663   -0.0348388    0.429283     0.0235843    0.0891237   -0.286536     0.470046      0.0764005   -0.311027    -0.158783     0.0965479   -0.00680537    0.160462    -0.00355933   0.0371954   0.0266416    0.151053  
  0.0183911    0.0362359    0.0613394    0.0638333   -0.0355746    0.11555     -0.15153      0.150579   -0.0613345    0.0601854   -0.358831    -0.324273     0.0120344   -0.221389    -0.137357    -0.206684      0.197027     0.0252079   -0.151374    -0.116886     0.206902     -0.0638322    0.00377032  -0.0121048   0.0351939   -0.21764   
 -0.00753141   0.0192445   -0.0375684    0.0617455   -0.0197728   -0.191256    -0.132886    -0.0829655  -0.0056985    0.166484     0.258787     0.113195     0.00307037   0.0139178   -0.344762     0.718183      0.0641598    0.232361    -0.137377     0.00687284   0.183226      0.0607858    0.00831563   0.125168    0.0216388    0.262184  
  0.0402694   -0.0175853    0.062803     0.0680406    0.108134    -0.0137937   -0.00402306   0.0499906  -0.100359     0.0785757    0.0742891    0.0328577   -0.0915092    0.0402047    0.0899448    0.0425518    -0.0689585   -0.0731677   -0.0181256    0.0750276   -0.0358896    -0.018754     0.0987003    0.0515578   0.108436     0.0248365 
 -0.0191959    0.0990601   -0.0658273    0.113857    -0.225864    -0.0245929   -0.0742192   -0.0300989  -0.0196136   -0.0691359    0.0716053    0.0950989   -0.0264498    0.187159     0.0377182   -0.0349419    -0.0686628   -0.102558    -0.066569     0.0175816   -0.13743      -0.00870693  -0.0510305   -0.233103    0.116953     0.0387142 
 -0.149104     0.164841    -0.0107607   -0.087938    -0.0781395    0.0820404   -0.018124    -0.153616    0.177205    -0.135628     0.387062    -0.0491949   -0.0641922   -0.120609    -0.180148    -0.697153      0.142017    -0.0511488    0.106338    -0.00605308   0.00899485   -0.0261273    0.839137     0.0129281  -0.00389208   0.148204  
 -0.150369     0.190156     0.00244692  -0.133288    -0.0426016    0.0795375    0.132898    -0.13779     0.0120932   -0.0824224   -0.0622273   -0.0647199   -0.0205565   -0.255302    -0.251285     0.920778      0.137965    -0.0234339    0.220441     0.065865     0.00875645   -0.122634    -0.861708    -0.0225352  -0.0154292   -0.0464779 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.107358
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.075087
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.092539
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.083385
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.098844
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.069624
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     22
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.106879
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.075751
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     19
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.093186
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      8
│     10
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083371
┌ Info: EM with 100000 data points 10 iterations avll -1.083371
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.046917e+05
      1       7.031668e+05      -2.015248e+05 |       32
      2       6.754947e+05      -2.767211e+04 |       32
      3       6.614596e+05      -1.403517e+04 |       32
      4       6.527024e+05      -8.757158e+03 |       32
      5       6.468275e+05      -5.874900e+03 |       32
      6       6.418694e+05      -4.958077e+03 |       32
      7       6.374380e+05      -4.431410e+03 |       32
      8       6.340166e+05      -3.421396e+03 |       32
      9       6.315008e+05      -2.515782e+03 |       32
     10       6.297302e+05      -1.770628e+03 |       32
     11       6.283680e+05      -1.362188e+03 |       32
     12       6.274142e+05      -9.538420e+02 |       32
     13       6.268378e+05      -5.764273e+02 |       32
     14       6.264401e+05      -3.976340e+02 |       32
     15       6.261250e+05      -3.150980e+02 |       32
     16       6.258603e+05      -2.646969e+02 |       32
     17       6.255733e+05      -2.869935e+02 |       32
     18       6.252779e+05      -2.954251e+02 |       32
     19       6.249908e+05      -2.871287e+02 |       32
     20       6.246930e+05      -2.978188e+02 |       32
     21       6.245184e+05      -1.745207e+02 |       32
     22       6.244293e+05      -8.910831e+01 |       32
     23       6.243883e+05      -4.104527e+01 |       32
     24       6.243737e+05      -1.459313e+01 |       28
     25       6.243645e+05      -9.188478e+00 |       27
     26       6.243581e+05      -6.372018e+00 |       28
     27       6.243543e+05      -3.824435e+00 |       25
     28       6.243506e+05      -3.729368e+00 |       25
     29       6.243477e+05      -2.913161e+00 |       25
     30       6.243452e+05      -2.500881e+00 |       18
     31       6.243437e+05      -1.504900e+00 |       18
     32       6.243422e+05      -1.432057e+00 |       16
     33       6.243415e+05      -7.194830e-01 |       10
     34       6.243411e+05      -4.440937e-01 |       14
     35       6.243405e+05      -5.480383e-01 |       13
     36       6.243400e+05      -5.240780e-01 |        8
     37       6.243398e+05      -1.978882e-01 |        7
     38       6.243396e+05      -1.437105e-01 |        4
     39       6.243396e+05      -9.138045e-02 |        2
     40       6.243395e+05      -2.019475e-02 |        0
     41       6.243395e+05       0.000000e+00 |        0
K-means converged with 41 iterations (objv = 624339.5337502599)
┌ Info: K-means with 32000 data points using 41 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.338293
[ Info: iteration 2, average log likelihood -1.308324
[ Info: iteration 3, average log likelihood -1.277382
[ Info: iteration 4, average log likelihood -1.245483
[ Info: iteration 5, average log likelihood -1.205008
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.159425
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.157184
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.119245
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│      9
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.105054
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.122705
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.111251
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.126804
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.118155
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.098994
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.123820
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.113008
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.098728
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087000
[ Info: iteration 19, average log likelihood -1.148014
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.102406
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      9
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.073807
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      6
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.107845
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.121288
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.119152
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.101096
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      6
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.103177
[ Info: iteration 27, average log likelihood -1.124128
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.078245
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.108490
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     4
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.124660
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.107188
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.095064
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     14
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.079681
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     11
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.119482
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.126180
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.103359
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.101562
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.091267
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.108285
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.117352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.115337
[ Info: iteration 42, average log likelihood -1.124095
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.068117
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     11
│     13
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.093746
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.139047
[ Info: iteration 46, average log likelihood -1.138120
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.089073
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     16
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051913
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     19
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.133146
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.157933
┌ Info: EM with 100000 data points 50 iterations avll -1.157933
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0606533   -0.0625589   -0.0131898   -0.0210969    0.0740368    0.118611     0.0462441     0.054759     0.0560877   -0.0305018    -0.0223896    0.110871      0.127113    -0.079101     0.000570859  -0.15276      0.100422    -0.365784      0.0252264   -0.134464    -0.139515      0.146144    -0.0771648    0.144576     0.197133      0.111118 
 -0.0409958   -0.00905784  -0.0401751   -0.094954     0.0132275    0.0665291   -0.115342     -0.0246481    0.0956733   -0.0748759     0.078367     0.0458981     0.0679689   -0.201796    -0.0135485     0.0147327   -0.0480939   -0.170454     -0.0220869    0.00690277   0.0220067    -0.117351     0.0456676   -0.186573    -0.246141     -0.106615 
 -0.138765     0.183823     0.0205448   -0.114621    -0.0430314    0.0672833    0.0572858    -0.148999     0.154668    -0.137947      0.215131    -0.0575059    -0.0698605   -0.175415    -0.252907      0.219287     0.118463    -0.0192213     0.512899     0.0447881   -0.00142134   -0.0582877    0.134345    -0.00282615  -0.0177807     0.0601539
 -0.0930499    0.0580737    0.0468493    0.0526654    0.00875323  -0.0256669   -0.0847443    -0.0629765    0.15031     -0.024334      0.0490894    0.00271067   -0.0988539   -0.0213441    0.0222363    -0.137786     0.0680621    0.0427724     0.0865175    0.100532     0.100183      0.0293429    0.0712947    0.0850084    0.00856859   -0.0789009
 -0.0761857    0.0282509   -0.123204    -0.0403141   -0.0763733    0.0809849    0.00319774   -0.0681945   -0.0655674    0.0210658     0.00270194   0.0176436     0.132461     0.0233696   -0.0622397    -0.296485     0.0426316   -0.0501142    -0.685715    -0.0509503    0.0163915     0.00859581  -0.30861     -0.0102615    0.0105404     0.028834 
  0.00990977   0.0326997   -0.0671051    0.0378962    0.0723547    0.0158464    0.14754       0.0980492   -0.0542098    0.103971      0.0627529   -0.00798768    0.119104    -0.137795     0.103791     -0.00843571  -0.0353275   -0.177052      0.167761     0.180232     0.0329131    -0.0592823   -0.110189    -0.0643506   -0.173603      0.0910111
 -0.0602973    0.0633811   -0.551677     0.165094    -0.208727    -0.00323776  -0.0971996    -0.0936827   -0.0574962   -0.0818054     0.191216     0.108494     -0.0448588    0.108169     0.0269907    -0.0758252   -0.047219    -0.118578     -0.0469192    0.0619116   -0.151563     -0.0376015   -0.109548    -0.223541     0.0909596    -0.0501144
  0.0125409    0.117894     0.187414     0.0755873   -0.24535     -0.0377784   -0.0707405    -0.00669812   0.0150539   -0.0500376     0.034081     0.0809492    -0.0243412    0.231594     0.0475357     0.00348384  -0.0884474   -0.0660272    -0.0787732    0.0129318   -0.124267      0.00966371  -0.0201406   -0.227675     0.118942      0.0891576
  0.0373928    0.0927331   -0.0191407   -0.101548    -0.0357799   -0.0356619   -0.0608915    -0.00729285   0.00716262   0.0416818    -0.182288     0.027554     -0.0679459    0.0586591    0.0322247     0.0391588   -0.0089697   -0.0203386    -0.154759     0.198053     0.271867      0.0523402    0.117155     0.068927     0.0349792     0.022473 
 -0.0886888   -0.113115    -0.0568389    0.176053     0.0720587    0.0423539    0.0339388     0.228396    -0.0175864    0.088786     -0.0882328   -0.0118512    -0.0301561    0.0147328    0.0473706     0.0669073    0.172081    -0.0646581     0.0602257   -0.0885098    0.000241195   0.0755529   -0.0637907    0.0619389    0.0257111     0.0312869
  0.0130418   -0.043948    -0.137656     0.122732    -0.119808     0.0128441    0.00784496    0.0461024    0.0744776    0.211688      0.563451    -0.0414161    -0.198425     0.126707     0.0954229     0.073528     0.0390565    0.0261789     0.23878      0.109406    -0.00973322   -0.0794362    0.0088105    0.120498     0.106267      0.0809419
  0.0767854    0.0574907    0.0454235   -0.0569224    0.0787312    0.0588036   -0.0439613     0.160321    -0.0873176    0.0626879    -0.131861     0.105196      0.130096    -0.0495266    0.016152     -0.173586    -0.0432919    0.0583562     0.0596719   -0.137794     0.00118623   -0.0329293    0.0919316   -0.0984123    0.02152      -0.193272 
  0.0125034    0.0052884   -0.158706    -0.00132428  -0.0575738    0.0669448   -0.0144903     0.0395373   -0.0302615    0.014087      0.0115643    0.0678822     0.209893     0.241373    -0.0554902    -0.162712    -0.0495484   -0.0563065    -0.27442     -0.0612182    0.10913       0.0760529   -0.231807    -0.0217998    0.081649     -0.101197 
  0.0116014    0.0323168    0.116053    -0.0780023   -0.0496191    0.146525     0.00852712    0.105202    -0.017078    -0.0197903     0.0783273   -0.101815      0.0211418    0.152596    -0.0619783     0.0484854   -0.0871847   -0.00151912    0.0812508   -0.148149     0.0136969     0.135795    -0.171592    -0.0313653   -0.116805     -0.0274671
 -0.0896774   -0.0348247    0.00997297  -0.0164463   -0.181499    -0.0460228    0.0510723     0.0112051    0.0673521   -0.0563342    -0.010456     0.0197837    -0.119559    -0.181974     0.149755     -0.0856981   -0.0754436   -0.0674841     0.0380561    0.00447958  -0.190143     -0.0539358   -0.142338     0.0399377    0.0306466     0.072135 
  0.0967042    0.0240881    0.181755    -0.0710475    0.0909378    0.190907    -0.0217465    -0.052469    -0.119275     0.0219495     0.0429665    0.141958     -0.0323828   -0.118045    -0.0380892     0.106085    -0.0214168   -0.00569822    0.0381143   -0.104715     0.0618667     0.0802875   -0.130321     0.0333072   -0.105181      0.0631652
  0.109029     0.118387     0.159257    -0.0205547    0.0454533    0.0798021   -0.0157418    -0.136022    -0.0560729    0.05033      -0.085825     0.0894211    -0.0961309    0.177093    -0.0155413    -0.0954212    0.187069     0.0051574     0.00414425   0.0843772    0.185533      0.00512708  -0.0425212    0.0369675   -0.0107077    -0.0359146
  0.112023    -0.154169     0.0188383    0.0795396   -0.0273369    0.0792626    0.0245259     0.0613549    0.0267145    0.000369894   0.0464145    0.0417373     0.0943783   -0.0792735   -0.0443166     0.0474345    0.0245265   -0.0613285    -0.02879      0.120021    -0.0841212     0.0431522    0.00907997  -0.247924     0.0387338     0.0598884
  0.049656     0.0682314   -0.141415    -0.0139015    0.0254459   -0.0310699   -0.0276211     0.115301    -0.00471405   0.0309074     0.0645889    0.139243      0.145262     0.0522536   -0.0577257     0.0441431    0.00258597   0.0435787     0.183952    -0.0856561   -0.0748505     0.215248    -0.0684267    0.0237015   -0.353525      0.190182 
  0.01062     -0.0986508   -0.0315388    0.00335686   0.0336024    0.052057     0.000452556   0.0136271    0.0263204   -0.0152073     0.0448446   -0.0293098     0.0114928   -0.00981532  -0.0156684     0.0387726   -0.0467589   -0.0149295     0.0083037    0.031565    -0.0279846     0.0111122    0.0502326    0.0454991    0.0636768     0.0651303
  0.022481     0.0196697    0.200745    -0.254523     0.0852384    0.0195888    0.0924494    -0.20562     -0.0483878   -0.0070494     0.0917191   -0.0169622     0.00314868   0.17855     -0.150352     -0.0110053   -0.144833     0.0730094    -0.176212    -0.0463794   -0.000992672  -0.0914039   -0.00637804   0.0593755    0.0915701     0.0202665
 -0.0378255   -0.00282549   0.0609455    0.0584237    0.0286442    0.0152968   -0.0790351    -0.00193563   0.17485      0.173189      0.0232417    0.0298393     0.0238085    0.0418848    0.0432785    -0.0311871    0.0161749   -0.091741     -0.103817    -0.0294694    0.111639      0.0716045    0.0350266    0.014777     0.0761345     0.0197614
  0.0130269    0.0358781    0.0507899    0.0637438    0.0069339    0.05922     -0.147018      0.0852603    0.0622951    0.0181996    -0.0174106    0.155883      0.0116728   -0.0375387   -0.256158     -0.031144     0.0399372    0.097455     -0.157685    -0.00855364   0.1456        0.0317684    0.00420103   0.0428761    0.0198349     0.0570066
  0.0838382    0.0692298    0.0419674   -0.0840821   -0.00401737  -0.0247398    0.0037272     0.145858     0.0524026   -0.0409504     0.0718448   -0.141895     -0.125583    -0.0278435   -0.0614498     0.103357     0.0324434    0.0517121     0.0929003    0.0321723   -0.0662998     0.0889498   -0.0614437   -0.0632639    0.000903756   0.0192483
 -0.0617121   -0.112407     0.103431     0.04395     -0.0340137   -0.0755907   -0.0811178     0.0835003    0.0856864   -0.0419898    -0.140143    -0.0712846     0.0427322    0.123782     0.0493866     0.00851027  -0.0899068    0.0970533    -0.0675505    0.0153433    0.0134087    -0.0444587    0.14229      0.0108371   -0.0513605     0.134371 
  0.0372001    0.154698    -0.0363305   -0.00728508   0.0842364   -0.0218154    0.0762847     0.0032076    0.00104702   0.0797596     0.0438392   -0.000739784   0.0096522   -0.0800331    0.0484058    -0.180285     0.0337291   -0.0462306     0.101828     0.120345    -0.0362253    -0.17394      0.0259807    0.0875903    0.0514552    -0.0642773
  0.0689854    0.0209932   -0.109715     0.0803584    0.194495     0.0669336   -0.0307491     0.0870516    0.0859143    0.0595135     0.168134     0.00384089   -0.0834767    0.104606    -0.10666       0.00517932  -0.0604117    0.000208059  -0.00733197   0.086941     0.117648     -0.0219702    0.0830379   -0.0828863    0.110509     -0.0774295
  0.0639531    0.147331     0.0286614   -0.042511     0.316814    -0.132134     0.0904915    -0.0877552   -0.135264     0.181288      0.153988    -0.0115025     0.0816054    0.208089     0.0446599     0.0471289   -0.0932925    0.0581027     0.0588557    0.0690904   -0.132353     -0.0833663    0.172518    -0.0314974   -0.0398209    -0.13018  
 -0.023792     0.0388707   -0.0691279    0.0168703    0.0385888    0.00451633   0.0858785     0.0109633   -0.22361     -0.0521533     0.0587788    0.128155      0.0415239   -0.00570786   0.0311197     0.0350143   -0.0755435   -0.0869311     0.0644887   -0.0790129    0.0885153     0.0709638    0.0104078   -0.0661014    0.051906      0.153633 
 -0.0984829    0.0688072   -0.163824    -0.119126    -0.0755425    0.112318     0.0584429    -0.148993     0.0153297   -0.0267449     0.039073    -0.0804862     0.0729075    0.0171127    0.126591     -0.0265062    0.00944211   0.0100078     0.118371    -0.0224986   -0.102389      0.00723838  -0.0900186    0.108729     0.00194996   -0.0385893
  0.113833     0.0729029   -0.0929636   -0.126392    -0.0300177   -0.0110669   -0.0587086    -0.197299     0.00516718   0.0225017     0.0172957    0.0305002    -0.0316268    0.173994     0.0620692    -0.117326    -0.0541615   -0.0156672     0.173335     0.166402     0.0354255     0.144606    -0.098219    -0.00801983  -0.12477      -0.157861 
  0.117606     0.0664347   -0.141041     0.0160815   -0.127334     0.035474     0.0795363     0.104895     0.0217208   -0.10112       0.159816     0.232778     -0.228431     0.00763918  -0.125456      0.106271     0.137146    -0.232004     -0.0650184   -0.0579517    0.0309033     0.0336265   -0.0171624    0.112172     0.0425154     0.147672 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.132234
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.086641
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.069770
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     11
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.091793
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│      9
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072435
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     14
│     16
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072620
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.091028
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     11
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062981
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│     14
│     16
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070596
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.092786
┌ Info: EM with 100000 data points 10 iterations avll -1.092786
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0690213    0.140665    -0.101329    -0.0123745    -0.0403764    0.0267422   -0.108312     -0.0425264   -0.114057      0.0944607    -0.03059     -0.0532983     0.0383691   -0.124656    -0.0268286    0.0332812   -0.070235     0.0360927     0.0496428    0.0364417    0.0799958   0.0869754     0.177828     -0.0805694   -0.00323091   0.0318835 
  0.0276511    0.0186232   -0.0126828    0.0675289     0.206047     0.027621    -0.0496071     0.168988    -0.000669595   0.0692408    -0.145097     0.0165122     0.0280691    0.122        0.00401608   0.0662054    0.138534    -0.277335     -0.161279     0.228742    -0.0138606   0.0895337    -0.140296      0.0739107   -0.0196799    0.0688889 
 -0.0146225   -0.0141867   -0.0328873   -0.047949     -0.0307516    0.0859294    0.189163      0.0795214    0.00935517    0.119048     -0.0299596    0.0436536     0.169908    -0.0552123    0.00730088   0.181608     0.0903661   -0.00598282   -0.00112025  -0.127317    -0.163892    0.111355      0.0815786    -0.134711     0.112234    -0.131582  
 -0.0377781   -0.118599     0.106714     0.0471515     0.183255    -0.0801526    0.0931391     0.0405784    0.144583      0.127038     -0.0700331   -0.139297     -0.146059    -0.0142344    0.0382476    0.026819    -0.0109268   -0.0300275     0.145848    -0.0259257   -0.106333    0.0638628    -0.0334878    -0.078129     0.0245667    0.14675   
 -0.05704      0.00561239   0.017991    -0.0933547    -0.108392    -0.0438334    0.0828785     0.104592     0.0543116     0.114809      0.07732      0.0720936     0.207789    -0.0778772   -0.0136436   -0.176778     0.100765    -0.141432     -0.073348     0.113112     0.0110643  -0.0603736    -0.0829636     0.120982    -0.0769216   -0.192701  
 -0.0339955    0.106533    -0.0988685   -0.0256604     0.0133575    0.0273781    0.0921922    -0.0259536   -0.199411      0.0132274     0.00419584   0.160641      0.0754658    0.00347542   0.0444637    0.108442     0.069081    -0.0179953     0.114547    -0.151729    -0.0720837   0.118061     -0.0153622    -0.136807     0.0274528    0.219724  
 -0.00875655   0.0669196    0.0416566    0.0808115     0.0779226    0.0104987   -0.03173       0.0952893   -0.0699623     0.171679     -0.0717016   -0.0686706     0.0155674   -0.0510671    0.0286784    0.117241     0.214919     0.0907669    -0.0943391   -0.126567    -0.17214     0.205004      0.054247     -0.0726401   -0.0846616    0.155106  
  0.0120583    0.00273571   0.0335456    0.030858      0.0954648   -0.174949    -0.0347946    -0.173837     0.133678     -0.0697015     0.0796824    0.0444607    -0.0514441   -0.0910078    0.0333323   -0.00120839  -0.0675392    0.0340232    -0.0452058   -0.0704045    0.0123432   0.0289457     0.0708044    -0.0943329   -0.0244749   -0.0500637 
 -0.0949887   -0.0611222   -0.0939036    0.00706428    0.0382333   -0.100413    -0.0441807    -0.0234121   -0.146174     -0.0130316    -0.0798818    0.110819      0.0162135   -0.0242814   -0.170353     0.105033    -0.12753      0.101719     -0.0530506   -0.0124656    0.0665232  -0.0845995     0.00412906   -0.0240422   -0.116542    -0.127423  
 -0.101042    -0.00315044   0.126678     0.0367329     0.191732     0.10181      0.0755        0.0549973    0.137304     -0.0181023     0.0250755    0.108164      0.100771    -0.214626    -0.188377     0.0124627    0.116385     0.0649707     0.040865     0.150449    -0.0566806   0.0490741    -0.029571     -0.104969    -0.0888388   -0.0774973 
  0.102816    -0.102538    -0.168571    -0.0627492    -0.0557922    0.0361362   -0.0661092    -0.063531     0.122281     -0.0274807     0.139916     0.00542651   -0.0984714   -0.0598665   -0.0271646    0.0552939   -0.00238609  -0.000804785  -0.0502501   -0.0412939   -0.146204    0.0872634     0.00612805    0.0301104    0.0929331   -0.0777279 
  0.00601326  -0.0681106    0.00821177   0.134349     -0.096544     0.126338    -0.123358      0.0086964   -0.0792731     0.0161807     0.0160459    0.0993169     0.0550224    0.104493    -0.120706     0.117704    -0.0750792    0.115049     -0.0233093    0.143466    -0.0215177  -0.0895113     0.0862432     0.0669544    0.0755235   -0.0234723 
  0.0153893   -0.266095    -0.0372083    0.1279       -0.0438506    0.01286      0.0928149     0.0970346    0.0402947     0.043606     -0.119742    -0.0322852    -0.0730741    0.112525    -0.17431     -0.0816268   -0.059112     0.153693     -0.0158444    0.0434119    0.0355718   0.121723     -0.0379433     0.169015     0.00337458   0.0537823 
 -0.00758027  -0.0481522    0.0485445    0.0868595     0.207896    -0.142446     0.028428      0.129746    -0.279761     -0.0161041     0.011156     0.0865168     0.0124037   -0.0363824    0.0464374    0.0687385   -0.103536     0.159986     -0.00418875  -0.00613823  -0.110466   -0.0421996     0.0399291     0.139815     0.00107235   0.0563421 
 -0.19323      0.109598     0.0351541    0.0907425    -0.0932098    0.00215273  -0.122728      0.0599689    0.0157213     0.131963      0.0215912   -0.00320629   -0.0618853   -0.127121    -0.084713     0.0131903    0.106734    -0.116975     -0.198761     0.104869     0.0906268  -0.0795048    -0.104224      0.0606363    0.0672568    0.1684    
 -0.100238     0.200009     0.0978232    0.124311      0.0217866   -0.0705886    0.126077      0.0693601    0.100781     -0.0138816    -0.101274     0.0100725    -0.0364848   -0.0228207    0.00617058  -0.0116132    0.0544722    0.00931063    0.068977    -0.0239184    0.011363    0.018233      0.0599377    -0.176983     0.0580218    0.180172  
 -0.0136196    0.0292587    0.0353644    0.0656188     0.0128578    0.0299566    0.206318      0.00161672  -0.146038     -0.000608343   0.0520693    0.0066356    -0.0620196   -0.180223    -0.259684    -0.139063     0.029559    -0.0160113    -0.0421552    0.196347     0.0877328   0.0899975    -0.162429     -0.035006    -0.0686087    0.0619186 
 -0.06284      0.150745     0.0961557    0.0910657    -0.0342193    0.240166     0.0820944     0.0251409    0.0584344     0.127445     -0.258414     0.00116752   -0.072846     0.205231    -0.152844     0.0326952   -0.044203    -0.0531934    -0.0266794    0.0589479    0.0800851  -0.00045563    0.0139456    -0.0964613    0.0776763    0.128417  
 -0.056823     0.0965977   -0.0595621   -0.128109     -0.0308441    0.120866    -0.141342     -0.15755      0.290226     -0.0426555     0.114299     0.0696336     0.114715    -0.034383    -0.0608941   -0.095833    -0.0860078    0.0749726     0.0685418   -0.125891     0.0102701   0.0967368     0.0218285     0.0813205    0.181288     0.0230116 
 -0.0113953   -0.0742038    0.144747    -0.22309      -0.168401    -0.0652086   -0.0711446     0.147409    -0.133495      0.0800852     0.0319816    0.0914035     0.136854    -0.15083      0.0929274   -0.0886459   -0.058662     0.0303575     0.192033     0.0356714    0.1644      0.00209247   -0.0445451    -0.0349885    0.136101    -0.0803738 
  0.0794599   -0.138359     0.0947361   -0.164825     -0.0796787   -0.0334838    0.000840788   0.0526852    0.07946       0.15321       0.0523743    0.0818869     0.0356509   -0.194342    -0.0918215    0.0525806   -0.0204617   -0.0291866    -0.0289849   -0.0877834    0.0288375  -0.045511      0.239485     -0.0864645   -0.025949     0.0288914 
  0.0533022    0.142375    -0.0444761    0.0168846     0.0785504    0.0459196   -0.0342122     0.0474074   -0.0938325    -0.0447173    -0.146323    -0.103562     -0.0564378   -0.128721    -0.0786334   -0.115581    -0.00843941   0.0119004     0.0206802    0.03986     -0.0122556   0.20698       0.0305237     0.180543     0.0488112   -0.0192543 
  0.0323709   -0.018928     0.0119952    0.0273551    -0.0158371    0.13318      0.0834121     0.0648267    0.0804041     0.0154069    -0.154622     0.0650468    -0.0889039   -0.11379     -0.160023    -0.167744     0.0633379   -0.00302376    0.0505188    0.0617244    0.104071   -0.0973551     0.0471726     0.10032     -0.113112    -0.0271478 
  0.0239711    0.00214203   0.076074     0.0344683     0.0332462   -0.00842453  -0.0282583    -0.180229    -0.20437      -0.0318332     0.0341032    0.0748251     0.11415     -0.0770133   -0.0650986   -0.0362809   -0.0828377    0.0959827    -0.17376     -0.0352071    0.0557851  -0.00399091   -0.0332729    -0.0378404   -0.0031528   -0.0580992 
  0.0607889    0.145307    -0.102382     0.141171     -0.00662198  -0.138022    -0.0627852    -0.0384748    0.105458      0.130638     -0.107025    -0.0857249     0.173815     0.0448137    0.117887    -0.0450751   -0.149239    -0.00293035   -0.0451879   -0.0479838   -0.0468579   0.00516601    0.0279726    -0.00270374   0.0587667    0.17558   
 -0.0281287    0.0648172   -0.0717707   -0.0288407     0.0934154    0.0247311    0.00371158    0.00870409   0.109232      0.0423815    -0.109797    -0.251812     -0.146312    -0.227283    -0.106545     0.0543291    0.0398783   -0.0249465    -0.259389    -0.0706118   -0.0104828   0.000821587   0.295615     -0.0603565    0.130499    -0.122478  
  0.0187987    0.0283009   -0.137399    -0.0245214    -0.140626    -0.181923     0.0560047    -0.0335139    0.143088     -0.0805062     0.0166262   -0.000587255   0.036031     0.138907     0.156616    -0.109131    -0.00575107   0.0369295     0.0599094    0.0299159   -0.074807    0.148768     -0.196985     -0.064473    -0.100805     0.116873  
  0.0187222    0.0300904    0.0625301   -0.0965162    -0.12857      0.179554    -0.00274828    0.0464691    0.181638     -0.0204301     0.0120376    0.102624     -0.183368     0.118723     0.0886513   -0.0804685   -0.0302334    0.0698942    -0.133692     0.16298      0.0448984  -0.00274905    0.0865992     0.00572341  -0.0272422   -0.0531746 
 -0.191759     0.109041    -0.0712278   -0.0738617    -0.0348046   -0.131001     0.0804007    -0.0104197    0.112884      0.209177      0.103354    -0.0820376    -0.0214628   -0.0632       0.0726441    0.15786      0.0227096   -0.101266     -0.0512447   -0.0121926    0.0618903   0.00544545    0.17708       0.0153847   -0.0566215   -0.0162578 
  0.165898     0.129218     0.0785104    0.000196431   0.0573309   -0.0714818    0.0398185    -0.28546      0.122395     -0.112915      0.0345554    0.0043615     0.0988014   -0.00992899  -0.0365192    0.126696     0.0747873    0.116833     -0.0073853   -0.00681973  -0.163235    0.128704     -0.033477     -0.00118483  -0.11285     -0.0653274 
 -0.011927     0.198266    -0.0249054    0.0594863    -0.0208184   -0.0770462   -0.0232277     0.0675714   -0.0788171     0.0667443     0.0132392   -0.17198       0.00448955   0.0382357   -0.054008    -0.0904061   -0.0786917   -0.00385472    0.108434    -0.0391174   -0.104832   -0.265493     -0.000587628   0.0335047   -0.0177493    0.0543668 
  0.192811    -0.019673    -0.0507368   -0.0101374     0.0324006    0.0322078   -0.114422     -0.0981102    0.0019437     0.0359726     0.140132     0.0680658    -0.0250747    0.0572424   -0.0597259    0.0106703    0.102754     0.199856      0.146894     0.0664911   -0.0522248  -0.0123928     0.0450517    -0.0512742    0.086312    -0.00519978kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4222803459781805
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422300
[ Info: iteration 2, average log likelihood -1.422218
[ Info: iteration 3, average log likelihood -1.422151
[ Info: iteration 4, average log likelihood -1.422071
[ Info: iteration 5, average log likelihood -1.421974
[ Info: iteration 6, average log likelihood -1.421865
[ Info: iteration 7, average log likelihood -1.421755
[ Info: iteration 8, average log likelihood -1.421658
[ Info: iteration 9, average log likelihood -1.421584
[ Info: iteration 10, average log likelihood -1.421533
[ Info: iteration 11, average log likelihood -1.421498
[ Info: iteration 12, average log likelihood -1.421468
[ Info: iteration 13, average log likelihood -1.421433
[ Info: iteration 14, average log likelihood -1.421374
[ Info: iteration 15, average log likelihood -1.421263
[ Info: iteration 16, average log likelihood -1.421052
[ Info: iteration 17, average log likelihood -1.420665
[ Info: iteration 18, average log likelihood -1.420028
[ Info: iteration 19, average log likelihood -1.419152
[ Info: iteration 20, average log likelihood -1.418234
[ Info: iteration 21, average log likelihood -1.417535
[ Info: iteration 22, average log likelihood -1.417138
[ Info: iteration 23, average log likelihood -1.416951
[ Info: iteration 24, average log likelihood -1.416871
[ Info: iteration 25, average log likelihood -1.416837
[ Info: iteration 26, average log likelihood -1.416822
[ Info: iteration 27, average log likelihood -1.416816
[ Info: iteration 28, average log likelihood -1.416813
[ Info: iteration 29, average log likelihood -1.416812
[ Info: iteration 30, average log likelihood -1.416811
[ Info: iteration 31, average log likelihood -1.416810
[ Info: iteration 32, average log likelihood -1.416810
[ Info: iteration 33, average log likelihood -1.416810
[ Info: iteration 34, average log likelihood -1.416809
[ Info: iteration 35, average log likelihood -1.416809
[ Info: iteration 36, average log likelihood -1.416809
[ Info: iteration 37, average log likelihood -1.416809
[ Info: iteration 38, average log likelihood -1.416808
[ Info: iteration 39, average log likelihood -1.416808
[ Info: iteration 40, average log likelihood -1.416808
[ Info: iteration 41, average log likelihood -1.416808
[ Info: iteration 42, average log likelihood -1.416808
[ Info: iteration 43, average log likelihood -1.416808
[ Info: iteration 44, average log likelihood -1.416808
[ Info: iteration 45, average log likelihood -1.416808
[ Info: iteration 46, average log likelihood -1.416808
[ Info: iteration 47, average log likelihood -1.416808
[ Info: iteration 48, average log likelihood -1.416807
[ Info: iteration 49, average log likelihood -1.416807
[ Info: iteration 50, average log likelihood -1.416807
┌ Info: EM with 100000 data points 50 iterations avll -1.416807
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422299535608562
│     -1.422217804263606
│      ⋮                
└     -1.416807356754578
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416822
[ Info: iteration 2, average log likelihood -1.416756
[ Info: iteration 3, average log likelihood -1.416706
[ Info: iteration 4, average log likelihood -1.416651
[ Info: iteration 5, average log likelihood -1.416585
[ Info: iteration 6, average log likelihood -1.416507
[ Info: iteration 7, average log likelihood -1.416417
[ Info: iteration 8, average log likelihood -1.416320
[ Info: iteration 9, average log likelihood -1.416223
[ Info: iteration 10, average log likelihood -1.416133
[ Info: iteration 11, average log likelihood -1.416056
[ Info: iteration 12, average log likelihood -1.415995
[ Info: iteration 13, average log likelihood -1.415949
[ Info: iteration 14, average log likelihood -1.415914
[ Info: iteration 15, average log likelihood -1.415888
[ Info: iteration 16, average log likelihood -1.415866
[ Info: iteration 17, average log likelihood -1.415848
[ Info: iteration 18, average log likelihood -1.415831
[ Info: iteration 19, average log likelihood -1.415815
[ Info: iteration 20, average log likelihood -1.415798
[ Info: iteration 21, average log likelihood -1.415781
[ Info: iteration 22, average log likelihood -1.415762
[ Info: iteration 23, average log likelihood -1.415743
[ Info: iteration 24, average log likelihood -1.415723
[ Info: iteration 25, average log likelihood -1.415702
[ Info: iteration 26, average log likelihood -1.415680
[ Info: iteration 27, average log likelihood -1.415658
[ Info: iteration 28, average log likelihood -1.415636
[ Info: iteration 29, average log likelihood -1.415615
[ Info: iteration 30, average log likelihood -1.415595
[ Info: iteration 31, average log likelihood -1.415576
[ Info: iteration 32, average log likelihood -1.415558
[ Info: iteration 33, average log likelihood -1.415542
[ Info: iteration 34, average log likelihood -1.415528
[ Info: iteration 35, average log likelihood -1.415516
[ Info: iteration 36, average log likelihood -1.415506
[ Info: iteration 37, average log likelihood -1.415497
[ Info: iteration 38, average log likelihood -1.415490
[ Info: iteration 39, average log likelihood -1.415483
[ Info: iteration 40, average log likelihood -1.415478
[ Info: iteration 41, average log likelihood -1.415473
[ Info: iteration 42, average log likelihood -1.415470
[ Info: iteration 43, average log likelihood -1.415466
[ Info: iteration 44, average log likelihood -1.415464
[ Info: iteration 45, average log likelihood -1.415461
[ Info: iteration 46, average log likelihood -1.415459
[ Info: iteration 47, average log likelihood -1.415458
[ Info: iteration 48, average log likelihood -1.415456
[ Info: iteration 49, average log likelihood -1.415455
[ Info: iteration 50, average log likelihood -1.415453
┌ Info: EM with 100000 data points 50 iterations avll -1.415453
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4168223915088565
│     -1.416756384696571 
│      ⋮                 
└     -1.4154533111263825
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415464
[ Info: iteration 2, average log likelihood -1.415395
[ Info: iteration 3, average log likelihood -1.415332
[ Info: iteration 4, average log likelihood -1.415254
[ Info: iteration 5, average log likelihood -1.415155
[ Info: iteration 6, average log likelihood -1.415034
[ Info: iteration 7, average log likelihood -1.414899
[ Info: iteration 8, average log likelihood -1.414762
[ Info: iteration 9, average log likelihood -1.414635
[ Info: iteration 10, average log likelihood -1.414526
[ Info: iteration 11, average log likelihood -1.414437
[ Info: iteration 12, average log likelihood -1.414367
[ Info: iteration 13, average log likelihood -1.414312
[ Info: iteration 14, average log likelihood -1.414270
[ Info: iteration 15, average log likelihood -1.414238
[ Info: iteration 16, average log likelihood -1.414213
[ Info: iteration 17, average log likelihood -1.414193
[ Info: iteration 18, average log likelihood -1.414177
[ Info: iteration 19, average log likelihood -1.414163
[ Info: iteration 20, average log likelihood -1.414151
[ Info: iteration 21, average log likelihood -1.414140
[ Info: iteration 22, average log likelihood -1.414130
[ Info: iteration 23, average log likelihood -1.414120
[ Info: iteration 24, average log likelihood -1.414112
[ Info: iteration 25, average log likelihood -1.414103
[ Info: iteration 26, average log likelihood -1.414095
[ Info: iteration 27, average log likelihood -1.414087
[ Info: iteration 28, average log likelihood -1.414080
[ Info: iteration 29, average log likelihood -1.414073
[ Info: iteration 30, average log likelihood -1.414066
[ Info: iteration 31, average log likelihood -1.414059
[ Info: iteration 32, average log likelihood -1.414052
[ Info: iteration 33, average log likelihood -1.414046
[ Info: iteration 34, average log likelihood -1.414040
[ Info: iteration 35, average log likelihood -1.414034
[ Info: iteration 36, average log likelihood -1.414028
[ Info: iteration 37, average log likelihood -1.414022
[ Info: iteration 38, average log likelihood -1.414016
[ Info: iteration 39, average log likelihood -1.414011
[ Info: iteration 40, average log likelihood -1.414005
[ Info: iteration 41, average log likelihood -1.414000
[ Info: iteration 42, average log likelihood -1.413995
[ Info: iteration 43, average log likelihood -1.413990
[ Info: iteration 44, average log likelihood -1.413985
[ Info: iteration 45, average log likelihood -1.413981
[ Info: iteration 46, average log likelihood -1.413976
[ Info: iteration 47, average log likelihood -1.413972
[ Info: iteration 48, average log likelihood -1.413967
[ Info: iteration 49, average log likelihood -1.413963
[ Info: iteration 50, average log likelihood -1.413959
┌ Info: EM with 100000 data points 50 iterations avll -1.413959
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4154635031418576
│     -1.4153951618263807
│      ⋮                 
└     -1.413959143395566 
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413965
[ Info: iteration 2, average log likelihood -1.413894
[ Info: iteration 3, average log likelihood -1.413829
[ Info: iteration 4, average log likelihood -1.413750
[ Info: iteration 5, average log likelihood -1.413653
[ Info: iteration 6, average log likelihood -1.413532
[ Info: iteration 7, average log likelihood -1.413393
[ Info: iteration 8, average log likelihood -1.413244
[ Info: iteration 9, average log likelihood -1.413094
[ Info: iteration 10, average log likelihood -1.412953
[ Info: iteration 11, average log likelihood -1.412826
[ Info: iteration 12, average log likelihood -1.412714
[ Info: iteration 13, average log likelihood -1.412617
[ Info: iteration 14, average log likelihood -1.412536
[ Info: iteration 15, average log likelihood -1.412467
[ Info: iteration 16, average log likelihood -1.412411
[ Info: iteration 17, average log likelihood -1.412363
[ Info: iteration 18, average log likelihood -1.412322
[ Info: iteration 19, average log likelihood -1.412286
[ Info: iteration 20, average log likelihood -1.412254
[ Info: iteration 21, average log likelihood -1.412224
[ Info: iteration 22, average log likelihood -1.412197
[ Info: iteration 23, average log likelihood -1.412172
[ Info: iteration 24, average log likelihood -1.412148
[ Info: iteration 25, average log likelihood -1.412126
[ Info: iteration 26, average log likelihood -1.412104
[ Info: iteration 27, average log likelihood -1.412083
[ Info: iteration 28, average log likelihood -1.412063
[ Info: iteration 29, average log likelihood -1.412043
[ Info: iteration 30, average log likelihood -1.412024
[ Info: iteration 31, average log likelihood -1.412006
[ Info: iteration 32, average log likelihood -1.411988
[ Info: iteration 33, average log likelihood -1.411971
[ Info: iteration 34, average log likelihood -1.411955
[ Info: iteration 35, average log likelihood -1.411939
[ Info: iteration 36, average log likelihood -1.411923
[ Info: iteration 37, average log likelihood -1.411909
[ Info: iteration 38, average log likelihood -1.411894
[ Info: iteration 39, average log likelihood -1.411880
[ Info: iteration 40, average log likelihood -1.411866
[ Info: iteration 41, average log likelihood -1.411853
[ Info: iteration 42, average log likelihood -1.411840
[ Info: iteration 43, average log likelihood -1.411828
[ Info: iteration 44, average log likelihood -1.411815
[ Info: iteration 45, average log likelihood -1.411803
[ Info: iteration 46, average log likelihood -1.411791
[ Info: iteration 47, average log likelihood -1.411780
[ Info: iteration 48, average log likelihood -1.411768
[ Info: iteration 49, average log likelihood -1.411757
[ Info: iteration 50, average log likelihood -1.411746
┌ Info: EM with 100000 data points 50 iterations avll -1.411746
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4139645342316445
│     -1.4138944456505809
│      ⋮                 
└     -1.4117459320110273
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411743
[ Info: iteration 2, average log likelihood -1.411666
[ Info: iteration 3, average log likelihood -1.411594
[ Info: iteration 4, average log likelihood -1.411512
[ Info: iteration 5, average log likelihood -1.411412
[ Info: iteration 6, average log likelihood -1.411288
[ Info: iteration 7, average log likelihood -1.411141
[ Info: iteration 8, average log likelihood -1.410977
[ Info: iteration 9, average log likelihood -1.410804
[ Info: iteration 10, average log likelihood -1.410633
[ Info: iteration 11, average log likelihood -1.410473
[ Info: iteration 12, average log likelihood -1.410329
[ Info: iteration 13, average log likelihood -1.410203
[ Info: iteration 14, average log likelihood -1.410095
[ Info: iteration 15, average log likelihood -1.410002
[ Info: iteration 16, average log likelihood -1.409923
[ Info: iteration 17, average log likelihood -1.409855
[ Info: iteration 18, average log likelihood -1.409797
[ Info: iteration 19, average log likelihood -1.409747
[ Info: iteration 20, average log likelihood -1.409702
[ Info: iteration 21, average log likelihood -1.409663
[ Info: iteration 22, average log likelihood -1.409628
[ Info: iteration 23, average log likelihood -1.409597
[ Info: iteration 24, average log likelihood -1.409568
[ Info: iteration 25, average log likelihood -1.409542
[ Info: iteration 26, average log likelihood -1.409518
[ Info: iteration 27, average log likelihood -1.409495
[ Info: iteration 28, average log likelihood -1.409474
[ Info: iteration 29, average log likelihood -1.409454
[ Info: iteration 30, average log likelihood -1.409436
[ Info: iteration 31, average log likelihood -1.409418
[ Info: iteration 32, average log likelihood -1.409401
[ Info: iteration 33, average log likelihood -1.409385
[ Info: iteration 34, average log likelihood -1.409369
[ Info: iteration 35, average log likelihood -1.409354
[ Info: iteration 36, average log likelihood -1.409340
[ Info: iteration 37, average log likelihood -1.409326
[ Info: iteration 38, average log likelihood -1.409312
[ Info: iteration 39, average log likelihood -1.409299
[ Info: iteration 40, average log likelihood -1.409287
[ Info: iteration 41, average log likelihood -1.409274
[ Info: iteration 42, average log likelihood -1.409263
[ Info: iteration 43, average log likelihood -1.409251
[ Info: iteration 44, average log likelihood -1.409240
[ Info: iteration 45, average log likelihood -1.409229
[ Info: iteration 46, average log likelihood -1.409218
[ Info: iteration 47, average log likelihood -1.409208
[ Info: iteration 48, average log likelihood -1.409198
[ Info: iteration 49, average log likelihood -1.409188
[ Info: iteration 50, average log likelihood -1.409178
┌ Info: EM with 100000 data points 50 iterations avll -1.409178
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4117433118338705
│     -1.4116661016428427
│      ⋮                 
└     -1.409177866978612 
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4222803459781805
│     -1.422299535608562 
│     -1.422217804263606 
│     -1.4221513107094297
│      ⋮                 
│     -1.409197518514803 
│     -1.4091875846775044
└     -1.409177866978612 
32×26 Array{Float64,2}:
 -0.309548    -0.140152    0.075133   -0.18737     0.106621    -0.0101085  -0.231428    -0.845497    0.297032      0.0513702   0.660591    -0.527182    0.402433   -0.243176    -0.0250193   -0.154678   -0.525929   -0.39618      0.083332   -0.537076     0.330786     0.384342    -0.653892      0.444468    0.01689      0.181207  
 -0.211453     0.171741    0.193547   -0.166799   -0.144841    -0.291283   -0.223606     0.812791    0.212082     -0.444569    0.69177      0.0717187  -0.135013   -0.0648884    0.457428    -0.435432   -1.22231    -0.175351     0.28868    -0.138586    -0.265601    -0.28115     -0.207507      0.379314    0.220495     0.597049  
  0.392439    -0.582862   -0.384797    0.397676   -0.159698    -0.128615    0.115771    -0.0671732  -0.107829     -0.534856   -0.101822     0.542032   -0.531416   -0.246393     0.165546     0.126955   -0.534029    0.0891325   -0.386515   -0.140995    -0.0449565   -0.36693     -1.06816       0.223093    0.210967    -0.199995  
 -0.00331764   0.369527   -0.358311    0.500845   -0.233906    -0.26567    -0.0197467    0.0430404  -0.178926      0.132385    0.0724576    0.392444   -0.181447   -0.483081     0.270013     0.328174   -0.399826    0.310461    -0.146201   -0.524034     0.255465    -0.00529877   0.11618      -0.102831    0.45364      0.0490728 
 -0.152699     0.91959    -0.0148243  -0.359946    0.657454    -0.516487   -0.0242085    0.442816    1.00417       0.306876   -0.296006     0.301025   -0.0927264  -0.534113     0.222654     0.555681   -0.267133    0.132872    -0.0235115  -0.155445     0.0610263   -0.0615681    0.476581      0.142001    0.0332962   -0.564994  
 -0.181561     0.275999    1.13425    -0.0406881  -0.216289    -0.715595   -0.156722     0.170697    0.413595     -0.203113   -0.329643     0.145612   -0.286144   -0.698197    -0.530916     0.119492   -0.235604    0.0661131    0.562691    0.0732771   -0.187588     0.0465031    0.187424     -0.274162    0.0148273   -0.326423  
  0.660626    -0.0513546   0.0412639  -0.348309   -0.1372      -0.410355    0.062696     0.138149    0.209936      0.170692   -1.15399      0.387106    0.0270656   0.00734647  -0.130601    -0.278837    0.036335    1.24894     -0.304523   -0.313977    -0.0613383    0.340965     0.166534     -0.409376    0.25183      0.0713714 
  0.907946    -0.0389534   0.302486   -0.43131     0.131982    -0.150288    0.00379702   0.30184     0.139689     -0.204644    0.214046     0.07348     0.456422    0.552078     0.466671    -0.0783634  -0.153232    0.121975    -0.392837   -0.115116     0.12972      0.203258     0.431678      0.647506   -0.179089     0.238099  
  0.0972732   -0.0915268   0.100409   -0.370335    0.235749    -0.121985    0.202646     0.290624    0.247595      0.0948342  -0.428313    -0.144075    0.123703    0.665968    -0.286989    -0.281789    0.381468   -0.341623    -0.0450521   0.228511    -0.270028     0.066404     0.249761     -0.0452105  -0.114021    -0.148427  
 -0.126805    -0.0315837   0.213263    0.293468   -0.137413     0.917566   -0.141716    -0.392033    0.0556486     0.124608    0.181282    -0.220504    0.0951481  -0.158785    -0.508084    -0.029145    0.359486    0.0653188    0.35818     0.128708    -0.0515808    0.134798     0.172525     -0.563524   -0.444634    -0.00870134
 -0.371576     0.184664   -0.0183758   0.0298679  -0.0956285    0.126053    0.500618    -0.369243    0.0389391     0.15082     0.0361954   -0.441579    0.30686     0.325624     0.0526859    0.0447163   0.860505    0.433214    -0.314344    0.00527469   0.0117163    0.482354    -0.586632      0.104756    0.0941973    0.321665  
 -0.64833      0.483387    0.166274   -0.361289    0.320859    -0.0561307   0.373639    -0.173588    0.404503      1.00267     0.285916    -0.473506    0.390085    0.14697      0.0282728    0.227691    0.684167   -0.0775539    0.191796   -0.107047    -0.0121398    0.460116     1.1822       -0.625247    0.133522     0.0212848 
 -0.504826    -0.254755   -0.0973465  -0.167476   -0.316315     0.158694   -0.584786     0.894979    0.556597      0.400921   -0.101706     0.0300666  -0.592392   -0.368608     0.0376468   -0.318166    0.0644409  -0.163519    -0.0752746  -0.00345097   0.536984    -0.591902     0.140278      0.0102633  -0.150929    -0.607539  
 -0.184021    -0.169884    0.0650133  -0.180812   -0.032055     0.38661    -0.475072     0.548519   -0.465777      0.55272    -0.0362096   -0.430722   -0.697829   -0.2514       0.160201    -0.232726    0.488539    0.415551    -0.458189    0.581519     0.353582    -0.211032     0.0680416    -0.214283    0.237933     0.678489  
 -0.313256     0.489795   -0.074331   -0.351774   -0.164332    -0.136882   -0.287968     0.0512158  -0.48125       0.0505941  -0.0277244    0.0321641   0.0378122   0.246956    -0.11721     -0.11965     0.260424   -0.488653     0.0302291   0.620177    -0.141772    -0.720258     0.26812       0.352732   -0.13364     -0.474332  
 -0.428749    -0.180724   -0.105393    0.12806     0.0614047   -0.123173   -0.625684     0.146749   -0.358825     -0.150131    0.237311     0.0629351   0.457478   -0.0233648   -0.267751    -0.346198    0.133365   -0.448124    -0.356649    0.452526    -0.00113543  -0.477112    -0.218982     -0.160939    0.138764     0.927417  
  0.410612    -0.579679    0.146177    0.121365    0.285069     0.28898     0.188236    -0.805261   -0.687544     -0.0334247  -0.1391      -0.36153    -0.561045    0.288329    -0.00803769  -0.146853    0.0381175   0.132498     0.408562    0.459238     0.309657     0.298978    -0.527431      0.256048   -0.178827    -0.185299  
  0.398517    -0.103803   -0.023312   -0.149373    0.0552067    0.106267    0.52951     -0.148908    0.427753     -0.248396    0.044411    -0.523292   -0.624229   -0.163526     0.117654    -0.0309031  -0.340816    0.564744     0.245025   -0.202086    -0.164157     0.874011    -0.54831      -0.0542786   0.023044     0.114203  
  0.417771    -0.0435496   0.380306    0.509068   -0.267035    -0.225863    0.331989    -0.605485   -0.437848     -0.403897    0.0823549    0.832011    0.562733    0.355068    -0.304062     0.497032   -0.409257    0.215587     0.4199     -0.475625    -0.389653     0.236583    -0.0569045     0.141771   -0.0764749   -0.0197049 
  0.45615      0.360957    0.143344    0.619175    0.564165     0.224056    0.528825    -0.607792    0.161024     -0.348197    0.193683     0.143894    0.443418    0.023566    -0.634899     0.337991    0.0474435  -0.0612287   -0.0296375   0.216206    -0.213867     0.623154    -0.130957     -0.038723   -0.492013    -0.22604   
 -0.109413    -0.296546   -1.19314     0.253395    0.150685     0.0370567   0.480102     0.170192   -0.836641      0.250373   -0.504177     0.625088    0.417762    0.255777     0.197165     0.256613    0.212428   -0.170676    -0.378361    0.298461    -0.017739     0.0776191   -0.157045      0.071682   -0.20292     -0.185318  
  0.00732269   0.0855174  -0.459079    0.439401    0.26969     -0.05073     0.178335    -0.0665399  -0.860554      0.186844   -0.226514    -0.58365     0.0342996   0.0343484    0.554947     0.387842   -0.0368469  -0.20361     -0.150134    0.167291    -0.0880736    0.0987405   -0.071987      0.414859    0.865806     0.567499  
 -0.0386152   -0.0240849  -0.166525    0.0324459  -0.134753     0.229123    0.0819062   -0.0849009  -0.152064      0.095198   -0.0536643    0.135961    0.24946     0.236743    -0.103089    -0.130937    0.276004    0.0853538   -0.197595    0.0950877    0.0608853   -0.118763     0.000616328  -0.0391246  -0.229155     0.0723818 
 -0.114233     0.0612703  -0.013958    0.0202725   0.152569    -0.185354    0.0665233   -0.0770191   0.0522759    -0.011367    0.0253494   -0.049167   -0.0783237  -0.142006    -0.0857905    0.124516   -0.0804128  -0.0627033   -0.029687    0.146317    -0.124078     0.142242    -0.193723      0.121594    0.270334     0.168346  
 -0.471085     0.0683065  -0.523021    0.139924   -0.210605     0.350498    0.124818    -0.5105      0.105208      0.311064    0.0101521   -0.340893   -0.359385   -0.520212    -0.274085     0.236877    0.145629   -0.00251996   0.09606    -0.293496    -0.00253548  -0.0602095   -0.0974473    -0.640615    0.0824024   -0.517941  
  0.235251     0.215499    0.321665   -0.669976   -0.0169723   -0.0289558  -0.544314    -0.601726    0.395366      0.015642   -0.145323    -0.378808    0.378944   -0.128654    -0.532381    -0.0598871   0.457722    0.0847382   -0.287514   -0.0967809    0.205331     0.190888     0.239882     -0.136345   -0.289445    -0.334713  
 -0.312206     0.185527   -0.484759    0.126908   -0.122669    -0.131374   -0.115237     0.520546    0.194314      0.489416    0.0798247   -0.153987    0.292349   -0.120982     0.146647     0.0136411  -0.220249   -0.0776045   -0.327083   -0.629282    -0.138203    -0.0376539    0.518759     -0.0176548   0.216634     0.45699   
 -0.151792    -0.282924    0.63723    -0.234342   -0.0216148    0.109773   -0.14913      0.357561    0.301729      0.36036     0.130967    -0.242416   -0.167594   -0.0412748   -0.109524    -0.176811    0.0220267  -0.0363719    0.444228   -0.164991    -0.0712262    0.317324     0.317449     -0.129441    0.00773326   0.155221  
  0.317389     0.120132    0.0302074   0.0669601  -0.142073    -0.772432    0.19632      0.166688   -0.000596742  -0.181793   -0.00520768   0.557879   -0.0801834   0.059254     0.33453     -0.03477    -0.620434    0.202019    -0.0099254  -0.275288     0.135956    -0.198913     0.111781      0.218041    0.00190685  -0.202476  
  0.317836    -0.233542    0.310028   -0.107182   -0.00344302   0.302525   -0.405149    -0.0647619   0.108609     -0.27532     0.213107     0.157375    0.0236779  -0.112514     0.274934    -0.142096   -0.348633   -0.0765387    0.215883   -0.0690405    0.215845    -0.394025    -0.0606202     0.213519   -0.088215    -0.272139  
  0.318725    -0.144032   -0.0635708   0.249258    0.340071     0.0253514   0.00446282   0.615531   -0.0155458    -0.18387    -0.681051     0.562187   -0.352102   -0.478007    -0.489403     0.278095   -0.105301   -0.23959     -0.0383857   0.347209    -0.257742     0.177292     0.41932      -0.274151   -0.112522    -0.219634  
 -0.201123     0.09635    -0.0356707   0.55296    -0.202446     0.48043     0.543845     0.32474     0.072501     -0.0131765  -0.0562111    0.566093   -0.218906    0.0997398    0.10943      0.0335214   0.437077    0.0270186    0.467773    0.488387    -0.280548    -0.247557     0.50566      -0.478957   -0.0926673   -0.193993  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409168
[ Info: iteration 2, average log likelihood -1.409159
[ Info: iteration 3, average log likelihood -1.409150
[ Info: iteration 4, average log likelihood -1.409141
[ Info: iteration 5, average log likelihood -1.409132
[ Info: iteration 6, average log likelihood -1.409123
[ Info: iteration 7, average log likelihood -1.409115
[ Info: iteration 8, average log likelihood -1.409106
[ Info: iteration 9, average log likelihood -1.409098
[ Info: iteration 10, average log likelihood -1.409090
┌ Info: EM with 100000 data points 10 iterations avll -1.409090
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.421466e+05
      1       6.960625e+05      -2.460842e+05 |       32
      2       6.864308e+05      -9.631632e+03 |       32
      3       6.822754e+05      -4.155406e+03 |       32
      4       6.797916e+05      -2.483803e+03 |       32
      5       6.781997e+05      -1.591915e+03 |       32
      6       6.770211e+05      -1.178626e+03 |       32
      7       6.760731e+05      -9.480122e+02 |       32
      8       6.752914e+05      -7.816449e+02 |       32
      9       6.746434e+05      -6.480470e+02 |       32
     10       6.740862e+05      -5.571864e+02 |       32
     11       6.736453e+05      -4.408940e+02 |       32
     12       6.732863e+05      -3.589700e+02 |       32
     13       6.729823e+05      -3.040273e+02 |       32
     14       6.727253e+05      -2.569887e+02 |       32
     15       6.724880e+05      -2.373018e+02 |       32
     16       6.722808e+05      -2.072755e+02 |       32
     17       6.721058e+05      -1.749523e+02 |       32
     18       6.719460e+05      -1.598373e+02 |       32
     19       6.718093e+05      -1.366781e+02 |       32
     20       6.716792e+05      -1.300942e+02 |       32
     21       6.715626e+05      -1.166122e+02 |       32
     22       6.714486e+05      -1.139420e+02 |       32
     23       6.713447e+05      -1.039068e+02 |       32
     24       6.712370e+05      -1.076977e+02 |       32
     25       6.711406e+05      -9.645954e+01 |       32
     26       6.710463e+05      -9.428876e+01 |       32
     27       6.709549e+05      -9.138453e+01 |       32
     28       6.708689e+05      -8.600793e+01 |       32
     29       6.707948e+05      -7.411807e+01 |       32
     30       6.707322e+05      -6.259642e+01 |       32
     31       6.706741e+05      -5.803282e+01 |       32
     32       6.706225e+05      -5.160778e+01 |       32
     33       6.705727e+05      -4.983667e+01 |       32
     34       6.705168e+05      -5.592979e+01 |       32
     35       6.704617e+05      -5.503768e+01 |       32
     36       6.704005e+05      -6.122834e+01 |       32
     37       6.703413e+05      -5.918167e+01 |       32
     38       6.702849e+05      -5.640897e+01 |       32
     39       6.702354e+05      -4.948622e+01 |       32
     40       6.701889e+05      -4.649064e+01 |       32
     41       6.701453e+05      -4.363927e+01 |       32
     42       6.701083e+05      -3.694779e+01 |       32
     43       6.700737e+05      -3.460317e+01 |       32
     44       6.700410e+05      -3.277179e+01 |       32
     45       6.700134e+05      -2.758149e+01 |       32
     46       6.699884e+05      -2.498726e+01 |       32
     47       6.699657e+05      -2.270903e+01 |       32
     48       6.699391e+05      -2.661264e+01 |       32
     49       6.699099e+05      -2.923139e+01 |       32
     50       6.698828e+05      -2.709995e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669882.7504396648)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420541
[ Info: iteration 2, average log likelihood -1.415704
[ Info: iteration 3, average log likelihood -1.414449
[ Info: iteration 4, average log likelihood -1.413542
[ Info: iteration 5, average log likelihood -1.412555
[ Info: iteration 6, average log likelihood -1.411560
[ Info: iteration 7, average log likelihood -1.410794
[ Info: iteration 8, average log likelihood -1.410330
[ Info: iteration 9, average log likelihood -1.410070
[ Info: iteration 10, average log likelihood -1.409910
[ Info: iteration 11, average log likelihood -1.409798
[ Info: iteration 12, average log likelihood -1.409711
[ Info: iteration 13, average log likelihood -1.409637
[ Info: iteration 14, average log likelihood -1.409574
[ Info: iteration 15, average log likelihood -1.409517
[ Info: iteration 16, average log likelihood -1.409466
[ Info: iteration 17, average log likelihood -1.409419
[ Info: iteration 18, average log likelihood -1.409377
[ Info: iteration 19, average log likelihood -1.409337
[ Info: iteration 20, average log likelihood -1.409301
[ Info: iteration 21, average log likelihood -1.409267
[ Info: iteration 22, average log likelihood -1.409236
[ Info: iteration 23, average log likelihood -1.409207
[ Info: iteration 24, average log likelihood -1.409179
[ Info: iteration 25, average log likelihood -1.409153
[ Info: iteration 26, average log likelihood -1.409129
[ Info: iteration 27, average log likelihood -1.409106
[ Info: iteration 28, average log likelihood -1.409084
[ Info: iteration 29, average log likelihood -1.409063
[ Info: iteration 30, average log likelihood -1.409043
[ Info: iteration 31, average log likelihood -1.409024
[ Info: iteration 32, average log likelihood -1.409006
[ Info: iteration 33, average log likelihood -1.408989
[ Info: iteration 34, average log likelihood -1.408973
[ Info: iteration 35, average log likelihood -1.408958
[ Info: iteration 36, average log likelihood -1.408943
[ Info: iteration 37, average log likelihood -1.408929
[ Info: iteration 38, average log likelihood -1.408916
[ Info: iteration 39, average log likelihood -1.408903
[ Info: iteration 40, average log likelihood -1.408891
[ Info: iteration 41, average log likelihood -1.408880
[ Info: iteration 42, average log likelihood -1.408869
[ Info: iteration 43, average log likelihood -1.408858
[ Info: iteration 44, average log likelihood -1.408848
[ Info: iteration 45, average log likelihood -1.408839
[ Info: iteration 46, average log likelihood -1.408830
[ Info: iteration 47, average log likelihood -1.408821
[ Info: iteration 48, average log likelihood -1.408813
[ Info: iteration 49, average log likelihood -1.408805
[ Info: iteration 50, average log likelihood -1.408797
┌ Info: EM with 100000 data points 50 iterations avll -1.408797
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.278548    -0.278146     0.805492   -0.0323732   1.19082      0.495802   -0.368329    -0.400267    0.0577564   -0.126841    -0.972946    -0.577151    -0.902792     0.441338     -0.0980107   -0.587658    0.215915   -0.172482    0.558032      0.569727    0.194869    -0.542161   -0.19478      0.332162   -0.037097     0.143517 
  0.102979     0.0502406    0.361344    0.0767631   0.0624952    0.0531488   0.243637    -0.131245    0.298515    -0.107219     0.00429618  -0.00793049   0.0959016    0.0173477    -0.327479     0.0519325  -0.061538   -0.0626593   0.318828     -0.0513699  -0.200092     0.357463    0.0759408   -0.0607317  -0.200637    -0.231672 
 -0.393608     0.365365     0.384564   -0.216327    0.169203    -0.547524   -0.279192     0.411061    0.577346     0.199078    -0.173818     0.0810016   -0.663501    -0.872579     -0.130783     0.169337   -0.308459    0.266489    0.0930706     0.0789642  -0.0481197    0.0363034  -0.0775494   -0.11627     0.322079     0.0297153
  0.710192    -0.116782     0.177169   -0.0124788  -0.108619     0.222944    0.625084    -0.171732    0.189205     0.0730824   -0.133047    -0.308652    -0.93269     -0.102473     -0.0286036    0.0396991  -0.331825    0.63905     0.51401      -0.216789    0.00467271   0.593605   -0.134509    -0.167626   -0.0709684   -0.267884 
  0.621667    -0.141555    -0.208032    0.292568    0.0126237   -0.60818     0.517205     0.0863086  -0.0760387   -0.563576    -0.249516     0.838998    -0.274796    -0.154061      0.372921     0.262358   -0.482295    0.234801   -0.291466     -0.11714     0.0909612   -0.227441   -0.532835     0.24386     0.267173    -0.513262 
 -0.346098     0.107698    -0.0734022  -0.101375   -0.479211    -0.420604   -0.453311     0.41058    -0.442191     0.0391193   -0.217536    -0.202899     0.0532946    0.049621      0.063765    -0.398403    0.130163   -0.300097   -0.231547      0.408678    0.108197    -0.38226     0.032687     0.30688     0.136467     0.157155 
 -0.50004     -0.010235    -0.15839    -0.317507   -0.126395     0.184317   -0.0427701    0.224326    0.220845     0.601326     0.249134    -0.553617     0.202843     0.0171766    -0.0619571   -0.0125044   0.0696457  -0.161627    0.0747094    -0.483683   -0.321565     0.12817     0.585774    -0.285492    0.023822     0.28319  
  0.0187246    0.14509     -0.0296787   0.268235   -0.173751     0.327495    0.313373    -0.625816    0.188183    -0.347493     0.153981    -0.354207     0.158381     0.0150242     0.169626    -0.0822724   0.0807792   0.569181    0.0119769    -0.324462   -0.164515     0.543963   -0.636029    -0.0570546   0.209919     0.571832 
 -0.086687     0.0264245   -0.0950566   0.0265922   0.109034     0.179056    0.00599961  -0.155124   -0.00796296   0.0993285   -0.0608979    0.0683682    0.133661     0.0258102    -0.201015     0.0322709   0.309975   -0.0708752  -0.110108      0.226751   -0.047638    -0.0479549  -0.00562139  -0.0571478  -0.00874554   0.0431422
 -0.511645    -0.0306853    0.0908675   0.235099    0.0244304    0.629754   -0.499284     0.191769   -0.495668     0.365831     0.401124    -0.493156     0.0751482   -0.285464     -0.279556    -0.222383    0.528285   -0.0903669  -0.219922      0.705311    0.113945    -0.0376163   0.256979    -0.468854   -0.0832829    0.951346 
 -0.751395    -0.290211     0.227032    0.245052   -0.104034     0.0328393   0.0919693   -0.343681    0.119251    -0.104582     1.12631     -0.126409     0.187164    -0.114858      0.105807     0.140559   -0.585242   -0.743474    0.769923     -0.151672    0.201415    -0.0966034  -0.616656     0.73937    -0.0926452   -0.102672 
  0.184711    -0.0596194   -0.243387    0.420209   -0.351379     0.477993   -0.712605     0.0405435  -0.589811    -0.516665     0.226277     0.621957    -0.318575    -0.129135      0.146099    -0.0759164  -0.415048   -0.18122     0.0495393     0.252644   -0.188663    -0.862278   -0.217145     0.268837   -0.270094    -0.114941 
 -0.569443    -0.253542    -0.383206   -0.280486    0.426249    -0.636421   -0.614656     0.247974   -0.149356    -0.0744612    0.190185     0.0437982    0.229111    -0.0526747    -0.0512602   -0.203034   -0.0269723  -0.576776   -0.574761      0.271744   -0.12201     -0.69074    -0.65173     -0.0700237   0.629733     0.905026 
 -0.0407247    0.850906    -0.227996    0.344532    0.0734518   -0.53488    -0.367023     0.401635    0.549889     0.0315926   -0.247413     0.688771     0.644936    -0.301478      0.17289      0.0304561  -0.561345   -0.121983   -0.187067     -0.699096    0.103379    -0.20763     0.960368    -0.0338532   0.24922      0.0591693
  0.313162     0.113333     0.256678   -0.721248    0.140098    -0.0702169  -0.764582    -0.899762    0.0807085   -0.00661584   0.0512191   -0.607686     0.427061    -0.118966     -0.413842    -0.159986    0.058751    0.0379312  -0.376702     -0.302294    0.562403     0.275674   -0.0710683    0.296652   -0.064195    -0.163877 
 -0.0134691   -0.0434441   -0.488161    0.14352    -0.244166    -0.199538   -0.0586775    0.115334    0.0511768    0.154692     0.343107    -0.289651    -0.153117    -0.288067      0.587041    -0.116064   -0.536014    0.401348   -0.371472     -0.757608    0.0934393    0.133963   -0.342894     0.110732    0.464227     0.701183 
 -0.246135     0.187194     0.293517    0.341858   -0.682403    -0.685125    0.247727     0.0690734  -0.798355     0.773136    -0.140664     0.521808    -0.112596     0.190997     -0.360792     0.330947   -0.113786   -0.211443    0.628373      0.0733058   0.0363768   -0.370105    0.558307    -0.0341785   0.81514     -0.331539 
 -0.0117114   -0.00289149  -0.448384    0.202637    0.0766514    0.750328    0.208147    -0.244346   -0.293149     0.289812    -0.150293     0.19525      0.50829      0.854653     -0.0262614   -0.0704645   0.940476   -0.155339   -0.196746      0.397337    0.0979484   -0.157519    0.222874    -0.0441804  -0.278501    -0.120725 
  0.135237    -0.32964      0.121685    0.692824   -0.211701    -0.293195    0.383335    -0.186862   -0.172678    -0.118567    -0.170983     0.852911     0.710016     0.289379     -0.575081     0.17724    -0.103253    0.374047    0.0630513    -0.105359   -0.160284     0.346664   -0.326162    -0.106017   -0.297747     0.292035 
 -0.580084    -0.00695389  -0.789345    0.296742   -0.334386     0.414335    0.114639    -0.540931    0.00977799   0.287186    -0.130327    -0.161808    -0.512025    -0.776465     -0.334131     0.327693    0.17807     0.0262542   0.0303871    -0.316479    0.0868821   -0.094253   -0.250197    -0.75288     0.0343199   -0.798765 
 -0.166879    -0.689139     0.28691     0.103436    0.00597774   0.618947   -0.394319     0.117504    0.354134     0.178442     0.0821887   -0.116194    -0.1978      -0.473588     -0.00929466  -0.492325    0.0641384  -0.0246674   0.162508     -0.0424524   0.462155     0.0385952  -0.292763    -0.271731    0.0170415    0.0190358
  0.263698     0.0578827   -0.345515    0.550445    0.468231     0.0271575   0.472822    -0.623682   -0.866958    -0.172969    -0.105115    -0.14313      0.325947    -0.0703971    -0.104576     0.551932   -0.082111   -0.168647   -0.0110377     0.364074   -0.0854347    0.412577   -0.304192     0.284945    0.0839594    0.217681 
  0.494654     0.0390365   -0.0812939  -0.504004   -0.0720173   -0.0885134  -0.252624     0.683654   -0.123484     0.315648    -0.867331     0.247694    -0.279747    -0.0397761    -0.177902    -0.106756    0.354311    0.749423   -0.578982      0.0896923  -0.0227463    0.0574242   0.511814    -0.398124   -0.0228143    0.209095 
 -0.436278     0.517483     0.564958   -0.1979     -0.33581     -0.0635437  -0.0332216   -0.25899     0.346049    -0.0898246   -0.0985942   -0.161832     0.267644    -0.000705993  -0.698599    -0.15462     0.444411   -0.127374    0.476144      0.322626   -0.318779     0.0689732   0.382308    -0.833042   -0.377092    -0.316178 
  0.0439591   -0.28102     -0.331002    0.647903    0.510388    -0.0725802   0.120849     0.571492   -0.0951457    0.350916    -0.248615    -0.255686    -0.00701021   0.201809      0.601012     0.224835   -0.164536   -0.244424   -0.453798     -0.331649    0.0915398    0.284188    0.180204     0.457516    0.566166     0.465821 
 -0.476301     0.393092    -0.118243   -0.617491    0.0420878   -0.221007   -0.49478      0.738069    0.21416      0.438618    -0.142273    -0.167935    -0.545412    -0.124319      0.14123      0.0436177   0.0951928  -0.401516   -0.0501975     0.303443    0.138381    -0.692114    0.517057     0.358905   -0.210282    -0.750446 
 -0.00621684  -0.123025    -0.0714408  -0.580634   -0.00484331  -0.0403844   0.459887    -0.218421    0.0736631   -0.19687      0.159817    -0.537059    -0.42445      0.556131     -0.134392    -0.154687    0.302546    0.224546   -0.354354      0.516518   -0.319726     0.541273   -0.899508     0.26725    -0.0406754   -0.102735 
  0.613262     0.166143     0.306824   -0.0265062   0.380938    -0.0660127   0.0566506   -0.246245    0.508269    -0.255449    -0.144145     0.278934     0.203597    -0.198774     -0.421082     0.325176   -0.302711   -0.0909616   0.0595122    -0.212431   -0.237389     0.272099    0.376096    -0.0477839  -0.361054    -0.762448 
 -0.483978     0.612435     0.146693   -0.42011     0.550354    -0.374479    0.69782     -0.348319    0.347288     0.85965     -0.0121342   -0.262051     0.280378    -0.0198676     0.443105     0.493525    0.771141    0.522377   -0.0954782    -0.159553    0.379318     0.382169    0.312673    -0.119043    0.179573    -0.103161 
  0.542851    -0.0470417    0.528976   -0.638262   -0.0830285   -0.302402   -0.173576     0.448797    0.176737    -0.365902     0.363361     0.135399     0.463984     0.462359      0.377184    -0.358869   -0.371713   -0.0732064   0.000485815   0.0278457  -0.0490028   -0.0176515   0.237057     0.595712   -0.215695     0.338628 
  0.166804    -0.0135095    0.0753954  -0.0474989  -0.143117    -0.25371     0.100326     0.0314466  -0.0454565   -0.059764     0.110496     0.178678    -0.0346885    0.0605431     0.174237    -0.0179987  -0.403044    0.166853    0.0673074    -0.232127    0.0794605   -0.0278538   0.035278     0.145055   -0.0412055   -0.0266077
 -0.122023    -0.0021047   -0.172032    0.476549    0.0467281    0.222265    0.545058     0.789362   -0.0439539   -0.185368    -0.291011     0.603971    -0.376044    -0.219628     -0.00899217   0.162365    0.18749    -0.164697    0.263276      0.565463   -0.418076    -0.0210644   0.490456    -0.400982   -0.0394638   -0.108776 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408790
[ Info: iteration 2, average log likelihood -1.408783
[ Info: iteration 3, average log likelihood -1.408776
[ Info: iteration 4, average log likelihood -1.408770
[ Info: iteration 5, average log likelihood -1.408763
[ Info: iteration 6, average log likelihood -1.408758
[ Info: iteration 7, average log likelihood -1.408752
[ Info: iteration 8, average log likelihood -1.408747
[ Info: iteration 9, average log likelihood -1.408742
[ Info: iteration 10, average log likelihood -1.408737
┌ Info: EM with 100000 data points 10 iterations avll -1.408737
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
