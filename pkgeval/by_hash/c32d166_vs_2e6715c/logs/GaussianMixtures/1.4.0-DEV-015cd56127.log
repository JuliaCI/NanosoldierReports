Julia Version 1.4.0-DEV.689
Commit 015cd56127 (2020-01-09 09:30 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed Missings ─────────── v0.4.3
  Installed CMake ────────────── v1.1.2
  Installed JLD ──────────────── v0.9.1
  Installed HDF5 ─────────────── v0.12.5
  Installed BinDeps ──────────── v1.0.0
  Installed BinaryProvider ───── v0.5.8
  Installed Clustering ───────── v0.13.3
  Installed Rmath ────────────── v0.6.0
  Installed Parameters ───────── v0.12.0
  Installed Distances ────────── v0.8.2
  Installed SpecialFunctions ─── v0.9.0
  Installed OrderedCollections ─ v1.1.0
  Installed StaticArrays ─────── v0.12.1
  Installed DataStructures ───── v0.17.7
  Installed StatsBase ────────── v0.32.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Arpack ───────────── v0.4.0
  Installed PDMats ───────────── v0.9.10
  Installed QuadGK ───────────── v2.3.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed Compat ───────────── v2.2.0
  Installed URIParser ────────── v0.4.0
  Installed OpenBLAS_jll ─────── v0.3.7+4
  Installed SortingAlgorithms ── v0.3.1
  Installed FileIO ───────────── v1.2.1
  Installed FillArrays ───────── v0.8.2
  Installed Blosc ────────────── v0.5.1
  Installed LegacyStrings ────── v0.4.1
  Installed NearestNeighbors ─── v0.4.4
  Installed DataAPI ──────────── v1.1.0
  Installed Distributions ────── v0.22.0
  Installed StatsFuns ────────── v0.9.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed ScikitLearnBase ──── v0.5.0
Downloading artifacts...
[ Info: Downloading https://github.com/JuliaBinaryWrappers/Arpack_jll.jl/releases/download/Arpack-v3.5.0+2/Arpack.v3.5.0.x86_64-linux-gnu-libgfortran4.tar.gz to /tmp/jl_PXGbZb-download.gz...
#=#=#                                                                         #######                                                                   10.9%######################################################################## 100.0%
[ Info: Downloading https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.7+4/OpenBLAS.v0.3.7.x86_64-linux-gnu-libgfortran4.tar.gz to /tmp/jl_bp6kze-download.gz...
#=#=#                                                                                                                                                    0.1%###############                                                           21.5%#####################################                                     52.7%######################################################################## 100.0%
[ Info: Downloading https://github.com/JuliaBinaryWrappers/OpenSpecFun_jll.jl/releases/download/OpenSpecFun-v0.5.3+1/OpenSpecFun.v0.5.3.x86_64-linux-gnu-libgfortran4.tar.gz to /tmp/jl_zuOVKw-download.gz...
#=#=#                                                                         #####                                                                      7.1%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_bRuyLT/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.7
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+4
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [9abbd945] Profile 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.722991716364833e6, [10986.409321370173, 89013.59067862983], [2071.639248339966 16023.399599142575 9614.32923973401; -1800.668208502132 -15708.873161990015 -10201.501502542036], [[11380.21401443977 2245.104308238227 1163.2631456797758; 2245.104308238226 27915.243946211056 10008.460429744859; 1163.2631456797758 10008.460429744859 16922.902151460665], [88710.22481124855 -2236.666540084566 -973.1935338650769; -2236.666540084566 72338.94440097509 -9808.753203170016; -973.1935338650768 -9808.753203170016 83195.21499671966]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.214065e+03
      1       9.122447e+02      -3.018202e+02 |        5
      2       8.864988e+02      -2.574589e+01 |        2
      3       8.796389e+02      -6.859887e+00 |        0
      4       8.796389e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 879.6389385064322)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.072581
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.796969
[ Info: iteration 2, lowerbound -3.646633
[ Info: iteration 3, lowerbound -3.470181
[ Info: iteration 4, lowerbound -3.259733
[ Info: iteration 5, lowerbound -3.044616
[ Info: iteration 6, lowerbound -2.856189
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.705965
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.586205
[ Info: iteration 9, lowerbound -2.500953
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.433241
[ Info: iteration 11, lowerbound -2.379077
[ Info: iteration 12, lowerbound -2.344154
[ Info: iteration 13, lowerbound -2.319837
[ Info: iteration 14, lowerbound -2.308145
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.303079
[ Info: iteration 16, lowerbound -2.299264
[ Info: iteration 17, lowerbound -2.299258
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan  9 16:02:34 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan  9 16:02:43 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Jan  9 16:02:45 2020: EM with 272 data points 0 iterations avll -2.072581
5.8 data points per parameter
, Thu Jan  9 16:02:47 2020: GMM converted to Variational GMM
, Thu Jan  9 16:02:56 2020: iteration 1, lowerbound -3.796969
, Thu Jan  9 16:02:56 2020: iteration 2, lowerbound -3.646633
, Thu Jan  9 16:02:56 2020: iteration 3, lowerbound -3.470181
, Thu Jan  9 16:02:56 2020: iteration 4, lowerbound -3.259733
, Thu Jan  9 16:02:56 2020: iteration 5, lowerbound -3.044616
, Thu Jan  9 16:02:56 2020: iteration 6, lowerbound -2.856189
, Thu Jan  9 16:02:56 2020: dropping number of Gaussions to 7
, Thu Jan  9 16:02:56 2020: iteration 7, lowerbound -2.705965
, Thu Jan  9 16:02:56 2020: dropping number of Gaussions to 5
, Thu Jan  9 16:02:56 2020: iteration 8, lowerbound -2.586205
, Thu Jan  9 16:02:56 2020: iteration 9, lowerbound -2.500953
, Thu Jan  9 16:02:57 2020: dropping number of Gaussions to 3
, Thu Jan  9 16:02:57 2020: iteration 10, lowerbound -2.433241
, Thu Jan  9 16:02:57 2020: iteration 11, lowerbound -2.379077
, Thu Jan  9 16:02:57 2020: iteration 12, lowerbound -2.344154
, Thu Jan  9 16:02:57 2020: iteration 13, lowerbound -2.319837
, Thu Jan  9 16:02:57 2020: iteration 14, lowerbound -2.308145
, Thu Jan  9 16:02:57 2020: dropping number of Gaussions to 2
, Thu Jan  9 16:02:57 2020: iteration 15, lowerbound -2.303079
, Thu Jan  9 16:02:57 2020: iteration 16, lowerbound -2.299264
, Thu Jan  9 16:02:57 2020: iteration 17, lowerbound -2.299258
, Thu Jan  9 16:02:57 2020: iteration 18, lowerbound -2.299255
, Thu Jan  9 16:02:57 2020: iteration 19, lowerbound -2.299254
, Thu Jan  9 16:02:57 2020: iteration 20, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 21, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 22, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 23, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 24, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 25, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 26, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 27, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 28, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 29, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 30, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 31, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 32, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 33, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 34, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 35, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 36, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 37, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 38, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 39, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 40, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 41, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 42, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 43, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 44, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 45, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 46, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 47, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 48, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 49, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: iteration 50, lowerbound -2.299253
, Thu Jan  9 16:02:57 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601388, 95.95490777398618]
β = [178.04509222601388, 95.95490777398618]
m = [4.250300733269909 79.28686694436182; 2.0002292577753704 53.8519871724613]
ν = [180.04509222601388, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484516 -0.00764404904232726; 0.0 0.008581705166333256], [0.37587636119483925 -0.008953123827346093; 0.0 0.012748664777409381]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.991608951702364
avll from llpg:  -0.9916089517023636
avll direct:     -0.9916089517023636
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9984883898498387
avll from llpg:  -0.9984883898498385
avll direct:     -0.9984883898498385
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0410114    0.0395318    -0.193331     0.163236     0.251167      0.0295703    0.190136    -0.0374365    0.00427815   0.136414     0.133736      0.0247418    0.129311    -0.0691476     0.0231307    0.00277836   0.0189972    0.0587849   -0.00461655   0.189762    -0.015005    -0.0193273    0.0062735   0.06414     -0.0886348   -0.0214768
  0.0900612   -0.146983     -0.0890876   -0.0363319    0.135305     -0.155748     0.0574621   -0.112665     0.00794824   0.017762     0.193974     -0.132396    -0.0291677    0.111681     -0.0892787   -0.0580943   -0.108613     0.0502491    0.060213    -0.101395    -0.00945731   0.380661    -0.096809    0.0291179   -0.146286    -0.0339612
  0.0199503   -0.0511034    -0.0137637    0.0770812    0.167876      0.156091    -0.053374    -0.0154269   -0.106617     0.0614168    0.0685179     0.0573176   -0.0472032   -0.124586      0.00914553   0.175178     0.123572    -0.0536611   -0.227322    -0.245389    -0.058805    -0.0588893    0.0101859  -0.0215565   -0.0942771   -0.0558691
 -0.168011    -0.0489544    -0.00736426   0.147498     0.0247375    -0.0313415   -0.080926     0.041723     0.180084     0.0241476    0.0323205    -0.0770037    0.0570795    0.111198     -0.0656413    0.0971286    0.0939086   -0.0877019   -0.0996966   -0.0828926    0.202095    -0.160876    -0.15105     0.129043     0.0718813    0.196866
  0.0877003   -0.00536475   -0.0876914   -0.0335008    0.03984      -0.148415     0.113169    -0.0766462   -0.0108745   -0.108194     0.0687199    -0.129001     0.307521    -0.104209     -0.00319839  -0.26805      0.0951333   -0.0312707   -0.115976     0.139406     0.0661131    0.0383027    0.108005    0.115132     0.130659     0.088052
  0.0360972    0.104832     -0.0682311   -0.0556123    0.0171347     0.0415885   -0.0261776   -0.0338404   -0.0724721    0.170938     0.0223981     0.00353584  -0.101203    -0.124032      0.0759684   -0.0921277    0.163105    -0.0395575    0.0287355    0.0212524   -0.010739     0.0824387    0.102374   -0.00976952   0.0890467   -0.0583855
 -0.144969     0.0456749     0.13158     -0.110925    -0.165726      0.00965001  -0.0151908    0.061826    -0.197014     0.0847964   -0.029152     -0.0415143   -0.0871477   -0.113324     -0.00194646   0.0932296    0.0964957   -0.0560996    0.079252     0.0611192    0.0617939   -0.038824     0.147113   -0.0331602   -0.0985655   -0.308562
  0.0805475   -0.000384949  -0.199711    -0.0393727   -0.0411859    -0.117596    -0.00389734   0.0576191   -0.220474     0.0373905   -0.102515     -0.156        0.202216    -0.161764      0.139238    -0.0261701   -0.102414    -0.117113    -0.0371241   -0.0686541    0.161574    -0.00832694   0.0789556   0.115325    -0.0710399   -0.0387473
  0.0149938   -0.0234543     0.0522193   -0.123677    -0.0885151    -0.0848556   -0.120702    -0.0361468   -0.0357872    0.00822842   0.0627992     0.0138325   -0.177439    -0.240609     -0.0282755   -0.206619    -0.0732209   -0.0428499    0.113245     0.127317    -0.0842259   -0.0733002   -0.158239   -0.0195426   -0.0905073    0.144665
  0.109715     0.0971023     0.0292954    0.00685873  -0.0263839    -0.116349    -0.0134307    0.0726285   -0.109933     0.147682     0.142804     -0.0172153   -0.169165    -0.0697269     0.059488     0.0268809   -0.100922     0.0244886    0.0278185   -0.0305027   -0.00324048   0.0257507   -0.085361   -0.00706008  -0.00581239  -0.0190237
  0.0797329   -0.0429036     0.111057     0.0738969    0.151424     -0.115653    -0.0213628   -0.0104507   -0.00786716  -0.0477641    0.00822384   -0.225614    -0.130472     0.167065      0.025069    -0.152293    -0.0158831   -0.0541938   -0.00114066   0.0482506    0.155199     0.0743302    0.023003   -0.204121    -0.0198398    0.0863085
 -0.0293203   -0.0144702     0.0767979    0.136023    -0.0196178    -0.0882279    0.03952     -0.0135943   -0.100409    -0.0583209   -0.000385108  -0.0326872   -0.0447057   -0.0501606     0.127699     0.0604238   -0.0974404    0.111929     0.0881475   -0.077845     0.218134    -0.0950626    0.0239479   0.00783349  -0.104646     0.000371565
 -0.120779     0.0547141    -0.0405149    0.00647199   0.118972      0.00883646  -0.12797     -0.0266972    0.0864733    0.175466     0.0591613     0.142188     0.00204414   0.198929     -0.11529      0.0803144    0.144997    -0.0465138    0.0734999   -0.0408431   -0.0409378   -0.204834    -0.107697    0.00100434  -0.07842     -0.0210489
  0.0285112    0.0532069    -0.0197988   -0.061232    -0.0954676     0.207634    -0.106132     0.0121129    0.0144065    0.0980672   -0.00210829    0.0588533   -0.155788     0.157733      0.0285518   -0.00962366   0.0496652    0.0430811    0.0141086   -0.0159086   -0.177951     0.0484049   -0.0359354  -0.135754    -0.0827119   -0.0174568
  0.0519357    0.0191358    -0.0161278    0.0337278   -0.0465791    -0.020416    -0.0815491   -0.177893     0.130649     0.0152515   -0.0317518     0.0321363   -0.0695835   -0.0320083    -0.194802     0.0971178    0.0566835   -0.155887     0.0402468   -0.145184     0.00393838   0.139686    -0.0900828   0.0237547   -0.0453849   -0.102909
  0.166477    -0.0165877    -0.06819      0.0914972   -0.0672286     0.021995     0.00395224   0.0262604   -0.00921528  -0.165738     0.0250682     0.086818    -0.197389     0.0519202     0.0237706    0.128614    -0.0855083    0.116368    -0.00878789  -0.0409991    0.0875757    0.0116059   -0.0412751  -0.0457499    0.193244     0.102677
  0.0154937   -0.065283     -0.0162671    0.157181     0.0161138     0.168875    -0.0247539    0.00801676   0.0741881    0.0314425    0.0619994     0.0418991   -0.15378      0.0231426    -0.0435553    0.00854229   0.195432     0.201977     0.00134009   0.0561653    0.0224875    0.0833476    0.0853113   0.120128     0.102338    -0.0301864
 -0.011433     0.119451     -0.00510959   0.0221807   -0.0243446     0.119899    -0.145452     0.101015    -0.0343665   -0.0848211    0.150263     -0.0986654    0.0712094    0.0552173    -0.286106    -0.0559132   -0.0500177   -0.0671494    0.0242055    0.069876    -0.006849    -0.0383682   -0.181619    0.00363474  -0.128631    -0.0208509
 -0.0785617    0.0487507     0.00920678   0.0586979    0.0497133     0.0906254   -0.0630337    0.0549279   -0.0271718    0.27298     -0.104138      0.0606926   -0.086772    -0.113896     -0.136248     0.164577    -0.151318     0.00840016  -0.154823    -0.0916321    0.193155    -0.170492     0.0186241   0.0253721    0.0536523    0.083432
 -0.0654077    0.200291     -0.0866784    0.0911877   -0.0901926    -0.00212111   0.0497177    0.112634     0.0669086   -0.0258664    0.174809      0.0380837    0.0778243   -0.0668451     0.126222     0.154295     0.0350477    0.058597     0.00787472   0.0229685    0.0721838   -0.129494     0.0264426  -0.00157171  -0.0454178    0.0175486
 -0.101908    -0.0449277     0.115924     0.0112488   -0.000145731   0.0209992    0.0784716    0.0649108   -0.154679    -0.021762     0.140984      0.206785    -0.204202    -0.000131146  -0.049812    -0.0298031   -0.107797    -0.102974     0.109969     0.114436     0.107914     0.105561    -0.0063346   0.0538104    0.069343     0.256239
  0.0046669    0.0714443     0.107068     0.118264     0.0948325    -0.0737972   -0.0574698   -0.0225917    0.100596     0.00307791   0.0467666    -0.162713    -0.0331091    0.0453775    -0.167862     0.105705     0.085304     0.171586     0.00635044   0.183579    -0.0501452    0.0995098   -0.0633905  -0.137562     0.00918826   0.0433565
  0.102982     0.114919     -0.121443     0.0376639    0.139186     -0.0694669   -0.0842427   -0.0269839    0.0954045    0.0746249    0.116439     -0.217627    -0.128869    -0.0084285     0.0763667   -0.0650586    0.0996636   -0.254761    -0.0539582   -0.131364     0.0497326   -0.0605958   -0.0395014  -0.0589036    0.036849     0.163467
 -0.00329894  -0.0905125     0.185877     0.21444      0.166294      0.123844    -0.0427717   -0.0498447   -0.0458295   -0.106761     0.143406     -0.175476    -0.0945425    0.0878516    -0.0331278   -0.0512535   -0.185635    -0.0355603   -0.0450508    0.0809715   -0.0659449   -0.0945273   -0.0215599   0.0996273    0.151266    -0.0600541
  0.152268    -0.0051017    -0.264443    -0.00480283   0.00744672   -0.00866744   0.0607985   -0.107092    -0.0229029   -0.0687669    0.116513     -0.0366141   -0.0149111   -0.0891672     0.0451544   -0.0395327   -0.0969421   -0.144624     0.00119902  -0.0910505    0.0615002   -0.12413     -0.11909     0.0628285    0.0550757   -0.00833302
 -0.10508     -0.0144098    -0.0178184    0.11141      0.18025      -0.15364     -0.0104813   -0.127697     0.0980807   -0.0813027   -0.164288     -0.0540146    0.101019     0.0446232     0.10739     -0.0246095   -0.0334449    0.0534017    0.00550617   0.104301     0.0363457   -0.0185999   -0.0117494   0.0754345   -0.0131118   -0.144794
 -0.0436207   -0.0890709     0.0655959    0.0241397   -0.0147078    -0.0410236   -0.0543401   -0.0132986   -0.104194     0.150182     0.0396001     0.241175    -0.0103459   -0.0178396     0.0887707    0.0246515   -0.0703197   -0.0663472   -0.0627233   -0.19817     -0.0927357   -0.0356974   -0.0812015   0.132746     0.0509901   -0.108683
 -0.0903122    0.0319659     0.00415688   0.0204517   -0.0951061    -0.112872    -0.0076282    0.0816161   -0.0314148   -0.043375     0.0346922    -0.0444834   -0.0175893   -0.00873345   -0.0732477   -0.0148761    0.101339     0.0209801   -0.0563147    0.0744956   -0.153229    -0.0815434    0.120376   -0.127864    -0.114335     0.180845
  0.0312913    0.0712397    -0.0857761   -0.136506     0.0162664    -0.105735    -0.120316     0.0424576    0.125928    -0.0325094    0.147211      0.00539489   0.0737247   -0.0653484     0.0283651    0.0211926   -0.0811368    0.0884372   -0.249865     0.00565268   0.121142    -0.117623     0.077479   -0.142367     0.0711869   -0.0810158
  0.319647    -0.0878673     0.161431     0.0942302   -0.155879     -0.105117    -0.11237      0.119518    -0.0175067   -0.012166     0.170871      0.123046     0.0481716    0.115643      0.102311    -0.0548181    0.0270337   -0.158398    -0.0485218   -0.236176    -0.0368119   -0.0567349    0.08207     0.137486     0.075288    -0.000309738
 -0.126273    -0.0434924    -0.0446014    0.0725768   -0.271093     -0.0684936   -0.083657    -0.182999     0.128946     0.0274828    0.201226      0.0952035   -0.114948     0.1828       -0.00104742  -0.0112797   -0.158178    -0.0189252    0.0218342    0.00374511   0.0869503    0.0710552    0.0859707  -0.0102035    0.157294     0.131366
 -0.0808708    0.0810824    -0.0443729    0.06173      0.116261      0.095699    -0.0529482   -0.160005    -0.145271    -0.089714    -0.0662138     0.0164557   -0.0835466   -0.0471727    -0.0825189    0.0594563    0.00955762   0.107746     0.131431     0.0516859    0.180439     0.125038     0.0919085   0.138638     0.0319281   -0.0428294kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3681234528155686
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368187
[ Info: iteration 2, average log likelihood -1.368126
[ Info: iteration 3, average log likelihood -1.367615
[ Info: iteration 4, average log likelihood -1.360557
[ Info: iteration 5, average log likelihood -1.340276
[ Info: iteration 6, average log likelihood -1.332306
[ Info: iteration 7, average log likelihood -1.331469
[ Info: iteration 8, average log likelihood -1.331206
[ Info: iteration 9, average log likelihood -1.331062
[ Info: iteration 10, average log likelihood -1.330963
[ Info: iteration 11, average log likelihood -1.330883
[ Info: iteration 12, average log likelihood -1.330809
[ Info: iteration 13, average log likelihood -1.330734
[ Info: iteration 14, average log likelihood -1.330653
[ Info: iteration 15, average log likelihood -1.330560
[ Info: iteration 16, average log likelihood -1.330452
[ Info: iteration 17, average log likelihood -1.330323
[ Info: iteration 18, average log likelihood -1.330165
[ Info: iteration 19, average log likelihood -1.329985
[ Info: iteration 20, average log likelihood -1.329788
[ Info: iteration 21, average log likelihood -1.329575
[ Info: iteration 22, average log likelihood -1.329339
[ Info: iteration 23, average log likelihood -1.329077
[ Info: iteration 24, average log likelihood -1.328770
[ Info: iteration 25, average log likelihood -1.328308
[ Info: iteration 26, average log likelihood -1.327585
[ Info: iteration 27, average log likelihood -1.326932
[ Info: iteration 28, average log likelihood -1.326500
[ Info: iteration 29, average log likelihood -1.326187
[ Info: iteration 30, average log likelihood -1.325932
[ Info: iteration 31, average log likelihood -1.325733
[ Info: iteration 32, average log likelihood -1.325600
[ Info: iteration 33, average log likelihood -1.325519
[ Info: iteration 34, average log likelihood -1.325470
[ Info: iteration 35, average log likelihood -1.325440
[ Info: iteration 36, average log likelihood -1.325423
[ Info: iteration 37, average log likelihood -1.325412
[ Info: iteration 38, average log likelihood -1.325405
[ Info: iteration 39, average log likelihood -1.325400
[ Info: iteration 40, average log likelihood -1.325397
[ Info: iteration 41, average log likelihood -1.325395
[ Info: iteration 42, average log likelihood -1.325394
[ Info: iteration 43, average log likelihood -1.325393
[ Info: iteration 44, average log likelihood -1.325392
[ Info: iteration 45, average log likelihood -1.325392
[ Info: iteration 46, average log likelihood -1.325392
[ Info: iteration 47, average log likelihood -1.325391
[ Info: iteration 48, average log likelihood -1.325391
[ Info: iteration 49, average log likelihood -1.325391
[ Info: iteration 50, average log likelihood -1.325391
┌ Info: EM with 100000 data points 50 iterations avll -1.325391
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3681872071976269
│     -1.3681258989207965
│      ⋮
└     -1.3253910730721745
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325490
[ Info: iteration 2, average log likelihood -1.325406
[ Info: iteration 3, average log likelihood -1.325001
[ Info: iteration 4, average log likelihood -1.321245
[ Info: iteration 5, average log likelihood -1.308919
[ Info: iteration 6, average log likelihood -1.298630
[ Info: iteration 7, average log likelihood -1.295619
[ Info: iteration 8, average log likelihood -1.294498
[ Info: iteration 9, average log likelihood -1.293809
[ Info: iteration 10, average log likelihood -1.293251
[ Info: iteration 11, average log likelihood -1.292683
[ Info: iteration 12, average log likelihood -1.292039
[ Info: iteration 13, average log likelihood -1.291316
[ Info: iteration 14, average log likelihood -1.290552
[ Info: iteration 15, average log likelihood -1.289782
[ Info: iteration 16, average log likelihood -1.289087
[ Info: iteration 17, average log likelihood -1.288623
[ Info: iteration 18, average log likelihood -1.288319
[ Info: iteration 19, average log likelihood -1.288085
[ Info: iteration 20, average log likelihood -1.287876
[ Info: iteration 21, average log likelihood -1.287673
[ Info: iteration 22, average log likelihood -1.287459
[ Info: iteration 23, average log likelihood -1.287232
[ Info: iteration 24, average log likelihood -1.286995
[ Info: iteration 25, average log likelihood -1.286765
[ Info: iteration 26, average log likelihood -1.286585
[ Info: iteration 27, average log likelihood -1.286451
[ Info: iteration 28, average log likelihood -1.286348
[ Info: iteration 29, average log likelihood -1.286265
[ Info: iteration 30, average log likelihood -1.286196
[ Info: iteration 31, average log likelihood -1.286137
[ Info: iteration 32, average log likelihood -1.286084
[ Info: iteration 33, average log likelihood -1.286039
[ Info: iteration 34, average log likelihood -1.285999
[ Info: iteration 35, average log likelihood -1.285964
[ Info: iteration 36, average log likelihood -1.285932
[ Info: iteration 37, average log likelihood -1.285902
[ Info: iteration 38, average log likelihood -1.285873
[ Info: iteration 39, average log likelihood -1.285844
[ Info: iteration 40, average log likelihood -1.285812
[ Info: iteration 41, average log likelihood -1.285778
[ Info: iteration 42, average log likelihood -1.285743
[ Info: iteration 43, average log likelihood -1.285706
[ Info: iteration 44, average log likelihood -1.285671
[ Info: iteration 45, average log likelihood -1.285640
[ Info: iteration 46, average log likelihood -1.285613
[ Info: iteration 47, average log likelihood -1.285591
[ Info: iteration 48, average log likelihood -1.285575
[ Info: iteration 49, average log likelihood -1.285562
[ Info: iteration 50, average log likelihood -1.285553
┌ Info: EM with 100000 data points 50 iterations avll -1.285553
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3254899403687872
│     -1.3254057403056858
│      ⋮
└     -1.2855528338068762
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.285708
[ Info: iteration 2, average log likelihood -1.285537
[ Info: iteration 3, average log likelihood -1.284885
[ Info: iteration 4, average log likelihood -1.279624
[ Info: iteration 5, average log likelihood -1.265238
[ Info: iteration 6, average log likelihood -1.252086
[ Info: iteration 7, average log likelihood -1.245607
[ Info: iteration 8, average log likelihood -1.241430
[ Info: iteration 9, average log likelihood -1.237826
[ Info: iteration 10, average log likelihood -1.234757
[ Info: iteration 11, average log likelihood -1.231847
[ Info: iteration 12, average log likelihood -1.228945
[ Info: iteration 13, average log likelihood -1.226696
[ Info: iteration 14, average log likelihood -1.225207
[ Info: iteration 15, average log likelihood -1.224385
[ Info: iteration 16, average log likelihood -1.223856
[ Info: iteration 17, average log likelihood -1.223432
[ Info: iteration 18, average log likelihood -1.223117
[ Info: iteration 19, average log likelihood -1.222906
[ Info: iteration 20, average log likelihood -1.222752
[ Info: iteration 21, average log likelihood -1.222629
[ Info: iteration 22, average log likelihood -1.222525
[ Info: iteration 23, average log likelihood -1.222439
[ Info: iteration 24, average log likelihood -1.222368
[ Info: iteration 25, average log likelihood -1.222312
[ Info: iteration 26, average log likelihood -1.222273
[ Info: iteration 27, average log likelihood -1.222248
[ Info: iteration 28, average log likelihood -1.222234
[ Info: iteration 29, average log likelihood -1.222226
[ Info: iteration 30, average log likelihood -1.222221
[ Info: iteration 31, average log likelihood -1.222219
[ Info: iteration 32, average log likelihood -1.222218
[ Info: iteration 33, average log likelihood -1.222218
[ Info: iteration 34, average log likelihood -1.222217
[ Info: iteration 35, average log likelihood -1.222217
[ Info: iteration 36, average log likelihood -1.222217
[ Info: iteration 37, average log likelihood -1.222217
[ Info: iteration 38, average log likelihood -1.222217
[ Info: iteration 39, average log likelihood -1.222217
[ Info: iteration 40, average log likelihood -1.222217
[ Info: iteration 41, average log likelihood -1.222217
[ Info: iteration 42, average log likelihood -1.222217
[ Info: iteration 43, average log likelihood -1.222217
[ Info: iteration 44, average log likelihood -1.222217
[ Info: iteration 45, average log likelihood -1.222217
[ Info: iteration 46, average log likelihood -1.222217
[ Info: iteration 47, average log likelihood -1.222217
[ Info: iteration 48, average log likelihood -1.222217
[ Info: iteration 49, average log likelihood -1.222217
[ Info: iteration 50, average log likelihood -1.222217
┌ Info: EM with 100000 data points 50 iterations avll -1.222217
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2857079803622449
│     -1.2855374109491813
│      ⋮
└     -1.2222170277329774
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.222433
[ Info: iteration 2, average log likelihood -1.222177
[ Info: iteration 3, average log likelihood -1.220533
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.204560
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.179505
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.168726
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.164024
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.155912
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.149553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.150471
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.144895
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.155917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.153691
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.139357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.152032
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.150878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.143829
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.154503
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.152938
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.137895
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.151302
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.150354
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.142962
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.154162
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.152780
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.137686
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.151224
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.150328
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.142949
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.154116
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.152759
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.137742
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.151164
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.150251
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.142913
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.153669
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.151824
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.136412
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.148766
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.147586
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.140490
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.151245
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.149890
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.135274
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.148437
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.147440
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.140314
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.151189
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.149855
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.135229
┌ Info: EM with 100000 data points 50 iterations avll -1.135229
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2224333050703085
│     -1.2221774317906229
│      ⋮
└     -1.135228575792954
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.148605
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.137297
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.130076
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.126989
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.087383
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.059303
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     10
│     12
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070798
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062266
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044479
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.055756
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     12
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.041882
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.044345
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.054053
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      9
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.034434
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.038066
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.061684
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.045656
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.029439
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.056807
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.048982
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.035778
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.055852
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.035256
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.015585
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.069176
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039304
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.033323
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.040035
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.036905
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.041714
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.055027
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.046374
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.028899
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.035578
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057991
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.037809
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051168
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.028896
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.030980
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.047584
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│     12
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.040620
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.037292
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.045106
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.016314
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.039313
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.044261
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.028738
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      8
│      9
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031595
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.024083
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│      8
│     23
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.042675
┌ Info: EM with 100000 data points 50 iterations avll -1.042675
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1486049129800668
│     -1.1372974315621571
│      ⋮
└     -1.0426751383488446
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3681234528155686
│     -1.3681872071976269
│     -1.3681258989207965
│     -1.3676153266409063
│      ⋮
│     -1.031595132106839
│     -1.024083310160447
└     -1.0426751383488446
32×26 Array{Float64,2}:
 -0.0254555    -0.00155126   0.0159637   0.121477     -0.0239082   -0.0827013   0.0143333   -0.0183633   -0.0813585    -0.0592911  -0.00142189  -0.0344211    -0.0473895   -0.0805586    0.08968       0.0513501   -0.091641     0.0941105   0.0909172   -0.09641      0.204697    -0.123893     0.0185467    0.00470918  -0.104857     0.00136529
  0.099708      0.141283    -0.122234    0.0391848     0.141798    -0.0935179  -0.0851534   -0.0223054    0.098517      0.0873624   0.115925    -0.224967     -0.0960504   -0.00740772   0.0646801    -0.0453236    0.132516    -0.258897   -0.0577701   -0.099427     0.0648188   -0.0767288   -0.0285049   -0.0649527    0.00795549   0.163497
 -0.113903     -0.124119    -0.0620669   0.122683     -0.254159    -0.0674759  -0.0950026   -0.178438     0.132186      0.033967    0.187277     0.0599182    -0.134347     0.196953    -0.020961     -0.03817     -0.205337     0.0112634   0.0467209   -0.489043     0.0610024    0.111996     0.0754114   -0.0624215    0.181977     0.130893
 -0.121829      0.032982    -0.0378593   0.0242596    -0.405308    -0.079388   -0.0659375   -0.189387     0.124965      0.036039    0.207768     0.0921134    -0.104404     0.15015      0.0929511    -0.0267784   -0.137572    -0.0360859   0.0112686    0.544314     0.107717     0.0455419    0.0924558    0.0850701    0.142191     0.131519
  0.0234545     0.069553     0.172773    0.117783      0.0830594   -0.0858431  -0.0240519   -0.0318386    0.106697     -0.0215578   0.0738311   -0.147774     -0.0188688    0.0694371   -0.165587      0.108743     0.0794151    0.16892    -0.0469983    0.174834    -0.0543395    0.128675    -0.077198    -0.073587     0.00233817   0.0435359
  0.0182619    -0.0504518   -0.0203771   0.157628      0.0269155    0.188632   -0.0221066    0.0105716    0.107428      0.0324732   0.0574295    0.0465022    -0.15201      0.00795328  -0.0408879     0.0084632    0.212564     0.198207    0.00472031   0.05734      0.0273444    0.0739078    0.0826938    0.120233     0.102103    -0.0289166
 -0.0356844     0.0705561   -0.0166876   0.112822      0.0943745   -0.0956757  -0.183763    -0.024544    -0.0912141    -0.164633   -0.132988    -0.000504245  -1.58605      0.246624    -0.147908      0.15875      0.0265817    0.172214    0.57292      0.0257023   -0.0847187    0.0105842   -0.0886855   -0.424224    -0.0352344    0.0561545
 -0.194883      0.0595099    0.452642    0.115959      0.108489    -0.0976127   0.116838    -0.0598047    0.884898      0.195114    0.209602    -0.47062       0.81393      0.0573279   -0.183943      0.0805177    0.0672855    0.166844    0.686278     0.439404    -0.0131821    0.257819    -0.213955    -0.836948     0.140576     0.0295423
  0.0804223     0.0957723    0.0279248   0.0156464    -0.0211263   -0.115762   -0.0191531    0.062633    -0.0980656     0.127339    0.14964     -0.0178966    -0.168605    -0.0723345    0.0543388     0.0321079   -0.101316     0.0234131   0.0227871   -0.0420865    0.00762447   0.00540322  -0.121065    -0.00243589   0.022585    -0.0394579
  0.0650327     0.00185473  -0.199431   -0.0205368    -0.0238487   -0.118072   -0.00956564   0.066047    -0.211365      0.022865   -0.100995    -0.154564      0.202912    -0.174027     0.158858     -0.0439356   -0.122975    -0.119026   -0.0374453   -0.0990047    0.170491     0.00124403   0.0599365    0.119193    -0.0555094   -0.0530581
  0.131589     -0.0522774    0.106666    0.0719696     0.130008    -0.102463   -0.0198456   -0.00750205  -0.000132862  -0.0220545  -0.0169244   -0.2346       -0.125583     0.137386     0.0296261    -0.156344    -0.0138776   -0.0320152  -0.0100572    0.0190108    0.145937     0.0619799    0.0300692   -0.215039    -0.0555139    0.0986962
 -0.0972766    -0.0537094    0.115968    0.0115998    -0.00776613   0.0214897   0.0729988    0.0758345   -0.150966     -0.0170533   0.131013     0.199888     -0.202376     0.0114316   -0.0422588    -0.0289417   -0.105018    -0.109677    0.106866     0.103978     0.128094     0.10122     -0.0199216    0.0380203    0.0520587    0.246408
  0.0503123    -0.0319873    0.0189022  -0.102219     -0.0972593   -0.12433    -0.118753    -0.0158985   -0.0299828    -0.0526314   0.0582089    0.0331709    -0.210524    -0.217862    -0.0192981    -0.147387    -0.0725265   -0.0125455   0.0786443    0.08083     -0.0540374   -0.0505556   -0.115725    -0.0077383   -0.0207744    0.152241
  0.195638     -0.030712    -0.0838988   0.145705     -0.0632842    0.0351421   0.0180252    0.0231288   -0.0133897    -0.180502    0.0229987    0.10366      -0.194249     0.0818933    0.0259036     0.178322    -0.0723598    0.13306    -0.0135317   -0.0558225    0.120523     0.0394531   -0.0333068   -0.0418664    0.208222     0.118377
 -0.0877766    -0.0230917   -0.0233759   0.0739005     0.125441    -0.176515    0.0242431   -0.0550804    0.0443195    -0.0849572  -0.153916    -0.0706179     0.0344242    0.0797848    0.131288     -0.0412471   -0.0219498    0.0432858   0.00651324   0.0989418    0.0369463   -0.0412035   -0.0146456   -0.417789    -0.0709142   -0.0673021
 -0.119153     -0.0878179   -0.011555    0.130481      0.231911    -0.186249    0.0410344   -0.210829     0.154116     -0.100358   -0.176275    -0.00644492    0.137667     0.00776812   0.0865935    -0.0768422   -0.0410315    0.0411819   0.00355068   0.114769     0.031659     0.00917364  -0.00179384   0.510784     0.035037    -0.199691
  0.0245912     0.0136599   -0.0322172  -0.0586425    -0.101788     0.216139   -0.105062     0.0135633    0.0443721     0.0992871  -0.00377435   0.06196      -0.155277     0.157358     0.03258       0.0209549    0.0556895    0.0451443   0.0120577   -0.0212373   -0.179399     0.0369134   -0.0445531   -0.161645    -0.0912283   -0.0214129
 -0.0512824    -0.108173     0.0702924   0.0234548    -0.00456905  -0.0271205  -0.0592909   -0.0184407   -0.105065      0.152017    0.0534726    0.241138     -0.00995963   0.00273918   0.0995579     0.00103753  -0.077536    -0.0650463  -0.0701242   -0.184623    -0.0836862   -0.022696    -0.0836619    0.153389     0.0507651   -0.113098
 -0.000628634  -0.0484928   -0.0606594  -0.0369043     0.0139248   -0.140822    0.0226053   -0.0223978   -0.0248976     0.0128131   0.0836219   -0.0797642    -0.0301826    0.0270202   -0.0634159    -0.0338724    0.00119183   0.035687    0.00938507  -0.00800169  -0.081292     0.157522     0.00121551  -0.0417601   -0.129218     0.0679425
 -0.0393023     0.135506    -0.0347516   0.0489963    -0.0545248    0.072348   -0.0498951    0.0945405    0.0103526    -0.0562429   0.183622    -0.0372944     0.06556     -0.0113931   -0.0917557     0.0417591    0.00953172  -0.0080011   0.0139835    0.0394325    0.0316745   -0.0762366   -0.0774669    9.35037e-5  -0.0738839    0.00710399
 -0.0472324    -0.00704364  -0.0220299   0.0798553    -0.0010074   -0.032851   -0.077108    -0.085694     0.154746      0.0600383  -0.00404206  -0.0189166    -0.0166798    0.0426379   -0.122354      0.0972856    0.0687143   -0.101774    0.00226813  -0.104595     0.0998781   -0.00457571  -0.110713     0.0643337    0.02271      0.0511408
 -0.0318378     0.102073    -0.0484072  -0.0685399     0.08337     -0.0365671  -0.117259     0.00597783   0.117766      0.0647437   0.114861     0.0799262    -0.0158034    0.0654077   -0.0496047     0.0541826    0.0151597    0.0138823  -0.0685142   -0.0165441    0.0355894   -0.173388    -0.0183226   -0.0601986   -0.0217286   -0.0443276
  0.0391222     0.0416487   -0.180073    0.190843      0.250279     0.0267458   0.21016     -0.0368886    0.00168195    0.114161    0.132891     0.0273283     0.130167    -0.0628896    0.0104324    -0.016145     0.00493275   0.070029    0.0484819    0.185478    -0.00575073   0.0128844    0.00239553   0.0530937   -0.0910877   -0.0224397
  0.0840561    -0.00971901  -0.0811271  -0.0459822     0.0455011   -0.161974    0.0924195   -0.0835004   -0.00600633   -0.0794921   0.0622078   -0.134031      0.324605    -0.10445     -0.00159916   -0.286187     0.102334    -0.033348   -0.061633     0.15552      0.051618     0.0401309    0.102933     0.123768     0.127645     0.132815
 -0.131694      0.0454675    0.131399   -0.117649     -0.161672     0.0121117  -0.0326471    0.0573348   -0.188467      0.0619048  -0.0294466   -0.120525     -0.0720486   -0.0993592    0.0011885     0.0816245    0.0824672   -0.0461614   0.073718     0.0674448    0.0360529   -0.0102508    0.140459    -0.0102988   -0.0764898   -0.295875
  0.0389272     0.105956    -0.063337   -0.0717275    -0.0507967    0.0389872  -0.0737288   -0.0488829   -0.076059      0.195       0.0147003    0.00729439   -0.109131    -0.12504      0.079027     -0.0929317    0.160208    -0.0656845   0.0241243    0.0123544   -0.0313107    0.0932994    0.0757655    0.0326798    0.0905632   -0.0623373
  0.0310209     4.14072e-5  -0.107008   -0.000406207   0.00951265   0.0241761  -0.02234     -0.0211243   -0.0285037     0.107121    0.0350667   -0.00305269   -0.0793789   -0.0994018   -0.0459303     0.0364157   -0.12113     -0.062957   -0.0526995   -0.0835261    0.137529    -0.188644    -0.0616172    0.0115446    0.0427066    0.0521942
  0.312572     -0.108205     0.163449    0.0924507    -0.156174    -0.106446   -0.103576     0.102135    -0.0216533    -0.0124316   0.158972     0.130306      0.0569473    0.117156     0.0965435    -0.0570218    0.0300951   -0.160063   -0.0572951   -0.233037    -0.0453242   -0.0938686    0.0825266    0.138236     0.0765974   -0.00307872
  0.0305288    -0.0259542   -0.0103333   0.0483426     0.13237      0.131362   -0.0805779   -0.00237395  -0.0895647     0.0580343   0.0743951    0.050294     -0.0512112   -0.145468    -0.000293171   0.128367     0.122808    -0.0272668  -0.150427    -0.183204    -0.0571773   -0.0677299   -0.00537976  -0.0199809   -0.0931204   -0.0241525
 -0.00369066   -0.0930118    0.15031     0.206359      0.155018     0.0974752  -0.033311    -0.0428971   -0.0445268    -0.112242    0.139537    -0.161039     -0.0933199    0.0344067   -0.0422155    -0.0621753   -0.201703    -0.0379652  -0.0417208    0.0530959   -0.0515832   -0.0928289   -0.0746641    0.0922414    0.138122    -0.0582736
 -0.237131      0.164752    -0.81402     0.0617125     0.118985     0.0618793  -0.0563442   -0.186044    -0.150793      0.132076   -0.0553939   -0.0896001    -0.081996    -0.040579    -0.0831517    -0.0273195   -0.0629697   -0.0606996  -0.07767      0.112499     0.256727     0.131243     0.0793407    0.0591998    0.0325505   -0.0426468
  0.0293926     0.0599875    0.59326     0.0617926     0.113121     0.0532389  -0.0609656   -0.129481    -0.134726     -0.287394   -0.078433     0.111346     -0.0812814   -0.0640824    0.0157541     0.198158     0.0772233    0.279491    0.366512     0.0430222    0.0825915    0.121909     0.0877946    0.191977     0.0312925   -0.0477466[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.027199
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.010702
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.003000
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.002832
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.008213
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.010816
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     12
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.014560
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.999359
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.008168
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.007279
┌ Info: EM with 100000 data points 10 iterations avll -1.007279
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       7.904542e+05
      1       6.306111e+05      -1.598431e+05 |       32
      2       5.960839e+05      -3.452716e+04 |       32
      3       5.822441e+05      -1.383978e+04 |       32
      4       5.758512e+05      -6.392888e+03 |       32
      5       5.724746e+05      -3.376595e+03 |       32
      6       5.703305e+05      -2.144145e+03 |       32
      7       5.687856e+05      -1.544854e+03 |       32
      8       5.678528e+05      -9.328954e+02 |       32
      9       5.671914e+05      -6.613887e+02 |       32
     10       5.665418e+05      -6.495764e+02 |       32
     11       5.658725e+05      -6.693217e+02 |       32
     12       5.651603e+05      -7.121600e+02 |       32
     13       5.644110e+05      -7.492856e+02 |       32
     14       5.637737e+05      -6.373466e+02 |       32
     15       5.632866e+05      -4.870951e+02 |       32
     16       5.629406e+05      -3.459640e+02 |       32
     17       5.624647e+05      -4.759527e+02 |       32
     18       5.614258e+05      -1.038900e+03 |       32
     19       5.595701e+05      -1.855709e+03 |       32
     20       5.581153e+05      -1.454716e+03 |       32
     21       5.572571e+05      -8.582721e+02 |       32
     22       5.568822e+05      -3.748525e+02 |       32
     23       5.567585e+05      -1.237362e+02 |       32
     24       5.567109e+05      -4.754126e+01 |       31
     25       5.566737e+05      -3.720336e+01 |       32
     26       5.566432e+05      -3.054770e+01 |       32
     27       5.566099e+05      -3.329695e+01 |       30
     28       5.565788e+05      -3.111544e+01 |       31
     29       5.565542e+05      -2.453479e+01 |       30
     30       5.565336e+05      -2.058760e+01 |       30
     31       5.565176e+05      -1.607724e+01 |       29
     32       5.565023e+05      -1.524459e+01 |       28
     33       5.564887e+05      -1.361960e+01 |       27
     34       5.564767e+05      -1.200635e+01 |       27
     35       5.564675e+05      -9.190274e+00 |       29
     36       5.564608e+05      -6.693093e+00 |       23
     37       5.564569e+05      -3.869033e+00 |       24
     38       5.564532e+05      -3.732166e+00 |       25
     39       5.564493e+05      -3.869657e+00 |       25
     40       5.564455e+05      -3.848507e+00 |       23
     41       5.564420e+05      -3.535179e+00 |       24
     42       5.564367e+05      -5.286832e+00 |       24
     43       5.564301e+05      -6.536512e+00 |       27
     44       5.564218e+05      -8.362112e+00 |       26
     45       5.564132e+05      -8.588181e+00 |       27
     46       5.563998e+05      -1.341010e+01 |       26
     47       5.563770e+05      -2.276961e+01 |       29
     48       5.563362e+05      -4.082352e+01 |       32
     49       5.562757e+05      -6.047965e+01 |       31
     50       5.562028e+05      -7.295699e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 556202.75053695)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.276250
[ Info: iteration 2, average log likelihood -1.246361
[ Info: iteration 3, average log likelihood -1.214968
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.170712
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.135918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.083201
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.023731
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.048480
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.033038
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.004310
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.012917
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.017312
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.027480
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.037871
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.004233
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.013601
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.052298
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.015552
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     15
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.985469
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.051402
[ Info: iteration 21, average log likelihood -1.051467
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     12
│     15
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.989136
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.039095
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.033784
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.015343
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.019455
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.026469
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     13
│     17
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.001756
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.050264
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.019991
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     12
│     13
│     18
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.990711
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.035942
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046906
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.009324
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     15
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.008290
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.027505
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.039528
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.011981
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.006955
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     17
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.021471
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.057634
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.005769
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     18
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.991927
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.040442
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.029037
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      8
│     15
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.008257
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.029630
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.029791
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.007163
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.014940
┌ Info: EM with 100000 data points 50 iterations avll -1.014940
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0150056   0.00487664   0.0790062    0.137796      0.0590315    0.0564052   -0.0275267    -0.00847855   0.12199      0.00313507   0.0619176   -0.0501501   -0.106992    0.0423497   -0.102921     0.0602255    0.149823      0.185276    0.0083674    0.121368    -0.0135414     0.0989114     0.00409901   0.00225025   0.0574617    0.00547711
 -0.136594    0.0458427    0.130837    -0.117971     -0.16985      0.0111843   -0.0244534     0.0587602   -0.189915     0.0711851   -0.0340454   -0.120284    -0.0655731  -0.0965982    0.00169793   0.0869788    0.0834886    -0.040538    0.0814784    0.0670606    0.0393605    -0.0150003     0.142203    -0.0112441   -0.0772225   -0.307116
 -0.104299    0.0347193   -0.0100313    0.00269429   -0.0938097   -0.109931    -0.00411697    0.0744745   -0.0467357   -0.0232014    0.0448297   -0.0349356   -0.0232395  -0.0147499   -0.0456746    0.00700367   0.0966642     0.0200031  -0.0534916    0.0743464   -0.150036     -0.0736898     0.132825    -0.131532    -0.104427     0.174017
 -0.0285033  -0.00348001   0.0223883    0.14623      -0.0195832   -0.0832067    0.0275317    -0.0219655   -0.090115    -0.0588031   -0.00104061  -0.0350535   -0.0430404  -0.0778558    0.0972307    0.0595588   -0.0977568     0.102366    0.0973202   -0.111608     0.213999     -0.122501      0.0275786    0.00779513  -0.108275     6.27619e-5
  0.0457736   0.0382575   -0.0875449    0.0720099    -0.0411155   -0.0205809   -0.0736313    -0.16055      0.11696      0.0703751   -0.0335325    0.0181607   -0.0460911  -0.0243291   -0.184918     0.114954     0.0351937    -0.128432    0.0849257   -0.127312     0.0214404     0.123416     -0.0955435    0.0246171   -0.0171066   -0.0890612
 -0.175247   -0.0493741    0.0216597    0.118445      0.0540366   -0.0309927   -0.08538       0.00571805   0.181693     0.0384879    0.0296887   -0.0640451    0.0414364   0.124451    -0.0669412    0.101296     0.124058     -0.0831609  -0.089685    -0.0800452    0.202446     -0.147358     -0.136713     0.122289     0.0806701    0.198612
  0.09965     0.141944    -0.122341     0.0393575     0.141955    -0.0943984   -0.0853402    -0.0217371    0.0974561    0.0852247    0.11558     -0.224408    -0.0946553  -0.00763623   0.0660123   -0.0468715    0.134569     -0.25881    -0.058503    -0.0994098    0.0655658    -0.0758269    -0.0290656   -0.0648769    0.00846983   0.163114
  0.025916   -0.032663     0.0530531   -0.171933     -0.0886719   -0.0621226   -0.134655      0.00572425  -0.0262073   -0.0121214    0.0671338   -0.0352914   -0.187426   -0.214272    -0.0327967   -0.184955    -0.0819872    -0.0610323   0.109046     0.13399     -0.100689     -0.0882772    -0.143622    -0.015233    -0.0929468    0.14164
 -0.0915483   0.13578     -0.0356758    0.00234429    0.10956      0.012605    -0.137411     -0.0610975    0.127012     0.135516     0.0836371    0.165801    -0.0632916   0.19411     -0.127268     0.0947157    0.124947     -0.0524208   0.0842358   -0.0273266   -0.0342462    -0.215269     -0.118295    -0.014755    -0.0814062   -0.0247199
  0.118409   -0.0506055    0.108225     0.0727151     0.135988    -0.0951984   -0.0105792    -0.00800232  -0.0065179   -0.0255322   -0.00763449  -0.222866    -0.128391    0.148609     0.0288247   -0.161404    -0.0169223    -0.0394257  -0.00647709   0.0188304    0.152367      0.0661296     0.0229035   -0.212779    -0.0498172    0.108345
  0.181467   -0.0287777   -0.0731085    0.118861     -0.0683081    0.0226025   -0.000392718   0.0211907   -0.0107317   -0.167656     0.0261034    0.10082     -0.193679    0.0501779    0.0217675    0.152704    -0.07373       0.117962   -0.0042071   -0.0420516    0.0969702     0.0328479    -0.0460122   -0.0374909    0.189157     0.120016
 -0.214433    0.174834    -0.13138      0.0632799     0.120757     0.0574468   -0.0611826    -0.165283    -0.163042    -0.108966    -0.0422583    0.00725595  -0.0810198  -0.0407204   -0.0418194    0.0677423    0.000701729   0.202383    0.318969     0.171943     0.194222      0.103731      0.0693255    0.105726     0.00866504  -0.0503524
  0.0771587   0.0396708   -0.0136729    0.0403055     0.0844845    0.0154308   -0.0313351    -0.158482    -0.118293    -0.116388    -0.100173     0.0856995   -0.0601083  -0.0526056    0.0351623    0.0750622   -0.0266431     0.0224422   0.182428    -0.0195586    0.221015      0.143491      0.0796847    0.121305     0.0354542   -0.0357863
  0.065493    0.00168552  -0.199332    -0.021453     -0.0229227   -0.118036    -0.00990857    0.0661813   -0.211835     0.0218914   -0.100837    -0.15458      0.202829   -0.173131     0.158898    -0.0432134   -0.123427     -0.118423   -0.0374611   -0.0964538    0.169735      0.000511818   0.0594558    0.118723    -0.0564774   -0.0564225
  0.057704   -0.0413097    0.00331998   0.0631032     0.157275     0.144603    -0.0663744    -0.00959283  -0.0833626    0.0969522    0.0639794    0.0506946   -0.0539722  -0.126229    -0.00341393   0.170681     0.155795     -0.060259   -0.314244    -0.272848    -0.0718649    -0.0456429     0.0126765   -0.00396465  -0.0790016   -0.0454847
  0.0245668   0.0148115   -0.0322827   -0.058673     -0.100789     0.218671    -0.105248      0.0132793    0.0437001    0.0991767   -0.00681883   0.0620324   -0.154887    0.157509     0.0340197    0.0228884    0.0566235     0.0462663   0.0121814   -0.0214958   -0.179463      0.0370337    -0.0434578   -0.160865    -0.0917316   -0.0219452
  0.14189    -0.0595311   -0.310261     0.000985199   0.00107552  -0.0179621    0.0487379    -0.11532     -0.0201271   -0.044373     0.192253    -0.0738685   -0.0157476  -0.0737094    0.0440931   -0.0483883   -0.0968392    -0.145606    0.0118329   -0.0877412    0.103664     -0.281269     -0.154633     0.00911878   0.0507254   -0.00648804
 -0.0993148  -0.0609347    0.115406     0.014263     -0.018738     0.0187132    0.0782816     0.070415    -0.154213    -0.0221191    0.138644     0.210183    -0.204732    0.00148021  -0.0431124   -0.0202972   -0.108061     -0.115581    0.114025     0.111762     0.125732      0.106018     -0.0170184    0.0461997    0.0522899    0.251752
  0.083494   -0.0122186   -0.0830149   -0.0456992     0.0454764   -0.163274     0.0929365    -0.0854769   -0.00541648  -0.0836859    0.0627877   -0.134586     0.330389   -0.105079    -0.00102519  -0.287977     0.102763     -0.0332904  -0.0648431    0.155058     0.0530421     0.0400656     0.103225     0.125761     0.12754      0.138363
  0.0397017   0.105903    -0.0634151   -0.0720971    -0.0496372    0.0383713   -0.0728592    -0.0495579   -0.0769173    0.198349     0.0146383    0.00790143  -0.109642   -0.126294     0.0780308   -0.0924749    0.163054     -0.0658406   0.0231227    0.0120943   -0.0324079     0.0931349     0.0800172    0.0313533    0.0911384   -0.0635109
 -0.052885   -0.107307     0.0696891    0.0242573    -0.00475339  -0.0242295   -0.0594356    -0.0218803   -0.105927     0.150912     0.0534756    0.241921    -0.0106322   0.00195708   0.0997524    0.00477947  -0.0778432    -0.0598402  -0.0682302   -0.186654    -0.0869537    -0.0218962    -0.0809068    0.154925     0.0503697   -0.114485
 -0.0550467   0.0573254    0.0189691    0.0573795     0.0460966    0.0797856   -0.0658218     0.0625844   -0.0403154    0.276113    -0.108799     0.0505894   -0.113918   -0.108202    -0.137041     0.164203    -0.16236       0.0127381  -0.147648    -0.128719     0.213956     -0.17094       0.0301697    0.00838074   0.0609984    0.0850152
 -0.105233   -0.0545426   -0.0175892    0.101807      0.179368    -0.18144      0.0316109    -0.130412     0.0997012   -0.0943558   -0.165582    -0.0408654    0.0841968   0.0469103    0.109366    -0.0558626   -0.0310932     0.0401418   0.00493661   0.105655     0.0347676    -0.0170535    -0.00880864   0.0318806   -0.0175402   -0.134799
  0.0256295   0.0908993   -0.0744612   -0.131137      0.0485533   -0.0991034   -0.109471      0.0462913    0.126631    -0.0300407    0.159461     0.00386913   0.0420304  -0.0677779    0.0257469    0.0201693   -0.0907436     0.0951008  -0.253349     0.00440526   0.123328     -0.105728      0.0859883   -0.129466     0.0622674   -0.0818975
 -0.116816   -0.0483189   -0.0505593    0.0754934    -0.328439    -0.0730126   -0.0805377    -0.184004     0.129257     0.0368062    0.19799      0.0750104   -0.118974    0.176134     0.0360638   -0.0328435   -0.177158     -0.0107315   0.0296236    0.0175909    0.0832909     0.0805358     0.0838938    0.00950625   0.162575     0.131564
 -0.0639427   0.212207    -0.0768985    0.0743071    -0.0762917    0.00951344   0.0454197     0.110145     0.0727789   -0.0192621    0.215657     0.0191514    0.0802904  -0.0774647    0.124195     0.150031     0.055733      0.0635236   0.00743159   0.00596299   0.0714333    -0.126003      0.0245218   -0.00214785  -0.0468607    0.0288081
  0.0884613   0.0949525    0.0307149    0.0188004    -0.0257615   -0.115968    -0.0131171     0.0666716   -0.102098     0.144749     0.14497     -0.019163    -0.171386   -0.0689615    0.0574712    0.0355863   -0.0981808     0.0267452   0.0248461   -0.0508754   -0.000969776   0.00593742   -0.112764    -0.00373492   0.0254875   -0.0529648
 -0.0227677   0.0577595    0.01288      0.0213145    -0.0228865    0.162136    -0.144601      0.130678    -0.0550713   -0.0711805    0.168431    -0.115677     0.0698364   0.0943794   -0.363237    -0.0687005   -0.0453568    -0.0753406   0.0178287    0.063156     0.00194201   -0.026478     -0.177559     0.0110307   -0.131178     0.00101125
  0.0384523   0.0456144   -0.185453     0.183928      0.249583     0.035949     0.207134     -0.0365353    0.00031292   0.117461     0.129284     0.0287304    0.126753   -0.0622703    0.00505759  -0.0138074    0.00706231    0.0759274   0.0543872    0.183617    -0.00578022    0.0200599     0.00548106   0.0568859   -0.0885563   -0.0229415
  0.315625   -0.112864     0.16594      0.0887058    -0.148065    -0.104105    -0.101379      0.10289     -0.0160466   -0.00920554   0.15697      0.136851     0.0571835   0.116351     0.0930669   -0.0601925    0.0316878    -0.163543   -0.0616539   -0.230269    -0.04402      -0.08764       0.0783648    0.135703     0.0715562   -0.00393827
  0.08558    -0.127255    -0.125289    -0.0591624     0.13728     -0.169906     0.0606853    -0.124092     0.00432701   0.0437936    0.127555    -0.132764    -0.0201334   0.104063    -0.0848524   -0.076503    -0.0845881     0.0504415   0.0644415   -0.0989452    0.00380055    0.384087     -0.126456     0.0474481   -0.155344    -0.0479
 -0.0027284  -0.095199     0.166663     0.224166      0.165495     0.108272    -0.0319596    -0.0433194   -0.0449415   -0.115508     0.141906    -0.168276    -0.0918342   0.0661575   -0.0413283   -0.056352    -0.203657     -0.035936   -0.0508896    0.0527721   -0.0505761    -0.0925517    -0.066604     0.0971245    0.14843     -0.0734863[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.031493
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     13
│     17
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.991219
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.975289
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     12
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.998729
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     13
│     17
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.005106
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     12
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.965526
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.009918
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     12
│     17
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.993913
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      8
│     13
│      ⋮
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.971308
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.004874
┌ Info: EM with 100000 data points 10 iterations avll -1.004874
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.118269    -0.0771286    0.0466264     0.117768     0.252386     0.129308    -0.11184      0.199792      0.0252184   -0.0515385   -0.0391206    0.0751308    0.0204674   -0.110991      0.0316315    0.0693168  -0.0582201    0.00959484   0.0441767    0.0333679     0.00473961  -0.0426116   -0.0722743    0.163484     -0.046676     0.0208545
  0.0590553    0.0643481   -0.0470875     0.172638    -0.0613044   -0.0271855    0.0575136   -0.136853     -0.0636525   -0.019019     0.0523587    0.0369835   -0.134188     0.0988988     0.0787966   -0.100856    0.00953808  -0.126369     0.00205683  -0.0520871    -0.148871    -0.0661235    0.0594588   -0.0296524    -0.0828343    0.0187557
 -0.0130261    0.0580824   -0.0554527     0.092914    -0.0709771    0.0180565   -0.0838587    0.0646944     0.0904221   -0.0868017    0.0650378    0.180247    -0.140549     0.135847      0.190181    -0.0918674  -0.0513387    0.0612754   -0.00314131   0.0424028    -0.0166134   -0.061211    -0.228736     0.0291444    -0.00444302   0.0700496
  0.10951      0.0317107    0.0405776    -0.00768499  -0.0378445   -0.0884605   -0.0747583   -0.0737877     0.183596    -0.0481437   -0.282266    -0.0697001   -0.0684067    0.0511569     0.0958446   -0.0535416   0.0480072   -0.0742946   -0.0989858    0.116407     -0.242679    -0.00216901  -0.00313679   0.0113085    -0.130584    -0.110538
 -0.0679599   -0.0274396    0.0930068     0.0442507    0.0826377   -0.0699762    0.18318      0.0189177    -0.0600852   -0.0947635   -0.00957134   0.0445099    0.175518    -0.000416132  -0.180661     0.0249358  -0.00777825  -0.0314872    0.0566612   -0.106695      0.0276964    0.20432      0.00788018  -0.210012      0.0746867   -0.242966
 -0.119276    -0.195123    -0.0639952    -0.0374473   -0.0798486    0.0911383   -0.0719421   -0.0288059    -0.134694     0.248685    -0.181235     0.0867071    0.0402537   -0.0462208     0.238144     0.0312087   0.0921906   -0.115364    -0.106341    -0.0519529    -0.0190222    0.185986    -0.011769     0.0738394    -0.0390054   -0.0933397
 -0.15995     -0.0968452    0.0442415    -0.085744    -0.0455831   -0.034916     0.0135657   -0.00773515    0.140747    -0.0586637    0.188967     0.0123748   -0.223332     0.0653996     0.041868     0.146063    0.00736465  -0.187988    -0.110466    -0.0247329     0.0135472    0.109334    -0.00883266   0.154417      0.0355199   -0.207495
 -0.0139163   -0.0807614   -0.0971086     0.103736    -0.197086    -0.0460441    0.114435    -0.033752      0.020958     0.0254338    0.0453851   -0.107404    -0.0681914   -0.0225936     0.0816439    0.0655048   0.0384561    0.201408     0.0601479    0.0413737    -0.036581    -0.069067     0.0115191    0.0466472    -0.109124    -0.0178875
  0.0490096    0.161176     0.161212     -0.189871    -0.171878    -0.00710641   0.0251732   -0.0622532    -0.0785646   -0.0280203    0.156793    -0.0393501    0.0100951    0.0142846    -0.0476091    0.117629   -0.137506     0.121419     0.0429528    0.0749315     0.118703    -0.136114     0.0625557    0.0509619    -0.0701018   -0.0989204
 -0.172655    -0.0940811    0.01366      -0.108951    -0.0139198   -0.0216117   -0.0418766   -0.0484532     0.113727     0.0654056    0.0168469   -0.06383      0.123311     0.0494486    -0.0804031    0.0939348  -0.121496    -0.0685377   -0.216226     0.000696936  -0.225988     0.0355421   -0.0590288    0.114033      0.0260624   -0.19632
  0.0898469    0.0270947   -0.125136     -0.0432028   -0.131895     0.122283    -0.18405      0.00627107   -0.0268038   -0.0436759    0.0537238   -0.00428931   0.176561     0.048537     -0.0871016    0.151506   -0.056931    -0.00995714  -0.0365378    0.000774791  -0.040353     0.113519     0.0520493   -0.0661658     0.0623529    0.0656358
 -0.151652     0.0144723   -0.0869458    -0.0825864   -0.160249    -0.141548    -0.0945893    0.0155896     0.229055     0.0560987   -0.136714     0.115702    -0.146196     0.0288501    -0.0027225   -0.056797    0.0693139    0.100425    -0.0875106   -0.102142     -0.0816799    0.120897    -0.0688406   -0.00778833   -0.0505467    0.0221934
 -0.102887     0.0357173   -0.116745      0.227251    -0.0454786    0.0609396    0.0137357   -0.0226176    -0.0918027   -0.00606945  -0.0154836   -0.0248184   -0.0532777    0.0117334    -0.0024243    0.0722741   0.1798      -0.0302552    0.135268    -0.105975     -0.0439882   -0.126579     0.0940277    0.171781     -0.193998    -0.00844742
 -0.0402238    0.112866     0.000535756  -0.00274759   0.0890005   -0.0497842    0.0271193    0.234543     -0.0111113    0.0431767    0.0419775    0.119978    -0.0747178   -0.0877714    -0.00855405   0.0613132   0.0174683    0.165504     0.083232    -0.00390282   -0.0315287    0.0103597   -0.128534    -0.105277     -0.130348     0.0503859
  0.0632597    0.0804768    0.0827011     0.0571327    0.00755208  -0.0437011    0.10159      0.0507535    -0.165275     0.0387218    0.251105    -0.118572     0.0464914   -0.0644796     0.140185    -0.0715395   0.0873744    0.0766416   -0.0127886   -0.0203259     0.0113389    0.0700378   -0.18041      0.0266795    -0.0467569    0.0273029
 -0.0414025    0.0268793    0.0657492    -0.0847232    0.124678    -0.0892159   -0.123137    -0.140984     -0.0353402    0.0271735   -0.0927528   -0.0551675   -0.0772283    0.0387182     0.102255     0.115169    0.171664     0.109728    -0.0532674   -0.0324349    -0.06862     -0.289379     0.130002    -0.030017     -0.156138     0.0319308
  0.0264331   -0.0429674   -0.0509851    -0.0488919    0.128219     0.0575051    0.22327     -0.123014     -0.0759756   -0.0673963    0.0916533    0.0370497   -0.109111    -0.00478051    0.0719105   -0.0370245   0.173565     0.0407352    0.0129597    0.0788102     0.00116322  -0.0597931   -0.174956     0.019743     -0.155378     0.0815511
 -0.0197754    0.0581387    0.0172266    -0.0956179   -0.0116834    0.0328624   -0.0148741   -0.0589023    -0.0607151    0.112326     0.123917    -0.0507719   -0.111492     0.120906     -0.0451873   -0.014052    0.156098     0.00981433   0.066651     0.1069        0.0631571    0.0508051   -0.107131     0.0615917     0.0623245   -0.139255
 -0.13357      0.00638662   0.0368053    -0.0309631   -0.141702    -0.160071    -0.168597    -0.0893592    -0.0277757    0.0702488   -0.0521268    0.109403    -0.0866682   -0.0172613     0.048425    -0.165179   -0.0469241   -0.0204354   -0.045103    -0.0725429     0.0580224    0.0151211   -0.161523    -0.0295193    -0.10511      0.0329911
 -0.160201     0.0253476    0.00466681    0.0953814   -0.207581    -0.0969556   -0.0118544    0.0334927     0.132415     0.0942148    0.282987     0.102238     0.0410526   -0.0281009     0.108423     0.164713   -0.0649769    0.0146526    0.143621    -0.235139      0.0944332    0.0436061    0.0141237    0.0230257     0.0602813   -0.00762874
  0.117359     0.0814267    0.159629      0.137286     0.177679    -0.13992     -0.0933705    0.0178579    -0.0358285   -0.165159     0.0694994   -0.135017     0.106054    -0.0815831    -0.0908227   -0.119677    0.0192822   -0.0795444    0.0199196    0.105842      0.210087    -0.135693    -0.0508689   -0.0786722     0.0832873   -0.00742318
 -0.122152     0.11454      0.0430161     0.217702     0.067955    -0.0257932   -0.0268376   -0.0228478    -0.0678744   -0.141657    -0.0515081   -0.123155    -0.00164762  -0.0166169     0.0168206    0.123477   -0.0447085   -0.0451348   -0.203892     0.158473     -0.0895014    0.010538     0.0725123   -0.0431727     0.0405215   -0.0498288
 -0.0247257    0.189666    -0.119315      0.165267     0.0779925   -0.0118958   -0.132968     0.0154637    -0.136009    -0.213618    -0.0509828    0.00761474  -0.0101123   -0.0388767    -0.0805119    0.0627822  -0.0614934   -0.145984     0.0192925   -0.0706392     0.147725    -0.0868541    0.0130835   -0.155524     -0.115359    -0.07572
 -0.00663772   0.0629613    0.0257301     0.100436     0.118796    -0.104408     0.00427263  -0.133744     -0.0302872    0.0218868   -0.0537505    0.0491892    0.0282833    0.0146948    -0.0960296    0.168375   -0.0393067    0.0158062    0.0970011   -0.0848185     0.0220928   -0.140349    -0.173243    -0.0520671    -0.0476951   -0.137713
  0.195263    -0.0613294    0.0570396     0.153694    -0.122206     0.088335     0.0257803   -0.030825     -0.120107     0.114258    -0.0560661    0.03252     -0.287343     0.0428796     0.0462543    0.0102088   0.0965554    0.0055639    0.109598     0.00556861    0.0884632   -0.0354081   -0.028956     0.000478583   0.134658     0.0355365
  0.127034     0.083056     0.0153771    -0.155089    -0.142407    -0.155777     0.135347    -0.138209     -0.0243056    0.0634721    0.0341459    0.17882      0.172446    -0.171313      0.182664    -0.137644    0.0110723    0.0973361   -0.134586     0.0768234     0.119296    -0.141196     0.1882      -0.0160454    -0.00469101  -0.217747
  0.147083     0.14168     -0.10291       0.0792533   -0.12354      0.0302046    0.0151776   -0.0458308     0.00468319   0.00909953   0.0174989    0.0244611   -0.0513428   -0.0888179    -0.177325    -0.047066    0.196649    -0.0454749   -0.110636    -0.0243988    -0.0893372   -0.199897     0.0532754   -0.00987848    0.0247248    0.102952
  0.101974    -0.101934     0.000863268  -0.199369     0.0915314    0.129735    -0.00693562  -0.000859461  -0.132021    -0.181861    -0.139593     0.00172964  -0.0523928   -0.0876073    -0.00881519   0.0138461  -0.046908     0.0411369    0.0978193    0.0583336    -0.0646139   -0.0989702    0.0320382   -0.0754388     0.0627681    0.109471
 -0.0115822   -0.16066     -0.0135748    -0.0374804    0.0845432   -0.00280109   0.0299203    0.0182092     0.0469032   -0.0559692    0.13295      0.114221    -0.0454428   -0.0095375    -0.122852    -0.0872875   0.132132     0.152958    -0.00679568   0.0424998    -0.107016    -0.0660439    0.10412     -0.0483947     0.087795     0.030793
  0.0114285   -0.0671131    0.0517644     0.0865147   -0.104744     0.0551285    0.0812255   -0.0295589    -0.0197805    0.109211    -0.0058085    0.0611866   -0.0889298   -0.0717934    -0.122983     0.176505   -0.0663337   -0.0899765    0.0253922    0.227062      0.0536908   -0.109093     0.0427436   -0.0390985    -0.110796    -0.102555
 -0.174335    -0.0813491    0.0527136    -0.0199196   -0.121949    -0.159191     0.192386    -0.0412992    -0.168372     0.00070354   0.0304016   -0.045542     0.0532658   -0.197073      0.0118739   -0.184517   -0.0179084    0.184532    -0.141888     0.0332329    -0.278627     0.0177313   -0.0558012   -3.05117e-6   -0.0648329   -0.0344571
  0.0215009   -0.0258832    0.0427208     0.0958364   -0.0994908    0.0863752    0.0403939   -0.0552451    -0.0213418   -0.00209908  -0.184198    -0.0705184    0.132119    -0.0203349    -0.119528     0.119797   -0.111039     0.028525    -0.0372587   -0.0451726    -0.0361332   -0.170514     0.214692    -0.074543     -0.0521105   -0.0158969kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.422012065281648
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422031
[ Info: iteration 2, average log likelihood -1.421972
[ Info: iteration 3, average log likelihood -1.421932
[ Info: iteration 4, average log likelihood -1.421886
[ Info: iteration 5, average log likelihood -1.421825
[ Info: iteration 6, average log likelihood -1.421730
[ Info: iteration 7, average log likelihood -1.421547
[ Info: iteration 8, average log likelihood -1.421156
[ Info: iteration 9, average log likelihood -1.420382
[ Info: iteration 10, average log likelihood -1.419209
[ Info: iteration 11, average log likelihood -1.418054
[ Info: iteration 12, average log likelihood -1.417350
[ Info: iteration 13, average log likelihood -1.417053
[ Info: iteration 14, average log likelihood -1.416945
[ Info: iteration 15, average log likelihood -1.416906
[ Info: iteration 16, average log likelihood -1.416892
[ Info: iteration 17, average log likelihood -1.416886
[ Info: iteration 18, average log likelihood -1.416883
[ Info: iteration 19, average log likelihood -1.416882
[ Info: iteration 20, average log likelihood -1.416881
[ Info: iteration 21, average log likelihood -1.416880
[ Info: iteration 22, average log likelihood -1.416880
[ Info: iteration 23, average log likelihood -1.416879
[ Info: iteration 24, average log likelihood -1.416879
[ Info: iteration 25, average log likelihood -1.416878
[ Info: iteration 26, average log likelihood -1.416878
[ Info: iteration 27, average log likelihood -1.416878
[ Info: iteration 28, average log likelihood -1.416877
[ Info: iteration 29, average log likelihood -1.416877
[ Info: iteration 30, average log likelihood -1.416877
[ Info: iteration 31, average log likelihood -1.416877
[ Info: iteration 32, average log likelihood -1.416876
[ Info: iteration 33, average log likelihood -1.416876
[ Info: iteration 34, average log likelihood -1.416876
[ Info: iteration 35, average log likelihood -1.416876
[ Info: iteration 36, average log likelihood -1.416876
[ Info: iteration 37, average log likelihood -1.416876
[ Info: iteration 38, average log likelihood -1.416876
[ Info: iteration 39, average log likelihood -1.416876
[ Info: iteration 40, average log likelihood -1.416875
[ Info: iteration 41, average log likelihood -1.416875
[ Info: iteration 42, average log likelihood -1.416875
[ Info: iteration 43, average log likelihood -1.416875
[ Info: iteration 44, average log likelihood -1.416875
[ Info: iteration 45, average log likelihood -1.416875
[ Info: iteration 46, average log likelihood -1.416875
[ Info: iteration 47, average log likelihood -1.416875
[ Info: iteration 48, average log likelihood -1.416875
[ Info: iteration 49, average log likelihood -1.416875
[ Info: iteration 50, average log likelihood -1.416875
┌ Info: EM with 100000 data points 50 iterations avll -1.416875
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4220308738955938
│     -1.421972234822851
│      ⋮
└     -1.4168749905315008
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416890
[ Info: iteration 2, average log likelihood -1.416836
[ Info: iteration 3, average log likelihood -1.416794
[ Info: iteration 4, average log likelihood -1.416748
[ Info: iteration 5, average log likelihood -1.416694
[ Info: iteration 6, average log likelihood -1.416634
[ Info: iteration 7, average log likelihood -1.416569
[ Info: iteration 8, average log likelihood -1.416503
[ Info: iteration 9, average log likelihood -1.416441
[ Info: iteration 10, average log likelihood -1.416384
[ Info: iteration 11, average log likelihood -1.416333
[ Info: iteration 12, average log likelihood -1.416289
[ Info: iteration 13, average log likelihood -1.416253
[ Info: iteration 14, average log likelihood -1.416223
[ Info: iteration 15, average log likelihood -1.416200
[ Info: iteration 16, average log likelihood -1.416182
[ Info: iteration 17, average log likelihood -1.416167
[ Info: iteration 18, average log likelihood -1.416156
[ Info: iteration 19, average log likelihood -1.416146
[ Info: iteration 20, average log likelihood -1.416137
[ Info: iteration 21, average log likelihood -1.416128
[ Info: iteration 22, average log likelihood -1.416120
[ Info: iteration 23, average log likelihood -1.416111
[ Info: iteration 24, average log likelihood -1.416102
[ Info: iteration 25, average log likelihood -1.416093
[ Info: iteration 26, average log likelihood -1.416082
[ Info: iteration 27, average log likelihood -1.416071
[ Info: iteration 28, average log likelihood -1.416059
[ Info: iteration 29, average log likelihood -1.416047
[ Info: iteration 30, average log likelihood -1.416033
[ Info: iteration 31, average log likelihood -1.416019
[ Info: iteration 32, average log likelihood -1.416004
[ Info: iteration 33, average log likelihood -1.415988
[ Info: iteration 34, average log likelihood -1.415973
[ Info: iteration 35, average log likelihood -1.415957
[ Info: iteration 36, average log likelihood -1.415941
[ Info: iteration 37, average log likelihood -1.415925
[ Info: iteration 38, average log likelihood -1.415910
[ Info: iteration 39, average log likelihood -1.415895
[ Info: iteration 40, average log likelihood -1.415882
[ Info: iteration 41, average log likelihood -1.415869
[ Info: iteration 42, average log likelihood -1.415857
[ Info: iteration 43, average log likelihood -1.415847
[ Info: iteration 44, average log likelihood -1.415837
[ Info: iteration 45, average log likelihood -1.415829
[ Info: iteration 46, average log likelihood -1.415822
[ Info: iteration 47, average log likelihood -1.415815
[ Info: iteration 48, average log likelihood -1.415809
[ Info: iteration 49, average log likelihood -1.415805
[ Info: iteration 50, average log likelihood -1.415800
┌ Info: EM with 100000 data points 50 iterations avll -1.415800
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4168899320599597
│     -1.4168356193500136
│      ⋮
└     -1.4158003168195357
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415808
[ Info: iteration 2, average log likelihood -1.415749
[ Info: iteration 3, average log likelihood -1.415700
[ Info: iteration 4, average log likelihood -1.415645
[ Info: iteration 5, average log likelihood -1.415580
[ Info: iteration 6, average log likelihood -1.415504
[ Info: iteration 7, average log likelihood -1.415420
[ Info: iteration 8, average log likelihood -1.415333
[ Info: iteration 9, average log likelihood -1.415249
[ Info: iteration 10, average log likelihood -1.415174
[ Info: iteration 11, average log likelihood -1.415108
[ Info: iteration 12, average log likelihood -1.415051
[ Info: iteration 13, average log likelihood -1.415001
[ Info: iteration 14, average log likelihood -1.414957
[ Info: iteration 15, average log likelihood -1.414918
[ Info: iteration 16, average log likelihood -1.414882
[ Info: iteration 17, average log likelihood -1.414851
[ Info: iteration 18, average log likelihood -1.414824
[ Info: iteration 19, average log likelihood -1.414801
[ Info: iteration 20, average log likelihood -1.414782
[ Info: iteration 21, average log likelihood -1.414766
[ Info: iteration 22, average log likelihood -1.414753
[ Info: iteration 23, average log likelihood -1.414741
[ Info: iteration 24, average log likelihood -1.414731
[ Info: iteration 25, average log likelihood -1.414722
[ Info: iteration 26, average log likelihood -1.414714
[ Info: iteration 27, average log likelihood -1.414706
[ Info: iteration 28, average log likelihood -1.414699
[ Info: iteration 29, average log likelihood -1.414692
[ Info: iteration 30, average log likelihood -1.414685
[ Info: iteration 31, average log likelihood -1.414679
[ Info: iteration 32, average log likelihood -1.414672
[ Info: iteration 33, average log likelihood -1.414665
[ Info: iteration 34, average log likelihood -1.414659
[ Info: iteration 35, average log likelihood -1.414652
[ Info: iteration 36, average log likelihood -1.414645
[ Info: iteration 37, average log likelihood -1.414638
[ Info: iteration 38, average log likelihood -1.414631
[ Info: iteration 39, average log likelihood -1.414624
[ Info: iteration 40, average log likelihood -1.414616
[ Info: iteration 41, average log likelihood -1.414609
[ Info: iteration 42, average log likelihood -1.414601
[ Info: iteration 43, average log likelihood -1.414593
[ Info: iteration 44, average log likelihood -1.414585
[ Info: iteration 45, average log likelihood -1.414577
[ Info: iteration 46, average log likelihood -1.414569
[ Info: iteration 47, average log likelihood -1.414562
[ Info: iteration 48, average log likelihood -1.414554
[ Info: iteration 49, average log likelihood -1.414547
[ Info: iteration 50, average log likelihood -1.414540
┌ Info: EM with 100000 data points 50 iterations avll -1.414540
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158082386382722
│     -1.4157493884171948
│      ⋮
└     -1.4145396351920274
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414541
[ Info: iteration 2, average log likelihood -1.414489
[ Info: iteration 3, average log likelihood -1.414441
[ Info: iteration 4, average log likelihood -1.414387
[ Info: iteration 5, average log likelihood -1.414322
[ Info: iteration 6, average log likelihood -1.414245
[ Info: iteration 7, average log likelihood -1.414158
[ Info: iteration 8, average log likelihood -1.414063
[ Info: iteration 9, average log likelihood -1.413966
[ Info: iteration 10, average log likelihood -1.413871
[ Info: iteration 11, average log likelihood -1.413781
[ Info: iteration 12, average log likelihood -1.413699
[ Info: iteration 13, average log likelihood -1.413624
[ Info: iteration 14, average log likelihood -1.413555
[ Info: iteration 15, average log likelihood -1.413491
[ Info: iteration 16, average log likelihood -1.413433
[ Info: iteration 17, average log likelihood -1.413378
[ Info: iteration 18, average log likelihood -1.413326
[ Info: iteration 19, average log likelihood -1.413279
[ Info: iteration 20, average log likelihood -1.413236
[ Info: iteration 21, average log likelihood -1.413196
[ Info: iteration 22, average log likelihood -1.413160
[ Info: iteration 23, average log likelihood -1.413128
[ Info: iteration 24, average log likelihood -1.413100
[ Info: iteration 25, average log likelihood -1.413074
[ Info: iteration 26, average log likelihood -1.413050
[ Info: iteration 27, average log likelihood -1.413029
[ Info: iteration 28, average log likelihood -1.413010
[ Info: iteration 29, average log likelihood -1.412992
[ Info: iteration 30, average log likelihood -1.412975
[ Info: iteration 31, average log likelihood -1.412959
[ Info: iteration 32, average log likelihood -1.412944
[ Info: iteration 33, average log likelihood -1.412930
[ Info: iteration 34, average log likelihood -1.412917
[ Info: iteration 35, average log likelihood -1.412904
[ Info: iteration 36, average log likelihood -1.412891
[ Info: iteration 37, average log likelihood -1.412879
[ Info: iteration 38, average log likelihood -1.412867
[ Info: iteration 39, average log likelihood -1.412856
[ Info: iteration 40, average log likelihood -1.412845
[ Info: iteration 41, average log likelihood -1.412834
[ Info: iteration 42, average log likelihood -1.412823
[ Info: iteration 43, average log likelihood -1.412812
[ Info: iteration 44, average log likelihood -1.412801
[ Info: iteration 45, average log likelihood -1.412791
[ Info: iteration 46, average log likelihood -1.412781
[ Info: iteration 47, average log likelihood -1.412771
[ Info: iteration 48, average log likelihood -1.412760
[ Info: iteration 49, average log likelihood -1.412750
[ Info: iteration 50, average log likelihood -1.412741
┌ Info: EM with 100000 data points 50 iterations avll -1.412741
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145412773584327
│     -1.4144888815679197
│      ⋮
└     -1.4127405965559137
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412739
[ Info: iteration 2, average log likelihood -1.412680
[ Info: iteration 3, average log likelihood -1.412625
[ Info: iteration 4, average log likelihood -1.412565
[ Info: iteration 5, average log likelihood -1.412492
[ Info: iteration 6, average log likelihood -1.412405
[ Info: iteration 7, average log likelihood -1.412301
[ Info: iteration 8, average log likelihood -1.412180
[ Info: iteration 9, average log likelihood -1.412047
[ Info: iteration 10, average log likelihood -1.411905
[ Info: iteration 11, average log likelihood -1.411761
[ Info: iteration 12, average log likelihood -1.411621
[ Info: iteration 13, average log likelihood -1.411487
[ Info: iteration 14, average log likelihood -1.411362
[ Info: iteration 15, average log likelihood -1.411249
[ Info: iteration 16, average log likelihood -1.411147
[ Info: iteration 17, average log likelihood -1.411056
[ Info: iteration 18, average log likelihood -1.410977
[ Info: iteration 19, average log likelihood -1.410907
[ Info: iteration 20, average log likelihood -1.410846
[ Info: iteration 21, average log likelihood -1.410793
[ Info: iteration 22, average log likelihood -1.410745
[ Info: iteration 23, average log likelihood -1.410703
[ Info: iteration 24, average log likelihood -1.410665
[ Info: iteration 25, average log likelihood -1.410630
[ Info: iteration 26, average log likelihood -1.410598
[ Info: iteration 27, average log likelihood -1.410568
[ Info: iteration 28, average log likelihood -1.410541
[ Info: iteration 29, average log likelihood -1.410515
[ Info: iteration 30, average log likelihood -1.410491
[ Info: iteration 31, average log likelihood -1.410467
[ Info: iteration 32, average log likelihood -1.410445
[ Info: iteration 33, average log likelihood -1.410424
[ Info: iteration 34, average log likelihood -1.410404
[ Info: iteration 35, average log likelihood -1.410384
[ Info: iteration 36, average log likelihood -1.410365
[ Info: iteration 37, average log likelihood -1.410347
[ Info: iteration 38, average log likelihood -1.410329
[ Info: iteration 39, average log likelihood -1.410312
[ Info: iteration 40, average log likelihood -1.410295
[ Info: iteration 41, average log likelihood -1.410278
[ Info: iteration 42, average log likelihood -1.410262
[ Info: iteration 43, average log likelihood -1.410246
[ Info: iteration 44, average log likelihood -1.410230
[ Info: iteration 45, average log likelihood -1.410214
[ Info: iteration 46, average log likelihood -1.410199
[ Info: iteration 47, average log likelihood -1.410184
[ Info: iteration 48, average log likelihood -1.410169
[ Info: iteration 49, average log likelihood -1.410154
[ Info: iteration 50, average log likelihood -1.410140
┌ Info: EM with 100000 data points 50 iterations avll -1.410140
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4127386788205603
│     -1.4126799673363972
│      ⋮
└     -1.410140313584514
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.422012065281648
│     -1.4220308738955938
│     -1.421972234822851
│     -1.4219318511589338
│      ⋮
│     -1.410168905017203
│     -1.4101544403506812
└     -1.410140313584514
32×26 Array{Float64,2}:
 -0.634983    -0.159444    -0.243568    -0.00340366  -0.0692001   -0.0642128   -0.468799     0.182322    0.558352     0.182834    -0.179896    -0.249594    -0.221126   -0.178081    0.0868815    0.0379757   -0.158214   -0.00159378   -0.0277998   0.408776   -0.0118921   -0.0627192    0.156499   -0.625344      0.127845    0.253685
  0.271164     0.137291     0.0241589    0.151058    -0.103172     0.0225993    0.315952     0.0999757  -0.0638874   -0.100545    -0.112532     0.273426    -0.156385    0.0202866  -0.242174     0.102196     0.212264    0.288347      0.125225   -0.265146   -0.102925     0.0465744   -0.23288     0.570971     -0.0303957   0.0130639
 -0.00128946  -0.0105838    0.225249    -0.324626    -0.089163    -0.508919    -0.177688    -0.555328    0.362184    -0.17537      0.696675    -0.0256346    0.634656    0.192445    0.195129     0.0497548   -0.623686   -0.121794     -0.603666    0.132109    0.00507634  -0.103701     0.688304   -0.25706      -0.0384553   0.332319
 -0.338589     0.145935    -0.041606     0.0988852   -0.501451    -0.618713     0.194703    -0.546935    0.719055     0.436703     0.637369    -0.32927      0.450677   -0.0308861  -0.460945     0.0689121   -0.427834    0.103845      0.560426    0.449209    0.140205     0.0199477    0.705792   -0.00696842   -0.533661   -0.521847
  0.461462    -0.273304     0.235066     0.603316    -0.72816     -0.437761     0.254647    -0.0877476  -0.309506    -0.88361     -0.138818     0.165503     0.255468    0.0903945   0.215862    -0.362643     0.063941    0.638013     -0.0111619  -0.0416897  -0.429809     0.111847     0.763348    0.0900033    -0.363509   -0.0998987
 -0.0413935   -0.216636     0.282529    -0.436044    -0.17995     -0.275668     0.350242     0.45397     0.739778     0.0125877    0.0909884    0.0944829   -0.271005   -0.123977   -0.549304     0.239813     0.31454     0.625468     -0.142474   -0.168216    0.0461121    0.25482      0.791434    0.00966092   -0.469401    0.253827
  0.238651     0.24827      0.429647    -0.040838    -0.30502      0.00661863   0.185299     0.187848    0.114392     0.800815     0.459707    -0.0336488   -0.674681   -0.360124    0.371954     0.00157746  -0.0194104  -0.161916     -0.368708    0.3333      0.295375     0.00141438   0.619319   -0.322915     -0.551522   -0.610541
  0.360522     0.36537     -0.251028     0.148597    -0.253388    -0.0923683    0.561974    -0.217005    0.136646     0.127593    -0.0400235   -0.253656    -0.277107   -0.025055   -0.179567     0.328097     0.115609   -0.351972     -0.244917   -0.388543   -0.420616     0.308256    -0.0628495   0.66894      -0.712482   -0.175402
 -0.2199       0.0905776   -0.237082     0.368355    -0.0264693    0.273765    -0.532054    -0.593      -0.797323    -0.357658     0.217759    -0.0691379    0.402906    0.0743141   0.25362     -0.0451766   -0.39438    -0.288574      0.389959   -0.370726    0.0637391   -0.248282    -0.793681   -0.023138      0.212842   -0.349239
 -0.632531    -0.256127    -0.117148     0.610435    -0.389012    -0.365874    -0.469042     0.166899    0.181324    -0.0954386   -0.353816     0.100356    -0.318484   -0.155594   -0.469727     0.100447    -0.422957    0.493114      0.177526   -0.534926   -0.154394     0.0752473   -0.506031    0.384958     -0.0231352  -0.109263
  0.0190263    0.437397     0.00431248   0.349834     0.820624     0.105451    -0.00524968   0.0502515  -0.14961     -0.614358     0.127147     0.0524808    0.0771193   0.0504405  -1.13137      0.150898     0.37462    -0.0449048     0.558396   -0.138865   -0.546959    -0.289399    -0.376577    0.068509     -0.437019   -0.0739617
 -0.484941    -0.00166601  -0.309171    -0.0718224    0.50387      0.243398    -0.076131    -0.055727    0.0580305   -0.567636     0.14386     -0.00313131   0.706429    0.405146   -0.734392    -0.0908989    0.413343   -0.00312943    0.290735    0.183694    0.28161      0.321012    -0.575556    0.000115583   0.733612    0.489997
  0.573918    -0.0588665   -0.166726     0.215641     0.185027    -0.366713     0.0414523   -0.260801   -0.552736     0.391442    -0.32139     -0.397488     0.263235    0.0689835   0.251957    -0.547318     0.101451   -1.10837      -0.0904422   0.704073   -0.258725     0.332609    -0.198561   -0.129063     -0.258462   -0.255817
  0.195275     0.0542481    0.127465    -0.94595      0.462531     0.747197     0.418989    -0.439779   -0.553818     0.0717832    0.453185    -0.0186933    0.350462   -0.0447045   0.438748    -0.00773039   0.410754   -0.67638      -0.23848     0.131423   -0.260345     0.0266493    0.241735    0.0166349     0.0965043  -0.00382177
 -0.180958    -0.233512     0.0402373   -0.0354532    0.0853239    0.178845     0.407862     0.590264   -0.33133     -0.132047    -0.28571      0.14922     -0.308143   -0.0874402  -0.546793    -0.161337     0.721237    0.561509     -0.130892    0.156594    0.502906    -0.0858066   -0.466138   -0.131964      0.101225   -0.319979
  0.172235    -0.370512     0.102829     0.0242045   -0.364677     0.277473    -0.195624     0.391709   -0.376435     0.0727532   -0.245383     0.204723    -0.250922   -0.101175    1.29315     -0.117176     0.333916    0.657433     -0.260777   -0.100279    0.203781    -0.0804162   -0.40303    -0.0787815     0.641831   -0.0466415
 -0.0210064    0.193459    -0.586344    -0.252991    -0.110563    -0.14522     -0.238046    -0.54583     0.078092     0.736706     0.221213    -0.203935    -0.339698   -0.293983    0.290253     0.183687    -0.124404   -0.212756      0.0105583   0.360548    0.0897292   -0.289593     0.0797489   0.252566      0.271669    0.13718
 -0.270448     0.188259     0.0676107   -0.359035     0.18293      0.160095    -0.0435469    0.621215    0.510361     0.59506     -0.285237    -0.630093    -0.346307   -0.207427   -0.0618455    0.398729     0.0671137  -0.431787     -0.167605    0.308313   -0.050466     0.00920956  -0.158065   -0.368715      0.144949    0.412628
  0.447012    -0.206813    -0.317374     0.12558      0.115079    -0.344791     0.106358     0.381885   -0.0734878    0.313468    -0.288353    -0.146615    -0.0238713   0.0976337  -0.0419086    0.141109     0.554719    0.362289      0.400969    0.633771    0.0616669   -0.396466     0.212798    0.132333     -0.0614679   0.313941
  0.302596     0.12174     -0.181392     0.193036     0.87148      0.631536    -0.375783     0.0136224   0.394426    -0.269368    -0.341438     0.319463    -0.743408    0.28127     0.20305      0.0891711    0.160026   -0.151174     -0.315142    0.647761   -0.19658     -0.694893     0.179496   -0.0979684     0.0100894   0.525434
 -0.0679056    0.0443654   -0.168716     0.217188     0.222388     0.177651    -0.149399    -0.0124573  -0.463305    -0.0367595   -0.202628    -0.155814     0.171       0.0548726   0.00684798  -0.151895    -0.0689521  -0.302627      0.216951   -0.0193075  -0.0609493   -0.118073    -0.492525   -0.0148528     0.0223941  -0.143213
 -0.0389152    0.404366     0.384566     0.555443    -0.10201      0.030334    -0.605318    -0.286439    0.386529    -0.1568       0.340085    -0.269124     0.0911333  -0.184736    0.144376    -0.417528    -0.0127315  -0.0150184     0.347017    0.293375   -0.0332938   -0.0530848   -0.117871    0.324411      0.0229981  -0.0399795
 -0.0364717    0.0249973    0.0741716    0.00699534  -0.599748     0.0545539    0.304338    -0.286614   -0.39695     -0.00554289   0.309358     0.562854    -0.311454   -0.060281    0.188411    -0.383907     0.15467     0.250293     -0.146682   -0.088081    0.353783     0.0510941   -0.07564     0.253897     -0.189073   -0.554225
  0.330942     0.18362      0.291386    -0.0888003    0.577053    -0.255639     0.242166    -0.335099   -0.203263     0.0486213    0.00850088  -0.03877     -0.354692   -0.391464   -0.123779    -0.202993     0.152921   -0.023578     -0.174259    0.189916   -0.319437    -0.102225     0.341032    0.16338      -0.482447   -0.333528
 -0.117031    -0.480808    -0.463682    -0.532555     0.696033     0.0449535    0.0243205    0.438912   -0.964588     0.183762    -0.653236     0.262028    -0.165634    0.249795   -0.113758     0.155115     0.298697   -0.234063      0.0409342  -0.443335   -0.150192    -0.740929    -0.258664   -0.270954      0.389033    0.498726
 -0.629978    -0.155426     0.233544    -0.132807     0.164853     0.124436    -0.122489     0.155395    0.251072    -0.182889     0.00445949   0.653935    -0.058412   -0.236389    0.0210668    0.111653    -0.751664    0.172312      0.129517   -0.332612    0.0126932   -0.516305     0.540876   -0.644033      0.170028   -0.205165
 -0.0124337    0.337916     0.948539    -0.235737     0.390524    -0.262785    -0.0176084    0.0897957  -0.310925    -0.0708183    0.126969     0.0683548    0.522056   -0.0284345  -0.276374    -0.175742    -0.463135   -0.542612     -0.0176478  -0.395179    0.232176     0.4102       0.174592   -0.660229      0.0208897  -0.539814
  0.386834    -0.0734953    0.132936     0.190542    -0.206998    -0.121716     0.255768     0.186543   -0.0624641   -0.145538    -0.241944     0.198172     0.779748    0.297625    0.103652     0.541853    -0.39235    -0.0587167    -0.353946   -0.167667    0.383592     0.527117    -0.443488   -0.425744      0.0825087   0.050423
  0.0289886    0.00294661   0.0165822   -0.016337    -0.0263903   -0.131228     0.0672888   -0.0484468   0.0847881   -0.0127109    0.0312644   -0.0021027    0.0297868   0.0502407  -0.235618     0.162356     0.012949   -0.000587818  -0.0491821  -0.0109328   0.0163965    0.00762844   0.071267   -0.0781336    -0.138602   -0.0388303
 -0.0925002   -0.0979229    0.0186796   -0.130923    -0.335072    -0.0956536   -0.0405837    0.112246    0.184578     0.122079     0.0106987    0.0449942   -0.215013   -0.127228    0.474584     0.213165    -0.222245    0.200668     -0.26628    -0.124295   -0.0300945   -0.0274034    0.201812   -0.194273      0.201692    0.083849
  0.20945     -0.0533619    0.17906     -0.576477     0.00174081   0.312975     0.116537    -0.0989352  -0.00451738  -0.399902     0.0726687    0.21834      0.166301    0.326244    0.288021     0.0749363    0.293002    0.244273     -0.0923935  -0.369008   -0.256567    -0.0463405   -0.0289749   0.44665       0.290394    0.594294
 -0.276067    -0.297509    -0.85715      0.490998    -0.71363      0.227937    -0.0553838   -0.104527    0.174606    -0.355234    -0.0342346    0.0642141   -0.0784905   0.383076    0.159797     0.171918     0.221862    0.0228273    -0.150804    0.0357514  -0.218875    -0.146943    -0.278114    0.322076      0.0455828   0.298221[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410127
[ Info: iteration 2, average log likelihood -1.410113
[ Info: iteration 3, average log likelihood -1.410100
[ Info: iteration 4, average log likelihood -1.410088
[ Info: iteration 5, average log likelihood -1.410075
[ Info: iteration 6, average log likelihood -1.410064
[ Info: iteration 7, average log likelihood -1.410052
[ Info: iteration 8, average log likelihood -1.410041
[ Info: iteration 9, average log likelihood -1.410031
[ Info: iteration 10, average log likelihood -1.410020
┌ Info: EM with 100000 data points 10 iterations avll -1.410020
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.409137e+05
      1       6.993164e+05      -2.415973e+05 |       32
      2       6.894647e+05      -9.851649e+03 |       32
      3       6.853995e+05      -4.065189e+03 |       32
      4       6.831501e+05      -2.249426e+03 |       32
      5       6.816013e+05      -1.548815e+03 |       32
      6       6.804583e+05      -1.142985e+03 |       32
      7       6.795889e+05      -8.693959e+02 |       32
      8       6.788900e+05      -6.989184e+02 |       32
      9       6.783083e+05      -5.816747e+02 |       32
     10       6.778084e+05      -4.999432e+02 |       32
     11       6.774183e+05      -3.900513e+02 |       32
     12       6.770624e+05      -3.559574e+02 |       32
     13       6.767407e+05      -3.216507e+02 |       32
     14       6.764690e+05      -2.717130e+02 |       32
     15       6.762268e+05      -2.422193e+02 |       32
     16       6.760115e+05      -2.153007e+02 |       32
     17       6.758140e+05      -1.975107e+02 |       32
     18       6.756454e+05      -1.685819e+02 |       32
     19       6.754696e+05      -1.758477e+02 |       32
     20       6.753024e+05      -1.671640e+02 |       32
     21       6.751692e+05      -1.332300e+02 |       32
     22       6.750507e+05      -1.185146e+02 |       32
     23       6.749284e+05      -1.222689e+02 |       32
     24       6.748079e+05      -1.204363e+02 |       32
     25       6.746917e+05      -1.162287e+02 |       32
     26       6.745778e+05      -1.139233e+02 |       32
     27       6.744607e+05      -1.170527e+02 |       32
     28       6.743397e+05      -1.209984e+02 |       32
     29       6.742400e+05      -9.976110e+01 |       32
     30       6.741476e+05      -9.240801e+01 |       32
     31       6.740594e+05      -8.816237e+01 |       32
     32       6.739815e+05      -7.789107e+01 |       32
     33       6.739032e+05      -7.833324e+01 |       32
     34       6.738157e+05      -8.745630e+01 |       32
     35       6.737356e+05      -8.017176e+01 |       32
     36       6.736569e+05      -7.869652e+01 |       32
     37       6.735846e+05      -7.229438e+01 |       32
     38       6.735163e+05      -6.827025e+01 |       32
     39       6.734534e+05      -6.293012e+01 |       32
     40       6.733948e+05      -5.853015e+01 |       32
     41       6.733404e+05      -5.447870e+01 |       32
     42       6.732857e+05      -5.466573e+01 |       32
     43       6.732305e+05      -5.522862e+01 |       32
     44       6.731770e+05      -5.349053e+01 |       32
     45       6.731226e+05      -5.436345e+01 |       32
     46       6.730759e+05      -4.672021e+01 |       32
     47       6.730234e+05      -5.248871e+01 |       32
     48       6.729678e+05      -5.555306e+01 |       32
     49       6.729133e+05      -5.450611e+01 |       32
     50       6.728581e+05      -5.523111e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672858.1105408965)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421651
[ Info: iteration 2, average log likelihood -1.416593
[ Info: iteration 3, average log likelihood -1.415141
[ Info: iteration 4, average log likelihood -1.413989
[ Info: iteration 5, average log likelihood -1.412820
[ Info: iteration 6, average log likelihood -1.411876
[ Info: iteration 7, average log likelihood -1.411315
[ Info: iteration 8, average log likelihood -1.411026
[ Info: iteration 9, average log likelihood -1.410864
[ Info: iteration 10, average log likelihood -1.410758
[ Info: iteration 11, average log likelihood -1.410680
[ Info: iteration 12, average log likelihood -1.410617
[ Info: iteration 13, average log likelihood -1.410566
[ Info: iteration 14, average log likelihood -1.410522
[ Info: iteration 15, average log likelihood -1.410484
[ Info: iteration 16, average log likelihood -1.410451
[ Info: iteration 17, average log likelihood -1.410422
[ Info: iteration 18, average log likelihood -1.410396
[ Info: iteration 19, average log likelihood -1.410372
[ Info: iteration 20, average log likelihood -1.410351
[ Info: iteration 21, average log likelihood -1.410331
[ Info: iteration 22, average log likelihood -1.410312
[ Info: iteration 23, average log likelihood -1.410295
[ Info: iteration 24, average log likelihood -1.410279
[ Info: iteration 25, average log likelihood -1.410264
[ Info: iteration 26, average log likelihood -1.410249
[ Info: iteration 27, average log likelihood -1.410236
[ Info: iteration 28, average log likelihood -1.410223
[ Info: iteration 29, average log likelihood -1.410210
[ Info: iteration 30, average log likelihood -1.410198
[ Info: iteration 31, average log likelihood -1.410186
[ Info: iteration 32, average log likelihood -1.410174
[ Info: iteration 33, average log likelihood -1.410163
[ Info: iteration 34, average log likelihood -1.410151
[ Info: iteration 35, average log likelihood -1.410140
[ Info: iteration 36, average log likelihood -1.410129
[ Info: iteration 37, average log likelihood -1.410119
[ Info: iteration 38, average log likelihood -1.410108
[ Info: iteration 39, average log likelihood -1.410097
[ Info: iteration 40, average log likelihood -1.410087
[ Info: iteration 41, average log likelihood -1.410076
[ Info: iteration 42, average log likelihood -1.410065
[ Info: iteration 43, average log likelihood -1.410055
[ Info: iteration 44, average log likelihood -1.410045
[ Info: iteration 45, average log likelihood -1.410034
[ Info: iteration 46, average log likelihood -1.410024
[ Info: iteration 47, average log likelihood -1.410014
[ Info: iteration 48, average log likelihood -1.410005
[ Info: iteration 49, average log likelihood -1.409995
[ Info: iteration 50, average log likelihood -1.409986
┌ Info: EM with 100000 data points 50 iterations avll -1.409986
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.453103    0.125559   -0.345949      0.0823028   -0.268675   -0.79637     0.357376    -0.648943    0.543679    0.547173    0.572309   -0.376196    0.0709092  -0.317021   -0.623167     0.0549073  -0.29517     -0.149404    0.232222     0.338416    0.0929323   -0.101612    0.58583     0.0571661  -0.652379    -0.693098
  0.0625186  -0.226545    0.00363906    0.277813    -0.549082   -0.147015    0.12244     -0.484168   -0.408585   -0.306965    0.0664865   0.548489   -0.0724964   0.203808    0.247558    -0.433358   -0.00141045   0.35271    -0.0561927   -0.192096    0.0761311   -0.057176   -0.0344756   0.390077   -0.270065    -0.497105
 -0.331847    0.145591    0.152366     -0.515416     0.255728    0.198308   -0.285871     0.514133    0.886446    0.627982   -0.522203   -0.636619   -0.447277   -0.0794549  -0.019908     0.302726    0.117209    -0.591      -0.111375     0.53584    -0.15473     -0.061221   -0.0054998  -0.518421    0.138065     0.605505
 -0.152022    0.309083   -0.0846452     0.253903     0.108142    0.418354   -0.231645    -0.765965   -0.918544   -0.317036    0.413951   -0.122935    0.323548    0.101117    0.170103     0.0135436  -0.251476    -0.539722    0.274597    -0.378626    0.0179407   -0.233272   -0.784521    0.0419091   0.0768258   -0.457545
 -0.454441   -0.105162    0.000636091   0.553845    -0.0506402  -0.181488   -0.734563    -0.150135   -0.0254194  -0.156435   -0.0895505  -0.0764856   0.0413892  -0.370716   -0.00578602  -0.0544091  -0.664427     0.0819366   0.327222    -0.534607   -0.488818    -0.0336575  -0.400196    0.100696    0.0218875   -0.0911929
  0.243716    0.28306     0.386937     -0.15185      0.910892   -0.155139    0.0105628   -0.0553465  -0.0476618   0.299045   -0.144433   -0.123436   -0.748107   -0.634243    0.0205238   -0.123414    0.169614     0.101976    0.0270671    0.417564   -0.294785    -0.396567    0.498171   -0.0139536  -0.572199    -0.349599
 -0.317947   -0.690237   -0.235144     -0.885212     0.816931    0.463696    0.158676    -0.0180801  -0.750074   -0.0767281  -0.0304352   0.384949   -0.0456294   0.269367    0.0168634   -0.219979    0.345734    -0.102252    0.209316    -0.114368   -0.488385    -0.565871    0.275543    0.0268972   0.31655      0.286791
  0.412632   -0.182829   -0.331647      0.0279383    0.57754     0.154924    0.269639     0.424214   -0.695654   -0.13784    -0.849079    0.10557     0.154157    0.0960976  -0.368919     0.394508    0.3393       0.176793   -0.195282    -0.0381685   0.240339    -0.218726   -0.879428   -0.0733971   0.299045     0.250368
  0.596382    0.0708078  -0.0582422     0.0915762    0.572729    0.314596   -0.480477    -0.391281    0.420206   -0.756576    0.0459039   0.111807   -0.247312    0.484447   -0.0773427    0.224616    0.373304     0.0166002   0.0652118    0.243178   -0.373579    -0.477517    0.0991406   0.400424    0.138192     0.519803
  0.253118   -0.34454     0.21737      -0.320945    -0.180321    0.419241   -0.0408691    0.232172   -0.432964   -0.296377   -0.298607    0.301673    0.182932    0.238871    0.928727    -0.0681623   0.301173     0.348913   -0.126823    -0.526281   -0.00760095  -0.0820623  -0.549145    0.170096    0.65376      0.515807
 -0.106044    0.0954226  -0.716326      0.248339    -0.203707    0.329923    0.196243     0.495809    0.0141979   0.878611    0.106726    0.124137   -0.454781    0.07357     0.17114      0.699749   -0.230161     0.172356    0.362052     0.30191     0.0582929   -0.310458    0.134291    0.17712    -0.0377023    0.457845
  0.608697    0.0818115  -0.0514863    -0.0351694    0.304612   -0.0748001   0.269715    -0.277529   -0.398852    0.305202   -0.097072   -0.295182    0.381978    0.0251375   0.256404    -0.345636    0.116087    -1.16043    -0.231        0.487675   -0.185057     0.198591   -0.010732   -0.112162   -0.289278    -0.182709
  0.367131    0.0944585  -0.102685     -0.339638    -0.0872781  -0.092028    0.308646    -0.293943    0.235966    0.16083     0.0703417  -0.148898    0.206257    0.201252   -0.131395     0.6477     -0.125184    -0.17244    -0.218285    -0.272195   -0.208522     0.142605    0.0747061   0.0718851  -0.398847     0.104141
  0.236184    0.57125    -0.11071       0.220377    -0.604387    0.14425     0.433662     0.183639   -0.0817287   0.060332   -0.475541    0.0206363  -0.905986   -0.0865778   0.0440376    0.0503053   0.641071     0.165813    0.202996    -0.524386   -0.183138     0.423992   -0.724057    1.01132    -0.239904    -0.60387
 -0.299449    0.430256    0.0615696     0.00506844   0.562759    0.386414    0.208454     0.353521    0.141921   -0.700198    0.304049    0.0820634   0.203398    0.130817   -1.1931       0.199207    0.551453     0.225144    0.539657    -0.228617   -0.327341    -0.162022   -0.256883    0.0695865  -0.232769     0.121375
 -0.0241182  -0.561419   -0.114263     -0.241038    -0.122049   -0.26038     0.266972     0.483913    0.350918   -0.149663   -0.415171    0.0468223  -0.220726   -0.143355   -0.147179    -0.148556    0.677883     0.818461   -0.158707     0.363411    0.0667225    0.0117426   0.581897   -0.0112922  -0.00803864   0.536729
  0.415799    0.191138    0.328434     -0.0159337    0.165818   -0.124721    0.374294    -0.0344735  -0.276961   -0.261874    0.055552    0.0761809   0.224137    0.0158973  -0.381938    -0.312486    0.370578    -0.08051    -0.147162     0.0659562  -0.0805041    0.232669    0.216985   -0.0354026  -0.231765    -0.202761
  0.487629   -0.0264877   0.252125      0.45039     -0.790687   -0.514423    0.380409     0.0927806   0.0569085  -0.462662   -0.0336004   0.0588202   0.268455    0.054795    0.0816923   -0.0962475  -0.0858842    0.471013    0.052588    -0.332225   -0.553028     0.406257    0.760579    0.318686   -0.540966     0.0234755
  0.162744    0.736862    0.40335       0.505188    -0.431377    0.0318172  -0.408759    -0.590027    0.806644    0.0507694   0.552703   -0.227762    0.0511477  -0.173314    0.145649    -0.340137   -0.149199     0.151689    0.258964     0.671302    0.126886     0.0757059   0.0986428   0.419221   -0.0915035    0.0169853
 -0.358958    0.164591   -0.314914     -0.200921    -0.30333     0.124516   -0.00158719  -0.1445      0.342113   -0.205422    0.0783098   0.438199   -0.703205   -0.270189    0.266259     0.318246   -0.193456     0.0662941  -0.640828    -0.300891   -0.282592    -0.0949734   0.420043   -0.171296    0.193334     0.258133
 -0.13819    -0.132565    0.20649      -0.141347    -0.23994    -0.152405   -0.093655     0.0901477   0.235211    0.0774325   0.0907989   0.018806    0.0333279  -0.0104127   0.127001     0.105166   -0.192978     0.186153    0.0157373   -0.0600591   0.115065    -0.0429165   0.179481   -0.13256     0.122314     0.0346882
 -0.44142    -0.325739    0.109751      0.400394    -0.159981    0.186999   -0.244158     0.574784   -0.347337   -0.069393   -0.168532    0.0395427  -0.172005   -0.200109    0.224677    -0.288428    0.211345     0.526811    0.0944256    0.229639    0.614107    -0.143743   -0.671346   -0.473852    0.136021    -0.607082
  0.0434157   0.0697786   0.506026     -0.388515    -0.651429    0.213243    0.46422      0.355372    0.0777571   0.512679    0.786661    0.248349   -0.276816   -0.26984     0.18926      0.0955847   0.12291      0.202841   -0.387798    -0.03695     0.649807    -0.0306289   0.568572   -0.149975   -0.166836    -0.36624
 -0.0713996   0.0352391  -0.124009      0.253738     0.114327    0.103757   -0.0950957    0.0214193  -0.150269   -0.0652082  -0.137355   -0.0956991  -0.0259998  -0.0143809  -0.0857407   -0.0794167   0.0974313   -0.124051    0.133777     0.0744435  -0.0752802   -0.123736   -0.305289    0.0764805  -0.0418559   -0.0204224
 -0.0834181   0.453586    0.894667     -0.297866     0.375623   -0.123886    0.10116      0.0871108  -0.252637    0.020818    0.223845    0.185322    0.430808   -0.198938   -0.102824    -0.17721    -0.587227    -0.329497   -0.189156    -0.58182     0.167393     0.879678   -0.0204513  -0.401573    0.0638287   -0.233595
 -0.230708    0.524814   -0.383892     -0.445027     0.636914   -0.0362618  -0.284957    -0.300135   -0.23839     0.373056    0.0150807  -0.180808    0.328435   -0.0580647  -0.238538    -0.171626    0.0161022   -0.253027    0.222537     0.148214    0.225567    -0.127304   -0.474755    0.0265755   0.597751     0.0952942
 -0.397848   -0.37779     0.254956     -0.408129    -0.016568   -0.510283   -0.238129    -0.534239    0.219075    0.0358525   0.945734   -0.247943    1.05029     0.303956    0.220677    -0.074217   -0.490752     0.156271   -0.275151     0.680999   -0.123374    -0.157684    0.730437   -0.502116    0.00641004   0.310886
 -0.175152   -0.0872923  -0.479066      0.0419711   -0.324294    0.0750225  -0.549598    -0.180435    0.0371126   0.272107   -0.0792752   0.0954678  -0.373391   -0.297545    0.514914     0.0419361   0.0599249    0.131717   -0.0757786    0.260692   -0.047383    -0.14237    -0.0719631  -0.101666    0.345515    -0.0184237
 -0.201339   -0.120551    0.56692       0.0065124    0.159788   -0.302249   -0.0308913    0.273697    0.14885    -0.292904   -0.249134    0.394476    0.446596    0.060752   -0.107547     0.276002   -0.703902    -0.114615    0.0267481   -0.197686    0.259528    -0.389444    0.493373   -0.871021    0.0822063   -0.263589
  0.377299   -0.153443   -0.289187     -0.047908    -0.295518   -0.0891851   0.157685    -0.0964532  -0.211424    0.413527    0.0277197  -0.337068   -0.418292   -0.0107742   0.635889     0.0780906   0.359706    -0.242825   -0.439842     0.481506   -0.0169375    0.0059767   0.0901959  -0.037341    0.00952857  -0.197856
 -0.416805   -0.254734   -0.67489       0.565181    -0.61021     0.0184287  -0.192096     0.160447    0.147454   -0.590924    0.188745   -0.145653    0.585133    0.610699   -0.289848     0.26202     0.0663609   -0.157994   -0.00609031  -0.0376495   0.266303     0.196204   -0.626199    0.107672    0.352836     0.437388
 -0.468104   -0.533969    0.0204033     0.515391    -0.0613384  -0.603812    0.0464968    0.40042     0.397038    0.0458161  -0.418579    0.172932   -0.616077    0.0237188  -0.943045     0.0905205  -0.149774     0.430663    0.076903    -0.343046    0.200585     0.0125143  -0.096263    0.383394   -0.387585    -0.0780406[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409977
[ Info: iteration 2, average log likelihood -1.409968
[ Info: iteration 3, average log likelihood -1.409959
[ Info: iteration 4, average log likelihood -1.409950
[ Info: iteration 5, average log likelihood -1.409941
[ Info: iteration 6, average log likelihood -1.409933
[ Info: iteration 7, average log likelihood -1.409925
[ Info: iteration 8, average log likelihood -1.409917
[ Info: iteration 9, average log likelihood -1.409908
[ Info: iteration 10, average log likelihood -1.409901
┌ Info: EM with 100000 data points 10 iterations avll -1.409901
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
