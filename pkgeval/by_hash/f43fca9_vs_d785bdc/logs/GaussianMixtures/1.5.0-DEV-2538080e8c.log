Julia Version 1.5.0-DEV.269
Commit 2538080e8c (2020-02-12 17:50 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed URIParser ────────── v0.4.0
  Installed SortingAlgorithms ── v0.3.1
  Installed GaussianMixtures ─── v0.3.0
  Installed LegacyStrings ────── v0.4.1
  Installed CMake ────────────── v1.1.2
  Installed BinDeps ──────────── v1.0.0
  Installed StaticArrays ─────── v0.12.1
  Installed BinaryProvider ───── v0.5.8
  Installed SpecialFunctions ─── v0.9.0
  Installed StatsFuns ────────── v0.9.3
  Installed PDMats ───────────── v0.9.11
  Installed JLD ──────────────── v0.9.2
  Installed Arpack_jll ───────── v3.5.0+2
  Installed StatsBase ────────── v0.32.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed Blosc ────────────── v0.5.1
  Installed FillArrays ───────── v0.8.4
  Installed Compat ───────────── v2.2.0
  Installed FileIO ───────────── v1.2.2
  Installed Clustering ───────── v0.13.3
  Installed Distributions ────── v0.22.4
  Installed CMakeWrapper ─────── v0.2.3
  Installed Distances ────────── v0.8.2
  Installed OrderedCollections ─ v1.1.0
  Installed DataStructures ───── v0.17.9
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Missings ─────────── v0.4.3
  Installed Rmath ────────────── v0.6.0
  Installed QuadGK ───────────── v2.3.1
  Installed HDF5 ─────────────── v0.12.5
  Installed Parameters ───────── v0.12.0
  Installed NearestNeighbors ─── v0.4.4
  Installed DataAPI ──────────── v1.1.0
  Installed Arpack ───────────── v0.4.0
#=#=#                                                                         #######################                                                   32.7%######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.6%#####                                                                      8.2%##########                                                                15.0%################                                                          22.6%#######################                                                   33.0%################################                                          44.9%############################################                              61.9%############################################################              83.7%######################################################################## 100.0%
#=#=#                                                                         #####                                                                      7.0%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_yrzvkd/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.1852016883959154e7, [98375.03991787985, 1624.9600821201414], [478.7152172203433 3819.2356503585684 -345.31926247281234; 183.83882158102028 -4021.045716801132 407.6168052972501], [[98457.86324896176 451.59872145034876 -170.53634391122324; 451.5987214503488 89197.94882080208 1209.1824484327506; -170.53634391122324 1209.1824484327506 97777.98777228611], [1723.3747762885278 -366.6868842375399 33.20701530247484; -366.6868842375399 10142.383343712589 -877.336253631176; 33.20701530247484 -877.3362536311761 1650.1499146331685]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.097252e+03
      1       9.124023e+02      -1.848501e+02 |        5
      2       9.013218e+02      -1.108047e+01 |        0
      3       9.013218e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 901.3218246224069)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075573
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.803082
[ Info: iteration 2, lowerbound -3.681678
[ Info: iteration 3, lowerbound -3.565896
[ Info: iteration 4, lowerbound -3.437753
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.291103
[ Info: iteration 6, lowerbound -3.129810
[ Info: iteration 7, lowerbound -2.981385
[ Info: iteration 8, lowerbound -2.872073
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.808537
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.779094
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.752162
[ Info: iteration 12, lowerbound -2.724566
[ Info: iteration 13, lowerbound -2.688770
[ Info: iteration 14, lowerbound -2.638605
[ Info: iteration 15, lowerbound -2.575322
[ Info: iteration 16, lowerbound -2.506376
[ Info: iteration 17, lowerbound -2.442830
[ Info: iteration 18, lowerbound -2.391826
[ Info: iteration 19, lowerbound -2.353520
[ Info: iteration 20, lowerbound -2.325936
[ Info: iteration 21, lowerbound -2.310157
[ Info: iteration 22, lowerbound -2.308227
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.302916
[ Info: iteration 24, lowerbound -2.299259
[ Info: iteration 25, lowerbound -2.299256
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb 12 19:13:35 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb 12 19:13:43 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Wed Feb 12 19:13:46 2020: EM with 272 data points 0 iterations avll -2.075573
5.8 data points per parameter
, Wed Feb 12 19:13:48 2020: GMM converted to Variational GMM
, Wed Feb 12 19:13:56 2020: iteration 1, lowerbound -3.803082
, Wed Feb 12 19:13:56 2020: iteration 2, lowerbound -3.681678
, Wed Feb 12 19:13:56 2020: iteration 3, lowerbound -3.565896
, Wed Feb 12 19:13:56 2020: iteration 4, lowerbound -3.437753
, Wed Feb 12 19:13:57 2020: dropping number of Gaussions to 7
, Wed Feb 12 19:13:57 2020: iteration 5, lowerbound -3.291103
, Wed Feb 12 19:13:57 2020: iteration 6, lowerbound -3.129810
, Wed Feb 12 19:13:57 2020: iteration 7, lowerbound -2.981385
, Wed Feb 12 19:13:57 2020: iteration 8, lowerbound -2.872073
, Wed Feb 12 19:13:57 2020: dropping number of Gaussions to 6
, Wed Feb 12 19:13:57 2020: iteration 9, lowerbound -2.808537
, Wed Feb 12 19:13:57 2020: dropping number of Gaussions to 4
, Wed Feb 12 19:13:57 2020: iteration 10, lowerbound -2.779094
, Wed Feb 12 19:13:57 2020: dropping number of Gaussions to 3
, Wed Feb 12 19:13:57 2020: iteration 11, lowerbound -2.752162
, Wed Feb 12 19:13:57 2020: iteration 12, lowerbound -2.724566
, Wed Feb 12 19:13:57 2020: iteration 13, lowerbound -2.688770
, Wed Feb 12 19:13:57 2020: iteration 14, lowerbound -2.638605
, Wed Feb 12 19:13:57 2020: iteration 15, lowerbound -2.575322
, Wed Feb 12 19:13:57 2020: iteration 16, lowerbound -2.506376
, Wed Feb 12 19:13:57 2020: iteration 17, lowerbound -2.442830
, Wed Feb 12 19:13:57 2020: iteration 18, lowerbound -2.391826
, Wed Feb 12 19:13:57 2020: iteration 19, lowerbound -2.353520
, Wed Feb 12 19:13:57 2020: iteration 20, lowerbound -2.325936
, Wed Feb 12 19:13:57 2020: iteration 21, lowerbound -2.310157
, Wed Feb 12 19:13:57 2020: iteration 22, lowerbound -2.308227
, Wed Feb 12 19:13:57 2020: dropping number of Gaussions to 2
, Wed Feb 12 19:13:57 2020: iteration 23, lowerbound -2.302916
, Wed Feb 12 19:13:57 2020: iteration 24, lowerbound -2.299259
, Wed Feb 12 19:13:57 2020: iteration 25, lowerbound -2.299256
, Wed Feb 12 19:13:57 2020: iteration 26, lowerbound -2.299254
, Wed Feb 12 19:13:57 2020: iteration 27, lowerbound -2.299254
, Wed Feb 12 19:13:57 2020: iteration 28, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 29, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 30, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 31, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 32, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 33, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 34, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 35, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 36, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 37, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 38, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 39, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 40, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 41, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 42, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 43, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 44, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 45, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 46, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 47, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 48, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 49, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: iteration 50, lowerbound -2.299253
, Wed Feb 12 19:13:57 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260191, 95.95490777398085]
β = [178.0450922260191, 95.95490777398085]
m = [4.250300733269868 79.28686694436125; 2.000229257775326 53.85198717246106]
ν = [180.0450922260191, 97.95490777398085]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484047 -0.007644049042328144; 0.0 0.008581705166333015], [0.3758763611949131 -0.008953123827346757; 0.0 0.012748664777409636]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -1.002235156061745
avll from llpg:  -1.0022351560913425
avll direct:     -1.0022351560913427
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9790252926298721
avll from llpg:  -0.9790252926298721
avll direct:     -0.9790252926298721
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.136376     0.0195634   0.166305     -0.0667037   -0.0284993    0.0848785   -0.0997703    0.0628949    0.0678025   -0.0683394    0.0889432    0.0534354   -0.234788     0.151713     0.000567291  -0.0977933   -0.0663706    -0.00321249    0.0814658    0.0539602     0.0942394    0.127901   -0.0104347     0.139872      0.173485    0.0247112
  0.0472691   -0.0856627  -0.0524321     0.044711     0.051308     0.0152583    0.089887     0.10333     -0.0385782    0.0548729   -0.0697385   -0.141469    -0.00494854  -0.252589    -0.0681797    -0.0958433   -0.0966235     0.00220486    0.103918    -0.0693995    -0.136335     0.113525   -0.000696387  -0.114032     -0.158538    0.169333
  0.08181     -0.184719    0.000585964  -0.0861922    0.125607     0.12692     -0.147528    -0.0330299    0.011099    -0.0816844    0.134703     0.0731992    0.110841    -0.141228     0.0667149    -0.141729     0.0180847     0.0407425     0.168513     0.157702      0.0355047   -0.0129292  -0.0779584     0.0482166    -0.0395386  -0.12494
  0.0927439   -0.132014    0.0680626     0.00686435   0.0686034    0.00588628   0.0673502    0.173634    -0.134104    -0.173288    -0.10164     -0.167758     0.250777     0.144662    -0.298911      0.156972    -0.106462     -0.0776957     0.0189194    0.0285377     0.0529171    0.0364703  -0.0684021    -0.0305088    -0.0595026   0.00827315
 -0.172304    -0.0598812  -0.0154649     0.126083    -0.134033    -0.00506984   0.206074    -0.0840674   -0.0402928    0.0195212    0.175363     0.0276184   -0.0861433    0.0710893   -0.0262078    -0.127925     0.0937211     0.124271     -0.0938609   -0.199127      0.00228624  -0.161432   -0.14127       0.000818292  -0.0385737   0.0308071
 -0.026624    -0.157994   -0.043866      0.0243948    0.0204128   -0.0958822   -0.0226118   -0.0455673    0.0241323    0.140032    -0.0508504    0.0288348    0.0342986   -0.0358832   -0.00640772   -0.00156088  -0.0849403    -0.0136057     0.00144483  -0.0160491     0.0586596    0.0621534  -0.0751415    -0.0981218     0.11382     0.0632619
  0.0924342    0.10184    -0.0494896     0.16691      0.099664    -0.0729123   -0.00740677  -0.0618645   -0.0465469    0.0331442    0.00203555  -0.0383914    0.127728     0.0591896    0.0408426    -0.0360887   -0.0864491     0.0445957     0.0799292    0.00150642   -0.0635414    0.0359783   0.0195925     0.193931     -0.042246    0.0480638
  0.0640174   -0.0506934  -0.0272356     0.10546     -0.0174008   -0.0213075    0.0426985    0.0420396    0.153571    -0.00482162  -0.13723     -0.0705835   -0.0409898   -0.169815     0.149299      0.060091    -0.039072      0.0208134    -0.156777    -0.151609     -0.161736     0.204753   -0.138143     -0.0135374    -0.055929   -0.0431519
 -0.0305272    0.0283236   0.0761278     0.055233    -0.112638     0.0755841   -0.115985    -0.0872165   -0.100958    -0.0536419   -0.0634103   -0.0770264   -0.0744657    0.117499     0.0716552     0.034936    -0.0868491    -0.137456      0.0648112    0.0349143     0.0267326    0.0950352   0.0198531     0.0135115    -0.0335396   0.1048
  0.136217     0.123671   -0.083296     -0.0637097    0.141059     0.197041    -0.051721     0.0395489    0.0240783    0.198362     0.0452889   -0.0337997    0.0268389   -0.139329     0.176919      0.0432184   -0.00719597    0.133046      0.0526799    0.0846541     0.105869    -0.0119485   0.0987388    -0.145273     -0.0543221   0.00800564
  0.0733798    0.141616    0.0161931     0.0665554    0.082471     0.0428056    0.130382     0.148385    -0.0382257    0.0372885   -0.0792456    0.148765     0.0534716   -0.0275694    0.013736     -0.0878927    0.000990404   0.00883221    0.00329191   0.170886      0.0810279   -0.0665125   0.118168     -0.0505797    -0.0534848  -0.140096
  0.066037    -0.0979918   0.0140649    -0.184024     0.114328     0.0583135    0.202899    -0.0867607   -0.0387799   -0.0979683    0.0687873    0.0026458    0.207538     0.0541279    0.111627     -0.0745916   -0.0729542     0.000777879  -0.141888     0.156602     -0.0244535    0.0711575  -0.262247     -0.0284642     0.0589522  -0.0937672
 -0.00661385  -0.161731   -0.182934      0.0955225   -0.10132      0.142898     0.00454472   0.0048764    0.111903     0.140762    -0.128589    -0.134457    -0.0841202   -0.104148     0.053475      0.0298519    0.0385204    -0.145033      0.0216019    0.0693842     0.0335279   -0.086952   -0.00371639   -0.111459      0.22344    -0.207089
 -0.125446     0.0671144   0.0241837     0.110298    -0.134601     0.128856    -0.137398    -0.0726501   -0.185409    -0.0609169   -0.0268895    0.165059    -0.0895565   -0.178774     0.0777527     0.173617     0.102749     -0.0975483    -0.211489    -0.0103227    -0.105206    -0.198491   -0.0857389     0.0928185     0.130207   -0.281194
 -0.00730353  -0.0484968   0.244291      0.0376813   -0.123832     0.0804325    0.0520129    0.118511     0.0245549   -0.0977437    0.0329674   -0.157944     0.0448972   -0.112006    -0.110141      0.0814375    0.120292     -0.00754112   -0.0694926    0.018661      0.129939     0.012216    0.201295     -0.104455     -0.0976559   0.0720006
  0.0332879   -0.0529018   0.0874279     0.128846     0.00839186   0.0386556   -0.131778    -0.0862765    0.146424     0.0638604    0.0735441   -0.190182    -0.0298928   -0.0143194   -0.00139183    0.0687984    0.0892027    -0.0649618     0.0140679   -0.196408     -0.013219    -0.0590213   0.0534        0.121972     -0.0865725   0.00231198
 -0.0597614   -0.157301   -0.0136986    -0.019174    -0.108182     0.152365    -0.116536    -0.130644    -0.105591     0.0988736   -0.0382126   -0.162502    -0.0762636   -0.199252    -0.0177911    -0.186821    -0.0297933     0.0208723     0.0813712   -0.00857611    0.0907224   -0.0664346  -0.0761774     0.179245     -0.0186886   0.020545
  0.0903253    0.0841481  -0.107489      0.0343916   -0.0294283    0.114571    -0.063301     0.102689    -0.188617    -0.00537551  -0.0221302    0.0354226    0.0171742   -0.0820092    0.123598     -0.161328    -0.178319     -0.143604     -0.125205    -0.000911713   0.0744358   -0.0909884  -0.0713376    -0.0349955     0.0638861  -0.0850015
  0.0528843   -0.0719139  -0.202893      0.115586    -0.0098059    0.147918    -0.179332     0.0405483   -0.0434701   -0.100391    -0.0246176    0.0787922   -0.0390385   -0.138993     0.131275     -0.0198844   -0.0379235    -0.0917023    -0.0131449   -0.118589      0.0542931    0.0627916   0.151155      0.0565095     0.0491359   0.0637274
  0.00643959   0.0195286  -0.0111843     0.0819009   -0.191105    -0.0532658   -0.136847    -0.018601     0.293449     0.0291156    0.015203     0.154021    -0.0219808    0.0541836    0.0651467     0.112208     0.0261542    -0.00400969   -0.224931    -0.0250505    -0.0363308    0.107506    0.196409      0.154928      0.0854505  -0.0384067
 -0.0502671    0.0321928  -0.0794688    -0.0238174    0.014435    -0.0223128   -0.0638322   -0.123462     0.0745333    0.103189     0.226314     0.00366093  -0.0364634    0.0537187   -0.0991348    -0.0507998   -0.227525      0.00477222    0.0510198   -0.0735104    -0.182598    -0.165873    0.104685      0.031148      0.12043     0.241188
 -0.111057    -0.153706    0.0554699     0.287802     0.022294     0.0685391   -0.0979967   -0.130437     0.0513207   -0.0364053    0.00398181  -0.0581014    0.123283     0.0206937   -0.0479943     0.032813    -0.153148      0.0546124    -0.0274627   -0.0866307    -0.0229664    0.140836    0.0654958     0.0332312     0.10779     0.0760547
 -0.114917    -0.0483447   0.00859104    0.147677    -0.0732659   -0.0676816   -0.0522322   -0.0954844   -0.0959116    0.0367731   -0.182772    -0.0138218   -0.0324294   -0.0258664    0.0122871     0.08167     -0.133969     -0.132184     -0.0450353    0.0822962     0.0172635    0.0835176  -0.0097201     0.156562      0.075358    0.0086764
  0.0570172    0.0540782   0.127908     -0.0374027    0.0368771    0.0540524    0.0320758   -0.0148242   -0.13082      0.124395    -0.0724966    0.0116716   -0.0157584   -0.00403926   0.0109074     0.0612678    0.0856696     0.0850756     0.0540475   -0.0374877     0.0882106    0.268474    0.0275692    -0.191897      0.0354855   0.001168
  0.141653    -0.0669152   0.00361505    0.0893305    0.0856944   -0.101943     0.187518    -0.00920231   0.138902     0.0442788    0.170008     0.144816    -0.11319      0.0932817   -0.147892      0.175911    -0.0204183    -0.0671135    -0.046595    -0.0249339    -0.155981     0.0929986   0.0470231    -0.16548       0.0665739  -0.144124
 -0.123373     0.166505    0.0803456     0.0152882    0.123839     0.204145    -0.0169335   -0.0571522    0.00363991   0.12624     -0.0137502   -0.169295     0.0979121    0.0764186    0.0607335    -0.0352465    0.177396     -0.0521881    -0.0165458   -0.0689722    -0.0735649   -0.0972634   0.0110766    -0.0186886    -0.0709551   0.134655
 -0.00140439   0.0949529  -0.0416089     0.0601399   -0.116367    -0.136901    -0.012466     0.047822    -0.128778    -0.1963       0.00493272  -0.0401034   -0.0997973   -0.0302771    0.0772017    -0.0428889   -0.161989      0.0553144     0.0621256   -0.0608858    -0.0820327   -0.0946202   0.141155     -0.035192     -0.0754517  -0.00404874
  0.0516144    0.0883588   0.0646085     0.00924841   0.0964803    0.0616914    0.0870021    0.0519408    0.11401      0.0662696   -0.14943      0.0769178   -0.0585256    0.186492    -0.208019      0.0108517    0.147613     -0.0638748    -0.126951     0.0391956    -0.056843    -0.152792   -0.104337      0.0666689     0.110878    0.124725
  0.112566     0.258386   -0.039279     -0.142307    -0.0195564    0.114412    -0.0813811   -0.0719622    0.0248471   -0.0017248    0.124346     0.20277      0.149524     0.0375799   -0.0676771    -0.0894683    0.153499      0.236215     -0.00112205   0.222132     -0.0452748   -0.0734589  -0.0485102    -0.119442      0.132169   -0.110377
 -0.077088     0.0284259   0.0889561    -0.0861707    0.0517326    0.056316    -0.0782084    0.0834705   -0.0579803   -0.12069     -0.104194     0.107733     0.0449902   -0.0115423    0.15222       0.00707311  -0.139357      0.00558647   -0.196202     0.00672511   -0.0453573   -0.0168723   0.0816369     0.0702018    -0.170857   -0.0909307
  0.0284986    0.122498   -0.0177993     0.177719    -0.247619    -0.100886    -0.0592328    0.0124024   -0.0306038    0.0803003    0.040605     0.0347117   -0.0607193   -0.100434     0.0948594    -0.104151    -0.0659665     0.30582      -0.0779576    0.0157949    -0.142115    -0.194073   -0.127895      0.0537092     0.0532689   0.150044
  0.0305649    0.125035   -0.104641     -0.0345234   -0.00518395   0.0359101    0.100465    -0.0430569   -0.0467863   -0.0173005    0.141269     0.0731486    0.0258678   -0.252918    -0.0383747    -0.144223     0.080921     -0.0449715     0.0109211   -0.0787045    -0.0808276   -0.025096    0.106486     -0.0493287     0.0694622  -0.127501kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.409712127564479
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409798
[ Info: iteration 2, average log likelihood -1.409720
[ Info: iteration 3, average log likelihood -1.409260
[ Info: iteration 4, average log likelihood -1.404087
[ Info: iteration 5, average log likelihood -1.386160
[ Info: iteration 6, average log likelihood -1.376814
[ Info: iteration 7, average log likelihood -1.374940
[ Info: iteration 8, average log likelihood -1.373831
[ Info: iteration 9, average log likelihood -1.373028
[ Info: iteration 10, average log likelihood -1.372451
[ Info: iteration 11, average log likelihood -1.372072
[ Info: iteration 12, average log likelihood -1.371817
[ Info: iteration 13, average log likelihood -1.371632
[ Info: iteration 14, average log likelihood -1.371491
[ Info: iteration 15, average log likelihood -1.371380
[ Info: iteration 16, average log likelihood -1.371294
[ Info: iteration 17, average log likelihood -1.371224
[ Info: iteration 18, average log likelihood -1.371164
[ Info: iteration 19, average log likelihood -1.371110
[ Info: iteration 20, average log likelihood -1.371058
[ Info: iteration 21, average log likelihood -1.371003
[ Info: iteration 22, average log likelihood -1.370940
[ Info: iteration 23, average log likelihood -1.370860
[ Info: iteration 24, average log likelihood -1.370749
[ Info: iteration 25, average log likelihood -1.370604
[ Info: iteration 26, average log likelihood -1.370458
[ Info: iteration 27, average log likelihood -1.370333
[ Info: iteration 28, average log likelihood -1.370243
[ Info: iteration 29, average log likelihood -1.370182
[ Info: iteration 30, average log likelihood -1.370142
[ Info: iteration 31, average log likelihood -1.370114
[ Info: iteration 32, average log likelihood -1.370094
[ Info: iteration 33, average log likelihood -1.370079
[ Info: iteration 34, average log likelihood -1.370068
[ Info: iteration 35, average log likelihood -1.370059
[ Info: iteration 36, average log likelihood -1.370052
[ Info: iteration 37, average log likelihood -1.370046
[ Info: iteration 38, average log likelihood -1.370042
[ Info: iteration 39, average log likelihood -1.370037
[ Info: iteration 40, average log likelihood -1.370034
[ Info: iteration 41, average log likelihood -1.370031
[ Info: iteration 42, average log likelihood -1.370029
[ Info: iteration 43, average log likelihood -1.370027
[ Info: iteration 44, average log likelihood -1.370025
[ Info: iteration 45, average log likelihood -1.370023
[ Info: iteration 46, average log likelihood -1.370022
[ Info: iteration 47, average log likelihood -1.370020
[ Info: iteration 48, average log likelihood -1.370019
[ Info: iteration 49, average log likelihood -1.370018
[ Info: iteration 50, average log likelihood -1.370017
┌ Info: EM with 100000 data points 50 iterations avll -1.370017
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4097981562474051
│     -1.4097197888080542
│      ⋮
└     -1.370017221885612
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.370143
[ Info: iteration 2, average log likelihood -1.370005
[ Info: iteration 3, average log likelihood -1.369205
[ Info: iteration 4, average log likelihood -1.361666
[ Info: iteration 5, average log likelihood -1.342742
[ Info: iteration 6, average log likelihood -1.331576
[ Info: iteration 7, average log likelihood -1.328022
[ Info: iteration 8, average log likelihood -1.325894
[ Info: iteration 9, average log likelihood -1.324285
[ Info: iteration 10, average log likelihood -1.323159
[ Info: iteration 11, average log likelihood -1.322352
[ Info: iteration 12, average log likelihood -1.321814
[ Info: iteration 13, average log likelihood -1.321489
[ Info: iteration 14, average log likelihood -1.321311
[ Info: iteration 15, average log likelihood -1.321217
[ Info: iteration 16, average log likelihood -1.321164
[ Info: iteration 17, average log likelihood -1.321132
[ Info: iteration 18, average log likelihood -1.321110
[ Info: iteration 19, average log likelihood -1.321093
[ Info: iteration 20, average log likelihood -1.321080
[ Info: iteration 21, average log likelihood -1.321069
[ Info: iteration 22, average log likelihood -1.321060
[ Info: iteration 23, average log likelihood -1.321054
[ Info: iteration 24, average log likelihood -1.321049
[ Info: iteration 25, average log likelihood -1.321045
[ Info: iteration 26, average log likelihood -1.321043
[ Info: iteration 27, average log likelihood -1.321041
[ Info: iteration 28, average log likelihood -1.321040
[ Info: iteration 29, average log likelihood -1.321039
[ Info: iteration 30, average log likelihood -1.321038
[ Info: iteration 31, average log likelihood -1.321038
[ Info: iteration 32, average log likelihood -1.321037
[ Info: iteration 33, average log likelihood -1.321037
[ Info: iteration 34, average log likelihood -1.321037
[ Info: iteration 35, average log likelihood -1.321036
[ Info: iteration 36, average log likelihood -1.321036
[ Info: iteration 37, average log likelihood -1.321036
[ Info: iteration 38, average log likelihood -1.321036
[ Info: iteration 39, average log likelihood -1.321036
[ Info: iteration 40, average log likelihood -1.321036
[ Info: iteration 41, average log likelihood -1.321036
[ Info: iteration 42, average log likelihood -1.321036
[ Info: iteration 43, average log likelihood -1.321036
[ Info: iteration 44, average log likelihood -1.321036
[ Info: iteration 45, average log likelihood -1.321036
[ Info: iteration 46, average log likelihood -1.321036
[ Info: iteration 47, average log likelihood -1.321036
[ Info: iteration 48, average log likelihood -1.321036
[ Info: iteration 49, average log likelihood -1.321036
[ Info: iteration 50, average log likelihood -1.321036
┌ Info: EM with 100000 data points 50 iterations avll -1.321036
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3701431556424752
│     -1.3700050660952217
│      ⋮
└     -1.3210359510179073
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321200
[ Info: iteration 2, average log likelihood -1.321057
[ Info: iteration 3, average log likelihood -1.320811
[ Info: iteration 4, average log likelihood -1.318558
[ Info: iteration 5, average log likelihood -1.306889
[ Info: iteration 6, average log likelihood -1.289306
[ Info: iteration 7, average log likelihood -1.280116
[ Info: iteration 8, average log likelihood -1.276163
[ Info: iteration 9, average log likelihood -1.274042
[ Info: iteration 10, average log likelihood -1.272546
[ Info: iteration 11, average log likelihood -1.271263
[ Info: iteration 12, average log likelihood -1.270113
[ Info: iteration 13, average log likelihood -1.269159
[ Info: iteration 14, average log likelihood -1.268473
[ Info: iteration 15, average log likelihood -1.268052
[ Info: iteration 16, average log likelihood -1.267810
[ Info: iteration 17, average log likelihood -1.267672
[ Info: iteration 18, average log likelihood -1.267590
[ Info: iteration 19, average log likelihood -1.267538
[ Info: iteration 20, average log likelihood -1.267500
[ Info: iteration 21, average log likelihood -1.267469
[ Info: iteration 22, average log likelihood -1.267441
[ Info: iteration 23, average log likelihood -1.267412
[ Info: iteration 24, average log likelihood -1.267379
[ Info: iteration 25, average log likelihood -1.267340
[ Info: iteration 26, average log likelihood -1.267290
[ Info: iteration 27, average log likelihood -1.267228
[ Info: iteration 28, average log likelihood -1.267160
[ Info: iteration 29, average log likelihood -1.267092
[ Info: iteration 30, average log likelihood -1.267028
[ Info: iteration 31, average log likelihood -1.266973
[ Info: iteration 32, average log likelihood -1.266928
[ Info: iteration 33, average log likelihood -1.266890
[ Info: iteration 34, average log likelihood -1.266860
[ Info: iteration 35, average log likelihood -1.266835
[ Info: iteration 36, average log likelihood -1.266816
[ Info: iteration 37, average log likelihood -1.266800
[ Info: iteration 38, average log likelihood -1.266787
[ Info: iteration 39, average log likelihood -1.266776
[ Info: iteration 40, average log likelihood -1.266767
[ Info: iteration 41, average log likelihood -1.266761
[ Info: iteration 42, average log likelihood -1.266755
[ Info: iteration 43, average log likelihood -1.266751
[ Info: iteration 44, average log likelihood -1.266747
[ Info: iteration 45, average log likelihood -1.266745
[ Info: iteration 46, average log likelihood -1.266742
[ Info: iteration 47, average log likelihood -1.266741
[ Info: iteration 48, average log likelihood -1.266739
[ Info: iteration 49, average log likelihood -1.266738
[ Info: iteration 50, average log likelihood -1.266738
┌ Info: EM with 100000 data points 50 iterations avll -1.266738
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.321199862214837
│     -1.3210571144628966
│      ⋮
└     -1.2667377297729698
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.266924
[ Info: iteration 2, average log likelihood -1.266692
[ Info: iteration 3, average log likelihood -1.265621
[ Info: iteration 4, average log likelihood -1.254248
[ Info: iteration 5, average log likelihood -1.223504
[ Info: iteration 6, average log likelihood -1.198169
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.184312
[ Info: iteration 8, average log likelihood -1.192958
[ Info: iteration 9, average log likelihood -1.182649
[ Info: iteration 10, average log likelihood -1.177634
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.172971
[ Info: iteration 12, average log likelihood -1.188661
[ Info: iteration 13, average log likelihood -1.180376
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.175328
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.181274
[ Info: iteration 16, average log likelihood -1.182956
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.175452
[ Info: iteration 18, average log likelihood -1.181136
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.175870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.178387
[ Info: iteration 21, average log likelihood -1.181976
[ Info: iteration 22, average log likelihood -1.176209
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.171671
[ Info: iteration 24, average log likelihood -1.185482
[ Info: iteration 25, average log likelihood -1.177236
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.171968
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.178469
[ Info: iteration 28, average log likelihood -1.180889
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.173317
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.179079
[ Info: iteration 31, average log likelihood -1.180670
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.173003
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.178624
[ Info: iteration 34, average log likelihood -1.180261
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.172405
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.177943
[ Info: iteration 37, average log likelihood -1.179517
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.171635
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.177373
[ Info: iteration 40, average log likelihood -1.178897
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.170977
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.176671
[ Info: iteration 43, average log likelihood -1.177881
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.169980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.176011
[ Info: iteration 46, average log likelihood -1.177483
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.169855
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.176016
[ Info: iteration 49, average log likelihood -1.177469
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.169854
┌ Info: EM with 100000 data points 50 iterations avll -1.169854
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2669240516360445
│     -1.2666915654017892
│      ⋮
└     -1.1698539553735054
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.176194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.171440
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.165890
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.156201
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.116535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110898
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.109964
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.100849
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.098374
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.114529
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.089833
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     22
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.093542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.107061
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.099420
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.087461
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.107360
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.094101
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097967
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.101400
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.094531
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.092900
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.111980
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.088596
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     22
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.093320
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.106903
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099359
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.087423
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.107312
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.093990
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.097805
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.101059
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     22
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.093075
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.085384
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.098127
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.089901
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.092127
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.095177
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090854
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.091065
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.108026
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.084371
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     19
│     20
│     22
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.081485
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.107897
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.097304
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.082698
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     17
│     19
│     20
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.087173
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.097077
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.096614
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.099358
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     19
│     20
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084070
┌ Info: EM with 100000 data points 50 iterations avll -1.084070
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1761938165941501
│     -1.171440484165315
│      ⋮
└     -1.0840703932323943
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.409712127564479
│     -1.4097981562474051
│     -1.4097197888080542
│     -1.4092597321568663
│      ⋮
│     -1.0966140031518397
│     -1.0993583607013029
└     -1.0840703932323943
32×26 Array{Float64,2}:
 -0.0922939   -0.158428    -0.0204372    -0.0295439   -0.0974092    0.154154    -0.117324    -0.133891    -0.105548      0.0635026   -0.0287078   -0.191975    -0.0913276   -0.199102     0.0152583   -0.236491   -0.0157891   0.017874     0.0829322   -0.00294056    0.093386    -0.0677748   -0.0764501    0.18683     -0.0110705    0.0865403
 -0.0215413   -0.0306417    0.00849695    0.0925672   -0.0386745   -0.0747663    0.0165294    0.0330286   -0.120808     -0.0929346   -0.101893    -0.0675053    0.0303089    0.0236701   -0.0431012    0.0581432  -0.142483   -0.056844     0.00843599   0.0216613     0.0162414    0.0157233    0.0128095    0.0145457    0.00561213   0.0441721
 -0.02057     -0.00877179   0.0809419     0.138861    -0.0873328    0.0823712    0.0856465   -0.0872953   -0.618157     -0.0685191   -0.0980955   -0.0807393   -0.0691982    0.144176     0.0644571   -0.0666659  -0.0461517  -0.133885     0.0916617    0.0872263     0.134287     0.0802803   -0.0106972    0.0105056   -0.11852      0.234012
 -0.035777     0.0249833    0.158241     -0.0326303   -0.0507725    0.0744237   -0.296175    -0.0863589    0.439265     -0.0978086   -0.0998077   -0.0581316   -0.0768742    0.0817913    0.0771599    0.141162   -0.132262   -0.130277     6.55474e-5   0.0644683    -0.0444542    0.136039     0.0435914    0.0206149    0.0798176    0.00689027
  0.0636769   -0.170262     0.0120666    -0.207111     0.0606586    0.0519816    0.275089    -0.109332    -0.592505     -0.0477309    0.0707902   -0.0976597    0.157447     0.0670204    0.0852717   -0.0940289  -0.0992256   0.0356496   -0.218792     0.272989      0.0756254   -0.1373      -0.300871    -0.0511032   -0.0154756   -0.0975329
  0.0660077   -0.0196719   -0.0306392    -0.174506     0.132159     0.0702965    0.112758    -0.0661761    0.494785     -0.157492     0.0658752    0.0823742    0.234953     0.0556584    0.132367    -0.109495   -0.0158838  -0.0344081   -0.0514569    0.0499799    -0.164979     0.154185    -0.202036     0.0396259    0.117212    -0.0890076
  0.0839054    0.0828031   -0.109141      0.015218    -0.0184213    0.114044    -0.0667044    0.0693322   -0.173378      0.00333301  -0.0225962    0.0344386    0.0167272   -0.083927     0.124977    -0.169285   -0.156789   -0.128237    -0.125034    -0.000868926   0.0999614   -0.159908    -0.0765271   -0.0234514    0.0642703   -0.0871106
  0.0481042   -0.018337     0.0186619     0.110109     0.00291337  -0.0204366    0.0426798    0.0538027    0.154404      0.028471    -0.136188    -0.0666998   -0.0417522   -0.172311     0.158339     0.0237443  -0.03442     0.0169528   -0.143426    -0.152359     -0.168254     0.205239    -0.105836    -0.0112397   -0.0506117   -0.03692
  0.0834397    0.152091     0.014224      0.0736799    0.082697     0.0449893    0.116398     0.145615    -0.0526752     0.0339835   -0.0766829    0.148106     0.00665305  -0.0234757    0.00863519  -0.0933481   0.0290811   0.0319388    0.00437226   0.15889       0.0800453   -0.0662041    0.0957144   -0.0511888   -0.142583    -0.139793
 -0.127339     0.0649677    0.0261881     0.109102    -0.12427      0.127732    -0.134763    -0.0793398   -0.193997     -0.0618971   -0.0308843    0.185671    -0.0811608   -0.177273     0.0511506    0.173454    0.0559109  -0.0985376   -0.218369    -0.014366     -0.102646    -0.183271    -0.0915607    0.0951792    0.162419    -0.294169
  0.0683602   -0.120625     0.11531      -0.026956     0.00598586   0.0981105   -0.0672695    0.0342915   -0.0431257    -0.0862526    0.0784468   -0.050961     0.0634426   -0.126595    -0.021041    -0.0496279   0.0753875  -0.00107421   0.0517644    0.0960808     0.0790153   -0.00132053   0.0609383   -0.0466681   -0.0562422   -0.0331503
  0.031088    -0.111383     0.0115872     0.180246     0.0532506   -0.00447008   0.0421837   -0.0608295    0.0920196    -0.0163218    0.0898021    0.0393612    0.0136209    0.0466752   -0.100318     0.101171   -0.0536219  -0.00213448  -0.0452291   -0.0628795    -0.0840092    0.106758     0.0468624   -0.0931253    0.110802    -0.0355473
  0.0467485   -0.0807139   -0.0492403     0.0396373    0.0603909    0.00474794   0.0948323    0.0988437   -0.0444507     0.141952    -0.0809326   -0.148069    -0.00675579  -0.229722    -0.0677896   -0.0914408  -0.0837214  -0.0165848    0.072482    -0.101462     -0.108348     0.113999     0.00749105  -0.09729     -0.142776     0.168517
  0.0220637   -0.0683956    0.0522815    -0.0371267   -0.0239156   -0.0130986   -0.0553575    0.00339065   0.041685      0.0367665    0.00654696   0.0504798   -0.126118     0.0584858   -0.0034288   -0.0467469  -0.0849467  -0.00178956   0.0623502    0.0256812     0.084446     0.0889894   -0.0429349    0.0517808    0.113203     0.0770102
 -0.0447163    0.0229418   -0.0970888    -0.00868701   0.015341    -0.0293121   -0.060696    -0.0972152    0.0407351     0.105123     0.213952     0.0164377   -0.0442497    0.0713769   -0.0961763   -0.048425   -0.233445   -0.00551199   0.0347041   -0.0703305    -0.191516    -0.135328     0.122011     0.0423562    0.118492     0.24853
 -0.00854968  -0.151286    -0.199081      0.0919481   -0.0942906    0.14013      0.00383523  -0.00118241   0.127593      0.134796    -0.084541    -0.131249    -0.0780437   -0.094622     0.0484417    0.022908    0.0673758  -0.142561     0.014578     0.07669       0.0476936   -0.109748     0.0184299   -0.141251     0.231046    -0.208797
  0.104659    -0.0223512    0.0420829    -0.0414336    0.0673062    0.00797318   0.00190942   0.153518    -0.121701     -0.190635    -0.0981508   -0.146832     0.21952      0.117355    -0.304158     0.0839657  -0.0946813  -0.0639977    0.0458629    0.0320983     0.0314835    0.0300884   -0.0333092   -0.0289462    0.0258096    0.0126609
  0.0440879    0.128786    -0.0899122    -0.0317238    0.00353111   0.0233502    0.0985221   -0.0548761   -0.0709471    -0.00758778   0.148953     0.0693834    0.0251103   -0.301814    -0.0420399   -0.132869    0.0650388  -0.0518665    0.00600416  -0.0675729    -0.0626029   -0.0363117    0.112911    -0.053586     0.0688348   -0.163249
 -0.0984993    0.214611     0.110391     -0.196486     0.159542     0.256232    -0.099212    -0.069031    -0.00537171    0.125906     0.0201756    0.0850836    0.0753775   -0.0419483   -0.109162    -0.40699     0.362729    0.0699544   -0.0172368   -0.00993805   -0.190438    -0.0354002    0.0283697    0.10477     -0.0460805    0.145575
 -0.0528534    0.125061     0.000848835   0.243285     0.0854561    0.194794     0.00704314  -0.0776377   -0.000194844   0.125905    -0.00738274  -0.364275     0.108471     0.151908     0.250343     0.386153    0.0318654  -0.217065    -0.0172737   -0.0449696     0.210772    -0.123363    -0.0220667   -0.173029    -0.0994826    0.119145
  0.0575172    0.0673502    0.00895104    0.0341966    0.102282     0.0652838    0.0471038    0.0412372    0.0719034     0.0584404   -0.149077     0.0695493   -0.0627227    0.152283    -0.193973     0.0130841   0.117913   -0.0151307   -0.134878     0.0340177    -0.0721242   -0.141142    -0.116263     0.054596     0.115682     0.125449
  0.0581049    0.0480375    0.123109     -0.038393     0.0389587    0.0520956    0.0169465   -0.00730185  -0.129818      0.126716    -0.0727587   -0.00160935  -0.0207726    0.011612     0.00478475   0.0599405   0.0808417   0.114202     0.0702043   -0.0377509     0.076662     0.259003     0.00739169  -0.213535     0.0317862   -0.0052666
  0.0276835   -0.0288035   -0.106904      0.0875832   -0.116652     0.0134542   -0.148886     0.00632277   0.146768     -0.0509001   -0.00667047   0.102217    -0.0158108   -0.0720555    0.0887358    0.0465951  -0.0115919  -0.0432671   -0.120145    -0.0996558    -0.0137642    0.0780884    0.177889     0.104002     0.0583364    0.00494375
  0.0777037    0.100114    -0.0475614     0.20586      0.0937044   -0.0788989   -0.00745715  -0.100689    -0.047299      0.00532189   0.00160112  -0.0447363    0.106666     0.0620802    0.048628    -0.0366037  -0.0911976   0.0430599    0.0616037    0.0363752    -0.0740903    0.0668588    0.0177494    0.195103    -0.0402411    0.0496584
  0.0040316   -0.0424675    0.0797448    -0.125291     0.0564771    0.0482166   -0.131899    -0.0478343    0.0562182     0.0619687   -0.242869    -0.165605    -0.0384829   -0.0463152    0.0728795    0.0678391   0.0610427  -0.200792     0.0166453   -0.278509     -0.0109251   -0.0542874    0.0886184    0.11919     -0.0860928   -1.34778
  0.0326658   -0.0825924    0.0912026     0.324299     0.0586558    0.0712381   -0.131699    -0.124977     0.208216      0.0622115    0.258183    -0.242383    -0.0201271   -0.0155618   -0.0233983    0.0665086  -0.0648524  -0.100788     0.0117351   -0.16783      -0.0192029   -0.0593229    0.0624334    0.141842    -0.0864095    0.999515
  0.194347     0.159535    -0.107156     -0.0549506    0.0540465    0.250189    -0.0691011   -0.406404    -0.031713      0.164112     0.0992814   -0.0464057    0.0459037   -0.121833     0.167702     0.0888473   0.0252279  -0.0761974    0.0300253    0.0883601     0.182665    -0.0123403    0.14307     -0.190355    -0.100238     0.0101762
  0.0934293    0.0798232   -0.0585792    -0.0749227    0.261048     0.0938829   -0.0243106    0.3195       0.0923055     0.217767     0.0536818   -0.0172018   -0.046406    -0.140713     0.183685    -0.0435099  -0.042979    0.286829     0.0172546    0.0763907     0.0533167   -0.0115812    0.0490978   -0.0956968   -0.0723641    0.0091991
 -0.0761522    0.050963     0.111673     -0.0853678    0.0473502    0.0578296   -0.0779079    0.0867001   -0.101727     -0.136563    -0.098445     0.0955487    0.0484072   -0.00815987   0.150618     0.0095518  -0.129937    0.004166    -0.191212     0.0022786    -0.0556394   -0.0142271    0.0624184    0.0696451   -0.170847    -0.0829595
 -0.164637    -0.0669445   -0.0254345     0.124316    -0.128315     0.00508187   0.207756    -0.0906918   -0.0244522     0.0198745    0.166262     0.031721    -0.103884     0.0725961   -0.00868395  -0.129029    0.0927631   0.11987     -0.0958393   -0.199534      0.00959593  -0.15869     -0.148617    -0.00486353  -0.0365521    0.0217757
  0.105503     0.287107    -0.0396272    -0.143011    -0.0290171    0.123313    -0.0772701   -0.0634393    0.0234055    -0.0169563    0.118134     0.203112     0.139057     0.0321946   -0.0635128   -0.0894405   0.166143    0.247444     0.0306026    0.211193     -0.0270713   -0.0788606   -0.0232268   -0.0936491    0.131306    -0.105928
  0.0241371    0.12504     -0.0114981     0.18534     -0.25567     -0.148761    -0.0649035    0.0121299   -0.0336442     0.0736347    0.059063     0.0241942   -0.0160016   -0.0882928    0.0906905   -0.0923232  -0.057854    0.332903    -0.0673272    0.0235133    -0.134886    -0.193966    -0.127011     0.0491617    0.0529508    0.102378[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.083236
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     17
│     19
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.066526
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.069001
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     15
│     16
│     17
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.051760
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     16
│     22
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072001
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│     15
│     16
│     17
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.052796
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     15
│     16
│     19
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070310
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│     15
│     16
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046461
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     22
│     26
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068601
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│     15
│     16
│     17
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.058948
┌ Info: EM with 100000 data points 10 iterations avll -1.058948
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.972893e+05
      1       6.802692e+05      -2.170201e+05 |       32
      2       6.532930e+05      -2.697622e+04 |       32
      3       6.363776e+05      -1.691541e+04 |       32
      4       6.274963e+05      -8.881316e+03 |       32
      5       6.222347e+05      -5.261592e+03 |       32
      6       6.186854e+05      -3.549267e+03 |       32
      7       6.159038e+05      -2.781617e+03 |       32
      8       6.134114e+05      -2.492368e+03 |       32
      9       6.117733e+05      -1.638121e+03 |       32
     10       6.109296e+05      -8.437331e+02 |       32
     11       6.102959e+05      -6.336251e+02 |       32
     12       6.095257e+05      -7.702270e+02 |       32
     13       6.083856e+05      -1.140110e+03 |       32
     14       6.068242e+05      -1.561394e+03 |       32
     15       6.054336e+05      -1.390650e+03 |       32
     16       6.048984e+05      -5.351753e+02 |       32
     17       6.046823e+05      -2.160718e+02 |       32
     18       6.045642e+05      -1.181478e+02 |       32
     19       6.044886e+05      -7.558043e+01 |       32
     20       6.044271e+05      -6.148238e+01 |       32
     21       6.043664e+05      -6.067587e+01 |       32
     22       6.042947e+05      -7.172384e+01 |       32
     23       6.042215e+05      -7.320115e+01 |       32
     24       6.041499e+05      -7.164395e+01 |       31
     25       6.040857e+05      -6.420145e+01 |       31
     26       6.040220e+05      -6.361408e+01 |       32
     27       6.039369e+05      -8.511181e+01 |       31
     28       6.038521e+05      -8.480192e+01 |       32
     29       6.037631e+05      -8.899805e+01 |       32
     30       6.036897e+05      -7.343183e+01 |       32
     31       6.036200e+05      -6.971703e+01 |       32
     32       6.035429e+05      -7.706575e+01 |       32
     33       6.034513e+05      -9.157359e+01 |       31
     34       6.033632e+05      -8.816429e+01 |       32
     35       6.032920e+05      -7.121034e+01 |       32
     36       6.032440e+05      -4.799656e+01 |       32
     37       6.031994e+05      -4.457639e+01 |       30
     38       6.031608e+05      -3.859051e+01 |       31
     39       6.031278e+05      -3.303239e+01 |       32
     40       6.030984e+05      -2.935585e+01 |       31
     41       6.030729e+05      -2.549020e+01 |       30
     42       6.030467e+05      -2.623517e+01 |       28
     43       6.030135e+05      -3.323047e+01 |       32
     44       6.029798e+05      -3.367048e+01 |       32
     45       6.029422e+05      -3.753999e+01 |       32
     46       6.029094e+05      -3.288949e+01 |       32
     47       6.028824e+05      -2.699165e+01 |       30
     48       6.028505e+05      -3.187067e+01 |       32
     49       6.028114e+05      -3.911526e+01 |       32
     50       6.027779e+05      -3.350036e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 602777.8784477762)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.328279
[ Info: iteration 2, average log likelihood -1.299275
[ Info: iteration 3, average log likelihood -1.271093
[ Info: iteration 4, average log likelihood -1.243584
[ Info: iteration 5, average log likelihood -1.213316
[ Info: iteration 6, average log likelihood -1.168964
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.126653
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.102064
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.096840
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.108227
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.063571
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.076677
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.084248
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.057125
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.068810
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.083742
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.072484
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.074370
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.038854
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.095255
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.091237
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.053594
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     20
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.048532
[ Info: iteration 24, average log likelihood -1.097809
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.054665
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.069841
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.077033
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.075588
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.066373
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.070945
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.051250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.092469
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.085813
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│     12
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047046
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.072381
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.093792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.061377
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.063304
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.062461
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081093
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.065212
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.083772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.050295
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.072888
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.080182
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.065946
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.073693
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.091273
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.061228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.056939
┌ Info: EM with 100000 data points 50 iterations avll -1.056939
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.056533    -0.050161     0.244836    0.0364199    -0.109782     0.0752423    0.0556562    0.125815     0.0106827    -0.100924     0.0283139    -0.152483     0.018254     -0.114412    -0.108956     0.0783595    0.134107    -0.00791999   -0.0688412    0.0159048     0.124168     0.00131598   0.198316    -0.115859    -0.0848448   0.0675883
  0.0649576   -0.0904456   -0.0111358  -0.188297      0.0994909    0.061979     0.193952    -0.0877604   -0.000353728  -0.108744     0.0680361    -0.00288018   0.199551      0.0579553    0.109085    -0.101098    -0.0502749    0.000559643  -0.117539     0.154097     -0.0519634    0.0210217   -0.247471    -0.003563     0.0533163  -0.0932112
  0.0490275    0.130603    -0.0839271  -0.0367048     0.00980993   0.0233341    0.093707    -0.0496711   -0.0708189    -0.0104526    0.136981      0.0559273    0.0291268    -0.279351    -0.0562751   -0.132141     0.058655    -0.0527197     0.00985456  -0.0599339    -0.0532121   -0.029368     0.108949    -0.0510454    0.0662792  -0.15739
  0.0154628   -0.075023     0.0974186   0.116908      0.0566311    0.0688238   -0.135809    -0.0789125    0.125078      0.0735194    0.0248525    -0.200399    -0.0357813    -0.0260718    0.0220702    0.061434     0.0165648   -0.156196      0.026609    -0.218676     -0.00648458  -0.0143428    0.0734155    0.0919287   -0.0616367  -0.00350362
 -0.0595226   -0.0132795    0.186313   -0.015701     -0.176226    -0.0479128    0.137941    -0.0252322    0.0139987    -0.431492    -0.140212      0.22998      0.31377       0.0897306    0.0549026    0.0899326    0.827451    -0.158924     -0.0653942   -0.646045     -0.143548     0.031052     0.13543      0.0551736    0.109073   -0.0308184
  0.142363     0.119319    -0.0831007  -0.0650415     0.159846     0.17306     -0.0464731   -0.0455701    0.0295605     0.191797     0.0796131    -0.032406     0.000165012  -0.131368     0.176364     0.0226011   -0.00828324   0.102359      0.0240508    0.0822975     0.117684    -0.0120977    0.0967131   -0.14253     -0.0855026   0.00956136
 -0.146134     0.142413    -0.0450775  -0.0335321     0.16863      0.25527     -0.0677756   -0.0162062    0.0260787     0.127309    -0.0160208    -0.112227     0.062016     -0.0899546   -0.0326278    0.0519377    0.264825    -0.347915     -0.0156071   -0.115763     -0.167239     0.0281325   -0.0760586   -0.0826381   -0.0593596   0.117132
 -0.0289954   -0.0626234   -0.145472    0.0311119    -0.0423206    0.0555342   -0.0284979   -0.0523547    0.0869276     0.12255      0.0751023    -0.0570817   -0.0615965    -0.0122228   -0.023192    -0.0129039   -0.0867191   -0.0749629     0.0317774    0.00209147   -0.0778673   -0.128166     0.0702964   -0.0497658    0.1728      0.0276168
  0.0481836   -0.0829753   -0.0488031   0.0415347     0.0550466    0.00293985   0.0950739    0.0952385   -0.0401402     0.15871     -0.0958384    -0.146198    -0.00545083   -0.235254    -0.0693014   -0.0904986   -0.0832582   -0.0150818     0.0734142   -0.106764     -0.109308     0.116255     0.00079831  -0.10323     -0.14744     0.172089
 -0.101732    -0.0594301    0.0177708   0.138641     -0.0602211   -0.0667647   -0.0247874   -0.105405    -0.0923513     0.0362004   -0.208687      0.0128364   -0.0127413    -0.0187687    0.00703243   0.0955643   -0.132018    -0.123748     -0.0290198    0.0817596     0.0667756    0.0852052   -0.0163054    0.0806428    0.11372     0.0428003
 -0.087558    -0.16025      0.0630336   0.273118      0.0270055    0.0957603   -0.096317    -0.125963     0.0353246    -0.0378964    0.00363333   -0.0678135    0.151125      0.00613341  -0.0488273    0.0276006   -0.135584     0.057437     -0.0165973   -0.0857991    -0.020422     0.153044     0.0666716    0.0167915    0.103304    0.0707166
  0.0851474    0.0650566    0.143584   -0.0373229     0.0286313    0.0503388    0.0559723   -0.00042403  -0.136728      0.125487    -0.0747623     0.0397065   -0.0213125     0.00641755   0.00916511   0.0538732    0.0928759    0.197555      0.0789778   -0.0233765     0.0795388    0.288543     0.00388102  -0.274953     0.0334775  -0.0182299
  0.0842731    0.154216     0.0149401   0.0729767     0.0824644    0.0449866    0.111682     0.147732    -0.0522172     0.0405218   -0.0773368     0.148013     0.00361758   -0.0249781    0.00971211  -0.0919983    0.0391715    0.0282272     0.00662662   0.15904       0.0801581   -0.0630071    0.0935044   -0.0515115   -0.135693   -0.140376
  0.143072    -0.0683356   -0.0395666   0.10115       0.0852694   -0.107323     0.183551    -0.0126051    0.150202      0.00882292   0.176359      0.147231    -0.128376      0.0834345   -0.147095     0.178161    -0.00511356  -0.0638163    -0.0644214   -0.0422179    -0.162069     0.0535169    0.0337657   -0.180595     0.116369   -0.141793
  0.137125     0.0210227    0.156342   -0.0668872    -0.0460863    0.0880472   -0.0812672    0.0580911    0.0653912    -0.0568064    0.0757927     0.080635    -0.283174      0.138157     0.00036398  -0.0981998   -0.0826984   -0.00366368    0.0872975    0.061763      0.0979963    0.127818    -0.0117911    0.150211     0.136079    0.0359227
 -0.128864     0.0654326    0.0258357   0.108083     -0.124796     0.128095    -0.135346    -0.0804508   -0.200922     -0.0612428   -0.0318158     0.186567    -0.0822588    -0.179317     0.0554128    0.172604     0.0559398   -0.0942629    -0.218672    -0.0130933    -0.10145     -0.184057    -0.0911953    0.0965464    0.159977   -0.294871
  0.106848     0.281578    -0.0348466  -0.147103     -0.0173143    0.135343    -0.0827328   -0.0596612    0.0259104     0.00596916   0.104631      0.201095     0.137299      0.033744    -0.0648653   -0.0916878    0.175374     0.220582      0.0243244    0.214181     -0.0259712   -0.0744768   -0.0320943   -0.0964775    0.124647   -0.0885407
  0.0764289   -0.0469084   -0.0684933  -0.0393578     0.050747     0.11779     -0.131798     0.00288598  -0.147029     -0.0345772    0.0443139     0.0465989    0.0537855    -0.108297     0.0941667   -0.178579    -0.0747936   -0.0661735     0.00129804   0.0919566     0.0710515   -0.0851558   -0.079472    -0.00406208   0.0174385  -0.106031
  0.0569659   -0.0752287   -0.211175    0.0999585    -0.0129269    0.119259    -0.181511     0.0210618   -0.0379657    -0.0916573   -0.0226196     0.0476668   -0.0281248    -0.195715     0.12652     -0.0189103   -0.0419305   -0.0866588     0.00517939  -0.11459       0.0434477    0.0692605    0.152566     0.0586994    0.0399441   0.0656462
 -0.0677421    0.169085     0.0668425   0.0341593     0.116598     0.215119    -0.0436128   -0.0796816   -0.00540791    0.125594     0.00671783   -0.153298     0.092426      0.0705876    0.0797084   -0.00125156   0.178864    -0.0524867    -0.0174678   -0.0221371     0.0337591   -0.0846497    0.00646567  -0.0363554   -0.0749762   0.130928
  0.00938725   0.0352941   -0.0175048   0.0798938    -0.194897    -0.0829021   -0.140567    -0.00678828   0.307865      0.0404839    0.0158252     0.128769    -0.0282328     0.0480552    0.0365987    0.106024    -0.0372186    0.0118606    -0.232346    -0.0532787    -0.0564595    0.103823     0.197967     0.145831     0.0797871  -0.0448415
  0.0489445   -0.0146904    0.0137694   0.10812       0.00433993  -0.0206698    0.0424607    0.0515168    0.149752      0.0296554   -0.135268     -0.0628688   -0.0433503    -0.172941     0.159594     0.0210425   -0.0324824    0.0182795    -0.141063    -0.15285      -0.163368     0.206014    -0.105025    -0.0130607   -0.0489587  -0.0373043
 -0.0891866   -0.157602    -0.0201578  -0.0293161    -0.0988414    0.153811    -0.117395    -0.134307    -0.104718      0.0635763   -0.0294709    -0.193518    -0.0908234    -0.198844     0.0150093   -0.236554    -0.0157167    0.0180229     0.082405    -0.00248004    0.0934015   -0.0680986   -0.0754914    0.187233    -0.0113745   0.0874038
  0.0551319    0.0841637    0.0223399   0.0327544     0.104021     0.0645076    0.066217     0.0340964    0.052222      0.0798332   -0.14546       0.0744487   -0.0688215     0.153056    -0.168586     0.0120377    0.132518     0.035558     -0.120341     0.0375015    -0.0582106   -0.116181    -0.124524     0.0401434    0.111454    0.123233
  0.0796916    0.104243    -0.0494308   0.198987      0.0933917   -0.0836531   -0.00640004  -0.104965    -0.0470512     0.00350686   0.000918089  -0.0450884    0.111971      0.0655536    0.0494333   -0.036982    -0.0879249    0.0439099     0.0643855    0.0407429    -0.071171     0.0663408    0.0138635    0.197389    -0.0420021   0.048709
 -0.0770008    0.0448006    0.1131     -0.0850956     0.049352     0.0599427   -0.0774725    0.0863746   -0.100424     -0.139502    -0.102812      0.0947729    0.0463459    -0.00959267   0.150014     0.0109304   -0.134479     0.00304758   -0.191395    -0.000393339  -0.0575685   -0.0134475    0.0615995    0.0705507   -0.17175    -0.0872279
 -0.0289404    0.00535131   0.117851    0.0517482    -0.0719337    0.0784538   -0.108459    -0.0869186   -0.0799535    -0.0834154   -0.0998713    -0.0695221   -0.0723031     0.111418     0.0706468    0.0383794   -0.0925005   -0.132113      0.0466108    0.0779476     0.0417562    0.109218     0.0164894    0.0169048   -0.0183924   0.119055
 -0.0734337   -0.15883     -0.0458499  -0.00986311    0.016575    -0.0988476   -0.0193675   -0.0417241    0.0204134     0.12844     -0.0509691     0.0232361    0.0474715    -0.0236245   -0.00436479  -0.00352576  -0.0845249    0.00692856    0.040586    -0.00155361    0.0733903    0.0497518   -0.0734532   -0.0438505    0.0905206   0.102855
  0.0804727   -0.113392     0.0480197  -0.000392119   0.0773424    0.00379394   0.062433     0.172159    -0.13593      -0.176984    -0.108922     -0.168541     0.25382       0.144198    -0.278922     0.130962    -0.123612    -0.0763382     0.0119501    0.043538      0.0574403    0.0370762   -0.0884253   -0.0305815   -0.0277363   0.0170315
  0.0250738    0.12552     -0.0115285   0.182711     -0.256202    -0.146596    -0.0665674    0.0113625   -0.0323817     0.0736601    0.0636338     0.0282295   -0.0155409    -0.0883716    0.0884691   -0.0925888   -0.0563063    0.332691     -0.0661967    0.0254998    -0.134492    -0.193961    -0.128424     0.0488344    0.0529977   0.10076
 -0.00617322   0.0816826   -0.0418695   0.108659     -0.115592    -0.150987     0.0005366    0.0738814   -0.139713     -0.186651     0.0597085    -0.0725692   -0.0966631    -0.0266594    0.0809605   -0.0328725   -0.165152     0.048676      0.0456997   -0.0511046    -0.0905775   -0.0931021    0.138514    -0.0400816   -0.0763676   0.0606739
 -0.164095    -0.0643024   -0.0241996   0.12327      -0.124145     0.00367664   0.20614     -0.0911972   -0.0254305     0.0205835    0.164243      0.0311013   -0.100591      0.0706113   -0.009677    -0.126205     0.0930737    0.121184     -0.0949367   -0.201318      0.00773311  -0.157814    -0.146642    -0.00587152  -0.0364252   0.0212247[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.057866
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     12
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.026491
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     15
│     17
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.024867
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     12
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043605
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.035174
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      7
│     12
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.013317
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054745
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     15
│     17
│     20
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.026362
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     12
│     15
│     17
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.020142
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│     15
│     17
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.047378
┌ Info: EM with 100000 data points 10 iterations avll -1.047378
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0133445    0.034807    0.0641585   -0.262472     0.216284     0.0335808    0.0155832   -0.0988066     0.104949     0.00797952  -0.14095      0.104064      0.104443    0.0607021   -0.110329    -0.00965258  -0.0713324    0.0742584    0.00584154    0.0450306     0.00485635   0.033846      0.253694     0.0344787   -0.00724291   0.174118
 -0.0771382    0.0671263  -0.0210464    0.140911     0.024286     0.1887      -0.106162    -0.000746346   0.072742    -0.034442     0.0676005    0.0278076    -0.1599     -0.0793695    0.030848    -0.0712186    0.0369419    0.104908    -0.022035      0.0822824     0.0160893    0.268128     -0.09354      0.0430177   -0.0541433   -0.000449673
 -0.0187447   -0.146169    0.119717    -0.0378874   -0.181174    -0.0769233    0.0715039   -0.0422166     0.0631249   -0.0220771   -0.0642855    0.103051     -0.0231723  -0.0792715   -0.0205169    0.0198565   -0.0665415    0.0185939    0.0282014    -0.19676       0.064746     0.000129144  -0.0990295    0.06784      0.0663027   -0.0153771
 -0.110787     0.110436    0.0828771   -0.138752    -0.0961755    0.0369821    0.0384559   -0.0134437     0.00505357   0.0448719   -0.0797452   -0.101387      0.172946   -0.045555    -0.00367453  -0.0243226   -0.0620402    0.015263     0.004693      0.0806898     0.0209923    0.136801     -0.0193579   -0.00368915   0.0598392    0.0181455
 -0.171823    -0.0291397   0.0152382   -0.0892183   -0.0583138    0.0100395   -0.0140551    0.217862      0.0265201    0.0324526   -0.134589     0.117202     -0.099485   -0.0118699   -0.178232     0.0363025    0.0132412    0.0354139    0.0474807    -0.00493643   -0.19525      0.172965      0.00346944  -0.0818237   -0.129652    -0.0503004
  0.092677     0.114867    0.0124297   -0.0376362   -0.0827595    0.0059915    0.0909569   -0.0142215     0.169737    -0.0576643   -0.0043307    0.0949796    -0.128208    0.0151754   -0.0794657    0.00746354  -0.0619347   -0.0911618    0.250953      0.095682      0.0623353    0.175574      0.192977     0.135411    -0.109362    -0.164554
  0.0158733    0.0959046   0.122531    -0.0512407    0.0294645   -0.0180506   -0.0870986   -0.0821917     0.125894    -0.133126    -0.107485    -0.171783      0.0282568  -0.00556583   0.00697906  -0.0275134   -0.194251    -0.0228727   -0.0251129    -0.0605294    -0.0914437   -0.0549588    -0.0730973    0.038782     0.0320391    0.048213
  0.0379207    0.0432791  -0.0780641   -0.0939296    0.0869268    0.0295214    0.124765    -0.0856328     0.207899     0.0193629   -0.0497844   -0.0737107     0.0351889  -0.069079    -0.224044    -0.161139     0.0718854   -0.0903175    0.0173057     0.133729     -0.0204681    0.16429       0.11567      0.0720627   -0.04745      0.0199338
 -0.0182088    0.0603648  -0.0839064    0.0048936   -0.185083    -0.152415    -0.0167556    0.0695435    -0.0153282    0.0939263    0.0974415    0.0423633     0.137817    0.00558037   0.121753    -0.080663     0.0709707   -0.113576    -0.0102962    -0.106177      0.0125997   -0.0437773    -0.0250876   -0.0903118   -0.106101    -0.104728
  0.0309043    0.0462973   0.0783587   -0.0797271    0.10903     -0.0895032    0.137788    -0.0932467     0.063779     0.0454134   -0.0352416    0.0304636    -0.0273926  -0.0336941    0.0958644   -0.00445205   0.141498     0.0110287    0.0740967    -0.0210911     0.122227     0.049823     -0.0225107   -0.157873     0.165612     0.0305284
  0.0143045   -0.0860674   0.14683      0.0373986   -0.0406131    0.105769    -0.00975247   0.052765      0.0949348   -0.0286069    0.0699591   -0.223855     -0.149507    0.123723    -0.0433969   -0.0205507   -0.040814    -0.0278053    0.216444      0.0237272    -0.0862284    0.136507      0.0725743   -0.0629608    0.119089    -0.236931
  0.223363    -0.0877512  -0.0168358   -0.156572     0.239314    -0.16964      0.0928331    0.125098     -0.195486    -0.00942743   0.106534    -0.0276544    -0.109158   -0.0845461   -0.0894024    0.125005    -0.0228533    0.0840517    0.00920089    0.084007      0.115588     0.0341608     0.205635     0.0292058   -0.0579261    0.0684518
  0.00390476  -0.169945    0.105743    -0.0739036   -0.0926897   -0.058208     0.0742611    0.0456743     0.0416579    0.101612    -0.180921     0.0570755    -0.23527    -0.0666067   -0.0925684   -0.0548881   -0.0554436   -0.0177963    0.00913156   -0.053586      0.00727422   0.0239849    -0.00441578  -0.0135068    0.131262     0.0474877
 -0.0415668    0.149408    0.0699011    0.0320659    0.0136291   -0.201914    -0.0860211   -0.097882      0.111972    -0.0450646    0.214756     0.0110306    -0.286981    0.0399002    0.0600383   -0.128488    -0.0758555    0.0100269    0.197222      0.0801804     0.170942     0.0342318     0.0151128    0.109873     0.0497877   -0.011245
 -0.0335116   -0.0144029  -0.0632131   -0.0875554    0.0196875    0.0100478    0.126866    -0.0277446    -0.0170905   -0.195253     0.142602     0.0557885     0.0568168  -0.0896897   -0.0118891    0.190172     0.0515494    0.0764629   -0.0873466     0.0205245     0.00644387   0.0191285    -0.124058     0.00143502  -0.102838     0.126962
  0.111699     0.0703047   0.0481118    0.0745679   -0.108215    -0.0162598   -0.0422275   -0.101268      0.0581556    0.00375301   0.0197233    0.0747545     0.180851    0.102872    -0.0949507   -0.0316398    0.163926     0.00719106  -0.0697793    -0.0135178     0.00633568  -0.00248611    0.107935     0.0414552    0.0817871    0.00698898
  0.0300173    0.107654    0.0232319   -0.0312083    0.055433     0.0385303   -0.134358     0.00127395    0.12942      0.165366     0.0184329    0.254827     -0.0354371   0.0797853    0.0580327   -0.115701     0.00330451   0.0484264   -0.0474948    -0.0135513    -0.00776384   0.0612866    -0.142551    -0.187663     0.0423392   -0.082421
  0.0244181    0.0441738   0.00554429  -0.0561865    0.0884599    0.174063    -0.112432    -0.0621034    -0.0109807   -0.191864     0.0373319    0.0638422     0.0214734  -0.12603     -0.0260943    0.0991881    0.104079     0.114077    -0.0154277    -0.0729462    -0.0395985    0.142848      0.0365336   -0.0905855   -0.176249    -0.133751
 -0.0415981   -0.156258   -0.0171248    0.130815     0.1049       0.00339765   0.0221879   -0.0471203     0.0135524   -0.0377046   -0.0458652    0.0762617     0.046113   -0.0463285    0.120044    -0.0867234   -0.0428753   -0.151572     0.201696      0.221473     -0.123155    -0.107785      0.0336754   -0.0758797   -0.133792    -0.00857217
 -0.178266    -0.10776    -0.00413767  -0.0185004    0.0125654    0.174244    -0.00673161   0.0607167    -0.0515951   -0.17938     -0.0115971   -0.0258654     0.0473304  -0.0996985    0.0801119    0.113078    -0.0621725   -0.119102    -0.168285     -0.0225586    -0.0552795    0.0892597    -0.081233     0.108358    -0.0204331   -0.0383576
 -0.0993755   -0.0848231   0.0401439   -0.0051082    0.0285755   -0.128894     0.135328    -0.119528      0.141225     0.122492     0.00995245  -0.00888571    0.0650029   0.194897     0.05824     -0.0201948    0.00341298  -0.0739837   -0.0232125     0.062151     -0.0475493   -0.115007     -0.0649352   -0.0255891    0.101995     0.0446433
  0.0655569    0.134954   -0.0841199   -0.0663024   -0.0457232   -0.0336124    0.098992    -0.0500564    -0.031564    -0.039956     0.0785423    0.0926936     0.0643014  -0.0422593   -0.11556      0.13403     -0.0998422    0.00083109  -0.00420656    0.0532216    -0.133655    -0.0118389    -0.129036     0.0507886   -0.134284     0.0953762
 -0.0303944   -0.021334    0.169831     0.00908838   0.105007    -0.0555999    0.0083084    0.192029      0.173227    -0.0181134   -0.0214671    0.00720572   -0.110477    0.0818357    0.00293378   0.0129058   -0.0680151   -0.0732324    0.0112867    -0.0199501     0.1277       0.220173      0.128411    -0.181185     0.0249559   -0.0700826
 -0.0697554   -0.142849   -0.102133    -0.019717     0.00184845   0.0743089    0.10153      0.0481248     0.107449    -0.0872214   -0.198755    -0.141401     -0.124168   -0.0533722    0.0176285    0.014314    -0.0905464   -0.0491294    0.0960506    -0.00842764    0.0212019    0.0906554     0.127325    -0.0559391   -0.0953781   -0.139862
  0.00236034  -0.0229507  -0.0662301   -0.160655    -0.0311808    0.169398     0.00891522   0.0653667    -0.140001    -0.0272054   -0.0430268    0.000859238  -0.0960467   0.13415      0.0967663    0.196531    -0.0975558    0.0536497    0.0197164    -0.0639248    -0.00376676  -0.061226      0.151491    -0.00629712   0.0926416   -0.0504286
  0.0325968    0.0776389   0.0366436   -0.011037    -0.0208412    0.0106231    0.100621    -0.0630072    -0.0948864   -0.00570974   0.0967155    0.146352      0.0493914  -0.123984    -0.186184    -0.150985    -0.0557575   -0.110073    -0.0989736    -0.0567141    -0.134095     0.144544      0.0491392    0.0376514   -0.0956824    0.0941453
 -0.115458    -0.113658    0.167775     0.1807       0.00658799   0.0343778   -0.0467738   -0.0518452     0.021387    -0.0247501   -0.0794157   -0.0123403    -0.0290998  -0.193484     0.131793     0.0030793   -0.0483482    0.101882    -0.000705296   0.000980756  -0.124941    -0.133613     -0.19568      0.0584098   -0.155731    -0.0568476
 -0.109438     0.0321691   0.0343217    0.1951       0.0214367   -0.0249493   -0.094994    -0.00277357    0.0948397    0.0704249   -0.0329663    0.0577022    -0.0147622  -0.0316099    0.0124389   -0.203661    -0.124695     0.0426772   -0.10265       0.113346      0.291447    -0.0636323     0.29053     -0.108242    -0.0140508   -0.00726641
  0.179453    -0.0133172   0.0676755   -0.122718    -0.146758     0.176567     0.143187     0.037558     -0.0401782   -0.117804     0.0262481   -0.0194926     0.235606    0.163375    -0.0666201    0.0116752   -0.092569     0.0108407   -0.0333026     0.117524      0.118767     0.0764232    -0.116606     0.0482743    0.119122    -0.0306848
 -0.00699237  -0.0945719   0.0299656   -0.0908492   -0.044829    -0.0140429   -0.0769158    0.0322111     0.0411483    0.137413     0.0415521   -0.0111426    -0.0422027  -0.0400826   -9.61558e-5   0.0626975    0.135515     0.0371418   -0.066819     -0.0737963     0.0367328    0.0573671     0.00485957   0.0522842    0.117586    -0.00758109
 -0.15259     -0.090162    0.105589     0.0755371    0.0510373    0.108755     0.136115     0.104941      0.106129     0.00236608   0.0860808   -0.0418651    -0.0883071   0.0353181   -0.0196259   -0.0752562    0.0011729    0.0411062   -0.0637836     0.0159404     0.0971186    0.0237284    -0.131409     0.0302082    0.130188     0.117007
  0.0619652    0.101552   -0.0849809   -0.0297504    0.111353     0.0719066    0.0595276    0.0372795     0.190367    -0.0788641   -0.0605983    0.0368616    -0.0106501  -0.0274063   -0.0401481    0.0673475   -0.0187773   -0.0395721    0.0522416     0.0648068     0.0855368    0.255229      0.118155     0.107121    -0.026629    -0.0783151kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4272074730895072
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427229
[ Info: iteration 2, average log likelihood -1.427144
[ Info: iteration 3, average log likelihood -1.427073
[ Info: iteration 4, average log likelihood -1.426982
[ Info: iteration 5, average log likelihood -1.426863
[ Info: iteration 6, average log likelihood -1.426705
[ Info: iteration 7, average log likelihood -1.426491
[ Info: iteration 8, average log likelihood -1.426173
[ Info: iteration 9, average log likelihood -1.425669
[ Info: iteration 10, average log likelihood -1.424903
[ Info: iteration 11, average log likelihood -1.423933
[ Info: iteration 12, average log likelihood -1.423008
[ Info: iteration 13, average log likelihood -1.422363
[ Info: iteration 14, average log likelihood -1.422014
[ Info: iteration 15, average log likelihood -1.421851
[ Info: iteration 16, average log likelihood -1.421778
[ Info: iteration 17, average log likelihood -1.421746
[ Info: iteration 18, average log likelihood -1.421732
[ Info: iteration 19, average log likelihood -1.421726
[ Info: iteration 20, average log likelihood -1.421723
[ Info: iteration 21, average log likelihood -1.421722
[ Info: iteration 22, average log likelihood -1.421721
[ Info: iteration 23, average log likelihood -1.421720
[ Info: iteration 24, average log likelihood -1.421720
[ Info: iteration 25, average log likelihood -1.421720
[ Info: iteration 26, average log likelihood -1.421720
[ Info: iteration 27, average log likelihood -1.421720
[ Info: iteration 28, average log likelihood -1.421719
[ Info: iteration 29, average log likelihood -1.421719
[ Info: iteration 30, average log likelihood -1.421719
[ Info: iteration 31, average log likelihood -1.421719
[ Info: iteration 32, average log likelihood -1.421719
[ Info: iteration 33, average log likelihood -1.421719
[ Info: iteration 34, average log likelihood -1.421719
[ Info: iteration 35, average log likelihood -1.421719
[ Info: iteration 36, average log likelihood -1.421719
[ Info: iteration 37, average log likelihood -1.421719
[ Info: iteration 38, average log likelihood -1.421719
[ Info: iteration 39, average log likelihood -1.421719
[ Info: iteration 40, average log likelihood -1.421718
[ Info: iteration 41, average log likelihood -1.421718
[ Info: iteration 42, average log likelihood -1.421718
[ Info: iteration 43, average log likelihood -1.421718
[ Info: iteration 44, average log likelihood -1.421718
[ Info: iteration 45, average log likelihood -1.421718
[ Info: iteration 46, average log likelihood -1.421718
[ Info: iteration 47, average log likelihood -1.421718
[ Info: iteration 48, average log likelihood -1.421718
[ Info: iteration 49, average log likelihood -1.421718
[ Info: iteration 50, average log likelihood -1.421718
┌ Info: EM with 100000 data points 50 iterations avll -1.421718
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4272285856703906
│     -1.4271436666973583
│      ⋮
└     -1.4217182669539712
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421739
[ Info: iteration 2, average log likelihood -1.421652
[ Info: iteration 3, average log likelihood -1.421579
[ Info: iteration 4, average log likelihood -1.421489
[ Info: iteration 5, average log likelihood -1.421377
[ Info: iteration 6, average log likelihood -1.421250
[ Info: iteration 7, average log likelihood -1.421122
[ Info: iteration 8, average log likelihood -1.421009
[ Info: iteration 9, average log likelihood -1.420920
[ Info: iteration 10, average log likelihood -1.420854
[ Info: iteration 11, average log likelihood -1.420803
[ Info: iteration 12, average log likelihood -1.420761
[ Info: iteration 13, average log likelihood -1.420725
[ Info: iteration 14, average log likelihood -1.420691
[ Info: iteration 15, average log likelihood -1.420656
[ Info: iteration 16, average log likelihood -1.420621
[ Info: iteration 17, average log likelihood -1.420585
[ Info: iteration 18, average log likelihood -1.420547
[ Info: iteration 19, average log likelihood -1.420509
[ Info: iteration 20, average log likelihood -1.420470
[ Info: iteration 21, average log likelihood -1.420433
[ Info: iteration 22, average log likelihood -1.420398
[ Info: iteration 23, average log likelihood -1.420366
[ Info: iteration 24, average log likelihood -1.420337
[ Info: iteration 25, average log likelihood -1.420312
[ Info: iteration 26, average log likelihood -1.420291
[ Info: iteration 27, average log likelihood -1.420273
[ Info: iteration 28, average log likelihood -1.420258
[ Info: iteration 29, average log likelihood -1.420245
[ Info: iteration 30, average log likelihood -1.420235
[ Info: iteration 31, average log likelihood -1.420226
[ Info: iteration 32, average log likelihood -1.420218
[ Info: iteration 33, average log likelihood -1.420212
[ Info: iteration 34, average log likelihood -1.420207
[ Info: iteration 35, average log likelihood -1.420202
[ Info: iteration 36, average log likelihood -1.420198
[ Info: iteration 37, average log likelihood -1.420195
[ Info: iteration 38, average log likelihood -1.420192
[ Info: iteration 39, average log likelihood -1.420189
[ Info: iteration 40, average log likelihood -1.420187
[ Info: iteration 41, average log likelihood -1.420185
[ Info: iteration 42, average log likelihood -1.420184
[ Info: iteration 43, average log likelihood -1.420182
[ Info: iteration 44, average log likelihood -1.420181
[ Info: iteration 45, average log likelihood -1.420180
[ Info: iteration 46, average log likelihood -1.420179
[ Info: iteration 47, average log likelihood -1.420178
[ Info: iteration 48, average log likelihood -1.420177
[ Info: iteration 49, average log likelihood -1.420176
[ Info: iteration 50, average log likelihood -1.420176
┌ Info: EM with 100000 data points 50 iterations avll -1.420176
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.42173906050652
│     -1.4216515948353743
│      ⋮
└     -1.4201758528406443
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420191
[ Info: iteration 2, average log likelihood -1.420126
[ Info: iteration 3, average log likelihood -1.420075
[ Info: iteration 4, average log likelihood -1.420018
[ Info: iteration 5, average log likelihood -1.419950
[ Info: iteration 6, average log likelihood -1.419868
[ Info: iteration 7, average log likelihood -1.419774
[ Info: iteration 8, average log likelihood -1.419672
[ Info: iteration 9, average log likelihood -1.419568
[ Info: iteration 10, average log likelihood -1.419468
[ Info: iteration 11, average log likelihood -1.419376
[ Info: iteration 12, average log likelihood -1.419295
[ Info: iteration 13, average log likelihood -1.419228
[ Info: iteration 14, average log likelihood -1.419172
[ Info: iteration 15, average log likelihood -1.419126
[ Info: iteration 16, average log likelihood -1.419088
[ Info: iteration 17, average log likelihood -1.419054
[ Info: iteration 18, average log likelihood -1.419025
[ Info: iteration 19, average log likelihood -1.418998
[ Info: iteration 20, average log likelihood -1.418974
[ Info: iteration 21, average log likelihood -1.418952
[ Info: iteration 22, average log likelihood -1.418930
[ Info: iteration 23, average log likelihood -1.418911
[ Info: iteration 24, average log likelihood -1.418892
[ Info: iteration 25, average log likelihood -1.418874
[ Info: iteration 26, average log likelihood -1.418857
[ Info: iteration 27, average log likelihood -1.418841
[ Info: iteration 28, average log likelihood -1.418826
[ Info: iteration 29, average log likelihood -1.418811
[ Info: iteration 30, average log likelihood -1.418797
[ Info: iteration 31, average log likelihood -1.418784
[ Info: iteration 32, average log likelihood -1.418771
[ Info: iteration 33, average log likelihood -1.418758
[ Info: iteration 34, average log likelihood -1.418746
[ Info: iteration 35, average log likelihood -1.418735
[ Info: iteration 36, average log likelihood -1.418724
[ Info: iteration 37, average log likelihood -1.418714
[ Info: iteration 38, average log likelihood -1.418704
[ Info: iteration 39, average log likelihood -1.418695
[ Info: iteration 40, average log likelihood -1.418687
[ Info: iteration 41, average log likelihood -1.418679
[ Info: iteration 42, average log likelihood -1.418672
[ Info: iteration 43, average log likelihood -1.418666
[ Info: iteration 44, average log likelihood -1.418660
[ Info: iteration 45, average log likelihood -1.418654
[ Info: iteration 46, average log likelihood -1.418649
[ Info: iteration 47, average log likelihood -1.418644
[ Info: iteration 48, average log likelihood -1.418640
[ Info: iteration 49, average log likelihood -1.418636
[ Info: iteration 50, average log likelihood -1.418632
┌ Info: EM with 100000 data points 50 iterations avll -1.418632
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201906195322413
│     -1.4201257874313362
│      ⋮
└     -1.4186322955499657
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418638
[ Info: iteration 2, average log likelihood -1.418576
[ Info: iteration 3, average log likelihood -1.418520
[ Info: iteration 4, average log likelihood -1.418454
[ Info: iteration 5, average log likelihood -1.418374
[ Info: iteration 6, average log likelihood -1.418277
[ Info: iteration 7, average log likelihood -1.418164
[ Info: iteration 8, average log likelihood -1.418043
[ Info: iteration 9, average log likelihood -1.417920
[ Info: iteration 10, average log likelihood -1.417801
[ Info: iteration 11, average log likelihood -1.417690
[ Info: iteration 12, average log likelihood -1.417587
[ Info: iteration 13, average log likelihood -1.417495
[ Info: iteration 14, average log likelihood -1.417413
[ Info: iteration 15, average log likelihood -1.417342
[ Info: iteration 16, average log likelihood -1.417279
[ Info: iteration 17, average log likelihood -1.417225
[ Info: iteration 18, average log likelihood -1.417178
[ Info: iteration 19, average log likelihood -1.417136
[ Info: iteration 20, average log likelihood -1.417099
[ Info: iteration 21, average log likelihood -1.417064
[ Info: iteration 22, average log likelihood -1.417033
[ Info: iteration 23, average log likelihood -1.417003
[ Info: iteration 24, average log likelihood -1.416974
[ Info: iteration 25, average log likelihood -1.416946
[ Info: iteration 26, average log likelihood -1.416919
[ Info: iteration 27, average log likelihood -1.416892
[ Info: iteration 28, average log likelihood -1.416866
[ Info: iteration 29, average log likelihood -1.416841
[ Info: iteration 30, average log likelihood -1.416816
[ Info: iteration 31, average log likelihood -1.416792
[ Info: iteration 32, average log likelihood -1.416768
[ Info: iteration 33, average log likelihood -1.416745
[ Info: iteration 34, average log likelihood -1.416722
[ Info: iteration 35, average log likelihood -1.416700
[ Info: iteration 36, average log likelihood -1.416679
[ Info: iteration 37, average log likelihood -1.416659
[ Info: iteration 38, average log likelihood -1.416639
[ Info: iteration 39, average log likelihood -1.416620
[ Info: iteration 40, average log likelihood -1.416602
[ Info: iteration 41, average log likelihood -1.416585
[ Info: iteration 42, average log likelihood -1.416568
[ Info: iteration 43, average log likelihood -1.416553
[ Info: iteration 44, average log likelihood -1.416538
[ Info: iteration 45, average log likelihood -1.416523
[ Info: iteration 46, average log likelihood -1.416510
[ Info: iteration 47, average log likelihood -1.416497
[ Info: iteration 48, average log likelihood -1.416484
[ Info: iteration 49, average log likelihood -1.416472
[ Info: iteration 50, average log likelihood -1.416461
┌ Info: EM with 100000 data points 50 iterations avll -1.416461
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4186383317040798
│     -1.4185759135395322
│      ⋮
└     -1.4164610512589888
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416459
[ Info: iteration 2, average log likelihood -1.416382
[ Info: iteration 3, average log likelihood -1.416306
[ Info: iteration 4, average log likelihood -1.416213
[ Info: iteration 5, average log likelihood -1.416094
[ Info: iteration 6, average log likelihood -1.415946
[ Info: iteration 7, average log likelihood -1.415772
[ Info: iteration 8, average log likelihood -1.415582
[ Info: iteration 9, average log likelihood -1.415386
[ Info: iteration 10, average log likelihood -1.415194
[ Info: iteration 11, average log likelihood -1.415014
[ Info: iteration 12, average log likelihood -1.414851
[ Info: iteration 13, average log likelihood -1.414707
[ Info: iteration 14, average log likelihood -1.414581
[ Info: iteration 15, average log likelihood -1.414472
[ Info: iteration 16, average log likelihood -1.414378
[ Info: iteration 17, average log likelihood -1.414297
[ Info: iteration 18, average log likelihood -1.414226
[ Info: iteration 19, average log likelihood -1.414164
[ Info: iteration 20, average log likelihood -1.414108
[ Info: iteration 21, average log likelihood -1.414059
[ Info: iteration 22, average log likelihood -1.414014
[ Info: iteration 23, average log likelihood -1.413973
[ Info: iteration 24, average log likelihood -1.413935
[ Info: iteration 25, average log likelihood -1.413900
[ Info: iteration 26, average log likelihood -1.413867
[ Info: iteration 27, average log likelihood -1.413837
[ Info: iteration 28, average log likelihood -1.413808
[ Info: iteration 29, average log likelihood -1.413781
[ Info: iteration 30, average log likelihood -1.413756
[ Info: iteration 31, average log likelihood -1.413732
[ Info: iteration 32, average log likelihood -1.413709
[ Info: iteration 33, average log likelihood -1.413688
[ Info: iteration 34, average log likelihood -1.413667
[ Info: iteration 35, average log likelihood -1.413648
[ Info: iteration 36, average log likelihood -1.413630
[ Info: iteration 37, average log likelihood -1.413612
[ Info: iteration 38, average log likelihood -1.413596
[ Info: iteration 39, average log likelihood -1.413580
[ Info: iteration 40, average log likelihood -1.413565
[ Info: iteration 41, average log likelihood -1.413550
[ Info: iteration 42, average log likelihood -1.413537
[ Info: iteration 43, average log likelihood -1.413523
[ Info: iteration 44, average log likelihood -1.413511
[ Info: iteration 45, average log likelihood -1.413499
[ Info: iteration 46, average log likelihood -1.413487
[ Info: iteration 47, average log likelihood -1.413476
[ Info: iteration 48, average log likelihood -1.413465
[ Info: iteration 49, average log likelihood -1.413455
[ Info: iteration 50, average log likelihood -1.413445
┌ Info: EM with 100000 data points 50 iterations avll -1.413445
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4164589893327342
│     -1.4163816257092918
│      ⋮
└     -1.4134449035767527
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4272074730895072
│     -1.4272285856703906
│     -1.4271436666973583
│     -1.4270725259283075
│      ⋮
│     -1.4134652465981876
│     -1.4134548953116755
└     -1.4134449035767527
32×26 Array{Float64,2}:
  0.187001      0.320845    -0.298365    0.182332    -0.486508    0.706295   -0.399253   -0.148682     0.219568   -0.315123     -0.377836   -0.220326   -0.332757    -0.214688    0.41277    -0.26825     0.229249    -0.174618    -0.00699846   0.0370346   -0.309457     0.0506519    0.0549503  -0.394425     0.173526   -0.216923
 -0.112185      0.0643612   -0.549253    0.307579    -0.446346    0.506161    0.237823   -0.02717     -0.128523    0.0432916    -0.221306   -0.149288   -0.118238     0.103442    0.31454     0.456709    0.0206359    0.636921    -0.217696     0.0818909   -0.0419037    0.135989    -0.238012    0.505909     0.214775   -0.0262075
  0.00684989    0.102425    -0.223583    0.151294    -0.27669    -0.41202     0.065356   -0.0797652    0.0232181   0.0790399     0.242884    0.282258   -0.0944673    0.268537   -0.192676    0.137027   -0.496059     0.16196      0.329756    -0.150798     0.272817    -0.200304    -0.0669404   0.201092    -0.101435    0.0989217
 -0.19289       0.293305    -0.0606737   0.418675     0.112629   -0.0506643  -0.0173842   0.100874     0.525737    0.0995329     0.12243     0.145918   -0.22527     -0.277899   -0.321919   -0.0421518   0.663263    -0.0192193   -0.1015      -0.228179    -0.0599748   -0.203414    -0.0474246  -0.0327311   -0.217679    0.328097
  0.432684      0.10969     -1.05254    -0.627023     0.328842    0.3261      0.161905   -0.492342     0.419631   -0.164135     -0.921175    0.0708566  -0.100847    -0.52916    -0.328305    0.158244    0.0186478    0.66388     -0.359708     0.469447     0.00221632   0.213805    -0.595041   -0.200454     0.192397   -0.287984
 -0.0234733    -0.480814     0.140692   -0.691881     0.474006    0.185953   -0.101139    0.121379    -0.303179   -0.0329918     0.12271     0.161993   -0.0156593   -0.35177    -0.246783    0.0792974  -0.530028    -0.0522136   -0.729679     0.239837    -0.247629     0.182671    -0.619831   -0.0770463   -0.247954    0.0409396
  0.0113824     0.0154981   -0.0834568  -0.0941682    0.0553428   0.163809    0.102824   -0.00568715   0.0525911  -0.0983107     0.0543018   0.0623147  -0.00723166  -0.0418406  -0.0219874   0.0195375  -0.0649897   -0.00931504  -0.196104     0.0192138   -0.0508731    0.104223    -0.0682249   0.00248068   0.0198144  -0.107926
  0.0601664    -0.27947      0.160944   -0.79323     -0.020225    0.370862    0.127362    0.218557    -0.0925581   0.371854     -0.134764    0.0184037  -0.044597     0.166937   -0.0295852   0.192453   -0.0398343   -0.195662    -0.105468     0.418942    -0.0577264    0.514248     0.131111    0.0634913    0.0116456  -0.0548053
  0.102106     -0.288631     0.42815     0.272034     0.0827149   0.574307   -0.0497233   1.00448     -0.273683   -0.338697      0.0477413  -0.0214446  -0.366686     0.0313945   0.246383   -0.0577613  -0.315654     0.402682    -0.126741     0.224939    -0.186614    -0.124659     0.1372      0.0378254   -0.401334    0.529826
  0.541974      0.0815201   -0.0348422   0.325933     0.488879    0.481074    0.35326     1.01628      0.106985   -0.569539     -0.185349    0.538853   -0.0261867    0.22501     0.0891031   0.0789563   0.405928     0.430907    -0.398753    -0.00543323   0.151624     0.1206       0.442117   -0.0760672   -0.338253   -0.14591
  0.229979      0.00509114   0.35689    -0.084664    -0.0140151  -0.150103   -0.42717     0.407885    -0.500548   -0.0598228     0.286934    0.883371   -0.155953     0.0768108  -0.353059    0.179682   -0.0232712    0.140437     0.714516    -0.370016    -0.0767517   -0.00294887   0.0835709  -0.726446    -0.0154288  -0.501227
  0.197083     -0.385371     0.0486089  -0.00490566  -0.369356   -0.400353   -0.0634567  -0.184998    -0.396274   -0.169726      0.218886    0.286375   -0.727278    -0.672288    0.140971    0.508729   -0.234765     0.0141615   -0.119782    -0.647714     0.0811234    0.00121472   0.619026    0.449511     0.0706267  -0.102588
  0.0315036    -0.133554     0.606909    0.0944941    0.0569535  -0.405024   -0.184146    0.0913329   -0.114647   -0.129672     -0.0779485  -0.192285    0.020878     0.172463    0.0265202  -0.292186   -0.0691416   -0.0978755    0.63433     -0.0637624   -0.0396147    0.0580921    0.170544   -0.0184521    0.110715    0.0941283
 -0.291661      0.161459     0.114368   -0.264568     0.35781    -0.318888    0.0498547  -0.486498     0.0689798   0.0157648    -0.351991   -0.117519    0.825597    -0.214138   -0.0836745  -0.180901    0.13053     -0.293601     0.23095      0.119485     0.229743    -0.0879044    0.0586352  -0.351711     0.0126958  -0.044096
 -0.0137295     0.0946939    0.188473    0.0943305    0.06836    -0.279874    0.0281385  -0.208368    -0.169659   -0.795333     -0.240629   -0.523636    0.381554     0.0892353   0.204173   -0.968222   -0.65998      0.0769179    0.515695     0.613247     0.344275     0.309075    -0.0746206   0.110054    -0.185959    0.161315
  0.05183       0.609561     0.696995    0.214371     0.251395   -0.0222983   0.468217    0.387961     0.606161   -0.193024      0.307122   -0.82637     0.236385     0.407301    0.62        0.25122    -0.269465     0.0967321   -0.00299879   0.893865     0.63554     -0.173735     0.308886    0.163949     0.0274673  -0.000723667
  0.148002      0.108334    -0.188412   -0.465172    -0.188952    0.182002    0.245009   -0.112138     0.610128    0.81536       0.349155    0.386548   -0.150707    -0.190223   -0.126822    0.268631    0.292523     0.0597525   -0.59331     -0.0925334    0.464792    -0.299734    -0.13613    -0.408531     0.376425   -0.305035
  0.0669973     0.471827     0.947075   -0.46386     -0.149491   -0.0279349   0.17142    -0.0748397    0.564446    0.106451     -0.356436    0.299879   -0.476218    -0.348309    0.270019    0.322074   -0.0234573    0.274684    -0.218333     0.337562     0.118585     0.0328415   -0.826431   -1.36215     -0.258584   -0.113874
  0.000905988  -0.0605016   -1.08062     0.587416    -0.361659   -0.0647725   0.230144   -0.146586     0.299176   -0.438886      0.226637   -0.0249246  -0.198448    -0.479499    0.257899    0.568367   -0.262384     0.788821    -0.740576     0.150156    -0.10292     -0.659719    -0.674011    0.363321     0.15078     0.4244
 -0.0923153     0.603208    -0.170572    0.697865    -0.771019    0.18871    -0.068618    0.165686    -0.0362604   0.0943873     0.201518    0.30796    -0.44022     -0.147472   -0.0775672   0.355532    0.408037     0.342797     0.219744    -0.668157     0.044718    -0.144808     0.168435    0.267039     0.0685466   0.172645
 -0.079152      0.113307     0.561109    0.359722     0.68877     0.16182    -0.0513485  -0.142568     0.0872954  -0.937777     -0.0448487  -0.2699      0.460104    -0.222466    0.0698164  -0.297692    0.503822    -0.0792304    0.00245862  -0.570538    -0.901717     0.352991     0.512936    0.231165    -0.0882088   0.117905
  0.0935645    -0.175644     0.0926031   0.12067      0.459079    0.357634    0.245067    0.021372    -0.169608   -0.569104      0.282741    0.320702    0.132122    -0.436348    0.96538     0.0193845   0.041481    -0.226077    -0.223909    -0.0339128    0.834396     0.649706     0.243863   -0.191462    -0.0194417  -0.508197
  0.446202     -0.299127     0.0349774  -0.117079    -0.032615    0.0317832  -0.223407    0.0527233   -0.312571   -0.0872483    -0.173716   -0.0650536  -0.0288983    0.130903    0.209651   -0.11194    -0.553546    -0.00314438   0.101291     0.218911     0.010395    -0.0219312    0.0845599  -0.176025     0.173723   -0.367324
  0.152694     -0.247047     0.162539   -0.675654     0.0572167   0.660179    0.546982    0.274296     0.120152    0.137316     -0.0842586   0.0957604  -0.517646    -0.413357    0.330599    0.296689    0.189371    -0.135918    -0.666282     0.315799    -0.0385208    0.710255     0.269158    0.338112     0.156886   -0.0483136
 -0.245544      0.514239    -0.291207    0.164541    -0.291755   -0.345929    0.0843373  -0.940582     0.837601    0.22533       0.0291957  -0.503365    0.287234     0.201308   -0.028901   -0.286412    0.356974    -0.292102     0.357697    -0.217988     0.00741764  -0.261714     0.0435019   0.0192949    0.57324    -0.118558
 -0.207797     -0.173975    -0.184228   -0.322408    -0.700217   -0.281222   -0.361017   -0.697561    -0.0511892   0.561522     -0.348895   -0.192615   -0.201783     0.245005   -0.686854   -0.0499346  -0.00542355  -0.221143     0.30879     -0.0988649   -0.433048     0.155561    -0.378679    0.136863     0.307183   -0.144953
 -0.479254     -0.56278     -0.234463    0.222275     0.635593   -0.632918    0.472261   -0.375826    -0.386076   -0.170038     -0.038394   -0.136618    0.351289    -0.0985416   0.231356    0.107324   -0.29001     -0.136094     0.135479    -0.389816     0.356578    -0.11448      0.272173    0.382744    -0.0840463  -0.554127
 -0.0858279    -0.890761     0.0106317  -0.306407     0.489321   -0.635191   -0.563811   -0.0997711   -0.348303    0.441158      0.184291   -0.165579    0.549757    -0.238637   -0.333161   -0.113711   -0.0812378   -0.37066      0.149622     0.323535     0.3177      -0.123445     0.473759    0.163727     0.0666008   0.544714
 -0.0920387    -0.00444022   0.120887    0.119836     0.164708    0.271614    0.166244    0.235586     0.546232    0.203579     -0.146093   -0.0647539   0.12781      1.00661    -0.734829   -0.305056   -0.0820621   -0.502638    -0.103632     0.198012    -0.891718     0.0282613   -0.240388   -0.190855    -0.503824    0.0676905
 -0.796838      0.150115     0.11705    -0.177691     0.427047   -0.241173    0.226332    0.418865     0.182454    0.23235      -0.083984    0.294971    0.47547      0.233752   -0.642697   -0.242786    0.366875     0.229465     0.187452     0.202611     0.115366     0.0879022   -0.402565   -0.0985716   -0.618325    0.538384
 -0.52697       0.138442     1.36736    -0.155175     0.49213    -0.408262   -0.0384418  -0.781832     0.395424    0.972314      0.0874659   0.336542   -0.789198     0.60279     0.0210564  -0.507481    0.137026    -0.903093     1.10395     -0.432798     0.583377     0.482344     0.500169   -0.00290628  -0.0799942  -0.12362
 -0.156703      0.459177     0.564506    0.32984     -0.3863      0.002973   -0.12891     0.650271     0.0988139  -0.000309068   1.34333    -0.0442001   0.0905724    0.457993    0.030601   -0.384399   -0.332923    -0.809233     0.291304    -0.281256    -0.0549579    0.366457     0.37925     0.422933    -0.182099    0.226826[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413435
[ Info: iteration 2, average log likelihood -1.413426
[ Info: iteration 3, average log likelihood -1.413417
[ Info: iteration 4, average log likelihood -1.413408
[ Info: iteration 5, average log likelihood -1.413400
[ Info: iteration 6, average log likelihood -1.413391
[ Info: iteration 7, average log likelihood -1.413383
[ Info: iteration 8, average log likelihood -1.413376
[ Info: iteration 9, average log likelihood -1.413368
[ Info: iteration 10, average log likelihood -1.413361
┌ Info: EM with 100000 data points 10 iterations avll -1.413361
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.599452e+05
      1       7.160260e+05      -2.439192e+05 |       32
      2       6.986100e+05      -1.741603e+04 |       32
      3       6.926005e+05      -6.009524e+03 |       32
      4       6.896306e+05      -2.969824e+03 |       32
      5       6.877195e+05      -1.911137e+03 |       32
      6       6.864040e+05      -1.315466e+03 |       32
      7       6.854355e+05      -9.685053e+02 |       32
      8       6.846352e+05      -8.003019e+02 |       32
      9       6.839850e+05      -6.502377e+02 |       32
     10       6.834365e+05      -5.484721e+02 |       32
     11       6.829639e+05      -4.726395e+02 |       32
     12       6.825374e+05      -4.264806e+02 |       32
     13       6.821737e+05      -3.636912e+02 |       32
     14       6.818541e+05      -3.195576e+02 |       32
     15       6.815440e+05      -3.100930e+02 |       32
     16       6.812751e+05      -2.688972e+02 |       32
     17       6.810203e+05      -2.548605e+02 |       32
     18       6.807677e+05      -2.525473e+02 |       32
     19       6.805302e+05      -2.374912e+02 |       32
     20       6.803130e+05      -2.172253e+02 |       32
     21       6.801168e+05      -1.962210e+02 |       32
     22       6.799341e+05      -1.826569e+02 |       32
     23       6.797723e+05      -1.618231e+02 |       32
     24       6.796296e+05      -1.427138e+02 |       32
     25       6.794903e+05      -1.392983e+02 |       32
     26       6.793777e+05      -1.126264e+02 |       32
     27       6.792633e+05      -1.143749e+02 |       32
     28       6.791678e+05      -9.549610e+01 |       32
     29       6.790809e+05      -8.692171e+01 |       32
     30       6.790037e+05      -7.723676e+01 |       32
     31       6.789288e+05      -7.481739e+01 |       32
     32       6.788599e+05      -6.891317e+01 |       32
     33       6.787975e+05      -6.241717e+01 |       32
     34       6.787379e+05      -5.960208e+01 |       32
     35       6.786765e+05      -6.145127e+01 |       32
     36       6.786138e+05      -6.263327e+01 |       32
     37       6.785581e+05      -5.568424e+01 |       32
     38       6.785174e+05      -4.075032e+01 |       32
     39       6.784853e+05      -3.206872e+01 |       32
     40       6.784522e+05      -3.310820e+01 |       32
     41       6.784184e+05      -3.383962e+01 |       32
     42       6.783886e+05      -2.975928e+01 |       32
     43       6.783563e+05      -3.232049e+01 |       32
     44       6.783207e+05      -3.557121e+01 |       32
     45       6.782911e+05      -2.961202e+01 |       32
     46       6.782686e+05      -2.247644e+01 |       32
     47       6.782445e+05      -2.412694e+01 |       32
     48       6.782213e+05      -2.315335e+01 |       32
     49       6.781994e+05      -2.195640e+01 |       32
     50       6.781757e+05      -2.366131e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678175.7318685001)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425366
[ Info: iteration 2, average log likelihood -1.420375
[ Info: iteration 3, average log likelihood -1.418919
[ Info: iteration 4, average log likelihood -1.417751
[ Info: iteration 5, average log likelihood -1.416588
[ Info: iteration 6, average log likelihood -1.415662
[ Info: iteration 7, average log likelihood -1.415102
[ Info: iteration 8, average log likelihood -1.414796
[ Info: iteration 9, average log likelihood -1.414611
[ Info: iteration 10, average log likelihood -1.414481
[ Info: iteration 11, average log likelihood -1.414379
[ Info: iteration 12, average log likelihood -1.414294
[ Info: iteration 13, average log likelihood -1.414220
[ Info: iteration 14, average log likelihood -1.414155
[ Info: iteration 15, average log likelihood -1.414097
[ Info: iteration 16, average log likelihood -1.414044
[ Info: iteration 17, average log likelihood -1.413995
[ Info: iteration 18, average log likelihood -1.413950
[ Info: iteration 19, average log likelihood -1.413908
[ Info: iteration 20, average log likelihood -1.413868
[ Info: iteration 21, average log likelihood -1.413831
[ Info: iteration 22, average log likelihood -1.413796
[ Info: iteration 23, average log likelihood -1.413763
[ Info: iteration 24, average log likelihood -1.413732
[ Info: iteration 25, average log likelihood -1.413703
[ Info: iteration 26, average log likelihood -1.413675
[ Info: iteration 27, average log likelihood -1.413648
[ Info: iteration 28, average log likelihood -1.413623
[ Info: iteration 29, average log likelihood -1.413599
[ Info: iteration 30, average log likelihood -1.413576
[ Info: iteration 31, average log likelihood -1.413554
[ Info: iteration 32, average log likelihood -1.413533
[ Info: iteration 33, average log likelihood -1.413514
[ Info: iteration 34, average log likelihood -1.413495
[ Info: iteration 35, average log likelihood -1.413477
[ Info: iteration 36, average log likelihood -1.413461
[ Info: iteration 37, average log likelihood -1.413445
[ Info: iteration 38, average log likelihood -1.413430
[ Info: iteration 39, average log likelihood -1.413416
[ Info: iteration 40, average log likelihood -1.413403
[ Info: iteration 41, average log likelihood -1.413390
[ Info: iteration 42, average log likelihood -1.413378
[ Info: iteration 43, average log likelihood -1.413367
[ Info: iteration 44, average log likelihood -1.413357
[ Info: iteration 45, average log likelihood -1.413347
[ Info: iteration 46, average log likelihood -1.413338
[ Info: iteration 47, average log likelihood -1.413329
[ Info: iteration 48, average log likelihood -1.413321
[ Info: iteration 49, average log likelihood -1.413313
[ Info: iteration 50, average log likelihood -1.413305
┌ Info: EM with 100000 data points 50 iterations avll -1.413305
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0946144   -0.329127    0.583762    -0.278627    0.394304    -0.564067    0.690624   -0.163383      0.239723   -0.00279738  -0.0935831  -0.65596     0.41571      0.638383   -0.143496    -0.265517    -0.686431    0.092674     0.1258       0.357074   -0.0020731   0.25746    -0.0744172    0.225093     0.00254737  -0.304327
  0.290689     0.411241   -0.212322     0.484441   -0.703442     0.430856    0.514953    0.341314     -0.173402   -0.15752      0.153223    0.408839   -0.531582     0.463363    0.0936234    0.476115     0.190373    0.800046    -0.254983    -0.455754   -0.0235745   0.0991827   0.218986     0.673643     0.253012    -0.114019
 -0.00744803   0.0019938  -1.02765      0.592528   -0.372297    -0.0389741   0.248491   -0.12415       0.170627   -0.313332     0.145593    0.0318011  -0.231488    -0.399719    0.253735     0.558074    -0.352872    0.805113    -0.59214      0.0911263   0.024771   -0.610287   -0.587965     0.460767     0.112474     0.343158
 -0.393469     0.381101   -0.464953     0.0834558  -0.447693    -0.192948   -0.022131   -1.0461        0.66866     0.298928     0.0100296  -0.598008    0.205625     0.201928   -0.0580103   -0.219391     0.320796   -0.292523     0.319266    -0.262357   -0.0678746  -0.131982   -0.0933011    0.143943     0.542675    -0.158729
  0.0417045   -0.518899    0.345044    -0.642529    0.0927592    0.62508     0.250638    0.568793     -0.0906098   0.336511     0.174368    0.279008   -0.437199    -0.143079    0.205868     0.655862     0.0779501  -0.055833    -0.659031    -0.0049717  -0.214053    0.401074    0.0531294   -0.0241134    0.0698648    0.0663262
  0.02541      0.0141728   0.0615514   -0.0993728   0.0160718    0.0379413   0.0371231   0.162618      0.0165787  -0.0497033    0.0965151   0.0825221  -0.00741432   0.0599922  -0.0827328   -0.0389778   -0.0751623  -0.0262654    0.0649335    0.0113536   0.0297556   0.108606    0.0108497    0.0179794   -0.063001     0.0301215
 -0.316739    -0.201251    0.196698     0.209187   -0.00063796   0.436969   -0.31873     0.52905      -0.233606   -0.363929    -0.146583   -0.0239837  -0.457611     0.14763     0.175986    -0.326182    -0.577044    0.210266     0.151423     0.336912   -0.326459    0.212134   -0.328982     0.240086    -0.364014     0.646193
  0.0769549    0.660669    0.698235     0.308189    0.233195     0.0700002   0.348768    0.486909      0.582165   -0.340337     0.491319   -0.909817    0.132748     0.424425    0.824558     0.198284    -0.376214    0.0940291    0.056242     0.858677    0.717319   -0.205944    0.370388     0.129858    -0.0277087    0.149806
  0.264372    -1.10487     0.0262551   -0.866412    0.543995    -0.345123   -0.304075    0.000287276  -0.539685    0.0275634    0.133439    0.157059    0.325923    -0.064563   -0.23421     -0.00876198  -0.737267    0.0200422   -0.382075     0.758459    0.081612   -0.156157   -0.123546    -0.137589    -0.0617019    0.112528
 -0.119115     0.515487    0.526924     0.388314   -0.367        0.0799729  -0.138336    0.552898      0.137565    0.0875682    1.35877    -0.0681613   0.0162646    0.473057   -0.0665919   -0.317193    -0.325595   -0.717696     0.330726    -0.262942   -0.0832648   0.437578    0.412938     0.460209    -0.194403     0.257611
  0.0129065    0.373368   -0.129752     0.485093   -0.102537     0.0694726  -0.604134    0.347669     -0.240808   -0.00402236   0.205261    0.987487   -0.329455    -0.322403   -0.400124     0.311165     0.494166    0.0568053    0.401114    -0.847324   -0.131655   -0.0841271  -0.106706    -0.57682     -0.149376    -0.238025
 -0.618734    -0.0327818  -0.504845    -0.807346   -0.514308     0.048625    0.13338    -0.0889447     0.0667375   0.112061     0.374028    0.507506    0.694042     0.520243   -0.413044     0.0563446   -0.551671   -0.360051     0.306654     0.09331     0.429605   -0.119591   -0.228222    -0.351258    -0.284437     0.264653
  0.027476     0.0625502  -0.155897    -0.132053   -0.435707    -0.073895   -0.0963782   0.0471437     0.177277    0.576946    -0.261329   -0.0932609  -0.0348759    0.635736   -1.11491      0.04435      0.0487465   0.0768615    0.2047       0.071372   -0.689411   -0.153466   -0.273338     0.0671857   -0.0201797    0.0937592
  0.0192374    0.444202   -0.081911     0.636308   -0.315959     0.0638782  -0.196262    0.0431984     0.307707   -0.0285722   -0.45606    -0.0169242  -0.122099    -0.344929    0.322548    -0.170598     0.77655     0.262293     0.416301     0.0953956   0.201487   -0.344891    0.195621    -0.317613     0.125915     0.236154
  0.124828    -0.323918    0.151094     0.0613693   0.519566     0.105269    0.449168    0.0818157    -0.274014   -0.652671     0.123664    0.345971   -0.0445182   -0.58585     0.774767    -0.0128339   -0.0548937  -0.137484    -0.284539    -0.163264    0.545131    0.548544    0.389258    -0.0231444   -0.199773    -0.556566
 -0.205767     0.0142833  -0.285392    -0.107579    0.0711124    0.0838346   0.166672   -0.493368      0.112145    0.147192    -0.0891625  -0.015707    0.0520907   -0.239704    0.122399     0.235984     0.024653   -0.0146113   -0.338034     0.0635735   0.0563292   0.0910026  -0.174778     0.0500209    0.178714    -0.202455
  0.0247618   -0.291178   -0.0535097    0.0994259  -0.60362     -0.144604   -0.517949   -0.373414     -0.215259   -0.155392    -0.133087   -0.274212   -0.488631    -0.0651653   0.0580541   -0.219204    -0.184132   -0.0716442    0.340141    -0.304271   -0.450701    0.181821   -0.0122179    0.0302123    0.319586    -0.0514232
  0.318499     0.0531205  -1.07215     -0.610685    0.243552     0.178195    0.0990356  -0.68984       0.377666    0.0536575   -0.769727    0.213895   -0.201888    -0.582412   -0.469294     0.218746     0.0648492   0.63818     -0.355908     0.28695     0.0453331   0.180803   -0.618414    -0.186        0.288881    -0.304939
  0.0476191    0.438298    0.882407    -0.634208   -0.159659     0.127058    0.0830067   0.0242448     0.421146    0.223652    -0.315996    0.251355   -0.408194    -0.384982    0.176212     0.351606    -0.0817848   0.362248    -0.255328     0.539416    0.141531    0.0464497  -0.859541    -1.23605     -0.111941    -0.153531
 -0.155603    -0.112844    0.719846    -0.896924    0.320588     0.0965599  -0.346651   -0.252141      0.0395434   0.659927    -0.356296   -0.0847323  -0.27833      0.21815    -0.431509    -0.184173     0.642245   -0.776641     0.657083     0.430382   -0.0287325   0.711389    0.850038    -0.108228     0.0106223   -0.307349
 -0.0543441   -0.0456673   0.143136     0.135819    0.313608    -0.0262696   0.0732981   0.236128      0.0740758  -0.0845711   -0.104647    0.0118552   0.20615      0.388432   -0.199449    -0.33421     -0.0761154  -0.0531673    0.14534      0.145285   -0.119412    0.0407585   0.00140281  -0.14568     -0.230065     0.0222877
 -0.178814    -0.0409696   0.366549     0.574141    0.408929     0.128988   -0.0277849  -0.126447      0.0954353  -0.897699    -0.0539686  -0.37952     0.270786    -0.0551032   0.094046    -0.0942946    0.428508    0.00844192   0.02153     -0.727335   -1.01821     0.212239    0.563472     0.378289    -0.243452     0.233733
  0.55638      0.256875   -0.468507    -0.27267     0.117285     0.921636    0.284206    0.545953      0.171907   -0.524594    -0.443426   -0.16643     0.187822     0.0748257   0.126301    -0.0484674    0.153625    0.338745    -0.622242     0.645576   -0.184831    0.567164   -0.0245992   -0.0552646   -0.127965     0.0160796
  0.471802    -0.132947    0.366661     0.273369    0.386177     0.208913    0.116511    0.842323     -0.122333   -0.453663     0.0357817   0.305433   -0.0161392    0.078733    0.0881308    0.0450426    0.0799207   0.406669     0.00433442  -0.0649319   0.101019   -0.145954    0.348543    -0.240069    -0.369582    -0.096853
 -0.200243     0.329724    0.3102      -0.0343568   0.357183    -0.297207   -0.101543   -0.386954     -0.102136   -0.396477    -0.39297    -0.390693    0.990927    -0.0961546   0.0190204   -0.583858    -0.143524   -0.18295      0.493854     0.285043    0.126448   -0.0176283   0.105297    -0.193423    -0.0648824    0.105655
 -0.0855046    0.339284   -0.00841048   0.0921344   0.117092     0.212466    0.318475    0.163612      1.14223     0.0778504    0.260383    0.140388   -0.0994605   -0.0482577  -0.189478    -0.166267     0.504805   -0.241999    -0.67838     -0.135961   -0.0504736  -0.288325   -0.157506    -0.308492    -0.198674     0.0637461
 -0.26004      0.0681096   0.500122     0.107494   -0.0211371   -0.815388    0.12701    -0.395358      0.0132617   0.310066     0.160247    0.322589   -0.314098     0.166117    0.0742873   -0.0152323   -0.184219   -0.196803     0.792316    -0.408612    0.591152   -0.175207    0.148995    -0.00340547   0.0360856    0.029172
 -0.139238    -0.498652    0.542566    -0.227926    0.470984    -0.570128   -0.617698   -0.260448     -0.0733828   0.234534     0.215196    0.225782    0.204293    -0.0658524  -0.801144    -0.323572     0.142643   -1.04251     -0.0130192   -0.54371    -0.394434    0.0397539  -0.115845    -0.198176    -0.0657458   -0.109442
  0.653428     0.176714   -0.12452     -0.157459   -0.517952     0.546505   -0.154859   -0.0488814    -0.204437    0.0331615   -0.443396   -0.18509    -0.418222     0.0422483   0.592213     0.0351153   -0.485121   -0.275069     0.0133404    0.374751    0.0707592   0.2636      0.0845289   -0.199989     0.405082    -0.79904
 -0.749597     0.139015    0.103029    -0.265344    0.323156    -0.100797    0.337698    0.382187     -0.196345    0.535516    -0.135709    0.463172    0.225218    -0.295744   -0.450911     0.156175     0.738514    0.41994     -0.0335775    0.425702    0.447149    0.617135   -0.310235     0.569322    -0.410204     0.619184
 -0.0976565   -0.783809   -0.561382     0.361737    0.298893    -0.443992   -0.37712     0.0507161    -0.592375    0.220902     0.143119   -0.343378    0.613753    -0.327228    0.00652266  -0.0939049   -0.0159963  -0.0624342    0.187234     0.0638167   0.63119    -0.311454    0.717388     0.581746     0.1667       0.157345
  0.0538881   -0.264913   -0.0422039   -0.205265   -0.569785    -0.146465   -0.0710519  -0.281421     -0.209199    0.161235     0.163126    0.130072   -0.693445    -0.849667    0.137414     0.550954    -0.13457     0.0874068   -0.12065     -0.52292     0.0735153  -0.110299    0.326664     0.394529     0.26621      0.0536642[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413298
[ Info: iteration 2, average log likelihood -1.413291
[ Info: iteration 3, average log likelihood -1.413284
[ Info: iteration 4, average log likelihood -1.413278
[ Info: iteration 5, average log likelihood -1.413272
[ Info: iteration 6, average log likelihood -1.413266
[ Info: iteration 7, average log likelihood -1.413261
[ Info: iteration 8, average log likelihood -1.413255
[ Info: iteration 9, average log likelihood -1.413250
[ Info: iteration 10, average log likelihood -1.413245
┌ Info: EM with 100000 data points 10 iterations avll -1.413245
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
