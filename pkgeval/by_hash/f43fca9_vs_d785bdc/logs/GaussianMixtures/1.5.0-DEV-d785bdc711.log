Julia Version 1.5.0-DEV.263
Commit d785bdc711 (2020-02-12 15:14 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed URIParser ────────── v0.4.0
  Installed Rmath ────────────── v0.6.0
  Installed Arpack ───────────── v0.4.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed GaussianMixtures ─── v0.3.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed SortingAlgorithms ── v0.3.1
  Installed DataAPI ──────────── v1.1.0
  Installed FileIO ───────────── v1.2.2
  Installed Distributions ────── v0.22.4
  Installed SpecialFunctions ─── v0.9.0
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed DataStructures ───── v0.17.9
  Installed BinaryProvider ───── v0.5.8
  Installed LegacyStrings ────── v0.4.1
  Installed Parameters ───────── v0.12.0
  Installed StaticArrays ─────── v0.12.1
  Installed HDF5 ─────────────── v0.12.5
  Installed PDMats ───────────── v0.9.11
  Installed QuadGK ───────────── v2.3.1
  Installed Missings ─────────── v0.4.3
  Installed Distances ────────── v0.8.2
  Installed CMake ────────────── v1.1.2
  Installed FillArrays ───────── v0.8.4
  Installed BinDeps ──────────── v1.0.0
  Installed StatsBase ────────── v0.32.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed Compat ───────────── v2.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed CMakeWrapper ─────── v0.2.3
  Installed Blosc ────────────── v0.5.1
  Installed JLD ──────────────── v0.9.2
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ##############################                                            42.5%######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%####                                                                       6.0%########                                                                  11.3%#############                                                             18.5%##################                                                        25.9%##########################                                                36.7%####################################                                      50.5%################################################                          67.6%################################################################          89.4%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_vjUgSf/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.3699200506226034e6, [98786.6581067758, 1213.3418932242112], [1586.804220713488 -111.147781210507 905.7106740980043; -1764.786494463949 -228.90480584843766 -1037.4863909912617], [[96633.72303675447 489.2682696678985 -436.1035717727499; 489.26826966789855 97753.86025351012 -191.08404204611818; -436.1035717727499 -191.08404204611813 97092.94693973714], [3000.8527787155363 -281.20300558363806 1097.7747157494027; -281.20300558363806 2013.6574646212232 -78.9299339682593; 1097.7747157494027 -78.9299339682593 1975.1427263074738]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.821446e+03
      1       1.137378e+03      -6.840680e+02 |        6
      2       1.010354e+03      -1.270242e+02 |        3
      3       9.749249e+02      -3.542927e+01 |        0
      4       9.749249e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 974.9248531655303)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075758
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.858658
[ Info: iteration 2, lowerbound -3.759267
[ Info: iteration 3, lowerbound -3.649924
[ Info: iteration 4, lowerbound -3.513496
[ Info: iteration 5, lowerbound -3.364336
[ Info: iteration 6, lowerbound -3.229433
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.119765
[ Info: iteration 8, lowerbound -3.038185
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.969616
[ Info: iteration 10, lowerbound -2.904676
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.841877
[ Info: iteration 12, lowerbound -2.788969
[ Info: iteration 13, lowerbound -2.751758
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.718030
[ Info: iteration 15, lowerbound -2.677359
[ Info: iteration 16, lowerbound -2.633155
[ Info: iteration 17, lowerbound -2.583816
[ Info: iteration 18, lowerbound -2.532882
[ Info: iteration 19, lowerbound -2.484151
[ Info: iteration 20, lowerbound -2.440287
[ Info: iteration 21, lowerbound -2.401969
[ Info: iteration 22, lowerbound -2.368377
[ Info: iteration 23, lowerbound -2.339247
[ Info: iteration 24, lowerbound -2.317368
[ Info: iteration 25, lowerbound -2.307651
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302998
[ Info: iteration 27, lowerbound -2.299262
[ Info: iteration 28, lowerbound -2.299257
[ Info: iteration 29, lowerbound -2.299255
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb 12 21:35:48 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb 12 21:35:56 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Feb 12 21:35:58 2020: EM with 272 data points 0 iterations avll -2.075758
5.8 data points per parameter
, Wed Feb 12 21:36:00 2020: GMM converted to Variational GMM
, Wed Feb 12 21:36:07 2020: iteration 1, lowerbound -3.858658
, Wed Feb 12 21:36:08 2020: iteration 2, lowerbound -3.759267
, Wed Feb 12 21:36:08 2020: iteration 3, lowerbound -3.649924
, Wed Feb 12 21:36:08 2020: iteration 4, lowerbound -3.513496
, Wed Feb 12 21:36:08 2020: iteration 5, lowerbound -3.364336
, Wed Feb 12 21:36:08 2020: iteration 6, lowerbound -3.229433
, Wed Feb 12 21:36:08 2020: dropping number of Gaussions to 7
, Wed Feb 12 21:36:08 2020: iteration 7, lowerbound -3.119765
, Wed Feb 12 21:36:08 2020: iteration 8, lowerbound -3.038185
, Wed Feb 12 21:36:08 2020: dropping number of Gaussions to 5
, Wed Feb 12 21:36:08 2020: iteration 9, lowerbound -2.969616
, Wed Feb 12 21:36:08 2020: iteration 10, lowerbound -2.904676
, Wed Feb 12 21:36:08 2020: dropping number of Gaussions to 4
, Wed Feb 12 21:36:08 2020: iteration 11, lowerbound -2.841877
, Wed Feb 12 21:36:08 2020: iteration 12, lowerbound -2.788969
, Wed Feb 12 21:36:08 2020: iteration 13, lowerbound -2.751758
, Wed Feb 12 21:36:08 2020: dropping number of Gaussions to 3
, Wed Feb 12 21:36:08 2020: iteration 14, lowerbound -2.718030
, Wed Feb 12 21:36:08 2020: iteration 15, lowerbound -2.677359
, Wed Feb 12 21:36:08 2020: iteration 16, lowerbound -2.633155
, Wed Feb 12 21:36:08 2020: iteration 17, lowerbound -2.583816
, Wed Feb 12 21:36:08 2020: iteration 18, lowerbound -2.532882
, Wed Feb 12 21:36:08 2020: iteration 19, lowerbound -2.484151
, Wed Feb 12 21:36:08 2020: iteration 20, lowerbound -2.440287
, Wed Feb 12 21:36:08 2020: iteration 21, lowerbound -2.401969
, Wed Feb 12 21:36:08 2020: iteration 22, lowerbound -2.368377
, Wed Feb 12 21:36:08 2020: iteration 23, lowerbound -2.339247
, Wed Feb 12 21:36:08 2020: iteration 24, lowerbound -2.317368
, Wed Feb 12 21:36:08 2020: iteration 25, lowerbound -2.307651
, Wed Feb 12 21:36:08 2020: dropping number of Gaussions to 2
, Wed Feb 12 21:36:08 2020: iteration 26, lowerbound -2.302998
, Wed Feb 12 21:36:08 2020: iteration 27, lowerbound -2.299262
, Wed Feb 12 21:36:08 2020: iteration 28, lowerbound -2.299257
, Wed Feb 12 21:36:08 2020: iteration 29, lowerbound -2.299255
, Wed Feb 12 21:36:08 2020: iteration 30, lowerbound -2.299254
, Wed Feb 12 21:36:08 2020: iteration 31, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 32, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 33, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 34, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 35, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 36, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 37, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 38, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 39, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 40, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 41, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 42, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 43, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 44, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 45, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 46, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 47, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 48, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 49, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: iteration 50, lowerbound -2.299253
, Wed Feb 12 21:36:08 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922261022, 95.95490777389782]
β = [178.0450922261022, 95.95490777389782]
m = [4.250300733269194 79.28686694435127; 2.0002292577746283 53.85198717245743]
ν = [180.0450922261022, 97.95490777389782]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554747521 -0.007644049042336694; 0.0 0.008581705166320133], [0.37587636119607454 -0.008953123827360758; 0.0 0.012748664777413075]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.0247039799436404
avll from llpg:  -1.0247039799436404
avll direct:     -1.0247039799436404
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9379713524015284
avll from llpg:  -0.9379713524015284
avll direct:     -0.9379713524015283
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.119874      0.0189211   -0.129344     0.143011     0.0425193    0.0654611    -0.125104     0.125574     0.107002     0.0688785   0.0588062    0.120069    -0.00649992  -0.108979    -0.0473285   -0.0633906     0.173046     0.131543     0.0819677    0.240918     0.0920789   -0.0270543   -0.00796552   0.122183    -0.282561     -0.145189
  0.112246      0.0831521    0.0169783    0.110996     0.145968    -0.0356914    -0.0414839   -0.0696219   -0.0280226    0.107121   -0.0289774   -0.0850743    0.0239177    0.199341     0.0310711   -0.124451     -0.101113     0.0406914   -0.0183228   -0.0210437   -0.0162716   -0.185626    -0.0305251   -0.0424715    0.0924959    -0.15001
  0.031535     -0.0667521   -0.0691519    0.0661941    0.166842    -0.0603363     0.00915831   0.126329    -0.0196111   -0.13832     0.0208938   -0.061498     0.0162246    0.00800739   0.00151623  -0.115471     -0.0647872   -0.133802    -0.0394574   -0.0709978    0.0271569    0.0631111    0.0753168   -0.0810657    0.0560651    -0.0764334
  0.101448      0.00507833  -0.0523118    0.120726     0.0473897   -0.112232     -0.147908    -0.139485     0.131677    -0.0175815   0.00470171   0.0520019   -0.0804918   -0.0154914   -0.181048    -0.149498     -0.0799015    0.0588338    0.114366    -0.0627777   -0.0539068   -0.025424     0.0433353   -0.0621128   -0.122077     -0.0510893
  0.133145      0.00476819  -0.0519917   -0.0380699   -0.155878    -0.0877374    -0.097404     0.230479    -0.0982607    0.135409    0.062909    -0.265756     0.0624805    0.157303    -0.167756    -0.065269      0.125273     0.0995726    0.0154192    0.0182742   -0.0907159    0.0325613    0.107711     0.14609     -0.0702851    -0.0183051
  0.00949322   -0.0242569   -0.00933056   0.0800996   -0.0395637   -0.025954     -0.0772812    0.0422189    0.0630551    0.0614753   0.134286    -0.237624    -0.130612    -0.0156535    0.021854     0.0766587     0.016635    -0.00928712   0.20789     -0.0863021   -0.0267297    0.231954     0.0411015    0.127775    -0.115128     -0.192675
  0.0705666    -0.0119266   -0.140098    -0.0941291    0.0168197   -0.0132786     0.0203204   -0.158421     0.120592    -0.0648934  -0.185561    -0.00373032   0.136623    -0.191185     0.0203519    0.229306      0.0651772    0.0498391    0.0682702    0.0391842    0.0567988    0.0268284   -0.00158048  -0.0768948    0.228788     -0.096499
  0.0324519    -0.0698027   -0.166096     0.0283537   -0.0763841   -0.039982     -0.0116164   -0.0500173    0.055401     0.0819336  -0.0610558    0.137934    -0.204301    -0.081297    -0.250227     0.0189135     0.138303    -0.0386734    0.113847     0.16548      0.053709    -0.159096    -0.0520639   -0.0737997    0.0333051     0.0804961
 -0.0706395    -0.226841     0.123419    -0.0276094    0.11209      0.108841     -0.196591    -0.13595     -0.0032715   -0.272846   -0.0213923    0.0862104   -0.0213178   -0.0216731   -0.0710828    0.0189988    -0.0180111    0.00653602  -0.181851    -0.00747578   0.191028     0.210153     0.0435152    0.135753     0.0977227     0.149048
  0.0293386     0.034764    -0.0787807    0.0999421    0.0833379   -0.0640724     0.0119547   -0.12513      0.22633      0.032594    0.071225     0.0106876    0.0283161   -0.0196058   -0.108807     0.0685241    -0.00170516   0.0158886    0.190575     0.184159    -0.131302    -0.0976241    0.112838     0.0347364    0.0273146     0.0684908
 -0.0153271     0.0887207   -0.198994    -0.0204356    0.069985     0.117751     -0.185614    -0.0685295    0.288266    -0.0809679  -0.0164215   -0.0162734   -0.04163     -0.0185738   -0.085693     0.024023      0.00899608   0.0755268    0.137993     0.114145     0.0941366   -0.0483851    0.0893865    0.0344019    0.000948647  -0.0781213
 -0.188362     -0.0598183    0.0226165    0.0824248    0.25055      0.108563     -0.0537477    0.0412239    0.0256423   -0.0123483   0.0644119   -0.123722     0.0817373    0.0340365   -0.0490519   -0.196369      0.108864     0.0177788   -0.0279022   -0.151394     0.235467    -0.0708375    0.228897     0.118348    -0.0328912     0.145701
  0.180488      0.0895768    0.127835    -0.11394      0.0205516   -0.026836      0.0502886   -0.0784256    0.145587    -0.191543    0.0451949   -0.0520468    0.17736     -0.040146     0.0272891    0.160734      0.269955    -0.0786669   -0.0363657   -0.0843781    0.0968189    0.00115485   0.0213983   -0.125339     0.036321      0.0524321
  0.0965934    -0.0984869    0.121136     0.166306    -0.0935018   -0.0555798     0.189973     0.171575     0.0433417   -0.0198513  -0.0196793   -0.0179763   -0.0258069   -0.148668     0.0311823   -0.0371       -0.0215344   -0.0455153   -0.155224     0.00319927  -0.00757774   0.0298649    0.112129     0.0262816    0.134153     -0.00528951
 -0.0097969     0.0488729    0.114613    -0.0545116    0.0115331   -0.133504     -0.166345     0.00225634   0.131374     0.0242966  -0.0135299   -0.0318726   -0.109129     0.0254001   -0.0954426   -0.0424829     0.113121     0.144884    -0.0306153    0.139115     0.0306545   -0.178452    -0.0256975   -0.0996237    0.0664736    -0.100723
  0.167177      0.0465206    0.0354818   -0.0322862   -0.0449366    0.0989146    -0.114729     0.0487013    0.0206088   -0.24806    -0.0483176   -0.0255096   -0.155385    -0.0975889    0.0996683    0.0801814     0.157549     0.122336    -0.0351465    0.0223323    0.199771     0.116595    -0.0236857   -0.177842    -0.11412      -0.0363211
  0.0668678     0.022758    -0.0643305   -0.104763    -0.0112216   -0.0822577     0.0368304    0.0242545   -0.115478    -0.101428   -0.00431349  -0.149016    -0.0333242    0.0738801    0.088061    -0.160413     -0.0709837    0.0266057    0.00657345   0.0269614   -0.0120578    0.081939     0.0125681   -0.0862749    0.243796      0.0524865
 -0.0166468    -0.0132166    0.0863542   -0.0211793    0.115021     0.116886     -0.00511354   0.0259236   -0.131603     0.0592017  -0.160038     0.015896     0.103923    -0.18543      0.0211584   -0.00578153    0.0599095    0.0824209   -0.0823575   -0.0412063    0.0305554   -0.0147334    0.0593244   -0.115712    -0.0927641    -0.0807217
 -0.0794252     0.137168     0.256266     0.00549957   0.070743     0.0684529    -0.229877     0.0814734   -0.00587533   0.142723   -0.0327389    0.0254412    0.106528     0.0843234   -0.0719434    0.0047561    -0.0516857   -0.164587    -0.00914036   0.0251705   -0.175741    -0.0669637    0.0519981   -0.1719       0.110914      0.0623973
 -0.047704     -0.0275041    0.0215379    0.1395       0.100857    -0.00613087    0.0119098    0.074376     0.115349     0.0502966  -0.208186     0.0593971    0.139306    -0.0786205    0.202664     0.0329871    -0.0416364   -0.123361     0.0164244    0.138398     0.050713     0.0776048    0.0608771   -0.12329     -0.0489437     0.0281005
  0.0510293     0.266187     0.0956276    0.0944243   -0.0123815   -0.131426     -0.0119341    0.0491663    0.211768    -0.0557302   0.144464    -0.0265513    0.133263    -0.0431951    0.0215782   -0.151038      0.107273    -0.109341    -0.103216     0.102261     0.0672419    0.156273    -0.102269     0.0800766    0.0584766    -0.0787334
 -0.0265018    -0.122596     0.0487879   -0.0638107   -0.130854    -0.041921     -0.0881548    0.0472092    0.0307094   -0.0341513  -0.00961073  -0.05289      0.0326312    0.0744076   -0.104901     0.000338623  -0.133271    -0.0186781    0.123514     0.0591344   -0.0860389   -0.00131961  -0.108091     0.147584     0.0316044     0.0629179
 -0.0764844    -0.0459898    0.0566465   -0.138114    -0.178655    -0.16919      -0.0439699   -0.0880468    0.120326     0.131709   -0.103385     0.168217    -0.127267     0.0681042   -0.140712     0.0253671    -0.133544    -0.254783    -0.00466098   0.101933     0.108417     0.0357811    0.0850542   -0.00475396   0.03375       0.165501
  0.035205     -0.00393698  -0.0561823    0.108352    -0.0781192    0.0055068     0.0445928    0.0498823    0.054451    -0.0334053   0.0594874   -0.0516238   -0.0171524   -0.0451275    0.0340687   -0.0100358    -0.0643469   -0.169151    -0.124858    -0.209395    -0.0158033   -0.0397703   -0.0107551   -0.0620957    0.00041726    0.119979
  0.122788      0.0272703   -0.0815782   -0.241834     0.104946    -0.0582122    -0.198463     0.112691     0.162907     0.183886   -0.202553     0.00467717  -0.0519402    0.130986     0.16378      0.00915594   -0.0227346   -0.0587533   -0.0929407    0.0685133   -0.081312    -0.0765656    0.064657     0.183532    -0.0141532     0.0216472
  0.142717     -0.205559    -0.106628     0.161248    -0.0739421    0.00990078   -0.0908334   -0.224488     0.146477     0.0765294  -0.0332178   -0.0695675    0.15545     -0.0326646    0.0316788   -0.130228     -0.0600092   -0.0553002    0.136027     0.110467     0.0159737    0.111073    -0.0726236   -0.0210733   -0.120907      0.0233351
 -0.0855522     0.00375772  -0.254122     0.0178172    0.0931823   -0.150876     -0.214443    -0.0992867   -0.357597     0.167604   -0.0602997   -0.168251    -0.0201507    0.14205      0.0161655   -0.00829955   -0.0969064   -0.01287      0.0416858    0.072396     0.231639    -0.151996     0.153439    -0.204121    -0.15113      -0.0302641
  0.0431063     0.129373    -0.0387748   -0.0500952    0.010958     0.115183     -0.043272    -0.0330843    0.0319439   -0.0347212  -0.00127923   0.0700603   -0.0990241    0.0293004    0.0237746   -0.207956     -0.084603    -0.129687     0.0181781    0.00150598  -0.175664    -0.0802812    0.0733858    0.0424648    0.00037717   -0.0266895
 -0.124129     -0.0635058    0.132257    -0.00345285   0.0333904    0.00833511   -0.100504    -0.0703365   -0.00160115   0.122153   -0.092987    -0.0262006   -0.177729    -0.0647848    0.0503978    0.246785     -0.0716144    0.05566      0.166627    -0.127569    -0.0868116   -0.0781333   -0.0378053   -0.0202739    0.0673698    -0.0751214
 -0.000648523  -0.0679609    0.00424574   0.0323747   -0.00635262   0.0208106     0.103508    -0.174599     0.0580123    0.0312557  -0.0482061   -0.0655073    0.00565182   0.111598     0.110289    -0.0986595    -0.00814957   0.073719    -0.0469346   -0.144833     0.06813     -0.0617063    0.0347762    0.0278889    0.166736      0.0011749
  0.0193177     0.0135883   -0.142695    -0.205309    -0.0478637   -0.000804502  -0.0278886   -0.103337     0.0328313    0.125198    0.198638     0.0587964    0.0308627    0.176845    -0.0450255   -0.0426016    -0.0147605   -0.0379973    0.039405     0.00211513   0.125588    -0.0504247   -0.0220976   -0.00213383   0.0892646    -0.167841
  0.0817916    -0.0539772    0.0581147   -0.0974616   -0.132311    -0.049849      0.122157    -0.108833     0.121318     0.0440038  -0.162486     0.220235     0.0723281    0.0164886    0.0989236   -0.166481      0.0137355   -0.0385249    0.0455035   -0.014559     0.0482782    0.121713     0.127099     0.0274893   -0.0334218     0.0563319kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4090084654026218
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409105
[ Info: iteration 2, average log likelihood -1.408965
[ Info: iteration 3, average log likelihood -1.407167
[ Info: iteration 4, average log likelihood -1.392870
[ Info: iteration 5, average log likelihood -1.376306
[ Info: iteration 6, average log likelihood -1.373068
[ Info: iteration 7, average log likelihood -1.372471
[ Info: iteration 8, average log likelihood -1.372298
[ Info: iteration 9, average log likelihood -1.372235
[ Info: iteration 10, average log likelihood -1.372205
[ Info: iteration 11, average log likelihood -1.372186
[ Info: iteration 12, average log likelihood -1.372171
[ Info: iteration 13, average log likelihood -1.372156
[ Info: iteration 14, average log likelihood -1.372141
[ Info: iteration 15, average log likelihood -1.372128
[ Info: iteration 16, average log likelihood -1.372116
[ Info: iteration 17, average log likelihood -1.372107
[ Info: iteration 18, average log likelihood -1.372100
[ Info: iteration 19, average log likelihood -1.372095
[ Info: iteration 20, average log likelihood -1.372091
[ Info: iteration 21, average log likelihood -1.372088
[ Info: iteration 22, average log likelihood -1.372086
[ Info: iteration 23, average log likelihood -1.372084
[ Info: iteration 24, average log likelihood -1.372082
[ Info: iteration 25, average log likelihood -1.372081
[ Info: iteration 26, average log likelihood -1.372080
[ Info: iteration 27, average log likelihood -1.372079
[ Info: iteration 28, average log likelihood -1.372078
[ Info: iteration 29, average log likelihood -1.372078
[ Info: iteration 30, average log likelihood -1.372077
[ Info: iteration 31, average log likelihood -1.372077
[ Info: iteration 32, average log likelihood -1.372076
[ Info: iteration 33, average log likelihood -1.372076
[ Info: iteration 34, average log likelihood -1.372076
[ Info: iteration 35, average log likelihood -1.372075
[ Info: iteration 36, average log likelihood -1.372075
[ Info: iteration 37, average log likelihood -1.372075
[ Info: iteration 38, average log likelihood -1.372075
[ Info: iteration 39, average log likelihood -1.372075
[ Info: iteration 40, average log likelihood -1.372074
[ Info: iteration 41, average log likelihood -1.372074
[ Info: iteration 42, average log likelihood -1.372074
[ Info: iteration 43, average log likelihood -1.372074
[ Info: iteration 44, average log likelihood -1.372074
[ Info: iteration 45, average log likelihood -1.372074
[ Info: iteration 46, average log likelihood -1.372074
[ Info: iteration 47, average log likelihood -1.372074
[ Info: iteration 48, average log likelihood -1.372074
[ Info: iteration 49, average log likelihood -1.372074
[ Info: iteration 50, average log likelihood -1.372074
┌ Info: EM with 100000 data points 50 iterations avll -1.372074
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4091045083241585
│     -1.4089649041526449
│      ⋮
└     -1.3720737173082656
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.372207
[ Info: iteration 2, average log likelihood -1.372096
[ Info: iteration 3, average log likelihood -1.371693
[ Info: iteration 4, average log likelihood -1.367383
[ Info: iteration 5, average log likelihood -1.352764
[ Info: iteration 6, average log likelihood -1.339779
[ Info: iteration 7, average log likelihood -1.333009
[ Info: iteration 8, average log likelihood -1.329222
[ Info: iteration 9, average log likelihood -1.327544
[ Info: iteration 10, average log likelihood -1.326627
[ Info: iteration 11, average log likelihood -1.325968
[ Info: iteration 12, average log likelihood -1.325348
[ Info: iteration 13, average log likelihood -1.324674
[ Info: iteration 14, average log likelihood -1.323943
[ Info: iteration 15, average log likelihood -1.323163
[ Info: iteration 16, average log likelihood -1.322303
[ Info: iteration 17, average log likelihood -1.321436
[ Info: iteration 18, average log likelihood -1.320661
[ Info: iteration 19, average log likelihood -1.320026
[ Info: iteration 20, average log likelihood -1.319577
[ Info: iteration 21, average log likelihood -1.319251
[ Info: iteration 22, average log likelihood -1.319002
[ Info: iteration 23, average log likelihood -1.318813
[ Info: iteration 24, average log likelihood -1.318664
[ Info: iteration 25, average log likelihood -1.318569
[ Info: iteration 26, average log likelihood -1.318531
[ Info: iteration 27, average log likelihood -1.318516
[ Info: iteration 28, average log likelihood -1.318509
[ Info: iteration 29, average log likelihood -1.318505
[ Info: iteration 30, average log likelihood -1.318503
[ Info: iteration 31, average log likelihood -1.318501
[ Info: iteration 32, average log likelihood -1.318500
[ Info: iteration 33, average log likelihood -1.318499
[ Info: iteration 34, average log likelihood -1.318498
[ Info: iteration 35, average log likelihood -1.318498
[ Info: iteration 36, average log likelihood -1.318497
[ Info: iteration 37, average log likelihood -1.318497
[ Info: iteration 38, average log likelihood -1.318496
[ Info: iteration 39, average log likelihood -1.318496
[ Info: iteration 40, average log likelihood -1.318495
[ Info: iteration 41, average log likelihood -1.318495
[ Info: iteration 42, average log likelihood -1.318495
[ Info: iteration 43, average log likelihood -1.318495
[ Info: iteration 44, average log likelihood -1.318494
[ Info: iteration 45, average log likelihood -1.318494
[ Info: iteration 46, average log likelihood -1.318494
[ Info: iteration 47, average log likelihood -1.318494
[ Info: iteration 48, average log likelihood -1.318494
[ Info: iteration 49, average log likelihood -1.318493
[ Info: iteration 50, average log likelihood -1.318493
┌ Info: EM with 100000 data points 50 iterations avll -1.318493
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3722068189444925
│     -1.3720957251159316
│      ⋮
└     -1.3184931890533627
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318705
[ Info: iteration 2, average log likelihood -1.318513
[ Info: iteration 3, average log likelihood -1.317888
[ Info: iteration 4, average log likelihood -1.311695
[ Info: iteration 5, average log likelihood -1.291667
[ Info: iteration 6, average log likelihood -1.277745
[ Info: iteration 7, average log likelihood -1.273412
[ Info: iteration 8, average log likelihood -1.271259
[ Info: iteration 9, average log likelihood -1.269423
[ Info: iteration 10, average log likelihood -1.267574
[ Info: iteration 11, average log likelihood -1.266006
[ Info: iteration 12, average log likelihood -1.264865
[ Info: iteration 13, average log likelihood -1.264053
[ Info: iteration 14, average log likelihood -1.263455
[ Info: iteration 15, average log likelihood -1.263001
[ Info: iteration 16, average log likelihood -1.262655
[ Info: iteration 17, average log likelihood -1.262403
[ Info: iteration 18, average log likelihood -1.262231
[ Info: iteration 19, average log likelihood -1.262119
[ Info: iteration 20, average log likelihood -1.262047
[ Info: iteration 21, average log likelihood -1.262001
[ Info: iteration 22, average log likelihood -1.261973
[ Info: iteration 23, average log likelihood -1.261955
[ Info: iteration 24, average log likelihood -1.261943
[ Info: iteration 25, average log likelihood -1.261934
[ Info: iteration 26, average log likelihood -1.261927
[ Info: iteration 27, average log likelihood -1.261922
[ Info: iteration 28, average log likelihood -1.261918
[ Info: iteration 29, average log likelihood -1.261915
[ Info: iteration 30, average log likelihood -1.261912
[ Info: iteration 31, average log likelihood -1.261909
[ Info: iteration 32, average log likelihood -1.261907
[ Info: iteration 33, average log likelihood -1.261906
[ Info: iteration 34, average log likelihood -1.261904
[ Info: iteration 35, average log likelihood -1.261903
[ Info: iteration 36, average log likelihood -1.261901
[ Info: iteration 37, average log likelihood -1.261900
[ Info: iteration 38, average log likelihood -1.261900
[ Info: iteration 39, average log likelihood -1.261899
[ Info: iteration 40, average log likelihood -1.261898
[ Info: iteration 41, average log likelihood -1.261898
[ Info: iteration 42, average log likelihood -1.261897
[ Info: iteration 43, average log likelihood -1.261897
[ Info: iteration 44, average log likelihood -1.261896
[ Info: iteration 45, average log likelihood -1.261896
[ Info: iteration 46, average log likelihood -1.261896
[ Info: iteration 47, average log likelihood -1.261896
[ Info: iteration 48, average log likelihood -1.261895
[ Info: iteration 49, average log likelihood -1.261895
[ Info: iteration 50, average log likelihood -1.261895
┌ Info: EM with 100000 data points 50 iterations avll -1.261895
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3187047621134877
│     -1.3185128139714024
│      ⋮
└     -1.261895245828138
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.262122
[ Info: iteration 2, average log likelihood -1.261865
[ Info: iteration 3, average log likelihood -1.260670
[ Info: iteration 4, average log likelihood -1.248901
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.219572
[ Info: iteration 6, average log likelihood -1.206242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.189158
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.190954
[ Info: iteration 9, average log likelihood -1.187644
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.176683
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.179142
[ Info: iteration 12, average log likelihood -1.193156
[ Info: iteration 13, average log likelihood -1.186029
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.174767
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.176944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.178460
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.183980
[ Info: iteration 18, average log likelihood -1.183036
[ Info: iteration 19, average log likelihood -1.173045
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.166893
[ Info: iteration 21, average log likelihood -1.194635
[ Info: iteration 22, average log likelihood -1.186360
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.175136
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177186
[ Info: iteration 25, average log likelihood -1.182103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.172180
[ Info: iteration 27, average log likelihood -1.185597
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.174532
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.181449
[ Info: iteration 30, average log likelihood -1.181388
[ Info: iteration 31, average log likelihood -1.171924
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.166451
[ Info: iteration 33, average log likelihood -1.194557
[ Info: iteration 34, average log likelihood -1.186208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.174909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.177024
[ Info: iteration 37, average log likelihood -1.181944
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.171963
[ Info: iteration 39, average log likelihood -1.185441
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.174261
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.181261
[ Info: iteration 42, average log likelihood -1.181232
[ Info: iteration 43, average log likelihood -1.171634
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.166190
[ Info: iteration 45, average log likelihood -1.194479
[ Info: iteration 46, average log likelihood -1.186062
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.174606
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.176795
[ Info: iteration 49, average log likelihood -1.181762
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.171741
┌ Info: EM with 100000 data points 50 iterations avll -1.171741
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.262121660057478
│     -1.2618652182374965
│      ⋮
└     -1.171740759679125
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.185400
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.173922
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.169009
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.150030
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     13
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.117227
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.104309
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.093447
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.094203
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094500
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.088785
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.088110
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.076835
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.079812
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.085933
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.082392
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.069045
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.086739
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     17
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.071424
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.064773
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066327
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.082018
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060119
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.065439
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.072924
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.066558
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│     17
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.068170
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.073728
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.055012
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.073632
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.078259
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.058283
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.063334
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.081994
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060064
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.065390
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.072900
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.066550
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│     17
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.068165
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.073719
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.055003
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.073625
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.078254
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.058275
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.063327
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081984
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     14
│     16
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.060052
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065373
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     16
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.072887
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.066527
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      9
│     16
│     17
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068140
┌ Info: EM with 100000 data points 50 iterations avll -1.068140
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1854000055240377
│     -1.1739219470171247
│      ⋮
└     -1.068140415231497
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4090084654026218
│     -1.4091045083241585
│     -1.4089649041526449
│     -1.4071673464900627
│      ⋮
│     -1.072886840484841
│     -1.0665272508404366
└     -1.068140415231497
32×26 Array{Float64,2}:
  0.00317488   0.0310616   -0.166951    -0.0572866    0.0135441    -0.112918    -0.944652    -0.0389898  -0.131649    -0.104634    0.00117856  -0.253395    -0.0116177    -0.0735124   -0.0472199   -0.273085     -0.0409115    0.0177692  -0.0384665    0.0969582    -0.0244553    0.0676372    0.00666303   -0.0460993     0.318135      0.0912767
  0.151822     0.0241038    0.0318048   -0.112238    -0.0139046    -0.0770231    0.82032      0.0406069  -0.109971    -0.0984016  -0.00889956  -0.0577581   -0.0195102     0.163161     0.187529    -0.0828904    -0.145727     0.0285106   0.0347606   -0.030993     -0.0117395    0.0441079    0.00373658   -0.149451      0.29185      -0.0150075
  0.00950377  -0.06499     -0.0227108    0.0285429   -0.00921464    0.0319011    0.0882663   -0.174107    0.058346     0.0245126  -0.0391986   -0.0591184    0.00031591    0.110123     0.10364     -0.0535734    -0.00664715   0.073044   -0.0510155   -0.16171       0.0695116   -0.0432972    0.0420626     0.0265055     0.174469      0.00217348
  0.121842     0.0270338   -0.0652873   -0.239782     0.101702     -0.0683695   -0.216658     0.13226     0.168988     0.176217   -0.2021       0.0196653   -0.0399326     0.0901542    0.150115     0.0298421    -0.0203694   -0.0624208  -0.0866132    0.0705211    -0.0790626   -0.151486     0.0657799     0.174698     -0.00626294    0.0272663
  0.0881172    0.021735    -0.114415     0.14194      0.0593496     0.0954959   -0.104301     0.127835    0.14443      0.0399658   0.0655248    0.119566    -0.0316834    -0.14061     -0.0508244   -0.0373873     0.176947     0.143081    0.0428689    0.252825      0.0832159   -0.0269764   -0.00553232    0.116995     -0.276065     -0.178164
  0.0296985   -0.00539043  -0.0155415    0.107768    -0.0722851    -0.00732266   0.0414187    0.0460783   0.0499231   -0.0163591   0.064911    -0.0547844   -0.0224233    -0.0439372    0.0476588    0.0137572    -0.0651263   -0.163848   -0.127239    -0.213575     -0.0189787   -0.0429808    0.0277295    -0.0615197    -0.00260524    0.120957
 -0.0707354   -0.219596     0.112973    -0.0293365    0.115443      0.118635    -0.20372     -0.1261     -0.0126711   -0.273491   -0.0328155    0.0893086   -0.0183152     0.0314885   -0.104002     0.0218       -0.0163441    0.0385711  -0.150227    -0.000347623   0.188667     0.206481     0.0529991     0.130724      0.0941054     0.123936
  0.0114402   -0.0256655   -0.00255964   0.0818513   -0.0426194    -0.0257641   -0.0857739    0.0361568   0.0454697    0.0670117   0.129711    -0.233316    -0.142491     -0.0168457    0.0385759    0.0596069    -0.0114373    0.0043277   0.207489    -0.0863145    -0.0291341    0.223528     0.0408442     0.12973      -0.112794     -0.201836
  0.0232471   -0.0790801   -0.193984     0.0224155   -0.0526496    -0.040944    -0.0207968   -0.0622787   0.0625435    0.0765404  -0.0580743    0.137616    -0.199688     -0.0731269   -0.232584     0.00783867    0.13605     -0.0438708   0.107788     0.166282      0.0527583   -0.182126    -0.0407584    -0.0592041     0.000715285   0.0865373
 -0.0131935   -0.110542     0.0410568   -0.0559127   -0.120041     -0.0453346   -0.0831634    0.0403484   0.028707    -0.0474521  -0.0316789   -0.0514457    0.0292988     0.0628611   -0.0971376   -0.000876914  -0.131943    -0.0287806   0.113922     0.0630147    -0.0828437    0.00983616  -0.112488      0.107556      0.0076329     0.0622527
  0.0367209   -0.00256819  -0.107023    -0.351754     0.14734       0.106342     0.0180887   -0.159656    0.124191     0.0278666   0.19773      0.0195038    0.0749854    -0.0525766   -0.0457839    0.0726619     0.0240056    0.0169657   0.136421     0.184677     -0.04489     -0.0870405    0.132297      0.0120958     0.0270846    -0.0194467
  0.0125965    0.0423016   -0.0593991    0.466372     0.000300168  -0.0857775   -0.0396289   -0.0552281   0.263403     0.0217624  -0.0329685   -0.00309854   0.000937785  -0.0526211   -0.13903      0.0530989     0.00787231   0.0174218   0.25734      0.192623     -0.190516    -0.118724     0.198308      0.0524685    -0.0486739     0.13769
 -0.0348629    0.0873373    0.158854    -0.0189549    0.0511299    -0.0331734   -0.194002     0.0560145   0.043914     0.0930836  -0.0182096   -0.00281345   0.0168748     0.0372263   -0.0793702   -0.0150113     0.0203613   -0.0234161  -0.0209215    0.0994795    -0.0686758   -0.0751073    0.0102983    -0.137608      0.0870579    -0.0201057
  0.221504     0.0511711    0.0325178   -0.0905338   -0.051929      0.106513    -0.115341     0.0551563   0.0271902   -0.270566   -0.0590329   -0.020663    -0.146648     -0.099137     0.0910306    0.0839165     0.150306     0.102981   -0.0565969    0.0277901     0.210279     0.112277    -0.0104109    -0.180358     -0.0931912    -0.0300764
  0.133328     0.0756996    0.0103781    0.155276     0.125681     -0.0472226   -0.0425472   -0.110727   -0.0274104    0.0946631  -0.0393622   -0.0808177    0.0236969     0.205851    -0.0344796   -0.127693     -0.145842     0.0476121   0.019888    -0.0440006    -0.0242054   -0.191942    -0.0179129    -0.0418891     0.0860271    -0.191314
 -0.0721016    0.0012883   -0.269063     0.0217392    0.101595     -0.15181     -0.210589    -0.0688778  -0.360704     0.174111   -0.0156198   -0.176       -0.0165552     0.133165     0.00134548  -0.0084388    -0.106148     0.01297     0.038838     0.101981      0.24475     -0.146737     0.161212     -0.194264     -0.149014     -0.0351695
  0.13291      0.0239986   -0.0537075   -0.0420674   -0.144342     -0.104666    -0.0888535    0.230555   -0.0925873    0.139434    0.0963029   -0.28311      0.0901815     0.17525     -0.170165    -0.0671287     0.130801     0.0940411   0.0128781    0.020601     -0.0871813    0.0207815    0.107472      0.140564     -0.0700732    -0.0171403
  0.0729206    0.25973      0.0909044    0.0996226    0.00621681   -0.146687    -0.0269415    0.0761664   0.210472    -0.0143841   0.153407    -0.0242526    0.143498     -0.0172336    0.04225     -0.154816      0.107627    -0.114519   -0.103248     0.130881      0.048674     0.143303    -0.0869417     0.0735276     0.0545466    -0.0736345
 -0.123346    -0.0620858    0.131705    -0.00690537   0.0158017     0.0150761   -0.100432    -0.0783499  -0.00697704   0.150705   -0.0929724   -0.0209108   -0.180443     -0.10507      0.0558532    0.222209     -0.0703125    0.055798    0.170427    -0.141343     -0.0851864   -0.0830056   -0.0450397    -0.000311312   0.0704007    -0.0757559
 -0.0139922    0.0875611   -0.201964    -0.0699199    0.0746784     0.116537    -0.186238    -0.0524798   0.28112     -0.0442193  -0.0170895    0.00520498  -0.0280639    -0.0034281   -0.0726972    0.0290809     0.01015      0.0655326   0.137919     0.119245      0.111955    -0.048037     0.127576      0.0305024     0.00339306   -0.075324
  0.0691468    0.117789    -0.0593469    0.0971812    0.0466626    -0.072962    -0.152015    -0.167931    0.100287    -0.0271843  -0.0309884    0.123789    -0.0711041    -0.0649084   -0.252452    -0.304892     -0.0786174    0.117801    0.114978    -0.0590173    -0.0491606   -0.0298111   -2.1799       -0.0652561    -0.117128     -0.0307808
  0.128939    -0.126128    -0.0639814    0.115505     0.0358922    -0.163595    -0.0683097   -0.102423    0.109165    -0.0108386   0.0346823   -0.0905694   -0.0700306     0.00917126  -0.162358    -0.0377695    -0.0783551    0.0588805   0.113238    -0.0606307    -0.0492925   -0.0205058    2.06095      -0.0603758    -0.115027     -0.029857
 -0.190489    -0.145386     0.0602017    0.0945041    0.244241      0.0685182   -0.0681598    0.0411162   0.0508411   -0.0109467   0.0698247   -0.124939     0.0317415    -0.00942514  -0.11066     -0.19249       0.1417      -0.0319419  -0.0193306   -0.057773      0.234403    -0.0706771    0.238368      0.00666237    0.0841547    -0.462328
 -0.179185     0.0628096   -0.0167113    0.0838808    0.239545      0.136672    -0.0414746    0.0419958   0.0131726   -0.0339934   0.0608222   -0.128278     0.0996007     0.0687241   -0.0142299   -0.191391      0.0465003    0.0376187  -0.031128    -0.253129      0.213483    -0.0708095    0.232013      0.207868     -0.127354      0.581895
  0.0510511    0.109977    -0.0453158   -0.0756589    0.0174912     0.130199    -0.0500814   -0.0269274   0.0698324   -0.0500565   0.0117868    0.0651609   -0.131611      0.027874     0.00206401  -0.153107     -0.0242013   -0.0963352   0.0210476   -0.039312     -0.147802    -0.0768719    0.0446196     0.0346325     0.0170963    -0.0489909
 -0.0098925   -0.0342641   -0.0214602   -0.103842    -0.101274     -0.115117     0.00457254  -0.12175     0.103872     0.0515449  -0.146457     0.0989685   -0.0065689    -0.0366409   -0.0752594    0.109091     -0.0420476   -0.131629    0.0175645    0.0944822     0.0894572    0.0373466    0.0810482    -0.0371558     0.116133      0.0588311
  0.063442    -0.0806876   -0.109017     0.00109786   0.0199351    -0.0152902   -0.0537221   -0.0798853   0.0609555    0.0281766   0.0590959   -0.0247647    0.0705612     0.0491438   -0.0200598   -0.100379     -0.0470232   -0.0825504   0.0514149   -0.00393184    0.0499553    0.0410982    0.0193298    -0.0384171     0.00642816   -0.077365
 -0.0327265   -0.0306276    0.05521      0.0486775    0.107444      0.0455062    0.0156251    0.0464766  -0.0131825    0.0880802  -0.185122     0.0450279    0.129866     -0.120323     0.116077     0.0244298     0.0229466   -0.0339227  -0.030874     0.0576712     0.0327849    0.0321286    0.0636279    -0.120426     -0.0651095    -0.0445798
  0.0691387   -0.0517516    0.0740461   -0.0750209   -0.133064     -0.0625882    0.118038    -0.116062    0.114233     0.0498475  -0.14891      0.221623     0.0507227    -0.0023526    0.109398    -0.137179     -0.00156928  -0.0308611   0.062264    -0.00871906    0.0482143    0.104707     0.119483      0.033429     -0.0270894     0.043558
  0.122268    -0.0811798    0.0997644    0.181495    -0.0913372    -0.0878824    0.237375     0.222388    0.146929    -0.0388289  -0.0164737   -0.0357334   -0.0294024    -0.144877     0.0371328   -0.0299192    -0.0214602   -0.0398478  -0.159098    -0.00300104   -0.00361076   0.00761239   0.113174      0.0680054     0.137406     -0.01119
  0.157906     0.051977    -0.526585    -0.0822607    0.00391356   -0.0273957    0.162115    -0.145418    0.140334    -0.150978    0.0631516   -0.0815457    0.20157      -0.100516     0.084918     0.12894       0.253181    -0.0654601  -0.00248093  -0.072329      0.150823    -0.0103605   -0.000589839   0.104341     -0.0397765     0.0632685
  0.192596     0.0731985    0.568783    -0.138272     0.0302051    -0.014447    -0.0564619    0.0174124   0.149734    -0.212186    0.0377196   -0.0264607    0.153836      0.0117955    0.00950962   0.194718      0.273274    -0.0980954  -0.0734795   -0.0912887     0.0331806    0.0307938   -0.00393433   -0.262215      0.0903253     0.0408729[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.073684
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.034333
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054296
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.045432
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.061140
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.025914
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.073306
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032758
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│     10
│     17
│     20
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.050180
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      9
│     10
│     14
│      ⋮
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.035634
┌ Info: EM with 100000 data points 10 iterations avll -1.035634
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.941964e+05
      1       6.808505e+05      -2.133459e+05 |       32
      2       6.552262e+05      -2.562433e+04 |       32
      3       6.413180e+05      -1.390825e+04 |       32
      4       6.304091e+05      -1.090882e+04 |       32
      5       6.224477e+05      -7.961445e+03 |       32
      6       6.172904e+05      -5.157302e+03 |       32
      7       6.144943e+05      -2.796136e+03 |       32
      8       6.128200e+05      -1.674235e+03 |       32
      9       6.116505e+05      -1.169470e+03 |       32
     10       6.109041e+05      -7.464724e+02 |       32
     11       6.104106e+05      -4.935045e+02 |       32
     12       6.100684e+05      -3.421489e+02 |       32
     13       6.097494e+05      -3.190237e+02 |       32
     14       6.094392e+05      -3.102303e+02 |       32
     15       6.091469e+05      -2.922837e+02 |       32
     16       6.089021e+05      -2.447445e+02 |       32
     17       6.087480e+05      -1.541151e+02 |       32
     18       6.086555e+05      -9.255348e+01 |       32
     19       6.085999e+05      -5.561469e+01 |       32
     20       6.085630e+05      -3.685305e+01 |       32
     21       6.085300e+05      -3.298110e+01 |       32
     22       6.084914e+05      -3.859491e+01 |       32
     23       6.084462e+05      -4.522577e+01 |       31
     24       6.083909e+05      -5.531495e+01 |       31
     25       6.083098e+05      -8.113412e+01 |       32
     26       6.081903e+05      -1.194165e+02 |       32
     27       6.080159e+05      -1.744636e+02 |       32
     28       6.078048e+05      -2.110510e+02 |       32
     29       6.075293e+05      -2.755658e+02 |       32
     30       6.072616e+05      -2.676818e+02 |       32
     31       6.070476e+05      -2.139777e+02 |       32
     32       6.069252e+05      -1.224201e+02 |       32
     33       6.068557e+05      -6.945609e+01 |       31
     34       6.068107e+05      -4.499111e+01 |       31
     35       6.067794e+05      -3.131741e+01 |       31
     36       6.067571e+05      -2.230534e+01 |       32
     37       6.067354e+05      -2.168038e+01 |       31
     38       6.067110e+05      -2.439954e+01 |       30
     39       6.066493e+05      -6.176311e+01 |       32
     40       6.065721e+05      -7.713680e+01 |       32
     41       6.065312e+05      -4.087914e+01 |       30
     42       6.064987e+05      -3.251330e+01 |       28
     43       6.064626e+05      -3.611014e+01 |       31
     44       6.064294e+05      -3.323135e+01 |       30
     45       6.063929e+05      -3.653849e+01 |       31
     46       6.063570e+05      -3.584367e+01 |       32
     47       6.063285e+05      -2.852399e+01 |       32
     48       6.063061e+05      -2.234532e+01 |       30
     49       6.062851e+05      -2.101920e+01 |       31
     50       6.062606e+05      -2.455868e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 606260.5640698296)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.320963
[ Info: iteration 2, average log likelihood -1.286779
[ Info: iteration 3, average log likelihood -1.251163
[ Info: iteration 4, average log likelihood -1.213801
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.172518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.146045
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.120421
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      9
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087848
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     10
│     12
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073978
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.117389
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081500
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.066397
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.081032
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.085843
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     12
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.042056
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     15
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074160
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      5
│     10
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.087567
[ Info: iteration 18, average log likelihood -1.111995
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     14
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.048729
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     12
│     15
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.120408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.092754
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      9
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.041617
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│     10
│     15
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.058943
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.119572
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.089898
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.068777
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│     15
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.039083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.115520
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091351
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      9
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.042364
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     10
│     15
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.059560
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.103411
[ Info: iteration 34, average log likelihood -1.094707
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     12
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.022294
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│     10
│     15
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.065646
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.112927
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.081548
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      9
│     12
│      ⋮
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.012761
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     15
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085809
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.135860
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087039
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     14
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.039277
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     15
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.045839
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102915
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.092051
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.037629
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     10
│     15
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.039303
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     16
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098528
[ Info: iteration 50, average log likelihood -1.091599
┌ Info: EM with 100000 data points 50 iterations avll -1.091599
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.114801    -0.0774952    0.0887972    0.163553    -0.0938402    -0.0786486    0.213372     0.199359     0.145837     -0.0372308    -0.019395    -0.0221906    -0.0277392    -0.126437    0.0320279   -0.0329624   -0.0211274   -0.0428904   -0.148712      0.00474676   0.00104327   0.0129387    0.112423     0.0697647    0.128031    -0.00653056
 -0.1572      -0.00759476  -0.013241     0.0751215    0.248512      0.106513    -0.0711912    0.0401207    0.0741604    -0.0280657     0.0508535   -0.109419      0.0602656     0.0304178  -0.054477    -0.157046     0.0739464    0.0158624   -0.000750575  -0.111794     0.204949    -0.0661141    0.232665     0.115722    -0.0312384    0.073384
  0.102396     0.0181319   -0.0601764   -0.157857     0.0829442    -0.0666847   -0.239904     0.133991     0.222784      0.168913     -0.28348      0.022896     -0.0308677     0.107822    0.134862     0.00700927  -0.00497039  -0.0426806   -0.0398724     0.107618    -0.0767879   -0.139416     0.0559817    0.19534     -0.0468474    0.0136054
  0.0526061    0.00917796  -0.146614    -0.0717979    0.0184235     0.0213347   -0.0197102   -0.135015     0.159228     -0.036708     -0.163338     0.0121377     0.126426     -0.158213    0.00965131   0.185978     0.0548572    0.0482435    0.0763696     0.0768748    0.0546947    0.0215249    0.0603891   -0.0687531    0.17986     -0.0843458
 -0.00974124  -0.0194247    0.0816612   -0.00837415   0.116179      0.116012     0.00364084   0.02632     -0.151778      0.0573938    -0.158326     0.00575748    0.110377     -0.181863    0.0228192   -0.00390184   0.0617692    0.0800389   -0.071721     -0.0452776    0.0152644   -0.0156268    0.0591677   -0.127526    -0.0989683   -0.112599
  0.130442     0.0749232   -0.00492829   0.145272     0.12988      -0.0461482   -0.0514129   -0.0934109   -0.036415      0.0879747    -0.0346699   -0.0799238     0.0229941     0.198463   -0.0292071   -0.115138    -0.12885      0.0472837    0.019067     -0.037838    -0.0160194   -0.176223    -0.0144097   -0.0448229    0.0792242   -0.181271
  0.00873208   0.0519931    0.051801    -0.0632977    0.047796     -0.126029    -0.176226     0.0147152    0.12096       0.0104177    -0.0103857   -0.0325036    -0.10899       0.0224266  -0.101533    -0.0280286    0.120493     0.118169    -0.010006      0.14187      0.0475406   -0.176545    -0.0604738   -0.10015      0.0648073   -0.0933294
  0.030026    -0.00530356  -0.0155184    0.107766    -0.0718488    -0.00721756   0.0413849    0.0460255    0.0499303    -0.0163781     0.064934    -0.0546966    -0.0222603    -0.0440031   0.0479133    0.0143428   -0.0651578   -0.163387    -0.127233     -0.213554    -0.0185856   -0.0429625    0.0277378   -0.0615036   -0.00276715   0.120968
  0.0996733   -0.0102059   -0.0617346    0.106309     0.042199     -0.120523    -0.110566    -0.134478     0.104445     -0.019135      0.00639039   0.00651478   -0.0760385    -0.0130994  -0.209485    -0.171026    -0.0780185    0.0901162    0.113201     -0.0529577   -0.0517409   -0.0263769    0.0609101   -0.0626812   -0.1199      -0.0322068
  0.105921     0.0213915   -0.127634     0.0919269    0.0830521     0.0789257   -0.078429     0.159602     0.135         0.0493435     0.078224     0.0995664    -0.02795      -0.161756   -0.0270023   -0.0414645    0.164217     0.148725     0.020082      0.235682     0.0686395   -0.046937     0.00904309   0.107696    -0.248486    -0.179172
  0.0295809   -0.0602216   -0.0690304    0.0716063    0.166904     -0.0577528   -0.0270964    0.085297    -0.00388759   -0.136925      0.0111312   -0.07581       0.0172013     0.0170263  -0.0335226   -0.135413    -0.0677186   -0.124365    -0.0383568    -0.10218      0.019632     0.0718356    0.133067    -0.0838443    0.0566199   -0.0778596
  0.0207679   -0.0764545   -0.186894     0.0180419   -0.0497873    -0.0405816   -0.0287397   -0.0487422    0.0571541     0.0743977    -0.046129     0.131746     -0.192041     -0.0689982  -0.231796     0.00824718   0.12832     -0.0438654    0.106128      0.165031     0.0497032   -0.174062    -0.0417534   -0.0482048   -0.00382643   0.0836708
  0.0229255    0.0213452   -0.0856726    0.0740908    0.0657782     0.00618009  -0.0192746   -0.096847     0.18352       0.0274961     0.0801292    0.00607127    0.0278913    -0.047375   -0.102991     0.0610979    0.015518     0.018271     0.197587      0.188196    -0.115001    -0.101387     0.170263     0.0291406   -0.0230717    0.0661607
  0.0233263    0.0163843   -0.135538    -0.198039    -0.051765     -0.0119492   -0.0542076   -0.0878635    0.0276283     0.164564      0.200214     0.0554985     0.0521213     0.174759   -0.082224    -0.0200793   -0.0198463   -0.0254361    0.0473022     0.00218898   0.113478    -0.0525316   -0.0181353    0.0175838    0.0510277   -0.160921
  0.119126     0.0205486   -0.0504673   -0.0397684   -0.214257     -0.120803    -0.101111     0.371403    -0.107086      0.126813      0.294031    -0.369869      0.141029      0.254878   -0.165913    -0.183098     0.15582      0.0942076    0.0130842     0.0638535   -0.0827167    0.0355031    0.0999513    0.147955    -0.0665398   -0.0169927
  0.282905     0.0441408    0.0106702   -0.123097    -0.100864      0.0813065   -0.124884     0.0687053   -0.0256673    -0.264928     -0.0465064   -0.0221494    -0.142456     -0.173268    0.135538     0.0595156    0.181181     0.110533    -0.0645553     0.0237993    0.234403     0.0711646   -0.00156138  -0.209806    -0.111513    -0.0267653
 -0.0426722   -0.0206048    0.00963013   0.0906525    0.0979507    -0.00622214   0.0121761    0.0662121    0.132369      0.11303      -0.206076     0.0854947     0.113434     -0.0710527   0.198921     0.0398942   -0.0216144   -0.141022     0.0129281     0.146654     0.0362182    0.0702049    0.0618437   -0.111914    -0.0305158    0.0242645
 -0.0736713   -0.0415248    0.0502515   -0.11686     -0.175445     -0.16888     -0.0562968   -0.081294     0.0706803     0.126704     -0.100947     0.135792     -0.110551      0.0777896  -0.139871     0.0241632   -0.128226    -0.258484    -0.0059797     0.111428     0.112965     0.0213686    0.130449    -0.00574742   0.0272706    0.151847
 -0.0686395   -0.207319     0.107194    -0.0256501    0.110152      0.117421    -0.207567    -0.122789    -0.0147008    -0.263432     -0.0349052    0.0874773    -0.0170658     0.0253782  -0.102872     0.0177258   -0.00204151   0.0306494   -0.141068      0.00639263   0.187619     0.195871     0.0489385    0.130073     0.083789     0.117522
  0.00965714  -0.0649129   -0.0205434    0.0311275   -0.00909238    0.0325428    0.0904153   -0.173707     0.0579812     0.0213463    -0.0383141   -0.0593204     0.000371971   0.11138     0.102945    -0.054629    -0.00782112   0.0733583   -0.0512077    -0.161509     0.069855    -0.0471643    0.0416363    0.0265733    0.1732       0.00175545
  0.142868    -0.20818     -0.119233     0.154353    -0.0739107     0.00597101  -0.081319    -0.243562     0.143141      0.0680279    -0.0338734   -0.0599261     0.152588     -0.0489149   0.0444226   -0.148608    -0.0657815   -0.0767325    0.144835      0.102589    -0.00110813   0.115276    -0.0559677   -0.0244821   -0.121079     0.024782
 -0.109226    -0.00877828  -0.274762     0.0322749    0.13904      -0.127306    -0.194095    -0.0972746   -0.291498      0.148619     -0.0490547   -0.14456      -0.027563      0.246347   -0.031602     0.00562117  -0.163844     0.0110242    0.0477975     0.0954985    0.194256    -0.133752     0.109463    -0.201226    -0.192373    -0.0191782
  0.0847576    0.0270727   -0.0585048   -0.0869534   -0.00205793   -0.0929188    0.0161008    0.0069326   -0.121243     -0.101285     -0.00425931  -0.146487     -0.0160212     0.0570733   0.0862239   -0.168819    -0.0968338    0.0238188    0.00242814    0.029824    -0.0174937    0.0548061    0.00525422  -0.10292      0.307069     0.0340117
  0.176991     0.0770233    0.0261125   -0.117169     0.0196918    -0.0219579    0.0591493   -0.0455194    0.138891     -0.190535      0.0564902   -0.0497875     0.176849     -0.0379652   0.0452409    0.167442     0.264932    -0.0834298   -0.0459324    -0.0961827    0.105833     0.00160268   0.00375143  -0.0843428    0.0274971    0.0532101
  0.0433352   -0.0717359    0.0796039   -0.0820636   -0.144305     -0.058738     0.0318954   -0.0462047    0.0779439     0.000867848  -0.106637     0.0883149     0.0453008     0.0267133   0.017345    -0.0757721   -0.0599861   -0.0296637    0.0902344     0.0239117    0.0029963    0.0761005    0.0116775    0.0898482   -0.00860749   0.0582673
  0.0567844    0.101305    -0.0657944   -0.11825      0.000231772   0.113737    -0.0667633   -0.195747    -0.0235187    -0.012511      0.0323087    0.0406015    -0.139214      0.0457458   0.00195072  -0.152934    -0.0260594   -0.143961     0.0043627    -0.0677537   -0.156965    -0.0546355    0.0359438    0.0241684   -0.0193062   -0.0268199
 -0.0876211   -0.0478967    0.0972166   -0.00832745   0.00541388    0.0186659   -0.109733    -0.14719     -0.043451      0.142807     -0.122885    -0.0232106    -0.206202     -0.133574    0.0298718    0.32597     -0.0578919    0.0689139    0.155692     -0.17125     -0.0777872   -0.0817656   -0.0367117   -0.023003     0.0603278   -0.0719789
  0.0106929   -0.0253774   -0.0025097    0.081847    -0.0409502    -0.0253616   -0.0857899    0.0379127    0.0453232     0.0668618     0.130075    -0.232826     -0.14362      -0.0187703   0.0358824    0.0622383   -0.0109174    0.00404545   0.207412     -0.0863787   -0.0283846    0.221974     0.040905     0.129809    -0.112613    -0.201387
 -0.00371861   0.0597978   -0.194341    -0.0733626    0.0947212     0.0917606   -0.161538    -0.0717354    0.154905     -0.0870052    -0.0347864   -0.000319348  -0.0533453     0.0204795  -0.0675604    0.0262845    0.0266253    0.0594504    0.123066      0.0935215    0.129888    -0.0194742    0.119532     0.00512133  -0.0336428   -0.0705462
  0.0737035    0.256959     0.088058     0.0975261    0.00913118   -0.14552     -0.0315143    0.0783288    0.209061     -0.0142884     0.154077    -0.0202676     0.142254     -0.015646    0.0427188   -0.15422      0.107314    -0.113987    -0.103085      0.126327     0.0501588    0.139481    -0.083421     0.0744829    0.0526914   -0.0736123
  0.0325632    0.0974988   -0.0332038   -0.0957037    0.0117527     0.141168    -0.0579807    0.00770169   0.0595856    -0.0502935     0.0342629    0.0656846    -0.194832      0.0310193  -0.014202    -0.193099    -0.0384005   -0.10163      0.0220554    -0.0364974   -0.138843    -0.0786339    0.0551043    0.0622726   -0.00242432  -0.0389397
 -0.0779961    0.128999     0.262571     0.00305757   0.0572453     0.0557042   -0.220388     0.0899488    0.000523856   0.156984     -0.0201716    0.0192755     0.10459       0.0773785  -0.0689725    0.00106967  -0.069516    -0.151858    -0.0202468     0.0685091   -0.169886     0.0162554    0.0614841   -0.164214     0.128071     0.0507373[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      9
│     12
│     14
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.018254
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      5
│      9
│      ⋮
│     18
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.985791
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     22
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.993862
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      5
│      9
│      ⋮
│     18
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.993188
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     22
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.997323
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.982103
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      9
│     12
│      ⋮
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.009164
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     18
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.983156
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.987509
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      5
│      9
│      ⋮
│     18
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.992839
┌ Info: EM with 100000 data points 10 iterations avll -0.992839
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.239442    -0.0849443   -0.129151    -0.0320953    0.133076     0.126574    -0.0997944   -0.163253     0.00773952   0.0800909     0.0723053    0.0608251   -0.00472059    0.0583152    0.0170236   -0.0720439    0.0851442   -0.00911345   0.118308     0.155219    -0.217439     0.00900157  -0.0164814   -0.0342935  -0.050591      0.13696
 -0.00898327   0.113991    -0.205796    -0.0763723    0.0952673   -0.021294     0.00119388   0.00498711   0.0648897    0.0581677    -0.0865688    0.0485324    0.0931225    -0.085179    -0.0484664   -0.187743     0.0995522    0.0559614    0.147004     0.171173     0.00769621   0.157498    -0.103781     0.0353053  -0.021785     -0.161745
  0.112439    -0.0642647   -0.214992     0.0391935   -0.108124     0.0532345   -0.0432528    0.130964    -0.0814258    0.109074      0.0187459   -0.0103602    0.18069      -0.00938541  -0.0205148   -0.0610947    0.0558698   -0.0536815   -0.180622    -0.175746     0.0622035    0.239319     0.0622697   -0.037406   -0.0249479     0.0140842
 -0.093275     0.109446     0.188647     0.137096    -0.073889     0.171799    -0.10573     -0.221063     0.0166322   -0.26635       0.0132342    0.0892005   -0.00797023   -0.0987939   -0.186998     0.0617273    0.102781     0.1214      -0.14036      0.00209838  -0.00510953  -0.0914143    0.166368     0.130471   -0.0202152    -0.0150594
 -0.0152072   -0.0756542   -0.149311    -0.0864532    0.140441     0.140169     0.0455042    0.0704088    0.022457    -0.0753391     0.0345621    0.0116607    0.0931474     0.100456     0.119535     0.112037     0.109948     0.149554    -0.130052     0.0625817    0.0447358   -0.189556     0.027181     0.109834    0.133107      0.0840686
  0.161325    -0.0936114   -0.0886576   -0.107326    -0.0543627   -0.0838341    0.0367261    0.00384018   0.0576632    0.0782289     0.0115557    0.117967    -0.124106     -0.164885     0.073218    -0.134642     0.0693277   -0.193475    -0.130187     0.00194489   0.160734     0.114584     0.0826841    0.17877    -0.123851     -0.103213
 -0.0547818   -0.172247    -0.0872408    0.0260612    0.268142     0.00417591   0.0969802    0.0742094    0.0865963   -0.000181794  -0.0781419    0.0483708   -0.0769445     0.0994921   -0.0439718    0.119736     0.0545045   -0.0482556   -0.0279053   -0.0366152    0.0313401    0.0589504   -0.0750331    0.12227    -0.0102786    -0.0114484
  0.0936411   -0.12117      0.0455571   -0.146988     0.148311     0.038485     0.0695446   -0.00168398  -0.0308013   -0.0885466    -0.167384     0.115884    -0.0336692     0.00635526   0.0391778    0.0510288   -0.0177186   -0.0757634    0.0355802    0.0402698   -0.040079     0.0508925    0.127622    -0.0466179  -0.13145       0.00720917
  0.0503925    0.0698653   -0.112425    -0.234125    -0.0926878    0.0938395   -0.0719478   -0.0554725   -0.00268322   0.00992197    0.0728469    0.0537931   -0.0962482    -0.0641835    0.0526763   -0.0643849   -0.106534     0.12547     -0.0856781    0.00262684   0.0363222    0.171819    -0.152885     0.138257    0.206553      0.00196018
 -0.172075     0.0691305    0.197839    -0.0685946   -0.0275161   -0.197411     0.0601604    0.0121409   -0.0319827    0.121941     -0.0700571   -0.0196126   -0.094952      0.135475    -0.0196507   -0.028305     0.0757233    0.0130342   -0.137635    -0.0421216    0.0247285    0.0850455    0.024105    -0.179681   -0.00363894    0.0859104
 -0.0516763    0.118683     0.0242465   -0.0789657   -0.0207939    0.125376     0.032908     0.0194524   -0.076964    -0.0148342    -0.0423982   -0.10871     -0.103652      0.20168     -0.096558    -0.00252609  -0.0319188    0.0945759   -0.154176    -0.0584554   -0.0341719   -0.0638244   -0.0462828   -0.389472    0.158834     -0.0609255
 -0.0368578   -0.123974     0.0346837   -0.133301     0.0169568   -0.0306126    0.0254571    0.113666    -0.0035261    0.235015      0.168483     0.0589944   -0.0230004     0.0117753    0.0940502    0.0285663   -0.055617    -0.00832187   0.130859    -0.0595825    0.174376    -0.0448933   -0.180328     0.0294021  -0.0857603     0.191236
  0.150712     0.117621    -0.0526518   -0.0508465    0.0778902   -0.139206    -0.0848946   -0.132362     0.0295783   -0.0260604    -0.0422489    0.174834    -0.00253472    0.0690102   -0.140352    -0.0815506    0.192663     0.0824293    0.126218    -0.29618      0.0579035    0.211601    -0.172816    -0.179635   -0.0457538    -0.0577454
  0.0973977   -0.132234    -0.143306     0.0205607    0.0446585   -0.0360048    0.137678     0.16319     -0.192182     0.0638079     0.0121042   -0.0915416    0.00220139   -0.0179398   -0.309978    -0.0423817   -0.049878     0.0244194    0.175288    -0.0888596   -0.0514123    0.0712598    0.00387358   0.082606    0.0417425     0.0376805
 -0.0211968   -0.184332     0.0174817   -0.0365772   -0.0846933    0.134015    -0.0432565    0.0237957    0.101013     0.117563     -0.0189082   -0.088448     0.0146606     0.126506     0.0489299   -0.0201203    0.0477474   -0.0472478   -0.121172     0.0484896    0.012203    -0.0387722    0.0325387   -0.10101    -0.13178      -0.0311962
  0.154547     0.0206702    0.0150115    0.131344    -0.299201     0.046975    -0.111987    -0.00725856  -0.0304847   -0.0109035    -0.0902227   -0.176386    -0.120221      0.119132     0.0265539    0.105233    -0.113945     0.160398    -0.197678     0.0747097    0.0226661   -0.0673881    0.0911198    0.22785    -0.158073     -0.0660777
  0.0733437    0.100329     0.0561823    0.164605    -0.00533744   0.086699     0.0801413    0.0679722   -0.187089     0.190673      0.00256988  -0.103075     0.0184912    -0.157329     0.0964456   -0.133817     0.0459895   -0.057446     0.134449     0.0261414   -0.0378944   -0.119087    -0.264763    -0.105       0.0346707    -0.00777744
  0.0974682   -0.186493    -0.00363171  -0.0198424    0.166987     0.0800592    0.0552111    0.088129    -0.0618682   -0.103729     -0.0537021   -0.0225441   -0.0604324    -0.0430264    0.116379     0.0769671   -0.0299939    0.0956228    0.025799    -0.0846665    0.0224004   -0.130058     0.0252235   -0.12057    -0.0447364     0.0516933
  0.156918    -0.113946    -0.0616104    0.0928744    0.135538    -0.0680086   -0.16417     -0.0548659    0.119319     0.124582     -0.020874     0.126949    -0.0498303    -0.0307354   -0.0462343    0.0303257   -0.119594     0.12039     -0.0177087    0.168409     0.0341575    0.0907004   -0.0964454   -0.0319568   0.0292673    -0.0838679
 -0.117344     0.00668833   0.0545733   -0.0295554   -0.141765    -0.0701635   -0.132985    -0.0637721   -0.00560325  -0.0270468    -0.102927    -0.113833    -0.165267      0.132852     0.0873894   -0.0285238   -0.0646129    0.00678567   0.151676     0.00730615   0.0137043   -0.0408768    0.0910193   -0.0411617   0.0948912     0.114079
 -0.0411392    0.0395536    0.0523705    0.0661243    0.121412    -0.118968     0.0791887    0.121014     0.095617     0.0564414     0.189524     0.0319314   -0.115569      0.088222    -0.100264    -0.160491     0.0863386   -0.11468      0.0403972    0.0728527    0.0868284    0.0713331    0.0784151    0.0269034  -0.19119       0.0472239
 -0.0761754    0.079645    -0.121268    -0.00869729   0.136328    -0.0144786    0.1903       0.178954    -0.110475     0.040508      0.0939895    0.109916     0.0599138     0.216772    -0.191189     0.127914     0.0298156    0.125562     0.177259    -0.0132561    0.0862625   -0.096826    -0.0106154   -0.0771014   0.148697      0.0785269
 -0.05261      0.146034    -0.0549378    0.0320408    0.0808338   -0.120923     0.104775     0.100729    -0.0292853    0.118577     -0.122071    -0.00884469  -0.060241     -0.0478213   -0.135286    -0.0541489    0.00337095   0.024852    -0.0931403   -0.0272052   -0.129104     0.150401     0.0374172    0.0716009  -0.0208364     0.0146864
  0.158781     0.0523765    0.225729     0.0428834    0.0906954    0.123108    -0.0711718    0.0468985   -0.133632     0.0248608     0.0162558   -0.0439692   -0.0559518     0.0322622   -0.00802767   0.0875148    0.171388     0.0466542    0.164956    -0.0365726    0.0355567   -0.135287     0.0176291   -0.0268373  -0.0719921    -0.0303317
  0.0725827   -0.0843257    0.193113     0.0546728    0.0380808   -0.00201854  -0.214808     0.0910119   -0.0461164    0.095256      0.0959134    0.01512      0.000420239   0.0557474    0.0836629    0.119087     0.195184     0.189378    -0.109179     0.0259523    0.0359114    0.209178     0.0642543   -0.157841    0.000618966  -0.0228856
  0.0125069    0.105835    -0.0209451   -0.0752468   -0.0823128    0.231096     0.0728292    0.088975    -0.103279    -0.0145883     0.0220742    0.0601101    0.0993866     0.0874125    0.070534    -0.0441999   -0.0794627   -0.0503973    0.09064      0.129151     0.0831065   -0.0836946   -0.111496     0.0908998  -0.023028      0.0711748
 -0.0511511   -0.00697008   0.0266888   -0.00419205   0.119223     0.14136      0.0823781    0.150003    -0.106143     0.104601      0.126819     0.154905     0.202773      0.138401     0.0711933   -0.115765     0.112601    -0.0665907    0.173995     0.00472134  -0.15492     -0.0383144   -0.048879    -0.167805   -0.064402      0.0150412
  0.043448     0.128702     0.0566655   -0.265939     0.0398214    0.0205699   -0.00483112  -0.0251914   -0.0647211    0.117603     -0.233454     0.0435811   -0.0509312     0.143265     0.0853008    0.0186061   -0.135085    -0.0591825   -0.0327211   -0.0673662   -0.0941128   -0.0612137    0.101961    -0.130856    0.0947432    -0.0156401
 -0.191957     0.12488      0.155502     0.0192981   -0.0141797   -0.106066    -0.00538958  -0.00814097   0.0232323    0.0294579    -0.00870872  -0.0125284   -0.134591     -0.0820734   -0.124388     0.166072     0.0272221   -0.170195     0.0674865    0.147804    -0.0544895    0.0155777   -0.0185134    0.0364856   0.0732469    -0.0921318
 -0.240644    -0.126715     0.00181837   0.00997556  -0.0824469   -0.145882     0.0179798    0.0964701   -0.0847767    0.039495      0.0850949    0.160704     0.0450383    -0.147518    -0.0932135    0.119863    -0.0434319   -0.0877082   -0.133314    -0.014369     0.064605    -0.0769683    0.00252889  -0.191375    0.0494954    -0.0623662
 -0.0736878   -0.0978047    0.0129569    0.167873    -0.0186333    0.00597101  -0.149138     0.00987633  -0.0049163    0.00136168   -0.119355     0.0367173   -0.062085      0.105462     0.0892117   -0.251068     0.067202    -0.00689511  -0.0719881    0.0633111    0.0524061   -0.0263401   -0.0918515   -0.242184    0.0210608    -0.0288496
  0.00514426   0.0779844   -0.05482      0.14072      0.0459075    0.183044    -0.0669931    0.08358     -0.0029456    0.0646976    -0.0560938   -0.00160816   7.98476e-5   -0.0634507    0.0459695   -0.0206966    0.0170433    0.168183     0.00325473   0.136134     0.11824      0.00653977   0.017046     0.018681    0.0649458    -0.00403684kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4214790648728415
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421498
[ Info: iteration 2, average log likelihood -1.421440
[ Info: iteration 3, average log likelihood -1.421400
[ Info: iteration 4, average log likelihood -1.421352
[ Info: iteration 5, average log likelihood -1.421291
[ Info: iteration 6, average log likelihood -1.421215
[ Info: iteration 7, average log likelihood -1.421124
[ Info: iteration 8, average log likelihood -1.421024
[ Info: iteration 9, average log likelihood -1.420913
[ Info: iteration 10, average log likelihood -1.420779
[ Info: iteration 11, average log likelihood -1.420573
[ Info: iteration 12, average log likelihood -1.420199
[ Info: iteration 13, average log likelihood -1.419528
[ Info: iteration 14, average log likelihood -1.418520
[ Info: iteration 15, average log likelihood -1.417413
[ Info: iteration 16, average log likelihood -1.416581
[ Info: iteration 17, average log likelihood -1.416131
[ Info: iteration 18, average log likelihood -1.415931
[ Info: iteration 19, average log likelihood -1.415849
[ Info: iteration 20, average log likelihood -1.415816
[ Info: iteration 21, average log likelihood -1.415802
[ Info: iteration 22, average log likelihood -1.415796
[ Info: iteration 23, average log likelihood -1.415793
[ Info: iteration 24, average log likelihood -1.415792
[ Info: iteration 25, average log likelihood -1.415791
[ Info: iteration 26, average log likelihood -1.415791
[ Info: iteration 27, average log likelihood -1.415791
[ Info: iteration 28, average log likelihood -1.415790
[ Info: iteration 29, average log likelihood -1.415790
[ Info: iteration 30, average log likelihood -1.415790
[ Info: iteration 31, average log likelihood -1.415790
[ Info: iteration 32, average log likelihood -1.415790
[ Info: iteration 33, average log likelihood -1.415790
[ Info: iteration 34, average log likelihood -1.415790
[ Info: iteration 35, average log likelihood -1.415789
[ Info: iteration 36, average log likelihood -1.415789
[ Info: iteration 37, average log likelihood -1.415789
[ Info: iteration 38, average log likelihood -1.415789
[ Info: iteration 39, average log likelihood -1.415789
[ Info: iteration 40, average log likelihood -1.415789
[ Info: iteration 41, average log likelihood -1.415789
[ Info: iteration 42, average log likelihood -1.415789
[ Info: iteration 43, average log likelihood -1.415789
[ Info: iteration 44, average log likelihood -1.415789
[ Info: iteration 45, average log likelihood -1.415789
[ Info: iteration 46, average log likelihood -1.415789
[ Info: iteration 47, average log likelihood -1.415789
[ Info: iteration 48, average log likelihood -1.415789
[ Info: iteration 49, average log likelihood -1.415789
[ Info: iteration 50, average log likelihood -1.415789
┌ Info: EM with 100000 data points 50 iterations avll -1.415789
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4214976408336415
│     -1.4214403737657015
│      ⋮
└     -1.4157888300285548
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415807
[ Info: iteration 2, average log likelihood -1.415747
[ Info: iteration 3, average log likelihood -1.415704
[ Info: iteration 4, average log likelihood -1.415652
[ Info: iteration 5, average log likelihood -1.415585
[ Info: iteration 6, average log likelihood -1.415502
[ Info: iteration 7, average log likelihood -1.415409
[ Info: iteration 8, average log likelihood -1.415316
[ Info: iteration 9, average log likelihood -1.415232
[ Info: iteration 10, average log likelihood -1.415163
[ Info: iteration 11, average log likelihood -1.415110
[ Info: iteration 12, average log likelihood -1.415069
[ Info: iteration 13, average log likelihood -1.415034
[ Info: iteration 14, average log likelihood -1.415004
[ Info: iteration 15, average log likelihood -1.414976
[ Info: iteration 16, average log likelihood -1.414950
[ Info: iteration 17, average log likelihood -1.414924
[ Info: iteration 18, average log likelihood -1.414899
[ Info: iteration 19, average log likelihood -1.414875
[ Info: iteration 20, average log likelihood -1.414851
[ Info: iteration 21, average log likelihood -1.414829
[ Info: iteration 22, average log likelihood -1.414807
[ Info: iteration 23, average log likelihood -1.414786
[ Info: iteration 24, average log likelihood -1.414766
[ Info: iteration 25, average log likelihood -1.414746
[ Info: iteration 26, average log likelihood -1.414728
[ Info: iteration 27, average log likelihood -1.414711
[ Info: iteration 28, average log likelihood -1.414694
[ Info: iteration 29, average log likelihood -1.414678
[ Info: iteration 30, average log likelihood -1.414663
[ Info: iteration 31, average log likelihood -1.414648
[ Info: iteration 32, average log likelihood -1.414634
[ Info: iteration 33, average log likelihood -1.414621
[ Info: iteration 34, average log likelihood -1.414608
[ Info: iteration 35, average log likelihood -1.414596
[ Info: iteration 36, average log likelihood -1.414585
[ Info: iteration 37, average log likelihood -1.414574
[ Info: iteration 38, average log likelihood -1.414564
[ Info: iteration 39, average log likelihood -1.414554
[ Info: iteration 40, average log likelihood -1.414545
[ Info: iteration 41, average log likelihood -1.414537
[ Info: iteration 42, average log likelihood -1.414530
[ Info: iteration 43, average log likelihood -1.414523
[ Info: iteration 44, average log likelihood -1.414516
[ Info: iteration 45, average log likelihood -1.414510
[ Info: iteration 46, average log likelihood -1.414505
[ Info: iteration 47, average log likelihood -1.414500
[ Info: iteration 48, average log likelihood -1.414496
[ Info: iteration 49, average log likelihood -1.414492
[ Info: iteration 50, average log likelihood -1.414488
┌ Info: EM with 100000 data points 50 iterations avll -1.414488
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158071924079147
│     -1.4157471055734097
│      ⋮
└     -1.414487924223364
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414497
[ Info: iteration 2, average log likelihood -1.414445
[ Info: iteration 3, average log likelihood -1.414405
[ Info: iteration 4, average log likelihood -1.414359
[ Info: iteration 5, average log likelihood -1.414301
[ Info: iteration 6, average log likelihood -1.414228
[ Info: iteration 7, average log likelihood -1.414139
[ Info: iteration 8, average log likelihood -1.414037
[ Info: iteration 9, average log likelihood -1.413931
[ Info: iteration 10, average log likelihood -1.413832
[ Info: iteration 11, average log likelihood -1.413745
[ Info: iteration 12, average log likelihood -1.413674
[ Info: iteration 13, average log likelihood -1.413616
[ Info: iteration 14, average log likelihood -1.413570
[ Info: iteration 15, average log likelihood -1.413533
[ Info: iteration 16, average log likelihood -1.413500
[ Info: iteration 17, average log likelihood -1.413472
[ Info: iteration 18, average log likelihood -1.413447
[ Info: iteration 19, average log likelihood -1.413423
[ Info: iteration 20, average log likelihood -1.413401
[ Info: iteration 21, average log likelihood -1.413379
[ Info: iteration 22, average log likelihood -1.413357
[ Info: iteration 23, average log likelihood -1.413336
[ Info: iteration 24, average log likelihood -1.413315
[ Info: iteration 25, average log likelihood -1.413294
[ Info: iteration 26, average log likelihood -1.413272
[ Info: iteration 27, average log likelihood -1.413251
[ Info: iteration 28, average log likelihood -1.413229
[ Info: iteration 29, average log likelihood -1.413208
[ Info: iteration 30, average log likelihood -1.413186
[ Info: iteration 31, average log likelihood -1.413165
[ Info: iteration 32, average log likelihood -1.413144
[ Info: iteration 33, average log likelihood -1.413124
[ Info: iteration 34, average log likelihood -1.413104
[ Info: iteration 35, average log likelihood -1.413086
[ Info: iteration 36, average log likelihood -1.413068
[ Info: iteration 37, average log likelihood -1.413051
[ Info: iteration 38, average log likelihood -1.413035
[ Info: iteration 39, average log likelihood -1.413020
[ Info: iteration 40, average log likelihood -1.413006
[ Info: iteration 41, average log likelihood -1.412993
[ Info: iteration 42, average log likelihood -1.412981
[ Info: iteration 43, average log likelihood -1.412970
[ Info: iteration 44, average log likelihood -1.412960
[ Info: iteration 45, average log likelihood -1.412950
[ Info: iteration 46, average log likelihood -1.412940
[ Info: iteration 47, average log likelihood -1.412931
[ Info: iteration 48, average log likelihood -1.412923
[ Info: iteration 49, average log likelihood -1.412914
[ Info: iteration 50, average log likelihood -1.412906
┌ Info: EM with 100000 data points 50 iterations avll -1.412906
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4144969131600245
│     -1.4144451922079198
│      ⋮
└     -1.4129061866903614
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412907
[ Info: iteration 2, average log likelihood -1.412839
[ Info: iteration 3, average log likelihood -1.412774
[ Info: iteration 4, average log likelihood -1.412698
[ Info: iteration 5, average log likelihood -1.412606
[ Info: iteration 6, average log likelihood -1.412493
[ Info: iteration 7, average log likelihood -1.412363
[ Info: iteration 8, average log likelihood -1.412222
[ Info: iteration 9, average log likelihood -1.412077
[ Info: iteration 10, average log likelihood -1.411937
[ Info: iteration 11, average log likelihood -1.411809
[ Info: iteration 12, average log likelihood -1.411696
[ Info: iteration 13, average log likelihood -1.411598
[ Info: iteration 14, average log likelihood -1.411516
[ Info: iteration 15, average log likelihood -1.411447
[ Info: iteration 16, average log likelihood -1.411389
[ Info: iteration 17, average log likelihood -1.411340
[ Info: iteration 18, average log likelihood -1.411298
[ Info: iteration 19, average log likelihood -1.411261
[ Info: iteration 20, average log likelihood -1.411229
[ Info: iteration 21, average log likelihood -1.411199
[ Info: iteration 22, average log likelihood -1.411173
[ Info: iteration 23, average log likelihood -1.411148
[ Info: iteration 24, average log likelihood -1.411124
[ Info: iteration 25, average log likelihood -1.411102
[ Info: iteration 26, average log likelihood -1.411081
[ Info: iteration 27, average log likelihood -1.411062
[ Info: iteration 28, average log likelihood -1.411043
[ Info: iteration 29, average log likelihood -1.411024
[ Info: iteration 30, average log likelihood -1.411007
[ Info: iteration 31, average log likelihood -1.410989
[ Info: iteration 32, average log likelihood -1.410973
[ Info: iteration 33, average log likelihood -1.410957
[ Info: iteration 34, average log likelihood -1.410941
[ Info: iteration 35, average log likelihood -1.410926
[ Info: iteration 36, average log likelihood -1.410911
[ Info: iteration 37, average log likelihood -1.410896
[ Info: iteration 38, average log likelihood -1.410882
[ Info: iteration 39, average log likelihood -1.410868
[ Info: iteration 40, average log likelihood -1.410855
[ Info: iteration 41, average log likelihood -1.410842
[ Info: iteration 42, average log likelihood -1.410829
[ Info: iteration 43, average log likelihood -1.410817
[ Info: iteration 44, average log likelihood -1.410805
[ Info: iteration 45, average log likelihood -1.410793
[ Info: iteration 46, average log likelihood -1.410781
[ Info: iteration 47, average log likelihood -1.410770
[ Info: iteration 48, average log likelihood -1.410760
[ Info: iteration 49, average log likelihood -1.410750
[ Info: iteration 50, average log likelihood -1.410740
┌ Info: EM with 100000 data points 50 iterations avll -1.410740
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4129071773110178
│     -1.4128393041804386
│      ⋮
└     -1.4107395415869295
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410739
[ Info: iteration 2, average log likelihood -1.410669
[ Info: iteration 3, average log likelihood -1.410605
[ Info: iteration 4, average log likelihood -1.410530
[ Info: iteration 5, average log likelihood -1.410439
[ Info: iteration 6, average log likelihood -1.410325
[ Info: iteration 7, average log likelihood -1.410188
[ Info: iteration 8, average log likelihood -1.410032
[ Info: iteration 9, average log likelihood -1.409865
[ Info: iteration 10, average log likelihood -1.409697
[ Info: iteration 11, average log likelihood -1.409537
[ Info: iteration 12, average log likelihood -1.409389
[ Info: iteration 13, average log likelihood -1.409258
[ Info: iteration 14, average log likelihood -1.409141
[ Info: iteration 15, average log likelihood -1.409038
[ Info: iteration 16, average log likelihood -1.408948
[ Info: iteration 17, average log likelihood -1.408868
[ Info: iteration 18, average log likelihood -1.408796
[ Info: iteration 19, average log likelihood -1.408732
[ Info: iteration 20, average log likelihood -1.408675
[ Info: iteration 21, average log likelihood -1.408622
[ Info: iteration 22, average log likelihood -1.408574
[ Info: iteration 23, average log likelihood -1.408530
[ Info: iteration 24, average log likelihood -1.408489
[ Info: iteration 25, average log likelihood -1.408450
[ Info: iteration 26, average log likelihood -1.408414
[ Info: iteration 27, average log likelihood -1.408379
[ Info: iteration 28, average log likelihood -1.408346
[ Info: iteration 29, average log likelihood -1.408315
[ Info: iteration 30, average log likelihood -1.408285
[ Info: iteration 31, average log likelihood -1.408256
[ Info: iteration 32, average log likelihood -1.408228
[ Info: iteration 33, average log likelihood -1.408201
[ Info: iteration 34, average log likelihood -1.408175
[ Info: iteration 35, average log likelihood -1.408150
[ Info: iteration 36, average log likelihood -1.408125
[ Info: iteration 37, average log likelihood -1.408102
[ Info: iteration 38, average log likelihood -1.408079
[ Info: iteration 39, average log likelihood -1.408057
[ Info: iteration 40, average log likelihood -1.408035
[ Info: iteration 41, average log likelihood -1.408014
[ Info: iteration 42, average log likelihood -1.407994
[ Info: iteration 43, average log likelihood -1.407975
[ Info: iteration 44, average log likelihood -1.407956
[ Info: iteration 45, average log likelihood -1.407938
[ Info: iteration 46, average log likelihood -1.407920
[ Info: iteration 47, average log likelihood -1.407903
[ Info: iteration 48, average log likelihood -1.407887
[ Info: iteration 49, average log likelihood -1.407871
[ Info: iteration 50, average log likelihood -1.407856
┌ Info: EM with 100000 data points 50 iterations avll -1.407856
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107385230299876
│     -1.4106694396435793
│      ⋮
└     -1.4078561493460677
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4214790648728415
│     -1.4214976408336415
│     -1.4214403737657015
│     -1.4214002130883947
│      ⋮
│     -1.4078868737526051
│     -1.4078712087388845
└     -1.4078561493460677
32×26 Array{Float64,2}:
  0.126396   -0.180646    -0.378755    -0.216924    -0.393381    0.108707    -0.330915     0.311988   -0.182142     0.0556638   0.0230047    0.0825971    0.089452   -0.3155       0.541956    0.292161   -0.328501    0.0736006  -0.406959    0.416206   -0.488887      0.724832    -0.438395     0.238647   -0.0786674    -0.19235
  0.33622     0.161701    -0.0851368    0.205109     1.03994     0.0440759    0.00105825  -0.184719   -0.248181     0.489478    0.0543726    0.00544504   0.429083    0.0941055    0.288193   -0.356394    0.11801    -0.506012   -0.183366    0.471735   -0.747903      0.423181    -0.794888     0.01633     0.512546      0.283294
 -0.169508    0.0947863    0.170569     0.731372     0.197388    0.28979      0.122855    -0.749025    0.170664    -0.0163818  -0.132761     0.45438      0.0611095   0.317473    -0.107188    0.165441    0.0596613  -0.0964073  -0.384415    0.433055    0.99748       0.555881    -0.134729     1.11462    -0.451317     -0.225726
  0.151553    0.572761    -0.201029     0.177205     0.018082    0.524484     0.0815939    0.508842    0.212221     0.134745    0.132943     0.266737     0.0500784  -0.392053     0.328632   -0.248467    0.605736   -0.0256015  -0.1336      0.376371    0.223959      0.404285     0.44683      0.999605   -0.937181     -0.237219
 -0.275552    0.0293595    0.559339    -0.75682     -0.0352915  -0.216793    -0.207822     0.318196    0.369706     0.30825     0.572068     0.205224     0.20982    -0.248777    -0.673211   -0.162147   -0.131902    0.195276    0.367844    0.735587   -0.435507      0.389729     0.148826     0.586091   -0.277012     -0.188916
 -0.561699    0.746692    -0.235927    -0.725893     0.457051   -0.51652     -0.664566     0.0982369  -0.297344    -0.498624    0.473178    -0.077216    -0.39539     0.110415     0.543062    0.0815809   0.713147    0.275365    0.285905    0.377444    0.241724      0.483783    -0.278957     0.325466    0.511439      0.12879
 -0.752281    0.226245    -0.109768     0.0900938   -0.352925    0.296064    -0.0485572   -0.373789   -0.142508     0.111358    0.229481     0.510525    -0.2846     -0.303        0.0940524   0.0471721   0.025754   -0.135263    0.476223    0.205721   -0.190582     -0.225613    -0.695846     0.289033   -0.293672      0.435066
 -0.244932   -0.0145372    0.399001     0.20045      0.59907     0.676149     0.194664     0.413402   -0.235814     0.0967432   0.432596     0.360019    -0.0619998  -0.298235     0.0773521   0.219189   -0.0920106   0.0341019  -0.174227    0.257542    0.2496       -0.332069     0.288406     0.465909    0.167966      0.838176
  0.365298   -0.200288    -0.118408     0.146287    -0.246171   -0.254423    -0.0885494   -0.304716   -0.279938    -0.0112164  -0.121442    -0.502166    -0.15598     0.482541    -0.205874    0.609387   -0.264746   -0.0427595  -0.324803   -0.295433    0.124201     -0.147485    -0.337479    -0.180489    0.127112     -0.144393
  0.119291    0.192275    -0.322947     0.490062     0.138383    0.0212663    0.0986427   -0.246397   -0.128778    -0.288592   -0.354258    -0.217747    -0.2423     -0.177235     0.902936    0.445289    0.306135   -0.349519   -0.231571   -0.254381    0.200713     -0.0105737    0.0075867   -0.152724   -0.000283452   0.137524
  0.0402559  -0.0636534   -0.281532    -0.0138896    0.156011    0.0725586    0.147565    -0.0937403  -0.0674093    0.0320388  -0.0116386    0.13994      0.0641137   0.148546     0.0233285   0.0236385  -0.0222986   0.0193699  -0.0295622   0.0718749   0.0195467     0.113618     0.0689449    0.0953533  -0.131214     -0.0417646
 -0.127958    0.09019      0.404387     0.0205509   -0.0942159   0.14103     -0.23999      0.172186    0.114286     0.125174    0.0400124   -0.164883     0.0623886  -0.153926    -0.0686927  -0.0486678   0.0186325   0.103351    0.0388425  -0.0125656  -0.0441404    -0.0542091   -0.09604     -0.16624     0.141442      0.0630788
  0.131047   -0.00780914  -0.0271154   -0.361726     0.14233    -0.438049     0.0981482    0.151452   -0.285937    -0.18449    -0.10557      0.0693569   -0.712782   -0.0533765   -0.211179    0.114388    0.478727   -0.713452    0.31466     0.182257    0.125776     -0.205554     0.267958     0.118889   -0.0135187    -0.244037
  0.166152    0.0862243    0.151909    -0.486291    -0.0277472  -0.494447     0.173423     0.0404996   0.040593     0.0463035  -0.324583    -0.0280666   -0.578372    0.125572     0.0347826  -0.422681    0.54843     0.337915    0.124907    0.0329088   0.409194     -0.416617     0.290263    -0.285937    0.343011      0.226212
 -0.0459234  -0.230681    -0.311352    -0.0387153    0.11786     0.00214445   0.190028    -0.0809398  -0.252438     0.146098   -0.391704     0.594584     0.110587    0.311743    -0.592369   -0.711244   -0.203125    0.213945    0.175816   -0.163591    0.0482197    -0.0371462   -0.00758946  -0.284758   -0.112865     -0.00655258
  0.368142   -0.0388001    0.541408     0.113626     0.0501553  -0.620846    -0.252074     0.0931841   0.56469     -0.311125   -0.00790285   0.349772     0.149696    0.513065    -0.398689   -0.479899    0.0461104   0.0311187   0.0834193  -0.280517   -0.290356     -0.0811106    0.00969651  -0.499949   -0.0693886    -0.415415
 -0.662565   -0.70014     -0.388012    -0.0111717   -0.402474    0.227695     0.00161101   0.16662     0.0742159   -0.354472    0.499949     0.345158    -0.389636    0.0568936   -0.286443    0.369051   -0.700791    0.382674   -0.196214   -0.29961     0.344306     -0.542705     0.453388    -0.673764   -0.0979951    -0.106773
 -0.0965782  -0.608923    -0.0821582   -0.373652    -0.128649    0.333545     0.739454     0.371744   -0.13302     -0.799369   -0.0237649    0.399331    -0.347957    0.501359     0.743924    0.509956   -0.0574648   0.430408   -0.130705   -0.0603897   0.289071     -0.0402249    0.656905     0.0891989  -0.442421     -0.164563
 -1.02826    -0.324721    -0.500614    -0.00562349   0.11189    -0.396234     1.11486     -0.157799   -0.504533     0.359945   -0.0189589   -0.153367    -0.453011   -0.53361     -0.312449    0.114684   -0.243316   -0.1441      0.0053097   0.318656    0.507818      0.0968737   -0.389877     0.156424   -0.144395      0.206455
  0.742965   -0.655847    -0.0983301   -0.137507    -0.238277    0.238537     0.788099    -0.198057    0.142158     0.521583   -0.79313      0.330366     0.117706   -0.563079    -0.278327    0.101757   -0.639842   -0.463288    0.0525121   0.024773   -0.288298      0.199946     0.353765    -0.638918   -0.349464      0.0296293
 -0.474231   -0.155284    -0.232662    -0.235887    -0.137938   -0.124147     0.407959     0.224752    0.0875345    0.0964804   0.0502508    0.392304     0.269432   -0.078496    -0.152296   -0.668567    0.346787    0.204607    0.996228   -0.179985    0.0790538    -0.344441     0.330725    -0.0458902   0.0754046    -0.0775904
  0.0170359   0.118591    -0.231522    -0.229581     0.325355    0.0878675    0.481975    -0.301221   -0.439168    -0.140623   -0.467768     0.970531    -0.0716703   0.699463    -0.15307     0.0369003   0.106426    0.0402891   0.0699392   0.464849   -0.000823719   0.204916     0.231822     0.121684   -0.77503       0.368642
 -0.0519367   0.0316656   -0.58972      0.284209    -0.0940026   0.293082     0.0433799   -0.0263149  -0.378897     0.258133   -0.106964    -0.43851     -0.166339    0.0926265    0.139783    0.308873   -0.0653218  -0.184248   -0.395444   -0.173846    0.405571      0.185566    -0.211261    -0.188167    0.275476     -0.125079
  0.210695   -0.014036     0.808916    -0.299488     0.256322   -0.19831     -0.16223      0.235941    0.17722      0.270336    0.108085     0.0454693   -0.356463   -0.33536      0.113137    0.0728749   0.107267   -0.143091   -0.28807     0.458783   -0.293178     -0.119852    -0.147431     0.403417   -0.0378194     0.522465
  0.104394   -0.317104     0.220188     0.253885    -0.053568    0.477343    -0.0314519    0.237871    0.190396     0.687612    0.230046    -0.0681053    0.571217    0.282729    -0.597404   -0.169421   -0.734284    0.0311271  -0.743382   -0.197576   -0.544003     -0.0070026   -0.216844     0.247199   -0.461717     -0.128829
  0.315103   -0.294142    -0.164395    -0.145016     0.300518    0.274305     0.268088     0.132328    0.160703     0.401548    0.077832    -0.0631279    0.667281    0.564159     0.026343   -0.207255   -0.138933    0.624573   -0.462458    0.269251    0.440043      0.415611     0.38423     -0.186549    0.454577      0.0936766
  0.161828    0.589301     0.00322394   0.26976     -0.0381734   0.415511    -0.804542    -0.117577    0.368659    -0.477341    0.225522     0.0362278    0.520164    0.25117      0.335484   -0.0661291   0.032509    0.476351    0.152002   -0.298707   -0.616166      0.00396873   0.130036     0.0201366   0.217568      0.147774
  0.546706    1.04547      0.240022    -0.352624     0.14823     0.227494    -0.282356    -0.211532    0.339464     0.602997   -0.225786    -0.245677     0.0885161   0.00065155  -0.204491   -0.199258    0.394352   -0.372386   -0.349442    0.269984   -0.204145     -0.0646937   -0.0612137    0.0906435  -0.289421      0.385118
 -0.107999   -0.348437    -0.0909928   -0.11117     -0.194163   -0.166729    -0.379709     0.486877    0.00105297   0.354182    0.464786    -0.774684     0.126156   -0.21911     -0.057743    0.027801   -0.116041   -0.149169    0.251648   -0.151523   -0.139491     -0.384851     0.0016352   -0.517058    0.965779     -0.430597
 -0.114569    0.109789     0.383476     0.1288      -0.333344    0.317736    -0.0620897    0.411016   -0.252319     0.492614    0.113465    -0.685417    -0.197917   -0.539806    -0.276424   -0.222526    0.216214   -0.0397968   0.281678   -0.958061    0.0937318    -0.282842    -0.222355    -0.29516    -0.0735877     0.32026
 -0.603054    0.0697154    0.120506     0.587657    -0.1075     -0.158777    -0.189294    -0.262032   -0.0977912   -0.739529   -0.511116    -0.167062    -0.0137825  -0.0341885    0.321184    0.257047    0.0161349   0.103427    0.627134   -0.122883    0.278335      0.237011    -0.464625    -0.480973    0.201904     -0.596298
  1.02023    -0.113574     0.267552     0.111751    -0.114997   -0.363719    -0.672315     0.0188056   0.294583    -0.463662    0.175063    -0.482684    -0.0850176   0.254258     0.0644331   0.194322    0.225609    0.270962   -0.156567   -0.481016    0.122735     -0.0782717    0.383596    -0.328897    0.443359     -0.590122[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407842
[ Info: iteration 2, average log likelihood -1.407828
[ Info: iteration 3, average log likelihood -1.407814
[ Info: iteration 4, average log likelihood -1.407802
[ Info: iteration 5, average log likelihood -1.407789
[ Info: iteration 6, average log likelihood -1.407777
[ Info: iteration 7, average log likelihood -1.407766
[ Info: iteration 8, average log likelihood -1.407754
[ Info: iteration 9, average log likelihood -1.407744
[ Info: iteration 10, average log likelihood -1.407733
┌ Info: EM with 100000 data points 10 iterations avll -1.407733
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.043755e+05
      1       7.041041e+05      -2.002714e+05 |       32
      2       6.890584e+05      -1.504563e+04 |       32
      3       6.835940e+05      -5.464492e+03 |       32
      4       6.808893e+05      -2.704701e+03 |       32
      5       6.791805e+05      -1.708736e+03 |       32
      6       6.779917e+05      -1.188858e+03 |       32
      7       6.770725e+05      -9.191790e+02 |       32
      8       6.763381e+05      -7.344165e+02 |       32
      9       6.757267e+05      -6.114162e+02 |       32
     10       6.752011e+05      -5.255881e+02 |       32
     11       6.747434e+05      -4.577112e+02 |       32
     12       6.743679e+05      -3.754645e+02 |       32
     13       6.740434e+05      -3.245373e+02 |       32
     14       6.737556e+05      -2.877962e+02 |       32
     15       6.735078e+05      -2.477289e+02 |       32
     16       6.732906e+05      -2.172455e+02 |       32
     17       6.730845e+05      -2.061257e+02 |       32
     18       6.728893e+05      -1.951316e+02 |       32
     19       6.727104e+05      -1.788912e+02 |       32
     20       6.725448e+05      -1.656517e+02 |       32
     21       6.723989e+05      -1.459215e+02 |       32
     22       6.722876e+05      -1.112620e+02 |       32
     23       6.721956e+05      -9.201014e+01 |       32
     24       6.721142e+05      -8.134876e+01 |       32
     25       6.720258e+05      -8.839965e+01 |       32
     26       6.719252e+05      -1.005945e+02 |       32
     27       6.718283e+05      -9.695188e+01 |       32
     28       6.717380e+05      -9.026943e+01 |       32
     29       6.716621e+05      -7.588313e+01 |       32
     30       6.715869e+05      -7.523584e+01 |       32
     31       6.715187e+05      -6.824534e+01 |       32
     32       6.714591e+05      -5.950896e+01 |       32
     33       6.713956e+05      -6.356237e+01 |       32
     34       6.713291e+05      -6.650932e+01 |       32
     35       6.712674e+05      -6.167698e+01 |       32
     36       6.712059e+05      -6.149526e+01 |       32
     37       6.711538e+05      -5.208169e+01 |       32
     38       6.711044e+05      -4.941510e+01 |       32
     39       6.710564e+05      -4.799566e+01 |       32
     40       6.710018e+05      -5.461478e+01 |       32
     41       6.709470e+05      -5.483295e+01 |       32
     42       6.708934e+05      -5.352403e+01 |       32
     43       6.708282e+05      -6.524258e+01 |       32
     44       6.707701e+05      -5.809589e+01 |       32
     45       6.707204e+05      -4.971570e+01 |       32
     46       6.706725e+05      -4.788833e+01 |       32
     47       6.706228e+05      -4.969514e+01 |       32
     48       6.705785e+05      -4.432340e+01 |       32
     49       6.705417e+05      -3.677984e+01 |       32
     50       6.705072e+05      -3.454737e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670507.1521082441)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420070
[ Info: iteration 2, average log likelihood -1.415098
[ Info: iteration 3, average log likelihood -1.413790
[ Info: iteration 4, average log likelihood -1.412819
[ Info: iteration 5, average log likelihood -1.411748
[ Info: iteration 6, average log likelihood -1.410678
[ Info: iteration 7, average log likelihood -1.409874
[ Info: iteration 8, average log likelihood -1.409394
[ Info: iteration 9, average log likelihood -1.409117
[ Info: iteration 10, average log likelihood -1.408936
[ Info: iteration 11, average log likelihood -1.408802
[ Info: iteration 12, average log likelihood -1.408695
[ Info: iteration 13, average log likelihood -1.408605
[ Info: iteration 14, average log likelihood -1.408527
[ Info: iteration 15, average log likelihood -1.408459
[ Info: iteration 16, average log likelihood -1.408398
[ Info: iteration 17, average log likelihood -1.408344
[ Info: iteration 18, average log likelihood -1.408295
[ Info: iteration 19, average log likelihood -1.408251
[ Info: iteration 20, average log likelihood -1.408211
[ Info: iteration 21, average log likelihood -1.408174
[ Info: iteration 22, average log likelihood -1.408140
[ Info: iteration 23, average log likelihood -1.408108
[ Info: iteration 24, average log likelihood -1.408079
[ Info: iteration 25, average log likelihood -1.408052
[ Info: iteration 26, average log likelihood -1.408026
[ Info: iteration 27, average log likelihood -1.408001
[ Info: iteration 28, average log likelihood -1.407979
[ Info: iteration 29, average log likelihood -1.407957
[ Info: iteration 30, average log likelihood -1.407936
[ Info: iteration 31, average log likelihood -1.407916
[ Info: iteration 32, average log likelihood -1.407898
[ Info: iteration 33, average log likelihood -1.407880
[ Info: iteration 34, average log likelihood -1.407862
[ Info: iteration 35, average log likelihood -1.407846
[ Info: iteration 36, average log likelihood -1.407830
[ Info: iteration 37, average log likelihood -1.407815
[ Info: iteration 38, average log likelihood -1.407800
[ Info: iteration 39, average log likelihood -1.407786
[ Info: iteration 40, average log likelihood -1.407773
[ Info: iteration 41, average log likelihood -1.407760
[ Info: iteration 42, average log likelihood -1.407747
[ Info: iteration 43, average log likelihood -1.407735
[ Info: iteration 44, average log likelihood -1.407723
[ Info: iteration 45, average log likelihood -1.407712
[ Info: iteration 46, average log likelihood -1.407701
[ Info: iteration 47, average log likelihood -1.407690
[ Info: iteration 48, average log likelihood -1.407680
[ Info: iteration 49, average log likelihood -1.407670
[ Info: iteration 50, average log likelihood -1.407660
┌ Info: EM with 100000 data points 50 iterations avll -1.407660
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.467079    -0.0792028    -0.0836068   0.426197   -0.400377    0.384993   -0.961661     0.13434    -0.19531     -0.203415     0.429526    -0.0386946  -0.298392     0.354725   -0.776731    0.534726   -0.161169     0.187487    -0.197777   -0.501352     0.36939     -0.166104    0.502429    -0.526903     0.181358   -0.572198
 -0.214603     0.155693      0.298742   -0.0137942  -0.432536    0.18572     0.0227367    0.354615   -0.239979     0.604555     0.119702    -0.695109   -0.354941    -0.664387   -0.267373   -0.230529    0.345281    -0.0853641    0.427273   -0.833525     0.163931    -0.418127   -0.129068    -0.34774     -0.0275877   0.384423
  0.0945381    0.343238      0.398132   -0.0585001   0.298464   -0.112829   -0.0657574   -0.0273358   0.0109603   -0.041766    -0.287804    -0.346413   -0.393431    -0.225279    0.258907    0.367665    0.632366    -0.363988    -0.0771382   0.188282     0.248987    -0.213863    0.170395     0.075194    -0.0791986   0.326668
  0.0227955   -0.162353     -0.0225041   0.0217451  -0.104278   -0.067033    0.0279831    0.0582565  -0.11344      0.0314382   -0.139728    -0.326617   -0.0577498    0.17168    -0.0624824   0.140495   -0.0275589   -0.0623269   -0.0858208  -0.0879481    0.143159     0.0491004  -0.0805869   -0.187743     0.0888296  -0.309469
  0.656187     0.385895      0.331795   -0.255154   -0.0416881   0.167104   -0.713609     0.21021     0.700113     0.203004     0.261973    -0.0128026   0.367358     0.116369    0.157434   -0.285173    0.0644715    0.132641    -0.204521   -0.043643    -0.687303    -0.098148    0.127457     0.111567     0.0481664   0.121992
 -0.11237     -0.000393744   0.242854    0.804356   -0.220633    0.038649   -0.237549    -0.636936    0.421801    -0.502686    -0.313052     0.49985     0.444316     0.0911723   0.354582    0.0325539  -0.332078     0.783778     0.149296   -0.0408217    0.00814535   0.279015   -0.207132    -0.510335    -0.122444    0.0084487
  0.0994604   -0.089103     -0.176688    0.204208   -0.321925   -0.219573    0.011112    -0.198941   -0.299893    -0.00979515  -0.158066    -0.299267   -0.315556     0.212749    0.0912482   0.407722   -0.166395    -0.178799    -0.199095   -0.345842     0.112526    -0.120789   -0.453917    -0.187484     0.0205851  -0.0587401
 -0.427586     0.169887      0.616785   -0.723341    0.0654952  -0.261049   -0.327925     0.232717    0.335706     0.193693     0.546823     0.0539868   0.113157    -0.218575   -0.694511   -0.14121    -0.0165003    0.101337     0.379212    0.710042    -0.286278     0.421489    0.01888      0.58941     -0.147218   -0.194391
  0.0977767   -0.251745      0.0603768   0.513809   -0.308881   -0.294529   -0.582542     0.0701721   0.283925    -0.178531     0.123203    -0.820172    0.112134    -0.234775    0.433021    0.229135   -0.126931     0.142396     0.289924   -0.526656     0.224197    -0.143231   -0.186757    -0.361955     0.863364   -0.562647
 -0.0933401   -0.02319       0.139202   -0.145522    0.554104    0.16154     0.499678     0.125292    0.0988125    0.128298     0.0927574    0.853931    0.10555      0.0550128   0.075609   -0.227608    0.242487     0.182282     0.206032    0.539603     0.161487    -0.248519    0.689637     0.376223    -0.162482    0.64644
  0.192662     0.0219179    -0.0328935  -0.243684    0.345865    0.0470263   0.352036     0.303359    0.00667109   0.612964    -0.173339    -0.218274    0.157895     0.39544    -0.217937   -0.816903    0.184144     0.416635    -0.219766   -0.102854     0.680949     0.0856425   0.216315    -0.404575     0.550977    0.145298
 -0.364811     0.129801     -0.0864033  -0.148454   -0.277761    0.395999   -0.0214977    0.193254    0.120583     0.0509665    0.194022     0.578097   -0.0408619   -0.246551    0.25725    -0.362498   -0.0232889    0.154957     0.243796    0.0462682   -0.35123     -0.0463369  -0.12144      0.183675    -0.235653    0.166552
 -0.0948651   -0.0268534     0.0245596  -0.0370197   0.0638554   0.0593481   0.120749    -0.0233386  -1.4744e-5    0.0416185   -0.0710647    0.14158    -0.0572084    0.0513356  -0.100053   -0.0692017   0.00945565   0.101473     0.0361207   0.104274     0.17509     -0.0348853   0.102425    -0.024094    -0.0571813   0.0761934
 -0.186605    -0.0996204     0.64861     0.535142   -0.0525633   0.784392   -0.00129092   0.182075    0.321096     0.596007     0.0120547   -0.268521    0.383324    -0.14387    -0.540028    0.126306   -0.671615     0.0678401   -0.754203   -0.00265569  -0.0427867   -0.297322   -0.170388     0.0456763   -0.0118912   0.108596
  0.508776     0.0340382    -0.0524796  -0.928737   -0.0882768   0.17371     0.455113     0.0847372  -0.378172     0.483765    -0.138294     0.393495   -0.523514     0.24998    -0.526359   -0.148115    0.0285702   -0.307832    -0.356725    0.36549     -0.295367    -0.135554    0.311702     0.241723    -0.76479     0.211226
  0.092532    -0.385071     -0.200917   -0.187792    0.126094   -0.120726    0.163088    -0.51448    -0.177622     0.190578    -0.9793       1.19598     0.121583    -0.0311663  -0.760738   -0.526487   -0.437307    -0.200243     0.282864    0.218331    -0.125443     0.248216   -0.234824    -0.450035    -0.323595    0.223374
  0.165118     0.504283     -0.0126307   0.514062    0.0962851   0.366943   -0.0174791    0.0226408   0.199478     0.0569984    0.0131895    0.300324    0.0172455   -0.16546     0.125349   -0.0192812   0.458558    -0.385281    -0.263811    0.298672     0.455584     0.518751    0.108735     1.20767     -0.849535   -0.286863
  0.00192231   0.466421     -0.342508   -0.749095    0.023976   -1.12967    -0.193396    -0.0231138  -0.157693    -0.667247     0.040798     0.144768   -0.511607    -0.0670363   0.558063   -0.0487944   0.835243     0.07922      0.59803     0.0602015    0.374757     0.203032    0.0102378   -0.0779495    0.393392   -0.0166154
 -0.613909     0.840812     -0.0611184   0.421193    0.465488    0.262781   -0.670523    -0.31453    -0.053761    -0.834995     0.0533913   -0.407165    0.0483505    0.309698    0.467061    0.191413    0.574517     0.0205422    0.121316   -0.0480658    0.0185465    0.174282   -0.413441    -0.020956     0.422968   -0.0126827
  0.444717     0.27341       0.306678    0.143912    0.842751   -0.0612601  -0.00541525  -0.180206   -0.364323     0.638311    -0.0113446   -0.030208    0.321393     0.0511531   0.187786   -0.229867    0.083615    -0.46535     -0.197205    0.536497    -0.671181     0.462251   -1.2409      -0.00431098   0.32915     0.492739
  0.363013    -0.0559713    -0.699689    0.48875     0.034822    0.459889    0.848403    -0.32371     0.0511758    0.0579141   -0.591857     0.109393    0.222084    -0.313205    0.672577    0.0260258  -0.143898    -0.541571    -0.380272   -0.532873    -0.279667     0.0443266   0.260229    -0.621429    -0.263395    0.201224
 -0.567069    -0.179936     -0.617829    0.3686      0.174627    0.492444    0.571821    -0.505206   -0.409555     0.366974     0.141864     0.233597    0.0257703    0.194504   -0.224831    0.22407    -0.299558     0.290158    -0.113665    0.323049     0.833105     0.645916   -0.169931     0.481047    -0.191313    0.227818
 -0.0792494   -0.755792     -0.199598   -0.489788   -0.569351   -0.223899    0.455712     0.62211    -0.172028     0.229009    -0.0126563   -0.173453    0.0180351   -0.340089   -0.240894    0.179278   -0.601607     0.098518     0.0579612   0.0510068    0.0528335    0.157725    0.102602    -0.398874     0.0357001  -0.445093
 -0.30079     -0.56237      -0.0636647  -0.259963   -0.220415    0.429178    0.627701     0.315886   -0.156111    -0.969837    -0.017092     0.511124   -0.431001     0.486241    0.713719    0.560241   -0.147531     0.493794    -0.0688191  -0.206547     0.420437    -0.182021    0.63359     -0.0952629   -0.441369   -0.0682905
  0.00158732  -0.0687286    -0.444713   -0.171549   -0.0818717   0.288557   -0.248984     0.156008   -0.279458     0.133488     0.0370115   -0.0319575  -0.0701863   -0.407153    0.803414    0.566842   -0.116605     0.0720106   -0.630471    0.773063    -0.129681     0.67137    -0.293571     0.376566     0.094158    0.218406
  0.296377    -0.168994      0.324389   -0.26611    -0.0944202  -0.687676   -0.269552     0.18773     0.412326    -0.24764     -0.00791706   0.0693008  -0.270229     0.303849   -0.393844   -0.352764    0.0724092    0.00555373   0.0959809  -0.142931    -0.323802    -0.357765    0.193366    -0.673762     0.224789   -0.316556
 -0.329928    -0.364431     -0.490482    0.247349    0.390311   -0.0901557   0.479793    -0.160251   -0.763214    -0.196472    -0.170045     0.164117   -0.35816     -0.0273454   0.0338847   0.214084    0.366706    -0.307063     0.557122    0.144281     0.373748    -0.301648    0.28485     -0.05729      0.301144   -0.328071
 -0.297927     0.170735     -0.156552   -0.158973    0.314117    0.69823    -0.193613     0.254913   -0.643392    -0.108376     0.764851    -0.106696   -0.00230116   0.0687706  -0.266466    0.0241969  -0.26302      0.105931     0.104271   -0.660581    -0.33696     -0.357679    0.00722867   0.0109018    0.42527     0.66776
 -0.0300286   -0.0142907     0.294665    0.526026    0.167006   -0.385634    0.239162    -0.0845852   0.181649    -0.392517    -0.220147     0.396594   -0.0573125    0.659469   -0.544271   -0.85583     0.192583    -0.134649     0.558548   -0.735574     0.161864    -0.176149   -0.109735    -0.173424    -0.226841   -0.407376
  0.255202     0.097912     -0.0656692   0.0448914   0.17551     0.133042   -0.393745     0.201449   -0.0289077    0.270622     0.167188    -0.211415    0.462132    -0.0770483  -0.0312399  -0.207098    0.10678     -0.0303462    0.0449436  -0.0640213   -0.492601     0.236157   -0.124077    -0.0376507    0.163539   -0.193858
  0.532267    -0.272017     -0.234314   -0.192141    0.353496   -0.180972   -0.00915274  -0.15089     0.187303    -0.207719    -0.0345667    0.113564    0.449082     0.855023    0.0168195   0.18883    -0.201567     0.3195      -0.411737    0.306278    -0.139274     0.296869    0.311237     0.151472    -0.0332861  -0.290447
 -1.28963     -0.0704588    -0.281589    0.0558127  -0.156499   -0.339668    0.318796    -0.0989917  -0.300157     0.308264     0.283283     0.326589   -0.35593     -0.46664    -0.152656    0.0865156  -0.222975    -0.0930372    0.428712    0.413926    -0.187       -0.383612   -0.83107      0.443621    -0.339658    0.295008[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407650
[ Info: iteration 2, average log likelihood -1.407641
[ Info: iteration 3, average log likelihood -1.407632
[ Info: iteration 4, average log likelihood -1.407623
[ Info: iteration 5, average log likelihood -1.407615
[ Info: iteration 6, average log likelihood -1.407606
[ Info: iteration 7, average log likelihood -1.407598
[ Info: iteration 8, average log likelihood -1.407590
[ Info: iteration 9, average log likelihood -1.407583
[ Info: iteration 10, average log likelihood -1.407575
┌ Info: EM with 100000 data points 10 iterations avll -1.407575
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
