Julia Version 1.5.0-DEV.33
Commit 8a19ef8ede (2020-01-08 16:19 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed LegacyStrings ────── v0.4.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.2
 Installed ScikitLearnBase ──── v0.5.0
 Installed URIParser ────────── v0.4.0
 Installed QuadGK ───────────── v2.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed DataStructures ───── v0.17.7
 Installed Clustering ───────── v0.13.3
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed OrderedCollections ─ v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.22.0
 Installed Parameters ───────── v0.12.0
 Installed DataAPI ──────────── v1.1.0
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed PDMats ───────────── v0.9.10
 Installed HDF5 ─────────────── v0.12.5
 Installed StaticArrays ─────── v0.12.1
 Installed StatsFuns ────────── v0.9.3
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed FileIO ───────────── v1.2.1
 Installed BinaryProvider ───── v0.5.8
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_z8cdwV/Project.toml`
 [no changes]
  Updating `/tmp/jl_z8cdwV/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_ioeL7m/Project.toml`
 [no changes]
  Updating `/tmp/jl_ioeL7m/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_fRO5MS/Project.toml`
 [no changes]
  Updating `/tmp/jl_fRO5MS/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_ImwqxC/Project.toml`
 [no changes]
  Updating `/tmp/jl_ImwqxC/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_9Lq9sQ/Project.toml`
 [no changes]
  Updating `/tmp/jl_9Lq9sQ/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_9Lq9sQ/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.5512706055107718e7, [54406.54600399848, 45593.45399600152], [19526.225909717028 -12301.592618573004 -9209.884702380587; -19164.92127229385 12167.17108065261 9343.816238865667], [[55401.371235661405 -7229.077514873115 -1913.4192609412714; -7229.077514873117 77612.24714662669 7407.443489938278; -1913.4192609412714 7407.443489938278 56597.5519246999], [45256.32054031306 7320.555103273163 1868.7528064193273; 7320.555103273163 22673.401322384816 -7604.990076343254; 1868.7528064193273 -7604.990076343254 43066.51635345382]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.623896e+03
      1       1.324616e+03      -2.992801e+02 |        8
      2       1.304168e+03      -2.044775e+01 |        4
      3       1.299439e+03      -4.729043e+00 |        0
      4       1.299439e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1299.4389324148087)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.090528
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.838808
[ Info: iteration 2, lowerbound -3.721015
[ Info: iteration 3, lowerbound -3.601938
[ Info: iteration 4, lowerbound -3.469581
[ Info: iteration 5, lowerbound -3.331668
[ Info: iteration 6, lowerbound -3.198048
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.067649
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.946158
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.839758
[ Info: iteration 10, lowerbound -2.753142
[ Info: iteration 11, lowerbound -2.691920
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.639237
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.582743
[ Info: iteration 14, lowerbound -2.528658
[ Info: iteration 15, lowerbound -2.480611
[ Info: iteration 16, lowerbound -2.437432
[ Info: iteration 17, lowerbound -2.399643
[ Info: iteration 18, lowerbound -2.366401
[ Info: iteration 19, lowerbound -2.337621
[ Info: iteration 20, lowerbound -2.316361
[ Info: iteration 21, lowerbound -2.307515
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302973
[ Info: iteration 23, lowerbound -2.299261
[ Info: iteration 24, lowerbound -2.299257
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan  9 03:19:57 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan  9 03:20:05 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Jan  9 03:20:08 2020: EM with 272 data points 0 iterations avll -2.090528
5.8 data points per parameter
, Thu Jan  9 03:20:10 2020: GMM converted to Variational GMM
, Thu Jan  9 03:20:19 2020: iteration 1, lowerbound -3.838808
, Thu Jan  9 03:20:19 2020: iteration 2, lowerbound -3.721015
, Thu Jan  9 03:20:19 2020: iteration 3, lowerbound -3.601938
, Thu Jan  9 03:20:19 2020: iteration 4, lowerbound -3.469581
, Thu Jan  9 03:20:19 2020: iteration 5, lowerbound -3.331668
, Thu Jan  9 03:20:19 2020: iteration 6, lowerbound -3.198048
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 7
, Thu Jan  9 03:20:20 2020: iteration 7, lowerbound -3.067649
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 6
, Thu Jan  9 03:20:20 2020: iteration 8, lowerbound -2.946158
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 5
, Thu Jan  9 03:20:20 2020: iteration 9, lowerbound -2.839758
, Thu Jan  9 03:20:20 2020: iteration 10, lowerbound -2.753142
, Thu Jan  9 03:20:20 2020: iteration 11, lowerbound -2.691920
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 4
, Thu Jan  9 03:20:20 2020: iteration 12, lowerbound -2.639237
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 3
, Thu Jan  9 03:20:20 2020: iteration 13, lowerbound -2.582743
, Thu Jan  9 03:20:20 2020: iteration 14, lowerbound -2.528658
, Thu Jan  9 03:20:20 2020: iteration 15, lowerbound -2.480611
, Thu Jan  9 03:20:20 2020: iteration 16, lowerbound -2.437432
, Thu Jan  9 03:20:20 2020: iteration 17, lowerbound -2.399643
, Thu Jan  9 03:20:20 2020: iteration 18, lowerbound -2.366401
, Thu Jan  9 03:20:20 2020: iteration 19, lowerbound -2.337621
, Thu Jan  9 03:20:20 2020: iteration 20, lowerbound -2.316361
, Thu Jan  9 03:20:20 2020: iteration 21, lowerbound -2.307515
, Thu Jan  9 03:20:20 2020: dropping number of Gaussions to 2
, Thu Jan  9 03:20:20 2020: iteration 22, lowerbound -2.302973
, Thu Jan  9 03:20:20 2020: iteration 23, lowerbound -2.299261
, Thu Jan  9 03:20:20 2020: iteration 24, lowerbound -2.299257
, Thu Jan  9 03:20:20 2020: iteration 25, lowerbound -2.299255
, Thu Jan  9 03:20:20 2020: iteration 26, lowerbound -2.299254
, Thu Jan  9 03:20:20 2020: iteration 27, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 28, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 29, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 30, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 31, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 32, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 33, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 34, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 35, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 36, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 37, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 38, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 39, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 40, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 41, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 42, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 43, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 44, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 45, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 46, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 47, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 48, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 49, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: iteration 50, lowerbound -2.299253
, Thu Jan  9 03:20:20 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398307, 178.04509222601686]
β = [95.95490777398307, 178.04509222601686]
m = [2.0002292577753455 53.85198717246117; 4.250300733269888 79.2868669443615]
ν = [97.95490777398307, 180.04509222601686]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948855 -0.008953123827346603; 0.0 0.012748664777409728], [0.18404155547484466 -0.007644049042327573; 0.0 0.008581705166333132]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0136653933400543
avll from llpg:  -1.013665393340088
avll direct:     -1.013665393340088
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.008425850554787
avll from llpg:  -1.008425850554787
avll direct:     -1.008425850554787
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0653388   -0.0855303    -0.0627372   -0.187782    -0.0437068    0.106115     -0.0918323   -0.105571     0.061852     0.0525985     0.000944377  -0.116014    -0.0238658    0.0525339    0.164025      0.1921      -0.0925516  -0.119642     0.0891531   0.0124258    0.00556796  -0.0478931    0.0582749     0.0299189   -0.0801678   -0.168904
 -0.0504845   -0.0901866     0.0542214   -0.00488932   0.00253183  -0.0475801     0.15513     -0.0531886   -0.0421769   -0.0345543    -0.0266001    -0.228551     0.158177     0.108898    -0.0242293     0.0644488   -0.0593163  -0.0242872    0.153923    0.00115965  -0.0636483   -0.0442126    0.0836655     0.0484882    0.0905641    0.163813
 -0.0693675    0.000209218  -0.223831     0.0254152   -0.0403289   -0.0701889    -0.150528    -0.0498993   -0.163359     0.0519091    -0.0942138    -0.0288932    0.116092     0.0069972    0.0267434     0.250585     0.115754    0.158901     0.028875   -0.0934527   -0.0849027   -0.262984    -0.153663      0.0940089    0.173321    -0.0972262
  0.0601545   -0.0493942    -0.0341785   -0.0126025    0.174667     0.123582      0.0232894    0.0480403    0.137405     0.000236409   0.160233     -0.0472564    0.0184371    0.0280325    0.0867526     0.141026    -0.0636593   0.201082    -0.164558    0.221547     0.0719712   -0.0327601   -0.0629274    -0.0699744    0.0988129    0.23751
  0.123315    -0.0561188    -0.0306029    0.0574136   -0.105667    -0.000807406  -0.0372742    0.196775     0.062859    -0.136445     -0.0656407    -0.0556638   -0.0799646   -0.193607    -0.0436958     0.0986692   -0.0529397   0.0294173   -0.025918    0.0311923    0.0810049    0.165551    -0.09636       0.0435877    0.134072    -0.0290901
 -0.0750708   -0.0207828    -0.081195     0.027069    -0.0394674    0.0444432     0.127813    -0.00658066  -0.00960958   0.105683     -0.0486917     0.0964235   -0.0135536   -0.202672     0.0227952     0.0396605    0.161668   -0.026083     0.136291    0.11464     -0.103724    -0.0681454    0.0202242     0.102263    -0.101704     0.0550247
 -0.105627     0.0129085    -0.0231603   -0.0415137   -0.0202535    0.0961212    -0.0829634    0.0134954    0.0300038    0.0919068    -0.0829468     0.124377    -0.0348832   -0.0574277    0.0206622    -0.0515668    0.135539   -0.119303     0.104845   -0.171198    -0.0376439   -0.0109685    0.0656454     0.00957074  -0.099487    -0.113052
 -0.0251435    0.161093     -0.0193371   -0.0186716    0.0731041    0.153652     -0.117397     0.0112228    0.0193651    0.0167709     0.0819488     0.0131543   -0.0412091    0.0705087   -0.0504516     0.0261602   -0.218824   -0.0292672   -0.0355041  -0.00146442  -0.155835     0.0390735   -0.113723      0.0999086    0.0229828    0.0339352
 -0.115955    -0.0917652    -0.0628727   -0.0598208    0.115728    -0.111336      0.1722       0.0676303    0.0316456   -0.0893153    -0.106891      0.0230806    0.0708654    0.0797841   -0.321911      0.116292     0.031256   -0.0803641   -0.112119    0.0959453    0.0284409    0.0356989    0.0321509     0.211615    -0.109362    -0.0746301
 -0.00665299   0.110862      0.0471655    0.148937    -0.0109917    0.1645        0.122338    -0.0244121    0.0158366    0.0889102     0.00240549    0.071562    -0.0895209   -0.218318    -0.189497      0.0392615    0.0487323   0.0558426   -0.142874    0.0367979   -0.0713364   -0.0989262    0.0681731     0.00149677  -0.0353568   -0.0232913
 -0.134186    -0.0640508     0.0169376   -0.206458     0.159452    -0.0142186     0.135172    -0.0262607    0.0541133    0.0138767     0.046829      0.0311508    0.0559084   -0.0879406   -0.0463714     0.214828    -0.0528957  -0.0569638    0.142027    0.04289      0.127861    -0.124523     0.0463368    -0.0133239   -0.030665     0.0330851
  0.0478621   -0.129155     -0.00169767  -0.024576     0.135367     0.0351284     0.00307111  -0.0714359   -0.0853376    0.113142     -0.128241      0.0695155    0.067452     0.022603     0.220522     -0.109454    -0.0128344  -0.103633    -0.0267642   0.180507    -0.0204108   -0.0657575   -0.000628781   0.0251545   -0.0105429    0.0352544
 -0.121586    -0.0661974     0.135628     0.00130687   0.102945     0.164702     -0.106044    -0.0825746   -0.0619898   -0.0922831    -0.00309513    0.0270875   -0.0344056    0.0261091   -0.190215     -0.0368207   -0.0611464  -0.108857     0.148284   -0.0261303    0.0342293   -0.0986494   -0.0413412    -0.0891242    0.0418522   -0.000889649
  0.0506285   -0.021318      0.0199159    0.0642253   -0.0932422    0.0479275     0.159855    -0.113982    -0.0371339   -0.0513123    -0.0606236     0.0740776    0.0461035   -0.0560526    0.0222064     0.160768     0.19279     0.0486367   -0.0103503   0.0164771   -0.0521954   -0.100932     0.188395      0.0197808   -0.169388    -0.21593
 -0.0885564   -0.0402279    -0.0450482    0.122694    -0.0881701    0.239769      0.00182888   0.00835913  -0.0782745    0.0329874     0.097355     -0.023706     0.0520288   -0.046788    -0.0934621    -0.0246938   -0.0248174   0.0417163   -0.0854419   0.060506    -0.0540104   -0.20139     -0.0696768     0.0421721    0.0540046    0.0670125
  0.0863492   -0.0235938    -0.144762    -0.0385566    0.103184     0.0873624    -0.140058    -0.149864     0.164479     0.143504     -0.0628038     0.0770859   -0.087676     0.0783931    0.00379789    0.0528682   -0.0112088   0.235251     0.12772    -0.0928186    0.272084    -0.0219709    0.108495     -0.043134     0.0235446   -0.143434
 -0.167457     0.227063      0.0606331    0.318013    -0.0707197   -0.0490882     0.00184225  -0.13208     -0.134584     0.0262098     0.0822618    -0.0310015   -0.135423     0.0527334    0.0190576    -0.0156131   -0.0552988   0.0686336   -0.124759   -0.197173     0.0434485   -0.0360249   -0.232871      0.0201118    0.00121274  -0.0158716
 -0.0834806    0.0285332    -0.0378449    0.0310151    0.0700372   -0.0725368     0.0949028   -0.0702707   -0.00688424   0.0218849     0.204751     -0.0261479   -0.0511549    0.041353     0.191318     -0.00557104  -0.0508212   0.0856942   -0.122313   -0.0307813    0.0403913    0.0726555   -0.0682006    -0.0122273   -0.198687    -0.125166
  0.135704    -0.0262905     0.22644     -0.150616    -0.147893     0.148295      0.040761    -0.0705096   -0.0535636   -0.157047     -0.0946011    -0.102894     0.104205    -0.0775367    0.0519137    -0.108082    -0.0518361  -0.105446     0.0460062   0.0208052    0.0262541   -0.211064     0.0210204     0.0931901   -0.0496409    0.0292723
 -0.0758233   -0.0628061    -0.0972814    0.136074     0.0401504   -0.0904665    -0.0386203   -0.0971001    0.0385602   -0.0160086    -0.117089     -0.141682     0.00810042  -0.00596682  -0.0982193    -0.0404307    0.0516412  -0.0172832    0.180712   -0.179799     0.0718783   -0.071271     0.113056      0.0597705    0.0115796    0.0061047
 -0.0211214   -0.0589787    -0.003129     0.00435116  -0.283511    -0.149284     -0.0677746    0.0185746   -0.163852     0.0909114    -0.0275002     0.181415    -0.103235    -0.0616578   -0.0466961    -0.128244    -0.0866661   0.00926169   0.0699798  -0.0489951    0.0933241   -0.00882933   0.1322       -0.0600596    0.0396794    0.0317563
  0.0127527   -0.0421189     0.0417243    0.0338671    0.00393699   0.192605      0.069993    -0.0573842    0.00938894   0.0677898    -0.0577938     0.0253374    0.0563587    0.150193    -0.0188684     0.106981     0.023312    0.0104749   -0.0830321   0.0180783    0.139208     0.115933    -0.0068712     0.0404617    0.115938    -0.0454446
  0.0532282    0.154725      0.0507539    0.0427587   -0.00547209   0.0664094     0.00102222  -0.057921     0.0104635   -0.00594934   -0.00149549    0.00101933  -0.0780044   -0.131695    -0.00423989   -0.109059     0.0848531   0.0936559    0.0833599   0.0873311    0.0576525    0.00529593  -0.13476      -0.0714833   -0.0311445   -0.0996261
  0.284384    -0.097103      0.058623    -0.11543      0.0133828   -0.0567687    -0.00433545   0.0628609   -0.201951    -0.117571     -0.0979719     0.134608    -0.116433    -0.0464406    0.0288355     0.0782507    0.0710082  -0.232545    -0.0104193  -0.0255129    0.0567984   -0.0108356    0.135199     -0.210538     0.187396     0.0712958
  0.0425963   -0.0444467     0.0496549    0.031565     0.0289508    0.0369732     0.0892701    0.0155366   -0.0619389    0.00249049   -0.0228391    -0.232439    -0.0101145   -0.0319443   -0.0793277    -0.0833439    0.0629025   0.0791815    0.154334   -0.12075     -0.0722211    0.0500365    0.135288     -0.00965489  -0.13992      0.119283
 -0.0802548    0.04585       0.0742609   -0.120425     0.0578941    0.0267601    -0.20708      0.13232      0.118796    -0.0530646    -0.0224754     0.0628823   -0.0606962   -0.187247    -0.0113978     0.0605229    0.20268     0.0821317    0.0867839   0.011402    -0.0877378    0.0575526    0.089252      0.0670163   -0.0295989    0.0370019
 -0.0369112    0.132965     -0.031467    -0.136943    -0.0293331   -0.0767547     0.0219452    0.0365176   -0.00817725   0.0315634    -0.148174     -0.008901     0.128121     0.0429556    0.0323828     0.0254359    0.0862662   0.0312099   -0.0181209   0.00458241   0.0740675   -0.156452    -0.101177     -0.11148      0.0425763    0.168608
 -0.160751    -0.0882816     0.0265246    0.00418121   0.162462    -0.0255308     0.108187     0.0048569    0.168396    -0.0995303     0.0251949    -0.00439848   0.0866096    0.11692      0.0324572    -0.070869    -0.129643    0.0385618    0.15702     0.0025917    0.0562448   -0.174379    -0.0126485    -0.0329185   -0.0359059   -0.0693591
  0.198399    -0.0589348    -0.0758712   -0.06107     -0.0920908   -0.0851332     0.0389601    0.0390722   -0.0081578   -0.0971789    -0.0571508     0.0859404   -0.0488806    0.0402125   -0.0058211    -0.0388484    0.0374081   0.328687    -0.101533   -0.10309     -0.129888     0.0785253    0.0416031     0.0449632    0.074913     0.0373826
  0.147217     0.00612916    0.106525     0.134768    -0.142212    -0.021688     -0.0283185    0.0380733   -0.139271     0.0634129     0.177695      0.0686521    0.016216    -0.16134     -0.0560733     0.0181916   -0.105045   -0.0221506    0.0286294   0.194792    -0.0873087   -0.00785422  -0.0726234    -0.0667882    0.0451723    0.00034895
  0.0310839   -0.0524448    -0.083841     0.0631355    0.0395226   -0.152093      0.140983     0.23848      0.00665703   0.008811     -0.139698      0.0243932   -0.0328326    0.0364034   -0.0299905     0.0800224   -0.0732454  -0.0361191   -0.164059   -0.162207    -0.206153     0.0586288    0.121844     -0.138184    -0.0913005    0.02297
 -0.137363     0.0516401    -0.0738106    0.0141341    0.0227394   -0.012604      0.0687356    0.0687209   -0.00995261  -0.131         0.122794      0.0145261   -0.12473     -0.0309046    0.000880591  -0.0356948    0.115268   -0.0712497   -0.0171578   0.181547    -0.174749    -0.0928265    0.0331498     0.0332026   -0.00349121  -0.0790988kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4428382980371321
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.442963
[ Info: iteration 2, average log likelihood -1.442843
[ Info: iteration 3, average log likelihood -1.441789
[ Info: iteration 4, average log likelihood -1.432384
[ Info: iteration 5, average log likelihood -1.416759
[ Info: iteration 6, average log likelihood -1.412101
[ Info: iteration 7, average log likelihood -1.410981
[ Info: iteration 8, average log likelihood -1.410182
[ Info: iteration 9, average log likelihood -1.409476
[ Info: iteration 10, average log likelihood -1.408818
[ Info: iteration 11, average log likelihood -1.408223
[ Info: iteration 12, average log likelihood -1.407769
[ Info: iteration 13, average log likelihood -1.407454
[ Info: iteration 14, average log likelihood -1.407223
[ Info: iteration 15, average log likelihood -1.406982
[ Info: iteration 16, average log likelihood -1.406687
[ Info: iteration 17, average log likelihood -1.406367
[ Info: iteration 18, average log likelihood -1.406089
[ Info: iteration 19, average log likelihood -1.405879
[ Info: iteration 20, average log likelihood -1.405732
[ Info: iteration 21, average log likelihood -1.405631
[ Info: iteration 22, average log likelihood -1.405557
[ Info: iteration 23, average log likelihood -1.405500
[ Info: iteration 24, average log likelihood -1.405455
[ Info: iteration 25, average log likelihood -1.405418
[ Info: iteration 26, average log likelihood -1.405386
[ Info: iteration 27, average log likelihood -1.405360
[ Info: iteration 28, average log likelihood -1.405336
[ Info: iteration 29, average log likelihood -1.405316
[ Info: iteration 30, average log likelihood -1.405298
[ Info: iteration 31, average log likelihood -1.405281
[ Info: iteration 32, average log likelihood -1.405267
[ Info: iteration 33, average log likelihood -1.405254
[ Info: iteration 34, average log likelihood -1.405243
[ Info: iteration 35, average log likelihood -1.405233
[ Info: iteration 36, average log likelihood -1.405224
[ Info: iteration 37, average log likelihood -1.405216
[ Info: iteration 38, average log likelihood -1.405209
[ Info: iteration 39, average log likelihood -1.405203
[ Info: iteration 40, average log likelihood -1.405197
[ Info: iteration 41, average log likelihood -1.405193
[ Info: iteration 42, average log likelihood -1.405189
[ Info: iteration 43, average log likelihood -1.405185
[ Info: iteration 44, average log likelihood -1.405182
[ Info: iteration 45, average log likelihood -1.405179
[ Info: iteration 46, average log likelihood -1.405177
[ Info: iteration 47, average log likelihood -1.405175
[ Info: iteration 48, average log likelihood -1.405173
[ Info: iteration 49, average log likelihood -1.405171
[ Info: iteration 50, average log likelihood -1.405170
┌ Info: EM with 100000 data points 50 iterations avll -1.405170
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4429634222862346
│     -1.4428427834968736
│      ⋮
└     -1.405169910590986
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405338
[ Info: iteration 2, average log likelihood -1.405180
[ Info: iteration 3, average log likelihood -1.404588
[ Info: iteration 4, average log likelihood -1.398949
[ Info: iteration 5, average log likelihood -1.382937
[ Info: iteration 6, average log likelihood -1.372933
[ Info: iteration 7, average log likelihood -1.368931
[ Info: iteration 8, average log likelihood -1.366413
[ Info: iteration 9, average log likelihood -1.364707
[ Info: iteration 10, average log likelihood -1.363532
[ Info: iteration 11, average log likelihood -1.362718
[ Info: iteration 12, average log likelihood -1.362186
[ Info: iteration 13, average log likelihood -1.361837
[ Info: iteration 14, average log likelihood -1.361588
[ Info: iteration 15, average log likelihood -1.361379
[ Info: iteration 16, average log likelihood -1.361166
[ Info: iteration 17, average log likelihood -1.360930
[ Info: iteration 18, average log likelihood -1.360678
[ Info: iteration 19, average log likelihood -1.360432
[ Info: iteration 20, average log likelihood -1.360216
[ Info: iteration 21, average log likelihood -1.360051
[ Info: iteration 22, average log likelihood -1.359943
[ Info: iteration 23, average log likelihood -1.359882
[ Info: iteration 24, average log likelihood -1.359848
[ Info: iteration 25, average log likelihood -1.359830
[ Info: iteration 26, average log likelihood -1.359819
[ Info: iteration 27, average log likelihood -1.359812
[ Info: iteration 28, average log likelihood -1.359808
[ Info: iteration 29, average log likelihood -1.359804
[ Info: iteration 30, average log likelihood -1.359801
[ Info: iteration 31, average log likelihood -1.359799
[ Info: iteration 32, average log likelihood -1.359797
[ Info: iteration 33, average log likelihood -1.359796
[ Info: iteration 34, average log likelihood -1.359794
[ Info: iteration 35, average log likelihood -1.359793
[ Info: iteration 36, average log likelihood -1.359792
[ Info: iteration 37, average log likelihood -1.359791
[ Info: iteration 38, average log likelihood -1.359791
[ Info: iteration 39, average log likelihood -1.359790
[ Info: iteration 40, average log likelihood -1.359789
[ Info: iteration 41, average log likelihood -1.359789
[ Info: iteration 42, average log likelihood -1.359788
[ Info: iteration 43, average log likelihood -1.359788
[ Info: iteration 44, average log likelihood -1.359787
[ Info: iteration 45, average log likelihood -1.359787
[ Info: iteration 46, average log likelihood -1.359786
[ Info: iteration 47, average log likelihood -1.359786
[ Info: iteration 48, average log likelihood -1.359786
[ Info: iteration 49, average log likelihood -1.359785
[ Info: iteration 50, average log likelihood -1.359785
┌ Info: EM with 100000 data points 50 iterations avll -1.359785
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4053379152222787
│     -1.405180496331301
│      ⋮
└     -1.3597852414180194
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.360047
[ Info: iteration 2, average log likelihood -1.359796
[ Info: iteration 3, average log likelihood -1.358858
[ Info: iteration 4, average log likelihood -1.349978
[ Info: iteration 5, average log likelihood -1.327439
[ Info: iteration 6, average log likelihood -1.313068
[ Info: iteration 7, average log likelihood -1.307334
[ Info: iteration 8, average log likelihood -1.303778
[ Info: iteration 9, average log likelihood -1.300740
[ Info: iteration 10, average log likelihood -1.297580
[ Info: iteration 11, average log likelihood -1.294271
[ Info: iteration 12, average log likelihood -1.291929
[ Info: iteration 13, average log likelihood -1.291035
[ Info: iteration 14, average log likelihood -1.290662
[ Info: iteration 15, average log likelihood -1.290448
[ Info: iteration 16, average log likelihood -1.290310
[ Info: iteration 17, average log likelihood -1.290207
[ Info: iteration 18, average log likelihood -1.290118
[ Info: iteration 19, average log likelihood -1.290032
[ Info: iteration 20, average log likelihood -1.289948
[ Info: iteration 21, average log likelihood -1.289863
[ Info: iteration 22, average log likelihood -1.289777
[ Info: iteration 23, average log likelihood -1.289691
[ Info: iteration 24, average log likelihood -1.289603
[ Info: iteration 25, average log likelihood -1.289516
[ Info: iteration 26, average log likelihood -1.289440
[ Info: iteration 27, average log likelihood -1.289386
[ Info: iteration 28, average log likelihood -1.289353
[ Info: iteration 29, average log likelihood -1.289335
[ Info: iteration 30, average log likelihood -1.289326
[ Info: iteration 31, average log likelihood -1.289322
[ Info: iteration 32, average log likelihood -1.289319
[ Info: iteration 33, average log likelihood -1.289318
[ Info: iteration 34, average log likelihood -1.289317
[ Info: iteration 35, average log likelihood -1.289317
[ Info: iteration 36, average log likelihood -1.289316
[ Info: iteration 37, average log likelihood -1.289316
[ Info: iteration 38, average log likelihood -1.289316
[ Info: iteration 39, average log likelihood -1.289316
[ Info: iteration 40, average log likelihood -1.289316
[ Info: iteration 41, average log likelihood -1.289316
[ Info: iteration 42, average log likelihood -1.289316
[ Info: iteration 43, average log likelihood -1.289316
[ Info: iteration 44, average log likelihood -1.289316
[ Info: iteration 45, average log likelihood -1.289316
[ Info: iteration 46, average log likelihood -1.289316
[ Info: iteration 47, average log likelihood -1.289316
[ Info: iteration 48, average log likelihood -1.289316
[ Info: iteration 49, average log likelihood -1.289316
[ Info: iteration 50, average log likelihood -1.289316
┌ Info: EM with 100000 data points 50 iterations avll -1.289316
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.360047495255997
│     -1.3597956469869699
│      ⋮
└     -1.2893155606299243
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.289608
[ Info: iteration 2, average log likelihood -1.289280
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.287333
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.271311
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.236841
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.228599
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.218527
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.227896
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.215176
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.213203
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.222296
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.228729
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.216192
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.214952
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.229609
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.222585
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.214351
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.222566
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.207013
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.224178
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.220793
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.215312
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.203743
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.209747
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.214693
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.211054
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.211878
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.205335
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.211555
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.218208
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.204277
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.202133
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.218727
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.210657
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.209718
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.203338
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.218175
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.210528
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.209502
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.203210
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.218129
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.210515
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.209449
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.203138
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.218126
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.210509
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.209427
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.203103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.218127
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.210506
┌ Info: EM with 100000 data points 50 iterations avll -1.210506
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.289607886853487
│     -1.2892798213036598
│      ⋮
└     -1.2105061145500273
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.209842
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.198579
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.206887
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.172958
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.138426
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.111280
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099132
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.103647
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.104230
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.096757
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.098319
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.088776
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.108479
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.105196
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.093062
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.097091
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.111321
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.096878
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.098527
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.100030
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.103020
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.091442
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.106689
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.094431
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│      ⋮
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.100177
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.110320
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.096156
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.088219
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.105732
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.104985
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.093172
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.096035
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.110939
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.097341
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.098286
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.087934
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.107320
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.101595
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.083911
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085135
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.100569
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.085357
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.086628
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      7
│     13
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.088063
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.091834
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.090767
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.090013
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.078779
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.097219
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.094210
┌ Info: EM with 100000 data points 50 iterations avll -1.094210
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2098424884555292
│     -1.198578989506454
│      ⋮
└     -1.0942100164923205
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4428382980371321
│     -1.4429634222862346
│     -1.4428427834968736
│     -1.4417892638770657
│      ⋮
│     -1.078779284965829
│     -1.0972192354642665
└     -1.0942100164923205
32×26 Array{Float64,2}:
 -0.167085   -0.130148     0.0353812   -0.268799     0.213659    -0.0198779     0.145083    -0.0159575    0.0577014    0.0733375     0.0236158     0.0507968   0.060562    -0.0973248   -0.0483286    0.228302     -0.0501246  -0.0362994    0.146893     0.0599779    0.182121    -0.170214     0.0548938   -0.0065759    -0.0428805    0.0453323
  0.147119   -0.0597566    0.204039    -0.133525    -0.207729     0.133852      0.0320782   -0.0866502   -0.0654677   -0.158999     -0.0670293    -0.109496    0.112884    -0.0744828    0.100583    -0.109869     -0.0647453  -0.108446     0.0393849    0.0166151    0.00489089  -0.226544     0.0192487    0.0690399    -0.0716173    0.0290058
 -0.0778571   0.0591185    0.0735427   -0.105805     0.0757843    0.0236516    -1.43252      0.132357     0.130083    -0.0244888    -0.00753323    0.0859599  -0.0494542   -0.0954235   -0.00627539   0.0621403     0.131307    0.0819019    0.0953499    0.0216173   -0.0838811   -0.0349733    0.0897599    0.050392      0.0184392    0.0380122
 -0.0511172   0.0928511    0.0765354   -0.141119     0.0427532    0.0248312     0.809581     0.132322     0.122425    -0.0805513    -0.026769      0.0627717  -0.0600398   -0.288068    -0.0267762    0.0600196     0.247534    0.0817304    0.0666142    0.00269945  -0.134078     0.0617852    0.0882197    0.0804463    -0.0495068    0.0373364
 -0.0965292   0.0118799   -0.0456586    0.0845802   -0.00677047   0.0626851     0.0419007   -0.0463253   -0.0571918    0.0196057     0.155418     -0.022176   -0.0102448    0.00322438   0.0602222   -0.00168158   -0.0424562   0.0717402   -0.106439    -0.0128176    0.00105586  -0.0410334   -0.0775979    0.00267193   -0.0893395   -0.0301567
 -0.0576334  -0.0982624   -0.0826238    0.155058     0.0413845   -0.070749     -0.0153848   -0.0879626    0.0381506   -0.0271686    -0.103907     -0.115648    0.00704543  -0.00728247  -0.0878883   -0.0385582     0.0532189  -0.018413     0.162876    -0.0512868    0.0821159   -0.094041     0.0767134    0.0724337     0.0220602    0.0182509
  0.0350464  -0.0534711   -0.0599517    0.0742728    0.0162726   -0.111515      0.138162     0.190687     0.0631485   -0.0188257    -0.107847      0.0300309   0.00371013   0.0231131   -0.0243378    0.0974971    -0.0584543  -0.02672     -0.142745    -0.122796    -0.192735     0.0298783    0.148708    -0.138625     -0.101557    -0.00233677
  0.142774   -0.0397392   -0.00345429   3.04016e-5  -0.079767    -0.0084359     0.0822219   -0.0367746   -0.0113124   -0.0605609    -0.050732      0.116698    0.00269924   0.00661202   0.00435928   0.0338514     0.101018    0.197189    -0.0608695   -0.0106449   -0.0850035   -0.0230874    0.0555823    0.0785003    -0.0330226   -0.0804703
 -0.136547    0.0493333   -0.0770919   -0.0136844    0.0178028   -0.024643      0.0640582    0.0753274   -0.00658051  -0.130787      0.145419      0.0173949  -0.137141    -0.0342204    0.0477522   -0.0354424     0.108736   -0.0686673   -0.0187318    0.179822    -0.199946    -0.0817928    0.0352713    0.055465     -0.0093367   -0.0886364
 -0.0657625   0.00757036   0.0631499   -0.0323178    0.0889099    0.177478     -0.133783    -0.0435966   -0.0166457   -0.0546153     0.047026      0.0141522  -0.0307069    0.0366302   -0.139999    -0.0199832    -0.134947   -0.0789529    0.0578246   -0.0143227   -0.0804373   -0.0318954   -0.0771633    0.00639235    0.0346711    0.0299819
  0.0559152  -0.149866    -0.00350339  -0.0276065    0.13883      0.0783486    -0.00679075  -0.0746827   -0.060437     0.0997738    -0.134053      0.0680903   0.0645497    0.00122056   0.202437    -0.125954     -0.0150313  -0.140967    -0.0213314    0.189878    -0.00711016  -0.0795609   -0.00432477   0.0856223     0.00306832   0.0294072
 -0.044417    0.0224202   -0.00572824   0.00838215  -0.0326818    0.136522      0.0229831   -0.0627041    0.0378413    0.0799237     0.000954888  -0.0162322  -0.0619989   -0.0990969   -0.0174183    0.102524     -0.0108485  -0.0307928   -0.0189339    0.0290671   -0.0410364   -0.0733372    0.0672932    0.0331793    -0.0552341   -0.0813754
 -0.114803   -0.43093     -0.0638418   -0.309261     0.193128    -0.112559      0.184897     0.0866783    0.030345    -0.0490446    -0.155902      0.0245383   0.0978068    0.0573153   -0.262134     0.122438      0.0526988  -0.0482771   -0.0929532    0.141389     0.088183     0.0143439    0.0118859    0.211077     -0.0366649   -0.368248
 -0.110453    0.301708    -0.0598534    0.224076     0.0436402   -0.109373      0.167406     0.0391413    0.0298999   -0.122208     -0.0637961     0.0170122   0.0150443    0.086976    -0.33857      0.12985       0.0103297  -0.109717    -0.119463     0.0815711   -0.0436951    0.0389724    0.0351173    0.211085     -0.180285     0.194191
 -0.0907356  -0.00176455  -0.0232388   -0.0399912   -0.0257387   -0.395317     -0.0832967    0.0140591   -0.0277358    0.0920313    -0.134508      0.607995   -0.0333446   -0.0272423    0.0329354    0.254753      0.13151    -0.121413     0.109744    -0.173587    -0.0381652   -0.0108428    0.0383702    0.0105701    -0.157678    -0.112833
 -0.123686    0.0169407   -0.0233711   -0.0428361   -0.0192666    0.600005     -0.0897319    0.0138633    0.0757451    0.0921988    -0.0573594    -0.366312   -0.0471595   -0.0956721    0.0248214   -0.382114      0.118286   -0.119845     0.112137    -0.178865    -0.0408692   -0.0115276    0.069642     0.00448423   -0.0762711   -0.113046
 -1.18956    -0.0707298    0.0295427   -0.00807033   0.157827     0.0887469     0.106489     0.00577599  -0.00196161  -0.120765      0.141802     -0.0195258   0.187967     0.107664     0.010852    -0.0619708    -0.128243    0.0369037    0.162115     0.146062     0.0440836   -0.141025    -0.0143458    0.000658086  -0.0252066   -0.110981
  1.00212    -0.13173      0.0236999   -0.0524422    0.194333    -0.0726807     0.105695     0.0067442    0.307814    -0.0766888    -0.069321      0.0233285   0.0178263    0.134374     0.0521221   -0.0463622    -0.129111    0.0291103    0.153127    -0.0339788    0.0371821   -0.202204    -0.0143511   -0.0571707    -0.0309419   -0.0739084
 -0.0248582   0.138664    -0.02468     -0.134346    -0.0176921   -0.0994578     0.0858307    0.0321112   -0.00852282   0.0320268    -0.265608      0.0290927   0.127327     0.0188194    0.0247258    0.0128027     0.0623058   0.0475862   -0.0745964   -0.00162172   0.069766    -0.169013    -0.0963761   -0.167781      0.0385239    0.163579
 -0.0620336  -0.0509468   -0.0782362    0.013939    -0.0202124   -0.0530661    -0.00895585  -0.0443759   -0.104648     0.0371355    -0.0596822    -0.114047    0.142184     0.0491665    0.027874     0.164971      0.0302569   0.0712851    0.0930577   -0.0484117   -0.0737811   -0.147039    -0.0330602    0.0667969     0.120569     0.024587
  0.0449918  -0.071931    -0.0403837   -0.0104865    0.173683     0.136333      0.00701535   0.0482546    0.138597    -0.0324466     0.19072      -0.0372227   0.0454776    0.00870784   0.120748     0.134796     -0.0772495   0.199327    -0.151627     0.215707     0.0693102   -0.0241184   -0.0745268   -0.0710088     0.104773     0.240326
  0.0606752  -0.0590861    0.0184952    0.0334601    0.0104689    0.183291      0.0626728   -0.0486999    0.00413063   0.0503684    -0.0592165     0.0085244   0.063735     0.161368     0.00858448   0.0991394     0.0235835   0.0110685   -0.119463     0.0400797    0.0774681    0.245295    -0.0712551    0.00719738    0.124356    -0.0314998
 -0.167931    0.21898      0.075049     0.326347    -0.0553171   -0.0554014     0.00800206  -0.139871    -0.157373     0.0532094     0.0920014    -0.0323903  -0.121602     0.0520707    0.0279913   -0.000443744  -0.0631588   0.0652464   -0.0753169   -0.181105     0.0547418   -0.049158    -0.239737     0.00667884    0.0104018   -0.0475093
  0.0488081   0.163873     0.0355311    0.0159345   -0.00878154   0.067337     -0.0216268   -0.0568053    0.0202598   -0.000670767   0.00741728    0.0163767  -0.0829066   -0.119714     0.0111066   -0.110684      0.0823352   0.0819812    0.11344      0.0489145    0.0432529    0.00761884  -0.107078    -0.0433257    -0.030872    -0.105544
 -0.0207824  -0.0583261   -0.00840096   0.00160465  -0.298897    -0.165331     -0.0670845    0.0191037   -0.166255     0.0927475    -0.0268157     0.184101   -0.105124    -0.08797     -0.057806    -0.132581     -0.0805516   0.00835296   0.0580253   -0.00231917   0.0928065   -0.101537     0.12906     -0.0600243     0.0375546    0.034298
  0.274607   -0.0972396    0.0774473   -0.131365     0.00471447  -0.0597227    -0.00250423   0.0604185   -0.17106     -0.113269     -0.081058      0.171048   -0.113535    -0.0323049    0.0234099    0.0809587     0.0407631  -0.231322    -0.00832524  -0.0286351    0.076147    -0.00760614   0.137223    -0.211401      0.185863     0.0696156
 -0.0706518  -0.020691    -0.0812182    0.0398065   -0.0457094    0.0329999     0.132201    -0.00390698  -0.131327     0.114517     -0.0280206     0.0929561   0.0449371   -0.204061     0.00522104   0.0453183     0.183912    1.54455      0.168477     0.132965    -0.101285    -0.0715165   -0.10705      0.0603144    -0.0939734    0.0498255
 -0.0749718  -0.0207079   -0.0866053    0.0325241   -0.0381029    0.0343791     0.118152    -0.00236997   0.0253537    0.111714     -0.0298577     0.127828   -0.0552951   -0.198243     0.0431674   -0.0487523     0.149073   -1.3054       0.147714     0.0342409   -0.110568    -0.0701715    0.101527     0.0511156    -0.0957385    0.0836275
  0.143885    0.00965303   0.105946     0.116177    -0.157835    -0.0208637    -0.0360199    0.0279027   -0.105351     0.0700412     0.155107      0.0818569  -0.0165003   -0.14915     -0.071381     0.0189451    -0.100897   -0.0407019    0.00748501   0.202232    -0.0808307   -0.00226596  -0.0837465   -0.0657265     0.0479115    0.000843152
  0.0655146  -0.0253177   -0.142477    -0.0443052    0.106595     0.0934352    -0.123061    -0.0959883    0.152474     0.159938     -0.0563833     0.0743922  -0.0846106    0.11344      0.00606879   0.0519941    -0.0298209   0.22983      0.130257    -0.104861     0.290995    -0.0245553    0.10861      0.0236992     0.0508821   -0.177189
  0.12572    -0.0630975   -0.0412133    0.0596719   -0.113387    -0.000723228  -0.0207123    0.211859     0.0512765   -0.137985     -0.125779     -0.057048   -0.0695822   -0.191115    -0.0396933    0.077064     -0.0506618   0.0222778   -0.0259965   -0.0770676    0.0679369    0.152256    -0.0948158    0.044541      0.124479    -0.0342492
  0.0874978  -0.0477917    0.0487044    0.0313463    0.0252331    0.0332982     0.0887168    0.0165862   -0.0493925    0.0429004    -0.0377916    -0.237225   -0.0207417   -0.0311855   -0.0984778   -0.0819897     0.0108546   0.0674862    0.156113    -0.114552    -0.0689481    0.0448302    0.12955     -0.00164702   -0.140797     0.16949[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.081032
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.059908
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.080733
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.064335
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.076219
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.064767
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.080945
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059152
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.080327
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062750
┌ Info: EM with 100000 data points 10 iterations avll -1.062750
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.294432e+05
      1       7.124172e+05      -2.170259e+05 |       32
      2       6.831739e+05      -2.924325e+04 |       32
      3       6.668009e+05      -1.637304e+04 |       32
      4       6.578266e+05      -8.974285e+03 |       32
      5       6.530183e+05      -4.808287e+03 |       32
      6       6.496090e+05      -3.409372e+03 |       32
      7       6.467891e+05      -2.819896e+03 |       32
      8       6.437591e+05      -3.029975e+03 |       32
      9       6.410178e+05      -2.741330e+03 |       32
     10       6.392938e+05      -1.723994e+03 |       32
     11       6.385087e+05      -7.850396e+02 |       32
     12       6.380908e+05      -4.179776e+02 |       32
     13       6.377821e+05      -3.087017e+02 |       32
     14       6.375037e+05      -2.783844e+02 |       32
     15       6.372157e+05      -2.880080e+02 |       32
     16       6.369481e+05      -2.676062e+02 |       32
     17       6.367357e+05      -2.123165e+02 |       32
     18       6.365628e+05      -1.729514e+02 |       32
     19       6.364658e+05      -9.695718e+01 |       32
     20       6.364010e+05      -6.484550e+01 |       32
     21       6.363563e+05      -4.467098e+01 |       31
     22       6.363203e+05      -3.601418e+01 |       31
     23       6.362915e+05      -2.883685e+01 |       32
     24       6.362643e+05      -2.714136e+01 |       32
     25       6.362385e+05      -2.578094e+01 |       31
     26       6.362061e+05      -3.240750e+01 |       31
     27       6.361636e+05      -4.258052e+01 |       32
     28       6.361199e+05      -4.362301e+01 |       31
     29       6.360728e+05      -4.711692e+01 |       31
     30       6.360160e+05      -5.684292e+01 |       32
     31       6.359370e+05      -7.900497e+01 |       32
     32       6.358386e+05      -9.831872e+01 |       32
     33       6.357119e+05      -1.267677e+02 |       32
     34       6.355729e+05      -1.389884e+02 |       32
     35       6.354225e+05      -1.503504e+02 |       32
     36       6.352874e+05      -1.350902e+02 |       32
     37       6.351775e+05      -1.099635e+02 |       32
     38       6.350785e+05      -9.898143e+01 |       32
     39       6.350148e+05      -6.371721e+01 |       30
     40       6.349659e+05      -4.886561e+01 |       32
     41       6.349258e+05      -4.009792e+01 |       32
     42       6.348950e+05      -3.078035e+01 |       32
     43       6.348697e+05      -2.531557e+01 |       32
     44       6.348520e+05      -1.774589e+01 |       30
     45       6.348359e+05      -1.607197e+01 |       28
     46       6.348176e+05      -1.827523e+01 |       31
     47       6.348011e+05      -1.658149e+01 |       30
     48       6.347878e+05      -1.324557e+01 |       30
     49       6.347711e+05      -1.665582e+01 |       29
     50       6.347543e+05      -1.682680e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 634754.3230349636)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.349813
[ Info: iteration 2, average log likelihood -1.324573
[ Info: iteration 3, average log likelihood -1.303750
[ Info: iteration 4, average log likelihood -1.279860
[ Info: iteration 5, average log likelihood -1.246381
[ Info: iteration 6, average log likelihood -1.203489
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.144612
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      6
│     15
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.109771
[ Info: iteration 9, average log likelihood -1.152293
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.105028
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.125416
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.092812
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.121913
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.118540
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     21
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.101534
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.139692
[ Info: iteration 17, average log likelihood -1.133480
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     15
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.095799
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.109124
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      6
│     19
│     21
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.088348
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.133719
[ Info: iteration 22, average log likelihood -1.121641
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     15
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075665
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.111523
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.130141
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.117369
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     13
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.081960
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.109670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.096523
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.108730
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     13
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.080484
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.111242
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.075395
[ Info: iteration 34, average log likelihood -1.113980
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     13
│     16
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.075588
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.114958
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.078125
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.103503
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.096224
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.075535
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.116314
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.079716
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.089499
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     19
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.115061
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.077954
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     13
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.076443
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.124076
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086370
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     15
│     16
│     23
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.065938
┌ Info: EM with 100000 data points 50 iterations avll -1.065938
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0891698  -0.0482997    0.0499743    0.0312287     0.0257729    0.0334487    0.0881975    0.0173054    -0.0544581    0.041636     -0.0379019   -0.237219    -0.0206601   -0.0324771   -0.10039      -0.0799897    0.011374    0.0655478    0.154836    -0.114555    -0.0679322    0.0432659    0.13015     -0.00344008   -0.139165     0.170175
 -0.182243    0.233402     0.074785     0.372771     -0.052221    -0.0577681    0.00298553  -0.146366     -0.186981     0.0482558     0.103283    -0.0332543   -0.146327     0.0545562    0.0268462    -0.00127559  -0.057604    0.0754254   -0.0871703   -0.189024     0.0593132   -0.0478063   -0.254357     0.00261637    0.0168374   -0.0509825
  0.161479   -0.0659215    0.210799    -0.146656     -0.284081     0.180432     0.0426719   -0.132751     -0.0600515   -0.153408     -0.0759527   -0.141799     0.111986    -0.0762784    0.134645     -0.0954134   -0.0739898  -0.131296     0.0497491    0.012861     0.00129112  -0.228325     0.00686639   0.0603851    -0.107236     0.0265815
 -0.0742434  -0.0207297   -0.083761     0.036495     -0.042251     0.0332982    0.12435     -0.00305057   -0.0504871    0.114845     -0.0297386    0.113048    -0.0113878   -0.202811     0.0249928    -0.00582192   0.16561    -0.00968003   0.157491     0.0780876   -0.106752    -0.0709541    0.00375973   0.0587544    -0.0968881    0.0710679
  0.0694981  -0.0251247   -0.141762    -0.0463155     0.108089     0.094179    -0.127528    -0.10105       0.153142     0.161974     -0.0555376    0.0746582   -0.084827     0.113241     0.00486772    0.0520978   -0.0305886   0.234043     0.131115    -0.103248     0.291781    -0.0228538    0.113922     0.0234493     0.0508747   -0.176719
 -0.106164    0.00589995  -0.0230835   -0.0407342    -0.0220157    0.0996848   -0.0857687    0.0139049     0.0259075    0.0913243    -0.0935036    0.127261    -0.0394094   -0.0613657    0.0278376    -0.062327     0.12451    -0.120312     0.110896    -0.174925    -0.0379455   -0.010606     0.0544171    0.00720642   -0.114976    -0.113747
  0.196274   -0.061339    -0.0692073   -0.0733996    -0.0515166   -0.0656902    0.0334498    0.0182349    -0.00191768  -0.0546473    -0.0559684    0.0932406   -0.0662677    0.0565783   -0.00426069   -0.0306633    0.0339383   0.27851     -0.0853418   -0.0232192   -0.124433     0.0411809    0.0369058    0.0921876     0.0712775    0.0315007
  0.128228   -0.0620682   -0.041061     0.0593134    -0.114087    -0.00118225  -0.0210415    0.209953      0.0502622   -0.137924     -0.1248      -0.058677    -0.0699701   -0.191153    -0.039288      0.0765396   -0.0499338   0.0222512   -0.0259086   -0.0787936    0.0673396    0.152907    -0.0946587    0.0439143     0.124779    -0.03592
 -0.104834   -0.0710002    0.140839    -0.00911475    0.11154      0.214481    -0.121353    -0.0952325    -0.0526887   -0.112172     -0.0129325    0.0269862   -0.0215092    0.0239879   -0.223045     -0.0804468   -0.053506   -0.116926     0.149443    -0.017512     0.00373727  -0.101376    -0.0396449   -0.0922843     0.0422612   -0.00364547
 -0.137782    0.0465216   -0.0782024   -0.00884933    0.0174173   -0.0278974    0.0639591    0.076826     -0.00659848  -0.131066      0.149149     0.0184003   -0.137642    -0.0339884    0.0513541    -0.0330316    0.110236   -0.0676855   -0.0171196    0.179975    -0.208786    -0.079696     0.0348662    0.0554188    -0.00329128  -0.0899364
  0.143516    0.00857611   0.105151     0.110303     -0.155817    -0.020037    -0.0467411    0.0304726    -0.098646     0.0651741     0.148852     0.0792511   -0.0184159   -0.149967    -0.071885      0.0197612   -0.0961255  -0.0373236    0.00887271   0.19643     -0.0819406   -0.00527173  -0.0792112   -0.0650906     0.0479529    0.00175905
 -0.0849764  -0.099041     0.0268509   -0.0334789     0.179003     0.00477075   0.106032     0.00639986    0.155883    -0.0988356     0.0362854    7.88613e-5   0.103793     0.121046     0.0317766    -0.054303    -0.128608    0.0326305    0.157928     0.0553522    0.0416844   -0.171624    -0.0139128   -0.0270905    -0.0289463   -0.0917803
  0.0436929  -0.0569697    0.023633     0.0338909     0.00981837   0.180965     0.0655016   -0.0494599     0.00184675   0.0453009    -0.0648345    0.0174735    0.0570092    0.15634     -0.000919566   0.0988038    0.0244797   0.0129362   -0.110279     0.040383     0.0826679    0.2272      -0.0690312    0.019769      0.126677    -0.0451384
 -0.0568444  -0.0931392    0.0582377    0.00809467    0.00527111  -0.038288     0.16279     -0.0524458    -0.0478221   -0.0107807    -0.0280942   -0.216242     0.165509     0.099745     0.0474259     0.0574007   -0.0592682  -0.0228311    0.163457     0.00121547  -0.0592405   -0.0360088    0.0824002    0.0285498     0.0926174    0.148994
 -0.112615   -0.0714664   -0.0617843   -0.0501126     0.120285    -0.111634     0.173867     0.0635277     0.0307762   -0.0834217    -0.110006     0.0226065    0.0574772    0.0696181   -0.296973      0.125109     0.0338037  -0.0780714   -0.104597     0.109841     0.0244757    0.0260782    0.0227321    0.211118     -0.106822    -0.0942833
 -0.0845154   0.025855    -0.0296823    0.0403318     0.0592368   -0.0862706    0.095241    -0.0830505    -0.0425887    0.021383      0.202397    -0.0127972   -0.0583577    0.0426566    0.184943      0.00381134  -0.0495691   0.0892852   -0.118885    -0.0275252    0.043633     0.0927152   -0.0724592   -0.0216671    -0.21605     -0.110485
 -0.0207234  -0.0583926   -0.00924399   0.000724327  -0.297575    -0.164754    -0.0669608    0.0192482    -0.168209     0.0924874    -0.0273082    0.18397     -0.104926    -0.0879967   -0.0576182    -0.13286     -0.0796412   0.00727295   0.0581497   -0.00350997   0.0929297   -0.103391     0.129135    -0.0603811     0.0379104    0.0344078
 -0.0494896  -0.103605    -0.0903671    0.118169      0.0626026   -0.109836     0.0335102   -0.0854465     0.0379804   -0.0258903    -0.117118    -0.103293    -0.00563916  -0.00626759  -0.0880378    -0.0384941    0.0330467  -0.0268561    0.046086    -0.101023     0.064525    -0.111713     0.116911     0.0463777     0.00529021   0.0221115
 -0.148627   -0.12245      0.0464432   -0.275288      0.183672    -0.0125682    0.124133    -0.0121818     0.036347     0.0308945     0.0251134    0.0558712    0.0868673   -0.109668    -0.0540476     0.176475    -0.0531706  -0.0426615    0.119796     0.0313546    0.199494    -0.170583     0.0484009   -0.000181139  -0.046415     0.0424074
 -0.0660551  -0.0114206   -0.202955     0.0256749    -0.0441185   -0.0666267   -0.163878    -0.038747     -0.154384     0.0910225    -0.089566    -0.0208465    0.11622      0.00156035   0.0112483     0.268535     0.112748    0.158165     0.0275767   -0.0939721   -0.0844766   -0.257977    -0.144986     0.0929013     0.146513    -0.0875417
  0.16558    -0.0633151    0.0874271   -0.0178294    -0.0488458   -0.00350553   0.0760187   -0.023128     -0.0913851   -0.088654     -0.0700847    0.135538    -0.0216331   -0.0444125    0.0203041     0.116604     0.100156   -0.0933444   -0.00984373  -0.00450735   0.0109966   -0.0438418    0.129373    -0.102628      0.0105819   -0.0674232
  0.0595636  -0.146954    -0.00334129  -0.0278925     0.139111     0.0758072   -0.00847503  -0.0746087    -0.0618079    0.10003      -0.135165     0.067869     0.064976     0.00224834   0.205358     -0.125584    -0.0138276  -0.142076    -0.0202287    0.190645    -0.0062278   -0.0810997   -0.00210637   0.0830067     0.00235803   0.0302604
 -0.079701   -0.00866048  -0.0621016    0.130485     -0.0907571    0.232038    -0.0205245   -0.000348812  -0.0723157    0.0171621     0.0973337   -0.0272146    0.0508668   -0.0443846   -0.0931359    -0.0203199   -0.0361968   0.0428938   -0.0981614    0.0173485   -0.0462979   -0.204876    -0.0739462    0.0335276     0.0670375    0.0652927
 -0.069877   -0.0870425   -0.0750991   -0.152137     -0.0429248    0.114979    -0.107179    -0.106918      0.0782388    0.0715998    -0.00521139  -0.119208    -0.025712     0.0425127    0.184365      0.206641    -0.0887346  -0.127984     0.0925256    0.0179011   -0.00116309  -0.043189     0.0450191    0.04133      -0.0841425   -0.148163
 -0.014561    0.127153     0.0517563    0.146074     -0.0226541    0.152378     0.130571    -0.0277468     0.0122341    0.0882799     0.00346291   0.0653244   -0.090103    -0.218518    -0.194733      0.00871579   0.0552167   0.0553624   -0.126076     0.0387098   -0.0770851   -0.0994016    0.0725195    0.0180105    -0.0350951   -0.0243827
 -0.0318283   0.0938641   -0.0120679   -0.051993      0.0766474    0.139924    -0.134339     0.0203711     0.0174468    0.0122779     0.101823     0.0232396   -0.0396893    0.0533241   -0.0748973     0.0320972   -0.218655   -0.0434473   -0.0339603   -0.0112001   -0.160588     0.0433329   -0.110519     0.110104      0.0324081    0.0602838
  0.0509166  -0.068535    -0.0240166   -0.0152592     0.168868     0.140939     0.00690079   0.0396584     0.122893    -0.0418682     0.174409    -0.0331206    0.0477999    0.0151957    0.144284      0.118837    -0.0727819   0.177794    -0.132201     0.202362     0.0663705   -0.018584    -0.0739001   -0.0653685     0.0915059    0.232249
 -0.0250289   0.135325    -0.022232    -0.127935     -0.0124322   -0.0976462    0.0813647    0.0303627    -0.00860848   0.0311586    -0.265661     0.0232272    0.1293       0.0200689    0.0257979     0.0100773    0.0625395   0.0469213   -0.0745098   -0.00268764   0.0708199   -0.175974    -0.0965764   -0.165289      0.0387657    0.158601
 -0.105622   -0.104319    -0.0673594    0.25473       0.0125013   -0.0900504   -0.074168    -0.0887892     0.0388481   -0.0312467    -0.124139    -0.143498     0.0151349   -0.0111396   -0.0984319    -0.0303781    0.0915727  -0.0142482    0.381528    -0.0191386    0.126574    -0.11212      0.0365654    0.120017      0.00654919   0.011818
  0.0476667   0.161555     0.0383809    0.0183838    -0.00928253   0.0663631   -0.024615    -0.0546819     0.0212346   -0.000781365   0.00763305   0.0180923   -0.0805281   -0.121781     0.00895786   -0.11407      0.082551    0.0858866    0.11487      0.0477304    0.0424196    0.0132837   -0.106147    -0.0439832    -0.0302629   -0.1098
  0.0310106  -0.0553979   -0.0868076    0.0678073     0.0380041   -0.146229     0.140569     0.249369      0.0903491   -0.00382267   -0.121101     0.0174821    0.0055568    0.0352992   -0.0287395     0.0661791   -0.0869097  -0.0355422   -0.169807    -0.156465    -0.211404     0.0518297    0.142414    -0.141265     -0.0929401    0.022733
 -0.048373    0.0945043    0.0870519   -0.125268      0.0490956    0.0210623   -0.250418     0.124206      0.111653    -0.0654632    -0.0250904    0.0694051   -0.0512991   -0.19945     -0.010941      0.0519613    0.19318     0.0723197    0.0799869    0.0161629   -0.117184    -0.00846696   0.0789192    0.0684242    -0.019672     0.0383272[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.130187
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.084132
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     18
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.069996
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      6
│     13
│     15
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.044025
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.105834
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     18
│     19
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072128
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.060829
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     13
│     15
│     16
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.100519
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.075998
┌ Info: EM with 100000 data points 10 iterations avll -1.075998
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0351695   -0.0202822    -0.0126775  -0.0562538    -0.133989    -0.140123    -0.0925847    0.159735    -0.134148     -0.127827     0.215415    -0.163058     0.0376175   -0.0359646    0.0634385    0.0717858   -0.129949    -0.086162    -0.070795    0.170009    -0.0636483   -0.0249353     0.0838477   -0.0884865     0.112008    -0.0754103
 -0.158004     0.00878796    0.144326    0.151524     -0.182153     0.0586206    0.0167491   -0.0922521   -0.0126768     0.0280941    0.0460467    0.076649     0.179714     0.0586257    0.0167616   -0.094256    -0.0282       0.16595      0.0240796  -0.0574503    0.00587345   0.000193948   0.0027529    0.116303      0.0325803    0.113492
  0.169997     0.000919316  -0.284808   -0.0397802    -0.00710499   0.0545192   -0.171995    -0.145215    -0.152706     -0.0912345   -0.0766963   -0.077818     0.0878367   -0.0991888    0.147209     0.127436     0.109944     0.0328108    0.0708799  -0.0747517    0.152265    -0.0365956     0.0449892    0.132633      0.101273    -0.180392
  0.112227     0.144928     -0.135213    0.00708536   -0.106367    -0.11382      0.0185901    0.00668342  -0.0704261     0.0425609    0.0444337    0.0515437   -0.185565     0.0411838   -0.136018    -0.00370788  -0.0464474    0.0268633   -0.118608    0.0461603   -0.115945     0.0726461    -0.116928    -0.108133     -0.0956129    0.0413061
 -0.0496924   -0.101147     -0.0836845  -0.0331805    -0.15237      0.0710222   -0.0696024    0.138313    -0.184758     -0.0397482   -0.0353535   -0.146128    -0.0293774   -0.0239825   -0.0699019   -0.00419538  -0.0610639   -0.106363    -0.116573    0.113514     0.0945416   -0.0287181    -0.146893     0.0947463    -0.105188    -0.160477
  0.0674972   -0.157974      0.242382    0.214841     -0.0470279    0.0269605    0.0527615    0.0258591   -0.0626628    -0.0780634    0.144684     0.0719573   -0.090868     0.0917133   -0.0798607   -0.0409856   -0.00913993  -0.130102    -0.0355712  -0.245817    -0.0224318    0.184268     -0.101997    -0.176337     -0.00524485   0.177427
 -0.0582165    0.00271623   -0.0806781  -0.012557     -0.0919206   -0.0622278   -0.0930039   -0.00487037  -0.0586526     0.106668     0.162095     0.19912      0.0595292    0.118769     0.125222     0.0844903    0.077024    -0.224129    -0.0235287  -0.0658898   -0.0329031   -0.0740032     0.0967277   -0.0469075    -0.138794     0.0332439
 -0.0377509   -0.0754314     0.0149079   0.0824362    -0.0706839   -0.0360205    7.46552e-6   0.1027       0.101982     -0.124211     0.0327669   -0.0465482    0.00882218   0.0892872   -0.186287     0.127258     0.0320206   -0.0145345   -0.0992081   0.110743    -0.00475199  -0.0351693     0.0595375    0.0283633    -0.0172555    0.104917
  0.140549    -0.0840294     0.0349629  -0.0444114    -0.00764161   0.126534     0.0147449    0.01197     -0.0219292     0.0664461   -0.0976627   -0.0275528   -0.0786656    0.142845     0.159612    -0.0618995   -0.0986709   -0.179929    -0.0418233   0.106894    -0.0470513    0.0733844     0.0989043    0.0751552    -0.133796     0.01778
 -0.052774     0.0409406     0.0488834  -0.0121726    -0.0733914    0.0944169   -0.0845783   -0.0346459    0.0588802     0.0484043    0.0105354    0.0581019   -0.0310082    0.115703     0.00411026   0.037597     0.0671659   -0.0311615    0.0993386  -0.104524     0.267219    -0.00403678    0.0376125    0.0763282    -0.103795    -0.0596293
 -0.0274857   -0.0453145    -0.0218755   0.112593     -0.0790731    0.11472      0.162779     0.218551    -0.0316808    -0.0663313    0.0520697    0.170559    -0.0944698    0.0709984    0.0633151   -0.0224664    0.0262606   -0.0178263    0.131706    0.0791336   -0.00839994   0.0253267     0.0048176    0.140947      0.0283545   -0.0416983
 -0.0623864   -0.0665193    -0.0791835  -0.245469      0.0362932    0.0233905   -0.0100537    0.13917      0.101268      0.00565511   0.0336579   -0.193483     0.032763    -0.0696429   -0.0504864    0.0230463    0.136473    -0.0353938    0.0408524  -0.161677    -0.14365      0.261833     -0.114347     0.123373      0.107389    -0.0251614
  0.00177938  -0.0452296    -0.0579213  -0.168757      0.175113     0.126476     0.135431    -0.0443705    0.00479512   -0.014091    -0.0209232   -0.118279     0.0133988    0.10397      0.0664936    0.0095708   -0.11113      0.19479      0.0677478   0.0984155   -0.0285605   -0.0430642    -0.104991     0.019831      0.13982      0.0948224
  0.0117942    0.0303397     0.0322249  -0.111342     -0.0411894   -0.0548853   -0.0210412    0.0831961   -0.0574618    -0.114558    -0.0768162   -0.065784     0.228708    -0.0156375   -0.0879158   -0.110853     0.0356037   -0.0271517    0.0779561   0.168159    -0.140836     0.0546002     0.0154131   -0.000932382  -0.028959     0.188848
  0.116754     0.0441489    -0.0864115   0.0548437     0.0292134    0.00547573  -0.0691031    0.145642     0.0965351     0.0399404    0.00959762  -0.00836716   0.0912494   -0.00934394   0.0730013    0.246142     0.151191    -0.217459     0.0270879  -0.168795    -0.017856     0.0736762     0.0786762   -0.0381983    -0.0645272   -0.00309226
  0.0425582    0.0881089    -0.0618632  -0.113053     -0.0468657    0.0438432    0.0263824   -0.0208796   -0.116753     -0.0204993   -0.063609     0.0278121    0.103998     0.178317    -0.0540653    0.0164873   -0.137731     0.00615208   0.0688864   0.172464     0.0455295    0.072554     -0.00413968   0.0481755    -0.060886    -0.200288
  0.0497174   -0.0704258     0.0082184  -0.0762025    -0.10018     -0.142411    -0.220709    -0.0101993    0.125656     -0.00123259  -0.112565     0.0463474   -0.0850761   -0.067472    -0.114746     0.0249539   -0.0697637   -0.0816876    0.328773    0.197484     0.11563     -0.0285191    -0.0123522    0.0282522     0.00125223  -0.085456
  0.0964113   -0.0833297     0.104956   -0.124585     -0.0451932    0.0796221    0.042665     0.070072    -0.071672     -0.0696405   -0.0497608   -0.123235     0.0223708   -0.0115256    0.0211882    0.0381777    0.131462     0.0904605   -0.102082   -0.0607539   -0.161725    -0.14979      -0.045892     0.0186462     0.116356    -0.127894
  0.305413     0.000119155   0.0253887  -0.0248352     0.079208    -0.00578333  -0.146487    -0.135947    -0.0913191     0.0103789    0.11974     -0.0514762   -0.0153667    0.0352079   -0.00154215  -0.0711763   -0.0587334    0.00810798   0.0104133  -0.0122424    0.121066     0.0877853    -0.0584931    0.0565883     0.0488409    0.0167079
  0.0797142    0.0376566     0.0715625  -0.111696     -0.0796034    0.149415    -0.136576     0.124279     0.0119517    -0.066233    -0.0775129   -0.104361    -0.0820109   -0.409091     0.0200913    0.0566093    0.0427932    0.0667794   -0.0563699  -0.0445988    0.100398    -0.059886      0.0842518    0.121164     -0.00217655   0.0587884
 -0.0211096   -0.0383276    -0.146976   -0.0720767     0.0066429    0.158831     0.0649243    0.189638    -0.0065993     0.151203    -0.081287    -0.0442473    0.0808004    0.0393083    0.150065    -0.0378431   -0.0570434    0.0786287   -0.0326555  -0.174029    -0.0982978    0.0892459    -0.0300198    0.0876294    -0.032799     0.140724
 -0.104088    -0.206113     -0.0909743   0.081154      0.109797    -0.0407768    0.00837091   0.129815     0.000938369   0.183293     0.018196     0.06447     -0.0386797   -0.153538    -0.0380213   -0.147975     0.0895453   -0.0665068    0.137298   -0.023875     0.0342449   -0.031093      0.0929728   -0.0275196    -0.208829     0.210722
  0.0807434    0.115299      0.0239462   0.024529     -0.0569898    0.18159      0.17764      0.122106    -0.102662      0.171011     0.0440749    0.0354734   -0.0661756    0.0369196   -0.10408      0.209653     0.00220951   0.00953533   0.0409002   0.00618574  -0.0535716   -0.145461      0.109667    -0.123227      0.0459156    0.037679
  0.154767    -0.0209495     0.048748    0.0118881     0.177886    -0.054732     0.14008      0.0920915   -0.159726      0.0884752    0.049457     0.137606     0.00973875   0.125221     0.188185     0.173593     0.0487082    0.117176     0.0396602  -0.00746741   0.0679724    0.118955     -0.0370028   -0.050427      0.0730089    0.0197068
 -0.0715317    0.00192156   -0.0653984  -0.0247748     0.0699998   -0.0316417    0.0473285   -0.0403858    0.0355098     0.0355989   -0.107258     0.080228    -0.095401     0.0291989    0.0786055   -0.127734    -0.0252919   -0.227332     0.0314301   0.0611136   -0.277035     0.123528      0.125075     0.185654     -0.198067     0.0532568
 -0.030163    -0.0187955     0.0306822  -0.19461       0.0291297   -0.00912104  -0.213486    -0.17589      0.0696679    -0.0286783    0.0168726    0.199417    -0.0609076    0.0286275   -0.050564     0.130084    -0.114208     0.152839     0.0606358   0.0496563   -0.00811074  -0.0370883    -0.053215     0.00427558   -0.0418626   -0.0427553
 -0.0667457    0.0834372    -0.0178029   0.278664     -0.0998201    0.0370944    0.0636575   -0.194531    -0.0221831     0.0937728    0.00864829  -0.0148373   -0.162786    -0.0895323    0.0887673   -0.0491622   -0.0734444    0.0567031   -0.0858554   0.0413391    0.190285    -0.00147014   -0.13702      0.0805588    -0.118006     0.0441701
  0.0756357   -0.107992      0.0516192  -0.000558255   0.0117371   -0.0716316   -0.00425425   0.156586    -0.102404     -0.14513     -0.0313468   -0.0801837    0.035135    -0.0432129    0.0837215    0.0454239   -0.280418     0.0253924   -0.0023791   0.105209     0.0760765   -0.00953635    0.1579       0.0409826     0.01229     -0.0200293
  0.0947503    0.241665      0.0869511  -0.00508535    0.0618033    0.0826126    0.0357378   -0.029788     0.0468163    -0.0190852    0.211782     0.0848917   -0.159053     0.100336     0.109707     0.107027    -0.166541     0.0506799    0.0570378  -0.0260847    0.148941    -0.0247886     0.183168    -0.281325      0.106829    -0.166459
  0.0566532   -0.0862002    -0.010524    0.0923206    -0.0746936    0.0824343   -0.0469803    0.0251548   -0.105529      0.00727408   0.200314     0.0578562   -0.0205688   -0.030112    -0.0810387    0.0335142    0.0915183   -0.0413983   -0.025944    0.0726852    0.00943136   0.00183027    0.0447108   -0.0310611     0.0460981   -0.0843201
  0.0136422   -0.00997556   -0.0745949   0.0203446     0.0211941   -0.0552124    0.0997825   -0.112798     0.110147     -0.177466     0.0413055   -0.0897047    0.161993    -0.15553      0.0453424   -0.0648675   -0.025527     0.122568     0.0435836  -0.0396203   -0.0944276    0.026896     -0.044771     0.141739     -0.132267    -0.129557
  0.0239996   -0.00137769    0.154022   -0.0144438    -0.127016     0.0299783   -0.0224002   -0.206303    -0.215537     -0.0100547   -0.0459115   -0.0532279   -0.0607119    0.109751     0.113828     0.0358065    0.0712819   -0.223283    -0.105146    0.0805239    0.0170223    0.0580128     0.00739495  -0.112632     -0.0945131   -0.0901225kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4213112917729274
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421330
[ Info: iteration 2, average log likelihood -1.421241
[ Info: iteration 3, average log likelihood -1.421155
[ Info: iteration 4, average log likelihood -1.421043
[ Info: iteration 5, average log likelihood -1.420901
[ Info: iteration 6, average log likelihood -1.420738
[ Info: iteration 7, average log likelihood -1.420574
[ Info: iteration 8, average log likelihood -1.420426
[ Info: iteration 9, average log likelihood -1.420296
[ Info: iteration 10, average log likelihood -1.420158
[ Info: iteration 11, average log likelihood -1.419967
[ Info: iteration 12, average log likelihood -1.419661
[ Info: iteration 13, average log likelihood -1.419171
[ Info: iteration 14, average log likelihood -1.418465
[ Info: iteration 15, average log likelihood -1.417622
[ Info: iteration 16, average log likelihood -1.416846
[ Info: iteration 17, average log likelihood -1.416306
[ Info: iteration 18, average log likelihood -1.416007
[ Info: iteration 19, average log likelihood -1.415862
[ Info: iteration 20, average log likelihood -1.415795
[ Info: iteration 21, average log likelihood -1.415765
[ Info: iteration 22, average log likelihood -1.415751
[ Info: iteration 23, average log likelihood -1.415744
[ Info: iteration 24, average log likelihood -1.415741
[ Info: iteration 25, average log likelihood -1.415739
[ Info: iteration 26, average log likelihood -1.415738
[ Info: iteration 27, average log likelihood -1.415738
[ Info: iteration 28, average log likelihood -1.415737
[ Info: iteration 29, average log likelihood -1.415737
[ Info: iteration 30, average log likelihood -1.415736
[ Info: iteration 31, average log likelihood -1.415736
[ Info: iteration 32, average log likelihood -1.415736
[ Info: iteration 33, average log likelihood -1.415735
[ Info: iteration 34, average log likelihood -1.415735
[ Info: iteration 35, average log likelihood -1.415735
[ Info: iteration 36, average log likelihood -1.415735
[ Info: iteration 37, average log likelihood -1.415735
[ Info: iteration 38, average log likelihood -1.415735
[ Info: iteration 39, average log likelihood -1.415734
[ Info: iteration 40, average log likelihood -1.415734
[ Info: iteration 41, average log likelihood -1.415734
[ Info: iteration 42, average log likelihood -1.415734
[ Info: iteration 43, average log likelihood -1.415734
[ Info: iteration 44, average log likelihood -1.415734
[ Info: iteration 45, average log likelihood -1.415734
[ Info: iteration 46, average log likelihood -1.415734
[ Info: iteration 47, average log likelihood -1.415734
[ Info: iteration 48, average log likelihood -1.415734
[ Info: iteration 49, average log likelihood -1.415734
[ Info: iteration 50, average log likelihood -1.415734
┌ Info: EM with 100000 data points 50 iterations avll -1.415734
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4213302866636603
│     -1.4212405873341962
│      ⋮
└     -1.415733798175238
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415753
[ Info: iteration 2, average log likelihood -1.415660
[ Info: iteration 3, average log likelihood -1.415571
[ Info: iteration 4, average log likelihood -1.415454
[ Info: iteration 5, average log likelihood -1.415305
[ Info: iteration 6, average log likelihood -1.415137
[ Info: iteration 7, average log likelihood -1.414976
[ Info: iteration 8, average log likelihood -1.414844
[ Info: iteration 9, average log likelihood -1.414747
[ Info: iteration 10, average log likelihood -1.414679
[ Info: iteration 11, average log likelihood -1.414631
[ Info: iteration 12, average log likelihood -1.414595
[ Info: iteration 13, average log likelihood -1.414567
[ Info: iteration 14, average log likelihood -1.414542
[ Info: iteration 15, average log likelihood -1.414521
[ Info: iteration 16, average log likelihood -1.414502
[ Info: iteration 17, average log likelihood -1.414485
[ Info: iteration 18, average log likelihood -1.414469
[ Info: iteration 19, average log likelihood -1.414454
[ Info: iteration 20, average log likelihood -1.414440
[ Info: iteration 21, average log likelihood -1.414427
[ Info: iteration 22, average log likelihood -1.414415
[ Info: iteration 23, average log likelihood -1.414405
[ Info: iteration 24, average log likelihood -1.414395
[ Info: iteration 25, average log likelihood -1.414386
[ Info: iteration 26, average log likelihood -1.414379
[ Info: iteration 27, average log likelihood -1.414372
[ Info: iteration 28, average log likelihood -1.414366
[ Info: iteration 29, average log likelihood -1.414360
[ Info: iteration 30, average log likelihood -1.414356
[ Info: iteration 31, average log likelihood -1.414351
[ Info: iteration 32, average log likelihood -1.414348
[ Info: iteration 33, average log likelihood -1.414345
[ Info: iteration 34, average log likelihood -1.414342
[ Info: iteration 35, average log likelihood -1.414339
[ Info: iteration 36, average log likelihood -1.414337
[ Info: iteration 37, average log likelihood -1.414335
[ Info: iteration 38, average log likelihood -1.414333
[ Info: iteration 39, average log likelihood -1.414332
[ Info: iteration 40, average log likelihood -1.414331
[ Info: iteration 41, average log likelihood -1.414329
[ Info: iteration 42, average log likelihood -1.414328
[ Info: iteration 43, average log likelihood -1.414327
[ Info: iteration 44, average log likelihood -1.414326
[ Info: iteration 45, average log likelihood -1.414326
[ Info: iteration 46, average log likelihood -1.414325
[ Info: iteration 47, average log likelihood -1.414324
[ Info: iteration 48, average log likelihood -1.414324
[ Info: iteration 49, average log likelihood -1.414323
[ Info: iteration 50, average log likelihood -1.414323
┌ Info: EM with 100000 data points 50 iterations avll -1.414323
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4157525700846885
│     -1.4156602650899255
│      ⋮
└     -1.4143226512090326
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414332
[ Info: iteration 2, average log likelihood -1.414275
[ Info: iteration 3, average log likelihood -1.414220
[ Info: iteration 4, average log likelihood -1.414150
[ Info: iteration 5, average log likelihood -1.414059
[ Info: iteration 6, average log likelihood -1.413943
[ Info: iteration 7, average log likelihood -1.413806
[ Info: iteration 8, average log likelihood -1.413661
[ Info: iteration 9, average log likelihood -1.413523
[ Info: iteration 10, average log likelihood -1.413401
[ Info: iteration 11, average log likelihood -1.413298
[ Info: iteration 12, average log likelihood -1.413213
[ Info: iteration 13, average log likelihood -1.413144
[ Info: iteration 14, average log likelihood -1.413088
[ Info: iteration 15, average log likelihood -1.413043
[ Info: iteration 16, average log likelihood -1.413006
[ Info: iteration 17, average log likelihood -1.412975
[ Info: iteration 18, average log likelihood -1.412950
[ Info: iteration 19, average log likelihood -1.412929
[ Info: iteration 20, average log likelihood -1.412911
[ Info: iteration 21, average log likelihood -1.412894
[ Info: iteration 22, average log likelihood -1.412880
[ Info: iteration 23, average log likelihood -1.412866
[ Info: iteration 24, average log likelihood -1.412854
[ Info: iteration 25, average log likelihood -1.412842
[ Info: iteration 26, average log likelihood -1.412831
[ Info: iteration 27, average log likelihood -1.412821
[ Info: iteration 28, average log likelihood -1.412811
[ Info: iteration 29, average log likelihood -1.412801
[ Info: iteration 30, average log likelihood -1.412792
[ Info: iteration 31, average log likelihood -1.412783
[ Info: iteration 32, average log likelihood -1.412774
[ Info: iteration 33, average log likelihood -1.412766
[ Info: iteration 34, average log likelihood -1.412758
[ Info: iteration 35, average log likelihood -1.412751
[ Info: iteration 36, average log likelihood -1.412744
[ Info: iteration 37, average log likelihood -1.412737
[ Info: iteration 38, average log likelihood -1.412730
[ Info: iteration 39, average log likelihood -1.412724
[ Info: iteration 40, average log likelihood -1.412718
[ Info: iteration 41, average log likelihood -1.412712
[ Info: iteration 42, average log likelihood -1.412706
[ Info: iteration 43, average log likelihood -1.412701
[ Info: iteration 44, average log likelihood -1.412696
[ Info: iteration 45, average log likelihood -1.412690
[ Info: iteration 46, average log likelihood -1.412686
[ Info: iteration 47, average log likelihood -1.412681
[ Info: iteration 48, average log likelihood -1.412676
[ Info: iteration 49, average log likelihood -1.412672
[ Info: iteration 50, average log likelihood -1.412667
┌ Info: EM with 100000 data points 50 iterations avll -1.412667
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414332283135884
│     -1.4142751679337882
│      ⋮
└     -1.4126673030524073
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412673
[ Info: iteration 2, average log likelihood -1.412624
[ Info: iteration 3, average log likelihood -1.412582
[ Info: iteration 4, average log likelihood -1.412535
[ Info: iteration 5, average log likelihood -1.412481
[ Info: iteration 6, average log likelihood -1.412415
[ Info: iteration 7, average log likelihood -1.412337
[ Info: iteration 8, average log likelihood -1.412244
[ Info: iteration 9, average log likelihood -1.412140
[ Info: iteration 10, average log likelihood -1.412028
[ Info: iteration 11, average log likelihood -1.411913
[ Info: iteration 12, average log likelihood -1.411801
[ Info: iteration 13, average log likelihood -1.411696
[ Info: iteration 14, average log likelihood -1.411600
[ Info: iteration 15, average log likelihood -1.411515
[ Info: iteration 16, average log likelihood -1.411441
[ Info: iteration 17, average log likelihood -1.411377
[ Info: iteration 18, average log likelihood -1.411322
[ Info: iteration 19, average log likelihood -1.411275
[ Info: iteration 20, average log likelihood -1.411233
[ Info: iteration 21, average log likelihood -1.411197
[ Info: iteration 22, average log likelihood -1.411165
[ Info: iteration 23, average log likelihood -1.411137
[ Info: iteration 24, average log likelihood -1.411112
[ Info: iteration 25, average log likelihood -1.411089
[ Info: iteration 26, average log likelihood -1.411069
[ Info: iteration 27, average log likelihood -1.411050
[ Info: iteration 28, average log likelihood -1.411033
[ Info: iteration 29, average log likelihood -1.411017
[ Info: iteration 30, average log likelihood -1.411003
[ Info: iteration 31, average log likelihood -1.410989
[ Info: iteration 32, average log likelihood -1.410976
[ Info: iteration 33, average log likelihood -1.410964
[ Info: iteration 34, average log likelihood -1.410953
[ Info: iteration 35, average log likelihood -1.410942
[ Info: iteration 36, average log likelihood -1.410931
[ Info: iteration 37, average log likelihood -1.410920
[ Info: iteration 38, average log likelihood -1.410910
[ Info: iteration 39, average log likelihood -1.410900
[ Info: iteration 40, average log likelihood -1.410891
[ Info: iteration 41, average log likelihood -1.410881
[ Info: iteration 42, average log likelihood -1.410872
[ Info: iteration 43, average log likelihood -1.410862
[ Info: iteration 44, average log likelihood -1.410853
[ Info: iteration 45, average log likelihood -1.410844
[ Info: iteration 46, average log likelihood -1.410834
[ Info: iteration 47, average log likelihood -1.410825
[ Info: iteration 48, average log likelihood -1.410816
[ Info: iteration 49, average log likelihood -1.410806
[ Info: iteration 50, average log likelihood -1.410797
┌ Info: EM with 100000 data points 50 iterations avll -1.410797
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4126725205653914
│     -1.4126236184803878
│      ⋮
└     -1.4107969019130482
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410796
[ Info: iteration 2, average log likelihood -1.410731
[ Info: iteration 3, average log likelihood -1.410667
[ Info: iteration 4, average log likelihood -1.410590
[ Info: iteration 5, average log likelihood -1.410492
[ Info: iteration 6, average log likelihood -1.410369
[ Info: iteration 7, average log likelihood -1.410219
[ Info: iteration 8, average log likelihood -1.410047
[ Info: iteration 9, average log likelihood -1.409862
[ Info: iteration 10, average log likelihood -1.409677
[ Info: iteration 11, average log likelihood -1.409501
[ Info: iteration 12, average log likelihood -1.409341
[ Info: iteration 13, average log likelihood -1.409199
[ Info: iteration 14, average log likelihood -1.409075
[ Info: iteration 15, average log likelihood -1.408968
[ Info: iteration 16, average log likelihood -1.408876
[ Info: iteration 17, average log likelihood -1.408797
[ Info: iteration 18, average log likelihood -1.408727
[ Info: iteration 19, average log likelihood -1.408667
[ Info: iteration 20, average log likelihood -1.408613
[ Info: iteration 21, average log likelihood -1.408566
[ Info: iteration 22, average log likelihood -1.408523
[ Info: iteration 23, average log likelihood -1.408485
[ Info: iteration 24, average log likelihood -1.408450
[ Info: iteration 25, average log likelihood -1.408418
[ Info: iteration 26, average log likelihood -1.408388
[ Info: iteration 27, average log likelihood -1.408360
[ Info: iteration 28, average log likelihood -1.408335
[ Info: iteration 29, average log likelihood -1.408311
[ Info: iteration 30, average log likelihood -1.408288
[ Info: iteration 31, average log likelihood -1.408267
[ Info: iteration 32, average log likelihood -1.408247
[ Info: iteration 33, average log likelihood -1.408228
[ Info: iteration 34, average log likelihood -1.408209
[ Info: iteration 35, average log likelihood -1.408192
[ Info: iteration 36, average log likelihood -1.408175
[ Info: iteration 37, average log likelihood -1.408159
[ Info: iteration 38, average log likelihood -1.408143
[ Info: iteration 39, average log likelihood -1.408128
[ Info: iteration 40, average log likelihood -1.408114
[ Info: iteration 41, average log likelihood -1.408099
[ Info: iteration 42, average log likelihood -1.408085
[ Info: iteration 43, average log likelihood -1.408072
[ Info: iteration 44, average log likelihood -1.408059
[ Info: iteration 45, average log likelihood -1.408046
[ Info: iteration 46, average log likelihood -1.408033
[ Info: iteration 47, average log likelihood -1.408021
[ Info: iteration 48, average log likelihood -1.408009
[ Info: iteration 49, average log likelihood -1.407997
[ Info: iteration 50, average log likelihood -1.407986
┌ Info: EM with 100000 data points 50 iterations avll -1.407986
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410795955990826
│     -1.4107310187969515
│      ⋮
└     -1.4079856861962845
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4213112917729274
│     -1.4213302866636603
│     -1.4212405873341962
│     -1.4211547591153821
│      ⋮
│     -1.4080089999176892
│     -1.4079972249549138
└     -1.4079856861962845
32×26 Array{Float64,2}:
  0.146652   -0.211691   -0.514762     0.184666   -0.542212    0.118361   -0.389963    -0.474286   -0.179733     0.122953     0.447702   -0.268289   -0.0662001   0.252164    -0.112183     -0.347564    0.0660388  -0.574538   -0.244684     0.338335    -0.2077      0.529968    -0.155123   -0.405106    -0.239459     -0.5251
 -0.048497    0.505328   -0.222152    -0.0490885  -0.947244    0.632457    0.066608    -0.229352   -0.298317    -0.0737511    0.067702   -0.436841   -0.03344     0.168894     0.467535     -0.158361    0.409877   -0.656182   -0.242845     0.103545     0.39036     0.544624     0.485544    0.101856    -0.000552797   0.195805
  0.0609111  -0.614594    0.406452    -0.129783   -0.142171    0.340289    0.116555     0.136153   -0.252279    -0.607758    -0.107081   -0.200758   -0.349376   -0.203304     0.68657      -0.0313931   0.532801    0.0591853  -0.41622     -0.398988     0.0472274   0.392803    -0.457804    0.270714     0.533663     -0.298218
  0.473034   -0.20254     0.555942     0.637481    0.297849    0.93916     0.585646     0.242107   -0.132441     0.488937     0.333698   -0.280595    0.272763    0.18897      0.353806      0.0642522   0.0257032  -0.387484    0.0983527   -0.0467796    0.373251    0.508994    -1.16156    -0.504537     0.0494204    -0.179549
 -0.130093   -0.0542513   0.23878      0.106479    0.224681   -0.0116979  -0.2731      -0.162443   -0.0860679    0.0977955    0.0212684  -0.056894   -0.254097    0.334668    -0.688622      0.0996302  -0.469112    0.541744    0.654074     0.303975     0.124839   -0.636452    -0.67588    -0.213804    -0.223261     -0.00528465
 -0.828231    0.110328    0.172212     0.0885479   0.463098    0.219039   -0.021902    -0.37573     0.494392     0.408141     0.252277    0.232765   -0.436759    0.930477     0.131695      0.522473   -0.114001    0.190328    0.188703    -0.0161959    0.946361    0.169681    -0.492297   -0.23442      0.231644      0.0527056
 -0.785842    0.0598143   0.770391    -0.403427   -0.368471   -0.0240531  -0.0468617   -0.490703    0.0611079    0.131951     0.250225    0.201098    0.171042    0.291441    -0.303021     -0.253281   -0.87619    -0.280549   -0.44157     -0.275334    -0.0929432  -0.0557434   -0.261513    0.163634     0.301407      0.124215
 -0.378214    0.227341    1.21407     -0.509155    0.0865288   0.382304   -0.131001    -0.257168   -0.50756     -0.181528     0.218546   -0.0788168   0.697168    0.154568     0.000815181   0.75484    -0.108053    0.178397    0.0244787   -0.0925604   -0.320272   -0.163936     0.288895   -0.620906     0.692677      0.203802
 -0.036469    0.141784    0.203179    -0.897332   -0.199729   -0.341689    0.284613    -0.481761   -0.144441    -0.302534    -0.0529003   0.0721783  -0.348729   -0.276751    -0.288799      0.182551   -0.314352    0.177669   -0.336939     0.833769    -0.431199    0.424073    -0.15324    -0.40612      0.00365485    0.893706
  0.442733   -0.418558   -0.287907    -0.0675723  -0.0526272  -0.308225    0.17857     -0.0827311  -0.244158     0.850746     0.025425    0.0778131   0.139627    0.727852    -0.199783     -0.150154   -0.219968    0.510849   -0.00831933   0.173844    -0.619496    0.206131    -0.0407492   0.0755769   -0.334073      0.68775
  0.116203    0.582054   -0.00638912   0.739783   -0.579377    0.184085    0.341979     0.0402534  -0.337424    -0.18056     -0.526218   -0.0786375  -0.580611    0.499438    -0.0666028    -0.408164   -0.190653    0.563423   -0.156485     0.554984     0.239102    0.169025    -0.27686     0.564073     0.114358      0.443865
 -0.0335983   0.314862   -0.394136     0.159144    0.104842   -0.566748   -0.0707585    0.256753   -0.227858    -0.0602014   -1.0762     -0.108128   -0.220665    0.0422457   -0.33061       0.247774   -0.730834    0.261849   -0.0107565    0.0855687   -0.045205    0.00395874   0.687353    0.310655    -0.122175      0.438994
 -0.241703   -0.252592    0.172842    -0.112752    0.686697    0.132783   -0.156311    -0.526655    0.20328      0.148498     0.475634    0.0193649   0.615183   -0.19763      0.209479      0.0833225   0.358629   -0.145389    0.0948653   -0.135454     0.141717    0.0842569   -0.136619   -0.0627983   -0.0457091    -0.2808
  0.363505   -0.023899   -0.0697077   -0.139512   -0.276011   -0.279812   -0.0121291    0.734202    0.100465     0.00725834  -0.125845    0.0914099  -0.0891478  -0.116984     0.00575646   -0.13741    -0.0487698  -0.0297006  -0.0876876   -0.186608    -0.189081   -0.257619     0.105635    0.112104    -0.0252815     0.0955015
  0.388506    0.0617582   0.123481     0.355562    0.60909     0.21416    -0.157515     0.143933   -0.401503     0.0412287   -0.0176382   0.26533     0.432353   -0.340559     0.285151      0.118518   -0.37365    -0.692458    0.284138    -0.447911     0.347605   -0.757208     0.674592    0.87534     -0.202808     -0.650123
  0.398334   -0.197827   -0.294127     0.560475   -0.0993501   0.458935    0.284618     0.815957   -0.166502     0.240149    -0.221496    0.0987454   0.0472323   0.511554     0.617213     -0.0400088   0.512564    0.167998    0.826676    -0.386158     0.522173   -0.827611     0.651593    0.172692     0.0876423    -0.434924
 -0.305963   -0.574377   -0.227273    -0.595397   -0.175763    0.214152   -0.27732     -0.221859    0.111264    -0.189272     0.434248   -0.208121   -0.0473896   0.0714294    0.154849      0.0952517  -0.0590876  -0.692437    0.322875    -0.0047084   -0.0967483  -0.138539     0.318914   -0.180854    -0.274264     -0.137177
 -0.252486   -0.566247   -0.0112338   -0.189584    0.616289    0.129007   -0.414543    -0.474006   -0.236236    -0.230392    -0.254976   -0.188597    0.242665    0.265055     0.0570941     0.351328    0.289474    0.305049    0.419265     0.037904     0.0945812  -0.1218       0.191787    0.116057    -0.240226     -0.345379
 -0.149965    0.381728   -0.192301    -0.242354   -0.25155    -0.389466    0.442043     0.277726    0.492431    -1.00325     -0.0212709   0.0651153  -0.467797    0.101661    -0.35729       0.547496    0.431476   -0.114559    0.381194    -0.319992     0.645227   -0.118455     0.587462   -0.213514    -0.0543617    -0.541932
 -0.70913    -0.362713   -0.144141    -1.02805     0.285211   -0.374185    0.296674    -0.0839661   0.0676926   -0.445484    -0.16051     0.423879   -0.175629   -0.215062    -0.0111347     0.501636    0.350343    1.69567     0.496053     0.0972658   -0.067103   -0.117669     0.209457    0.345605     0.242342      0.526015
  0.608037    0.0892172  -0.772882     0.500553    0.570493   -0.0433671   0.136755     0.0295369   0.271123     0.130557     0.0262045   0.270837   -0.272798   -0.408644     0.2336       -0.0100639   0.576556    0.253124    0.178643     0.677883     0.145748    0.0150663   -0.0421237  -0.157166    -0.649198     -0.153915
 -0.410544    0.640867    0.0264983    0.298504    0.417731    0.423162   -0.128415    -0.27037     0.394342    -0.157157     0.24737     0.0930179  -0.204455   -0.50255     -0.12528       0.158189   -0.230493   -0.261214   -0.333718     0.355856     0.0544893   0.41205     -0.0798804  -0.0365989   -0.309445     -0.428436
  0.104988   -0.0752122   0.369098    -0.186716    0.104026    0.361433    0.449374    -0.705846    0.530424     0.263782     0.820846    0.0443104   0.509714    0.0410945    0.0146578     0.126283    0.394712    0.102244   -0.0135392   -0.0999175    0.168152   -0.193856    -0.327526    0.230788    -0.597581      0.145829
  0.125964    0.0386389  -0.0027262    0.0511211  -0.0866186   0.246837    0.0454796    0.329833    0.289392     0.186499     0.619013    0.210649    0.464306   -0.49193     -0.00196882   -0.0316463   0.536723   -0.490891    0.00315145  -0.508578     0.151661    0.0051558   -0.0918479  -0.233373     0.117942     -0.370189
  0.0181545   0.105377   -0.0918071    0.0687594  -0.472584   -0.129263   -0.0272966   -0.002321   -0.243508    -0.118526     0.256575   -0.319182   -0.233361   -0.0526799   -0.0416739     0.0189247   0.138197    0.165051   -0.37224      0.367602    -0.100017    0.670045    -0.338747   -0.638511     0.553762      0.108204
  0.293168    0.093221   -0.0643785    0.276412   -0.221386    0.239449    0.144518    -0.0711443  -0.285805     0.0533313   -0.133814   -0.0867769   0.0362333   0.0620966    0.342416     -0.150332    0.271975   -0.0812444  -0.486062     0.00165006   0.0857765   0.38123      0.0319776   0.525289     0.032257     -0.17046
 -0.0787121  -0.171162    0.096372    -0.0733765   0.0850901   0.108798   -0.0790821   -0.110734   -0.0798662    0.138        0.176166    0.0222844  -0.0297269   0.00116194  -0.0267065    -0.0618347  -0.0177736   0.0483937   0.0747655    0.11191     -0.051309   -0.0567657   -0.275529   -0.0164814   -0.00819198   -0.0981686
  0.133295    0.167611   -0.122179    -0.0149562  -0.0315152  -0.0646942   0.0773917    0.127142    0.00156894  -0.253842    -0.276591    0.0640204  -0.0257502   0.0478769    0.00602505    0.150254    0.0285387   0.0514893   0.135069     0.0277692    0.0784842  -0.0369087    0.409373   -0.00238217  -0.114988      0.182366
  0.495517   -0.176244   -0.500133    -0.126305   -0.512192   -0.415899   -0.259177     0.529312   -0.320255    -0.505746    -0.265663   -0.152641   -0.0541134  -0.640626    -0.0572287    -0.580181   -0.0919415   0.00541    -0.0468187    0.0338672   -0.505673   -0.0604114    0.548973    0.106098    -0.103142      0.0281975
  0.354072   -0.466892    0.126507    -0.11947     0.685985   -0.580495   -0.300603     0.586398    0.20772      0.0706548    0.0241622   0.170908    0.283874   -0.630151     0.0530879     0.234328   -0.331254    0.0452885   0.112479    -0.301719    -0.554389    0.159433     0.187175   -0.0736997    0.224153      0.0264534
 -0.377894    0.087716   -0.0172766    0.124865   -0.451192   -0.182143   -0.208686     0.330697   -0.274796     0.0526872   -0.245671   -0.39868     0.0520637   0.352576    -0.235838      0.0275623  -0.511234   -0.235002    0.0948882   -0.426983    -0.0371572  -0.121208    -0.0241582   0.265522     0.320799      0.0586973
  0.4508      0.251465    0.2687       0.0525057  -0.306608   -0.125441   -0.00801101   0.603757   -0.0544563    0.359963    -0.234042    0.429548   -0.171008   -0.0100836    0.198485     -0.357617   -0.383708   -0.0870057  -0.269792    -0.0868492   -0.258642   -0.40656     -0.164236    0.266116     0.0504487     0.369511[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407974
[ Info: iteration 2, average log likelihood -1.407963
[ Info: iteration 3, average log likelihood -1.407952
[ Info: iteration 4, average log likelihood -1.407942
[ Info: iteration 5, average log likelihood -1.407931
[ Info: iteration 6, average log likelihood -1.407921
[ Info: iteration 7, average log likelihood -1.407911
[ Info: iteration 8, average log likelihood -1.407901
[ Info: iteration 9, average log likelihood -1.407891
[ Info: iteration 10, average log likelihood -1.407881
┌ Info: EM with 100000 data points 10 iterations avll -1.407881
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.872255e+05
      1       7.049068e+05      -1.823187e+05 |       32
      2       6.901179e+05      -1.478884e+04 |       32
      3       6.847233e+05      -5.394669e+03 |       32
      4       6.818485e+05      -2.874756e+03 |       32
      5       6.800437e+05      -1.804768e+03 |       32
      6       6.788807e+05      -1.163090e+03 |       32
      7       6.780128e+05      -8.678437e+02 |       32
      8       6.772853e+05      -7.275383e+02 |       32
      9       6.766619e+05      -6.233868e+02 |       32
     10       6.761450e+05      -5.168474e+02 |       32
     11       6.757277e+05      -4.173134e+02 |       32
     12       6.753464e+05      -3.812792e+02 |       32
     13       6.750035e+05      -3.429091e+02 |       32
     14       6.746797e+05      -3.238496e+02 |       32
     15       6.743692e+05      -3.104377e+02 |       32
     16       6.741015e+05      -2.677505e+02 |       32
     17       6.738539e+05      -2.476175e+02 |       32
     18       6.736199e+05      -2.340133e+02 |       32
     19       6.734047e+05      -2.151381e+02 |       32
     20       6.731713e+05      -2.334227e+02 |       32
     21       6.729383e+05      -2.329874e+02 |       32
     22       6.727194e+05      -2.189097e+02 |       32
     23       6.725122e+05      -2.071615e+02 |       32
     24       6.723136e+05      -1.986368e+02 |       32
     25       6.721337e+05      -1.799169e+02 |       32
     26       6.719613e+05      -1.724147e+02 |       32
     27       6.717877e+05      -1.735640e+02 |       32
     28       6.716154e+05      -1.723113e+02 |       32
     29       6.714612e+05      -1.541722e+02 |       32
     30       6.713312e+05      -1.300552e+02 |       32
     31       6.712147e+05      -1.164763e+02 |       32
     32       6.711142e+05      -1.005082e+02 |       32
     33       6.710236e+05      -9.058623e+01 |       32
     34       6.709493e+05      -7.434736e+01 |       32
     35       6.708859e+05      -6.332662e+01 |       32
     36       6.708209e+05      -6.501580e+01 |       32
     37       6.707605e+05      -6.042815e+01 |       32
     38       6.707068e+05      -5.366062e+01 |       32
     39       6.706602e+05      -4.661075e+01 |       32
     40       6.706221e+05      -3.811094e+01 |       32
     41       6.705903e+05      -3.179402e+01 |       32
     42       6.705608e+05      -2.955273e+01 |       32
     43       6.705368e+05      -2.399698e+01 |       32
     44       6.705079e+05      -2.887866e+01 |       32
     45       6.704827e+05      -2.519356e+01 |       32
     46       6.704578e+05      -2.488425e+01 |       32
     47       6.704325e+05      -2.532445e+01 |       32
     48       6.704075e+05      -2.499895e+01 |       32
     49       6.703827e+05      -2.475107e+01 |       32
     50       6.703579e+05      -2.479125e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670357.9386993581)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419909
[ Info: iteration 2, average log likelihood -1.414864
[ Info: iteration 3, average log likelihood -1.413427
[ Info: iteration 4, average log likelihood -1.412308
[ Info: iteration 5, average log likelihood -1.411171
[ Info: iteration 6, average log likelihood -1.410201
[ Info: iteration 7, average log likelihood -1.409578
[ Info: iteration 8, average log likelihood -1.409235
[ Info: iteration 9, average log likelihood -1.409037
[ Info: iteration 10, average log likelihood -1.408905
[ Info: iteration 11, average log likelihood -1.408805
[ Info: iteration 12, average log likelihood -1.408724
[ Info: iteration 13, average log likelihood -1.408656
[ Info: iteration 14, average log likelihood -1.408597
[ Info: iteration 15, average log likelihood -1.408545
[ Info: iteration 16, average log likelihood -1.408499
[ Info: iteration 17, average log likelihood -1.408458
[ Info: iteration 18, average log likelihood -1.408421
[ Info: iteration 19, average log likelihood -1.408387
[ Info: iteration 20, average log likelihood -1.408355
[ Info: iteration 21, average log likelihood -1.408326
[ Info: iteration 22, average log likelihood -1.408299
[ Info: iteration 23, average log likelihood -1.408273
[ Info: iteration 24, average log likelihood -1.408249
[ Info: iteration 25, average log likelihood -1.408226
[ Info: iteration 26, average log likelihood -1.408204
[ Info: iteration 27, average log likelihood -1.408182
[ Info: iteration 28, average log likelihood -1.408161
[ Info: iteration 29, average log likelihood -1.408141
[ Info: iteration 30, average log likelihood -1.408121
[ Info: iteration 31, average log likelihood -1.408102
[ Info: iteration 32, average log likelihood -1.408083
[ Info: iteration 33, average log likelihood -1.408064
[ Info: iteration 34, average log likelihood -1.408046
[ Info: iteration 35, average log likelihood -1.408027
[ Info: iteration 36, average log likelihood -1.408009
[ Info: iteration 37, average log likelihood -1.407991
[ Info: iteration 38, average log likelihood -1.407974
[ Info: iteration 39, average log likelihood -1.407957
[ Info: iteration 40, average log likelihood -1.407940
[ Info: iteration 41, average log likelihood -1.407923
[ Info: iteration 42, average log likelihood -1.407906
[ Info: iteration 43, average log likelihood -1.407890
[ Info: iteration 44, average log likelihood -1.407874
[ Info: iteration 45, average log likelihood -1.407859
[ Info: iteration 46, average log likelihood -1.407844
[ Info: iteration 47, average log likelihood -1.407830
[ Info: iteration 48, average log likelihood -1.407816
[ Info: iteration 49, average log likelihood -1.407803
[ Info: iteration 50, average log likelihood -1.407791
┌ Info: EM with 100000 data points 50 iterations avll -1.407791
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.464491   -0.136925    0.665531    -0.25196     0.361579    0.312187   -0.300473   -0.983175    -0.187026    0.396078    0.175922     0.140651     0.195552    0.124951    -0.549817    0.155307     -0.476829    0.273798     0.00644458   0.449505   -0.326334   -0.249384   -0.6098     -0.262236    -0.106668     0.168323
 -0.404167    0.165533    0.0516551    0.650742   -0.33717    -0.0586256  -0.0482901   0.188893    -0.599241    0.30495     0.11727     -0.302791     0.138899    0.00294431  -0.323071   -0.0955485    -0.408638   -0.393696    -0.0387494   -0.3161     -0.116969    0.0278566  -0.132442    0.24447      0.451496    -0.223937
  0.496136    0.232295    0.197224     0.119451   -0.237398   -0.132089   -0.0790366   0.544114    -0.0238776   0.420642   -0.553626     0.549908    -0.348956   -0.0416113    0.237319   -0.622587     -0.534938   -0.244892    -0.273023    -0.0225355  -0.262513   -0.468701   -0.274488    0.250462     0.0868066    0.705413
  0.496111   -0.576508   -0.170908    -0.132343   -0.111966   -0.485139    0.187791    0.0851208   -0.314155    0.73853    -0.0885804    0.129932     0.0720673   0.690595    -0.130694   -0.0980909    -0.26495     0.533437     0.085716     0.0378778  -0.657178    0.181874   -0.0445959   0.0368238   -0.174805     0.714357
 -0.125962   -0.472074   -0.651915    -0.583925   -0.537126   -0.342296   -0.429508   -0.090639    -0.113059   -0.439732   -0.044476    -0.253646    -0.201541    0.177617    -0.246509   -0.164066     -0.291459   -0.292125     0.12778     -0.106045   -0.361601   -0.236222    0.43265     0.113213    -0.228956    -0.0922859
  0.120536   -0.331266    0.430876     0.219135   -0.0139269   0.499566    0.174312    0.144373    -0.356152   -0.0710932   0.161909    -0.178312    -0.267598   -0.0374847    0.537527    0.0575252     0.401609    0.205893    -0.638541    -0.0681049   0.0366742   0.581767   -0.768144    0.154734     0.492609    -0.29997
  0.226709    0.415663    0.30871      0.443787   -0.675457    0.510556    0.190328   -0.0828982   -0.458578   -0.507758   -0.640352    -0.273466    -0.32696     0.533301    -0.234958   -0.336038     -0.0855053   0.832086     0.248225     0.48484     0.314155    0.309278   -0.0176006   0.586307    -0.108888     0.512135
  0.0445456   0.140978    0.189048     0.128553    0.165675    0.347329    0.0886406   0.0411636    0.357588    0.160835    0.448756     0.334776     0.25636    -0.309663     0.140147    0.168776      0.412088   -0.215074    -0.0522314   -0.305921    0.300383   -0.0253015  -0.112579   -0.132513     0.0500181   -0.287933
  0.688393    0.0487805  -0.501348     0.557748    0.701451    0.0331472   0.218812   -0.045983     0.12385     0.179091    0.00939654   0.273494    -0.0447908  -0.456431     0.29173    -0.00265897    0.5785      0.375012     0.167021     0.70425     0.148329    0.0611692  -0.190724   -0.166587    -0.532072    -0.211252
  0.408121   -0.469177   -0.194911    -0.0322148   0.331056   -0.436703   -0.563191    0.513462     0.0142599  -0.26922     0.0479459   -0.144896     0.278755   -0.931       -0.114026   -0.151845     -0.116913    0.0304252    0.251797    -0.0921633  -0.473351    0.312072    0.249279   -0.24171      0.163037     0.0420364
  0.0884582   0.26067     0.00269399  -0.494762   -0.486852   -0.326063    0.308622   -0.269929    -0.131508   -0.320262    0.211808    -0.116058    -0.372171   -0.304686    -0.155354    0.0319915    -0.133924   -0.00256727  -0.389438     0.732328   -0.279325    0.676935   -0.187851   -0.54855      0.223836     0.757317
  0.150455   -0.288616    0.227508     0.086822    0.946312    0.0600144  -0.312294    0.044415    -0.283408    0.0591578  -0.12546      0.301381     0.44417    -0.14396      0.336811    0.23745      -0.186773   -0.389945     0.310739    -0.370849    0.193621   -0.624492    0.506177    0.564805    -0.244446    -0.585589
  0.07375     0.0833089  -0.273693     0.0648783  -0.211319   -0.380399   -0.079155    0.277922    -0.196994   -0.0202794  -0.418185    -0.0930897   -0.168533   -0.0303304   -0.286635   -0.108633     -0.33756     0.0256771   -0.116866     0.0641957  -0.0728329   0.0834351   0.395263    0.116728    -0.015386     0.211434
 -0.549929   -0.219578    0.0910464   -0.811194    0.449179   -0.364323    0.262571   -0.0459643    0.0289445  -0.404436   -0.274928     0.345534    -0.0393082  -0.115589    -0.0402142   0.555036      0.130575    1.32126      0.343557     0.0482466  -0.140575   -0.111652    0.239089    0.210806     0.24331      0.479105
 -0.0476152  -0.328229    0.0325231   -0.26401    -0.21294     0.278881    0.177403    0.460842     0.0487114  -0.097315    0.763659     0.0955931    0.15837    -0.0723196   -0.205056    0.61881       0.449071   -0.311715     0.410554    -0.269088    0.0471425   0.113595    0.0771317  -0.919677     0.0595684   -0.64945
  0.497042    0.114328   -0.368584     0.200854   -0.642265    0.128596    0.0482892   0.800686     0.0282308  -0.279897   -0.0871576   -0.0945451   -0.10146    -0.459563     0.421279   -0.381173      0.275382   -0.481478    -0.230577    -0.189136    0.0806285   0.0102677   0.240145    0.379046    -0.0620069   -0.159556
  0.0260658  -0.255268    0.287094    -0.0416405   0.13659     0.411516   -0.0288326  -0.253481     0.140344    0.142314    0.630254    -0.151276     0.429407    0.0553145    0.421082   -0.123415      0.297079   -0.58545     -0.102913    -0.21563     0.128345    0.186951   -0.416304   -0.184779     0.00082233  -0.349291
  0.204775    0.0483076   0.0452049    0.0467209   0.135785    0.20023     0.396224   -0.413222     0.570032    0.643846    0.78198      0.286605     0.186587    0.176366    -0.204935   -0.0706799     0.257834    0.263551    -0.092813     0.105814    0.0417535  -0.219759   -0.340802    0.202888    -0.746015     0.209883
  0.144719   -0.0612633  -0.0310363   -0.018396   -0.188855   -0.035903    0.0351627  -0.00645199  -0.270211   -0.334776   -0.152588    -0.108036    -0.0829139  -0.0272078    0.156627    0.034785      0.261833    0.0701521   -0.0746423   -0.0371899   0.0472787   0.23396     0.0790934  -0.00617017   0.231814    -0.065238
 -0.635536    0.363677   -0.54088      0.20137    -1.18171     0.429468    0.170105   -0.577719    -0.397626   -0.280783    0.0960268   -0.313485    -0.65461     1.02432     -0.0823925   0.00199229    0.0512725   0.245287    -0.00806887   0.590727    0.231228   -0.0845463  -0.467971   -0.208605     0.333972    -0.312435
  0.278457    0.394095    0.0181455    0.208268    0.258014   -0.428075   -0.533181    0.863914     0.406816   -0.25371     0.00446612  -0.302388    -0.745132    0.290882    -0.293878    0.759992     -0.176605    0.553102     0.563639    -0.189451    0.229661   -0.800754   -0.641523   -0.133847    -0.163615    -0.246913
  0.471441   -0.237401   -0.215391     0.464792   -0.1991      0.375007    0.296096    0.693284    -0.36138     0.287213   -0.17636     -0.00127716   0.144244    0.650663     0.620856   -0.104448      0.396814    0.261437     0.89915     -0.371881    0.490294   -0.788599    0.572602    0.215613     0.189616    -0.372518
 -0.780773    0.0812198   0.131449     0.216972    0.389839    0.160683   -0.195066   -0.425345     0.3382      0.322602    0.0801876   -0.00289417  -0.357996    0.82952      0.0768466   0.346674     -0.390319    0.0546964    0.277393    -0.0452091   0.991163    0.239514   -0.51287    -0.234588     0.372979     0.187523
 -0.094482    0.548678   -0.422144     0.115694    0.0682837  -0.128652    0.49974     0.39751      0.605588   -0.460022   -0.539216     0.474364    -0.255102   -0.0959609   -0.332651    0.340818      0.0826123  -0.452266     0.204266    -0.339666    0.429878   -0.225239    0.953391    0.265855    -0.33823     -0.1041
 -0.124898   -0.174338   -0.130491    -0.10961     0.328611    0.159147   -0.168956   -0.256274    -0.0245809  -0.0943458  -0.0677484   -0.0835626   -0.10738     0.197024    -0.0514085   0.15169       0.066446    0.14336      0.426256     0.301432    0.197135   -0.143917    0.0537608  -0.0626763   -0.285024    -0.000538534
 -0.235935    0.199974    1.00709     -0.698673   -0.443186    0.0354428  -0.155627    0.0693522   -0.102323   -0.179046    0.0288493   -0.149965     0.360157    0.23457     -0.023928    0.296731     -0.280391   -0.206234    -0.141773    -0.513093   -0.221706   -0.212172    0.201304   -0.0587904    0.473666     0.382146
  0.0778693  -0.178936    0.124647    -0.246651   -0.189392    0.0277171  -0.0395468   0.151109     0.0705992   0.206139    0.245333     0.0264278    0.132121   -0.00608519   0.0710363  -0.166982     -0.191522   -0.262902    -0.048089    -0.100156   -0.326601   -0.149952   -0.0645406   0.0751195   -0.100754     0.0545406
  0.248333    0.409783   -0.185114     0.293645   -0.0264384  -0.322789   -0.023464    0.418568    -0.222347    0.0492497  -0.601283     0.0306662   -0.100393    0.0580632   -0.14761     0.000198343  -0.367492    0.327148    -0.255046     0.177638   -0.158524    0.043897    0.186048    0.193714     0.00136673   0.315215
 -0.163166    0.315148    0.688558    -0.304481   -0.907391   -0.945115    0.788132    0.41127      0.272795    0.310512    0.0972821    0.196977     0.0567334   0.0209343    0.813599   -0.121783     -1.01286     0.459746    -0.702137     0.314018    0.024326   -0.723654   -0.649595    0.187011     0.615082    -1.05737
 -0.736967   -0.248642   -0.0701726   -0.520756    0.0279507   0.122536    0.161768   -0.846299     0.503822   -0.589765    0.459242    -0.622681     0.30354    -0.161784     0.0923031   0.0654618     0.47767    -0.152154     0.523172    -0.316021    0.487427    0.110218    0.0179806   0.0785615   -0.362613    -0.435036
 -0.601223    0.58172    -0.0244543    0.189668    0.514298    0.247892   -0.139311   -0.351316     0.45773    -0.291274    0.362245    -0.00972158  -0.132441   -0.54102     -0.241628    0.224569     -0.358138   -0.314526    -0.482374     0.404081   -0.108451    0.605981   -0.0315271  -0.0536581   -0.284564    -0.428106
  0.237491    0.207503   -0.241322     0.180538   -0.553325    0.627987   -0.0898762  -0.551772    -0.227941    0.461418    0.100965    -0.0623328    0.052498    0.251257     0.33202    -0.310443      0.225592   -0.80948     -0.573023     0.24664     0.0632853   0.694301    0.342846    0.0102344   -0.308558    -0.186341[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407779
[ Info: iteration 2, average log likelihood -1.407768
[ Info: iteration 3, average log likelihood -1.407758
[ Info: iteration 4, average log likelihood -1.407748
[ Info: iteration 5, average log likelihood -1.407739
[ Info: iteration 6, average log likelihood -1.407731
[ Info: iteration 7, average log likelihood -1.407723
[ Info: iteration 8, average log likelihood -1.407715
[ Info: iteration 9, average log likelihood -1.407708
[ Info: iteration 10, average log likelihood -1.407701
┌ Info: EM with 100000 data points 10 iterations avll -1.407701
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
