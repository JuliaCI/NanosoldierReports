Julia Version 1.5.0-DEV.13
Commit dfcba8768f (2020-01-06 06:02 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed SortingAlgorithms ── v0.3.1
 Installed URIParser ────────── v0.4.0
 Installed PDMats ───────────── v0.9.10
 Installed CMake ────────────── v1.1.2
 Installed Rmath ────────────── v0.6.0
 Installed Blosc ────────────── v0.5.1
 Installed StaticArrays ─────── v0.12.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed LegacyStrings ────── v0.4.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed Distances ────────── v0.8.2
 Installed DataStructures ───── v0.17.7
 Installed HDF5 ─────────────── v0.12.5
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed BinDeps ──────────── v1.0.0
 Installed FileIO ───────────── v1.2.1
 Installed Distributions ────── v0.22.0
 Installed BinaryProvider ───── v0.5.8
 Installed StatsBase ────────── v0.32.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed Parameters ───────── v0.12.0
 Installed JLD ──────────────── v0.9.1
 Installed OrderedCollections ─ v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed FillArrays ───────── v0.8.2
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed StatsFuns ────────── v0.9.3
 Installed SpecialFunctions ─── v0.9.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.7
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.0
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_vnN71R/Project.toml`
 [no changes]
  Updating `/tmp/jl_vnN71R/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_xC0OY6/Project.toml`
 [no changes]
  Updating `/tmp/jl_xC0OY6/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_DTwfHW/Project.toml`
 [no changes]
  Updating `/tmp/jl_DTwfHW/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_PwHPIC/Project.toml`
 [no changes]
  Updating `/tmp/jl_PwHPIC/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_btFLxO/Project.toml`
 [no changes]
  Updating `/tmp/jl_btFLxO/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_btFLxO/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.0
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.0966776196222326e6, [36066.82824228458, 63933.17175771543], [-6097.926453577825 25130.701598763266 -20618.896613816287; 6064.096165974691 -25575.56499820033 21177.982298972354], [[39743.260079582935 -7372.099791082799 -5281.543835107185; -7372.0997910828 44603.66934892335 2874.105542906497; -5281.543835107184 2874.1055429064963 46141.77670831396], [59729.85955947002 6988.216191543819 5001.936424954535; 6988.216191543819 55250.18161504157 -2794.5731397337177; 5001.936424954534 -2794.5731397337177 54323.703794060864]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.548515e+03
      1       8.692049e+02      -6.793104e+02 |        6
      2       8.165547e+02      -5.265022e+01 |        2
      3       8.138171e+02      -2.737565e+00 |        0
      4       8.138171e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 813.8171344640914)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.061472
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.807267
[ Info: iteration 2, lowerbound -3.681683
[ Info: iteration 3, lowerbound -3.534393
[ Info: iteration 4, lowerbound -3.352313
[ Info: iteration 5, lowerbound -3.151877
[ Info: iteration 6, lowerbound -2.957829
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.789104
[ Info: iteration 8, lowerbound -2.656152
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.550461
[ Info: iteration 10, lowerbound -2.464585
[ Info: iteration 11, lowerbound -2.413592
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.375629
[ Info: iteration 13, lowerbound -2.342282
[ Info: iteration 14, lowerbound -2.319332
[ Info: iteration 15, lowerbound -2.308041
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.303058
[ Info: iteration 17, lowerbound -2.299263
[ Info: iteration 18, lowerbound -2.299257
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan  8 21:09:50 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan  8 21:10:00 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Jan  8 21:10:02 2020: EM with 272 data points 0 iterations avll -2.061472
5.8 data points per parameter
, Wed Jan  8 21:10:05 2020: GMM converted to Variational GMM
, Wed Jan  8 21:10:14 2020: iteration 1, lowerbound -3.807267
, Wed Jan  8 21:10:14 2020: iteration 2, lowerbound -3.681683
, Wed Jan  8 21:10:14 2020: iteration 3, lowerbound -3.534393
, Wed Jan  8 21:10:14 2020: iteration 4, lowerbound -3.352313
, Wed Jan  8 21:10:14 2020: iteration 5, lowerbound -3.151877
, Wed Jan  8 21:10:14 2020: iteration 6, lowerbound -2.957829
, Wed Jan  8 21:10:15 2020: dropping number of Gaussions to 7
, Wed Jan  8 21:10:15 2020: iteration 7, lowerbound -2.789104
, Wed Jan  8 21:10:15 2020: iteration 8, lowerbound -2.656152
, Wed Jan  8 21:10:15 2020: dropping number of Gaussions to 4
, Wed Jan  8 21:10:15 2020: iteration 9, lowerbound -2.550461
, Wed Jan  8 21:10:15 2020: iteration 10, lowerbound -2.464585
, Wed Jan  8 21:10:15 2020: iteration 11, lowerbound -2.413592
, Wed Jan  8 21:10:15 2020: dropping number of Gaussions to 3
, Wed Jan  8 21:10:15 2020: iteration 12, lowerbound -2.375629
, Wed Jan  8 21:10:15 2020: iteration 13, lowerbound -2.342282
, Wed Jan  8 21:10:15 2020: iteration 14, lowerbound -2.319332
, Wed Jan  8 21:10:15 2020: iteration 15, lowerbound -2.308041
, Wed Jan  8 21:10:15 2020: dropping number of Gaussions to 2
, Wed Jan  8 21:10:15 2020: iteration 16, lowerbound -2.303058
, Wed Jan  8 21:10:15 2020: iteration 17, lowerbound -2.299263
, Wed Jan  8 21:10:15 2020: iteration 18, lowerbound -2.299257
, Wed Jan  8 21:10:15 2020: iteration 19, lowerbound -2.299255
, Wed Jan  8 21:10:15 2020: iteration 20, lowerbound -2.299254
, Wed Jan  8 21:10:15 2020: iteration 21, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 22, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 23, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 24, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 25, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 26, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 27, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 28, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 29, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 30, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 31, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 32, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 33, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 34, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 35, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 36, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 37, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 38, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 39, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 40, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 41, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 42, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 43, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 44, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 45, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 46, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 47, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 48, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 49, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: iteration 50, lowerbound -2.299253
, Wed Jan  8 21:10:15 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398615]
β = [178.04509222601382, 95.95490777398615]
m = [4.250300733269911 79.28686694436185; 2.00022925777537 53.8519871724613]
ν = [180.04509222601382, 97.95490777398615]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484843 -0.007644049042327528; 0.0 0.008581705166333562], [0.37587636119484097 -0.008953123827346214; 0.0 0.01274866477740938]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9910076560477411
avll from llpg:  -0.9910076560477408
avll direct:     -0.9910076560477408
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9905856155545718
avll from llpg:  -0.9905856155545719
avll direct:     -0.9905856155545719
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.103786    -0.157984      0.186616    -0.14653     -0.077722    -0.0603442    0.0785328    0.0844148   -0.0417829  -0.102463    -0.0665389    -0.0274824   -0.146869    -0.0858531   0.0154594   -0.0335875    0.0365361   0.00130885   -0.071112     0.064762     0.00526264  -0.183864      0.168906      0.0202831    0.0858588    0.0385577
 -0.12662     -0.0364852    -0.0861588   -0.0555257    0.0455331   -0.0349206   -0.0851614    0.065434    -0.0434453  -0.00855859  -0.0773301    -0.00244881  -0.144221     0.199066    0.174547    -0.0376709   -0.0183193  -0.00230605   -0.0095882   -0.124399     0.0204993   -0.144327      0.181971      0.206431    -0.0242466    0.0300873
 -0.0534566   -0.0505046    -0.0384783    0.13296     -0.0979026   -0.0127497    0.260226     0.0399294   -0.229733    0.136575    -0.0282931     0.0407828    0.0124561   -0.106234    0.0628597   -0.0857206   -0.145686    0.0164712    -0.0435233   -0.151209     0.107563     0.0278594    -0.110371      0.0185362   -0.0818303   -0.0107421
 -0.0199804    0.0157574    -0.0988845   -0.163426    -0.18424      0.00445803  -0.0196946   -0.00558074   0.0704987  -0.0260863   -0.0727004     0.0311253    0.0886683   -0.100846   -0.0544412   -0.11243      0.0702851   0.209705      0.0899237    0.0256445   -0.0543112    0.0236344    -0.00121743   -0.0766148    0.0573967   -0.074781
 -0.0470061    0.0787299    -0.00532619   0.0330853   -0.115502    -0.0544206    0.0235501    0.0453778    0.056991    0.271169     0.0548228     0.0123957   -0.0736475   -0.0458936   0.0739411    0.153481    -0.0560946  -0.0824688    -0.0934668    0.11297      0.0264461   -0.0251863    -0.0611608    -0.094179    -0.0987836    0.0144517
  0.123487    -0.000477156  -0.023846    -0.0575433   -0.165371    -0.0369904   -0.100981    -0.00505532   0.0459419  -0.105616     0.0437832     0.0702431   -0.279856    -0.0576109   0.0721464    0.07512     -0.111299   -0.0835997    -0.0866235    0.0464585   -0.0457454   -0.0735307     0.0593825    -0.0403435    0.03594     -0.0288243
  0.00719368  -0.0769855    -0.111465     0.0717686   -0.139443    -0.121607     0.0595996    0.0821619   -0.0931891   0.0207876    0.056953      0.0690944    0.16662     -0.0231532  -0.0967124   -0.00138987  -0.0859166  -0.0781305    -0.0562961    0.00891071  -0.0514503   -0.130369     -0.0365031     0.0269571    0.0308692   -0.00889943
 -0.026938     0.0311716    -0.231426     0.0685825   -0.00273186  -0.0465079   -0.00321687  -0.0278619    0.078675    0.165898     0.0234396    -0.00523799  -0.0269773   -0.117515   -0.166057    -0.267084     0.0228343   0.0153612     0.0671051    0.00311491  -0.140772     0.107533     -0.0424594     0.0394619    0.0399734    0.0938051
 -0.111547     0.103504      0.134026    -0.153047     0.0558662   -0.109617    -0.00897131   0.0759819    0.083255   -0.145464     0.0384461     0.0541277   -0.00210615  -0.099561    0.111222     0.00850179  -0.215216   -0.100368     -0.0375305    0.100711     0.0805346   -0.135784      0.0251407    -0.0465725   -0.111394    -0.117995
  0.00613906  -0.167347      0.158824    -0.125175     0.0868419   -0.0467574   -0.161716     0.0147678    0.084312   -0.063002    -0.269229      0.104693     0.139524     0.117991   -0.0445241    0.220095    -0.038172    0.128737     -0.118455     0.0504212    0.0334082   -0.0600924     0.0363211    -0.0302814   -0.073476     0.028243
  0.110321    -0.106976      0.0282515    0.0691675    0.0552084    0.0277753    0.0200867    0.107528    -0.145316    0.072754     0.0533536    -0.0511483   -0.107526    -0.244837    0.0341568   -0.252647    -0.0251919   0.0849491     0.0427623   -0.0168111    0.0320987    0.0262894    -0.0421606     0.130356     0.0872632   -0.114789
 -0.0455926    0.0372564     0.00975055  -0.0304836    0.135707     0.113435     0.0279509   -6.81926e-5   0.0660148  -0.0890492    0.0683518     0.0704093   -0.0107053    0.0117698   0.0378267   -0.0113384   -0.0476383   0.0276891    -0.209222     0.067713    -0.0647506    0.0690968    -0.0636111     0.250255     0.0828948   -0.119933
  0.0796735    0.0564018     0.11539     -0.252638    -0.0952412    0.0528889   -0.0100814   -0.0922563   -0.0328881   0.142951    -0.0388713     0.187541    -0.0491987    0.057956   -0.117883    -0.00195865   0.02001    -0.0460976     0.206218     0.132257    -0.081886     0.0481181     0.0464927     0.0884361   -0.0506687   -0.195461
 -0.0326372   -0.0592262    -0.0905125    0.137646    -0.0431701    0.0694259   -0.110213     0.0218032   -0.146544    0.0253976   -0.00538512    0.0760504   -0.0953547   -0.14624     0.090063     0.0369136    0.0868458  -0.0645402    -0.113711     0.0119997   -0.00432411  -0.057917     -0.032356      0.026744    -0.0503798    0.136816
  0.0421369    0.0375196    -0.0196435    0.0398787    0.0964239    0.00233922   0.0207199    0.208031     0.0932456  -0.0218716    0.133901     -0.102627    -0.15035      0.0347206   0.00161891   0.0595216   -0.0382205  -0.13401      -0.0160671   -0.0250011    0.254231     0.0481615     0.0483041     0.0464428   -0.0366786   -0.0979954
  0.0906625    0.00960988   -0.0858691   -0.0798122   -0.0137036    0.0484686   -0.0488869    0.00592618   0.0241598  -0.020269    -0.0898183     0.0487328   -0.139914     0.0195518  -0.150554     0.0668832    0.0315192   0.0824637     0.106577     0.0376329    0.269695    -0.0902066     0.134056      0.024078     0.0660744    0.0495049
 -0.131569    -0.0062558    -0.0501606    0.216458     0.145923    -0.0399645    0.121274    -0.0305151   -0.121705    0.0925272    0.0257284    -0.0838974    0.0226589   -0.158777    0.0728297    0.00207041  -0.0766726  -0.119343      0.0362685   -0.149501    -0.0618581   -0.135839     -0.0721364     0.0871755   -0.032797     0.0663772
 -0.0829162   -0.119841     -0.139417     0.0710026    0.00202603  -0.0574325    0.00805675   0.0210998    0.0406913  -0.0449842    0.103732      0.0163907    0.134673     0.0767248  -0.175935     0.0987407    0.0682519  -0.000358576   0.138895    -0.289616     0.0748886   -0.0569257     0.129584      0.00693679   0.00794108  -0.021849
  0.109895     0.102746     -0.049489     0.113656     0.0417809   -0.00779831   0.069508    -0.106257    -0.121561    0.0620657    0.0331632     0.0137284    0.139784    -0.134125   -0.0768867   -0.0504178    0.0991947   0.0403998     0.0389251    0.121597     0.177088    -0.0758965     0.0538396     0.121087    -0.140355     0.060247
 -0.148994    -0.0317344     0.104052    -0.0468825    0.324329     0.0528978   -0.198631    -0.0142979    0.0777265  -0.0407825   -0.0228979     0.0174633    0.00804522   0.089464    0.0444462   -0.113219     0.0877502  -0.113255     -0.0424516    0.056659     0.0108548    0.175373      0.0175916    -0.0594248    0.0079067   -0.127586
 -0.132673    -0.0348276    -0.123735     0.0548515    0.263898     0.0107866   -0.147973     0.0935928   -0.0447378  -0.11666     -0.022745      0.0462194    0.00862535   0.118016   -0.0619991    0.00657224  -0.06606    -0.0474985    -0.0286334   -0.00750376  -0.123581    -0.0521407    -0.137071      0.0687603   -0.0789461    0.0860197
  0.176854     0.0914156    -0.208963     0.00218269  -0.125944     0.195628    -0.167505     0.108741     0.0819393   0.0816026    0.0316653    -0.00219733   0.0116587   -0.133187   -0.088529     0.0168001    0.0412654   0.145783     -0.0645849    0.0726143    0.16521     -0.000657428  -0.00081221   -0.111661    -0.120635    -0.0914182
 -0.0442877    0.0110643    -0.0613088    0.0731681    0.0776491   -0.158566    -0.152584    -0.075869    -0.075588   -0.0321077    0.026617      0.023132     0.0541389   -0.0324405   0.0462123   -0.185753    -0.132502    0.0148363     0.0787143   -0.00928616  -0.0136728    0.0324798     0.0609789     0.0362621   -0.104043     0.000816224
  0.0796312    0.176964     -0.037661     0.133418    -0.121362    -0.0228458    0.122365    -0.035298     0.175544   -0.0232868   -0.0707163     0.00556592   0.00832151  -0.158731   -0.0283814   -0.09347     -0.077482    0.198828     -0.00708229  -0.0237847    0.0250354    0.0267638     0.00260007   -0.0724189   -0.0294768   -0.0631265
  0.0512371   -0.193697      0.00905637  -0.0311872   -0.00191396   0.0702006   -0.103016     0.0339638    0.099847    0.0486355    0.0106738     0.0168987    0.00627678  -0.0281394  -0.0759253   -0.0403027    0.0813191  -0.0266253    -0.012652    -0.182103    -0.244734    -0.00848      -0.0885075     0.126013    -0.0527275   -0.049458
  0.0812547    0.034541     -0.0494901    0.0395326    0.0652879    0.0722638    0.0965546    0.0777137    0.179352   -0.0933729   -0.0506651     0.124051     0.0526403   -0.0307166   0.0894939    0.0420463    0.0448107  -0.0622396     0.026698    -0.119877    -0.0692226    0.0963207     0.0253309    -0.0269077    0.117028    -0.12299
 -0.141788    -0.173695     -0.102723     0.0134162   -0.0257639    0.0601968   -0.0901004    0.168207    -0.118848   -0.106335    -0.0390594    -0.0270293    0.0397374   -0.0740423  -0.261754     0.0124723   -0.0123005  -0.0640875    -0.0864198    0.0833999   -0.0859258    0.00496724    0.00122245   -0.182587     0.00141283  -0.0394783
 -0.0107023   -0.0588929     0.067325     0.0523397    0.0682811    0.0541983   -0.0149762    0.129833    -0.150436   -0.16881     -0.0494754     0.0782856   -0.104943    -0.0750667   0.0632628   -0.0343437    0.0169136   0.169397      0.0355759    0.06188      0.0205564   -0.158203     -0.000421024   0.204783    -0.0399208   -0.0921007
 -0.0426205   -0.0978195     0.156877     0.171467     0.125491     0.0172992   -0.0239134    0.090224    -0.168928    0.0546535    0.000676153  -0.111428    -0.0152351    0.167217   -0.11098     -0.0108438   -0.0164174  -0.118104     -0.114775     0.0714437   -0.0410947    0.236983     -0.00424276    0.0651137   -0.0299332   -0.0124158
 -0.202002     0.0807381     0.0179155   -0.232459     0.0340547    0.0496999    0.179324     0.105829    -0.0562602   0.125254    -0.0632835    -0.0900133   -0.0345657    0.163446    0.125939     0.112864    -0.0965541  -0.155497      6.09465e-5   0.0785241   -0.0505687   -0.00700976    0.0340377    -0.186734    -0.0611681   -0.0313817
  0.133346     0.146135     -0.0741469   -0.00194628  -0.0726006    0.0398419    0.0424593   -0.114446    -0.0345718   0.0609725   -0.0998421     0.121112    -0.00801079  -0.0630056  -0.0277418    0.0277883   -0.073113   -0.0960565    -0.15515     -0.0136598    0.138254     0.0831915     0.0891853    -0.00373691  -0.0817338   -0.0170554
 -0.0973657   -0.020536      0.066092     0.250087     0.00402937   0.0719725    0.03146     -0.11186      0.0660105   0.0441247   -0.0721325    -0.117871    -0.0377042    0.0341555   0.0847054    0.0927432    0.0570495  -0.0672687     0.0426243    0.149826     0.0798387   -0.0814888     0.0852979     0.00770331  -0.0232225   -0.0894545kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4109862296697315
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411085
[ Info: iteration 2, average log likelihood -1.410984
[ Info: iteration 3, average log likelihood -1.410460
[ Info: iteration 4, average log likelihood -1.405379
[ Info: iteration 5, average log likelihood -1.390856
[ Info: iteration 6, average log likelihood -1.384339
[ Info: iteration 7, average log likelihood -1.383180
[ Info: iteration 8, average log likelihood -1.382574
[ Info: iteration 9, average log likelihood -1.382279
[ Info: iteration 10, average log likelihood -1.382140
[ Info: iteration 11, average log likelihood -1.382069
[ Info: iteration 12, average log likelihood -1.382029
[ Info: iteration 13, average log likelihood -1.382004
[ Info: iteration 14, average log likelihood -1.381985
[ Info: iteration 15, average log likelihood -1.381970
[ Info: iteration 16, average log likelihood -1.381958
[ Info: iteration 17, average log likelihood -1.381947
[ Info: iteration 18, average log likelihood -1.381936
[ Info: iteration 19, average log likelihood -1.381926
[ Info: iteration 20, average log likelihood -1.381916
[ Info: iteration 21, average log likelihood -1.381907
[ Info: iteration 22, average log likelihood -1.381898
[ Info: iteration 23, average log likelihood -1.381890
[ Info: iteration 24, average log likelihood -1.381883
[ Info: iteration 25, average log likelihood -1.381877
[ Info: iteration 26, average log likelihood -1.381871
[ Info: iteration 27, average log likelihood -1.381866
[ Info: iteration 28, average log likelihood -1.381862
[ Info: iteration 29, average log likelihood -1.381858
[ Info: iteration 30, average log likelihood -1.381854
[ Info: iteration 31, average log likelihood -1.381852
[ Info: iteration 32, average log likelihood -1.381849
[ Info: iteration 33, average log likelihood -1.381847
[ Info: iteration 34, average log likelihood -1.381845
[ Info: iteration 35, average log likelihood -1.381843
[ Info: iteration 36, average log likelihood -1.381842
[ Info: iteration 37, average log likelihood -1.381841
[ Info: iteration 38, average log likelihood -1.381840
[ Info: iteration 39, average log likelihood -1.381839
[ Info: iteration 40, average log likelihood -1.381838
[ Info: iteration 41, average log likelihood -1.381837
[ Info: iteration 42, average log likelihood -1.381837
[ Info: iteration 43, average log likelihood -1.381836
[ Info: iteration 44, average log likelihood -1.381836
[ Info: iteration 45, average log likelihood -1.381836
[ Info: iteration 46, average log likelihood -1.381835
[ Info: iteration 47, average log likelihood -1.381835
[ Info: iteration 48, average log likelihood -1.381835
[ Info: iteration 49, average log likelihood -1.381835
[ Info: iteration 50, average log likelihood -1.381834
┌ Info: EM with 100000 data points 50 iterations avll -1.381834
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4110847234818449
│     -1.4109842192113977
│      ⋮
└     -1.3818344355405232
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.381969
[ Info: iteration 2, average log likelihood -1.381846
[ Info: iteration 3, average log likelihood -1.381521
[ Info: iteration 4, average log likelihood -1.378568
[ Info: iteration 5, average log likelihood -1.368087
[ Info: iteration 6, average log likelihood -1.358775
[ Info: iteration 7, average log likelihood -1.355452
[ Info: iteration 8, average log likelihood -1.353936
[ Info: iteration 9, average log likelihood -1.352893
[ Info: iteration 10, average log likelihood -1.352080
[ Info: iteration 11, average log likelihood -1.351413
[ Info: iteration 12, average log likelihood -1.350849
[ Info: iteration 13, average log likelihood -1.350363
[ Info: iteration 14, average log likelihood -1.349934
[ Info: iteration 15, average log likelihood -1.349533
[ Info: iteration 16, average log likelihood -1.349124
[ Info: iteration 17, average log likelihood -1.348656
[ Info: iteration 18, average log likelihood -1.348064
[ Info: iteration 19, average log likelihood -1.347317
[ Info: iteration 20, average log likelihood -1.346492
[ Info: iteration 21, average log likelihood -1.345732
[ Info: iteration 22, average log likelihood -1.345085
[ Info: iteration 23, average log likelihood -1.344626
[ Info: iteration 24, average log likelihood -1.344339
[ Info: iteration 25, average log likelihood -1.344145
[ Info: iteration 26, average log likelihood -1.344002
[ Info: iteration 27, average log likelihood -1.343889
[ Info: iteration 28, average log likelihood -1.343793
[ Info: iteration 29, average log likelihood -1.343707
[ Info: iteration 30, average log likelihood -1.343623
[ Info: iteration 31, average log likelihood -1.343536
[ Info: iteration 32, average log likelihood -1.343442
[ Info: iteration 33, average log likelihood -1.343333
[ Info: iteration 34, average log likelihood -1.343202
[ Info: iteration 35, average log likelihood -1.343045
[ Info: iteration 36, average log likelihood -1.342856
[ Info: iteration 37, average log likelihood -1.342633
[ Info: iteration 38, average log likelihood -1.342369
[ Info: iteration 39, average log likelihood -1.342058
[ Info: iteration 40, average log likelihood -1.341724
[ Info: iteration 41, average log likelihood -1.341434
[ Info: iteration 42, average log likelihood -1.341207
[ Info: iteration 43, average log likelihood -1.341024
[ Info: iteration 44, average log likelihood -1.340871
[ Info: iteration 45, average log likelihood -1.340740
[ Info: iteration 46, average log likelihood -1.340626
[ Info: iteration 47, average log likelihood -1.340527
[ Info: iteration 48, average log likelihood -1.340444
[ Info: iteration 49, average log likelihood -1.340375
[ Info: iteration 50, average log likelihood -1.340317
┌ Info: EM with 100000 data points 50 iterations avll -1.340317
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3819689891538922
│     -1.3818460772601955
│      ⋮
└     -1.340317248890272
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.340433
[ Info: iteration 2, average log likelihood -1.340217
[ Info: iteration 3, average log likelihood -1.339509
[ Info: iteration 4, average log likelihood -1.333068
[ Info: iteration 5, average log likelihood -1.314274
[ Info: iteration 6, average log likelihood -1.298818
[ Info: iteration 7, average log likelihood -1.291780
[ Info: iteration 8, average log likelihood -1.288279
[ Info: iteration 9, average log likelihood -1.286926
[ Info: iteration 10, average log likelihood -1.286256
[ Info: iteration 11, average log likelihood -1.285846
[ Info: iteration 12, average log likelihood -1.285578
[ Info: iteration 13, average log likelihood -1.285374
[ Info: iteration 14, average log likelihood -1.285183
[ Info: iteration 15, average log likelihood -1.284970
[ Info: iteration 16, average log likelihood -1.284723
[ Info: iteration 17, average log likelihood -1.284473
[ Info: iteration 18, average log likelihood -1.284274
[ Info: iteration 19, average log likelihood -1.284144
[ Info: iteration 20, average log likelihood -1.284062
[ Info: iteration 21, average log likelihood -1.284005
[ Info: iteration 22, average log likelihood -1.283965
[ Info: iteration 23, average log likelihood -1.283935
[ Info: iteration 24, average log likelihood -1.283912
[ Info: iteration 25, average log likelihood -1.283894
[ Info: iteration 26, average log likelihood -1.283879
[ Info: iteration 27, average log likelihood -1.283867
[ Info: iteration 28, average log likelihood -1.283857
[ Info: iteration 29, average log likelihood -1.283848
[ Info: iteration 30, average log likelihood -1.283841
[ Info: iteration 31, average log likelihood -1.283834
[ Info: iteration 32, average log likelihood -1.283828
[ Info: iteration 33, average log likelihood -1.283822
[ Info: iteration 34, average log likelihood -1.283816
[ Info: iteration 35, average log likelihood -1.283811
[ Info: iteration 36, average log likelihood -1.283805
[ Info: iteration 37, average log likelihood -1.283799
[ Info: iteration 38, average log likelihood -1.283792
[ Info: iteration 39, average log likelihood -1.283785
[ Info: iteration 40, average log likelihood -1.283777
[ Info: iteration 41, average log likelihood -1.283769
[ Info: iteration 42, average log likelihood -1.283759
[ Info: iteration 43, average log likelihood -1.283748
[ Info: iteration 44, average log likelihood -1.283735
[ Info: iteration 45, average log likelihood -1.283721
[ Info: iteration 46, average log likelihood -1.283704
[ Info: iteration 47, average log likelihood -1.283685
[ Info: iteration 48, average log likelihood -1.283662
[ Info: iteration 49, average log likelihood -1.283635
[ Info: iteration 50, average log likelihood -1.283604
┌ Info: EM with 100000 data points 50 iterations avll -1.283604
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3404325001980242
│     -1.3402171036653252
│      ⋮
└     -1.2836038553239801
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.283784
[ Info: iteration 2, average log likelihood -1.283502
[ Info: iteration 3, average log likelihood -1.282353
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.268220
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.239360
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.216793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.204986
[ Info: iteration 8, average log likelihood -1.203396
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.186606
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.211987
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.210470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.205271
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.193519
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.193369
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.209366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.208717
[ Info: iteration 17, average log likelihood -1.206091
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.188321
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.184298
[ Info: iteration 20, average log likelihood -1.220989
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.198148
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.202180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.192715
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.187076
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.209579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.198365
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.190967
[ Info: iteration 28, average log likelihood -1.206129
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.185434
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.211308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.200629
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.193813
[ Info: iteration 33, average log likelihood -1.195358
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.181139
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.198088
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.213035
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.203746
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.191973
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.199831
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.201522
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.194608
[ Info: iteration 42, average log likelihood -1.197990
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.182526
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     8
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.192125
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.216713
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.203151
[ Info: iteration 47, average log likelihood -1.201400
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.184747
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.181510
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.206640
┌ Info: EM with 100000 data points 50 iterations avll -1.206640
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2837837842065458
│     -1.2835015036066337
│      ⋮
└     -1.206639811393446
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.202747
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.188590
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     11
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.184866
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     12
│     15
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.162086
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.137505
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     12
│      ⋮
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.092006
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     21
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.098392
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120072
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.085394
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073498
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.089411
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.109277
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.088527
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.089175
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.062713
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.100373
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.114378
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.075680
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.064735
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.116593
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│     12
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.095966
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.076165
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     20
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.097943
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.089006
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.076079
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099023
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.089920
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.087582
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.104860
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.089617
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.051044
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.118857
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.091585
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.078396
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.089256
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081410
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.073132
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.112269
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.074550
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.082919
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.085333
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.084948
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.087123
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.109076
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│     11
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.079552
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.061507
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.098630
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.089856
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│      ⋮
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.087781
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.091135
┌ Info: EM with 100000 data points 50 iterations avll -1.091135
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.202747072858989
│     -1.1885900789942432
│      ⋮
└     -1.0911346283803331
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4109862296697315
│     -1.4110847234818449
│     -1.4109842192113977
│     -1.4104602726068718
│      ⋮
│     -1.0898557844090775
│     -1.0877807498915704
└     -1.0911346283803331
32×26 Array{Float64,2}:
 -0.0963918  -0.0842222   -0.099042      0.104749     -0.0187454    -0.0156181   -0.0207912   0.0337282    -0.0445489   -0.0137566    0.0383127    0.0294247    0.0352294    -0.0139546    -0.0990328    0.0531075    0.0595917  -0.0213147    0.0353145   -0.167554     0.0528772   -0.0553844   0.0695136    0.0226792    -0.0205068    0.059311
  0.044858    0.0274999   -0.0947804    -0.0900198     0.000357784   0.0465977   -0.0473688   0.0396581     0.00959826   0.00323728  -0.0951236    0.0605388   -0.157782     -0.000383922  -0.157616     0.0592339    0.0361313   0.0470357    0.114008     0.0356672    0.260311    -0.082456    0.110133     0.0080166     0.0785049    0.0324608
 -0.13681    -0.0337765   -0.11684       0.0647033     0.263755      0.0123687   -0.144789    0.093372     -0.0204956   -0.113224    -0.0331826    0.0874005    0.00152401    0.131393     -0.0442803    0.0256805   -0.0660439  -0.0414797   -0.0277479   -0.00551387  -0.134099    -0.0520547  -0.131668     0.0642091    -0.0640532    0.11177
  0.0898277  -0.152108     0.155919     -0.116486     -0.0743471    -0.0264609    0.062092    0.0767625    -0.0478042   -0.0709183   -0.0693382   -0.0246318   -0.121714     -0.0855622    -0.0063259    0.0115293    0.0406963  -0.029154    -0.0485448    0.0726125    0.0192833   -0.179281    0.188638     0.0248231     0.0687659    0.0381152
  0.0473382   0.0648872   -0.0827755     0.0311176     0.0778092     0.00591954   0.0228989   0.195437      0.0968777   -0.0469403    0.133232    -0.0997451   -0.150174      0.0270094    -0.0291392    0.0238119   -0.0337225  -0.122459    -0.00774458  -0.0206843    0.252276     0.0549487   0.0443943    0.0325629    -0.0530234   -0.103037
 -0.193308    0.0855511   -0.0202216    -0.212559      0.0223633     0.0472896    0.162307    0.0933864    -0.0207973    0.119466    -0.0424256   -0.105254    -0.0355495     0.144447      0.144063     0.143359    -0.0955037  -0.16839     -0.0109389    0.0817735   -0.0315596   -0.0210226   0.0470179   -0.195641     -0.057853    -0.0472969
 -0.0412862   0.358594    -0.0496235     0.0474848     0.212419     -0.0535783    0.0222435  -0.13456       0.0484966    0.230961     0.0619889    0.0156959    0.139701     -0.0892896     0.0528547    0.118877    -0.0524236  -0.124348    -0.110756     0.0226766    0.00416856  -0.0398473  -0.211134    -0.123263     -0.267831     0.0239205
 -0.0320499  -0.227947    -0.0453405     0.0323971    -0.409892     -0.0544988    0.0245494   0.289595      0.159756     0.260432     0.0437326    0.00206668  -0.341284     -0.0239166     0.0597306    0.11085     -0.0590275  -0.164421    -0.0279862    0.140501     0.0119892    0.0260948   0.07589     -0.0380976     0.128225     0.036058
 -0.0625772  -0.0471904   -0.044005      0.131295     -0.105537     -0.0458264    0.283328    0.064581     -0.211144     0.135759    -0.0308268    0.0407461    0.0401043    -0.107401      0.0763399   -0.0836508   -0.139338    0.023049    -0.0524383   -0.174414     0.0878725    0.0257572  -0.118299     0.0321761    -0.0634614   -0.0255509
  0.0824961   0.172702    -0.0303525     0.128106     -0.100629     -0.0645047    0.114107   -0.0481411     0.207465    -0.0181846   -0.0758372    0.00959461   0.0798007    -0.162096     -0.0212137   -0.0762024   -0.0705971   0.197611    -0.00778659  -0.0174034    0.0156447    0.0724532  -0.00042084  -0.107129     -0.0105226   -0.12471
  0.0886191   0.157667    -0.226018      0.0185806    -0.0664619     0.0603594    0.0651992  -0.0846941    -0.016215    -0.0439618   -0.135723     0.118037    -0.000463133  -0.0953915    -0.110059     0.0150498   -0.0736327  -0.0965811   -0.162889     0.0333273   -0.679364     0.135288   -0.555148    -0.00289822   -0.00505454   0.0239729
  0.12132     0.123897     0.144693     -0.0113633    -0.0998938     0.0468005    0.0464847  -0.10596      -0.0519211    0.117568    -0.0567741    0.11606     -0.0150185     0.0496016     0.0537421    0.038605    -0.0733388  -0.0997922   -0.157644    -0.118095     0.810133    -0.0151066   0.72858     -0.000934689  -0.133035    -0.131536
 -0.162612   -0.175386    -0.101111      0.0131819    -0.0195759     0.0532032   -0.0951928   0.209317     -0.118446    -0.108329    -0.0428062   -0.0198616    0.0398436    -0.0602753    -0.255705     0.0115585   -0.0485864  -0.0433575   -0.0890527    0.0733368   -0.087241     0.014798    0.00280075  -0.181608      0.00903699  -0.0385534
 -0.0922412   0.0513255    0.0177555    -0.031442      0.109777      0.113342     0.0172145  -0.000599008   0.0683781   -0.0872123    0.0458637    0.058827     0.0221372     0.0191691     0.0428832   -0.00821755  -0.0456954   0.0280032   -0.209268     0.0950858   -0.118152     0.0508212  -0.0655751    0.264314      0.076501    -0.0832177
  0.010733   -0.166102     0.156835     -0.117029      0.0365077    -0.0582401   -0.124673    0.0324928     0.0760657   -0.0709631   -0.243011    -0.195214     0.133585      0.553362     -0.0524794    0.238366    -0.0366328   0.138788    -0.11933      0.0623268    0.0309602   -0.0539322   0.0326173   -0.036771     -0.145443     0.0488291
  0.0015604  -0.172233     0.149414     -0.117464      0.275597     -0.00871089  -0.150338    0.00457729    0.076427    -0.0469943   -0.223081     0.790358     0.127661     -0.685102     -0.00859245   0.153316     0.0546708   0.0731597   -0.113471     0.0499723    0.0304546   -0.0492117   0.0333994    0.10269       0.117239     0.048605
 -0.0480981   0.0196121    0.00842963   -0.266191      0.0737746    -0.0941527   -0.147122   -0.0190271    -0.204088    -0.0321485   -0.261587     0.191012     0.0602986     0.0300492     0.0467815   -0.207741    -0.35048     0.020596     0.14793     -0.0571193    0.0764376    0.0318532  -0.0489006   -0.394688     -0.0984164    0.00989815
 -0.0453097   0.00668517  -0.0775862     0.331257      0.050127     -0.15883     -0.152691   -0.0892665     0.0181784   -0.0315348    0.261741    -0.0925498    0.0542149    -0.0509568     0.046254    -0.185365     0.0300793   0.00630595   0.0762697    0.0272421   -0.0862038    0.0314288   0.137009     0.345137     -0.109317     5.17918e-5
  0.148329    0.0980737   -0.0946512     0.112103      0.227533     -0.0343499    0.0609339  -0.289152     -0.103041     0.0787956    0.033224     0.0200765    0.138962     -0.107171     -0.49321     -0.502597     0.255572    0.0410693    0.0415092    0.118538     0.197389    -0.0757557   0.0416135    0.107039     -0.14096     -0.249801
  0.0700033   0.102537    -0.000562771   0.125741     -0.187141     -0.0140661    0.0802022   0.0366375    -0.117246     0.0468799    0.0332978    0.0171785    0.139963     -0.130455      0.35811      0.280162     0.0222167   0.0407099    0.133067     0.118672     0.170098    -0.0756619   0.0311898    0.138016     -0.139914     0.232457
  0.169557    0.0966819   -0.200524     -0.000691969  -0.118506      0.183035    -0.158724    0.123848      0.0640947    0.085647     0.0387075   -0.00314123   0.00331686   -0.113195     -0.0715373    0.0192606    0.0413238   0.132379    -0.0413025    0.0586657    0.163268     0.0178512  -0.00621257  -0.135966     -0.0914078   -0.0738312
 -0.1022      0.00398641  -0.0643183     0.209178      0.121886     -0.0172459    0.124384   -0.0168927    -0.162822     0.0909384    0.0452509   -0.117297     0.0243222    -0.148762      0.0412433    0.0325252   -0.0637092  -0.120364     0.0446832   -0.146074    -0.0831712   -0.138387   -0.0781861    0.0914096    -0.0491044    0.0789872
  0.0602148  -0.19319      0.00635212   -0.0326069     0.0295265     0.0880922   -0.103677    0.036152      0.116757     0.0257662    0.00644289   0.00339669   0.00907352   -0.0484332    -0.0801063   -0.0497336    0.0838533  -0.0259766   -0.0210214   -0.192483    -0.242257    -0.0213452  -0.0976286    0.119165     -0.0510273   -0.0643006
 -0.0422825  -0.0479147    0.0660827     0.00772305    0.0632391     0.0564703   -0.0134505   0.128768     -0.123101    -0.124566    -0.0565572    0.0192793   -0.0941146    -0.0469432     0.0630128    0.0183784    0.0126133   0.146698     0.0146929    0.048654     0.00561066  -0.134188    0.00435566   0.181747     -0.0483932   -0.0502484
 -0.0203946   0.023343    -0.095189     -0.162138     -0.187945      0.0190239   -0.0193558   0.000394422   0.0702108   -0.0199558   -0.0795879    0.0169136    0.0343107    -0.131452     -0.0493493   -0.119797     0.0703808   0.235465     0.0822894    0.00837187  -0.0555829    0.0229417  -0.00433615  -0.0794826     0.0558354   -0.0750258
 -0.106692   -0.0117651    0.0856982     0.242061      0.00477968    0.0860779    0.0252712  -0.0939895     0.084266     0.0334833   -0.0339612   -0.154584    -0.0283915     0.0262283     0.0745529    0.0827121    0.0571436  -0.0747185    0.0627153    0.139412     0.104902    -0.0788698   0.0988347    0.0117973    -0.0217569   -0.0984612
  0.0281386  -0.0937103    0.0925404     0.129439      0.08405      -0.0007259    0.0110053   0.098183     -0.158313     0.0638644    0.0250044   -0.10595     -0.0559066    -0.0634067    -0.063233    -0.138492    -0.0268954  -0.0111122   -0.0321901    0.027602    -0.00706743   0.124554   -0.049899     0.100326      0.0283146   -0.0634914
 -0.0396791   0.0272885    0.0113833    -0.0931599     0.0653973     0.0228062   -0.0393975  -0.0390422     0.0437109    0.0694435   -0.0164502    0.0747469   -0.0212261     0.019136     -0.0712884   -0.12229      0.0425217  -0.0598479    0.0841201    0.0664247   -0.0933184    0.102265   -0.0175561    0.0273878    -0.0112191   -0.0895209
  0.141789   -0.0124032   -0.0372079    -0.0333917    -0.158664     -0.0399865   -0.088769   -0.0070704     0.0491793   -0.106477     0.0438182    0.0712567   -0.280193     -0.0645411     0.0689033    0.0653992   -0.126677   -0.0824299   -0.0603614    0.0409114   -0.0516976   -0.0664358   0.0293026   -0.0253882     0.038026    -0.0311962
 -0.111423    0.0858472    0.129462     -0.171845      0.0495997    -0.112905     0.0361727   0.0818211     0.0944291   -0.152587     0.0617136    0.0546687   -0.00771034   -0.0877407     0.108773     0.00654396  -0.205155   -0.0975318    0.00275478   0.0965007    0.0849854   -0.177846    0.0352437   -0.0446789    -0.0971119   -0.112198
 -0.0618743  -0.0618417   -0.0692652    -0.00580067   -0.0104675    -0.058013    -0.0186887   0.0934568    -0.0694184    0.029612    -0.024618     0.0234472    0.0221067     0.0853061     0.0388222   -0.0230407   -0.0535813  -0.0373153   -0.0437192   -0.0737533    0.0103597   -0.135129    0.0592796    0.130036      0.0167309    0.00781837
  0.0952298   0.0221341   -0.0521682     0.0380957     0.0688799     0.0898192    0.0954315   0.082744      0.195203    -0.0925592   -0.0435163    0.109204     0.0509802    -0.0296453     0.0838167    0.0344987    0.0490452  -0.0401762    0.0288827   -0.121612    -0.0662514    0.115582    0.0213317   -0.0297896     0.131978    -0.125101[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077857
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.049305
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054573
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060559
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.064955
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.035580
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     19
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.077740
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.048211
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052350
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     24
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.060549
┌ Info: EM with 100000 data points 10 iterations avll -1.060549
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.849868e+05
      1       6.909619e+05      -1.940249e+05 |       32
      2       6.552515e+05      -3.571038e+04 |       32
      3       6.404434e+05      -1.480811e+04 |       32
      4       6.305480e+05      -9.895389e+03 |       32
      5       6.229123e+05      -7.635694e+03 |       32
      6       6.190420e+05      -3.870356e+03 |       32
      7       6.164767e+05      -2.565289e+03 |       32
      8       6.142502e+05      -2.226440e+03 |       32
      9       6.131607e+05      -1.089555e+03 |       32
     10       6.127353e+05      -4.253532e+02 |       32
     11       6.125371e+05      -1.981928e+02 |       32
     12       6.123728e+05      -1.643289e+02 |       32
     13       6.121705e+05      -2.023332e+02 |       32
     14       6.119012e+05      -2.692830e+02 |       32
     15       6.115561e+05      -3.450797e+02 |       32
     16       6.111694e+05      -3.866924e+02 |       32
     17       6.108605e+05      -3.089202e+02 |       32
     18       6.106497e+05      -2.108083e+02 |       32
     19       6.105325e+05      -1.172077e+02 |       32
     20       6.104699e+05      -6.252165e+01 |       32
     21       6.104313e+05      -3.862150e+01 |       32
     22       6.104042e+05      -2.717723e+01 |       32
     23       6.103793e+05      -2.484524e+01 |       32
     24       6.103585e+05      -2.080545e+01 |       31
     25       6.103454e+05      -1.308622e+01 |       31
     26       6.103319e+05      -1.352431e+01 |       31
     27       6.103206e+05      -1.127137e+01 |       32
     28       6.103049e+05      -1.573427e+01 |       32
     29       6.102843e+05      -2.054025e+01 |       32
     30       6.102604e+05      -2.397188e+01 |       31
     31       6.102359e+05      -2.443308e+01 |       31
     32       6.102145e+05      -2.146341e+01 |       32
     33       6.101856e+05      -2.885502e+01 |       32
     34       6.101436e+05      -4.199039e+01 |       32
     35       6.100785e+05      -6.515103e+01 |       32
     36       6.099730e+05      -1.055230e+02 |       32
     37       6.098418e+05      -1.312044e+02 |       32
     38       6.096544e+05      -1.873556e+02 |       32
     39       6.094843e+05      -1.700643e+02 |       32
     40       6.094004e+05      -8.392572e+01 |       32
     41       6.093509e+05      -4.951673e+01 |       30
     42       6.093282e+05      -2.264246e+01 |       30
     43       6.093168e+05      -1.143508e+01 |       29
     44       6.093112e+05      -5.619352e+00 |       27
     45       6.093082e+05      -2.943849e+00 |       21
     46       6.093071e+05      -1.151390e+00 |       18
     47       6.093064e+05      -7.399037e-01 |       16
     48       6.093059e+05      -4.392893e-01 |        3
     49       6.093058e+05      -1.592620e-01 |        6
     50       6.093055e+05      -2.526048e-01 |        4
K-means terminated without convergence after 50 iterations (objv = 609305.5063276655)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.333697
[ Info: iteration 2, average log likelihood -1.304195
[ Info: iteration 3, average log likelihood -1.271957
[ Info: iteration 4, average log likelihood -1.234930
[ Info: iteration 5, average log likelihood -1.189724
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.140916
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.124824
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.135263
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     20
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102237
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.106178
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     21
│     23
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.094641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.138978
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.107945
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     20
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.070934
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.103536
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.143296
[ Info: iteration 17, average log likelihood -1.116207
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     23
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.058095
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     21
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.082788
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.135007
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.117580
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082359
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     21
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.077471
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.130970
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.115607
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     13
│     20
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.073335
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     21
│     26
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.084236
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.142713
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.118722
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│     13
│     20
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.073696
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     21
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.103704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.133203
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.112439
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│     13
│     19
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.069412
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     20
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.100893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.121870
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     22
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.103796
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.107213
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.098017
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.117223
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│     12
│     20
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086554
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.099556
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     21
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.125013
[ Info: iteration 44, average log likelihood -1.149599
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.086553
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     12
│     13
│     20
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.068370
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.117469
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.130876
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.106142
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.099467
┌ Info: EM with 100000 data points 50 iterations avll -1.099467
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.142081    -0.111166    -0.114067      0.0795636  -0.00120046  -0.0539285    0.00192543   0.0395845    0.0336355   -0.0344919     0.0702601    0.0141854     0.120972     0.0700151  -0.222569     0.064669     0.0352346    0.000571484   0.126375    -0.278463     0.0883951   -0.0540929    0.119155      0.0197417    0.00702393   0.000709113
 -0.160239    -0.179377    -0.0978309     0.0138434  -0.0236791    0.0510834   -0.0914639    0.208494    -0.111497    -0.104888     -0.0385292   -0.0197159     0.0310263   -0.0588595  -0.249138     0.0131616   -0.0476153   -0.0452714    -0.0899904    0.0742052   -0.0879963    0.0130415    0.00308743   -0.183046     0.00797843  -0.0376992
  0.108066     0.157544    -0.0613125    -0.0141893  -0.0846576    0.0518577    0.0663243   -0.0980182   -0.0325613    0.0379146    -0.107763     0.119451     -0.00855044  -0.0469113  -0.0277071    0.0249694   -0.0729333   -0.0964455    -0.160052    -0.0988125    0.00459774   0.0852312   -0.0409948    -0.00168804  -0.0778867   -0.039309
  0.0590756   -0.197918     0.00533019   -0.0282056   0.0272256    0.088031    -0.0990627    0.0363391    0.119642     0.0232254     0.0032642    0.00498076    0.00985571  -0.0472734  -0.0799998   -0.0492616    0.0835554   -0.0259545    -0.022205    -0.191917    -0.244659    -0.0201752   -0.0983762     0.11999     -0.0515524   -0.062469
 -0.190294     0.0884645   -0.0470144    -0.30797     0.00289441   0.0269702    0.186966     0.102894    -0.0644137    0.143303     -0.0940359   -0.194328     -0.0303767    0.172652    0.255268     0.140173    -0.107497    -0.211734      0.00146344   0.0709633   -0.0117952    0.0238102    0.00396078   -0.215383    -0.107878    -0.0158016
  0.0336702    0.0577688   -0.0449775     0.0936228   0.0411277   -0.0734446   -0.0378394   -0.0972737   -0.0973343    0.0161124     0.0287353    0.0238398     0.100227    -0.0691055  -0.0185052   -0.157809     0.00542006   0.0272619     0.0963874    0.0554563    0.0877219   -0.0234357    0.0449495     0.0690797   -0.122689    -0.00426455
  0.199724     0.103829    -0.205031      0.0121573  -0.129093     0.192222    -0.167216     0.127492     0.0721227    0.0813745     0.0448317    0.000980062   0.0119654   -0.132229   -0.0907453    0.0196186    0.0522809    0.145408     -0.0488702    0.0665934    0.171721     0.00976819  -0.00525602   -0.123022    -0.0966347   -0.075465
 -0.079551    -0.0835324   -0.060972      0.152704   -0.0914365   -0.025563     0.218773     0.0428113   -0.225115     0.139971     -0.02022      0.0414659     0.123875    -0.0910765   0.0825121   -0.0306945   -0.137902     0.033956     -0.063311    -0.277736     0.101662     0.0456809   -0.127434      0.00757454  -0.0732954   -0.00591043
 -0.110041     0.0943231    0.125304     -0.169225    0.0436814   -0.109315     0.0308675    0.0777449    0.0964523   -0.146882      0.0615437    0.0535458    -0.0154464   -0.0831151   0.110571     0.0100844   -0.197204    -0.0958532    -0.00701461   0.0953695    0.0908461   -0.174269     0.0341344    -0.0443396   -0.097629    -0.110477
 -0.0193891   -0.0491678    0.0666279     0.0745678   0.044506     0.0648093   -0.0129093    0.125548    -0.120056    -0.166388     -0.00681923   0.0405365    -0.102261    -0.0975035   0.0069868    0.00856855   0.0521134    0.15293       0.00625464   0.0853647    0.039105    -0.181707     0.0357829     0.199493    -0.0321612   -0.0848355
  0.0936927    0.0226003   -0.0524207     0.0372424   0.0684818    0.0913522    0.0954172    0.0831496    0.191569    -0.0920808    -0.043938     0.109868      0.0504366   -0.0297802   0.0838321    0.0343837    0.048492    -0.0410337     0.0286289   -0.121818    -0.0656631    0.114922     0.0202335    -0.0308662    0.130641    -0.12664
 -0.0372027   -0.0563621    0.0553009    -0.0104214   0.0813736    0.0462152   -0.0329501    0.12855     -0.103827    -0.127345     -0.0618093    0.0217855    -0.0993839   -0.03638     0.0727182    0.00989637  -0.0061065    0.152495      0.0346268    0.0131949    0.014416    -0.13167     -0.0254597     0.193084    -0.0368769   -0.0316783
 -0.125776    -0.0432074   -0.0819548    -0.0778847   0.0450628   -0.0283421   -0.083476     0.10983     -0.0324155    0.0194814    -0.105211    -0.0111966    -0.143508     0.195489    0.179894    -0.0355284   -0.0229454    0.00171375   -0.0179965   -0.122868     0.0604022   -0.151714     0.152521      0.186207    -0.0082748    0.0262278
  0.0320842    0.0217106   -0.00563228   -0.0362903  -0.0312421    0.0382507   -0.035328    -0.00268602   0.0556381   -0.0982726     0.0498074    0.0616691    -0.126612    -0.0200282   0.0573907    0.0343782   -0.0853136   -0.0288331    -0.138769     0.0666771   -0.087125    -0.00656406  -0.0155511     0.1191       0.0569327   -0.0617536
  0.0538389    0.0379806   -0.10289      -0.076915   -0.00863804   0.0350845   -0.038913     0.0554588    0.0265265    0.0412168    -0.0781752    0.0590385    -0.168824    -0.014696   -0.130162     0.0794242    0.0221348    0.035737      0.101718     0.0422427    0.241225    -0.0911531    0.105178      0.00707355   0.0703827    0.0280841
 -0.10208      0.00729444  -0.0572424     0.207346    0.119369    -0.0148835    0.12876     -0.0179433   -0.152548     0.0964067     0.0433647   -0.114969      0.0281531   -0.15997     0.0492387    0.037634    -0.0648807   -0.120328      0.0481841   -0.140165    -0.0891534   -0.12972     -0.0767727     0.0896532   -0.0440261    0.0772359
  0.0676062    0.101361     0.0787553    -0.253549   -0.110661     0.0566587    0.0469411   -0.0639257    0.00179122   0.0895577    -0.0395711    0.205399     -0.0517729    0.0562908  -0.118472    -0.00806982   0.00108809  -0.0511616     0.199141     0.125503    -0.0853264    0.0456878   -0.0246459     0.0880206   -0.0451974   -0.19294
  0.0600936    0.136002    -0.0315883     0.130605   -0.10116     -0.0644632    0.13627     -0.0263336    0.148315    -0.000831847  -0.0697432    0.0121562     0.0957907   -0.153266   -0.00918318  -0.0808484   -0.0857176    0.171178     -0.01072     -0.020227     0.0212601    0.0659806   -0.0171386    -0.0797533   -0.0193399   -0.113901
 -0.0367505   -0.00126652  -0.249893      0.0869804  -0.0271197   -0.0364413    0.0324383   -0.0372991    0.0976591    0.167352      0.029519    -0.0583037    -0.0101543   -0.0987667  -0.238198    -0.276495     0.0241952    0.0151287     0.102801     0.0149672   -0.238838     0.102029    -0.0488071     0.0175598    0.0355279    0.0803282
 -0.00156983  -0.082754    -0.0500164     0.0703307  -0.111693    -0.100402     0.0674865    0.0744138   -0.0984183    0.0331324     0.0575096    0.0699195     0.185677    -0.02561    -0.0988838   -0.00141443  -0.0839032   -0.0710951    -0.0687384   -0.019323    -0.045788    -0.138855    -0.0363435     0.0607318    0.0277573   -0.0043961
 -0.0240233    0.0270008   -0.094102     -0.156562   -0.182004     0.0161731   -0.0152282    0.00270763   0.0690228   -0.0134795    -0.0764375    0.0129987     0.0194271   -0.116691   -0.0429455   -0.120496     0.0630401    0.22333       0.0845126    0.0129196   -0.0574701    0.0224488   -0.00434127   -0.0926185    0.0552427   -0.0738303
  0.00268526  -0.0573934    0.130045     -0.0931913  -0.0645918   -0.0284483    0.172207     0.0945473   -0.117194     0.0459588    -0.0595164   -0.0106188    -0.120001    -0.0426689   0.0244182   -0.0154278   -0.05734     -0.00938047   -0.0495594    0.0134271    0.0795394   -0.163845     0.0582416     0.00174177   0.0324972   -0.0253259
 -0.0687917   -0.0160425   -0.0769395     0.100573   -0.049238     0.0605728    0.0185023    0.0391071   -0.166589     0.0490102    -0.0262801    0.0415843    -0.0720994   -0.110846    0.11448      0.0380289    0.0433623   -0.0722352    -0.0967234    0.00015284   0.00880468  -0.0355909   -0.0333149    -0.0142837   -0.0880317    0.115145
 -0.15912     -0.0428948    0.109753     -0.0452439   0.310757     0.0392459   -0.182109    -0.00268391   0.0801311   -0.0192988    -0.00911973   0.015547      0.0189897    0.0747499   0.0726445   -0.112487     0.0725528   -0.0976551    -0.0424314    0.0475574    0.00342677   0.172507    -0.000126643  -0.0590412    0.0093578   -0.113696
  0.0327       0.0692473   -0.0845729     0.0268332   0.0821008    0.00621163   0.0255511    0.191402     0.0952417   -0.0393294     0.13212     -0.093318     -0.14456      0.0277774  -0.0186437    0.037258    -0.0375215   -0.120936     -0.00723055  -0.0177124    0.252813     0.0562554    0.0430366     0.024796    -0.0548474   -0.10166
 -0.127726    -0.0233198   -0.0189247     0.148588    0.155734     0.0473545   -0.0618515    0.0131074    0.0271976   -0.0527671    -0.0377989   -0.0277664    -0.00572044   0.0782288   0.0162571    0.0648151   -0.0139573   -0.0561145     0.020556     0.0585106   -0.0298429   -0.0651004   -0.0434929     0.0413787   -0.0469789    0.0123993
  0.00763763  -0.166763     0.154151     -0.121077    0.116862    -0.0426415   -0.134027     0.0292362    0.0828104   -0.0613447    -0.245308     0.115706      0.132406     0.156437   -0.037533     0.225773    -0.0158542    0.116751     -0.116846     0.0572223    0.0326847   -0.0548254    0.0354318     0.00160857  -0.0623475    0.0470164
  0.0346047    0.0878775   -0.000100944   0.101292   -0.0675767    0.0749957    0.0270946   -0.112158     0.00856294   0.0327986    -0.0585064    0.0766568     0.00258588   0.0780705  -0.00379108   0.0521121   -0.0480474   -0.0975905    -0.141656     0.166021     0.138603    -0.0358765    0.411717     -0.00132842  -0.0375911   -0.0817379
  0.0853852   -0.159384     0.17323      -0.139673   -0.0705934   -0.039476     0.080184     0.081762    -0.0464477   -0.0742476    -0.0676174   -0.0399942    -0.130994    -0.0716162  -0.0010036    0.0259547    0.0382611   -0.030806     -0.0438532    0.0657104    0.0242061   -0.182724     0.214501      0.0156018    0.0854263    0.0344849
 -0.0514838    0.120622    -0.0138665     0.0385967  -0.111996    -0.049063     0.0247907    0.0657453    0.129558     0.294733      0.0440167    0.0305595    -0.211681    -0.0467806   0.0869383    0.119993    -0.0574345   -0.223575     -0.0965465    0.184669     0.0516802   -0.0160057   -0.0689125    -0.0806619   -0.0949591    0.0164892
 -0.0574321   -0.0818155    0.160318      0.150388    0.126919    -0.00490798  -0.0161955    0.073815    -0.170908     0.0682441    -0.00317553  -0.110771     -0.0191947    0.124382   -0.15868      0.00624779  -0.0182759   -0.116468     -0.104653     0.0460091   -0.0673971    0.206052     0.00118139    0.0619811   -0.0448586   -0.0129277
  0.107957    -0.0832789    0.0195694     0.0929803   0.0282355    0.00316376   0.054195     0.112402    -0.145035     0.0789791     0.0499392   -0.100139     -0.0921199   -0.228813    0.0377573   -0.237156    -0.0276565    0.0772636     0.0352132    0.0078437    0.031534     0.0202898   -0.0750915     0.134471     0.0743616   -0.109073[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     10
│     20
│     21
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.073295
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.035829
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.026837
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.052986
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     10
│     20
│     21
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.042213
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.018971
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     10
│     13
│     20
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046938
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043338
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030460
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.042522
┌ Info: EM with 100000 data points 10 iterations avll -1.042522
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.149158    -0.131246    -0.0467539   -0.0352189   -0.0262263  -0.139226     0.0461225     0.044738   -0.0562899    0.00244504   0.0593241    0.116359     0.0344562   -0.0141195  -0.134071    0.0723336    0.157323     0.0278842   -0.046362      0.106807    -0.0750225   -0.00655277  -0.0949504    0.00846572   0.071381     0.0709595
 -0.00992093   0.0280762    0.173564    -0.00948364  -0.146691   -0.0965847    0.295396     -0.180911    0.207247    -0.0273983   -0.0103643   -0.0839953   -0.199259    -0.0533389   0.0159928   0.202042     0.048724    -0.0502167    0.0397534     0.0912583    0.170852     0.0501673    0.00365415   0.0690969    0.148173     0.0889883
  0.0201833   -0.0193853   -0.155737    -0.195115     0.0617407   0.0388587    0.000589835  -0.0746906  -0.0217125   -0.0932113    0.0678225    0.0474142   -0.0587468    0.0565226  -0.0100949  -0.0182884   -0.058718     0.045079     0.106862      0.0130502    0.0530768   -0.0295562    0.140693    -0.057816    -0.139448     0.0717355
 -0.029333     0.0146852   -0.156219    -0.154881     0.158916    0.0349213    0.0448278     0.171132   -0.0289075    0.119043     0.126618     0.0735032    0.0364743   -0.0423904  -0.0251883  -0.163127    -0.0286094    0.136105     0.0608063     0.0431863    0.0153192    0.0872831   -0.0694694   -0.190901     0.187405     0.221935
  0.14345      0.162426     0.0551545    0.0549752    0.0166242   0.155036     0.201247     -0.183006    0.00808219  -0.0556809    0.160854    -0.00967186   0.0941311    0.0810587   0.016062   -0.172662    -0.0874922    0.160181     0.0734524    -0.133072     0.0658871    0.0620951   -0.00951353  -0.04199     -0.0518246   -0.0703324
 -0.0380966   -0.0630209   -0.15313     -0.0174908   -0.0333572  -0.0144071    0.0274639     0.0305772  -0.00568849   0.0750641   -0.0373425   -0.110492    -0.0214031    0.0954498   0.055652    0.0731317    0.00991342  -0.0964965    0.084892      0.01768      0.0676386    0.157204    -0.0917326   -0.0782523    0.0618835    0.010744
  0.0388954   -0.037409    -0.0411996    0.119916    -0.156416   -0.0710149    0.0204395     0.0868731   0.124684    -0.0423619   -0.137725    -0.00327712  -0.0422793   -0.0394071   0.0109073  -0.0257628   -0.0696182   -0.0311386   -0.0226671    -0.0284293    0.0526526    0.0966733   -0.0309138    0.131131     0.163682     0.178695
 -0.15847     -0.00340032   0.0463818   -0.127132     0.060034   -0.0393402   -0.0095124    -0.0653734   0.0159121   -0.0251058   -0.0296803   -0.135146    -0.062724    -0.0846653  -0.241271    0.148792     0.0683324    0.140431    -0.0767448    -0.144899     0.0833307    0.120536     0.0140187    0.0807745   -0.1957      -0.0676759
  0.0980869    0.0667008    0.0220725   -0.0987599    0.0100623   0.0120358   -0.136869      0.0610974   0.0191792   -0.16888      0.0823342   -0.0247388   -0.0294962    0.0632611   0.063358    0.091928     0.0334934    0.121636     0.0600783     0.139569    -0.0384667    0.0117279   -0.0709873    0.0359076    0.0216193   -0.17687
  0.172206    -0.102531    -0.0920808    0.0854068   -0.197355    0.0123844    0.290775      0.0516517  -0.0537184    0.0570171    0.0911624   -0.00905618  -0.121129     0.0922404   0.160934   -0.0334667    0.0094877   -0.0380141    0.128662     -0.010862    -0.0258084    0.0883424    0.1082      -0.140815    -0.138962    -0.266036
  0.0318728   -0.00191346  -0.0446857   -0.0772646    0.248184   -0.10124     -0.0723036     0.0841878  -0.00879969  -0.0479199   -0.0778062   -0.109152     0.0464348   -0.0975605  -0.0215444  -0.0050763    0.00139079  -0.0156917   -0.0471498    -0.115702     0.122796     0.0468451    0.0902602    0.218308    -0.233408    -0.160686
 -0.0987505   -0.00589856   0.0716802    0.0700339   -0.0566365   0.044102     0.057489     -0.145755    0.0752011    0.137388     0.00396054  -0.0906947    0.0211217   -0.0239823  -0.0556063   0.163857     0.0438485    0.0671293    0.000864713   0.076072    -0.159903     0.157566     0.148031     0.132229    -0.00239891  -0.0327745
 -0.0911619    0.143838     0.0701755   -0.0574394   -0.0624125  -0.124838     0.0934163    -0.0309903  -0.0631581   -0.0121869   -0.0119304    0.0933928   -0.133486     0.0159988  -0.010164    0.151005    -0.0409976    0.0629707   -0.0575237    -0.00142052  -0.184126    -0.0802705   -0.00887579  -0.00316071  -0.0287112   -0.120921
 -0.127692     0.039        0.00403808  -0.00321422   0.0979547  -0.0268195   -0.0823972     0.0298977  -5.52186e-5   0.0174991   -0.076581    -0.0837333   -0.0957895   -0.0136157  -0.0385716  -0.0622772   -0.0313526   -0.00328084   0.16617      -0.111418    -0.0949823    0.133641     0.0081426    0.0230327   -0.102181     0.0990278
  0.0150378   -0.019806    -0.0406461    0.0103615   -0.177137    0.173626     0.112072     -0.0881386  -0.236387     0.126752    -0.17292     -0.0128611   -0.0541884    0.0223092   0.0673048  -0.179438     0.0438081    0.0400715   -0.0803913     0.0483972    0.0316487   -0.0330495    0.250747     0.102637     0.00295642   0.106459
  0.0224721    0.0433501   -0.00105188   0.0729143    0.0335787  -0.0267207    0.0846705     0.083871   -0.236412     0.0495238    0.0248173   -0.132583     0.0176072   -0.0743856   0.0135808  -0.0926833   -0.191808    -0.0440083   -0.0685182    -0.112184    -0.123672     0.0304555    0.0318892   -0.0489765   -0.19022     -0.274962
  0.0265741   -0.0243623    0.0169475    0.00203702   0.0328363  -0.113331    -0.0455796    -0.0125492  -0.0290183    0.0461228    0.163495     0.176812     0.0487867    0.127077   -0.0557762   0.0478317   -0.124361    -0.0321307    0.0246467     0.102291    -0.0645193   -0.0230316   -0.037258     0.0276726   -0.0182484    0.384582
  0.0223372    0.0390533   -0.0547988   -0.137514    -0.0196711  -0.0742845   -0.105158      0.159206   -0.113903     0.121643    -0.0530626    0.0810028   -0.0131789    0.095163   -0.12257    -0.104448     0.0200452    0.111608    -0.0710247     0.0657138   -0.00397463   0.0802132    0.0203099    0.0784476    0.166833    -0.0157746
 -0.04359     -0.107811     0.275376    -0.0516978   -0.0054209   0.256166    -0.114254     -0.0372997  -0.0115624   -0.180844    -0.266957     0.039989     0.141902    -0.0378076   0.099931    0.0219731    0.0811306    0.105845     0.138146     -0.0404307   -0.320086    -0.0178868   -0.134719    -0.0961261    0.175404    -0.182715
  0.0833044    0.185797    -0.0116824   -0.0372231    0.0741035  -0.21405     -0.133291     -0.0858758  -0.13462     -0.046749     0.0743525   -0.0119401    0.0539844    0.0556929  -0.0386502   0.14917      0.0665565    0.0354651   -0.00354658    0.053043    -0.0022124    0.0854351   -0.146721    -0.0154073   -0.0237399   -0.0704067
 -0.110304    -0.029054     0.106371     0.211931     0.0399941   0.0175294    0.127317      0.116723   -0.00640355   0.0675839    0.101582     0.0110093    0.0923569    0.270677    0.0669082  -0.0323684   -0.0419651   -0.0723107   -0.0782789    -0.0387056    0.0934306   -0.0924721    0.165494    -0.0449474    0.0472448    0.0605847
 -0.155869    -0.0744155    0.0515317   -0.0816232    0.264376   -0.0659856   -0.104304     -0.169713    0.212139     0.0341022    0.0605605    0.142784     0.0622381    0.227927    0.0187972  -0.0740467   -0.0380956   -0.0234054   -0.170995      0.0973249   -0.0146505    0.0392171    0.105684     0.13055     -0.0264296    0.0157518
 -0.010309     0.0663518    0.048098    -0.068822     0.111407    0.0323478    0.0443883     0.0536016   0.0178434    0.11539     -0.0653652    0.0803475   -0.00113993  -0.0406128   0.02251    -0.00692048  -0.00174151  -0.263265     0.193455     -0.0106615   -0.00702941   0.0736116    0.137833    -0.168375     0.046569    -0.0167085
 -0.171314     0.0292665    0.178237     0.107232    -0.0201114  -0.0420536    0.107091     -0.12017    -0.115777    -0.0573702   -0.113977     0.094035     0.157953    -0.0761445   0.0202183   0.0574972   -0.0545303    0.00169346   0.0386203    -0.0407069   -0.011137    -0.209611     0.168898     0.0345256   -0.196868     0.198555
  0.0175748    0.0792703   -0.038252     0.113599     0.0585325  -0.0582599   -0.0294024    -0.0579195   0.0771443    0.0752553    0.24328      0.0655105   -0.015647    -0.0422586   0.0356764  -0.0325215    0.0484305    0.126663    -0.0783599    -0.171691     0.206446    -0.0764498   -0.0575144    0.159851     0.127306     0.166881
 -0.0655318    0.314845    -0.106257     0.136022    -0.0262949   0.101108     0.0380505    -0.0643587  -0.0926455   -0.0721419   -0.0193027    0.133046     0.0773967    0.0520024   0.0460412   0.249732     0.0954706    0.172203    -0.0162632     0.0011715    0.0586278    0.0748081   -0.040346     0.129145     0.00427568   0.0184066
 -0.0882918   -0.0704618   -0.0751085    0.0338157    0.028893   -0.00154405   0.0277794     0.106051   -0.157198    -0.210529    -0.121226    -0.0428786    0.0743555   -0.218514    0.0169048   0.0315471    0.0496332    0.056277    -0.00201514    0.0627451   -0.159975     0.113749    -0.0170944    0.0178883    0.0778656    0.0064715
 -0.10296      0.0132483    0.20932     -0.0647571    0.187999   -0.110771    -0.112625     -0.172709    0.0515356    0.0355599   -0.0210996    0.193191    -0.0613708   -0.151567    0.0590947   0.0274379   -0.0963514    0.058618     0.105771      0.0761709    0.0354083   -0.0402417   -0.196393     0.188698     0.0494606    0.0283547
 -0.0851763   -0.0199286    0.257406    -0.0273474   -0.124781   -0.0453226    0.0221823    -0.0444127   0.0267544    0.0635603   -0.0702837   -0.0562165    0.0953869    0.0647612  -0.0895611  -0.044131     0.0286988   -0.078224     0.0958126     0.0520809    0.110242     0.112867     0.104342     0.020356    -0.072724     0.00059144
  0.0129435   -0.0187179   -0.136466    -0.129812    -0.177697   -0.142938    -0.0212461    -0.0216259  -0.0657056   -0.0682547   -0.0117738    0.0132408    0.108581    -0.172266    0.124664    0.0176876   -0.100167     0.0774078    0.0786272    -0.0430204    0.241278     0.0892284   -0.00395589  -0.00958347   0.146117     0.00534775
 -0.0790973   -0.0554133   -0.0449859   -0.179854    -0.0422886   0.0272011   -0.0647255     0.121243   -0.0890592    0.160669    -0.0988933    0.106467     0.0277061   -0.0906809   0.0165184   0.221806    -0.122263     0.0665582   -0.00734894   -0.0192741    0.0724257    0.054852     0.186315     0.179746    -0.0507398    0.0805865
 -0.0287398   -0.293318     0.139763     0.0790866   -0.156219   -0.109909    -0.141591      0.0170387   0.0324354   -0.00010268  -0.0750803   -0.0568913    0.0594708    0.0156539  -0.223625    0.00400202  -0.0053852   -0.0236943   -0.0410066    -0.01736      0.109783    -0.0247498    0.0414967   -0.00939491  -0.114815    -0.18967kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4201518435076133
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420170
[ Info: iteration 2, average log likelihood -1.420086
[ Info: iteration 3, average log likelihood -1.420003
[ Info: iteration 4, average log likelihood -1.419893
[ Info: iteration 5, average log likelihood -1.419751
[ Info: iteration 6, average log likelihood -1.419585
[ Info: iteration 7, average log likelihood -1.419417
[ Info: iteration 8, average log likelihood -1.419261
[ Info: iteration 9, average log likelihood -1.419108
[ Info: iteration 10, average log likelihood -1.418914
[ Info: iteration 11, average log likelihood -1.418610
[ Info: iteration 12, average log likelihood -1.418111
[ Info: iteration 13, average log likelihood -1.417375
[ Info: iteration 14, average log likelihood -1.416490
[ Info: iteration 15, average log likelihood -1.415688
[ Info: iteration 16, average log likelihood -1.415144
[ Info: iteration 17, average log likelihood -1.414849
[ Info: iteration 18, average log likelihood -1.414708
[ Info: iteration 19, average log likelihood -1.414644
[ Info: iteration 20, average log likelihood -1.414616
[ Info: iteration 21, average log likelihood -1.414603
[ Info: iteration 22, average log likelihood -1.414597
[ Info: iteration 23, average log likelihood -1.414594
[ Info: iteration 24, average log likelihood -1.414593
[ Info: iteration 25, average log likelihood -1.414592
[ Info: iteration 26, average log likelihood -1.414592
[ Info: iteration 27, average log likelihood -1.414592
[ Info: iteration 28, average log likelihood -1.414591
[ Info: iteration 29, average log likelihood -1.414591
[ Info: iteration 30, average log likelihood -1.414591
[ Info: iteration 31, average log likelihood -1.414591
[ Info: iteration 32, average log likelihood -1.414591
[ Info: iteration 33, average log likelihood -1.414591
[ Info: iteration 34, average log likelihood -1.414591
[ Info: iteration 35, average log likelihood -1.414591
[ Info: iteration 36, average log likelihood -1.414591
[ Info: iteration 37, average log likelihood -1.414590
[ Info: iteration 38, average log likelihood -1.414590
[ Info: iteration 39, average log likelihood -1.414590
[ Info: iteration 40, average log likelihood -1.414590
[ Info: iteration 41, average log likelihood -1.414590
[ Info: iteration 42, average log likelihood -1.414590
[ Info: iteration 43, average log likelihood -1.414590
[ Info: iteration 44, average log likelihood -1.414590
[ Info: iteration 45, average log likelihood -1.414590
[ Info: iteration 46, average log likelihood -1.414590
[ Info: iteration 47, average log likelihood -1.414590
[ Info: iteration 48, average log likelihood -1.414590
[ Info: iteration 49, average log likelihood -1.414590
[ Info: iteration 50, average log likelihood -1.414590
┌ Info: EM with 100000 data points 50 iterations avll -1.414590
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201703195839939
│     -1.4200858818408315
│      ⋮
└     -1.414590049138994
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414605
[ Info: iteration 2, average log likelihood -1.414528
[ Info: iteration 3, average log likelihood -1.414452
[ Info: iteration 4, average log likelihood -1.414351
[ Info: iteration 5, average log likelihood -1.414223
[ Info: iteration 6, average log likelihood -1.414077
[ Info: iteration 7, average log likelihood -1.413937
[ Info: iteration 8, average log likelihood -1.413821
[ Info: iteration 9, average log likelihood -1.413734
[ Info: iteration 10, average log likelihood -1.413669
[ Info: iteration 11, average log likelihood -1.413617
[ Info: iteration 12, average log likelihood -1.413575
[ Info: iteration 13, average log likelihood -1.413539
[ Info: iteration 14, average log likelihood -1.413510
[ Info: iteration 15, average log likelihood -1.413487
[ Info: iteration 16, average log likelihood -1.413468
[ Info: iteration 17, average log likelihood -1.413454
[ Info: iteration 18, average log likelihood -1.413444
[ Info: iteration 19, average log likelihood -1.413436
[ Info: iteration 20, average log likelihood -1.413429
[ Info: iteration 21, average log likelihood -1.413424
[ Info: iteration 22, average log likelihood -1.413419
[ Info: iteration 23, average log likelihood -1.413415
[ Info: iteration 24, average log likelihood -1.413412
[ Info: iteration 25, average log likelihood -1.413409
[ Info: iteration 26, average log likelihood -1.413407
[ Info: iteration 27, average log likelihood -1.413404
[ Info: iteration 28, average log likelihood -1.413402
[ Info: iteration 29, average log likelihood -1.413401
[ Info: iteration 30, average log likelihood -1.413399
[ Info: iteration 31, average log likelihood -1.413397
[ Info: iteration 32, average log likelihood -1.413396
[ Info: iteration 33, average log likelihood -1.413395
[ Info: iteration 34, average log likelihood -1.413394
[ Info: iteration 35, average log likelihood -1.413393
[ Info: iteration 36, average log likelihood -1.413392
[ Info: iteration 37, average log likelihood -1.413391
[ Info: iteration 38, average log likelihood -1.413390
[ Info: iteration 39, average log likelihood -1.413389
[ Info: iteration 40, average log likelihood -1.413388
[ Info: iteration 41, average log likelihood -1.413387
[ Info: iteration 42, average log likelihood -1.413387
[ Info: iteration 43, average log likelihood -1.413386
[ Info: iteration 44, average log likelihood -1.413385
[ Info: iteration 45, average log likelihood -1.413385
[ Info: iteration 46, average log likelihood -1.413384
[ Info: iteration 47, average log likelihood -1.413383
[ Info: iteration 48, average log likelihood -1.413383
[ Info: iteration 49, average log likelihood -1.413382
[ Info: iteration 50, average log likelihood -1.413381
┌ Info: EM with 100000 data points 50 iterations avll -1.413381
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414604877975503
│     -1.4145283708641745
│      ⋮
└     -1.4133812760102256
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413391
[ Info: iteration 2, average log likelihood -1.413340
[ Info: iteration 3, average log likelihood -1.413298
[ Info: iteration 4, average log likelihood -1.413251
[ Info: iteration 5, average log likelihood -1.413196
[ Info: iteration 6, average log likelihood -1.413129
[ Info: iteration 7, average log likelihood -1.413051
[ Info: iteration 8, average log likelihood -1.412963
[ Info: iteration 9, average log likelihood -1.412868
[ Info: iteration 10, average log likelihood -1.412770
[ Info: iteration 11, average log likelihood -1.412674
[ Info: iteration 12, average log likelihood -1.412583
[ Info: iteration 13, average log likelihood -1.412502
[ Info: iteration 14, average log likelihood -1.412432
[ Info: iteration 15, average log likelihood -1.412372
[ Info: iteration 16, average log likelihood -1.412324
[ Info: iteration 17, average log likelihood -1.412284
[ Info: iteration 18, average log likelihood -1.412251
[ Info: iteration 19, average log likelihood -1.412223
[ Info: iteration 20, average log likelihood -1.412199
[ Info: iteration 21, average log likelihood -1.412179
[ Info: iteration 22, average log likelihood -1.412160
[ Info: iteration 23, average log likelihood -1.412144
[ Info: iteration 24, average log likelihood -1.412129
[ Info: iteration 25, average log likelihood -1.412115
[ Info: iteration 26, average log likelihood -1.412103
[ Info: iteration 27, average log likelihood -1.412091
[ Info: iteration 28, average log likelihood -1.412080
[ Info: iteration 29, average log likelihood -1.412070
[ Info: iteration 30, average log likelihood -1.412061
[ Info: iteration 31, average log likelihood -1.412052
[ Info: iteration 32, average log likelihood -1.412044
[ Info: iteration 33, average log likelihood -1.412037
[ Info: iteration 34, average log likelihood -1.412029
[ Info: iteration 35, average log likelihood -1.412023
[ Info: iteration 36, average log likelihood -1.412016
[ Info: iteration 37, average log likelihood -1.412010
[ Info: iteration 38, average log likelihood -1.412004
[ Info: iteration 39, average log likelihood -1.411999
[ Info: iteration 40, average log likelihood -1.411993
[ Info: iteration 41, average log likelihood -1.411988
[ Info: iteration 42, average log likelihood -1.411983
[ Info: iteration 43, average log likelihood -1.411978
[ Info: iteration 44, average log likelihood -1.411973
[ Info: iteration 45, average log likelihood -1.411968
[ Info: iteration 46, average log likelihood -1.411963
[ Info: iteration 47, average log likelihood -1.411959
[ Info: iteration 48, average log likelihood -1.411954
[ Info: iteration 49, average log likelihood -1.411949
[ Info: iteration 50, average log likelihood -1.411944
┌ Info: EM with 100000 data points 50 iterations avll -1.411944
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4133909364241755
│     -1.413339960494078
│      ⋮
└     -1.4119440303612245
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411949
[ Info: iteration 2, average log likelihood -1.411900
[ Info: iteration 3, average log likelihood -1.411856
[ Info: iteration 4, average log likelihood -1.411808
[ Info: iteration 5, average log likelihood -1.411751
[ Info: iteration 6, average log likelihood -1.411682
[ Info: iteration 7, average log likelihood -1.411601
[ Info: iteration 8, average log likelihood -1.411509
[ Info: iteration 9, average log likelihood -1.411408
[ Info: iteration 10, average log likelihood -1.411303
[ Info: iteration 11, average log likelihood -1.411198
[ Info: iteration 12, average log likelihood -1.411095
[ Info: iteration 13, average log likelihood -1.410997
[ Info: iteration 14, average log likelihood -1.410906
[ Info: iteration 15, average log likelihood -1.410822
[ Info: iteration 16, average log likelihood -1.410745
[ Info: iteration 17, average log likelihood -1.410676
[ Info: iteration 18, average log likelihood -1.410614
[ Info: iteration 19, average log likelihood -1.410558
[ Info: iteration 20, average log likelihood -1.410508
[ Info: iteration 21, average log likelihood -1.410464
[ Info: iteration 22, average log likelihood -1.410423
[ Info: iteration 23, average log likelihood -1.410386
[ Info: iteration 24, average log likelihood -1.410352
[ Info: iteration 25, average log likelihood -1.410321
[ Info: iteration 26, average log likelihood -1.410291
[ Info: iteration 27, average log likelihood -1.410264
[ Info: iteration 28, average log likelihood -1.410238
[ Info: iteration 29, average log likelihood -1.410213
[ Info: iteration 30, average log likelihood -1.410190
[ Info: iteration 31, average log likelihood -1.410168
[ Info: iteration 32, average log likelihood -1.410146
[ Info: iteration 33, average log likelihood -1.410126
[ Info: iteration 34, average log likelihood -1.410107
[ Info: iteration 35, average log likelihood -1.410089
[ Info: iteration 36, average log likelihood -1.410071
[ Info: iteration 37, average log likelihood -1.410055
[ Info: iteration 38, average log likelihood -1.410039
[ Info: iteration 39, average log likelihood -1.410024
[ Info: iteration 40, average log likelihood -1.410009
[ Info: iteration 41, average log likelihood -1.409995
[ Info: iteration 42, average log likelihood -1.409982
[ Info: iteration 43, average log likelihood -1.409969
[ Info: iteration 44, average log likelihood -1.409957
[ Info: iteration 45, average log likelihood -1.409946
[ Info: iteration 46, average log likelihood -1.409935
[ Info: iteration 47, average log likelihood -1.409924
[ Info: iteration 48, average log likelihood -1.409914
[ Info: iteration 49, average log likelihood -1.409904
[ Info: iteration 50, average log likelihood -1.409895
┌ Info: EM with 100000 data points 50 iterations avll -1.409895
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4119487076573052
│     -1.4118995091978088
│      ⋮
└     -1.4098945642267298
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409894
[ Info: iteration 2, average log likelihood -1.409831
[ Info: iteration 3, average log likelihood -1.409772
[ Info: iteration 4, average log likelihood -1.409705
[ Info: iteration 5, average log likelihood -1.409623
[ Info: iteration 6, average log likelihood -1.409523
[ Info: iteration 7, average log likelihood -1.409404
[ Info: iteration 8, average log likelihood -1.409269
[ Info: iteration 9, average log likelihood -1.409122
[ Info: iteration 10, average log likelihood -1.408970
[ Info: iteration 11, average log likelihood -1.408821
[ Info: iteration 12, average log likelihood -1.408679
[ Info: iteration 13, average log likelihood -1.408548
[ Info: iteration 14, average log likelihood -1.408428
[ Info: iteration 15, average log likelihood -1.408321
[ Info: iteration 16, average log likelihood -1.408226
[ Info: iteration 17, average log likelihood -1.408141
[ Info: iteration 18, average log likelihood -1.408065
[ Info: iteration 19, average log likelihood -1.407998
[ Info: iteration 20, average log likelihood -1.407938
[ Info: iteration 21, average log likelihood -1.407884
[ Info: iteration 22, average log likelihood -1.407836
[ Info: iteration 23, average log likelihood -1.407791
[ Info: iteration 24, average log likelihood -1.407751
[ Info: iteration 25, average log likelihood -1.407713
[ Info: iteration 26, average log likelihood -1.407679
[ Info: iteration 27, average log likelihood -1.407647
[ Info: iteration 28, average log likelihood -1.407616
[ Info: iteration 29, average log likelihood -1.407588
[ Info: iteration 30, average log likelihood -1.407561
[ Info: iteration 31, average log likelihood -1.407536
[ Info: iteration 32, average log likelihood -1.407512
[ Info: iteration 33, average log likelihood -1.407488
[ Info: iteration 34, average log likelihood -1.407466
[ Info: iteration 35, average log likelihood -1.407445
[ Info: iteration 36, average log likelihood -1.407425
[ Info: iteration 37, average log likelihood -1.407406
[ Info: iteration 38, average log likelihood -1.407387
[ Info: iteration 39, average log likelihood -1.407370
[ Info: iteration 40, average log likelihood -1.407352
[ Info: iteration 41, average log likelihood -1.407336
[ Info: iteration 42, average log likelihood -1.407320
[ Info: iteration 43, average log likelihood -1.407305
[ Info: iteration 44, average log likelihood -1.407291
[ Info: iteration 45, average log likelihood -1.407277
[ Info: iteration 46, average log likelihood -1.407263
[ Info: iteration 47, average log likelihood -1.407250
[ Info: iteration 48, average log likelihood -1.407238
[ Info: iteration 49, average log likelihood -1.407226
[ Info: iteration 50, average log likelihood -1.407214
┌ Info: EM with 100000 data points 50 iterations avll -1.407214
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4098943064985614
│     -1.4098307678763276
│      ⋮
└     -1.4072141336434425
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4201518435076133
│     -1.4201703195839939
│     -1.4200858818408315
│     -1.4200032703855552
│      ⋮
│     -1.4072376490411636
│     -1.4072256604216211
└     -1.4072141336434425
32×26 Array{Float64,2}:
 -0.0875601     0.112157     0.599545    0.0899855   -0.0798787   0.0446518    0.537633    0.467053    0.0113145  -0.246638     0.585354   -0.406611    -0.211192      0.640255    0.262738    -0.245805    -0.0719965    0.0745188   0.379031   -0.178898   -0.0328686   -0.386166    0.145048     -0.423429   -0.214754   -0.0701979
 -0.028477      0.0765479   -0.339636   -0.142913     0.0820226  -0.0536917   -0.0401651   0.0586231   0.0859599  -0.0598942   -0.143746    0.277072    -0.0632741    -0.0189071  -0.172275    -0.0266303   -0.305762    -0.060964    0.0946537  -0.103503   -0.161056    -0.0595426  -0.0534206     0.27023    -0.0038929  -0.0230317
  0.691192     -0.341137    -0.474107   -0.335702     0.156976    0.0785936   -0.202395   -0.498744   -0.956514   -0.155927    -0.467401   -0.427287    -0.31549      -0.131582    0.331446     0.656879     0.689102     0.111842    0.482147   -0.155289   -0.99634      0.151522    0.348958     -0.353747   -0.0447057  -0.0963973
 -0.0390301     0.0555216    0.632525   -0.125264     0.455698   -0.282661    -0.363902   -0.470343   -0.442663    0.111738     0.374942   -0.55298      0.0626352    -0.164966    0.160249     0.276839     0.452652     0.471739   -0.015651   -0.0736804   0.694085     0.243779    0.0176878    -0.384179   -0.193717    0.0898202
 -0.253239     -0.803134    -0.440247    0.0105726   -0.396337    0.191449     0.234906    0.432475   -0.123864   -0.200811    -0.234925    0.6386       0.111806     -0.445225   -0.12794     -0.189718     1.09748     -0.264523   -0.137362    0.843285   -0.349344     0.188726   -0.383909     -0.256091    0.692782    0.347638
 -0.0412096    -0.15277     -0.0366714  -0.613791    -0.724776    0.116395     0.347196    0.424876    0.292096   -0.212249    -0.450135   -0.238759    -0.482691      0.0270536   0.904174     0.445027    -0.00507617  -0.471379    0.0582051   0.421044   -0.174589    -0.393848   -0.205914     -0.21193     0.52936    -0.0378926
  0.202162     -0.00905129   0.0570462   0.353079    -0.145086    0.18712      0.0647993   0.148306    0.146822    0.663427    -0.806891   -0.2353       0.391654     -0.295133    0.402391    -0.449022     0.139828    -0.220653   -0.312338    0.183287    0.12813      0.471828    0.0508706    -0.520301    0.395884    0.144648
 -0.153177      0.1106       0.60101     0.0774111   -0.611112   -0.124709     0.155854   -0.0965635   0.172047    0.652327     0.860919    0.0156804    0.409828     -0.236926    0.145552     0.51336      0.0172195   -0.0563215  -0.376498    0.44879     0.312744     0.292863    0.0994604     0.63542     0.439343    0.270504
 -0.196814     -0.77896      0.82121     0.349826    -0.422361   -0.11801     -0.884595   -0.0582909  -0.116013   -0.39974     -0.695933    0.484447     0.541847      0.338485   -0.475401    -0.0121099   -0.247845    -0.347424    0.0913886  -0.285727    0.553372    -0.284784   -0.660314     -0.347585   -0.265923   -0.924577
 -0.242499     -0.290756    -0.142542    0.42967      0.050652    0.0386679   -0.0216324   0.0301444  -0.0293359  -0.183342    -0.0650272  -0.278999     0.100923      0.837212   -0.373061     0.140203    -0.276546    -0.0240005  -0.339471   -0.441398    0.374976    -0.064655   -0.107944     -0.301416   -0.563913   -0.762407
 -0.757689      0.11896      0.214891    0.292762     0.101537   -0.0925246   -0.0788617   0.393904   -0.242221   -0.254698     0.880383    0.339825     0.157209      0.300585   -0.232026    -0.12139      0.0504283   -0.057084    0.0654037   0.0660168   0.560616     0.0559525   0.203086      0.0625655  -0.435688    0.469848
 -0.54108       0.272782    -0.0411894  -0.163203    -0.0433823  -0.786428    -0.66937     0.286166   -0.144462   -0.0569755    0.0787935   0.312264    -0.169418      0.0682283  -0.0582548    0.497545     0.24847      0.128543   -0.315949    0.132248    0.689232    -0.331798    0.0558175    -0.291749   -0.268314    0.38448
 -0.139574     -0.118133    -0.341393    0.267669     0.232531   -0.031072    -0.257094   -0.203425   -0.246463   -0.0727375    0.39723     0.630896     0.796737     -0.0263141  -0.988536    -0.471667    -0.115895     0.381401   -0.424615   -0.307591    0.340105     0.502834    0.341339      0.402392   -0.580353   -0.0669317
  0.104249     -0.160792    -0.360043    0.803349    -0.187025    0.137684     0.0778156  -0.0231814  -0.442185    0.393182    -0.171911    0.676047    -0.232098      0.330241   -0.197828     0.759985    -0.0374397    0.905311   -0.634444    0.0884343   0.0243805    0.38001    -0.196403      0.361545    0.848064   -0.267077
 -0.162923     -0.304136    -0.194236    0.0131155    0.349815   -0.131047    -0.0151647   0.125379    1.09747    -0.0411718   -0.129276   -0.110176    -0.429051     -0.857882   -0.105563     0.00675277   0.181742    -0.45637     0.246637   -0.0269067  -0.0326507    0.297074   -0.17026       0.231505   -0.477828   -0.0232676
 -0.21471       0.834354    -0.0312531  -0.123934     0.102042   -0.211878     0.535386    0.110086    0.333693   -0.367091    -0.450421   -0.0306783   -0.305499     -0.267869   -0.926093     0.18312     -0.379166    -0.0732726   0.100647   -0.170946    0.26608      0.040317   -0.702598      0.245746   -0.344839   -0.406528
 -0.146716     -0.66523      0.605584   -0.0921594   -0.29523    -0.00678214   0.038278   -0.441609   -0.236857    0.27032      0.587818    0.0724894    0.00456058    0.410746    0.219363    -0.0097951    0.0536398    0.183611    0.110849   -0.0366723  -0.303143    -0.0716383   0.206694      0.224629    0.409089   -0.0202464
  0.000874989   0.361025     0.0842332  -0.297083     0.0741276   0.458099    -0.195988   -0.0200371  -0.61144    -0.146866    -0.082429   -0.128266     0.0110709     0.720695    0.461788    -0.46176     -0.33721      0.505676    0.389881   -0.237868   -0.214732    -0.228611    0.0502549    -0.183888    0.256013    0.128367
  0.0558026    -0.41128     -0.118791   -0.138444    -0.175639    0.136889    -0.0150208  -0.35176     0.322462    0.0933483   -0.594212    0.821178    -0.000390634   0.184237   -0.0412507   -0.326715    -0.489577    -0.557625   -0.16795     0.0718608  -0.483109     0.283695    0.139736      0.810654    0.118421   -0.324647
  0.168419      0.0309132    0.200323   -0.271397     0.131908    0.103176     0.0474249  -0.406139   -0.131562    0.0684869   -0.331556    0.206989    -0.0630363     0.0763061   0.161367    -0.0420205   -0.799613    -0.0597673   0.132676   -0.421666    0.490074     0.117295    0.833868      0.388729    0.0637929   0.198529
  0.223635      0.419765     0.53792     0.296528    -0.290228   -0.574244     0.136616    0.48919     0.423547    0.428652    -0.0344651   0.208497    -0.278524      0.084603    0.159213    -0.389889    -0.317152     0.0459291   0.128838   -0.525117   -0.00222205   0.157928   -0.355871     -0.0681672   0.502859    0.0473324
  0.171052      0.287727    -0.0986354  -0.00501926   0.419633   -0.364127     0.0632025   0.120299   -0.146755    0.188033     0.25232     0.177444    -0.550699     -0.522494    0.689638     0.220382    -0.0560845    0.33729     0.555358    0.490433   -0.103537    -0.125737    0.0106237     0.18755     0.449731    0.764286
  0.529318     -0.0961268   -0.463531    0.173609    -0.0755682   0.384018     0.992332   -0.0094236   0.424426    0.165287     0.273736   -0.351224     0.331845     -0.188209   -0.177075    -0.479269    -0.035135     0.116772    0.048728   -0.202984   -0.67376      0.22886     0.0310535     0.211714    0.291977    0.158008
  0.033747      0.390539    -0.093967    0.246365    -0.0808583   0.266559     0.261268    0.620938    0.309086   -0.240858    -0.217666   -0.351524     0.112691     -0.103719    0.350226     0.00799556  -0.158946    -0.12358     0.308161    0.147079   -0.240412     0.107404   -0.000630296  -0.250433   -0.378983    0.0664973
 -0.00894685    0.133858    -0.273402   -0.333793     0.431718   -0.468811    -0.0656624  -0.35318    -0.264117   -0.408424     0.183731    0.00459095  -0.491177     -0.333085   -0.58709      0.150625     0.320758     0.0820407   0.472415   -0.186795   -0.224658    -0.0712377  -0.19029       0.0861672   0.0370715  -0.0985028
  0.553815     -0.099866     0.0722698  -0.311712    -0.0375105   0.128284     0.0515627  -0.374309   -0.0254084   0.311266    -0.492755   -0.445563    -0.146341     -0.448062    0.423455    -0.0183385    0.0406317   -0.202397    0.273439    0.0795108  -0.4519       0.284438   -0.0838748     0.146538    0.300198   -0.365442
 -0.424356      0.117365    -0.536369   -0.181997    -0.0553385   0.0163511   -0.342164    0.131266    0.0504394   0.41457     -0.0216349  -0.153086     0.111576      0.0588386  -0.200487     0.195493     0.4191       0.300634   -0.267223    0.837334   -0.697734    -0.220412   -0.739027      0.130843   -0.531214   -0.0855912
 -0.118142     -0.0492059   -0.528737   -0.503236     0.0896808   0.380061    -0.263987   -0.232056   -0.395834   -0.514501    -0.061719    0.165416     0.422672     -0.164806    0.00315426   0.452596     0.459566    -0.0315926  -0.219254    0.4923     -0.291554    -0.387721    0.578893     -0.212406   -0.416278    0.200566
  0.199706      0.442692     0.147758    0.010299     0.149297   -0.0477418   -0.0281216  -0.233926   -0.216331    0.0871014    0.182055   -0.14801      0.353279     -0.0962473  -0.484499    -0.506351     0.0917693    0.342014   -0.308709   -0.33002     0.470551     0.109544    0.00466349    0.0763742  -0.286522    0.0368472
  0.13456      -0.0229488    0.311313    0.353924    -0.103592   -0.171368     0.392984   -0.173022    0.0722678   0.0246135    0.118881   -0.243362     0.482847     -0.118437   -0.354374     0.345725     0.111741    -0.322064   -0.495873    0.0743721   0.601168     0.387522    0.181056     -0.0703901   0.0978001  -0.0666728
 -0.0717018    -0.0584952   -0.136904   -0.024542    -0.305959    0.010845     0.0618354   0.121434    0.01267    -0.00784878   0.0247762   0.0894137   -0.0608806    -0.0976842  -0.00693643   0.00855578   0.185986     0.0151379  -0.0375133   0.018562   -0.0564269    0.0520245  -0.107139      0.0669833   0.130587    0.0412667
 -0.0976389    -0.0544549    0.114844    0.0575229    0.427196   -0.0245251   -0.155622   -0.150063   -0.0105297   0.0414017   -0.143603    0.0247955    0.0356658     0.178439    0.0663991    0.157325    -0.278772     0.0748076   0.0660484   0.032344    0.0993238   -0.0760514   0.203241      0.0491155  -0.177262   -0.157251[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407203
[ Info: iteration 2, average log likelihood -1.407192
[ Info: iteration 3, average log likelihood -1.407182
[ Info: iteration 4, average log likelihood -1.407172
[ Info: iteration 5, average log likelihood -1.407163
[ Info: iteration 6, average log likelihood -1.407154
[ Info: iteration 7, average log likelihood -1.407145
[ Info: iteration 8, average log likelihood -1.407136
[ Info: iteration 9, average log likelihood -1.407128
[ Info: iteration 10, average log likelihood -1.407120
┌ Info: EM with 100000 data points 10 iterations avll -1.407120
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.916917e+05
      1       7.049008e+05      -1.867909e+05 |       32
      2       6.887613e+05      -1.613956e+04 |       32
      3       6.826392e+05      -6.122125e+03 |       32
      4       6.797529e+05      -2.886290e+03 |       32
      5       6.780740e+05      -1.678875e+03 |       32
      6       6.768965e+05      -1.177446e+03 |       32
      7       6.759964e+05      -9.001146e+02 |       32
      8       6.752911e+05      -7.053087e+02 |       32
      9       6.746848e+05      -6.063089e+02 |       32
     10       6.741766e+05      -5.082117e+02 |       32
     11       6.737410e+05      -4.356313e+02 |       32
     12       6.733716e+05      -3.693979e+02 |       32
     13       6.730493e+05      -3.222985e+02 |       32
     14       6.727599e+05      -2.893410e+02 |       32
     15       6.724786e+05      -2.813516e+02 |       32
     16       6.722127e+05      -2.659082e+02 |       32
     17       6.719749e+05      -2.377376e+02 |       32
     18       6.717490e+05      -2.259826e+02 |       32
     19       6.715469e+05      -2.020774e+02 |       32
     20       6.713748e+05      -1.720993e+02 |       32
     21       6.712213e+05      -1.535046e+02 |       32
     22       6.710852e+05      -1.360316e+02 |       32
     23       6.709703e+05      -1.149237e+02 |       32
     24       6.708613e+05      -1.090527e+02 |       32
     25       6.707608e+05      -1.004814e+02 |       32
     26       6.706558e+05      -1.049887e+02 |       32
     27       6.705563e+05      -9.948482e+01 |       32
     28       6.704581e+05      -9.823014e+01 |       32
     29       6.703624e+05      -9.572287e+01 |       32
     30       6.702804e+05      -8.197974e+01 |       32
     31       6.702112e+05      -6.914312e+01 |       32
     32       6.701532e+05      -5.799304e+01 |       32
     33       6.700958e+05      -5.743235e+01 |       32
     34       6.700420e+05      -5.381420e+01 |       32
     35       6.699908e+05      -5.120233e+01 |       32
     36       6.699465e+05      -4.433870e+01 |       32
     37       6.699021e+05      -4.436753e+01 |       32
     38       6.698580e+05      -4.408509e+01 |       32
     39       6.698134e+05      -4.463087e+01 |       32
     40       6.697716e+05      -4.176840e+01 |       32
     41       6.697304e+05      -4.122460e+01 |       32
     42       6.696861e+05      -4.432228e+01 |       32
     43       6.696405e+05      -4.551695e+01 |       32
     44       6.695917e+05      -4.883483e+01 |       32
     45       6.695472e+05      -4.452066e+01 |       32
     46       6.695103e+05      -3.686389e+01 |       32
     47       6.694764e+05      -3.394113e+01 |       32
     48       6.694427e+05      -3.368990e+01 |       32
     49       6.694130e+05      -2.973389e+01 |       32
     50       6.693858e+05      -2.710466e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669385.8474338108)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419388
[ Info: iteration 2, average log likelihood -1.414271
[ Info: iteration 3, average log likelihood -1.412807
[ Info: iteration 4, average log likelihood -1.411625
[ Info: iteration 5, average log likelihood -1.410390
[ Info: iteration 6, average log likelihood -1.409365
[ Info: iteration 7, average log likelihood -1.408743
[ Info: iteration 8, average log likelihood -1.408418
[ Info: iteration 9, average log likelihood -1.408234
[ Info: iteration 10, average log likelihood -1.408110
[ Info: iteration 11, average log likelihood -1.408015
[ Info: iteration 12, average log likelihood -1.407936
[ Info: iteration 13, average log likelihood -1.407867
[ Info: iteration 14, average log likelihood -1.407807
[ Info: iteration 15, average log likelihood -1.407753
[ Info: iteration 16, average log likelihood -1.407703
[ Info: iteration 17, average log likelihood -1.407659
[ Info: iteration 18, average log likelihood -1.407618
[ Info: iteration 19, average log likelihood -1.407580
[ Info: iteration 20, average log likelihood -1.407546
[ Info: iteration 21, average log likelihood -1.407514
[ Info: iteration 22, average log likelihood -1.407484
[ Info: iteration 23, average log likelihood -1.407456
[ Info: iteration 24, average log likelihood -1.407430
[ Info: iteration 25, average log likelihood -1.407405
[ Info: iteration 26, average log likelihood -1.407381
[ Info: iteration 27, average log likelihood -1.407359
[ Info: iteration 28, average log likelihood -1.407338
[ Info: iteration 29, average log likelihood -1.407317
[ Info: iteration 30, average log likelihood -1.407298
[ Info: iteration 31, average log likelihood -1.407279
[ Info: iteration 32, average log likelihood -1.407261
[ Info: iteration 33, average log likelihood -1.407244
[ Info: iteration 34, average log likelihood -1.407227
[ Info: iteration 35, average log likelihood -1.407211
[ Info: iteration 36, average log likelihood -1.407195
[ Info: iteration 37, average log likelihood -1.407180
[ Info: iteration 38, average log likelihood -1.407166
[ Info: iteration 39, average log likelihood -1.407152
[ Info: iteration 40, average log likelihood -1.407139
[ Info: iteration 41, average log likelihood -1.407126
[ Info: iteration 42, average log likelihood -1.407114
[ Info: iteration 43, average log likelihood -1.407102
[ Info: iteration 44, average log likelihood -1.407090
[ Info: iteration 45, average log likelihood -1.407079
[ Info: iteration 46, average log likelihood -1.407069
[ Info: iteration 47, average log likelihood -1.407059
[ Info: iteration 48, average log likelihood -1.407049
[ Info: iteration 49, average log likelihood -1.407040
[ Info: iteration 50, average log likelihood -1.407031
┌ Info: EM with 100000 data points 50 iterations avll -1.407031
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.421888    -0.0691625     0.356343   -0.620729    0.451711    -0.090338   -0.106097   -0.0787779    0.761202    -0.338604   -0.0478647  -0.783837   -0.498496   -0.345324    0.220228   -0.151719     0.125302    -0.49965     0.425889   -0.350673     0.154582   -0.291085    0.110512     -0.172543   -0.762024   -0.0610667
 -0.0672996    0.176425      0.141659   -0.188552   -0.110464    -0.100863    0.0378799   0.17421      0.0444669    0.0511554   0.0659445  -0.165397   -0.0627451   0.12797     0.17797     0.12712      0.102409    -0.0421495   0.0284228   0.0549645    0.0315882  -0.156206   -0.000578525  -0.213673   -0.0105996  -0.0669017
 -0.234095     0.000483952   0.050576    0.392882   -0.129202    -0.352818    0.582094    0.410345     0.790253     0.0365415  -0.206973    0.458084   -0.3982      0.0931726  -0.167262   -0.187003    -0.816125    -0.593474    0.175456   -0.198018    -0.191214    0.149594   -0.254629      0.247072    0.202508   -0.25596
 -0.0702275    0.294732      1.08926     0.596968    0.0205701    0.20732     0.590215    0.00383694  -0.0758861    0.183069    0.0594445  -0.583372    0.0507608   0.49315     0.158903    0.273685    -0.327697     0.704098   -0.0209305   0.110695     0.747395    0.574929   -0.270085      0.255882    0.430229   -0.308507
 -0.750315     0.083965     -0.297214   -0.198928   -0.042053    -0.359522   -0.605108    0.238817    -0.279453    -0.455235    0.494604    0.704478    0.0223545   0.192944   -0.51576     0.255848     0.175773    -0.0609702  -0.161624    0.0460361    0.351544   -0.156317    0.187239      0.137205   -0.529631    0.27837
  0.108438     0.500081      0.203881   -0.188388   -0.0372101    0.343344    0.0601126   0.0882706   -0.591938    -0.0406034   0.0316898  -0.190885    0.0958641   0.592647    0.640168   -0.624381    -0.380929     0.202025    0.518272   -0.338298    -0.219953   -0.228839    0.243716     -0.337464    0.476388    0.537067
  0.682063     0.390774     -0.0488547  -0.0439837  -0.167294     0.021471    0.196168    0.00374065   0.579882     0.830362   -0.668035   -0.303648   -0.0219613  -0.707527    0.212901   -0.26652      0.0323572   -0.199323   -0.0742693  -0.0617015   -0.194401    0.397468   -0.287916     -0.0535389   0.463551   -0.142823
 -0.197207    -0.593802     -0.434442    0.145301   -0.376956     0.178462    0.129162    0.445128    -0.133982     0.0314796  -0.21158     0.581947    0.385193   -0.323248   -0.245558   -0.228552     0.932479    -0.198015   -0.430691    0.822832    -0.276031    0.239296   -0.200157     -0.222876    0.473385    0.207498
 -0.401137    -0.374732      0.325907    0.645322    0.296961     0.357873    0.395253    0.274453    -0.559669    -0.556881    0.632128    0.1346      0.207985    0.804271   -0.114206   -0.164786    -0.484111     0.22145     0.298843   -0.0591673    0.223883   -0.194015    0.412765     -0.310403   -0.670121   -0.0887482
 -0.13356     -0.0398255    -0.0234985   0.0446453   0.00939886  -0.0123471  -0.0268543  -0.102887    -0.167844    -0.0522421   0.0197362  -0.0268688   0.20035     0.108721   -0.141088    0.13042      0.0657786    0.033061   -0.161903    0.113465     0.0254798  -0.0542101  -0.0201255    -0.0140935  -0.0782508  -0.131846
  0.0941199    0.52273      -0.362047    0.632756    0.2742      -0.0503273  -0.153596    0.522313     0.137131    -0.0210969  -0.123244   -0.264748    0.175437    0.463153   -0.422908   -0.0505763   -0.354066     0.124274   -0.268503   -0.662077     0.496749    0.0464543  -0.0453249    -0.305103   -0.64914    -0.437302
 -0.0131592    0.329168      0.0865349  -0.683022   -0.168005     0.0867114  -0.109881   -0.322913    -0.049823    -0.0920287  -0.311664    0.283315   -0.0805806   0.298672   -0.0412977   0.167985    -0.93362     -0.0813481  -0.0229384  -0.233237     0.231238   -0.118837    0.460778      0.693726   -0.264854   -0.196297
  0.183687     0.148239     -0.183249   -0.623773    0.00250212   0.073665    0.614413   -0.454111    -0.158417    -0.212065    0.571536   -0.0131502  -0.602951   -0.59165     0.613352    0.368169     0.33506      0.149155    0.3959      0.656664    -0.434939    0.142348    0.109265      0.371083    0.536751    0.66651
  0.188948     0.395854     -0.040008    0.165379   -0.208792    -0.19644     0.745456   -0.00441187   0.0993171   -0.409906    0.0765653  -0.131561    0.0791607  -0.606047   -0.993649    0.0758396    0.187467    -0.0846428  -0.11782    -0.0964166    0.388127    0.26966    -0.338216      0.371392   -0.143662   -0.102584
 -0.00112638   0.109174     -0.0255898  -0.041997    0.0383748   -0.0722587  -0.111796    0.125329     0.116803     0.0754657  -0.0546119   0.0917828  -0.462867   -0.21559     0.236956    0.00712759  -0.0709652    0.134866    0.381547   -0.00430356  -0.113932    0.0594445  -0.0461577     0.19511     0.0372347   0.103858
  0.631486    -0.0743149    -0.499107   -0.593618    0.370704    -0.229112   -0.140379   -0.208511    -0.728216    -0.443246   -0.283559   -0.330994   -0.489388   -0.165933   -0.0327022   0.435187     0.826841    -0.048605    0.629445   -0.146325    -0.91348    -0.0749166   0.165276     -0.493084   -0.0442156  -0.101837
 -0.205598    -0.394861      1.00677     0.282353   -0.31544     -0.128747   -1.1054      0.256855     0.0658784   -0.103514   -0.605062    0.467251    0.389801    0.438284   -0.315287   -0.265636    -0.333764    -0.0127057   0.151889   -0.416534     0.452148   -0.334878   -0.494056     -0.193675   -0.478018   -0.891081
  0.278372    -0.135872     -0.412666    0.0630516   0.291423     0.293743    0.0261445  -0.309958    -0.0767219    0.0239285   0.018224    0.453204    0.299452   -0.156794   -0.377353   -0.295622    -0.491045     0.331629   -0.109801   -0.342403     0.0649997   0.470304    0.251609      0.903266   -0.078082    0.266554
  0.238053    -0.59861      -0.255866   -0.0837005   0.2229       0.479541   -0.0116218  -0.83111     -0.516017     0.109917   -0.444338   -0.306221    0.192643   -0.185708    0.61573     0.444914    -0.140334     0.110755    0.178722    0.127625    -0.447748   -0.107032    0.794919     -0.160994    0.128609    0.00818936
  0.304329    -0.074822      0.377287   -0.0170761   0.347001    -0.0629621   0.165244   -0.271536     0.174476     0.141708   -0.170453    0.107637    0.202388    0.0747256   0.0450669  -0.224644    -0.445874    -0.177305   -0.0416096  -0.324085     0.314669    0.204667    0.572757      0.0609771   0.123303    0.0606365
  0.149774    -0.034788     -0.728051    0.195121    0.0148188    0.555931    0.391833    0.0865286    0.375911    -0.195191   -0.355275   -0.071493    0.0641944  -0.0289276  -0.11472    -0.112984    -0.103915     0.154359    0.109189    0.185773    -0.826169    0.033815   -0.425022      0.328779   -0.197192   -0.350315
 -0.436432     0.0709932     0.603805    0.294591    0.33471     -0.541173   -0.042616   -0.672442    -0.0587274    0.33199     1.02739    -0.0404265  -0.0765796  -0.363718   -0.425248    0.0415762    0.22591      0.137918    0.0741905  -0.241235     0.263761    0.598008   -0.158715      0.0641863  -0.0267768   0.0893204
 -0.0354583   -0.122709      0.231238    0.15083    -0.510622    -0.0178211  -0.0150114  -0.0912208   -0.166688     0.757305    0.426296    0.223179    0.343066    0.297337    0.251991    0.463632    -0.153998     0.093416   -0.557152    0.45215      0.265283    0.0395109   0.488829      0.52646     0.513312    0.315859
 -0.0778031   -0.116017     -0.305764    0.123721    0.331712    -0.0691687  -0.503617   -0.625242    -0.507563     0.010807   -0.726506    0.416258   -0.399469   -0.161513   -0.311821    0.155545    -0.0940075    0.171949   -0.0226986  -0.0115199    0.184097    0.198917   -0.117706      0.176253    0.406857   -0.282308
 -0.3665       0.230622     -0.512145   -0.365272    0.351119    -0.135584   -0.61295     0.0436925   -0.0359817    0.201384   -0.148165   -0.147648    0.122749   -0.165249    0.0401149   0.443845     0.450413     0.265692   -0.317159    0.925543    -0.244463   -0.319589   -0.245053     -0.185375   -0.753792    0.235057
 -0.0540153    0.394078      0.368671    0.22422     0.452275    -1.00015    -0.295529    0.431872     0.079482     0.215726    0.285068    0.094549   -0.171216   -0.310539    0.247644    0.17229      0.05782      0.329367    0.274152    0.217129     0.453373   -0.355565   -0.396419     -0.373847    0.239903    0.687633
  0.263223     0.0594269     0.335614   -0.342147    0.0451972    0.129574   -0.633091   -0.292434    -0.977256    -0.148445    0.401527   -0.22497     0.46536     0.0596079  -0.0543729   0.060349     0.66354      0.807539   -0.0742893  -0.248772     0.436192    0.268581    0.331905     -0.0626877  -0.513434   -0.0105007
 -0.0289805   -0.215141      0.116728   -0.0399097  -0.314441    -0.249253    0.1341      0.170491    -0.0419082    0.293628    0.366866    0.0299428  -0.682925    0.473383    0.151875   -0.0657543    0.435691     0.385231   -0.369006   -0.454145    -0.122133   -0.305926   -0.213124     -0.333911    0.635238   -0.249255
 -0.0618775    0.216265     -0.0978681   0.125367   -0.213392     0.141573    0.465116    0.43265      0.320767     0.0475132   0.36094    -0.21576     0.395118   -0.334204    0.13076    -0.266689     0.268619    -0.130535    0.0205316   0.102673     0.0297604   0.272329    0.200798     -0.056125   -0.206228    0.634873
  0.16969     -0.813493      0.389994   -0.218101   -0.428631     0.147658    0.184875   -0.285473     0.0747167    0.2996      0.0980642  -0.0569421   0.15352     0.20475     0.223175   -0.104919    -0.094326    -0.228996    0.413814    0.0240289   -0.710976    0.106864   -0.102898      0.497673    0.482766   -0.328487
 -0.122193    -0.170824     -0.0950928  -0.260988   -0.635954     0.0615664   0.150741    0.530224     0.141702    -0.534214   -0.746735   -0.0983177  -0.26817    -0.124329    0.776347    0.505148    -0.00420294  -0.43103     0.0453757   0.456586    -0.0419966  -0.245531   -0.0556342    -0.476274    0.241741    0.030435
 -0.368476    -0.683104      0.101011    0.236999   -0.162329    -0.130841    0.0323559  -0.60406     -0.00020295  -0.180033   -0.257673   -0.294163    0.694966    0.306515   -0.613554    0.149205     0.281313    -0.600358   -0.532619   -0.137141     0.452288    0.373566   -0.194276     -0.605769   -0.373477   -0.704845[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407022
[ Info: iteration 2, average log likelihood -1.407014
[ Info: iteration 3, average log likelihood -1.407006
[ Info: iteration 4, average log likelihood -1.406998
[ Info: iteration 5, average log likelihood -1.406990
[ Info: iteration 6, average log likelihood -1.406983
[ Info: iteration 7, average log likelihood -1.406976
[ Info: iteration 8, average log likelihood -1.406969
[ Info: iteration 9, average log likelihood -1.406962
[ Info: iteration 10, average log likelihood -1.406956
┌ Info: EM with 100000 data points 10 iterations avll -1.406956
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
