Julia Version 1.5.0-DEV.133
Commit c9940ed95b (2020-01-21 18:51 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed URIParser ────────── v0.4.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed QuadGK ───────────── v2.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed StatsBase ────────── v0.32.0
 Installed Rmath ────────────── v0.6.0
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed PDMats ───────────── v0.9.10
 Installed NearestNeighbors ─── v0.4.4
 Installed DataStructures ───── v0.17.9
 Installed StatsFuns ────────── v0.9.3
 Installed FileIO ───────────── v1.2.1
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Arpack ───────────── v0.4.0
 Installed Clustering ───────── v0.13.3
 Installed JLD ──────────────── v0.9.1
 Installed StaticArrays ─────── v0.12.1
 Installed Blosc ────────────── v0.5.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Compat ───────────── v2.2.0
 Installed Distances ────────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.22.3
 Installed SpecialFunctions ─── v0.9.0
 Installed DataAPI ──────────── v1.1.0
 Installed LegacyStrings ────── v0.4.1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_nM2Afb/Project.toml`
 [no changes]
  Updating `/tmp/jl_nM2Afb/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_aDZhgm/Project.toml`
 [no changes]
  Updating `/tmp/jl_aDZhgm/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_Rq3Ap0/Project.toml`
 [no changes]
  Updating `/tmp/jl_Rq3Ap0/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_up8n1l/Project.toml`
 [no changes]
  Updating `/tmp/jl_up8n1l/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_jFs5d8/Project.toml`
 [no changes]
  Updating `/tmp/jl_jFs5d8/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_jFs5d8/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -751617.5212541827, [27134.38603721593, 72865.61396278407], [-12840.844346760477 10316.926920462083 4191.741963316983; 13154.91706590257 -9651.70434548245 -3991.672339659505], [[17705.077490234202 -9803.051806363941 -8976.970869226778; -9803.051806363943 24001.066387475792 -9548.601867051437; -8976.970869226778 -9548.601867051437 28288.77176684584], [82428.34839403123 10516.584306697268 9056.251285459453; 10516.584306697268 75965.90064728004 9677.040031046152; 9056.251285459453 9677.040031046152 71489.92627655894]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.432555e+03
      1       9.797489e+02      -4.528062e+02 |        8
      2       9.188319e+02      -6.091696e+01 |        2
      3       9.111054e+02      -7.726513e+00 |        0
      4       9.111054e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 911.1054033090081)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076159
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.810953
[ Info: iteration 2, lowerbound -3.659274
[ Info: iteration 3, lowerbound -3.494375
[ Info: iteration 4, lowerbound -3.312750
[ Info: iteration 5, lowerbound -3.137958
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.979326
[ Info: iteration 7, lowerbound -2.854350
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.771944
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.707795
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.647886
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.575920
[ Info: iteration 12, lowerbound -2.503443
[ Info: iteration 13, lowerbound -2.440271
[ Info: iteration 14, lowerbound -2.389755
[ Info: iteration 15, lowerbound -2.351910
[ Info: iteration 16, lowerbound -2.324827
[ Info: iteration 17, lowerbound -2.309723
[ Info: iteration 18, lowerbound -2.308453
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 22 16:19:08 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 22 16:19:17 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Jan 22 16:19:19 2020: EM with 272 data points 0 iterations avll -2.076159
5.8 data points per parameter
, Wed Jan 22 16:19:21 2020: GMM converted to Variational GMM
, Wed Jan 22 16:19:29 2020: iteration 1, lowerbound -3.810953
, Wed Jan 22 16:19:29 2020: iteration 2, lowerbound -3.659274
, Wed Jan 22 16:19:29 2020: iteration 3, lowerbound -3.494375
, Wed Jan 22 16:19:29 2020: iteration 4, lowerbound -3.312750
, Wed Jan 22 16:19:29 2020: iteration 5, lowerbound -3.137958
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 7
, Wed Jan 22 16:19:30 2020: iteration 6, lowerbound -2.979326
, Wed Jan 22 16:19:30 2020: iteration 7, lowerbound -2.854350
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 6
, Wed Jan 22 16:19:30 2020: iteration 8, lowerbound -2.771944
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 5
, Wed Jan 22 16:19:30 2020: iteration 9, lowerbound -2.707795
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 4
, Wed Jan 22 16:19:30 2020: iteration 10, lowerbound -2.647886
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 3
, Wed Jan 22 16:19:30 2020: iteration 11, lowerbound -2.575920
, Wed Jan 22 16:19:30 2020: iteration 12, lowerbound -2.503443
, Wed Jan 22 16:19:30 2020: iteration 13, lowerbound -2.440271
, Wed Jan 22 16:19:30 2020: iteration 14, lowerbound -2.389755
, Wed Jan 22 16:19:30 2020: iteration 15, lowerbound -2.351910
, Wed Jan 22 16:19:30 2020: iteration 16, lowerbound -2.324827
, Wed Jan 22 16:19:30 2020: iteration 17, lowerbound -2.309723
, Wed Jan 22 16:19:30 2020: iteration 18, lowerbound -2.308453
, Wed Jan 22 16:19:30 2020: dropping number of Gaussions to 2
, Wed Jan 22 16:19:30 2020: iteration 19, lowerbound -2.302915
, Wed Jan 22 16:19:30 2020: iteration 20, lowerbound -2.299259
, Wed Jan 22 16:19:30 2020: iteration 21, lowerbound -2.299256
, Wed Jan 22 16:19:30 2020: iteration 22, lowerbound -2.299254
, Wed Jan 22 16:19:30 2020: iteration 23, lowerbound -2.299254
, Wed Jan 22 16:19:30 2020: iteration 24, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 25, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 26, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 27, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 28, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 29, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 30, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 31, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 32, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 33, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 34, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 35, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 36, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 37, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 38, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 39, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 40, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 41, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 42, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 43, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 44, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 45, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 46, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 47, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 48, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 49, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: iteration 50, lowerbound -2.299253
, Wed Jan 22 16:19:30 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260141, 95.95490777398594]
β = [178.0450922260141, 95.95490777398594]
m = [4.250300733269907 79.28686694436182; 2.000229257775368 53.851987172461264]
ν = [180.0450922260141, 97.95490777398594]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484594 -0.007644049042327515; 0.0 0.008581705166333456], [0.3758763611948427 -0.008953123827346086; 0.0 0.012748664777409213]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.981421712470255
avll from llpg:  -0.9814217124702554
avll direct:     -0.9814217124702554
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0004476310530699
avll from llpg:  -1.0004476310530699
avll direct:     -1.0004476310530699
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0642999    0.00893527  -0.00313895  -0.118395    -0.0546815    0.135636    -0.172067      0.100248      0.0132666     0.0627584  -0.0480408     0.0977923   -0.0406114    0.0376945    0.0540271  -0.118981     0.0817326    0.0184848     0.0601167   0.223079     0.0486818   0.0754341    -0.00946706  -0.0860615   -0.0696474    0.114286
  0.0384929    0.0205725    0.0515866   -0.0415426   -0.0630896   -0.0166148    0.12799      -0.0240117    -0.0948575     0.0901837   0.135369      0.0941699    0.145986    -0.0767936    0.0493798   0.0384563   -0.0441142    0.0732204     0.0923215   0.0151988   -0.152886   -0.0728807    -0.0215202    0.153907    -0.130031     0.0877308
 -0.0778552    0.115856    -0.0894495    0.126235     0.0526724   -0.0325412    0.0899268     0.0362417     0.0589805    -0.0622631  -0.0074734    -0.0814688   -0.0513771   -0.083094    -0.187982    0.0281063   -0.0813743    0.00081725    0.135361    0.0904104    0.095471   -0.095495     -0.110692    -0.147389    -0.0440004   -0.052759
  0.0234046   -0.0168004   -0.00822924   0.0317179   -0.015035    -0.0546212   -0.147704     -0.0626363    -0.0575353     0.14046    -0.122111     -0.0397263    0.0573762    0.0370722    0.121127    0.144561     0.00683018  -0.0483051    -0.0760333   0.15908     -0.0501582   0.0751544     0.0191976    0.0512552   -0.00367719  -0.0829585
  0.174194     0.220054     0.0425927   -0.168706     0.0941109    0.0810058   -0.143127      0.058865      0.0886593    -0.0466591  -0.0928444     0.0846124   -0.0561402    0.0529998   -0.0690123   0.135717    -0.0900863   -0.0146051     0.0689179  -0.193558     0.207585   -0.0977642     0.0264558    0.0139475   -0.0166511    0.0547199
 -0.180113    -0.0583784   -0.258035    -0.0210946   -0.0995166    0.0780993   -0.0594111     0.0910361     0.0596091    -0.0905174  -0.0247555    -0.0458906    0.0109023   -0.0960759   -0.115272   -0.0262263   -0.00333825   0.171028      0.162636   -0.089847    -0.0427158  -0.0410532    -0.0261899    0.00502195   0.114687     0.14402
  0.074058     0.0383892   -0.0661456    0.0687571   -0.0307191    0.0782198    0.0706848     0.188323      0.0668578     0.105066    0.00213704   -0.230463    -0.0269106    0.155433    -0.0164621   0.125691     0.0334659    0.020225      0.0516979  -0.0430739   -0.0885552  -0.122676     -0.149685     0.102548     0.0913207    0.0152027
  0.249027    -0.0813315    0.0916568    0.0356656   -0.106795    -0.00410139   0.117486      0.132292      0.0572013     0.112748    0.121743      0.0939214    0.0307098    0.145189     0.0985694  -0.135694     0.0512272   -0.000862971   0.0426542   0.0501308   -0.189844    0.028209     -0.0221153   -0.233062     0.123742    -0.0610793
 -0.0368685   -0.0106958    0.0320426    0.160436     0.152628     0.0964494   -0.0210513    -0.110159      0.0628952     0.0524788   0.0866935     0.187312    -0.0728194    0.136099    -0.0375225  -0.00154579   0.0601324    0.0602262     0.102686    0.0798734   -0.019389   -0.0504975     0.0178895    0.0107975    0.0562914   -0.183414
 -0.0428912   -0.134655    -0.0513532    0.0705895   -0.0746767   -0.0135968    0.049347      0.0544658     0.018445     -0.167875    0.136676      0.115315     0.00676799   0.12946      0.170359    0.0561726   -0.13083      0.155974     -0.198579    0.0249905    0.0184516   0.0209508     0.0335716   -0.0999072   -0.0143978   -0.0651268
 -0.0237669    0.054343     0.127328    -0.118435     0.185126    -0.13624     -0.0709135    -0.0607985     0.15227      -0.0136251   0.201391     -0.0635497    0.155674     0.114853     0.14424     0.0247251   -0.143417    -0.104599     -0.168979   -0.0158001    0.0325692   0.0496293     0.114478    -0.0344764   -0.022392     0.087617
 -0.0700517   -0.0195816   -0.0154572   -0.0123593   -0.0128153   -0.0147618    0.0519123     0.0480109    -0.108658      0.080597    0.135776      0.128107    -0.00653115   0.0256139    0.0449225  -0.131655     0.139535     0.00191845   -0.0227323  -0.13288     -0.0434571  -0.0228002     0.0722905   -0.218008    -0.0938064    0.1251
  0.0262221   -0.0268707    0.170923    -0.0240729    0.08033     -0.0217364    0.0810891    -0.0272461    -0.0322181     0.122103   -0.018193      0.157507    -0.1503      -0.0738744    0.0573291   0.020724     0.0528058   -0.0693992     0.0359216   0.00708297  -0.1208      0.000139309  -0.115344    -0.177964     0.0923198    0.275021
  0.0249939    0.087582    -0.071248    -0.16402      0.0317513    0.0816127    0.0530364    -0.0512277    -0.0488731     0.116266    0.220242     -0.149796     0.155916     0.0163837    0.0695236  -0.078634    -0.0111863    0.0328936    -0.135146   -0.00363308   0.14309     0.000245294   0.0247335    0.0361947    0.0206732   -0.0661468
  0.0798122    0.249206    -0.041931     0.0259758    0.0473253    0.144992     0.117483     -0.075781      0.0206066    -0.0143376   0.0672734    -0.0263592   -0.0982916   -0.0381717   -0.0620155  -0.098676     0.0566388   -0.0327731    -0.30569     0.0983945    0.102139   -0.0548142    -0.103486    -0.0614169   -0.0342719    0.168121
  0.159294     0.0444027    0.0145498    0.0176571    0.0689456    0.197486     0.0864687    -0.0217488    -0.163867      0.144938   -0.0722405     0.11076      0.153409    -0.0656005    0.110625    0.00637496   0.0327989    0.120955     -0.12002    -0.00395718   0.0116105   0.0339148    -0.0449116   -0.0868194   -0.152916     0.0525379
  0.00814044   0.124576     0.195489    -0.0893691   -0.0105291   -0.208501    -0.0225342     0.0518228    -0.0395419     0.0115059   0.176603     -0.042221    -0.0115774   -0.0500514    0.066739   -0.103222    -0.163191     0.0555308     0.055063   -0.0161434   -0.0680576   0.145034     -0.047983     0.0129881    0.00496912   0.0529737
 -0.0289775    0.0756716   -0.201146     0.0803931   -0.0948236   -0.1441      -0.107319     -0.0431642     0.0421898     0.0413293  -0.12288      -0.0232765   -0.0517781   -0.051074     0.11974    -0.0233522    0.0202614   -0.00575266    0.0669765   0.0194517   -0.0795999   0.00457392   -0.0968492   -0.0543359   -0.196047    -0.0366702
  0.0644071    0.101068     0.00124725   0.0498002   -0.013568     0.209793     0.0180894    -0.0427382    -0.000683925  -0.0489349   0.000329952  -0.0831667    0.123638    -0.0521515   -0.22177    -0.0944324    0.0424461    0.0507248     0.164095    0.0719651    0.0492246  -0.0493936    -0.0371287    0.116376    -0.0768469   -0.0820093
 -0.0580814    0.144953     0.0449355   -0.0281858   -0.0632698   -0.148926     0.0932327     0.0458222     0.16564      -0.0730709   0.0580368    -0.0950117   -0.0943955   -0.00392255   0.0290016   0.0846531    0.013846     0.00449678    0.0837409  -0.0552212   -0.0582492   0.00529187   -0.0547178    0.0405821   -0.0570142   -0.126641
 -0.0168687   -0.0899605   -0.0323426   -0.0585914   -0.159947    -0.0569657   -0.0065662     0.133991      0.111612      0.100382   -0.0132385    -0.026643    -0.162408    -0.11938      0.0221418   0.00307974   0.0159547   -0.0417043    -0.139551   -0.069745    -0.062964   -0.0709316    -0.0205259   -0.166489    -0.112931    -0.0150586
 -0.054319     0.198989    -0.0703432    0.004368     0.0290773    0.0245217    0.015519      0.0694731    -0.0152894    -0.0836543  -0.0144895    -0.130376    -0.101726    -0.0456986   -0.10524    -0.0206434    0.0212799    0.0305242    -0.0615816  -0.0674745    0.0905605  -0.0938146     0.149899    -0.112404    -0.0303733   -0.0758564
  0.135906     0.0209872   -0.0728599    0.0647935    0.1087      -0.0210769    0.000130882   0.000257542  -0.00822576    0.0759248   0.0210224    -0.160092    -0.0636213    0.217521     0.0584757   0.0535396    0.0549813    0.00843873    0.0088096  -0.0720012    0.0746861  -0.0525546    -0.012935     0.128483    -0.111933     0.152003
 -0.0827161    0.166902     0.00940424  -0.0227611   -0.0550501    0.0902609   -0.00421702   -0.0153678     0.00567407   -0.0335925   0.0998329     0.0544821   -0.00636962   0.0358137   -0.0635231   0.0263026   -0.015444     0.079744     -0.158872    0.0724156    0.0570656   0.0970625     0.0956756    0.104102     0.161361     0.0297547
  0.124793     0.161772     0.0179944   -0.0571614   -0.0969756   -0.108508     0.00326523    0.235537     -0.00401189   -0.0514403   0.116003      0.0942146    0.192827     0.115373    -0.0765143   0.110052     0.0871314    0.0934577    -0.143018   -0.00865886  -0.079452   -0.011971      0.063444     0.0699777   -0.0866851    0.126974
  0.0614076   -0.0567118    0.154765     0.218754     0.0185126    0.0306562    0.0844466    -0.110929      0.0463019     0.0365726  -0.0629256     0.0292328   -0.0440255    0.0644532    0.0673848   0.0672411   -0.0643273    0.0766561    -0.0764221  -0.0615547    0.034191    0.0650012     0.186251    -0.0687317   -0.197991     0.00629002
  0.115457     0.0363757    0.032712    -0.00480761  -0.00576392  -0.00276808   0.00452445    0.0592578    -0.0484161    -0.14566     0.0912861     0.084585    -0.0460812   -0.0773294   -0.116021   -0.00384509   0.0749955   -0.0543283    -0.0504665   0.0193856   -0.0665254   0.0462054    -0.0217737    0.172711     0.0199094    0.0214037
 -0.140387    -0.0722956    0.0666483   -0.0249396   -0.0559146    0.240991     0.144706     -0.0689665     0.041387     -0.119863   -0.125121     -0.159186    -0.0115725    0.104371    -0.177063    0.197214     0.0806237    0.236125      0.0419052  -0.151        0.182327    0.0569282     0.222344    -0.125506    -0.103537    -0.0888704
  0.013689    -0.147362    -0.0331169   -0.0693588    0.261627    -0.0337384    0.00417626   -0.110755     -0.000759084   0.103133   -0.0238449     0.0341438   -0.0571388   -0.00658866   0.0376807   0.0751532    0.066826     0.134302      0.0754184  -0.00494321   0.0505909   0.181298     -0.0322831    0.0760118   -0.0414637   -0.0135137
 -0.047342     0.0216536   -0.0833193    0.0305666   -0.369255    -0.0120415   -0.124093      0.184692     -0.231697      0.126924    0.1514       -0.169139     0.0961857    0.193819    -0.166645    0.00414631   0.307414    -0.114905      0.0510046  -0.252142    -0.0396061   0.0703835     0.0703564    0.0639298   -0.0137438   -0.0588369
  0.135217     0.127435     0.206278    -0.19089      0.038851    -0.0398679    0.0285882    -0.132951     -0.0408418    -0.0221298  -0.0421794     0.0442012   -0.0901538   -0.0234214    0.0610625  -0.148348     0.0376161    0.0661352     0.0498154  -0.0516742   -0.0175954   0.093825      0.00107413   0.0578899   -0.0431954   -0.089441
 -0.0126725   -0.22265     -0.090634    -0.0580377   -0.220012    -0.131382    -0.0104769     0.0816709    -0.022165     -0.0483099   0.0639688     0.00704289   0.123909    -0.0552351   -0.0892284  -0.0948567   -0.0245557    0.145171     -0.126499   -0.0279852    0.0843888  -0.0252668     0.184583    -0.0309222   -0.00532443  -0.0493597kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3727548274214763
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.372810
[ Info: iteration 2, average log likelihood -1.372745
[ Info: iteration 3, average log likelihood -1.371771
[ Info: iteration 4, average log likelihood -1.362444
[ Info: iteration 5, average log likelihood -1.341296
[ Info: iteration 6, average log likelihood -1.334084
[ Info: iteration 7, average log likelihood -1.332832
[ Info: iteration 8, average log likelihood -1.332064
[ Info: iteration 9, average log likelihood -1.331406
[ Info: iteration 10, average log likelihood -1.330801
[ Info: iteration 11, average log likelihood -1.330231
[ Info: iteration 12, average log likelihood -1.329708
[ Info: iteration 13, average log likelihood -1.329287
[ Info: iteration 14, average log likelihood -1.328960
[ Info: iteration 15, average log likelihood -1.328703
[ Info: iteration 16, average log likelihood -1.328521
[ Info: iteration 17, average log likelihood -1.328393
[ Info: iteration 18, average log likelihood -1.328294
[ Info: iteration 19, average log likelihood -1.328200
[ Info: iteration 20, average log likelihood -1.328083
[ Info: iteration 21, average log likelihood -1.327943
[ Info: iteration 22, average log likelihood -1.327801
[ Info: iteration 23, average log likelihood -1.327684
[ Info: iteration 24, average log likelihood -1.327597
[ Info: iteration 25, average log likelihood -1.327535
[ Info: iteration 26, average log likelihood -1.327492
[ Info: iteration 27, average log likelihood -1.327461
[ Info: iteration 28, average log likelihood -1.327439
[ Info: iteration 29, average log likelihood -1.327422
[ Info: iteration 30, average log likelihood -1.327410
[ Info: iteration 31, average log likelihood -1.327400
[ Info: iteration 32, average log likelihood -1.327392
[ Info: iteration 33, average log likelihood -1.327385
[ Info: iteration 34, average log likelihood -1.327379
[ Info: iteration 35, average log likelihood -1.327374
[ Info: iteration 36, average log likelihood -1.327370
[ Info: iteration 37, average log likelihood -1.327366
[ Info: iteration 38, average log likelihood -1.327362
[ Info: iteration 39, average log likelihood -1.327358
[ Info: iteration 40, average log likelihood -1.327355
[ Info: iteration 41, average log likelihood -1.327352
[ Info: iteration 42, average log likelihood -1.327349
[ Info: iteration 43, average log likelihood -1.327347
[ Info: iteration 44, average log likelihood -1.327345
[ Info: iteration 45, average log likelihood -1.327344
[ Info: iteration 46, average log likelihood -1.327342
[ Info: iteration 47, average log likelihood -1.327341
[ Info: iteration 48, average log likelihood -1.327341
[ Info: iteration 49, average log likelihood -1.327340
[ Info: iteration 50, average log likelihood -1.327339
┌ Info: EM with 100000 data points 50 iterations avll -1.327339
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3728104144202018
│     -1.3727452761021601
│      ⋮
└     -1.3273393464125407
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327439
[ Info: iteration 2, average log likelihood -1.327340
[ Info: iteration 3, average log likelihood -1.326693
[ Info: iteration 4, average log likelihood -1.319562
[ Info: iteration 5, average log likelihood -1.300003
[ Info: iteration 6, average log likelihood -1.289652
[ Info: iteration 7, average log likelihood -1.287067
[ Info: iteration 8, average log likelihood -1.286109
[ Info: iteration 9, average log likelihood -1.285583
[ Info: iteration 10, average log likelihood -1.285177
[ Info: iteration 11, average log likelihood -1.284768
[ Info: iteration 12, average log likelihood -1.284253
[ Info: iteration 13, average log likelihood -1.283580
[ Info: iteration 14, average log likelihood -1.282890
[ Info: iteration 15, average log likelihood -1.282283
[ Info: iteration 16, average log likelihood -1.281672
[ Info: iteration 17, average log likelihood -1.281047
[ Info: iteration 18, average log likelihood -1.280420
[ Info: iteration 19, average log likelihood -1.279850
[ Info: iteration 20, average log likelihood -1.279378
[ Info: iteration 21, average log likelihood -1.279020
[ Info: iteration 22, average log likelihood -1.278727
[ Info: iteration 23, average log likelihood -1.278405
[ Info: iteration 24, average log likelihood -1.277945
[ Info: iteration 25, average log likelihood -1.277423
[ Info: iteration 26, average log likelihood -1.277006
[ Info: iteration 27, average log likelihood -1.276664
[ Info: iteration 28, average log likelihood -1.276381
[ Info: iteration 29, average log likelihood -1.276152
[ Info: iteration 30, average log likelihood -1.275972
[ Info: iteration 31, average log likelihood -1.275832
[ Info: iteration 32, average log likelihood -1.275724
[ Info: iteration 33, average log likelihood -1.275634
[ Info: iteration 34, average log likelihood -1.275555
[ Info: iteration 35, average log likelihood -1.275488
[ Info: iteration 36, average log likelihood -1.275430
[ Info: iteration 37, average log likelihood -1.275381
[ Info: iteration 38, average log likelihood -1.275337
[ Info: iteration 39, average log likelihood -1.275296
[ Info: iteration 40, average log likelihood -1.275258
[ Info: iteration 41, average log likelihood -1.275223
[ Info: iteration 42, average log likelihood -1.275190
[ Info: iteration 43, average log likelihood -1.275158
[ Info: iteration 44, average log likelihood -1.275129
[ Info: iteration 45, average log likelihood -1.275100
[ Info: iteration 46, average log likelihood -1.275071
[ Info: iteration 47, average log likelihood -1.275042
[ Info: iteration 48, average log likelihood -1.275012
[ Info: iteration 49, average log likelihood -1.274980
[ Info: iteration 50, average log likelihood -1.274947
┌ Info: EM with 100000 data points 50 iterations avll -1.274947
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3274392909839698
│     -1.3273396496499392
│      ⋮
└     -1.2749469839841705
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.275056
[ Info: iteration 2, average log likelihood -1.274866
[ Info: iteration 3, average log likelihood -1.273741
[ Info: iteration 4, average log likelihood -1.264401
[ Info: iteration 5, average log likelihood -1.242975
[ Info: iteration 6, average log likelihood -1.226441
[ Info: iteration 7, average log likelihood -1.220290
[ Info: iteration 8, average log likelihood -1.217772
[ Info: iteration 9, average log likelihood -1.216388
[ Info: iteration 10, average log likelihood -1.215458
[ Info: iteration 11, average log likelihood -1.214751
[ Info: iteration 12, average log likelihood -1.214172
[ Info: iteration 13, average log likelihood -1.213648
[ Info: iteration 14, average log likelihood -1.213131
[ Info: iteration 15, average log likelihood -1.212584
[ Info: iteration 16, average log likelihood -1.212005
[ Info: iteration 17, average log likelihood -1.211486
[ Info: iteration 18, average log likelihood -1.211115
[ Info: iteration 19, average log likelihood -1.210903
[ Info: iteration 20, average log likelihood -1.210775
[ Info: iteration 21, average log likelihood -1.210681
[ Info: iteration 22, average log likelihood -1.210598
[ Info: iteration 23, average log likelihood -1.210516
[ Info: iteration 24, average log likelihood -1.210428
[ Info: iteration 25, average log likelihood -1.210326
[ Info: iteration 26, average log likelihood -1.210202
[ Info: iteration 27, average log likelihood -1.210053
[ Info: iteration 28, average log likelihood -1.209894
[ Info: iteration 29, average log likelihood -1.209728
[ Info: iteration 30, average log likelihood -1.209575
[ Info: iteration 31, average log likelihood -1.209453
[ Info: iteration 32, average log likelihood -1.209359
[ Info: iteration 33, average log likelihood -1.209286
[ Info: iteration 34, average log likelihood -1.209221
[ Info: iteration 35, average log likelihood -1.209155
[ Info: iteration 36, average log likelihood -1.209084
[ Info: iteration 37, average log likelihood -1.209007
[ Info: iteration 38, average log likelihood -1.208926
[ Info: iteration 39, average log likelihood -1.208839
[ Info: iteration 40, average log likelihood -1.208745
[ Info: iteration 41, average log likelihood -1.208634
[ Info: iteration 42, average log likelihood -1.208495
[ Info: iteration 43, average log likelihood -1.208308
[ Info: iteration 44, average log likelihood -1.208030
[ Info: iteration 45, average log likelihood -1.207583
[ Info: iteration 46, average log likelihood -1.206842
[ Info: iteration 47, average log likelihood -1.205741
[ Info: iteration 48, average log likelihood -1.204568
[ Info: iteration 49, average log likelihood -1.203932
[ Info: iteration 50, average log likelihood -1.203732
┌ Info: EM with 100000 data points 50 iterations avll -1.203732
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2750564247637828
│     -1.2748660265946699
│      ⋮
└     -1.2037320069226838
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.203853
[ Info: iteration 2, average log likelihood -1.203553
[ Info: iteration 3, average log likelihood -1.201796
[ Info: iteration 4, average log likelihood -1.179453
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.131544
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.120082
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.113875
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120612
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.110099
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.119933
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.112777
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.109712
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│     11
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.106400
[ Info: iteration 14, average log likelihood -1.133617
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.104955
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.119602
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.106147
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.116989
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.110362
[ Info: iteration 20, average log likelihood -1.117295
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.090052
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.126467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.111873
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102783
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│     11
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.098273
[ Info: iteration 26, average log likelihood -1.124855
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.094734
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.110810
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.098487
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.110437
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.105960
[ Info: iteration 32, average log likelihood -1.112895
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.084861
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.116378
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.110815
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.100491
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     11
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.097524
[ Info: iteration 38, average log likelihood -1.118747
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.091701
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.114933
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.100700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.105985
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.103997
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.111537
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.089761
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.119030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.106880
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.098261
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│     11
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.096214
[ Info: iteration 50, average log likelihood -1.123633
┌ Info: EM with 100000 data points 50 iterations avll -1.123633
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.203852584004854
│     -1.2035532156003201
│      ⋮
└     -1.1236333057461132
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.094545
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.086756
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.085738
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.078822
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.056813
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.027625
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.024860
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.019817
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.014687
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.033466
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.031487
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.009895
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.025194
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.026385
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.030488
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.018477
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.014855
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.036345
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.024674
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.005417
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.018805
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.022069
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.036363
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.024313
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.013781
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.015226
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.037240
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.032991
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.015686
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.007791
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.018594
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      6
│     11
│     12
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.028086
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.035409
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.015610
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.016187
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.030614
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.022682
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.018620
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.022655
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.015810
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.033715
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.020900
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.021340
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.019756
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.029915
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.027362
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.016753
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      6
│     11
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.005711
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.027872
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.032974
┌ Info: EM with 100000 data points 50 iterations avll -1.032974
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.0945449711363577
│     -1.0867559905241087
│      ⋮
└     -1.0329743541228142
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3727548274214763
│     -1.3728104144202018
│     -1.3727452761021601
│     -1.3717713208875246
│      ⋮
│     -1.005710673785205
│     -1.0278717048177513
└     -1.0329743541228142
32×26 Array{Float64,2}:
  0.0149067    0.0571189   -0.00679509  -0.0435411   -0.0389952   -0.0686932    0.0443212    0.121317    -0.0827049    0.00569105   0.104331     0.113387     0.0814463    0.0650233   -0.00497861   -0.0122972    0.112161     0.0402665    -0.0681069  -0.0688011   -0.0645793   -0.0051231    0.0608124   -0.0901553   -0.129697     0.108246
  0.00161682   0.0640881    0.10899     -0.119996     0.131273    -0.120434    -0.0586895   -0.0236265    0.115255    -0.0400061    0.187561    -0.0608402    0.142442     0.111817     0.0914486     0.0320975   -0.0966492   -0.0706933    -0.155104    0.0191923    0.0151766    0.0439485    0.094766    -0.0129245   -0.0443842    0.0849607
  0.0151204   -0.0544707   -0.0935905    0.0169401   -0.169894    -0.0566224   -0.0476548    0.101566    -0.100108     0.0457345    0.0940948   -0.113966     0.0592943    0.117527    -0.0769398     0.0358845    0.125614     0.000205165  -0.0314932  -0.136076     0.0424735   -0.00949097   0.0617163    0.0466516   -0.0409837    0.0152005
  0.00938913   0.0591507    0.0399605   -0.0864513    0.0151072    0.182169     0.0137549   -0.027849     0.0675406   -0.0780544   -0.110081    -0.0488538   -0.0300679    0.0752374   -0.128929      0.158311     0.00278712   0.125071      0.0520784  -0.173899     0.165646    -0.0284701    0.1357      -0.0582497   -0.0537395   -0.0285435
  0.116114     0.0453803    0.0529884   -0.00629263  -0.00571044   0.0251967   -0.0198513    0.0425193   -0.0510043   -0.135973     0.0904673    0.0841802   -0.0542258   -0.0730598   -0.121529      0.00271279   0.0792609   -0.0319453    -0.048517    0.0364913   -0.00578267   0.0464949   -0.0179974    0.175169     0.0518388    0.0135893
 -0.0691425   -0.0111683    0.0240932    0.127625     0.148608     0.0140926   -0.0192775   -0.112714     0.0645262    0.0427157    0.0865331    0.184239    -0.0837615    0.131787    -0.0410586    -0.0124873    0.0663088    0.0512856     0.0969297   0.0805346   -0.00184985  -0.0540006    0.0201089    0.0113473    0.0537106   -0.182371
  0.0387421    0.0312497    0.0504615   -0.0405686   -0.0534531    0.011411     0.0723703   -0.0133564   -0.0990097    0.0880253    0.141892     0.0869635    0.146088    -0.0741893    0.041602      0.0322932   -0.0546632    0.0250485     0.0730597   0.00901961  -0.129865    -0.0711142    0.00865031   0.147667    -0.0625636    0.114296
 -0.00500363   0.0409108   -0.00109755  -0.0392142   -0.0290932    0.160712    -0.0734642    0.0348081    0.00972717  -0.00339879  -0.0144365    0.00255122   0.0333006   -0.00365123  -0.0807482    -0.0969353    0.0657233    0.0348221     0.110942    0.148793     0.0523188    0.0346795   -0.0301446    0.0105532   -0.0746416    0.0140708
  0.0575595    0.0468327    0.118109    -0.0184389    0.0661316   -0.0308954   -0.00149231  -0.00347879   0.102208     0.116302     0.101109     0.153308    -0.339806    -0.0855416    0.0565532     0.0385935    0.0598457   -0.0610595     0.0356867  -0.440792    -0.180729    -0.037526    -0.115433    -0.149104     0.0741315    0.268742
  0.01778     -0.0855543    0.199347    -0.0356732    0.111949    -0.0150662    0.0886213   -0.0528433   -0.170976     0.129443    -0.0870183    0.160194     0.0661518   -0.056904     0.0580424     0.00740557   0.0550194   -0.065213      0.0372665   0.407072    -0.0819023    0.0298243   -0.113027    -0.189083     0.104167     0.286545
  0.192043    -0.244829     0.0672352    0.0339615   -0.0483846   -0.0456214    0.0826569    0.156445     0.11459      0.111924     0.124112     0.14559      0.0337588    0.206609     0.0746202    -0.18156      0.051969    -0.483911      0.0597174   0.0295152   -0.23264      0.033941    -0.035727    -0.233079     0.108866    -0.160056
  0.192631     0.0248257    0.105318     0.0329206   -0.161134     0.0774806    0.126836     0.126162     0.0220098    0.113425     0.121859     0.099663     0.0317237    0.0855116    0.12243      -0.0396276    0.0510787    0.400154      0.022332    0.0196806   -0.170975     0.0479473   -0.00426365  -0.233006     0.133799     0.0309319
 -0.0606045    0.126204    -0.0814261    0.0318736    0.114758     0.0108421   -0.316642     0.0730708    0.00170435  -0.0973101   -0.0144659   -0.1299      -0.0984964   -0.0529863   -0.115353     -0.0231336   -0.117311    -0.0602225    -0.0407684   0.0364919    0.124308    -0.0945986    0.136709    -0.166994    -0.0696099   -0.178338
 -0.0604345    0.238678    -0.0708441   -0.00195531  -0.0899518    0.0403441    0.385963     0.0690836   -0.0498177   -0.0696086   -0.0138589   -0.130066    -0.0983669   -0.0341184   -0.0672146    -0.0187378    0.139302     0.0732936    -0.0447882  -0.197868     0.0657086   -0.104141     0.164081    -0.0645045    0.0428001    0.0376429
  0.0241136    0.00260813  -0.0396438    0.068978    -0.0313129    0.0690265    0.225099     0.187976     0.0576664    0.13079     -0.01251     -0.237213    -0.00547844   0.260089    -0.100674      0.122381     0.0340725    0.292991     -0.461281   -0.0391916   -0.0859995    0.234239    -0.139529     0.0942064    0.113678     0.0155538
  0.0866943   -0.0390119   -0.130089     0.0834495   -0.0600759    0.0867364   -0.0383758    0.187853     0.110621     0.0938995    0.0129934   -0.220734    -0.0458321   -0.0102767    0.0638896     0.126681     0.0353019   -0.287968      0.670202   -0.0420817   -0.0684419   -0.517141    -0.168032     0.090074     0.0646983    0.0157007
  0.0123686   -0.0637627   -0.124914    -0.00718999   0.0719302   -0.100412    -0.075537    -0.0874571   -0.0261284    0.0994959   -0.0898137    0.0440409   -0.0557991   -0.0117007    0.115325      0.0140866    0.0245716    0.0827278     0.062292   -0.00461753  -0.0183873    0.10287     -0.0839552    0.0279303   -0.123822    -0.0115457
 -0.0531462    0.0950553   -0.0838483    0.117755     0.0478041   -0.0256877    0.0676892    0.0215997    0.151898    -0.0426374    0.00144748  -0.0995999   -0.0611409   -0.0761726   -0.146875      0.0125849   -0.0412652   -0.0179327     0.145735    0.0671724    0.0833904   -0.0593173   -0.132671    -0.123711    -0.0700678   -0.0453957
  0.0342669    0.0887517    0.102687    -0.0612655   -0.00532867  -0.0595456    0.00858496  -0.0210439    0.0339769   -0.0104183   -0.0508119   -0.0296989   -0.0839293   -0.0346635    0.0540618     0.010625     0.0239686    0.0125091     0.0200356  -0.00915306  -0.0614825    0.0528862   -0.0167879    0.0386342   -0.0453219   -0.0857395
 -0.0105531    0.110905    -0.0364279   -0.106491    -0.0112514    0.0854065    0.0229598   -0.0301934   -0.0192329    0.0631674    0.16785     -0.0568987    0.0881725    0.0229262    0.0153323    -0.0187121   -0.0134554    0.0485815    -0.143018    0.0155876    0.0564907    0.0415715    0.0618279    0.0516464    0.0797271   -0.0260234
 -0.00923503  -0.0849068   -0.0420683   -0.0571336    0.00960879  -0.0405337   -0.0073774    0.1345       0.206273     0.227052    -0.0244956   -0.10717     -1.13884     -0.188818     0.000670188  -0.0424579    0.0175239    0.00320619   -0.138609   -0.055056    -0.0651539   -0.0706191   -0.0207692   -0.173965    -0.107543    -0.111451
 -0.0294824   -0.10055     -0.0290684   -0.0531257   -0.450821     0.0130964   -0.0029359    0.0296041    0.0735262   -0.060352     0.0019431    0.10176      0.97165     -0.0603573    0.0416791    -0.0101493    0.0103236   -0.133941     -0.14162    -0.114396    -0.0716735   -0.0706514    0.00497694  -0.320726    -0.105058     0.114634
 -0.0312572    0.131497     0.191913    -0.0854592   -0.0158327   -0.207283    -0.0263255    0.045054    -0.0380904    0.0107262    0.178863    -0.0249309    0.00219809  -0.0545507    0.0724484    -0.105024    -0.162756     0.0508234     0.0840546  -0.0208779   -0.0565666    0.15104     -0.0953556    0.00232238   0.00368264   0.0542985
  0.0724865    0.25176     -0.0279282    0.0106314    0.0457597    0.165355     0.117334    -0.0645049    0.0166158   -0.0408201    0.0646115   -0.0103847   -0.0727985   -0.0417075   -0.0603235    -0.0999284    0.0614715   -0.0325727    -0.325544    0.0854533    0.0983601   -0.0537814   -0.0964957   -0.0523259   -0.038254     0.167719
 -0.183284    -0.0622697   -0.250123    -0.0212272   -0.0922655    0.0843241   -0.0789022    0.105642     0.0626227   -0.0958701   -0.0424985    0.0849982    0.0390302   -0.027741    -0.234247      0.0735503   -0.00234425   0.282649      0.14189    -0.082269    -0.0409006   -0.644664    -0.0194593    0.021515     0.121972     0.270399
 -0.177324    -0.0511578   -0.270808    -0.00162459  -0.109005     0.0753081   -0.0483244    0.035641     0.0578584   -0.0655596   -0.00402228  -0.14915      0.00194711  -0.236588    -0.0926997    -0.158293    -0.00407219   0.0936302     0.161628   -0.121679    -0.0446125    0.586157    -0.031223    -0.00484713   0.117169     0.0847606
  0.0375136   -0.0516204    0.155331     0.262006     0.0287146    0.0338545    0.0814916   -0.125436     0.0610062   -0.00099757  -0.0662705    0.100952    -0.0448928    0.0579313   -1.0433       -0.101937    -0.0610359    0.177009     -0.0214001  -0.0603404    0.0376869    0.0780459    0.194397    -0.0843688   -0.204423    -0.000791633
  0.0985153   -0.0652778    0.188108     0.240815     0.0343576    0.0194017    0.0875081   -0.10473      0.0286861    0.0303221   -0.0542181    0.0695549   -0.0499441    0.0604539    1.05297       0.145497    -0.0654077   -0.0784118    -0.106944   -0.0609202    0.0419582    0.0575368    0.16857     -0.0863503   -0.194512     0.0102702
 -0.29962     -0.128465    -0.0510573    0.0468169   -0.0466349   -0.030817     0.0463577    0.0590175    0.0597533   -0.0689605    0.152963     0.125467    -0.0135882    0.17115      0.163831      0.116507    -0.153307    -0.439444     -0.198274    0.0304822   -0.673406     0.0624352    0.0185607   -0.151657    -0.0181571   -0.0911612
  0.162241    -0.130753    -0.0513566    0.0983107   -0.0667021   -0.00838247   0.0390003    0.044557    -0.0491124   -0.239226     0.135903     0.104261    -0.0109912    0.0407692    0.150155     -0.0465038   -0.135949     0.597802     -0.136284   -0.0105116    0.502652    -0.0342072    0.0379922   -0.136814    -0.0145091   -0.0555262
  0.153405     0.070714     0.0118936    0.0155532    0.0993798    0.22307      0.100362     0.162978    -0.069384     0.13996     -0.0726826    0.107218     0.158648    -0.0731113   -0.016085      0.0299803    0.0423485    0.114728     -0.0932129  -0.048167     0.0261033    0.0413786   -0.0364005   -0.0470022   -0.13096      0.0578523
  0.15648      0.053294     0.0144381    0.0172644    0.053143     0.207314     0.0692152    0.0233353   -0.158961     0.143952    -0.0705692    0.114344     0.0915974   -0.0795463    0.194847     -0.00475255   0.0226239    0.126956     -0.119617    0.0380195    0.0401942    0.0587313   -0.0430468   -0.0991023   -0.159681     0.0537461[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.029419
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.011051
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      6
│     11
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.005285
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.024602
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.014453
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.014237
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.020446
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.018455
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      6
│     11
│     12
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.010014
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.024677
┌ Info: EM with 100000 data points 10 iterations avll -1.024677
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.016897e+05
      1       6.240167e+05      -1.776730e+05 |       32
      2       5.944082e+05      -2.960849e+04 |       32
      3       5.800095e+05      -1.439875e+04 |       32
      4       5.722442e+05      -7.765254e+03 |       32
      5       5.678949e+05      -4.349331e+03 |       32
      6       5.653899e+05      -2.505036e+03 |       32
      7       5.641247e+05      -1.265174e+03 |       32
      8       5.635099e+05      -6.147825e+02 |       32
      9       5.631601e+05      -3.497554e+02 |       32
     10       5.629382e+05      -2.219213e+02 |       32
     11       5.627860e+05      -1.521771e+02 |       32
     12       5.626447e+05      -1.413478e+02 |       32
     13       5.625141e+05      -1.306401e+02 |       32
     14       5.624091e+05      -1.050069e+02 |       32
     15       5.623162e+05      -9.287936e+01 |       32
     16       5.622323e+05      -8.382370e+01 |       32
     17       5.621435e+05      -8.881507e+01 |       32
     18       5.620646e+05      -7.891958e+01 |       32
     19       5.619811e+05      -8.356070e+01 |       32
     20       5.618978e+05      -8.329708e+01 |       32
     21       5.618045e+05      -9.327147e+01 |       31
     22       5.617088e+05      -9.566350e+01 |       32
     23       5.616013e+05      -1.074912e+02 |       32
     24       5.614562e+05      -1.451802e+02 |       32
     25       5.612257e+05      -2.304104e+02 |       32
     26       5.608598e+05      -3.659765e+02 |       32
     27       5.603895e+05      -4.702667e+02 |       32
     28       5.598027e+05      -5.868238e+02 |       32
     29       5.592357e+05      -5.669929e+02 |       32
     30       5.587992e+05      -4.364864e+02 |       32
     31       5.585340e+05      -2.651499e+02 |       32
     32       5.583804e+05      -1.536034e+02 |       31
     33       5.582833e+05      -9.715834e+01 |       31
     34       5.582260e+05      -5.729202e+01 |       32
     35       5.581893e+05      -3.667433e+01 |       31
     36       5.581577e+05      -3.162923e+01 |       30
     37       5.581394e+05      -1.830908e+01 |       27
     38       5.581303e+05      -9.031849e+00 |       30
     39       5.581236e+05      -6.697412e+00 |       26
     40       5.581173e+05      -6.387092e+00 |       28
     41       5.581133e+05      -3.977092e+00 |       25
     42       5.581109e+05      -2.420087e+00 |       22
     43       5.581087e+05      -2.178678e+00 |       18
     44       5.581061e+05      -2.596816e+00 |       22
     45       5.581021e+05      -4.023165e+00 |       24
     46       5.580979e+05      -4.151490e+00 |       22
     47       5.580932e+05      -4.753522e+00 |       21
     48       5.580875e+05      -5.638496e+00 |       23
     49       5.580828e+05      -4.706641e+00 |       22
     50       5.580781e+05      -4.685997e+00 |       22
K-means terminated without convergence after 50 iterations (objv = 558078.1291105169)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.268924
[ Info: iteration 2, average log likelihood -1.222968
[ Info: iteration 3, average log likelihood -1.175411
[ Info: iteration 4, average log likelihood -1.114597
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     10
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055102
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078855
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.027896
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     10
│     14
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.998565
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.036460
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     16
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.009353
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -0.978781
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     13
│     14
│     17
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.008684
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.041152
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.022183
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     10
│     20
│     22
│     23
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -0.972997
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     16
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.016537
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.042534
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.989241
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│     10
│     17
│     20
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -0.966554
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.054766
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.021710
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      7
│     14
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.963386
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.052060
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.022078
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.992463
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     10
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.994518
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     16
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.017773
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.015575
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.031232
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      7
│     10
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.989476
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     17
│     19
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.014031
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.031878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.010505
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│     10
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.999763
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     17
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.022392
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.011054
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     10
│     13
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.009131
[ Info: iteration 39, average log likelihood -1.054058
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     19
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.973038
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      7
│     10
│      ⋮
│     17
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.973666
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.071021
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.008084
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│     10
│     19
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.981294
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.033327
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033275
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      7
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.998716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.031261
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     13
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.996846
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     10
│     14
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.002576
┌ Info: EM with 100000 data points 50 iterations avll -1.002576
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0323212     0.0782354   -0.0974364   -0.187818     0.00484757   0.0844576    0.05164      -0.0446177   -0.0634382    0.129541     0.223041    -0.16803     0.148923     0.00147377   0.0722303   -0.0750843    -0.0166573    0.0329417   -0.147757    -0.0596125    0.0908127   -0.00218107   0.0278567    0.00485612   0.0283136   -0.0482664
  0.0527404    -0.0178293   -0.0832967    0.0767649   -0.0458228    0.0778018    0.0984129     0.187886     0.0837253    0.112234     2.34755e-5  -0.229106   -0.0263116    0.129273    -0.0204282    0.124413      0.0346196    0.0096547    0.0909036   -0.0393927   -0.0765121   -0.130667    -0.1523       0.092724     0.0902253    0.0157874
 -0.0146376    -0.094718    -0.036604    -0.0535483   -0.152938     0.0502397   -0.000985912   0.109688     0.166743     0.0518383   -0.00832906  -0.034504   -0.189896    -0.13052      0.0090479   -0.0180085     0.0130577   -0.0554704   -0.13821     -0.0536373   -0.0613717   -0.0706223   -0.0108065   -0.232525    -0.102584    -0.0319178
 -0.072597     -0.0183109   -0.0131312   -0.0354425    0.00563864  -0.0163161    0.0631832     0.0434096   -0.108116     0.0736731    0.116215     0.114544   -0.00672367   0.0264972    0.059209    -0.131918      0.132401    -0.00726598  -0.0248602   -0.132112    -0.0485996   -0.00262298   0.0643348   -0.225887    -0.128923     0.123405
 -0.13906       0.174448     0.00448448  -0.00739341  -0.0429631    0.152332     0.00368901   -0.0107524    0.0448477   -0.0216734    0.109293     0.0630346   0.00750101   0.0603801   -0.0652428    0.0298496    -0.0140621    0.0780006   -0.145813     0.0789781    0.0966138    0.0861895    0.146023     0.127573     0.13446      0.0485883
  0.0566089     0.0912359    0.00109673   0.0447826    0.00899858   0.209701     0.0200622    -0.026824     0.00572973  -0.0541322    0.0138272   -0.102065    0.114072    -0.055059    -0.214433    -0.0811199     0.0483986    0.0629921    0.171387     0.0726171    0.0476196   -0.0425347   -0.0545049    0.111903    -0.0920964   -0.0864938
 -0.0714023    -0.0176925    0.0271476    0.126179     0.150873     0.00807288  -0.0196844    -0.112232     0.0641073    0.0430438    0.0865304    0.185066   -0.0850163    0.135277    -0.0423412   -0.0132137     0.06519      0.0500136    0.0973069    0.0777853   -0.00612776  -0.0532312    0.0182652    0.0108689    0.0564886   -0.182988
  0.0223894    -0.00350124  -0.0164175    0.0275922    0.00988921  -0.0169857   -0.141134     -0.0542823   -0.0642098    0.0691994   -0.0892425   -0.0430865   0.0480038    0.0362742    0.0978515    0.137654      0.00664646  -0.0409796   -0.0863983    0.159751    -0.0507803    0.0761429   -0.00240207   0.0294235    0.0276229   -0.0860702
 -0.180506     -0.0569137   -0.259996    -0.012276    -0.100223     0.080084    -0.0642851     0.0717486    0.0603385   -0.0812747   -0.0243406   -0.0267526   0.0213038   -0.127599    -0.166912    -0.0370715    -0.00322822   0.193096     0.151557    -0.10126     -0.0426443   -0.0575421   -0.0252342    0.00893828   0.119696     0.181593
 -0.0617298     0.180497    -0.0763464    0.0152402    0.0120546    0.024117     0.0291237     0.0724367   -0.0194213   -0.0821502   -0.0135635   -0.13046    -0.0977417   -0.0422638   -0.091127    -0.0207461     0.00927887   0.00732576  -0.044102    -0.0821061    0.0965126   -0.0993698    0.149637    -0.118233    -0.0139435   -0.074756
  0.0398924     0.0143287   -0.0435793    0.00194193   0.0267649    0.0563814   -0.0831263     0.0487193    0.010805     0.068174     0.0180515   -0.0381272  -0.0571014    0.141787     0.0557964    0.0189976     0.0646786    0.00155468   0.0271114    0.0779834    0.0709073    0.0168432   -0.00820333   0.023466    -0.0954215    0.13667
 -0.0199164    -0.0873549    0.0293248   -0.121324    -0.0172216   -0.130882    -0.0371733     0.0109207    0.0544478   -0.0443165    0.129579    -0.0319301   0.141408     0.0299462    0.0195111   -0.0345946    -0.0857315    0.00974646  -0.145734    -0.0280967    0.0581517    0.0255957    0.139307    -0.0336326   -0.028459     0.0251799
  0.104933      0.112622     0.246734    -0.186784     0.0340298   -0.022998     0.054685     -0.0563312   -0.0519542   -0.00507818  -0.0558619    0.0347804  -0.105309    -0.0167265    0.044656    -0.125202      0.0374949    0.0705718   -0.00973899  -0.0400563   -0.00932709   0.0954879    0.00681118   0.0798237   -0.0313032   -0.0421
 -0.0456281    -0.128542    -0.049898     0.0730048   -0.0623566   -0.00839474   0.0476414     0.0492048   -0.00592593  -0.149315     0.135125     0.113539   -0.0118377    0.0989881    0.161305     0.0275056    -0.139304     0.127809    -0.161485     0.00906416  -0.0477679    0.0203852    0.025464    -0.137019    -0.0162165   -0.0675042
 -0.00730161    0.0463615   -0.188477     0.0777919   -0.108292    -0.142867    -0.122302     -0.0377998   -0.0310005    0.0559478   -0.0971551   -0.0347235  -0.0699267   -0.0615995    0.121901    -0.0336781    -0.00929065  -0.00458163   0.0671373    0.0297702   -0.0769222   -0.00499862  -0.131048    -0.0779845   -0.189013    -0.0278757
  0.217397     -0.0613132    0.0604772    0.0532033   -0.140961     0.198118     0.165871      0.124928     0.0665928    0.0869547    0.100786     0.233071    0.0438405    0.124138     0.0733265   -0.0971328     0.0367866    0.107668    -0.00317075   0.04885     -0.173019     0.0496877   -0.0076354   -0.185812     0.10804     -0.0498928
  0.0269169    -0.0137786    0.0116239   -0.0343905   -0.278089    -0.00916477   0.00218202    0.00605657   0.118511     0.133308     0.0497199    0.12177     0.01676     -0.0876169    0.028568    -0.0607239     0.0368042   -0.0769497   -0.106953     0.00165345  -0.143712    -0.0597737    0.0676014   -0.429379    -0.0428461    0.113438
 -0.0658657     0.145513     0.0183146    0.0016063   -0.0651242   -0.120879     0.0628201     0.0465812    0.165832    -0.0667769    0.0346173   -0.095429   -0.0945506   -0.0897996    0.0316701    0.085882      0.014537    -0.003094     0.0840249   -0.0601021   -0.0688739   -0.00810206  -0.0422907    0.0121877   -0.0595321   -0.125979
 -0.135482     -0.0639498    0.0462652   -0.0247672   -0.0541682    0.257632     0.139636     -0.0812372    0.0547815   -0.0945743   -0.116445    -0.144692   -0.0141949    0.100001    -0.166444     0.198384      0.0760128    0.260225     0.0370212   -0.140557     0.152799     0.0475823    0.254628    -0.104634    -0.0627901   -0.0790172
  0.150037      0.0689363    0.01305      0.0143014    0.0889164    0.248632     0.0764596     0.103949    -0.185396     0.133725    -0.054605     0.11235     0.145744    -0.0739806    0.129367     0.00935052    0.0318086    0.118069    -0.11057      0.0215659    0.0324573    0.0603218   -0.038506    -0.0801457   -0.154516     0.0660461
  0.17041       0.212061     0.0416338   -0.168863     0.0949176    0.12463     -0.138228      0.034922     0.0818207   -0.0563028   -0.0760546    0.0839792  -0.0541795    0.0601132   -0.067229     0.135543     -0.0901393   -0.0149741    0.0663968   -0.203315     0.171997    -0.0878532    0.0166536    0.0212223   -0.0164479    0.0395434
  0.131433      0.0611802    0.0581039   -0.0122172   -0.00538286   0.0309983   -0.0106408     0.0494893   -0.0443298   -0.131554     0.0907637    0.0970082  -0.0538192   -0.0927175   -0.119084    -0.000532808   0.080121    -0.0337957   -0.0518886    0.0195413   -0.0261268    0.0479415   -0.0162808    0.172884     0.0384082    0.0345202
 -0.0736221     0.0766114   -0.0825034    0.124986     0.0353008   -0.0213633    0.0884673     0.0355303    0.118056    -0.0546112    0.0178467   -0.111418   -0.0552955   -0.0764082   -0.18784      0.0219809    -0.0428706   -0.0210945    0.113406     0.0781758    0.0977899   -0.0955066   -0.133516    -0.147441    -0.0532323   -0.0551804
  0.0673402    -0.0579716    0.1724       0.250811     0.0299696    0.0268551    0.0843874    -0.115514     0.0453727    0.0146096   -0.060228     0.0837178  -0.0473293    0.059059    -0.00412802   0.0201723    -0.0632572    0.0487104   -0.0642725   -0.0607195    0.0394218    0.0681568    0.181886    -0.0863194   -0.199403     0.00497105
  0.0144598     0.126142    -0.0714172    0.024435    -0.166963     0.0649657   -0.00588614    0.0676283   -0.119163     0.0476564    0.110369    -0.0878023   0.0185635    0.0871986   -0.122282    -0.0345076     0.191322    -0.0703977   -0.146487    -0.103226     0.0328375    0.0121486   -0.00581972   0.00120295  -0.019311     0.0519573
  0.0846453    -0.0399251    0.0752394    0.0501241   -0.0233013   -0.216546    -0.0305227     0.107066     0.206079     0.075702     0.0885974   -0.0174546   0.0511819    0.114693     0.0787369   -0.0475949     0.0358203   -0.224874    -0.0274137    0.0108813   -0.180958     0.0577856   -0.0030687   -0.162825     0.0972917   -0.0197785
 -0.0161149     0.132429     0.187181    -0.0825997   -0.0175677   -0.206767    -0.0257684     0.046509    -0.0335998    0.0110421    0.175546    -0.0242339  -0.00291556  -0.0519983    0.0715032   -0.10654      -0.159813     0.048045     0.0724456   -0.0148826   -0.0584036    0.145404    -0.0936111   -0.00528518   0.00515766   0.0555441
  0.0447481     0.0163647    0.0521138   -0.0369505   -0.0526028    0.00411597   0.0840753     0.0028615   -0.087117     0.0903966    0.137382     0.0873904   0.136931    -0.0691258    0.0496078    0.0218212    -0.043634     0.0330383    0.073641     0.0121141   -0.136278    -0.0708092    0.00307976   0.120392    -0.0499426    0.112795
  0.000749318  -0.140743    -0.0366915   -0.0679134    0.243775    -0.0318323    0.0110505    -0.112226     0.0141497    0.11067     -0.0473854    0.0811112  -0.0310284    0.0166849    0.0382604    0.0451744     0.0723719    0.128013     0.0537097   -0.00562773   0.0522096    0.17393     -0.0467325    0.0765578   -0.0409417   -0.0123247
  0.124332      0.161124     0.00853482  -0.0791968   -0.0987292   -0.126608     0.011156      0.231978    -0.0106426   -0.084054     0.14457      0.111376    0.204912     0.129627    -0.0760713    0.111934      0.0985436    0.0943171   -0.143933    -0.00955167  -0.0778228   -0.0207052    0.0714807    0.0543769   -0.125785     0.118055
  0.0386932    -0.0588167   -0.0215986   -0.0462841   -0.192837    -0.164421    -0.00574158    0.00861939   0.083021     0.241945    -0.00624839   0.0183288  -0.417624    -0.101858     0.0558439   -0.0695815     0.0211443    0.0051965   -0.125923    -0.13758     -0.0974264   -0.0625985   -0.0227137   -0.207903    -0.0874388   -0.00914997
  0.0388571    -0.0200128    0.159478    -0.0269295    0.0890107   -0.0231331    0.0449558    -0.0278229   -0.0369996    0.12298      0.00686628   0.156836   -0.134707    -0.0711088    0.0572931    0.0231388     0.0574426   -0.0629424    0.0364646   -0.0128582   -0.130404    -0.00299877  -0.114167    -0.1702       0.0899297    0.277653[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.028545
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     17
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.967649
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     22
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.935773
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     19
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.996340
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.981340
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     22
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.938313
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.999576
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     13
│     14
│     17
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.949054
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.938572
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     17
│     19
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.984681
┌ Info: EM with 100000 data points 10 iterations avll -0.984681
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0799072    0.010729     0.012407     -0.060826    -0.0405892    0.0337257   -0.0488426   0.0163723   -0.145735     0.0903679   -0.16349      0.120062    -0.0388289    0.0395231    0.142145     0.11588      0.171601     0.141277    -0.220295    -0.0666272   -0.0709165    0.0755346  -0.172943     0.12965      0.0492797   -0.0410965
 -0.0401375    0.0553722   -0.0475115     0.17435     -0.0706681   -0.0411385   -0.057392   -0.113714    -0.00398166   0.0185773    0.16188      0.188915     0.0642408    0.0806044   -0.054426     0.17872     -0.226681    -0.12462      0.225384     0.0519214   -0.0927698   -0.0326112  -0.0819065    0.183166     0.132341     0.122084
  0.0727386   -0.0269493   -0.0985767    -0.0582128   -0.0294561    0.00320245   0.0193069   0.0200057    0.0702311   -0.14792     -0.102222    -0.0585229   -0.0884731    0.224958     0.250506    -0.0133743   -0.111909    -0.0717927   -0.0713266   -0.119029     0.195325     0.139656   -0.0458085    0.0601627    0.122209    -0.0455932
  0.0899811    0.0328354   -0.0211042     0.0845947   -0.188745    -0.0960678    0.0990073   0.119264     0.048505     0.0272339    0.0512679   -0.0496709   -0.14029      0.0221144   -0.0876567   -0.181165     0.0106327   -0.0601617    0.0446116    0.0608997   -0.0955288   -0.0821032  -0.139894    -0.0880295   -0.119657    -0.0637304
  0.0236683   -0.0593003    0.0586367     0.165498    -0.0132538    0.0586081    0.0665788  -0.0695238   -0.0479833    0.0102788    0.0618623    0.123373    -0.0433091   -0.0917723    0.115543     0.0427926   -0.0474694   -0.190542     0.0361434    0.0972502   -0.0498931    0.0143355   0.0501624    0.0728869    0.0459719   -0.034194
 -0.0531315    0.082002     0.0329852    -0.00139589   0.0452107    0.0805484   -0.0833867   0.0772626    0.095705    -0.147279     0.227088    -0.00652446  -0.122388     0.0114589    0.0634444    0.0430457    0.0587564   -0.108857    -0.016026    -0.137369     0.00924667   0.10152    -0.139392    -0.0966185   -0.175446    -0.00634645
 -0.099918     0.108831    -0.0863469    -0.0807164   -0.0656668   -0.130614    -0.11266    -0.206801     0.0803829   -0.0828763    0.0113731    0.184694    -0.0876862   -0.0377259   -0.100609     0.00221746  -0.0271068   -0.114875     0.103216    -0.129363    -0.107769    -0.0991026   0.00333229   0.138635     0.0466288   -0.169288
  0.109888    -0.143938     0.011493      0.123437     0.274701     0.159903     0.0693541  -0.0284329   -0.0863103    0.0438388   -0.0469678    0.125916     0.12641     -0.0266615    0.0637939    0.00165451   0.0508535    0.0889201    0.323578     0.0679168   -0.0287226    0.0876268   0.00464832   0.0223077   -0.070686     0.128283
 -0.135843     0.0119954    0.120197      0.00263027   0.0153321    0.106534    -0.0494863  -0.184818     0.135208    -0.00020739  -0.0221311    0.071795     0.0040174    0.104103     0.150173     0.0493186   -0.0566682   -0.0526322   -0.0725146    0.0740393   -0.0440092    0.121686   -0.037825     0.069664     0.0418092    0.0574027
 -0.0947033   -0.124688    -0.0062313     0.0373942    0.0277315   -0.205405    -0.131026   -0.0537796    0.0950496    0.123071     0.0284028   -0.0998677   -0.0261072    0.0358445   -0.108581     0.0581339   -0.035675     0.102901     0.0818174    0.134611     0.0719311   -0.0269995   0.0924298   -0.11172     -0.00743711  -0.167514
  0.145024    -0.0052693   -0.0338871     0.202483     0.104907    -0.00153584  -0.298083   -0.0661886    0.118147     0.130514    -0.00755302  -0.270456    -0.0212099   -0.136487     0.0333688    0.0603548    0.0751231    0.0904952   -0.0743483   -0.10646      0.0527811   -0.178817   -0.013349    -0.127931    -0.0236128   -0.0250513
 -0.28483     -0.00438863   0.0504403     0.00477451  -0.0411689   -0.130908     0.120513    0.0538706   -0.0645806   -0.0868202    0.158979    -0.102446    -0.0706829    0.0981948    0.117425    -0.191936    -0.0664641    0.0386758   -0.158599     0.0364868    0.0343542   -0.0137217   0.0246399    0.0171767   -0.00974841  -0.0752495
  0.0529266    0.0311675    0.00842481    0.0544914    0.0120904    0.127801     0.138937   -0.137214    -0.01963      0.00575962   0.0337308   -0.1653       0.0265841    0.129046    -0.0581293    0.0380143   -0.0213176   -0.190569     0.0767556    0.0494411    0.0043221   -0.07396     0.0247746   -0.0881972   -0.0289851   -0.0057853
 -0.110203     0.0718738   -0.224664     -0.00235739  -0.0491893    0.0801786   -0.156297   -0.231562    -0.147254    -0.0856968    0.0663356    0.100534     0.0343421   -0.040993     0.0183469   -0.0234146   -0.115434    -0.0802555    0.0794549    0.00854447  -0.0516376    0.0200299  -0.0530607   -0.263574     0.160311    -0.094767
  0.0684264    0.0342028   -0.042684     -0.129448    -0.0770775   -0.0507978    0.260316   -0.00559116   0.0326115   -0.0228698   -0.0265125    0.00401918   0.113131    -0.10537      0.0275612   -0.0894934   -0.0595405   -0.107122     0.0983918   -0.00891656  -0.107267    -0.0225982  -0.172146    -0.146922     0.0581011    0.0488648
 -0.129593    -0.123357     0.100391      0.114172     0.113383    -0.215622    -0.0414229  -0.0577148   -0.0955671    0.0185065   -0.104087     0.0283364   -0.0399871   -0.0148998    0.062954    -0.0118132    0.207799    -0.123134     0.0277817   -0.0536676    0.104203     0.0856596   0.0319145    0.0222488    0.224999    -0.0446477
  0.0828671    0.0261442   -0.101925     -0.0917762    0.0855713    0.0340787   -0.0687287   0.0409524   -0.14626     -0.0933235    0.102575    -0.0903301    0.00723983   0.159035     0.107822     0.010956    -0.0845751   -0.0287931    0.0920222   -0.0190283   -0.0464102   -0.110647    0.083736     0.0691412   -0.147348    -0.0492462
 -0.0424919   -0.136042     0.0209824     0.0520668    0.290494     0.0155198   -0.0956713   0.0957307   -0.0894148   -0.0154635   -0.17608     -0.064498    -0.0609734   -0.105409    -0.138053    -0.00337235   0.269056     0.152905    -0.136024     0.0891424   -0.0450853    0.0803593   0.0741887    0.0299016   -0.0205038   -0.102461
  0.0255576    0.0953216   -0.0342426    -0.116328    -0.0296358   -0.00971154   0.159469    0.0194901   -0.0864642   -0.10073      0.0326316    0.065207     0.0781206   -0.0864712   -0.0121413    0.00669644  -0.0850319   -0.012789    -0.0336249    0.0467139    0.0522797   -0.144355   -0.0243429    0.0237074   -0.0771052   -0.0197685
 -0.00431915  -0.188883    -0.000391354  -0.0451516   -0.0141317   -0.087187     0.121853    0.0143379    0.148304     0.154611    -0.0839284    0.0393171   -0.0502446    0.1004      -0.0970128    0.0467766   -0.170363    -0.00143269   0.0110932    0.168109     0.0274329   -0.0183207  -0.0723996    0.0415002   -0.022276     0.0618159
  0.100835     0.0808584   -0.140289      0.0332874   -0.188131    -0.0580001    0.0243642  -0.152648     0.154154    -0.12576      0.0138755    0.0509784   -0.0725346    0.00726242  -0.0318815    0.0278792   -0.0358147    0.0367999    0.0539537    0.00812164   0.240948    -0.0499405  -0.0570488   -0.0334638    0.00398374   0.100006
 -0.0043515   -0.107644     0.0583119     0.010666    -0.229805     0.235024    -0.0767032  -0.135619    -0.0571344    0.101826    -0.00928411   0.0912838    0.146393     0.162238     0.0110384   -0.055636     0.0846034    0.0621093    0.0707769    0.0473964   -0.0944963    0.253783    0.145489    -0.00754376  -0.028013     0.0605508
 -0.0487478    0.0172613   -0.00107849   -0.075239     0.0617094   -0.0404305    0.191163   -0.16073      0.062177    -0.219943     0.141958    -0.196171     0.0469612    0.0272455   -0.0739555    0.0115223    0.00742286   0.105323    -0.126664    -0.075316     0.0141836    0.0483949   0.2192      -0.183533     0.00474679   0.0470595
 -0.0843615   -0.0807414   -0.118221      0.16112     -0.0160706    0.0862073    0.185151    0.0252081   -0.209552    -0.0234697    0.00532553  -0.00857057  -0.0615717    0.187872     0.0812004   -0.12288      0.00132014   0.0774666   -0.100834     0.010209    -0.0221057    0.0382945   0.0287941   -0.157418    -0.186387    -0.0594515
 -0.187847     0.0507089    0.0196778     0.0020006    0.0654831   -0.0594706    0.123964    0.193947    -0.108245    -0.0144955   -0.0338752    0.0931905    0.0600263    0.0513675    0.0658728   -0.0512434    0.0942736   -0.10136      0.0586119   -0.116428    -0.144812    -0.0233621  -0.0772538   -0.041042     0.139354     0.016689
  0.0340105   -0.0922413    0.0737248    -0.0377937   -0.0701444   -0.0596583   -0.111709   -0.0204672    0.0756749    0.0668801   -0.0214784    0.0844499    0.0231042   -0.0292416   -0.0533257    0.0326814    0.0605078    0.135364     0.156849    -0.029754     0.109613     0.203899   -0.0534622    0.0275233    0.0846393    0.0390107
 -0.104018    -0.00539902  -0.182049      0.130195     0.0887436   -0.021241     0.0239787   0.134948     0.150974    -0.145715    -0.0392375   -0.0117758    0.0368349   -0.0520668    0.045414     0.107784    -0.066185    -0.124264    -0.00288925  -0.0729558   -0.0139646    0.288149   -0.0108605   -0.136425     0.0969136   -0.0609866
 -0.0294663   -0.0244782    0.197491      0.0128169    0.079995    -0.195776    -0.174342    0.152573    -0.111395    -0.00298601   0.0885461    0.16457      0.117686     0.0860103    0.0499856    0.0861819    0.109538    -0.174438     0.0399755    0.128901    -0.0791462    0.0390113   0.116581    -0.098843    -0.0704563    0.0294004
 -0.00890399   0.00794944  -0.10983      -0.0685746    0.00423311  -0.0128626    0.0183618  -0.0860798   -0.276146     0.0379205    0.17769      0.0707587    0.223889    -0.06871      0.087657    -0.0475796    0.125955    -0.00918974  -0.0424566    0.0111575    0.0974217   -0.057733   -0.190468    -0.036443     0.124957     0.124654
  0.0421228    0.133669    -0.124316      0.0814436   -0.00710693  -0.128777     0.199317    0.0239326   -0.0686877    0.0228247    0.0605524   -0.102389    -0.0223822    0.0669731   -0.070989     0.0368639   -0.0105685    0.0382008   -0.171295    -0.123734    -0.007607    -0.0450726   0.0777098   -0.0807276    0.0779034    0.0378533
 -0.0112588    0.00362299  -0.0547976     0.0880372   -0.112346    -0.0505217    0.0230418   0.0928714    0.122984    -0.203393    -0.0478277    0.179502    -0.0219705    0.0623341   -0.00524379   0.076649     0.0204176   -0.127786     0.0719242    0.0899604    0.133517    -0.0468286   0.130669    -0.0074969    0.0312831    0.0376561
 -0.170377     0.0344787   -0.095363      0.0232695   -0.0354039    0.00417225  -0.0164033   0.0436183   -0.0310956    0.159688    -0.0447948    0.222079    -0.00217572   0.135582     0.0194044   -0.0663349   -0.168401    -0.0208689   -0.0722646   -0.0256442    0.161144     0.0576243   0.151607     0.0564212    0.0128499    0.00457013kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4244332965230795
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424452
[ Info: iteration 2, average log likelihood -1.424383
[ Info: iteration 3, average log likelihood -1.424330
[ Info: iteration 4, average log likelihood -1.424266
[ Info: iteration 5, average log likelihood -1.424189
[ Info: iteration 6, average log likelihood -1.424100
[ Info: iteration 7, average log likelihood -1.424004
[ Info: iteration 8, average log likelihood -1.423904
[ Info: iteration 9, average log likelihood -1.423797
[ Info: iteration 10, average log likelihood -1.423656
[ Info: iteration 11, average log likelihood -1.423422
[ Info: iteration 12, average log likelihood -1.422993
[ Info: iteration 13, average log likelihood -1.422264
[ Info: iteration 14, average log likelihood -1.421262
[ Info: iteration 15, average log likelihood -1.420274
[ Info: iteration 16, average log likelihood -1.419596
[ Info: iteration 17, average log likelihood -1.419249
[ Info: iteration 18, average log likelihood -1.419098
[ Info: iteration 19, average log likelihood -1.419036
[ Info: iteration 20, average log likelihood -1.419011
[ Info: iteration 21, average log likelihood -1.419001
[ Info: iteration 22, average log likelihood -1.418997
[ Info: iteration 23, average log likelihood -1.418995
[ Info: iteration 24, average log likelihood -1.418994
[ Info: iteration 25, average log likelihood -1.418994
[ Info: iteration 26, average log likelihood -1.418993
[ Info: iteration 27, average log likelihood -1.418993
[ Info: iteration 28, average log likelihood -1.418993
[ Info: iteration 29, average log likelihood -1.418993
[ Info: iteration 30, average log likelihood -1.418993
[ Info: iteration 31, average log likelihood -1.418993
[ Info: iteration 32, average log likelihood -1.418993
[ Info: iteration 33, average log likelihood -1.418993
[ Info: iteration 34, average log likelihood -1.418993
[ Info: iteration 35, average log likelihood -1.418992
[ Info: iteration 36, average log likelihood -1.418992
[ Info: iteration 37, average log likelihood -1.418992
[ Info: iteration 38, average log likelihood -1.418992
[ Info: iteration 39, average log likelihood -1.418992
[ Info: iteration 40, average log likelihood -1.418992
[ Info: iteration 41, average log likelihood -1.418992
[ Info: iteration 42, average log likelihood -1.418992
[ Info: iteration 43, average log likelihood -1.418992
[ Info: iteration 44, average log likelihood -1.418992
[ Info: iteration 45, average log likelihood -1.418992
[ Info: iteration 46, average log likelihood -1.418992
[ Info: iteration 47, average log likelihood -1.418992
[ Info: iteration 48, average log likelihood -1.418992
[ Info: iteration 49, average log likelihood -1.418992
[ Info: iteration 50, average log likelihood -1.418992
┌ Info: EM with 100000 data points 50 iterations avll -1.418992
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4244520183337361
│     -1.424383305084959
│      ⋮
└     -1.4189920915514427
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419007
[ Info: iteration 2, average log likelihood -1.418950
[ Info: iteration 3, average log likelihood -1.418903
[ Info: iteration 4, average log likelihood -1.418847
[ Info: iteration 5, average log likelihood -1.418779
[ Info: iteration 6, average log likelihood -1.418699
[ Info: iteration 7, average log likelihood -1.418608
[ Info: iteration 8, average log likelihood -1.418513
[ Info: iteration 9, average log likelihood -1.418424
[ Info: iteration 10, average log likelihood -1.418346
[ Info: iteration 11, average log likelihood -1.418285
[ Info: iteration 12, average log likelihood -1.418240
[ Info: iteration 13, average log likelihood -1.418208
[ Info: iteration 14, average log likelihood -1.418188
[ Info: iteration 15, average log likelihood -1.418174
[ Info: iteration 16, average log likelihood -1.418164
[ Info: iteration 17, average log likelihood -1.418157
[ Info: iteration 18, average log likelihood -1.418151
[ Info: iteration 19, average log likelihood -1.418146
[ Info: iteration 20, average log likelihood -1.418142
[ Info: iteration 21, average log likelihood -1.418137
[ Info: iteration 22, average log likelihood -1.418132
[ Info: iteration 23, average log likelihood -1.418127
[ Info: iteration 24, average log likelihood -1.418122
[ Info: iteration 25, average log likelihood -1.418116
[ Info: iteration 26, average log likelihood -1.418109
[ Info: iteration 27, average log likelihood -1.418101
[ Info: iteration 28, average log likelihood -1.418093
[ Info: iteration 29, average log likelihood -1.418084
[ Info: iteration 30, average log likelihood -1.418074
[ Info: iteration 31, average log likelihood -1.418062
[ Info: iteration 32, average log likelihood -1.418050
[ Info: iteration 33, average log likelihood -1.418036
[ Info: iteration 34, average log likelihood -1.418021
[ Info: iteration 35, average log likelihood -1.418005
[ Info: iteration 36, average log likelihood -1.417988
[ Info: iteration 37, average log likelihood -1.417970
[ Info: iteration 38, average log likelihood -1.417952
[ Info: iteration 39, average log likelihood -1.417934
[ Info: iteration 40, average log likelihood -1.417915
[ Info: iteration 41, average log likelihood -1.417898
[ Info: iteration 42, average log likelihood -1.417881
[ Info: iteration 43, average log likelihood -1.417865
[ Info: iteration 44, average log likelihood -1.417850
[ Info: iteration 45, average log likelihood -1.417837
[ Info: iteration 46, average log likelihood -1.417825
[ Info: iteration 47, average log likelihood -1.417814
[ Info: iteration 48, average log likelihood -1.417805
[ Info: iteration 49, average log likelihood -1.417797
[ Info: iteration 50, average log likelihood -1.417789
┌ Info: EM with 100000 data points 50 iterations avll -1.417789
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4190067620954792
│     -1.418950294989115
│      ⋮
└     -1.4177893004127637
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417794
[ Info: iteration 2, average log likelihood -1.417738
[ Info: iteration 3, average log likelihood -1.417689
[ Info: iteration 4, average log likelihood -1.417634
[ Info: iteration 5, average log likelihood -1.417568
[ Info: iteration 6, average log likelihood -1.417488
[ Info: iteration 7, average log likelihood -1.417396
[ Info: iteration 8, average log likelihood -1.417294
[ Info: iteration 9, average log likelihood -1.417188
[ Info: iteration 10, average log likelihood -1.417084
[ Info: iteration 11, average log likelihood -1.416988
[ Info: iteration 12, average log likelihood -1.416902
[ Info: iteration 13, average log likelihood -1.416828
[ Info: iteration 14, average log likelihood -1.416766
[ Info: iteration 15, average log likelihood -1.416715
[ Info: iteration 16, average log likelihood -1.416673
[ Info: iteration 17, average log likelihood -1.416638
[ Info: iteration 18, average log likelihood -1.416609
[ Info: iteration 19, average log likelihood -1.416584
[ Info: iteration 20, average log likelihood -1.416563
[ Info: iteration 21, average log likelihood -1.416544
[ Info: iteration 22, average log likelihood -1.416526
[ Info: iteration 23, average log likelihood -1.416511
[ Info: iteration 24, average log likelihood -1.416497
[ Info: iteration 25, average log likelihood -1.416483
[ Info: iteration 26, average log likelihood -1.416471
[ Info: iteration 27, average log likelihood -1.416460
[ Info: iteration 28, average log likelihood -1.416449
[ Info: iteration 29, average log likelihood -1.416439
[ Info: iteration 30, average log likelihood -1.416429
[ Info: iteration 31, average log likelihood -1.416420
[ Info: iteration 32, average log likelihood -1.416412
[ Info: iteration 33, average log likelihood -1.416404
[ Info: iteration 34, average log likelihood -1.416396
[ Info: iteration 35, average log likelihood -1.416389
[ Info: iteration 36, average log likelihood -1.416382
[ Info: iteration 37, average log likelihood -1.416376
[ Info: iteration 38, average log likelihood -1.416370
[ Info: iteration 39, average log likelihood -1.416364
[ Info: iteration 40, average log likelihood -1.416358
[ Info: iteration 41, average log likelihood -1.416353
[ Info: iteration 42, average log likelihood -1.416347
[ Info: iteration 43, average log likelihood -1.416342
[ Info: iteration 44, average log likelihood -1.416338
[ Info: iteration 45, average log likelihood -1.416333
[ Info: iteration 46, average log likelihood -1.416329
[ Info: iteration 47, average log likelihood -1.416324
[ Info: iteration 48, average log likelihood -1.416320
[ Info: iteration 49, average log likelihood -1.416316
[ Info: iteration 50, average log likelihood -1.416312
┌ Info: EM with 100000 data points 50 iterations avll -1.416312
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4177935640636727
│     -1.4177383003062658
│      ⋮
└     -1.4163122164358892
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416318
[ Info: iteration 2, average log likelihood -1.416267
[ Info: iteration 3, average log likelihood -1.416222
[ Info: iteration 4, average log likelihood -1.416172
[ Info: iteration 5, average log likelihood -1.416111
[ Info: iteration 6, average log likelihood -1.416038
[ Info: iteration 7, average log likelihood -1.415953
[ Info: iteration 8, average log likelihood -1.415859
[ Info: iteration 9, average log likelihood -1.415762
[ Info: iteration 10, average log likelihood -1.415667
[ Info: iteration 11, average log likelihood -1.415576
[ Info: iteration 12, average log likelihood -1.415492
[ Info: iteration 13, average log likelihood -1.415415
[ Info: iteration 14, average log likelihood -1.415344
[ Info: iteration 15, average log likelihood -1.415280
[ Info: iteration 16, average log likelihood -1.415221
[ Info: iteration 17, average log likelihood -1.415169
[ Info: iteration 18, average log likelihood -1.415121
[ Info: iteration 19, average log likelihood -1.415079
[ Info: iteration 20, average log likelihood -1.415040
[ Info: iteration 21, average log likelihood -1.415004
[ Info: iteration 22, average log likelihood -1.414970
[ Info: iteration 23, average log likelihood -1.414939
[ Info: iteration 24, average log likelihood -1.414910
[ Info: iteration 25, average log likelihood -1.414881
[ Info: iteration 26, average log likelihood -1.414854
[ Info: iteration 27, average log likelihood -1.414827
[ Info: iteration 28, average log likelihood -1.414801
[ Info: iteration 29, average log likelihood -1.414775
[ Info: iteration 30, average log likelihood -1.414749
[ Info: iteration 31, average log likelihood -1.414724
[ Info: iteration 32, average log likelihood -1.414699
[ Info: iteration 33, average log likelihood -1.414674
[ Info: iteration 34, average log likelihood -1.414650
[ Info: iteration 35, average log likelihood -1.414626
[ Info: iteration 36, average log likelihood -1.414603
[ Info: iteration 37, average log likelihood -1.414580
[ Info: iteration 38, average log likelihood -1.414558
[ Info: iteration 39, average log likelihood -1.414537
[ Info: iteration 40, average log likelihood -1.414516
[ Info: iteration 41, average log likelihood -1.414496
[ Info: iteration 42, average log likelihood -1.414476
[ Info: iteration 43, average log likelihood -1.414458
[ Info: iteration 44, average log likelihood -1.414440
[ Info: iteration 45, average log likelihood -1.414423
[ Info: iteration 46, average log likelihood -1.414407
[ Info: iteration 47, average log likelihood -1.414391
[ Info: iteration 48, average log likelihood -1.414377
[ Info: iteration 49, average log likelihood -1.414363
[ Info: iteration 50, average log likelihood -1.414350
┌ Info: EM with 100000 data points 50 iterations avll -1.414350
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4163181141521983
│     -1.4162673621620738
│      ⋮
└     -1.4143495168586548
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414345
[ Info: iteration 2, average log likelihood -1.414277
[ Info: iteration 3, average log likelihood -1.414213
[ Info: iteration 4, average log likelihood -1.414140
[ Info: iteration 5, average log likelihood -1.414049
[ Info: iteration 6, average log likelihood -1.413938
[ Info: iteration 7, average log likelihood -1.413805
[ Info: iteration 8, average log likelihood -1.413654
[ Info: iteration 9, average log likelihood -1.413492
[ Info: iteration 10, average log likelihood -1.413329
[ Info: iteration 11, average log likelihood -1.413171
[ Info: iteration 12, average log likelihood -1.413025
[ Info: iteration 13, average log likelihood -1.412890
[ Info: iteration 14, average log likelihood -1.412769
[ Info: iteration 15, average log likelihood -1.412659
[ Info: iteration 16, average log likelihood -1.412561
[ Info: iteration 17, average log likelihood -1.412472
[ Info: iteration 18, average log likelihood -1.412393
[ Info: iteration 19, average log likelihood -1.412321
[ Info: iteration 20, average log likelihood -1.412256
[ Info: iteration 21, average log likelihood -1.412196
[ Info: iteration 22, average log likelihood -1.412142
[ Info: iteration 23, average log likelihood -1.412091
[ Info: iteration 24, average log likelihood -1.412044
[ Info: iteration 25, average log likelihood -1.412000
[ Info: iteration 26, average log likelihood -1.411958
[ Info: iteration 27, average log likelihood -1.411918
[ Info: iteration 28, average log likelihood -1.411880
[ Info: iteration 29, average log likelihood -1.411843
[ Info: iteration 30, average log likelihood -1.411807
[ Info: iteration 31, average log likelihood -1.411773
[ Info: iteration 32, average log likelihood -1.411740
[ Info: iteration 33, average log likelihood -1.411709
[ Info: iteration 34, average log likelihood -1.411678
[ Info: iteration 35, average log likelihood -1.411650
[ Info: iteration 36, average log likelihood -1.411622
[ Info: iteration 37, average log likelihood -1.411597
[ Info: iteration 38, average log likelihood -1.411572
[ Info: iteration 39, average log likelihood -1.411549
[ Info: iteration 40, average log likelihood -1.411528
[ Info: iteration 41, average log likelihood -1.411507
[ Info: iteration 42, average log likelihood -1.411488
[ Info: iteration 43, average log likelihood -1.411469
[ Info: iteration 44, average log likelihood -1.411451
[ Info: iteration 45, average log likelihood -1.411435
[ Info: iteration 46, average log likelihood -1.411418
[ Info: iteration 47, average log likelihood -1.411403
[ Info: iteration 48, average log likelihood -1.411388
[ Info: iteration 49, average log likelihood -1.411373
[ Info: iteration 50, average log likelihood -1.411359
┌ Info: EM with 100000 data points 50 iterations avll -1.411359
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4143454660348374
│     -1.4142771793807642
│      ⋮
└     -1.4113590442544905
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4244332965230795
│     -1.4244520183337361
│     -1.424383305084959
│     -1.42432972673027
│      ⋮
│     -1.4113877631711964
│     -1.4113731995079257
└     -1.4113590442544905
32×26 Array{Float64,2}:
  0.106798    -0.201448     0.224133   -0.332988   -0.607553    -0.276491   -0.367755      0.00303734    0.237679    -0.140496    0.00832539   -0.311545    0.346328    0.344334    -0.327675    -0.648546     0.0766729   -0.530432   -0.142012    -0.774024     0.469877     0.19111    -0.149405   -0.169205     -0.107566    0.215652
 -0.106621     0.30209      0.548225   -0.2918     -0.577025     0.199888    0.0959578    -0.0261282     0.200238     0.631706   -0.231009      0.695393   -0.0583155  -0.162321     0.243769    -0.420226     0.136742     0.23583    -0.51573      0.0823782    0.422612     0.0617549   0.181804   -0.263274     -0.209313    0.00529874
  0.379149     0.0544739   -0.189849    0.0324443   0.0306717    0.518355   -0.547628     -0.572934      0.0789854   -0.281148   -0.214343     -0.200075   -0.11816     0.00367396  -0.0825418   -0.0406965   -0.540673    -0.470347    0.0453554   -0.222209    -0.0355924    0.171826    0.0983021  -0.852734      0.197516    0.0260144
  0.192552    -0.145149    -0.0706473   0.086771    0.0865301    0.65651    -0.484886      0.0541188    -0.0157674    0.413228   -0.113644      0.393655    0.0467438   0.100449    -0.431897     0.129753    -0.461836    -0.183463   -0.329507    -0.492186     0.334911    -0.0847667   0.0514042   0.301106      0.258536    0.055395
  0.0418555   -0.194326    -0.376935    0.180108   -0.100488    -0.373793   -0.255675      0.326891      0.0502815    0.4627      0.553727     -0.434498    0.0286467   0.0442307   -0.0795865   -0.3983      -0.0556602   -0.634663   -0.782884     0.281579     0.119982    -0.622749   -0.381402   -0.0104324    -0.0691651  -0.93013
  0.119994    -0.19395     -0.191548    0.211521    0.260322    -0.246968    0.144605      0.11393      -0.277416     0.428106    0.0748209     0.524603    0.149037    0.546128     0.726184     0.541617    -0.065949    -0.497056   -0.6461      -0.178642    -0.0817462    0.313256    0.0853257   0.0894874    -0.13309    -0.706838
 -0.056694    -0.120017     0.747521    0.450465   -0.258088     0.125899   -0.328898      0.126024     -0.307393    -0.0613584   0.0272203    -0.140179   -0.426959   -0.301967    -0.0510017   -0.705725     0.184467     0.0373265   0.00938489   0.593034    -0.294735     0.0135513  -0.602468    0.509845     -0.186696    0.332574
  0.0164478    0.0785588    0.433438    0.794067   -0.200472     0.113401    0.0061172    -0.0852214     0.0278482    0.239582    0.377785     -0.138737    0.0225495   0.525545    -0.274536    -0.00512201   0.093841     0.0750137  -0.295293     0.620844     0.0291751    0.361839    0.0185892   0.00259644   -0.09865    -0.480641
 -0.0255473    0.324607     0.0347353   0.112088    0.31272     -0.0536436   0.079983      0.49962      -0.0870483   -0.0328064  -0.0633694    -0.171204    0.241787   -0.158721    -0.0542022    0.0383599   -0.0980928    0.0100989  -0.167165    -0.0339895   -0.389618    -0.542882    0.101969    0.000483308   0.138479   -0.416008
 -0.132481     0.0516988   -0.0190249   0.244945    0.0880474    0.074671   -0.0298515     0.0522181     0.00527016   0.0244693  -0.0520863     0.0479614  -0.0599114  -0.0817406   -0.128575     0.211556     0.173183     0.0790579   0.137337     0.0155706   -0.00833532   0.138303    0.0475431   0.0403891     0.111182   -0.134634
 -0.306302    -0.176869    -0.535437   -0.587179    0.257699    -0.12158     0.575803     -0.0181142    -0.0409734   -0.0692276  -0.0372621     0.552077    0.246835    0.0112487    0.406006     0.271698    -0.241454     0.0322171   0.405362    -0.600386     0.0584779   -0.227283    0.356834    0.116054      0.2438      0.274536
 -0.5729       0.0341282   -0.15625     0.114923    0.40366      0.293285    0.360887     -0.258766     -0.0876498    0.269259    0.328889      0.686694   -0.150975   -0.18261      0.3404       0.454819     0.110419     0.598806    0.134365     0.433809    -0.180285     0.146751   -0.158967    0.205598      0.611238   -0.291915
  0.00153762  -0.232647     0.0486616  -0.201355   -0.150995     0.0257597  -0.013657     -0.141084     -0.0349516    0.0715294   0.163681      0.203893   -0.0540811   0.125584     0.262573    -0.175098    -0.0160977   -0.090525   -0.171695    -0.0372629    0.0692011    0.124848   -0.356309   -0.061688     -0.0202778   0.229577
  0.0864793    0.0679497   -0.171761   -0.211609   -0.20133     -0.395384   -0.000337814  -0.194541     -0.00134822  -0.192161    0.119353     -0.211091    0.025278    0.313197     0.163256    -0.127279    -0.0947242   -0.178547    0.316988     0.0825913    0.198574    -0.0565415   0.333157   -0.0657764    -0.375627    0.219956
 -0.247026    -0.0760588    0.0329602  -0.114698    0.385334    -0.279643    0.252861     -0.245093      0.475142    -0.748334   -0.000743745  -0.339626    0.0372627  -0.168871     0.214682    -0.234101     0.376567     0.158603    0.419251     0.197323    -0.174721    -0.206708   -0.365258   -0.449745     -0.0954963   0.653612
  0.138009    -0.151496    -0.280226    0.0468268   0.386331    -0.253383   -0.109641      0.343982      0.274784    -0.961613    0.120557      0.0230713  -0.574652   -0.0359219   -0.277571    -0.0400959    0.311823    -0.0762311   0.320215    -0.0891393   -0.136947     0.220319   -0.0122883   0.504287      0.481154   -0.234781
 -0.0845318   -0.0834871   -0.125739   -0.152341    0.0406893   -0.0976223   0.0666975    -0.174611      0.129612    -0.344714   -0.178138     -0.104755   -0.034186    0.0195995    0.01189     -0.121502     0.040761     0.0488922   0.114577    -0.195289    -0.0535458    0.0171013  -0.104932   -0.407932      0.226379    0.180784
 -0.136234     0.0438038    0.263647    0.431762   -0.059477     0.3824     -0.116155      0.452699     -0.147156     0.489689    0.210833      0.0873079   0.150786    0.124935    -0.317839    -0.00321458  -0.163773    -0.0447494  -0.360622     0.181565    -0.0706125   -0.0176409   0.0474914   0.465641      0.0161457  -0.505891
 -0.733908     0.893428     0.377383   -0.0564761  -0.0857484    0.44011    -0.380855      0.411214      0.0115121   -0.829884    0.0910491    -0.218078    0.0947081  -0.336416    -0.371281    -0.636641     0.290639    -0.070475    0.274957     0.348032     0.188311    -0.535224    0.81017    -0.00945795    0.229937    0.171143
 -0.205308     0.62415      0.0365966  -0.0698055   0.00832658   0.481607   -0.572484      0.62631       0.0838609   -0.18128     0.0115276    -0.0324505  -0.0367278   0.191899    -0.268292     0.484001    -0.439084     0.340973    0.486811    -0.182017     0.272466    -0.203498    0.434904   -0.49057       0.12139    -0.422732
  0.134409     0.12677     -0.364264    0.331105   -0.31319     -0.280526    0.00389957   -0.152939     -0.891328    -0.10018    -0.0136919    -0.858241    0.658262    0.211327    -0.365001     0.36556     -0.22408     -0.299245    0.125468     0.00473514  -0.380199     0.11343    -0.150169   -0.078616     -0.282535    0.184136
  0.146604    -0.00858669  -0.327729    0.539268    1.21737     -0.640522   -0.217681      0.0330077    -0.254196    -0.651563    0.31753      -0.636392    0.416905    0.303853    -0.645854     0.543281    -0.751618    -0.54642     0.657517    -0.142304    -0.054346    -0.982574    0.594674    0.0928126    -0.420057   -0.308023
  0.194513     0.595959     0.007603    0.64128     0.587632    -0.652711    0.234761     -0.436503      0.422158     0.321951   -0.129684      0.026386   -0.109817    0.085312     0.0788861    0.609208     0.579164     0.150481    0.602202    -0.025686     0.411767     0.216845    0.736376   -0.162615     -0.240521   -0.374709
 -0.508605     0.447437    -0.31447     0.0300098   0.312948     0.21543     0.0535485    -0.432976     -0.157208    -0.141727    0.977847      0.232261    0.126949   -0.0107009   -0.506303     0.60586      0.707408    -1.0033      0.0784201   -0.289221     0.287513     0.159808    0.232476    0.714727     -0.596865   -0.241771
  0.487771    -0.45707      0.257051   -0.299636   -0.475944    -0.135957    0.067586      0.539713     -0.216515     0.279444   -0.708311      0.360956    0.0509041  -0.013032     0.813457    -0.489366    -0.546631     0.689845   -0.405332     0.142376    -0.543846    -0.198384   -0.735764   -0.60269       0.785912    0.393587
 -0.290261    -0.664422     0.084012    0.362466   -0.228608    -0.231884    0.0617519     0.11225      -0.0830957    0.309276   -0.855585     -0.309268    0.0589993  -0.378141    -0.169138     0.0477781    0.2862       0.527339    0.0369492   -0.169808    -0.024917     0.442252   -0.13254    -0.20244       0.484516    0.240021
 -0.109114    -0.00339639  -0.553452   -0.388769   -0.0804089   -0.0777833   0.523434      0.434292     -0.102687     0.134993   -0.419144     -0.250619    0.218664   -1.18635      0.00447221  -0.255294     0.00868562  -0.0287853  -0.108154     0.0775493   -0.294762    -0.379428   -0.136843   -0.158007     -0.149436    0.437491
  0.457165     0.0332288   -0.369209    0.0888153  -0.216221    -1.0233      0.668405     -0.356604     -0.320546    -0.025893   -0.954421      0.957041    1.04803    -0.487827    -0.113731    -0.131967     0.199929    -0.0881159  -0.130589    -0.18492      0.00102045  -0.350215   -0.423175    0.36035      -0.029223    0.573214
 -0.149752    -0.551474    -0.234762   -0.354428   -0.492637     0.0414657  -0.212559     -0.357369      0.280307     0.248758    0.399644      0.108715   -1.05138     0.171997     0.188681     0.0879237   -0.194979     0.0660576   0.170651    -0.184563     0.281272     0.542232   -0.324287   -0.206311     -0.157626    0.140901
  0.66016      0.91438      0.0525791  -0.549965   -0.0879446   -0.0463011  -0.0493675     0.000695041  -0.156958    -0.536402    0.362515      0.467605   -0.462613    0.259778     0.77911      0.362977     0.0730331    0.0782022   0.305593     0.260673    -0.0843665   -0.0176693   0.305113    0.116368     -0.618249    0.258594
 -0.104485    -0.778156    -0.190812   -0.0499839   0.101377    -0.569358    1.07664      -0.810917     -0.123624     0.0782966   0.666139     -0.245813    0.120328    0.321463     0.362003    -0.563746     0.391742    -0.136245   -0.130711     0.360953    -0.483105     0.241068   -0.145442    0.273691     -0.0028208   0.135836
  0.334122    -0.513942     0.0659934  -0.0969864   0.216718     0.443547    0.278201     -0.924764     -0.231222     0.0203899  -0.327465     -0.0158228   0.462877    0.332061     0.14625      0.538105    -0.216715     0.357671    0.269464     0.442196     0.243991     0.166469   -0.0857517   0.202948     -0.110337    0.834883[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411345
[ Info: iteration 2, average log likelihood -1.411332
[ Info: iteration 3, average log likelihood -1.411318
[ Info: iteration 4, average log likelihood -1.411305
[ Info: iteration 5, average log likelihood -1.411292
[ Info: iteration 6, average log likelihood -1.411280
[ Info: iteration 7, average log likelihood -1.411267
[ Info: iteration 8, average log likelihood -1.411254
[ Info: iteration 9, average log likelihood -1.411241
[ Info: iteration 10, average log likelihood -1.411228
┌ Info: EM with 100000 data points 10 iterations avll -1.411228
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.667224e+05
      1       7.104494e+05      -2.562730e+05 |       32
      2       6.955237e+05      -1.492570e+04 |       32
      3       6.896780e+05      -5.845692e+03 |       32
      4       6.866603e+05      -3.017722e+03 |       32
      5       6.848211e+05      -1.839143e+03 |       32
      6       6.835783e+05      -1.242845e+03 |       32
      7       6.826248e+05      -9.534503e+02 |       32
      8       6.818755e+05      -7.493837e+02 |       32
      9       6.812181e+05      -6.573831e+02 |       32
     10       6.806638e+05      -5.543043e+02 |       32
     11       6.801906e+05      -4.731750e+02 |       32
     12       6.797993e+05      -3.912941e+02 |       32
     13       6.794542e+05      -3.451330e+02 |       32
     14       6.791327e+05      -3.214553e+02 |       32
     15       6.788489e+05      -2.838353e+02 |       32
     16       6.785684e+05      -2.804505e+02 |       32
     17       6.783143e+05      -2.541517e+02 |       32
     18       6.780733e+05      -2.409293e+02 |       32
     19       6.778548e+05      -2.185204e+02 |       32
     20       6.776441e+05      -2.107234e+02 |       32
     21       6.774557e+05      -1.883776e+02 |       32
     22       6.772830e+05      -1.727133e+02 |       32
     23       6.771185e+05      -1.645502e+02 |       32
     24       6.769531e+05      -1.653442e+02 |       32
     25       6.767800e+05      -1.730867e+02 |       32
     26       6.766035e+05      -1.765140e+02 |       32
     27       6.764306e+05      -1.728921e+02 |       32
     28       6.762654e+05      -1.651943e+02 |       32
     29       6.761230e+05      -1.424765e+02 |       32
     30       6.759842e+05      -1.387521e+02 |       32
     31       6.758622e+05      -1.219959e+02 |       32
     32       6.757465e+05      -1.156991e+02 |       32
     33       6.756307e+05      -1.158197e+02 |       32
     34       6.755305e+05      -1.001784e+02 |       32
     35       6.754327e+05      -9.779959e+01 |       32
     36       6.753308e+05      -1.019432e+02 |       32
     37       6.752270e+05      -1.038085e+02 |       32
     38       6.751395e+05      -8.747823e+01 |       32
     39       6.750622e+05      -7.723372e+01 |       32
     40       6.749798e+05      -8.242756e+01 |       32
     41       6.749047e+05      -7.515961e+01 |       32
     42       6.748402e+05      -6.446897e+01 |       32
     43       6.747842e+05      -5.602534e+01 |       32
     44       6.747375e+05      -4.668876e+01 |       32
     45       6.746983e+05      -3.918280e+01 |       32
     46       6.746641e+05      -3.419359e+01 |       32
     47       6.746331e+05      -3.101345e+01 |       32
     48       6.746054e+05      -2.770349e+01 |       32
     49       6.745784e+05      -2.696329e+01 |       32
     50       6.745543e+05      -2.408768e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674554.3298742725)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423379
[ Info: iteration 2, average log likelihood -1.418459
[ Info: iteration 3, average log likelihood -1.417199
[ Info: iteration 4, average log likelihood -1.416325
[ Info: iteration 5, average log likelihood -1.415379
[ Info: iteration 6, average log likelihood -1.414385
[ Info: iteration 7, average log likelihood -1.413581
[ Info: iteration 8, average log likelihood -1.413083
[ Info: iteration 9, average log likelihood -1.412808
[ Info: iteration 10, average log likelihood -1.412643
[ Info: iteration 11, average log likelihood -1.412529
[ Info: iteration 12, average log likelihood -1.412440
[ Info: iteration 13, average log likelihood -1.412366
[ Info: iteration 14, average log likelihood -1.412301
[ Info: iteration 15, average log likelihood -1.412242
[ Info: iteration 16, average log likelihood -1.412187
[ Info: iteration 17, average log likelihood -1.412136
[ Info: iteration 18, average log likelihood -1.412087
[ Info: iteration 19, average log likelihood -1.412040
[ Info: iteration 20, average log likelihood -1.411995
[ Info: iteration 21, average log likelihood -1.411952
[ Info: iteration 22, average log likelihood -1.411910
[ Info: iteration 23, average log likelihood -1.411869
[ Info: iteration 24, average log likelihood -1.411829
[ Info: iteration 25, average log likelihood -1.411790
[ Info: iteration 26, average log likelihood -1.411753
[ Info: iteration 27, average log likelihood -1.411717
[ Info: iteration 28, average log likelihood -1.411683
[ Info: iteration 29, average log likelihood -1.411650
[ Info: iteration 30, average log likelihood -1.411619
[ Info: iteration 31, average log likelihood -1.411590
[ Info: iteration 32, average log likelihood -1.411563
[ Info: iteration 33, average log likelihood -1.411537
[ Info: iteration 34, average log likelihood -1.411512
[ Info: iteration 35, average log likelihood -1.411489
[ Info: iteration 36, average log likelihood -1.411467
[ Info: iteration 37, average log likelihood -1.411446
[ Info: iteration 38, average log likelihood -1.411426
[ Info: iteration 39, average log likelihood -1.411407
[ Info: iteration 40, average log likelihood -1.411388
[ Info: iteration 41, average log likelihood -1.411371
[ Info: iteration 42, average log likelihood -1.411354
[ Info: iteration 43, average log likelihood -1.411337
[ Info: iteration 44, average log likelihood -1.411322
[ Info: iteration 45, average log likelihood -1.411307
[ Info: iteration 46, average log likelihood -1.411292
[ Info: iteration 47, average log likelihood -1.411278
[ Info: iteration 48, average log likelihood -1.411264
[ Info: iteration 49, average log likelihood -1.411251
[ Info: iteration 50, average log likelihood -1.411238
┌ Info: EM with 100000 data points 50 iterations avll -1.411238
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.796059    -0.0368486    0.023162   -0.0871928    0.281995    0.13665      0.375829   -0.132635     0.364547     0.435592    0.360442     0.804857    -0.364356    -0.207936     0.373898    0.09576     0.11918      0.64869     0.238051    0.116591    0.137521    0.016708      0.132941     0.241432    0.483829   -0.206822
 -0.192713     0.262232     0.066731    0.262932    -0.518395   -0.0958902   -0.0523054  -0.00356395  -0.740612     0.271043   -0.293006    -0.399746     0.461358    -0.095178     0.163296   -0.0179401  -0.467978    -0.123175   -0.0122541   0.139242   -0.439334    0.0536899    -0.162789    -0.385202   -0.357081    0.176952
  0.290364     1.18203      0.0848252   0.111255    -0.363929   -0.444287     0.293048    0.146094     0.0443969   -0.124067    0.169057    -0.142403    -0.344155    -0.121138     0.211813    0.245493    0.483501     0.426225    0.422183    0.381678    0.291731   -0.159239      0.530188    -0.299152   -0.722003   -0.26459
 -0.193352    -0.099911    -0.296943   -0.449775     0.40816    -0.23653      0.374641    0.10138      0.42649     -0.463444   -0.245262    -0.2593       0.266732    -0.62941      0.413813   -0.225808    0.206709     0.15752     0.33176     0.174849   -0.335314   -0.558151     -0.399484    -0.375241   -0.136727    0.711075
  0.245755    -0.0812319   -0.567483   -0.0924252   -0.10786    -0.616211     0.720473   -0.0589926   -0.420788     0.0834454  -0.666611     0.341267     0.724061    -0.594369    -0.165055    0.11318     0.0994338   -0.154444   -0.122163   -0.259344   -0.152199   -0.26236      -0.115461     0.277834    0.0193603   0.398595
  0.249479    -0.123907    -0.261077   -0.397941    -0.0453718  -0.263495    -0.221653   -0.414015    -0.0201453   -0.427796    0.271295    -0.0326633    0.0316915    0.620683     0.273464   -0.100697   -0.226824    -0.295088    0.385928   -0.0284143   0.340107   -0.0106285     0.00916795  -0.0141776  -0.309538    0.505203
 -0.201132    -0.737906    -0.146255    0.249007     0.356772    0.298872    -0.213757    0.063096     0.137472    -0.028842   -0.363743     0.223054     0.0325622    0.041663    -0.314156    0.0450516  -0.157797    -0.34702    -0.149054   -0.462255    0.0218846   0.237014     -0.415304    -0.0330025   0.585444    0.187759
  0.0110166    0.333577    -0.350903   -0.17004      0.321727   -0.399189    -0.122284    0.514111     0.137733    -0.586891    0.0984263   -0.02847     -0.328487    -0.103852    -0.184414   -0.0725102  -0.0950994   -0.100699    0.11964    -0.238298   -0.262032   -0.221836      0.232324     0.170856    0.307842   -0.461918
 -0.0966175   -0.382048     0.551071    0.23156     -0.493837   -0.206409     0.0194994   0.49725     -0.116409     0.332255   -0.570973     0.100471    -0.0991864   -0.194003     0.300459   -0.470463    0.178826     0.485372   -0.474068    0.49901    -0.22035     0.164946     -0.489886    -0.201807    0.464491    0.00302128
  0.0258039    0.13354      0.200446    0.211722    -0.076243    0.464023    -0.542494    0.110683    -0.0182295   -0.187458    0.291075    -0.184584    -0.276452     0.143271    -0.05744    -0.0514778  -0.192527    -0.0024643   0.152216    0.219186   -0.0296664   0.000674374  -0.128604    -0.207989    0.116107   -0.147507
 -0.0539102   -0.100256    -0.121292    0.00824154   0.0396739   0.00732409  -0.0215725   0.00601885  -0.0320177    0.0317654  -0.00213105   0.00509918  -0.0837491    0.044591     0.0299402   0.01987    -0.0452916   -0.108721   -0.0681247   0.015332   -0.0299978   0.0536966    -0.0469061   -0.0581462   0.0758947  -0.072261
 -0.182641    -0.0582458    0.159876    0.305377     0.18082    -0.16969      0.211386    0.020202     0.0409328   -0.0804045  -0.0327485   -0.106131     0.108083     0.00656964  -0.0657396   0.118702    0.366098     0.0913662   0.260808    0.155522   -0.104669    0.0493452     0.0457257    0.122473   -0.0592761   0.0614768
  0.260203     0.0613812   -0.286168    0.369717     0.902367   -0.526859    -0.305986    0.0641884   -0.336301    -0.689544    0.230715    -0.691707     0.406631     0.387846    -0.561824    0.471876   -0.634395    -0.546632    0.625513   -0.0847726  -0.0725928  -0.682168      0.424714     0.0799417  -0.475602   -0.153733
  0.0174006   -0.0603687   -0.810251    0.178752     0.459883    0.298224     0.271327   -0.323339    -0.406434    -0.261298    0.0244955    0.1461       0.00198871  -0.099611     0.0520502   0.90277    -0.00621107   0.209438    0.0499273   0.392965   -0.174347    0.208202     -0.101558     0.0439907   0.565881   -0.307081
 -0.218101     0.173329     0.666583    0.394509     0.215597    0.237521     0.187499   -0.0547959   -0.116982     0.237181    0.947535     0.43532      0.31586      0.512587    -0.0272373  -0.0264063   0.200871    -0.214935   -0.396259    0.803323    0.311306    0.134546     -0.623388     0.276488   -0.289021    0.0206241
  0.0648153   -0.157584    -0.23876     0.34677     -0.0882902  -0.344229    -0.198595    0.279556    -0.00862939   0.530734    0.420448    -0.357369     0.090257     0.147392    -0.041928   -0.227754    0.0166304   -0.628055   -0.748764    0.186487    0.200192   -0.324207     -0.227761    -0.0781793  -0.13004    -0.971902
  0.155646    -0.081985    -0.211072    0.131188     0.367082   -0.301399     0.2656      0.121787    -0.224624     0.383158   -0.0446889    0.624766     0.135972     0.53455      0.953931    0.637622   -0.023039    -0.429166   -0.338995   -0.234413   -0.144291    0.188779      0.367509     0.199674   -0.157216   -0.621203
 -0.00366916   0.449881     0.337306   -0.27007     -0.26643     0.597487    -0.868731    0.724506     0.201352     0.193871   -0.267328     0.358824    -0.0235845    0.0255242   -0.102712   -0.0163449  -0.322945    -0.111803   -0.0903197  -0.39397     0.449873   -0.318803      0.407788    -0.10297    -0.0491133   0.0355074
 -0.00163293  -0.100532     0.0433993  -0.00062996  -0.0455888  -0.107325    -0.308574   -0.0350896    0.130815    -0.492364   -0.615001    -0.267749    -0.573561    -0.587648    -0.391107   -0.259271    0.240984     0.548517    0.954344   -0.164938   -0.0912346  -0.0700774     0.105684    -0.0340576   0.368615    0.555325
 -0.0994932    0.380386     0.285908    0.65486      0.291506    0.40436     -0.135005    0.782693    -0.0451477   -0.0354765   0.153076    -0.257592     0.308522    -0.117049    -0.554138    0.148061    0.0486406    0.225148   -0.0811864   0.20369    -0.818462   -0.475367      0.0583955    0.310102    0.112367   -0.660314
  0.320976    -0.47409      0.219155   -0.168174    -0.2         0.488886     0.350117   -0.739392    -0.182307     0.434259   -0.790562     0.112382     0.590844     0.0351807    0.181438    0.460988   -0.137619     0.694475    0.11689     0.282996    0.252672    0.104945      0.214043    -0.0907991  -0.188133    0.880607
 -0.155217    -0.143808    -0.152709   -0.098044    -0.438172    0.361636    -0.0622362  -0.313362     0.716891    -0.231649    0.345138    -0.625761    -0.60344      0.108007    -0.324802   -0.318842   -0.0601927   -0.168766    0.0229539  -0.0875273   0.43927     0.366669     -0.0620692   -0.650975   -0.104778    0.0322424
  0.0320634   -7.82958e-5  -0.0353388  -0.194767    -0.16275     0.0446225    0.048611   -0.0882186   -0.0160615    0.275918   -0.0348368    0.270403     0.0457294   -0.0432512    0.11978    -0.0760196  -0.0823409   -0.0369679  -0.25683    -0.19424     0.180092   -0.00551701    0.0330579   -0.0722741   0.0131969   0.0200027
  0.70398      0.370538    -0.0248288   0.337962     0.595577    0.152169    -0.237672   -0.776991     0.348061     0.0575083  -0.139601     0.10848     -0.0727544    0.19342     -0.320168    0.405609   -0.131926    -0.0896832   0.0469221  -0.253463    0.386051    0.204474      0.485296    -0.247008    0.273795   -0.332625
  0.166358     0.0082524    0.122639   -0.542778    -0.18786    -0.0300773    0.154167   -0.356398     0.0617808   -0.289093    0.0578931    0.571947    -0.782415    -0.00507323   0.921833   -0.0732596   0.152768     0.0726821   0.0306009  -0.0329352  -0.0193411   0.609036     -0.257281     0.0200781  -0.214215    0.456418
 -1.21317      1.20843      0.198514   -0.278518     0.123675    0.683469     0.0192545   0.411322    -0.205522    -0.985461   -0.170141    -0.178376     0.773371    -0.430987    -0.27835    -0.738251    0.420749    -0.407264   -0.128375    0.347353    0.624259   -0.339413      1.25269      0.0888682   0.320014    0.390631
  0.232427    -0.551192    -0.217771   -0.627699    -0.256846    0.452674     0.301119   -0.130157    -0.290501     0.0928535   0.126982     0.236764    -0.00365338   0.0888605    0.0539933  -0.784943   -0.79024      0.0628754  -0.421262   -0.0364128  -0.412411   -0.460663     -0.828158     0.166826    0.478832    0.398714
 -0.953899     0.396011    -0.504336   -0.3816       0.0309813  -0.169082     0.261262    0.252282    -0.0237935   -0.350575    0.325568     0.220742     1.05902      0.559293     0.179285    0.506704   -0.411726     0.427951    0.441318   -0.780161    0.266723   -0.217211      0.655936    -0.906587    0.536348   -0.144307
 -0.161942    -0.529865     0.0443632   0.327126     0.232494   -0.67881      0.748763   -0.725497    -0.00721014  -0.209375    0.511142    -0.531705     0.162259     0.316338     0.162462   -0.304243    0.544862    -0.0473949   0.119231    0.352701   -0.506958    0.301213     -0.120127     0.0382236   0.0595324   0.113219
  0.0888638   -0.235416     0.209582    0.463772    -0.54291     0.253291    -0.273836   -0.00868317  -0.292677     0.591914    0.428751    -0.00528454  -0.305075     0.511574    -0.506644    0.181076   -0.275849     0.0158275  -0.17443     0.154214    0.207015    0.633161      0.334041     0.429273   -0.376075   -0.3536
 -0.549948     0.456677    -0.417162   -0.0283026    0.236838    0.187829     0.0482872  -0.411812    -0.265993    -0.0514406   0.880508     0.180731     0.12087     -0.182138    -0.500037    0.599669    0.747449    -1.10491     0.169306   -0.549677    0.186938    0.131623      0.31015      0.794303   -0.695414   -0.204967
  0.10472     -0.22179      0.311681   -0.349244    -0.80484    -0.408117    -0.243219   -0.0900062   -0.0806493   -0.0509827  -0.328102    -0.309745     0.583368    -0.0527263   -0.299083   -0.763083    0.242965    -0.515504   -0.273664   -0.779531    0.20233     0.153964     -0.304128    -0.237543   -0.169611    0.366439[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411226
[ Info: iteration 2, average log likelihood -1.411214
[ Info: iteration 3, average log likelihood -1.411203
[ Info: iteration 4, average log likelihood -1.411192
[ Info: iteration 5, average log likelihood -1.411183
[ Info: iteration 6, average log likelihood -1.411173
[ Info: iteration 7, average log likelihood -1.411165
[ Info: iteration 8, average log likelihood -1.411156
[ Info: iteration 9, average log likelihood -1.411149
[ Info: iteration 10, average log likelihood -1.411141
┌ Info: EM with 100000 data points 10 iterations avll -1.411141
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
