Julia Version 1.5.0-DEV.145
Commit 6af5f03d2a (2020-01-23 23:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed JLD ──────────────── v0.9.1
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed LegacyStrings ────── v0.4.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Rmath ────────────── v0.6.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Distributions ────── v0.22.3
 Installed SpecialFunctions ─── v0.9.0
 Installed OrderedCollections ─ v1.1.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Parameters ───────── v0.12.0
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack_jll ───────── v3.5.0+2
 Installed PDMats ───────────── v0.9.11
 Installed Distances ────────── v0.8.2
 Installed StatsBase ────────── v0.32.0
 Installed DataAPI ──────────── v1.1.0
 Installed FileIO ───────────── v1.2.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed StatsFuns ────────── v0.9.3
 Installed HDF5 ─────────────── v0.12.5
 Installed FillArrays ───────── v0.8.4
 Installed Missings ─────────── v0.4.3
 Installed Arpack ───────────── v0.4.0
 Installed CMake ────────────── v1.1.2
 Installed DataStructures ───── v0.17.9
 Installed QuadGK ───────────── v2.3.1
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed URIParser ────────── v0.4.0
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_9Scrqx/Project.toml`
 [no changes]
  Updating `/tmp/jl_9Scrqx/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_MzPOfI/Project.toml`
 [no changes]
  Updating `/tmp/jl_MzPOfI/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_lP7Yul/Project.toml`
 [no changes]
  Updating `/tmp/jl_lP7Yul/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_487kPD/Project.toml`
 [no changes]
  Updating `/tmp/jl_487kPD/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_x5CNNj/Project.toml`
 [no changes]
  Updating `/tmp/jl_x5CNNj/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_x5CNNj/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.340342336972122e6, [2868.6481049933714, 97131.35189500664], [1785.386995856943 -3930.463649248908 -3761.8508202912776; -1792.371022430096 3743.2005269916713 4182.4118228840425], [[3893.899351650176 -2125.5281203144914 -1584.4215972234717; -2125.5281203144914 5915.998814694876 5402.572709484078; -1584.4215972234715 5402.572709484078 5543.218152654769], [96455.6635048074 1575.599996672822 1419.4330921248084; 1575.5999966728223 93867.72743523565 -5205.865948992966; 1419.4330921248084 -5205.865948992966 94553.18308564571]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.498657e+03
      1       1.266275e+03      -2.323821e+02 |        8
      2       1.157384e+03      -1.088906e+02 |        2
      3       1.131729e+03      -2.565491e+01 |        2
      4       1.097985e+03      -3.374437e+01 |        2
      5       1.061481e+03      -3.650425e+01 |        4
      6       9.999105e+02      -6.157024e+01 |        0
      7       9.999105e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 999.9104705111495)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.063426
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.762163
[ Info: iteration 2, lowerbound -3.643129
[ Info: iteration 3, lowerbound -3.529458
[ Info: iteration 4, lowerbound -3.404525
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.267630
[ Info: iteration 6, lowerbound -3.130152
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.996296
[ Info: iteration 8, lowerbound -2.861321
[ Info: iteration 9, lowerbound -2.736569
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.610871
[ Info: iteration 11, lowerbound -2.495528
[ Info: iteration 12, lowerbound -2.413542
[ Info: iteration 13, lowerbound -2.359529
[ Info: iteration 14, lowerbound -2.331410
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.312770
[ Info: iteration 16, lowerbound -2.308880
[ Info: dropping number of Gaussions to 2
[ Info: iteration 17, lowerbound -2.302917
[ Info: iteration 18, lowerbound -2.299259
[ Info: iteration 19, lowerbound -2.299256
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan 27 20:59:59 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan 27 21:00:07 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Mon Jan 27 21:00:09 2020: EM with 272 data points 0 iterations avll -2.063426
5.8 data points per parameter
, Mon Jan 27 21:00:11 2020: GMM converted to Variational GMM
, Mon Jan 27 21:00:18 2020: iteration 1, lowerbound -3.762163
, Mon Jan 27 21:00:18 2020: iteration 2, lowerbound -3.643129
, Mon Jan 27 21:00:18 2020: iteration 3, lowerbound -3.529458
, Mon Jan 27 21:00:18 2020: iteration 4, lowerbound -3.404525
, Mon Jan 27 21:00:18 2020: dropping number of Gaussions to 7
, Mon Jan 27 21:00:18 2020: iteration 5, lowerbound -3.267630
, Mon Jan 27 21:00:18 2020: iteration 6, lowerbound -3.130152
, Mon Jan 27 21:00:18 2020: dropping number of Gaussions to 6
, Mon Jan 27 21:00:18 2020: iteration 7, lowerbound -2.996296
, Mon Jan 27 21:00:18 2020: iteration 8, lowerbound -2.861321
, Mon Jan 27 21:00:18 2020: iteration 9, lowerbound -2.736569
, Mon Jan 27 21:00:18 2020: dropping number of Gaussions to 4
, Mon Jan 27 21:00:18 2020: iteration 10, lowerbound -2.610871
, Mon Jan 27 21:00:18 2020: iteration 11, lowerbound -2.495528
, Mon Jan 27 21:00:18 2020: iteration 12, lowerbound -2.413542
, Mon Jan 27 21:00:18 2020: iteration 13, lowerbound -2.359529
, Mon Jan 27 21:00:18 2020: iteration 14, lowerbound -2.331410
, Mon Jan 27 21:00:18 2020: dropping number of Gaussions to 3
, Mon Jan 27 21:00:18 2020: iteration 15, lowerbound -2.312770
, Mon Jan 27 21:00:18 2020: iteration 16, lowerbound -2.308880
, Mon Jan 27 21:00:18 2020: dropping number of Gaussions to 2
, Mon Jan 27 21:00:18 2020: iteration 17, lowerbound -2.302917
, Mon Jan 27 21:00:18 2020: iteration 18, lowerbound -2.299259
, Mon Jan 27 21:00:18 2020: iteration 19, lowerbound -2.299256
, Mon Jan 27 21:00:18 2020: iteration 20, lowerbound -2.299254
, Mon Jan 27 21:00:18 2020: iteration 21, lowerbound -2.299254
, Mon Jan 27 21:00:18 2020: iteration 22, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 23, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 24, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 25, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 26, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 27, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 28, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 29, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 30, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 31, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 32, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 33, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 34, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 35, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 36, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 37, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 38, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 39, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 40, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 41, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 42, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 43, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 44, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 45, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 46, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 47, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 48, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 49, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: iteration 50, lowerbound -2.299253
, Mon Jan 27 21:00:18 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601388, 95.95490777398615]
β = [178.04509222601388, 95.95490777398615]
m = [4.250300733269909 79.28686694436183; 2.00022925777537 53.8519871724613]
ν = [180.04509222601388, 97.95490777398615]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484516 -0.007644049042327397; 0.0 0.008581705166333407], [0.3758763611948393 -0.008953123827346091; 0.0 0.012748664777409383]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9930671697485137
avll from llpg:  -0.9930671697485184
avll direct:     -0.9930671697485184
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.00975280508748
avll from llpg:  -1.0097528050874802
avll direct:     -1.0097528050874802
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0142562   -0.0322571   -0.0780343    0.198965     0.00323893  -0.092694     0.0304773     0.198398    -0.205652    -0.11118      0.0354711   -0.172584     0.0771324    0.0621565   -0.0389134     0.00768901   0.0863974   0.00931     -0.0232705    0.0227604   -0.130365    0.0453281   -0.0635106    -0.0799025    0.0185608   0.00014294
 -0.178908     0.0609017    0.0479787    0.182751     0.0254428    0.0072425    0.0273644    -0.101777    -0.0489921   -0.0164465    0.0900135   -0.061671    -0.247902    -0.0589673   -0.0683614     0.0295516   -0.0795123  -0.0254199    0.12072      0.0348674    0.0952775   0.0396387   -0.0336389    -0.0602718   -0.108433   -0.103882
 -0.00505079  -0.039485    -0.117312    -0.0897408    0.00643603   0.0326182    0.0513419    -0.101794    -0.0570119    0.06578     -0.0753162    0.269312    -0.0218517   -0.148838    -0.0771031     0.00922525  -0.057698    0.114335     0.00840584  -0.21209     -0.0983153  -0.0629206    0.04736      -0.243354     0.0237218   0.269296
  0.00762318   0.00254517   0.165914    -0.0452507   -0.0366218   -0.00382562   0.143636     -0.0543509   -0.0656685   -0.0591836    0.00516139   0.0604272   -0.0590595    0.100326    -0.0621805    -0.107122    -0.0324965  -0.105192    -0.08261      0.0674838   -0.0518934  -0.00448265   0.212349     -0.0714572   -0.0430939  -0.063211
 -0.0825981   -0.0247285    0.0814475   -0.0439213    0.0716435   -0.0693864   -0.0900847     0.171289     0.0130312   -0.0593403    0.127879    -0.104473    -0.00562147   0.00728004  -0.119981      0.0797055    0.0736543   0.0363074   -0.0130006    0.00272104  -0.125941   -0.0162662    0.185787      0.0940622   -0.0301173   0.183838
 -0.0652487    0.0116677   -0.0318026   -0.0523791    0.00275244   0.0471933   -0.0331993     0.0369262    0.135033     0.0918964   -0.0460439   -0.00419924   0.0103599   -0.0764818   -0.00335954    0.00103     -0.0700019  -0.0822329   -0.083407     0.184807     0.0342258   0.0706685    0.174023     -0.0108184   -0.038594   -0.0438051
  0.0206341   -0.0452216   -0.0756476   -0.0610347   -0.0723713   -0.046079     0.114625     -0.111012     0.0886844    0.119151    -0.133672     0.0240991    0.0536131    0.0412113    0.0900767     0.161574    -0.176893   -0.136874     0.0278232   -0.223484     0.0739829   0.0230397    0.00252038    0.0448533   -0.094152    0.130698
  0.025986    -0.00554928  -0.107246    -0.219815     0.0842616   -0.00997802  -0.0970984     0.107003     0.0129463   -0.209878     0.050017    -0.126657     0.120982     0.00333886  -0.0272288    -0.109291     0.214011    0.0118778   -0.0811455    0.1025       0.145108   -0.0206685   -0.0534228    -0.0945299   -0.257453   -0.0249847
  0.0717585   -0.0301933    0.0537927   -0.107982     0.294463     0.192629    -0.0329595    -0.0793335    0.167503     0.0446617    0.0447904    0.00813451   0.0290565    0.0441853   -0.0327272     0.0878206   -0.102562   -0.0694714   -0.227774     0.0733807   -0.1077      0.0598133   -0.0200798    -0.0839734    0.225293   -0.0247242
  0.0972374    0.0425273    0.142281    -0.118686     0.0829021    0.0475326    0.0580248    -0.00275026  -0.0934967   -0.2295       0.0733068    0.138648     0.0375092    0.134489    -0.0890378     0.102061     0.2062     -0.135502    -0.066177     0.0978428    0.121016    0.0771998    0.169545     -0.133424     0.113146    0.0431631
 -0.0600066   -0.155874     0.183388    -0.0440232    0.105598    -0.0738893   -0.0729818    -0.00218412   0.0211243    0.175805    -0.101631     0.101198     0.0216128   -0.206824    -0.0781887     0.0162595    0.0346689   0.00230599  -0.113826    -0.00025893   0.0287111  -0.173392     0.101883     -0.0883988   -0.264948    0.0917578
 -0.0895004    0.0250502    0.132181    -0.05301     -0.131307     0.0413665    0.123569      0.0338432    0.0732531   -0.0334942   -0.11902      0.0823112   -0.0611266    0.118107     0.0401604     0.119989     0.122847   -0.0334141   -0.0391121   -0.116849    -0.0359568   0.0538895    0.153552     -0.0519031    0.126437    0.0183553
  0.0242682    0.00170275   0.105406    -0.0259421   -0.0467323   -0.01788      0.00609649    0.0883904   -0.0169922    0.114152    -0.125311    -0.301635    -0.027646     0.0870572    0.0226661    -0.127712    -0.134459    0.0219475    0.0818836    0.118416     0.160713   -0.0397528    0.144718      0.0168688   -0.0716699  -0.189714
 -0.0298887    0.29405     -0.0133005    0.0675787   -0.164517     0.00129112  -0.0327047     0.0697119    0.0517798    0.188603    -0.00575472   0.107558    -0.184935    -0.0489256   -0.125258     -0.0559044   -0.013521    0.023501    -0.0610308    0.173498    -0.055785    0.238566    -0.0228489     0.117715     0.013343    0.144075
  0.0691557    0.00998981  -0.122675    -0.00257376  -0.0483379    0.0646921    0.0529285     0.106297     0.152411    -0.00873282  -0.0277633    0.179687     0.0320392    0.0927107   -0.112591     -0.0325016    0.139374   -0.109117     0.199739     0.0507779    0.0403886   0.173633     0.136852      0.175141    -0.0208535  -0.0544997
  0.0266838   -0.0349624    0.123417     0.0136942    0.0739674    0.0897784    0.0264998    -0.110173    -0.165279     0.0916134    0.0621432   -0.0709064   -0.119978     0.111282    -0.156179      0.219945     0.200113   -0.0289133   -0.0209656    0.0890089   -0.0969887  -0.165578     0.0268495    -0.020966    -0.0151996  -0.0210794
 -0.110188     0.102297     0.146552     0.0669698   -0.131742    -0.164941    -0.179467      0.136111     0.0663336   -0.0107106    0.175804     0.0049316    0.152349     0.17462     -0.0590368     0.0737518    0.0400884   0.0545191    0.0056454   -0.00755835  -0.0297946   0.0913884    0.0639967     0.0327881    0.0458766  -0.0672226
 -0.126129     0.0380238    0.0210345   -0.0812504   -0.0168451   -0.142995    -0.0377259    -0.0886183    0.0462525    0.00921974   0.0410142    0.123421     0.070973     0.147647    -0.0585949    -0.0947151   -0.0328677  -0.027266     0.0775305    0.0888754    0.117605   -0.0169019    0.091139      0.0598858    0.238963    0.0280466
  0.115409    -0.0136148   -0.00938614  -0.169369    -0.0988992   -0.262587    -0.0331795     0.0212974   -0.181703     0.156538     0.0171561   -0.0419354    0.0668464    0.0514828    0.10312       0.0375581    0.127888    0.109704    -0.101764     0.124798     0.0516538  -0.0742162    0.0702967     0.156481     0.133808   -0.0847574
  0.238305     0.0480309    0.0352749    0.122382     0.0550634   -0.0974779   -0.105152     -0.0131474   -0.0339049    0.0597055   -0.170865    -0.228963    -0.00894635   0.129885    -0.0765548    -0.121922    -0.0535415   0.0930355    0.0686848   -0.00979468  -0.0424536   0.118632     0.000325781   0.0463464   -0.112367    0.0187335
  0.00353146   0.0408737    0.150043     0.0258652   -0.02972     -0.00360487   0.001522      0.0178218   -0.0504831    0.0898395    0.10853      0.0749984    0.108104    -0.0482081   -0.209897     -0.142601    -0.0597298  -0.0149251   -0.0168434   -0.046446     0.0898022   0.109206    -0.0107339     0.124634     0.0462208   0.105819
 -0.00544677  -0.109255    -0.00840537   0.0470096    0.1235       0.00533246   0.000338536  -0.0721138   -0.0527274   -0.0150211   -0.218098     0.0247982   -0.0663847   -0.0193941   -0.0231724    -0.112404    -0.156131    0.032898     0.0375924    0.0918271    0.0238562   0.0818557    0.113265     -0.085058    -0.109952    0.0513807
  0.0119387   -0.0948276   -0.133847     0.00691414   0.0853187   -0.172824     0.0641121     0.0837941   -0.0134744    0.01535      0.0992984    0.0548037    0.0185976   -0.162779     0.105531      0.0226527    0.0510067  -0.0725147   -0.0271658   -0.0248753   -0.109694    0.132584    -0.186989      0.0894566    0.0471607  -0.0173047
  0.0447661   -0.111688    -0.0294051    0.00221627  -0.0346729    0.0195384   -0.0422709     0.00706     -0.0234843   -0.204188     0.0265297    0.118349    -0.0695401    0.0304627   -0.0260427     0.0566095   -0.146253    0.151745     0.0219024   -0.00371361  -0.0707421  -0.279328    -0.0368624     0.161134     0.0245169  -0.0127523
  0.179448    -0.0565796    0.0311341    0.0266035    0.0125823    0.0251779   -0.0340643    -0.0791406   -0.0312164    0.0108541   -0.148315    -0.0288448    0.0558938   -0.0319167   -0.000811378   0.0668592   -0.0453688  -0.0693487   -0.010145    -0.0498929   -0.0779995   0.235139     0.144441      0.0636473   -0.211039   -0.0307269
 -0.11688     -0.0321717   -0.0716338    0.0610458   -0.0104992    0.0809579    0.0348486     0.0109342    0.0095419    0.116363     0.127875    -0.0142119   -0.0282539    0.0335849    0.0478905     0.103713     0.0365075  -0.0801639    0.0736113    0.110739     0.0303747  -0.15527      0.0418504    -0.0618695   -0.0663507  -0.148443
  0.0642729   -0.111334     0.120983     0.0874868    0.00747025  -0.110566     0.067206     -0.182145     0.0261699   -0.0123294   -0.0167333   -0.201252    -0.00641125  -0.0918609    0.0981585    -0.0907148    0.054033   -0.0952693    0.0334469   -0.0347752   -0.218712   -0.0316374   -0.00991447    0.0637584    0.0936249  -0.089474
  0.10739     -0.0853132    0.0395414    0.00171478  -0.0459246   -0.144095     0.0410883     0.0914167    0.00825113   0.0433788   -0.0249258    0.149043    -0.144294    -0.0637591    0.0989598     0.0201817   -0.0127862  -0.138438     0.206274     0.0125886    0.161759    0.116714     0.0651392    -0.0517988   -0.0882711  -0.0881859
  0.0667502    0.088505    -0.0698727    0.181426     0.122053    -0.0860407    0.00326579   -0.0440272   -0.0896133   -0.0316255    0.0171368   -0.0757843   -0.205491     0.168164     0.0996262    -0.0404097   -0.0073761   0.00351083   0.120876    -0.0725854    0.0166313  -0.0420409    0.0121302     0.150431    -0.238118    0.00566966
  0.070449     0.116251    -0.0617316    0.0690305   -0.0492445   -0.0530386    0.0728064     0.218661     0.0165537    0.013715     0.0566045    0.0115001   -0.156441    -0.052124     0.05136       0.0274221   -0.0151378  -0.150236    -0.143346    -0.32453      0.0626299   0.00711957   0.115264      0.0505252    0.171937   -0.067277
 -0.245671     0.0258441   -0.0684797    0.214162     0.0599545    0.121027     0.199531      0.00111368   0.00520036  -0.00105156  -0.0400853    0.0322956   -0.135122    -0.101618     0.0279692     0.12047      0.0939591   0.151668     0.175551     0.0890714    0.0107963   0.0160517   -0.0746725     0.00755823  -0.0496158   0.0384378
  0.0935729   -0.0598197   -0.0252339    0.0341692   -0.0132131    0.0380006   -0.168795      0.0760023   -0.203808    -0.155708    -0.0809431   -0.131206     0.0245757   -0.201266     0.140066     -0.0545061   -0.0951841   0.0533974    0.0861955    0.113431    -0.0513418   0.212748    -0.125324     -0.112225     0.0444842  -0.035156kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4412564274337407
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.441313
[ Info: iteration 2, average log likelihood -1.441256
[ Info: iteration 3, average log likelihood -1.440923
[ Info: iteration 4, average log likelihood -1.437298
[ Info: iteration 5, average log likelihood -1.424645
[ Info: iteration 6, average log likelihood -1.415054
[ Info: iteration 7, average log likelihood -1.413094
[ Info: iteration 8, average log likelihood -1.412509
[ Info: iteration 9, average log likelihood -1.412121
[ Info: iteration 10, average log likelihood -1.411789
[ Info: iteration 11, average log likelihood -1.411477
[ Info: iteration 12, average log likelihood -1.411164
[ Info: iteration 13, average log likelihood -1.410831
[ Info: iteration 14, average log likelihood -1.410372
[ Info: iteration 15, average log likelihood -1.409731
[ Info: iteration 16, average log likelihood -1.409189
[ Info: iteration 17, average log likelihood -1.408832
[ Info: iteration 18, average log likelihood -1.408606
[ Info: iteration 19, average log likelihood -1.408459
[ Info: iteration 20, average log likelihood -1.408361
[ Info: iteration 21, average log likelihood -1.408293
[ Info: iteration 22, average log likelihood -1.408243
[ Info: iteration 23, average log likelihood -1.408203
[ Info: iteration 24, average log likelihood -1.408168
[ Info: iteration 25, average log likelihood -1.408136
[ Info: iteration 26, average log likelihood -1.408104
[ Info: iteration 27, average log likelihood -1.408073
[ Info: iteration 28, average log likelihood -1.408042
[ Info: iteration 29, average log likelihood -1.408011
[ Info: iteration 30, average log likelihood -1.407980
[ Info: iteration 31, average log likelihood -1.407949
[ Info: iteration 32, average log likelihood -1.407917
[ Info: iteration 33, average log likelihood -1.407886
[ Info: iteration 34, average log likelihood -1.407854
[ Info: iteration 35, average log likelihood -1.407822
[ Info: iteration 36, average log likelihood -1.407790
[ Info: iteration 37, average log likelihood -1.407760
[ Info: iteration 38, average log likelihood -1.407729
[ Info: iteration 39, average log likelihood -1.407699
[ Info: iteration 40, average log likelihood -1.407670
[ Info: iteration 41, average log likelihood -1.407642
[ Info: iteration 42, average log likelihood -1.407613
[ Info: iteration 43, average log likelihood -1.407586
[ Info: iteration 44, average log likelihood -1.407561
[ Info: iteration 45, average log likelihood -1.407538
[ Info: iteration 46, average log likelihood -1.407518
[ Info: iteration 47, average log likelihood -1.407502
[ Info: iteration 48, average log likelihood -1.407489
[ Info: iteration 49, average log likelihood -1.407479
[ Info: iteration 50, average log likelihood -1.407471
┌ Info: EM with 100000 data points 50 iterations avll -1.407471
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.441313425360355
│     -1.4412558073399613
│      ⋮
└     -1.4074707716430044
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407596
[ Info: iteration 2, average log likelihood -1.407481
[ Info: iteration 3, average log likelihood -1.407044
[ Info: iteration 4, average log likelihood -1.402854
[ Info: iteration 5, average log likelihood -1.389430
[ Info: iteration 6, average log likelihood -1.377669
[ Info: iteration 7, average log likelihood -1.371637
[ Info: iteration 8, average log likelihood -1.367182
[ Info: iteration 9, average log likelihood -1.363799
[ Info: iteration 10, average log likelihood -1.361734
[ Info: iteration 11, average log likelihood -1.360598
[ Info: iteration 12, average log likelihood -1.359950
[ Info: iteration 13, average log likelihood -1.359545
[ Info: iteration 14, average log likelihood -1.359265
[ Info: iteration 15, average log likelihood -1.359056
[ Info: iteration 16, average log likelihood -1.358879
[ Info: iteration 17, average log likelihood -1.358706
[ Info: iteration 18, average log likelihood -1.358519
[ Info: iteration 19, average log likelihood -1.358286
[ Info: iteration 20, average log likelihood -1.357990
[ Info: iteration 21, average log likelihood -1.357625
[ Info: iteration 22, average log likelihood -1.357209
[ Info: iteration 23, average log likelihood -1.356808
[ Info: iteration 24, average log likelihood -1.356460
[ Info: iteration 25, average log likelihood -1.356162
[ Info: iteration 26, average log likelihood -1.355906
[ Info: iteration 27, average log likelihood -1.355682
[ Info: iteration 28, average log likelihood -1.355477
[ Info: iteration 29, average log likelihood -1.355274
[ Info: iteration 30, average log likelihood -1.355061
[ Info: iteration 31, average log likelihood -1.354822
[ Info: iteration 32, average log likelihood -1.354551
[ Info: iteration 33, average log likelihood -1.354248
[ Info: iteration 34, average log likelihood -1.353928
[ Info: iteration 35, average log likelihood -1.353640
[ Info: iteration 36, average log likelihood -1.353430
[ Info: iteration 37, average log likelihood -1.353302
[ Info: iteration 38, average log likelihood -1.353230
[ Info: iteration 39, average log likelihood -1.353190
[ Info: iteration 40, average log likelihood -1.353168
[ Info: iteration 41, average log likelihood -1.353155
[ Info: iteration 42, average log likelihood -1.353146
[ Info: iteration 43, average log likelihood -1.353141
[ Info: iteration 44, average log likelihood -1.353137
[ Info: iteration 45, average log likelihood -1.353134
[ Info: iteration 46, average log likelihood -1.353132
[ Info: iteration 47, average log likelihood -1.353130
[ Info: iteration 48, average log likelihood -1.353129
[ Info: iteration 49, average log likelihood -1.353128
[ Info: iteration 50, average log likelihood -1.353127
┌ Info: EM with 100000 data points 50 iterations avll -1.353127
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4075957664784946
│     -1.4074808712060227
│      ⋮
└     -1.3531270826954578
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.353304
[ Info: iteration 2, average log likelihood -1.353128
[ Info: iteration 3, average log likelihood -1.352606
[ Info: iteration 4, average log likelihood -1.347994
[ Info: iteration 5, average log likelihood -1.331603
[ Info: iteration 6, average log likelihood -1.316493
[ Info: iteration 7, average log likelihood -1.310158
[ Info: iteration 8, average log likelihood -1.307132
[ Info: iteration 9, average log likelihood -1.305546
[ Info: iteration 10, average log likelihood -1.304309
[ Info: iteration 11, average log likelihood -1.303073
[ Info: iteration 12, average log likelihood -1.302246
[ Info: iteration 13, average log likelihood -1.301725
[ Info: iteration 14, average log likelihood -1.301345
[ Info: iteration 15, average log likelihood -1.301022
[ Info: iteration 16, average log likelihood -1.300719
[ Info: iteration 17, average log likelihood -1.300430
[ Info: iteration 18, average log likelihood -1.300171
[ Info: iteration 19, average log likelihood -1.299947
[ Info: iteration 20, average log likelihood -1.299756
[ Info: iteration 21, average log likelihood -1.299605
[ Info: iteration 22, average log likelihood -1.299496
[ Info: iteration 23, average log likelihood -1.299423
[ Info: iteration 24, average log likelihood -1.299376
[ Info: iteration 25, average log likelihood -1.299344
[ Info: iteration 26, average log likelihood -1.299319
[ Info: iteration 27, average log likelihood -1.299295
[ Info: iteration 28, average log likelihood -1.299269
[ Info: iteration 29, average log likelihood -1.299232
[ Info: iteration 30, average log likelihood -1.299175
[ Info: iteration 31, average log likelihood -1.299069
[ Info: iteration 32, average log likelihood -1.298849
[ Info: iteration 33, average log likelihood -1.298352
[ Info: iteration 34, average log likelihood -1.297228
[ Info: iteration 35, average log likelihood -1.295460
[ Info: iteration 36, average log likelihood -1.294107
[ Info: iteration 37, average log likelihood -1.293843
[ Info: iteration 38, average log likelihood -1.293807
[ Info: iteration 39, average log likelihood -1.293790
[ Info: iteration 40, average log likelihood -1.293768
[ Info: iteration 41, average log likelihood -1.293736
[ Info: iteration 42, average log likelihood -1.293688
[ Info: iteration 43, average log likelihood -1.293602
[ Info: iteration 44, average log likelihood -1.293463
[ Info: iteration 45, average log likelihood -1.293270
[ Info: iteration 46, average log likelihood -1.293012
[ Info: iteration 47, average log likelihood -1.292732
[ Info: iteration 48, average log likelihood -1.292516
[ Info: iteration 49, average log likelihood -1.292378
[ Info: iteration 50, average log likelihood -1.292293
┌ Info: EM with 100000 data points 50 iterations avll -1.292293
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3533039517084604
│     -1.3531284022768397
│      ⋮
└     -1.2922926378079098
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.292462
[ Info: iteration 2, average log likelihood -1.292130
[ Info: iteration 3, average log likelihood -1.291146
[ Info: iteration 4, average log likelihood -1.283283
[ Info: iteration 5, average log likelihood -1.260862
[ Info: iteration 6, average log likelihood -1.242726
[ Info: iteration 7, average log likelihood -1.235161
[ Info: iteration 8, average log likelihood -1.231010
[ Info: iteration 9, average log likelihood -1.226939
[ Info: iteration 10, average log likelihood -1.222211
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.218165
[ Info: iteration 12, average log likelihood -1.227197
[ Info: iteration 13, average log likelihood -1.221355
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.218061
[ Info: iteration 15, average log likelihood -1.231224
[ Info: iteration 16, average log likelihood -1.224612
[ Info: iteration 17, average log likelihood -1.221647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.220199
[ Info: iteration 19, average log likelihood -1.229663
[ Info: iteration 20, average log likelihood -1.224812
[ Info: iteration 21, average log likelihood -1.223476
[ Info: iteration 22, average log likelihood -1.221720
[ Info: iteration 23, average log likelihood -1.218543
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.214707
[ Info: iteration 25, average log likelihood -1.228811
[ Info: iteration 26, average log likelihood -1.222984
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.220354
[ Info: iteration 28, average log likelihood -1.228921
[ Info: iteration 29, average log likelihood -1.222815
[ Info: iteration 30, average log likelihood -1.220649
[ Info: iteration 31, average log likelihood -1.219818
[ Info: iteration 32, average log likelihood -1.219008
[ Info: iteration 33, average log likelihood -1.217947
[ Info: iteration 34, average log likelihood -1.215956
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.212368
[ Info: iteration 36, average log likelihood -1.224982
[ Info: iteration 37, average log likelihood -1.218995
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.216358
[ Info: iteration 39, average log likelihood -1.225237
[ Info: iteration 40, average log likelihood -1.219788
[ Info: iteration 41, average log likelihood -1.218295
[ Info: iteration 42, average log likelihood -1.217101
[ Info: iteration 43, average log likelihood -1.215387
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.212352
[ Info: iteration 45, average log likelihood -1.215453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.207904
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.220509
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.220159
[ Info: iteration 49, average log likelihood -1.223837
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.216779
┌ Info: EM with 100000 data points 50 iterations avll -1.216779
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2924616879066733
│     -1.2921302714647336
│      ⋮
└     -1.2167786654353085
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.221892
[ Info: iteration 2, average log likelihood -1.216660
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.211974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.197669
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.153209
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.130453
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.131031
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.109888
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.133192
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.116526
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.113185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.112023
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.106743
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.120124
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.120581
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     13
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.104979
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.118507
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.099479
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.127311
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.113643
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.111852
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.111329
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.106483
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.120047
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     13
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.104937
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.118477
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.099454
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.127297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.113632
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111843
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.111322
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.106476
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.120044
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.120537
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     13
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.104936
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.118474
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099453
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.127294
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.113630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.111840
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.111320
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.106474
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.120042
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.120535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     13
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.104934
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.118472
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.099451
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.127292
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.113628
┌ Info: EM with 100000 data points 50 iterations avll -1.113628
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2218922823923277
│     -1.216660140125338
│      ⋮
└     -1.1136282759381837
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4412564274337407
│     -1.441313425360355
│     -1.4412558073399613
│     -1.4409226865620557
│      ⋮
│     -1.099451130227521
│     -1.1272916497054346
└     -1.1136282759381837
32×26 Array{Float64,2}:
  0.123062    -0.00666257   0.0802179    0.076693     -0.097459      0.0372715    -0.065009    -0.0937989    0.158156    0.0052707   -0.200171    -0.0277307   0.0413699   -0.0530152   -0.00389268    0.13713     -0.0513469  -0.0941789   -0.179463    -0.0225142    -0.155997    0.266099     0.150434   -1.66721      -0.229004     0.028676
  0.191059     0.0862563   -0.0309442    0.0424903     0.0204427     0.0340059    -0.0207013   -0.0952169    0.0457116   0.0110932   -0.0795748   -0.0216071   0.0232575    0.125567     0.000827529   0.159024    -0.0805786  -0.0509499   -0.046086    -0.0508042     0.0585246   0.240096     0.145981    0.372966     -0.0957667   -0.0803264
  0.233812    -0.147557     0.0498435   -0.00993925   -0.0469347     0.0200447     0.00615888  -0.0614871   -0.16081     0.00740898  -0.070812    -0.158018    0.128493    -0.142021     0.00525375   -0.0451803   -0.02532    -0.00908508   0.125795    -0.106761     -0.0874167   0.207394     0.13323    -0.0972418    -0.15997      0.0255263
  0.125286    -0.0977189    0.0335197   -0.0121923     0.0453483     0.0131157    -0.07705     -0.108285    -0.174396    0.0130087   -0.27474     -0.0618048   0.0200923   -0.0643708   -0.00844847    0.0426359   -0.0194238  -0.109813    -0.089887     0.0245782    -0.105503    0.229705     0.14754     1.28631      -0.463596    -0.0690975
 -0.144622    -0.0567538    0.025436     0.1807       -0.120764      0.0713536     0.0260226   -0.121476     0.0257542  -0.0240164    0.174625    -0.0509557  -0.239191    -0.0131561   -0.995742      0.0380137   -0.0450307  -0.0500842    0.0473017    0.317934      0.0839155   0.0364409   -0.0289819  -0.064907     -0.171094    -0.0996641
 -0.137602     0.173008     0.0596069    0.183441      0.187992     -0.0631742     0.0148775   -0.0925722   -0.0637813   0.0308475    0.12112     -0.025682   -0.262471    -0.116059     0.897617      0.0211561   -0.105171   -0.00646843   0.194902    -0.211089      0.095653    0.0417835   -0.0373152  -0.0596031    -0.0528766   -0.107755
  0.0276893    0.00267774   0.157543    -0.0593251     8.70435e-5   -0.00162333    0.12231     -0.0399976   -0.0460205  -0.067102     0.0358571    0.0370652  -0.0635285    0.113231    -0.0226266    -0.105218    -0.0241916  -0.108332    -0.0768171    0.0724756    -0.0183134  -0.0265368    0.190085   -0.0615149    -0.0980668   -0.0618248
 -0.0785012    0.0430794   -0.0261304   -0.0603804    -0.0145673     0.0703291    -0.0355503    0.0371747    0.123417    0.104354    -0.0595727   -0.0178228   0.054726    -0.0968618    0.0127012     0.00142763  -0.060498   -0.0992272   -0.0867628    0.186969      0.0296743   0.0639737    0.159137   -0.000462024  -0.0382243   -0.0480681
 -0.0600177   -0.149263     0.181429    -0.0401877     0.119814     -0.0436143    -0.069999    -0.0133712    4.6317e-5   0.191216    -0.119854     0.105369    0.0403696   -0.211633    -0.0619253     0.0246947    0.0308867  -0.0109679   -0.112572    -0.000442971   0.0363219  -0.200307     0.0992025  -0.0907389    -0.253753     0.0929644
  0.103248    -0.0116672   -0.002308    -0.196967     -0.0691946    -0.249689     -0.0326903    0.0214964   -0.179833    0.162992     0.0273496   -0.0489643   0.0666624    0.0579789    0.101639      0.0297107    0.179712    0.129687    -0.103516     0.129203      0.0196148  -0.0808589    0.0793907   0.168694      0.115005    -0.108702
  0.260014     0.0784049    0.0293355    0.080459      0.0529538    -0.10783      -0.10195     -0.0146415   -0.0346194   0.0600612   -0.193684    -0.233927    0.00450531   0.137115    -0.0736891    -0.113954    -0.04989     0.117062     0.0511331   -0.00761651   -0.0479586   0.121155     0.0170838   0.0453344    -0.114234    -0.0054344
  0.014391    -0.0407319   -0.0768162    0.206501      0.0164833    -0.103693      0.0277147    0.196391    -0.19065    -0.114615     0.035224    -0.172529    0.0597311    0.0512849   -0.0578199     0.00451008   0.120382    0.0156886    0.00460845  -0.0108011    -0.152472    0.0488668   -0.0996839  -0.0794335     0.0469611   -0.0185712
 -0.0308121    0.293411     0.0133395    0.0440249    -0.116788      0.00741176   -0.0398938    0.0680791    0.0533181   0.185706    -0.00744973   0.108049   -0.165142    -0.0461487   -0.0998645    -0.0807535    0.0039032   0.0206667   -0.0715448    0.24452      -0.101787    0.215666    -0.0244204   0.102235     -0.0163565    0.139982
  0.0579112    0.0941022   -0.0707806    0.040367     -0.0719324    -0.0502638     0.0731124    0.215442     0.0170934   0.0376338    0.0490561    0.0057749  -0.147444    -0.0523571    0.0313878     0.0248372   -0.0174941  -0.149615    -0.132251    -0.320396      0.0885794  -0.00580391   0.110824    0.0489967     0.16502     -0.0784959
  0.0240595    0.0554904    0.14354      0.0241582    -0.0185351    -0.0164451     0.0150629    0.0198949   -0.050977    0.0803369    0.108599     0.0697273   0.0921378   -0.0100288   -0.20162      -0.123337    -0.0757709  -0.0137729   -0.0156726   -0.0363477     0.0895563   0.0972342   -0.0171822   0.116113      0.0462298    0.0899799
  0.0769042    0.0816258   -0.0874467    0.138592      0.116069     -0.0820848    -0.00613432  -0.0487927   -0.0776703  -0.0387074    0.0522554   -0.0675414  -0.189522     0.148041     0.0872788    -0.0428455   -0.0121919   0.00862854   0.10467     -0.0736949     0.0267983  -0.0518053    0.0370432   0.145574     -0.23689     -0.00784156
  0.0791063    0.0131653   -0.129044    -0.182486      0.071113     -0.000393701  -0.0869221    0.0799211   -0.0180079  -0.172885     0.0527641   -0.179871    0.126053    -0.00930961   0.00162367   -0.113598     0.201698    0.00466567  -0.0558638    0.180978      0.126599   -0.0420758   -0.056801   -0.101445     -0.233202    -0.0314088
  0.0683601   -0.115613     0.120073     0.0937038     0.00592989   -0.171031      0.0819205   -0.201912    -0.0403349  -0.0207519   -0.00109058  -0.186958   -0.023257    -0.0997009    0.100409     -0.0866377    0.0558136  -0.107836     0.0459071    0.0426896    -0.241685   -0.0256703    0.0107928   0.0592855     0.10777     -0.0658121
  0.00377905  -0.11325     -0.0277158   -0.000700007  -0.064896      0.0249913    -0.0610573    0.00743808  -0.0420258  -0.24228      0.0278359    0.0967056  -0.0676204    0.0322955   -0.0351091     0.0475308   -0.13549     0.152888     0.0306621   -0.0139372    -0.052751   -0.270088    -0.0587755   0.116931      0.0199449   -0.0128109
  0.0325417    0.044996     0.0419028   -0.0810288     0.0508372    -0.0229531     0.00765566  -0.0573519   -0.0328366  -0.0957924    0.0513312    0.12913     0.0487642    0.137065    -0.0706756    -0.0141477    0.0653039  -0.0885278    0.0119368    0.0945618     0.107363    0.0216321    0.132166   -0.0372943     0.173492     0.0630904
  0.0114803   -0.0864676   -0.121415     0.00577298    0.0727581    -0.170045      0.0705367    0.0803379   -0.0278375   0.0149139    0.149327     0.0422923   0.0185463   -0.16818      0.105315      0.0224217    0.0498383  -0.075835    -0.0380951   -0.0181109    -0.106621    0.11943     -0.192669    0.0871748     0.0565302   -0.0262312
 -0.110376    -0.0350471   -0.0709784    0.0660764    -0.000732358   0.0849668     0.0449203    0.012432     0.0238609   0.115395     0.128506     0.0423896  -0.0284222    0.0260723    0.0421653     0.100938     0.0497759  -0.0726482    0.0556609    0.0963611     0.0597145  -0.148401     0.0962504  -0.0674537    -0.0731731   -0.140733
  0.0489659    0.00707707  -0.0135344   -0.00488784   -0.0385138     0.0140061     0.0290131    0.0998622    0.0847001   0.0406669   -0.0773706   -0.0384758   0.00323158   0.100075    -0.0474559    -0.0727905    0.0238315  -0.04121      0.143267     0.0875491     0.120413    0.0767423    0.14144     0.0972592    -0.0475695   -0.114024
 -0.074273    -0.0281281    0.108439    -0.0467407     0.069805     -0.0627765    -0.109649     0.16982      0.0262683  -0.0644128    0.133579    -0.115038   -0.0079496    0.0189978   -0.121819      0.094496     0.0867297   0.04296     -0.00482223   0.00383006   -0.127647   -0.00589185   0.207983    0.0943845    -0.0465284    0.184564
  0.0835845   -0.0559601    0.0708361   -0.0662977     0.151762      0.00720997    0.00535199  -0.0013372    0.0983112   0.0260844    0.0261658    0.0813865  -0.0443359   -0.00832456   0.0351727     0.0570966   -0.0619238  -0.124965     0.0115788    0.0470874     0.0152324   0.0935814    0.0182215  -0.0883047     0.0626563   -0.046381
 -0.128098     0.103083     0.159532     0.0813237    -0.141515     -0.15174      -0.168267     0.134438     0.0798389  -0.00976279   0.185418     0.0426061   0.162913     0.17438     -0.0675052     0.0705165    0.0442212   0.017316     0.0043271   -0.00420845   -0.0296815   0.0875846    0.0624424   0.0344731     0.081543    -0.0911469
 -0.0037128   -0.0385141   -0.0621636   -0.074152     -0.0320981     0.00297416    0.0542064   -0.0857425    0.0171419   0.0814395   -0.095253     0.130069    0.0293305   -0.0486102   -0.0139443     0.0867366   -0.0834374  -0.0573054    0.0170425   -0.21573      -0.0207301  -0.0323448    0.0103502  -0.105385     -0.039563     0.200687
 -0.0916702   -0.00887515   0.0290687    0.0548116    -0.0311209     0.0687308     0.0356531    0.017784    -0.0492837  -0.0658023   -0.0905799    0.0213012  -0.0574904   -0.0646548    0.071809      0.0616064    0.051244    0.118722     0.0726449    0.0118686    -0.0263145   0.0829355   -0.0138859  -0.0578777     0.0301672    0.0326144
 -0.314778    -0.0377136    0.11432      0.0616263     0.0858347     0.0796949    -0.0267212   -0.102106    -0.132232    0.0199303    0.0881929   -0.08627    -0.126578     0.131408    -0.1916        0.173952     0.228571   -0.0309917   -0.0108919    0.0829815    -0.0826438  -0.136977     0.0278616  -0.0342344     0.00256991   0.0138166
  0.617764    -0.0375068    0.124745    -0.0940726    -0.0475042     0.0897397     0.127965    -0.0734457   -0.194646    0.24519      0.0643171   -0.0221821  -0.11752      0.0957499   -0.0586946     0.32959      0.136165   -0.0325774    0.00753134   0.0790714    -0.0879351  -0.147958    -0.0791651  -0.0260509    -0.0416148   -0.0342037
 -0.00415886  -0.102831    -0.00857038   0.0505137     0.159481      0.0362985    -0.0302658   -0.0637327   -0.0297039  -1.25811     -0.217022    -0.125526    0.0538927   -0.0783658   -0.0773929    -0.0406215   -0.143318    0.00606367   0.0452802    0.0889929    -0.0117206   0.110928     0.101923   -0.0520543    -0.113069     0.0211363
 -0.00385206  -0.116375    -0.00875045   0.0311382     0.114881     -0.0709811     0.0112657   -0.0602069   -0.113258    1.25351     -0.218081     0.122043   -0.151426     0.0648761    0.0136413    -0.206549    -0.163959    0.0625593    0.0370917    0.0896785     0.0298111   0.0881295    0.131966   -0.048143     -0.115066     0.0586558[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.111839
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.087363
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.106022
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.090996
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.107924
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.085542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     14
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.111638
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087398
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.106133
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     13
│     14
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090995
┌ Info: EM with 100000 data points 10 iterations avll -1.090995
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.806100e+05
      1       7.246963e+05      -2.559137e+05 |       32
      2       6.998801e+05      -2.481615e+04 |       32
      3       6.836759e+05      -1.620417e+04 |       32
      4       6.712665e+05      -1.240943e+04 |       32
      5       6.628553e+05      -8.411189e+03 |       32
      6       6.577874e+05      -5.067897e+03 |       32
      7       6.548871e+05      -2.900362e+03 |       32
      8       6.532358e+05      -1.651295e+03 |       32
      9       6.522527e+05      -9.830564e+02 |       32
     10       6.514821e+05      -7.705624e+02 |       32
     11       6.506294e+05      -8.527842e+02 |       32
     12       6.496725e+05      -9.568247e+02 |       32
     13       6.487683e+05      -9.042399e+02 |       32
     14       6.480797e+05      -6.886329e+02 |       32
     15       6.475705e+05      -5.091368e+02 |       32
     16       6.471492e+05      -4.213612e+02 |       32
     17       6.467991e+05      -3.500674e+02 |       32
     18       6.465686e+05      -2.305247e+02 |       32
     19       6.464345e+05      -1.340724e+02 |       31
     20       6.463465e+05      -8.803476e+01 |       32
     21       6.462839e+05      -6.258636e+01 |       30
     22       6.462392e+05      -4.466021e+01 |       32
     23       6.462125e+05      -2.669842e+01 |       31
     24       6.461896e+05      -2.287201e+01 |       30
     25       6.461688e+05      -2.080783e+01 |       31
     26       6.461492e+05      -1.966549e+01 |       30
     27       6.461361e+05      -1.308091e+01 |       31
     28       6.461254e+05      -1.066329e+01 |       30
     29       6.461178e+05      -7.661047e+00 |       30
     30       6.461129e+05      -4.831979e+00 |       25
     31       6.461104e+05      -2.578987e+00 |       23
     32       6.461085e+05      -1.837201e+00 |       21
     33       6.461067e+05      -1.840872e+00 |       17
     34       6.461052e+05      -1.439666e+00 |       17
     35       6.461041e+05      -1.097763e+00 |       10
     36       6.461038e+05      -3.742248e-01 |       12
     37       6.461034e+05      -3.979271e-01 |        9
     38       6.461031e+05      -2.305568e-01 |        6
     39       6.461030e+05      -1.454508e-01 |        6
     40       6.461029e+05      -7.728441e-02 |        5
     41       6.461028e+05      -1.439689e-01 |        3
     42       6.461027e+05      -1.231607e-01 |        2
     43       6.461026e+05      -3.185809e-02 |        2
     44       6.461026e+05      -1.615481e-02 |        4
     45       6.461025e+05      -1.041890e-01 |        3
     46       6.461024e+05      -8.421206e-02 |        5
     47       6.461023e+05      -1.480254e-01 |        2
     48       6.461022e+05      -5.102452e-02 |        2
     49       6.461022e+05      -4.723491e-02 |        2
     50       6.461021e+05      -1.807365e-02 |        2
K-means terminated without convergence after 50 iterations (objv = 646102.1498705612)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.361137
[ Info: iteration 2, average log likelihood -1.328740
[ Info: iteration 3, average log likelihood -1.295057
[ Info: iteration 4, average log likelihood -1.256486
[ Info: iteration 5, average log likelihood -1.214174
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.169517
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.145565
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.149396
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.135770
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.125549
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.121874
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.128885
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.121831
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091289
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     10
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.120742
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.118002
[ Info: iteration 17, average log likelihood -1.124769
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      5
│     12
│     13
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.068829
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.144012
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.107241
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.101731
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.095164
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.117954
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102783
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.101883
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     10
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.100173
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.122750
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.103756
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     10
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.089779
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     14
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.116025
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.124219
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.100896
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     13
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.087418
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     20
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.113803
[ Info: iteration 35, average log likelihood -1.135885
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081824
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     13
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.102845
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.120109
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.120023
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.070202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     13
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.100334
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.134288
[ Info: iteration 43, average log likelihood -1.109599
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│     12
│     14
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.057823
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.122985
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.129825
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.099250
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051193
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.129573
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.113402
┌ Info: EM with 100000 data points 50 iterations avll -1.113402
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.104637     -0.0150998   -0.00423904  -0.183533     -0.0565416   -0.253734     -0.0329488    0.0185736   -0.182604     0.158074      0.031358     -0.0471421    0.0651252    0.0528479   0.0999777   0.0264697     0.181997     0.123289    -0.0980229    0.123441     0.0214262  -0.0776668    0.0790997     0.168153     0.108804    -0.107447
  0.0294009    -0.00165792   0.161768    -0.0493622    -0.0130113    0.0105972     0.164849    -0.0679335   -0.057622    -0.0608436     0.0448273     0.0541616   -0.0796822    0.118983   -0.0193902  -0.104534     -0.0418686   -0.10422     -0.0758714    0.0619685   -0.0313445  -0.0362114    0.19516      -0.0639032   -0.0863915   -0.0671928
  0.0548706     0.233394     0.0289817   -0.00367773    0.158616     0.046579     -0.804286     0.0690071    0.0568078    0.0804484    -0.013157      0.121837    -0.089519    -0.0578049  -0.0584126   0.241911     -0.0171843    0.0218773   -0.00502568   0.081051     0.120747    0.171292    -0.0161168    -0.0548098   -0.113728    -0.0704051
 -0.0237691     0.288445     0.00312631   0.044184     -0.160298    -0.000554347   0.0157105    0.0725335    0.0502495    0.203786     -0.00712591    0.105225    -0.167001    -0.0527932  -0.111627   -0.133673     -0.00630269   0.00822971  -0.0709829    0.309414    -0.12708     0.242781    -0.0178974     0.125917    -0.00168986   0.179431
  0.102016     -0.0856865    0.0763768    0.00688758   -0.0233491   -0.129904      0.057872     0.0965171    0.0036314    0.041946      0.000697283   0.147955    -0.16199     -0.0647517   0.0955289   0.0197191     0.00395381  -0.130515     0.256993     0.0141136    0.149619    0.121313     0.065104     -0.0791693   -0.0910576   -0.0873573
  0.00302489   -0.0317557    0.00547442  -0.0574238    -0.07361     -0.0352015     0.0634247   -0.110367     0.091003     0.113528     -0.13148       0.00890593   0.0510689    0.0451092   0.0721675   0.159531     -0.145076    -0.142568     0.00145249  -0.222934     0.0677235   0.0122838    0.000458816   0.0409547   -0.0876714    0.155215
 -0.0449581    -0.0642805   -0.0984866    0.0336544     0.0415009   -0.042389      0.0626901    0.045958     0.0010485    0.058141      0.134549      0.0464668   -0.00388455  -0.0671101   0.0725019   0.0578363     0.0515091   -0.0776162    0.0113422    0.0432364   -0.0188508  -0.0146578   -0.0531756     0.00956377  -0.0121203   -0.0823465
  0.0749887     0.100609    -0.232327    -0.00312462   -0.119625     0.164938      0.0364557    0.107706     0.208129    -0.0351912    -0.0324191     0.540621     0.034656     0.194932   -0.108804   -0.0171712     0.234053    -0.128775     0.177011     0.0567929    0.145617    0.325503     0.168516      0.17989     -0.0377458   -0.0359784
 -0.128465      0.10312      0.161445     0.0808204    -0.14198     -0.151649     -0.169432     0.134812     0.0808374   -0.0116454     0.18637       0.0447796    0.162856     0.175338   -0.068158    0.069469      0.043499     0.0165816    0.00488506  -0.00396765  -0.0300051   0.0890359    0.0625546     0.0344432    0.0813409   -0.0900275
  0.0492431    -0.00312527  -0.158044    -0.19016       0.0754665    0.0145559    -0.0821354    0.0977127    0.0234356   -0.189455      0.0405501    -0.199871     0.107492     0.0187286  -0.0298701  -0.104587      0.247099    -0.0148183   -0.0328233    0.239363     0.152124   -0.0689615   -0.0396584    -0.0742468   -0.238807    -0.0192241
  0.0148607    -0.0414524   -0.0765826    0.204073      0.0191895   -0.102189      0.027611     0.195854    -0.19349     -0.113195      0.0374485    -0.17937      0.060917     0.0539444  -0.0602489  -0.000229927   0.124372     0.0152097    0.00184497  -0.0141398   -0.15357     0.051713    -0.104179     -0.0792474    0.049688    -0.0192004
  0.0664296    -0.0228699    0.0745128   -0.129225      0.281026     0.120084     -0.0432118   -0.0865909    0.175851     0.015056      0.0426228     0.0145145    0.0530685    0.0468275  -0.0205668   0.0818933    -0.102884    -0.12797     -0.221627     0.0738546   -0.109395    0.069352    -0.0180667    -0.0913277    0.197526    -0.0031216
  0.0734547    -0.0791235    0.0621953    0.0497846    -0.0135195   -0.159265      0.0652622   -0.10067      0.027179    -0.0185958    -0.00480605   -0.162176     0.00431368  -0.063458    0.0302866  -0.0696759     0.0924469   -0.0966222    0.0769829    0.0213313   -0.180071   -0.00694884   0.0518679     0.074171     0.0521909   -0.0459968
  0.00251964   -0.0834746    0.110937    -0.0062258     0.130249     0.0679541    -0.00857138  -0.0280994    0.0521221    0.0848715    -0.0391268     0.0930399   -0.0194225   -0.1136     -0.0698802   0.0131646     0.0259764   -0.015484    -0.0796265    0.0334935    0.0137768   0.0143642    0.0406341    -0.0364547   -0.132984     0.0492709
  0.0319196     0.0562478    0.136768     0.0128909    -0.0206695   -0.0142414     0.0188037    0.0302211   -0.0514506    0.0800497     0.109893      0.0718098    0.0848888   -0.010436   -0.205685   -0.125116     -0.0645994   -0.0204537   -0.0197674   -0.0395145    0.0870653   0.0970669   -0.0143617     0.118693     0.0529462    0.0915327
  0.0750458     0.0824157   -0.084495     0.141089      0.117168    -0.0883795    -0.0051245   -0.0464347   -0.0804235   -0.0381712     0.0555667    -0.0744482   -0.189061     0.153902    0.0861957  -0.0450931    -0.0114835    0.00815545   0.109797    -0.0769079    0.0268543  -0.0559897    0.04305       0.146356    -0.237084    -0.00716403
  0.066864      0.106048    -0.0641865    0.0372769    -0.0797149   -0.0491097     0.0798279    0.210379     0.0240674    0.0216032     0.0549683     0.0123772   -0.143254    -0.0428414   0.0405509   0.0224446    -0.0455669   -0.137302    -0.138873    -0.404139     0.103874   -0.00938635   0.106433      0.0489235    0.151175    -0.0769218
 -0.0535511    -0.00771767   0.00784464  -0.0658191    -0.0593839    0.0398133     0.0963524   -0.0312749    0.0109875    0.0111743    -0.103568      0.204334    -0.0282906   -0.0269398  -0.0207506   0.068772      0.0495582    0.0926107   -0.00529496  -0.16918     -0.069235   -0.00843346   0.0837627    -0.152797     0.0576889    0.176187
 -0.0671868     0.0360569   -0.00590162  -0.0580555    -0.0113515    0.0589246    -0.03071      0.0384078    0.108909     0.0854908    -0.0482616    -0.0104907    0.0502147   -0.0794194   0.0116516  -0.00872807   -0.0577916   -0.0993051   -0.0885903    0.176629     0.02806     0.0543071    0.160605     -0.0027374   -0.0301374   -0.0449223
  0.0898786     0.0522771    0.145608    -0.11874       0.0837948    0.0904771     0.0602315   -0.0178456   -0.0996311   -0.206432      0.068699      0.140269     0.0303199    0.128322   -0.0836813   0.0909823     0.168069    -0.136317    -0.0585277    0.0978868    0.115035    0.0670071    0.178081     -0.122365     0.115356     0.0433388
  0.171327     -0.0429723    0.0304386    0.0221149    -0.0179446    0.0256797    -0.0368044   -0.0885139   -0.0417815    0.0092498    -0.153003     -0.0701333    0.0550008   -0.0335658  -0.001129    0.0697531    -0.0440311   -0.0637776   -0.0399083   -0.0410746   -0.0675156   0.234373     0.143901      0.0225085   -0.231977    -0.0241575
  0.0398266    -0.0292077    0.122264     0.00245583    0.0472898    0.101236      0.0343168   -0.0936322   -0.156183     0.111606      0.0805725    -0.0649759   -0.10993      0.119006   -0.159345    0.241162      0.181557    -0.030912    -0.0169199    0.0842067   -0.103325   -0.157734    -0.014094     -0.0185019   -0.00452037  -0.00265998
 -0.141995      0.0559552    0.0414127    0.181945      0.0290269    0.00329203    0.0191044   -0.10625     -0.0182637    0.00352342    0.14703      -0.037873    -0.249293    -0.0629787  -0.0673392   0.0294688    -0.0728536   -0.0295087    0.118811     0.0602038    0.0887099   0.039027    -0.0327273    -0.0617291   -0.114957    -0.103373
  0.000594015  -0.111619    -0.025859     0.000110172  -0.0608434    0.0240628    -0.0584329    0.00906879  -0.0508471   -0.23661       0.028232      0.095402    -0.0674971    0.0326185  -0.0361444   0.0460065    -0.13078      0.152367     0.0322267   -0.0142425   -0.0513302  -0.273159    -0.0661613     0.117335     0.0185536   -0.0138351
  0.0247358    -0.00888166   0.12979     -0.0158743    -0.0232506   -0.00592289    0.00807544   0.0953507   -0.00975299   0.112432     -0.121152     -0.294437    -0.0245698    0.107846    0.0204151  -0.129461     -0.128006     0.0278651    0.0896867    0.12127      0.161449   -0.0380886    0.140477      0.0165805   -0.0730746   -0.196851
 -0.0139772     0.0385363   -0.0549223   -0.0547912     0.0151601   -0.142025     -0.053005    -0.0947195    0.0453057    0.013929      0.038953      0.122204     0.0670268    0.149023   -0.0586319  -0.1162       -0.0321422   -0.0482678    0.0791368    0.0923451    0.108245   -0.0264797    0.110373      0.0523169    0.237616     0.0789549
 -0.00400266   -0.109642    -0.00876019   0.0404169     0.136115    -0.0194113    -0.00849832  -0.0611975   -0.0728951    0.0408991    -0.217598      0.0024432   -0.0526008   -0.0048262  -0.0303545  -0.125939     -0.153941     0.0356531    0.0417201    0.0895938    0.0101007   0.0993424    0.117613     -0.049303    -0.114367     0.040905
 -0.0739701    -0.0288491    0.106949    -0.0464707     0.0697802   -0.0634541    -0.108554     0.169492     0.0279836   -0.0636125     0.133276     -0.11454     -0.00807269   0.017027   -0.120053    0.0944357     0.086233     0.0430203   -0.00589762   0.0040198   -0.128977   -0.00427619   0.204773      0.0944783   -0.0472271    0.18459
 -0.060131     -0.150046     0.18259     -0.0410775     0.119253    -0.0437577    -0.0698363   -0.0141246    0.00253096   0.192591     -0.120462      0.106293     0.041615    -0.210361   -0.0600879   0.0246912     0.0321658   -0.0115524   -0.113703    -0.00068969   0.0363716  -0.200829     0.0997887    -0.0912423   -0.255804     0.0923149
  0.0970557    -0.061961    -0.0110284    0.0362778    -0.00695517   0.0408098    -0.214039     0.0599488   -0.237521    -0.143937     -0.0838157    -0.120758     0.0159236   -0.205225    0.138285   -0.0506771    -0.0604041    0.0573968    0.0846733    0.103344    -0.0648341   0.178995    -0.123378     -0.114127     0.0355974   -0.0716882
  0.259449      0.0786312    0.0243725    0.0810916     0.0531738   -0.107658     -0.101889    -0.0147741   -0.0354642    0.0597118    -0.195327     -0.234364     0.00663614   0.13897    -0.0754719  -0.117031     -0.048578     0.119094     0.0522477   -0.00721559  -0.0472692   0.121184     0.0146664     0.0464063   -0.11721     -0.00739611
 -0.293738      0.0257666   -0.0748078    0.199987      0.0563928    0.113488      0.209543    -0.030867    -0.00154931  -0.000634221  -0.0355757     0.0415143   -0.141391    -0.0775039   0.0172955   0.131385      0.0783021    0.146853     0.213031     0.0863883    0.0122609   0.015612    -0.0705775    -0.00218726  -0.0508895    0.044886[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.106938
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.052217
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      8
│      ⋮
│     20
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.060853
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.093220
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     12
│     17
│     22
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.062350
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     20
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.053160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.089679
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     12
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.063262
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      5
│      8
│      ⋮
│     20
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051526
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.103497
┌ Info: EM with 100000 data points 10 iterations avll -1.103497
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0203265    0.0328625   -0.18532     -0.0973803    0.00573806    0.0663109   -0.0677443  -0.172531     0.120005     -0.12846      0.016677      0.185677    -0.0741581    -0.122991    -0.0209576    0.0885219   -0.0215393    0.0812035  -0.0700577    0.0820471    0.0977345   -0.0618815    0.0716295    0.0859308    0.17664     -0.119765
  0.144664    -0.0728318    0.196381     0.0800192    0.000348941  -0.100638     0.0821035   0.098498    -0.0308358     0.0430042    0.101355     -0.0824747    0.0291606     0.0850165    0.0128677   -0.160695     0.0632731    0.217447   -0.0550155    0.102916    -0.119734    -0.0630555    0.189652    -0.134413    -0.0486702    0.16095
  0.110242    -0.123857    -0.00254172  -0.00405868  -0.0186697    -0.00461266  -0.076705    0.0410966   -0.000779189   0.0206257    0.0647409    -0.0724207    0.0481174     0.0511138   -0.0358789   -0.0811761    0.129375    -0.0924597   0.0334942    0.0412226    0.0154819   -0.0652503   -0.00913018   0.0330582   -0.00170459  -0.0796172
  0.074956    -0.161795    -0.138112    -0.0133156   -0.129719     -0.201052     0.0292486  -0.0293447   -0.112923     -0.0646472   -0.00285374   -0.131275     0.0528293     0.0740507    0.112683    -0.0517584   -0.103327    -0.22601    -0.033311    -0.0237226    0.0231463   -0.152315     0.0496902   -0.073178     0.0356483    0.0792975
  0.0515261   -0.0570424    0.103703     0.0688495   -0.113545     -0.037207     0.0301198  -0.120042    -0.000298279  -0.230891    -0.110836      0.0340497    0.0314836    -0.115643     0.00162818   0.0833572    0.0474631   -0.0466955  -0.0263053   -0.166138    -0.0277715    0.113725    -0.0831575   -0.102797     0.0821427   -0.0154256
 -0.0346372    0.0251933   -0.093968     0.101018     0.0884612     0.00312458   0.0382045   0.0387276    0.0690127     0.222622     0.316869     -0.103944    -0.0917393    -0.0224511   -0.112007     0.180111     0.103327    -0.160945   -0.0126062    0.067171    -0.112182    -0.125405     0.0541164   -0.0879654   -0.12289     -0.0396364
  0.0950429   -0.0466953    0.0365133    0.0835481    0.0606112     0.109131     0.0515489  -0.075162    -0.0569365     0.0413901   -0.0230152    -0.0635192   -0.103391     -0.0146922   -0.0993954   -0.154011    -0.0736726    0.203163    0.0778713    0.0211806   -0.0123436   -0.0914851   -0.0117603    0.073386     0.0328791   -0.0182838
  0.0876422    0.00358713  -0.0203336   -0.0593562   -0.167145     -0.0236441   -0.338516   -0.0413561    0.0650591     0.0587476   -0.0596443    -0.0756389    0.0575584    -0.0206961   -0.127184     0.156368    -0.0511826   -0.108267   -0.0540714   -0.106543    -0.138153     0.0407798    0.130847    -0.0967879   -0.0360457    0.0766938
  0.0243332   -0.0410511   -0.0301536   -0.0562048    0.0930254     0.165467     0.102125   -0.135911    -0.00434355   -0.113702     0.00173135    0.0442204    0.0909325     0.109996     0.0730161   -0.0431936    0.15551     -0.0661104   0.0336753   -0.137517     0.202266     0.244894    -0.067401    -0.111342     0.248538    -0.0938821
 -0.0941421   -0.0329834    0.0869687    0.176885    -0.0235854    -0.0712018   -0.0129533  -0.0937691    0.0545001     0.0813007    0.045603     -0.100633    -0.0220352    -0.0490972    0.279793    -0.141574     0.0114976    0.0989105  -0.0804491    0.074653    -0.132044    -0.0401065    0.0646235    0.0467572    0.0256981   -0.00126815
  0.012867     0.150244     0.078915     0.0704202    0.039614      0.0119607   -0.15988     0.0471845    0.0548703     0.132621     0.0263116    -0.0295999   -0.0153696    -0.116901    -0.0863454    0.240722    -0.157282    -0.0605861   0.0657144    0.0921818   -0.184309     0.0558958   -0.0157608    0.0240852    0.0245725    0.0117379
 -0.0315021    0.0989781   -0.0697161    0.0297161    0.0489616    -0.0556548    0.0680585   0.0465421    0.0743601     0.00986355   0.0103747     0.0503624    0.0720809     0.0346184   -0.172693    -0.00719022   0.0382778   -0.0171504   0.168275    -0.126761     0.00309235  -0.0913525   -0.202294     0.0509469    0.210341    -0.0280956
 -0.0170576    0.0959342   -0.0243847    0.0156773   -0.00889277   -0.0934233    0.0130728   0.0885765    0.053216      0.00966853  -0.10748      -0.0339275    0.175776      0.0856287   -0.115921     0.0364908   -0.00516032   0.0112188  -0.0038032    0.182664    -0.186636     0.110679     0.0256451   -0.0953678    0.0227972    0.0833076
 -0.138436    -0.075884    -0.0159413    0.0929664    0.00983372   -0.00353335   0.0522098   0.0772236    0.0825793     0.0487899   -0.0946878     0.135459     0.128724     -0.112677     0.0197979   -0.00343843  -0.127651     0.131005    0.0768202   -0.0040609    0.0870885    0.0879257    0.00476394  -0.133279    -0.0475481   -0.103038
  0.0501944   -0.0755999    0.0331869   -0.052555     0.0322764     0.13435     -0.209958   -0.0128026    0.112712     -0.0259352    0.107261     -0.0653157    0.0195651    -0.125093    -0.0409058    0.0715556   -0.151249     0.031316   -0.168491     0.125476    -0.0677875   -0.0604865    0.0252815   -0.245948    -0.00878261  -0.0755048
 -0.105595     0.127568     0.0694567    0.0576135    0.151434      0.108071    -0.0669386   0.0628245   -0.179221      0.0755268    0.000840302   0.0603405    0.00351293   -0.101289     0.0821455   -0.0879709    0.0260329   -0.0327637  -0.0656491   -0.0119696   -0.165785     0.127197    -0.0777927    0.00663513  -0.0227688   -0.00273686
  0.0329585   -0.0483267    0.227789     0.0434104    0.0475539    -0.0828545    0.0291608   0.0429887   -0.124493     -0.0335972   -0.0276794    -0.0479281   -0.0653015    -0.0259975    0.053138    -0.0640155   -0.079188    -0.0664531   0.141706    -0.0720073    0.00625025   0.00953749   0.134426    -0.0207248   -0.00469011   0.000606968
  0.068978     0.124253     0.0381743   -0.0757461    0.076759     -0.13198      0.0224164   0.0331681    0.10705      -0.0316773    0.0180714    -0.0931062    0.0464793     0.28241      0.0622389    0.0179012   -0.246554    -0.0364422   0.0289084    0.0101692    0.0980432    0.105618    -0.0588112    0.0125772   -0.0315311    0.0833133
  0.112368    -0.116012    -0.00197941  -0.0407724    0.198285      0.00871103  -0.0674623  -0.0218057   -0.144824     -0.10814      0.0157679     0.157883     0.0287513    -0.0348586    0.0608859   -0.0495382   -0.0630146   -0.144517    0.00460056   0.0382197    0.0520283    0.0695137    0.187693     0.101996     0.0465703    0.138484
  0.0444826    0.0218765    0.119287     0.233743    -0.105883     -0.0502045    0.0671634   0.052257    -0.0382627    -0.0711384    0.00741135   -0.173982     0.0991518     0.0421628    0.144443    -0.0208914   -0.0758685   -0.0855772   0.0128706   -0.045848     0.153011     0.00544465   0.0250175   -0.121799    -0.0218609    0.0858192
 -0.0094908    0.0611417    0.113149     0.00630993   0.196724      0.163721     0.0212066  -0.0308198   -0.0480247    -0.0160929    0.172548      0.00276639  -0.0890432     0.00840128   0.0207361   -0.16416      0.237432    -0.0127518   0.0818043   -0.138859    -0.143302    -0.0868972    0.0485502    0.134158    -0.159381     0.111321
  0.146015    -0.172138     0.0724407    0.0135944   -0.0657183    -0.0208099    0.101865   -0.0836141    0.027401     -0.0953329   -0.0617225     0.102689    -0.0554067    -0.097309     0.114961     0.0844531   -0.0104284   -0.0280096   0.0008447   -0.119416    -0.0547574    0.143001     0.0698691   -0.0523714    0.221455     0.000888898
 -0.0622472    0.0680539    0.0343789   -0.16361     -0.109936      0.0775696    0.0482938  -0.0711336    0.182785      0.282351     0.179135      0.16171      0.172085      0.0455855    0.0397072    0.00913117   0.0898256    0.0586743  -0.0957858    0.00601104  -0.0510825   -0.0309416    0.190343     0.0413907    0.152355    -0.0967878
  0.0611973   -0.111415     0.173768    -0.236448    -0.11225       0.0288695   -0.0871817  -0.109673     0.0197638    -0.133013    -0.0254296     0.0141974   -0.0219916    -0.0442451   -0.249011    -0.144065    -0.0780964    0.0391534   0.14702     -0.00864423  -0.065221    -0.0716791   -0.0213185    0.137369    -0.0158721    0.296734
 -0.0030812    0.0745334   -0.0392443    0.0287679    0.105674     -0.0695052   -0.0100086  -0.0234413    0.124824      0.119638     0.0438598    -0.201962    -0.0313334    -0.0788409    0.0756013    0.0787135    0.0467293   -0.119541    0.0225915    0.0597189    0.123772    -0.0462735    0.00309484  -0.0452956   -0.0489528    0.24319
 -0.00574038  -0.122205     0.162585     0.166345     0.03351      -0.00822747  -0.0261635   0.160379    -0.0912708     0.0338427    0.064817      0.00755272  -0.00812515   -0.114642    -0.164284     0.0508874    0.10674      0.0597274   0.0653137   -0.193635    -0.0128082    0.0362686    0.0227223   -0.0217772   -0.101122    -0.0392136
  0.0495145   -0.0882584    0.0440279   -0.260171     0.0260122     0.020009     0.191476    0.110606    -0.0535025    -0.120408     0.0632757    -0.0299247   -0.00667323    0.127007     0.0060558    0.113336     0.0824017   -0.0213595   0.144173     0.0679268   -0.0698407    0.133222    -0.0570978    0.0111      -0.0322519   -0.00459285
  0.173693     0.14103     -0.0675687   -0.138202     0.00180528    0.10049     -0.0683507  -0.0453574   -0.00839813    0.286089     0.0101432    -0.00269496  -0.0180762    -0.0747898   -0.104223     0.0858915   -0.0771943    0.0856155   0.0332794    0.137271    -0.137352     0.0792318    0.122821    -0.0651136   -0.0998496    0.04294
 -0.0165958   -0.0899025    0.130918    -0.0418188    0.0866642    -0.0621933   -0.111497    0.00590362  -0.00141391   -0.0588515   -0.150879     -0.121258     0.000504369  -0.120685     0.0478581    0.039792     0.105036    -0.0892779   0.144176     0.0954715   -0.159784     0.105491    -0.0249728    0.0737789   -0.0267438    0.103803
 -0.202751     0.100384     0.032604     0.152666     0.18123       0.0948316   -0.0928559  -0.107956    -0.0482021     0.0168811   -0.0682514     0.198009    -0.0117365    -0.0260984    0.0577451    0.104013    -0.186551    -0.0336407   0.0813524   -0.0110702   -0.0206114    0.0257746    0.101939    -0.164159     0.0076913   -0.0116069
  0.147059    -0.0457766    0.112369     0.0513685    0.0774317    -0.01256      0.079439    0.0539299   -0.0538274     0.111089     0.0871602    -0.063725     0.113583     -0.0907099    0.0468956   -0.148408     0.226082    -0.268649   -0.037256    -0.0320009    0.00740528  -0.0166846    0.0778967   -0.285667    -0.130266    -0.0393396
  0.125433     0.0614957    0.0591682   -0.0789081    0.0240106    -0.0895727   -0.0818042   0.0445583   -0.14878      -0.025506    -0.157726     -0.0584128    0.0579521    -0.0544296    0.109987     0.118603    -0.0308216    0.129042   -0.0320356    0.0534133   -0.0740636   -0.273286    -0.109885    -0.081514     0.0441503   -0.120151kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.412089655029593
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412108
[ Info: iteration 2, average log likelihood -1.412043
[ Info: iteration 3, average log likelihood -1.411993
[ Info: iteration 4, average log likelihood -1.411935
[ Info: iteration 5, average log likelihood -1.411865
[ Info: iteration 6, average log likelihood -1.411780
[ Info: iteration 7, average log likelihood -1.411678
[ Info: iteration 8, average log likelihood -1.411538
[ Info: iteration 9, average log likelihood -1.411308
[ Info: iteration 10, average log likelihood -1.410880
[ Info: iteration 11, average log likelihood -1.410130
[ Info: iteration 12, average log likelihood -1.409074
[ Info: iteration 13, average log likelihood -1.408020
[ Info: iteration 14, average log likelihood -1.407303
[ Info: iteration 15, average log likelihood -1.406945
[ Info: iteration 16, average log likelihood -1.406793
[ Info: iteration 17, average log likelihood -1.406733
[ Info: iteration 18, average log likelihood -1.406709
[ Info: iteration 19, average log likelihood -1.406699
[ Info: iteration 20, average log likelihood -1.406695
[ Info: iteration 21, average log likelihood -1.406693
[ Info: iteration 22, average log likelihood -1.406692
[ Info: iteration 23, average log likelihood -1.406691
[ Info: iteration 24, average log likelihood -1.406691
[ Info: iteration 25, average log likelihood -1.406690
[ Info: iteration 26, average log likelihood -1.406690
[ Info: iteration 27, average log likelihood -1.406690
[ Info: iteration 28, average log likelihood -1.406690
[ Info: iteration 29, average log likelihood -1.406690
[ Info: iteration 30, average log likelihood -1.406689
[ Info: iteration 31, average log likelihood -1.406689
[ Info: iteration 32, average log likelihood -1.406689
[ Info: iteration 33, average log likelihood -1.406689
[ Info: iteration 34, average log likelihood -1.406689
[ Info: iteration 35, average log likelihood -1.406689
[ Info: iteration 36, average log likelihood -1.406689
[ Info: iteration 37, average log likelihood -1.406689
[ Info: iteration 38, average log likelihood -1.406689
[ Info: iteration 39, average log likelihood -1.406689
[ Info: iteration 40, average log likelihood -1.406689
[ Info: iteration 41, average log likelihood -1.406689
[ Info: iteration 42, average log likelihood -1.406688
[ Info: iteration 43, average log likelihood -1.406688
[ Info: iteration 44, average log likelihood -1.406688
[ Info: iteration 45, average log likelihood -1.406688
[ Info: iteration 46, average log likelihood -1.406688
[ Info: iteration 47, average log likelihood -1.406688
[ Info: iteration 48, average log likelihood -1.406688
[ Info: iteration 49, average log likelihood -1.406688
[ Info: iteration 50, average log likelihood -1.406688
┌ Info: EM with 100000 data points 50 iterations avll -1.406688
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4121079691986707
│     -1.4120434770948047
│      ⋮
└     -1.4066882584031153
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406706
[ Info: iteration 2, average log likelihood -1.406640
[ Info: iteration 3, average log likelihood -1.406588
[ Info: iteration 4, average log likelihood -1.406526
[ Info: iteration 5, average log likelihood -1.406453
[ Info: iteration 6, average log likelihood -1.406372
[ Info: iteration 7, average log likelihood -1.406291
[ Info: iteration 8, average log likelihood -1.406217
[ Info: iteration 9, average log likelihood -1.406157
[ Info: iteration 10, average log likelihood -1.406112
[ Info: iteration 11, average log likelihood -1.406080
[ Info: iteration 12, average log likelihood -1.406055
[ Info: iteration 13, average log likelihood -1.406036
[ Info: iteration 14, average log likelihood -1.406020
[ Info: iteration 15, average log likelihood -1.406006
[ Info: iteration 16, average log likelihood -1.405993
[ Info: iteration 17, average log likelihood -1.405980
[ Info: iteration 18, average log likelihood -1.405968
[ Info: iteration 19, average log likelihood -1.405955
[ Info: iteration 20, average log likelihood -1.405943
[ Info: iteration 21, average log likelihood -1.405930
[ Info: iteration 22, average log likelihood -1.405918
[ Info: iteration 23, average log likelihood -1.405905
[ Info: iteration 24, average log likelihood -1.405892
[ Info: iteration 25, average log likelihood -1.405879
[ Info: iteration 26, average log likelihood -1.405866
[ Info: iteration 27, average log likelihood -1.405854
[ Info: iteration 28, average log likelihood -1.405842
[ Info: iteration 29, average log likelihood -1.405831
[ Info: iteration 30, average log likelihood -1.405820
[ Info: iteration 31, average log likelihood -1.405811
[ Info: iteration 32, average log likelihood -1.405802
[ Info: iteration 33, average log likelihood -1.405794
[ Info: iteration 34, average log likelihood -1.405786
[ Info: iteration 35, average log likelihood -1.405779
[ Info: iteration 36, average log likelihood -1.405773
[ Info: iteration 37, average log likelihood -1.405767
[ Info: iteration 38, average log likelihood -1.405762
[ Info: iteration 39, average log likelihood -1.405758
[ Info: iteration 40, average log likelihood -1.405753
[ Info: iteration 41, average log likelihood -1.405749
[ Info: iteration 42, average log likelihood -1.405745
[ Info: iteration 43, average log likelihood -1.405741
[ Info: iteration 44, average log likelihood -1.405738
[ Info: iteration 45, average log likelihood -1.405735
[ Info: iteration 46, average log likelihood -1.405731
[ Info: iteration 47, average log likelihood -1.405728
[ Info: iteration 48, average log likelihood -1.405725
[ Info: iteration 49, average log likelihood -1.405723
[ Info: iteration 50, average log likelihood -1.405720
┌ Info: EM with 100000 data points 50 iterations avll -1.405720
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4067063479194473
│     -1.4066397380963456
│      ⋮
└     -1.4057199291427318
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405728
[ Info: iteration 2, average log likelihood -1.405674
[ Info: iteration 3, average log likelihood -1.405628
[ Info: iteration 4, average log likelihood -1.405577
[ Info: iteration 5, average log likelihood -1.405516
[ Info: iteration 6, average log likelihood -1.405442
[ Info: iteration 7, average log likelihood -1.405358
[ Info: iteration 8, average log likelihood -1.405265
[ Info: iteration 9, average log likelihood -1.405172
[ Info: iteration 10, average log likelihood -1.405082
[ Info: iteration 11, average log likelihood -1.405000
[ Info: iteration 12, average log likelihood -1.404929
[ Info: iteration 13, average log likelihood -1.404869
[ Info: iteration 14, average log likelihood -1.404819
[ Info: iteration 15, average log likelihood -1.404778
[ Info: iteration 16, average log likelihood -1.404744
[ Info: iteration 17, average log likelihood -1.404716
[ Info: iteration 18, average log likelihood -1.404693
[ Info: iteration 19, average log likelihood -1.404672
[ Info: iteration 20, average log likelihood -1.404653
[ Info: iteration 21, average log likelihood -1.404636
[ Info: iteration 22, average log likelihood -1.404620
[ Info: iteration 23, average log likelihood -1.404604
[ Info: iteration 24, average log likelihood -1.404589
[ Info: iteration 25, average log likelihood -1.404574
[ Info: iteration 26, average log likelihood -1.404560
[ Info: iteration 27, average log likelihood -1.404546
[ Info: iteration 28, average log likelihood -1.404532
[ Info: iteration 29, average log likelihood -1.404519
[ Info: iteration 30, average log likelihood -1.404506
[ Info: iteration 31, average log likelihood -1.404494
[ Info: iteration 32, average log likelihood -1.404482
[ Info: iteration 33, average log likelihood -1.404470
[ Info: iteration 34, average log likelihood -1.404460
[ Info: iteration 35, average log likelihood -1.404450
[ Info: iteration 36, average log likelihood -1.404441
[ Info: iteration 37, average log likelihood -1.404432
[ Info: iteration 38, average log likelihood -1.404423
[ Info: iteration 39, average log likelihood -1.404416
[ Info: iteration 40, average log likelihood -1.404408
[ Info: iteration 41, average log likelihood -1.404401
[ Info: iteration 42, average log likelihood -1.404394
[ Info: iteration 43, average log likelihood -1.404388
[ Info: iteration 44, average log likelihood -1.404381
[ Info: iteration 45, average log likelihood -1.404375
[ Info: iteration 46, average log likelihood -1.404369
[ Info: iteration 47, average log likelihood -1.404363
[ Info: iteration 48, average log likelihood -1.404358
[ Info: iteration 49, average log likelihood -1.404352
[ Info: iteration 50, average log likelihood -1.404347
┌ Info: EM with 100000 data points 50 iterations avll -1.404347
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.405727844593738
│     -1.4056735896351977
│      ⋮
└     -1.4043466112525484
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404350
[ Info: iteration 2, average log likelihood -1.404286
[ Info: iteration 3, average log likelihood -1.404229
[ Info: iteration 4, average log likelihood -1.404164
[ Info: iteration 5, average log likelihood -1.404086
[ Info: iteration 6, average log likelihood -1.403992
[ Info: iteration 7, average log likelihood -1.403885
[ Info: iteration 8, average log likelihood -1.403769
[ Info: iteration 9, average log likelihood -1.403650
[ Info: iteration 10, average log likelihood -1.403533
[ Info: iteration 11, average log likelihood -1.403423
[ Info: iteration 12, average log likelihood -1.403321
[ Info: iteration 13, average log likelihood -1.403230
[ Info: iteration 14, average log likelihood -1.403149
[ Info: iteration 15, average log likelihood -1.403079
[ Info: iteration 16, average log likelihood -1.403018
[ Info: iteration 17, average log likelihood -1.402966
[ Info: iteration 18, average log likelihood -1.402922
[ Info: iteration 19, average log likelihood -1.402883
[ Info: iteration 20, average log likelihood -1.402850
[ Info: iteration 21, average log likelihood -1.402820
[ Info: iteration 22, average log likelihood -1.402794
[ Info: iteration 23, average log likelihood -1.402770
[ Info: iteration 24, average log likelihood -1.402748
[ Info: iteration 25, average log likelihood -1.402728
[ Info: iteration 26, average log likelihood -1.402709
[ Info: iteration 27, average log likelihood -1.402692
[ Info: iteration 28, average log likelihood -1.402675
[ Info: iteration 29, average log likelihood -1.402659
[ Info: iteration 30, average log likelihood -1.402644
[ Info: iteration 31, average log likelihood -1.402629
[ Info: iteration 32, average log likelihood -1.402615
[ Info: iteration 33, average log likelihood -1.402601
[ Info: iteration 34, average log likelihood -1.402588
[ Info: iteration 35, average log likelihood -1.402575
[ Info: iteration 36, average log likelihood -1.402562
[ Info: iteration 37, average log likelihood -1.402550
[ Info: iteration 38, average log likelihood -1.402538
[ Info: iteration 39, average log likelihood -1.402526
[ Info: iteration 40, average log likelihood -1.402514
[ Info: iteration 41, average log likelihood -1.402503
[ Info: iteration 42, average log likelihood -1.402491
[ Info: iteration 43, average log likelihood -1.402480
[ Info: iteration 44, average log likelihood -1.402469
[ Info: iteration 45, average log likelihood -1.402458
[ Info: iteration 46, average log likelihood -1.402447
[ Info: iteration 47, average log likelihood -1.402436
[ Info: iteration 48, average log likelihood -1.402425
[ Info: iteration 49, average log likelihood -1.402414
[ Info: iteration 50, average log likelihood -1.402404
┌ Info: EM with 100000 data points 50 iterations avll -1.402404
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4043499230959098
│     -1.4042860338937746
│      ⋮
└     -1.402403722419391
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402402
[ Info: iteration 2, average log likelihood -1.402335
[ Info: iteration 3, average log likelihood -1.402273
[ Info: iteration 4, average log likelihood -1.402202
[ Info: iteration 5, average log likelihood -1.402115
[ Info: iteration 6, average log likelihood -1.402010
[ Info: iteration 7, average log likelihood -1.401885
[ Info: iteration 8, average log likelihood -1.401743
[ Info: iteration 9, average log likelihood -1.401590
[ Info: iteration 10, average log likelihood -1.401434
[ Info: iteration 11, average log likelihood -1.401280
[ Info: iteration 12, average log likelihood -1.401135
[ Info: iteration 13, average log likelihood -1.401000
[ Info: iteration 14, average log likelihood -1.400876
[ Info: iteration 15, average log likelihood -1.400763
[ Info: iteration 16, average log likelihood -1.400661
[ Info: iteration 17, average log likelihood -1.400568
[ Info: iteration 18, average log likelihood -1.400485
[ Info: iteration 19, average log likelihood -1.400409
[ Info: iteration 20, average log likelihood -1.400340
[ Info: iteration 21, average log likelihood -1.400277
[ Info: iteration 22, average log likelihood -1.400219
[ Info: iteration 23, average log likelihood -1.400166
[ Info: iteration 24, average log likelihood -1.400116
[ Info: iteration 25, average log likelihood -1.400069
[ Info: iteration 26, average log likelihood -1.400026
[ Info: iteration 27, average log likelihood -1.399986
[ Info: iteration 28, average log likelihood -1.399948
[ Info: iteration 29, average log likelihood -1.399913
[ Info: iteration 30, average log likelihood -1.399881
[ Info: iteration 31, average log likelihood -1.399850
[ Info: iteration 32, average log likelihood -1.399822
[ Info: iteration 33, average log likelihood -1.399796
[ Info: iteration 34, average log likelihood -1.399772
[ Info: iteration 35, average log likelihood -1.399749
[ Info: iteration 36, average log likelihood -1.399727
[ Info: iteration 37, average log likelihood -1.399707
[ Info: iteration 38, average log likelihood -1.399688
[ Info: iteration 39, average log likelihood -1.399671
[ Info: iteration 40, average log likelihood -1.399654
[ Info: iteration 41, average log likelihood -1.399638
[ Info: iteration 42, average log likelihood -1.399623
[ Info: iteration 43, average log likelihood -1.399608
[ Info: iteration 44, average log likelihood -1.399595
[ Info: iteration 45, average log likelihood -1.399581
[ Info: iteration 46, average log likelihood -1.399568
[ Info: iteration 47, average log likelihood -1.399556
[ Info: iteration 48, average log likelihood -1.399544
[ Info: iteration 49, average log likelihood -1.399532
[ Info: iteration 50, average log likelihood -1.399521
┌ Info: EM with 100000 data points 50 iterations avll -1.399521
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.402401549345731
│     -1.4023351661301429
│      ⋮
└     -1.39952056903847
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.412089655029593
│     -1.4121079691986707
│     -1.4120434770948047
│     -1.4119934912447905
│      ⋮
│     -1.3995438699803333
│     -1.399532092056071
└     -1.39952056903847
32×26 Array{Float64,2}:
 -0.285616    -0.0988529   -0.12363    -0.37273     -0.0446236  -0.384945    -0.0500068   0.330223    -0.0868457     0.123582     0.0316339   -0.0981378    0.0467611  -0.381829   -0.0342497   -0.164672    0.017346    -0.347526    -0.15484    -0.0190611   -0.46223     0.0408104    0.117718    -0.166384      0.200328   -0.041007
  0.030633     0.0582228    0.202263    0.261706     0.183259    0.146653     0.0455285  -0.153376     0.0769129    -0.0550435    0.213558    -0.337873    -0.0872132   0.51032     0.0196115    0.170622   -0.0594213    0.368425     0.0147635  -0.023832     0.476568    0.139415     0.0185894    0.255987     -0.209466    0.130676
  0.392997     0.0736399   -0.231553   -0.238074    -0.0580768   0.00152764  -0.156747   -0.585035     0.28853       0.481148    -0.439425     1.58205     -0.413694   -1.12071     0.336807     0.533175   -0.4093      -0.314944     0.046898    0.0583163   -0.575573   -0.267653     0.0848433   -0.27124       0.0659539   0.0385708
  0.289332     0.199549     0.23451     0.0892921   -0.334423    0.0192146   -0.185892   -0.199838    -0.506316      0.0633082   -0.415241     0.962477     0.0481794   0.296476   -0.408582     0.205542   -0.278751    -0.0850566    0.609404   -0.423627    -0.426085    0.0301723    0.183705    -0.377888      0.079348   -0.13002
  0.18226      0.00488473  -0.0403367  -0.485256     0.372419    0.51682      0.0707487  -0.0946142    0.490339      0.390517    -0.849793     0.559697     0.503945   -0.0648515   0.0102345   -0.0119939   0.614769     0.0758665    0.39949    -0.27775      0.319974   -0.846894    -0.406113     0.784374     -0.243704   -0.176008
  0.00847687  -0.0757628    0.337767   -0.0230232   -0.19685     0.30918      0.261978    0.0677607    0.509329      0.757059     0.713388    -0.08975     -0.553489   -0.527201    0.414704     0.52001     0.471008     0.592927     0.256863   -0.258894     0.357636   -0.400602     0.173943     0.236601     -0.0647409  -0.707841
  0.188087    -0.00683954  -0.129765    0.430229     0.0282445   1.08609      0.221312   -0.386601    -0.34586      -0.23616     -0.35389      0.383095    -0.126788    0.39648    -0.483164    -0.172631    0.779301     0.373045    -0.662699   -0.264748     0.17372     0.460528    -0.33289      0.093323     -0.508304    0.0146209
 -0.145199    -0.213822     0.68443    -0.315058     0.419928    0.211908     0.0160951   0.43937     -0.668367      0.018856    -0.239262     0.486143    -0.571289    0.446546   -0.136376    -0.330397    1.32132     -0.156155    -0.31495    -0.398756    -0.280007    0.748216    -0.236327    -0.0283345     0.0640462  -0.401403
  0.150157     0.0069301   -0.0796848   0.448731    -0.48315    -1.32038      0.561986    0.103539    -0.576319     -0.211063     0.263496    -0.780616    -0.160269   -0.498411    0.145041    -0.0919085  -0.491307    -0.412932    -0.361852    0.281384    -0.186235   -0.152416     0.185776    -0.680895     -0.198515   -0.0617717
  0.274242    -0.239536    -0.326734   -0.0840725    0.328081    0.0157994   -0.254629    0.407127     0.0526976    -0.30988     -0.231431    -0.0485308   -0.134454   -0.258335    0.413252    -0.134878   -0.032267    -0.705546    -0.518275   -0.168629     0.279098   -0.161039     0.149146    -0.406466     -0.478887   -0.0469993
 -8.2874e-5    0.0492216   -0.384936    0.296269    -0.0219314  -0.169591     0.388866    0.0854547    0.542907      0.223338    -0.206125    -0.234212     0.603541   -0.387779    0.371457     0.278966   -1.11616      0.138205     0.412548    0.604834     0.133323   -0.643101    -0.247457     0.000953044  -0.0732163   0.12784
  0.432716     0.411205    -0.158399    0.131088    -0.274738    0.138655     0.232769   -0.669282     0.600438     -0.429572     0.288174    -0.0627882    0.243714    0.1697      0.0437469   -0.117614   -0.198589     0.759303    -0.322451    0.896234     0.253765   -0.445174     0.978843    -0.447697      0.102649   -0.122546
  0.151954    -0.674129     0.0200052   0.126777     0.0328144   0.496217    -0.701045    0.156079     0.214537     -0.00314982   0.370929     0.148359     0.456885   -0.31474    -0.260413    -0.187051    0.0747967   -0.0412498    0.437244    0.358381    -0.673977   -0.00733893  -0.113977    -0.0762419     0.439569    0.265735
 -0.16825      0.821811     0.141587   -0.0212069    0.192093    0.0701281   -0.154826   -0.169586     0.0832011     0.371718    -0.194498     0.274634     0.601291   -0.237151   -0.041496     0.183505    0.329487     0.227058     0.545775    0.137508    -1.02387     0.319003     0.251225     0.386937      0.222339    0.64635
  0.277375    -0.0192033    0.0696267  -0.40092      0.0855776   0.47277     -0.0949058   0.598949    -0.271594     -0.365249     0.333961    -0.527181     0.0936835  -0.0953079   0.0976184    0.819189    0.0514657   -0.00322692  -0.0507989   0.25481     -0.0764259   0.194024    -0.63223      0.0702762    -0.0244702   0.327897
  0.591973     0.185116     0.0810288   0.941405     0.283719    0.127293     0.0992749   0.128425    -0.389458      0.0997323    0.0119742   -0.166099     0.157054   -0.204563    0.374933     0.633962   -0.408781    -0.372681    -0.0491145   0.242499     0.0465765   0.520309    -0.592446    -0.279397      0.158467    0.112081
 -0.462043    -0.313948    -0.0167677  -0.220309    -0.248535   -0.3561      -0.0359024  -0.706293     0.292278     -0.0329894   -0.196149     0.423348    -0.511433   -0.0446471  -0.327755    -0.955762    0.301186     0.167457     0.137464   -0.408091     0.067182   -0.584715     0.780614     0.0692254    -0.304075   -0.0356432
 -0.315169     0.0473486   -0.225553   -0.19081      0.0589419  -0.412363    -0.283009   -0.157574     0.704808      0.156429    -0.623843     0.394889     0.178688    0.36388     0.236004    -0.241989   -0.239961     0.0128247   -0.616333    0.0875058    0.123562    0.100682     0.242172     0.128315      0.321075   -0.480967
 -0.31648     -0.03876     -0.324885   -0.263715     0.115171   -0.224723    -0.759479   -0.61988     -0.000595738  -0.377638     0.228491    -0.05042      0.013964    0.140053    0.231556     0.336865   -0.540684     0.0140851    0.443062   -0.00593049  -0.199925   -0.0134028    0.267167     0.0962203    -0.169564    0.367604
 -0.0650086   -0.103232     0.360252   -0.0454207    0.0503702   0.248267    -0.736305    0.0569921    0.396667     -0.170939     0.353214     0.0615604   -0.397523    0.392476   -0.168678     0.106958    0.147232     0.292696     0.336152   -0.196614     0.116372    0.153172     0.629132     0.018988     -0.0254456  -0.199617
 -0.108464     0.0946903    0.0113368  -0.234655     0.558538   -0.237906     0.146079    0.00364791   0.376451      0.052871    -0.208026    -0.56283     -0.332009    0.12212     0.293201     0.0993508   0.49355     -0.364698    -0.219766    0.294967     0.0768466   0.443374    -0.431509     0.561127     -0.515173    0.130215
 -0.130225    -0.396207     0.110343    0.108885    -0.193365   -0.0575733    0.169256    0.580239     0.602912     -0.140808     0.255404    -0.572895    -0.194657   -0.0814039  -0.0137498   -0.24373     0.0158862    0.283433    -0.228872    0.298195     0.499842   -0.0357546    0.0442971    0.316033     -0.139603    0.241531
  0.0587654   -0.540363     0.212463   -0.211826    -0.53256    -0.0020123    0.379704    0.494352    -0.204543      0.247239     0.101386    -0.0478005   -0.030655   -0.179195   -0.272912    -0.564395    0.198746    -0.560038    -0.260511   -0.066345     0.0695849  -0.179253    -0.279837    -0.0913767     0.744481   -0.47921
 -0.212737    -0.103359     0.169015    0.328181    -0.208004   -0.288196     0.0484706  -0.297443     0.187687      0.241408     0.437504    -0.278719     0.485741    0.167499   -0.137585    -0.192769    0.156186     0.239255     0.23902     0.380583     0.0756561   0.476659    -0.177728     0.169773      0.77458     0.0303769
  0.0241176    0.148522     0.160358    0.0577954   -0.013339   -0.0056903    0.0942802  -0.107803    -0.129256     -0.042302     0.0644169   -0.0885216    0.0687236   0.0822319  -0.00916624   0.125987    0.0152422    0.102882     0.0979472  -0.0163407    0.012416   -0.00410134   0.0319707    0.0532837    -0.0163517   0.0501811
  0.0746575   -0.250348    -0.18811     0.00703723  -0.0151116  -0.0767571   -0.236343    0.379584    -0.540313     -0.0716078   -0.0286551    0.202599     0.386213    0.304778   -0.320696     0.010293   -0.446974    -0.197427     0.237554    0.093647    -0.653704   -0.328318     0.227036    -0.29678       0.02572     0.329945
  0.0955207   -0.455789    -0.0259677  -0.00745543   0.123255    0.0307962   -0.272137    0.00917672   0.193386      0.236611     0.00287978   0.125837    -0.0685229  -0.204816    0.0472219   -0.30757     0.186324    -0.218406     0.0402827   0.0598574   -0.0459956   0.00672277  -0.13247     -0.0693227     0.0179332  -0.0424655
  0.146142     0.329736    -0.2156     -0.170225    -0.0470937   0.289944    -0.192527    0.0807746    0.0810408     0.0236531   -0.162657     0.34988      0.0926592  -0.455773    0.144879     0.271406   -0.106313    -0.111877    -0.201353   -0.0262461   -0.256855    0.0573986   -0.00517237  -0.296258      0.264788   -0.11022
 -0.190422     0.198118     0.444589   -0.484612    -0.101649   -0.215442     0.343276   -0.324157    -0.271437     -0.199673     0.29768     -0.764067     0.185749   -0.175951   -0.0865668   -1.0335      0.321401     0.528277     0.0818436  -0.13734     -0.53985     0.0919426    0.61376     -0.115731     -0.0791962   0.169278
 -0.037657     0.118147     0.353046    0.26602      0.101596   -0.326625     0.498064   -0.0900736   -0.759622      0.710849     0.0984622   -0.0282949    0.114111   -0.27       -0.204644     0.0382988  -0.0642979   -0.163501     0.505216   -0.533752    -0.224213    0.0323056   -0.502105     0.0755154    -0.159951    0.108841
 -0.0286294    0.406472    -0.423395    0.154927     0.336613   -0.0291923    0.380613   -0.154431    -0.262543     -0.0292268   -0.204673    -0.0943791   -0.171493    0.391841   -0.364938     0.299626   -0.236277     0.165628    -0.204734   -0.12316      0.30687     0.0341938    0.375656    -0.332304     -0.362797   -0.143057
  0.291681     0.37854      0.649411    0.0423226   -0.0827429   0.256926     0.441426   -0.266186    -0.573691     -0.66866      0.0603353    0.00508731  -0.0288177   0.312293    0.123579     0.12269     0.00730475  -0.0907992    0.128657   -0.391699     0.406249   -0.232493    -0.0686735   -0.228252      0.0845648   0.247758[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.399509
[ Info: iteration 2, average log likelihood -1.399498
[ Info: iteration 3, average log likelihood -1.399487
[ Info: iteration 4, average log likelihood -1.399476
[ Info: iteration 5, average log likelihood -1.399465
[ Info: iteration 6, average log likelihood -1.399454
[ Info: iteration 7, average log likelihood -1.399444
[ Info: iteration 8, average log likelihood -1.399433
[ Info: iteration 9, average log likelihood -1.399422
[ Info: iteration 10, average log likelihood -1.399411
┌ Info: EM with 100000 data points 10 iterations avll -1.399411
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.950109e+05
      1       6.867977e+05      -2.082132e+05 |       32
      2       6.753857e+05      -1.141197e+04 |       32
      3       6.705959e+05      -4.789828e+03 |       32
      4       6.678765e+05      -2.719330e+03 |       32
      5       6.659897e+05      -1.886801e+03 |       32
      6       6.646420e+05      -1.347731e+03 |       32
      7       6.635865e+05      -1.055522e+03 |       32
      8       6.627730e+05      -8.134935e+02 |       32
      9       6.621102e+05      -6.628004e+02 |       32
     10       6.615823e+05      -5.279253e+02 |       32
     11       6.611318e+05      -4.505030e+02 |       32
     12       6.607304e+05      -4.013599e+02 |       32
     13       6.603647e+05      -3.656658e+02 |       32
     14       6.600792e+05      -2.854762e+02 |       32
     15       6.598321e+05      -2.471564e+02 |       32
     16       6.595902e+05      -2.418962e+02 |       32
     17       6.593765e+05      -2.137398e+02 |       32
     18       6.592005e+05      -1.759260e+02 |       32
     19       6.590510e+05      -1.495618e+02 |       32
     20       6.589129e+05      -1.381001e+02 |       32
     21       6.587840e+05      -1.288467e+02 |       32
     22       6.586589e+05      -1.251509e+02 |       32
     23       6.585503e+05      -1.085582e+02 |       32
     24       6.584470e+05      -1.033163e+02 |       32
     25       6.583363e+05      -1.106950e+02 |       32
     26       6.582342e+05      -1.020540e+02 |       32
     27       6.581401e+05      -9.410455e+01 |       32
     28       6.580546e+05      -8.550141e+01 |       32
     29       6.579749e+05      -7.974273e+01 |       32
     30       6.578977e+05      -7.720028e+01 |       32
     31       6.578179e+05      -7.976779e+01 |       32
     32       6.577372e+05      -8.077525e+01 |       32
     33       6.576552e+05      -8.195068e+01 |       32
     34       6.575669e+05      -8.827029e+01 |       32
     35       6.574736e+05      -9.332605e+01 |       32
     36       6.573822e+05      -9.144219e+01 |       32
     37       6.573113e+05      -7.090471e+01 |       32
     38       6.572412e+05      -7.005795e+01 |       32
     39       6.571765e+05      -6.470873e+01 |       32
     40       6.571143e+05      -6.219615e+01 |       32
     41       6.570550e+05      -5.929563e+01 |       32
     42       6.570076e+05      -4.737624e+01 |       32
     43       6.569615e+05      -4.608525e+01 |       32
     44       6.569183e+05      -4.319499e+01 |       32
     45       6.568771e+05      -4.120342e+01 |       32
     46       6.568406e+05      -3.654744e+01 |       32
     47       6.568065e+05      -3.412712e+01 |       32
     48       6.567721e+05      -3.440973e+01 |       32
     49       6.567374e+05      -3.469229e+01 |       32
     50       6.567073e+05      -3.005130e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 656707.3154024126)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411560
[ Info: iteration 2, average log likelihood -1.406312
[ Info: iteration 3, average log likelihood -1.404855
[ Info: iteration 4, average log likelihood -1.403727
[ Info: iteration 5, average log likelihood -1.402584
[ Info: iteration 6, average log likelihood -1.401630
[ Info: iteration 7, average log likelihood -1.401046
[ Info: iteration 8, average log likelihood -1.400746
[ Info: iteration 9, average log likelihood -1.400584
[ Info: iteration 10, average log likelihood -1.400481
[ Info: iteration 11, average log likelihood -1.400405
[ Info: iteration 12, average log likelihood -1.400343
[ Info: iteration 13, average log likelihood -1.400290
[ Info: iteration 14, average log likelihood -1.400242
[ Info: iteration 15, average log likelihood -1.400198
[ Info: iteration 16, average log likelihood -1.400156
[ Info: iteration 17, average log likelihood -1.400117
[ Info: iteration 18, average log likelihood -1.400080
[ Info: iteration 19, average log likelihood -1.400044
[ Info: iteration 20, average log likelihood -1.400010
[ Info: iteration 21, average log likelihood -1.399976
[ Info: iteration 22, average log likelihood -1.399943
[ Info: iteration 23, average log likelihood -1.399911
[ Info: iteration 24, average log likelihood -1.399880
[ Info: iteration 25, average log likelihood -1.399850
[ Info: iteration 26, average log likelihood -1.399820
[ Info: iteration 27, average log likelihood -1.399791
[ Info: iteration 28, average log likelihood -1.399763
[ Info: iteration 29, average log likelihood -1.399736
[ Info: iteration 30, average log likelihood -1.399709
[ Info: iteration 31, average log likelihood -1.399684
[ Info: iteration 32, average log likelihood -1.399659
[ Info: iteration 33, average log likelihood -1.399636
[ Info: iteration 34, average log likelihood -1.399613
[ Info: iteration 35, average log likelihood -1.399591
[ Info: iteration 36, average log likelihood -1.399570
[ Info: iteration 37, average log likelihood -1.399550
[ Info: iteration 38, average log likelihood -1.399530
[ Info: iteration 39, average log likelihood -1.399512
[ Info: iteration 40, average log likelihood -1.399494
[ Info: iteration 41, average log likelihood -1.399476
[ Info: iteration 42, average log likelihood -1.399459
[ Info: iteration 43, average log likelihood -1.399443
[ Info: iteration 44, average log likelihood -1.399427
[ Info: iteration 45, average log likelihood -1.399411
[ Info: iteration 46, average log likelihood -1.399396
[ Info: iteration 47, average log likelihood -1.399381
[ Info: iteration 48, average log likelihood -1.399366
[ Info: iteration 49, average log likelihood -1.399352
[ Info: iteration 50, average log likelihood -1.399338
┌ Info: EM with 100000 data points 50 iterations avll -1.399338
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.172074    -0.346739   -0.0542623   -0.143898     0.174426     0.284833    -1.00239       0.116719    0.469626    0.163982      0.535362    -0.0926359    0.280984    -0.501817     0.391712   -0.0278359   0.336596    -0.207076    -0.0671338     0.225334     -0.421083     0.221698     0.0291448  -0.0679938    0.342925    0.0240907
 -0.109469    -0.231624   -0.342035    -0.150826     0.0355091    0.0273774   -0.204806      0.211473    0.432156    0.000170187  -0.145471     0.035415    -0.0596132   -0.166524    -0.0842923  -0.175088    0.0140314   -0.161527    -0.250253      0.191282      0.0128232   -0.116291     0.167891   -0.150099    -0.0749785   0.0670989
  0.0266086   -0.0514215  -0.0318404    0.127408     0.123299     0.0692522   -0.0882973    -0.0240456  -0.06373    -0.0940643     0.153534    -0.196903     0.102076     0.110737    -0.0840003   0.0491884  -0.0636035   -0.0308997   -0.0204681    -0.00278713   -0.00459649   0.123091    -0.0312778  -0.0688984   -0.011875    0.0940955
  0.134377     0.0734534   0.253545     0.0737124    0.0392212    1.17946      0.267531      0.142139   -0.131827    0.032737     -0.430226     0.612385    -0.164682     0.156976    -0.469444   -0.154376    0.890146     0.343281    -0.442942     -0.228942      0.19531      0.432528    -0.309188   -0.0990513   -0.0656969  -0.268733
 -0.0470644    0.337119    0.0602845   -0.0183855    0.00152996   0.038381    -0.0369886    -0.244388   -0.212921   -0.215336      0.0344871    0.0126007    0.122775     0.120613     0.0185163   0.199547   -0.138202     0.129287     0.0120712    -0.00730552   -0.136631     0.0478866    0.235515   -0.10174      0.105257    0.107411
 -0.372841    -0.0844146   0.138522    -0.00255974   0.182639    -0.296443     0.15705      -0.213259    0.0406269   0.594032      0.0170518   -0.0252708   -0.00793098  -0.231988     0.122901   -0.122045    0.0748338   -0.0255158    0.299471     -0.154275     -0.174566    -0.127002    -0.246546    0.312339    -0.2382     -0.0514059
 -0.333604    -0.296442   -0.0413695   -0.426732    -0.202447    -0.157306    -0.262783     -0.376687    0.50001    -0.0351998    -0.188132     0.61781     -0.457507    -0.127014    -0.136999   -0.741959    0.142687    -0.0421483    0.09147      -0.208536      0.0657363   -0.636728     0.654997   -0.00878277  -0.120558   -0.156857
  0.0837928   -0.380654    0.801908    -0.139865     0.703192    -0.222305    -0.167512      0.284601   -0.626315   -0.160856     -0.0583568    0.37899     -0.598303     0.680369     0.0488609  -0.430258    1.38897     -0.256678    -0.0207736    -0.221832     -0.425438     0.658512    -0.372092    0.14822      0.202789   -0.476995
 -0.208518     0.0618518   0.230244    -0.196245    -0.0176281    0.527054    -0.287197      0.457415   -0.208921   -0.203946      0.303885    -0.243372    -0.358214    -0.178844    -0.277435    0.754184   -0.00104495   0.0483643    0.39596       0.0392173    -0.429296    -0.0706564   -0.621454    0.187629    -0.343689    0.526076
  0.0089337   -0.0590004  -0.465289    -0.00918797  -0.239565    -0.707344     0.0135867    -0.119643    0.441262   -0.0622929     0.270621    -0.518339     0.494817    -0.29408      0.220294    0.237986   -1.0862      -0.0483355    0.495877      0.653772     -0.0131805   -0.652416     0.385007   -0.0336578   -0.032404    0.272422
  0.178926     0.580959    0.207427     0.354929    -0.0233781   -0.127306     0.160693     -0.533921   -0.430313    0.300866     -0.243873     0.613799    -0.0373679    0.0618547   -0.260771    0.312931   -0.357479    -0.00676973   0.689802     -0.482342     -0.260697     0.181747     0.028462   -0.240312    -0.134359    0.114492
  0.539614    -0.0424961   0.254382     0.155943    -0.0577169    0.144354     0.126516      0.22826    -0.0650934   0.144952      0.00081922  -0.0156052   -0.0301286   -0.133453     0.0564028   0.0701112   0.129403    -0.0753204    0.172093     -0.0830783     0.202116     0.0515793   -0.346366   -0.018774     0.0250471  -0.0989561
 -0.130607    -0.316963   -0.149044    -0.649227    -0.565493    -0.00225121   0.696998      0.879527   -0.18775     0.692345     -0.214166    -0.101729     0.125628    -0.416505     0.0450562  -0.365172    0.318393    -0.559455    -0.368179     -0.197171     -0.0906215   -0.690938    -0.430917    0.25551      0.780251   -0.964664
  0.318927     0.0923714  -0.247677    -0.0659708    0.152364    -0.255969    -0.056576      0.0552116   0.160114   -0.0511703     0.0593838   -0.108186    -0.121091    -0.325448     0.25862     0.0852309  -0.0160151   -0.452021    -0.626699     -0.191013      0.243566    -0.0145203    0.428518   -0.842534    -0.0221502  -0.645885
  0.0742678    0.436495    0.176194    -0.491967     0.234261    -0.0164475    0.377906     -0.112339   -0.0245149   0.405611     -0.509162     0.722463     0.136524    -1.21921      0.481564    0.2302      0.145816    -0.0545131   -0.000984211   0.200438     -0.870869    -0.300346    -0.0518965  -0.186852     0.0363741   0.166357
 -0.0389714    0.198752   -0.0796525   -0.27011      0.554792    -0.248538     0.0633761     0.0951908   0.478201   -0.139071     -0.282772    -0.74127     -0.239172     0.272142     0.378339    0.0896558   0.424862    -0.191957    -0.424021      0.314945      0.209206     0.561437    -0.162884    0.573273    -0.572756    0.106044
  0.130387    -0.22774    -0.27222      0.386497     0.103019    -0.010141    -0.45286       0.0701436   0.347954    0.2829       -0.48087      0.805112    -0.0898293    0.0658198    0.395783    0.565936   -0.483556    -0.531414    -0.0635842     0.101706      0.293425    -0.318964    -0.59648     0.295302     0.0318805  -0.295147
  0.113599    -0.0890288   0.140389    -0.0240948   -0.583046     0.270553    -0.427783      0.268448   -0.351722   -0.260006      0.386989     0.393382     0.438063     0.0506393   -0.355814    0.0737335  -0.379368     0.25373      0.400149      0.300708     -0.887252    -0.387451     0.445434   -0.696637     0.472057    0.186777
  0.290773     0.281079    1.07636     -0.0592264   -0.697889    -0.219145     0.000521339  -0.297394   -0.305276    0.363506      0.773583    -0.217806     0.220439     0.390349     0.514886    0.227917    0.159197     0.267888     0.16554      -0.300498      0.164126     0.206162     0.356105    0.280091     0.225931   -0.336058
  0.408923     0.0170304   0.11602      0.161361     0.260333     0.735775     0.492863      0.120258    0.18512     0.122212      0.341804    -0.369193    -0.344007    -0.233056     0.158621    0.520281   -0.0671867    0.431792     0.289419     -0.000533942   0.690846    -0.659903    -0.144105   -0.0329737   -0.424407   -0.176536
 -0.135578     0.494566   -0.230167     0.0169737    0.44359      0.211853    -0.0831348    -0.392413    0.567115   -0.124035     -0.26276      0.2047       0.347513     0.264743     0.263231    0.583308   -0.342847     1.05044     -0.180718      0.239893      0.250717     0.0260652    0.461628   -0.0201176   -0.0525595  -0.106111
  0.139042     0.0387391   0.0215797    0.555927    -0.324889    -0.899636     0.745453      0.119261   -0.684258   -0.112483      0.209786    -0.713169    -0.280223    -0.423528     0.0447564  -0.133429   -0.43423     -0.367797    -0.340521      0.0529138     0.00183339  -0.0383168   -0.0498821  -0.621239    -0.194054    0.0612881
 -0.154392     0.253879    0.237791    -0.526871     0.0135647   -0.28086      0.648471     -0.442046   -0.150401   -0.214554      0.0171137   -0.806333     0.232695    -0.173279    -0.19524    -1.14287     0.587774     0.807514     0.222652     -0.160307     -0.609867    -0.130922     0.627661    0.00619273  -0.482729    0.293281
 -0.0577678   -0.189988   -0.00196432   0.220256     0.0840484    0.00133175   0.316983     -0.0772396  -0.620277    0.25997       0.338552     0.0027536    0.410216    -0.0281093   -0.554278   -0.0644511   0.167848    -0.145728     0.223225      0.030044     -0.320527     0.0729258   -0.384344   -0.0999656    0.55653     0.146182
 -0.265053    -0.458327    0.363801     0.0630117   -0.314677    -0.0879211    0.144262      0.326989    0.418653   -0.235158      0.43128     -0.596605    -0.19942      0.0709089   -0.0820457  -0.439648    0.0971185    0.274786    -0.152575      0.212036      0.539584     0.0884553    0.0196902   0.360009     0.197888    0.171711
 -0.277623     0.101162    0.099116    -0.299532     0.277221     0.0244648    0.108873     -0.175341   -0.790526   -0.288982      0.129727     0.00730633  -0.452391     0.544193    -0.288017    0.203233    0.311681    -0.154972    -0.371381     -0.764052      0.312626    -0.00499136   0.257756   -0.0880263   -0.257191    0.0156663
 -0.240417     0.297133    0.195342     0.103866     0.185692     0.0435044   -0.470202     -0.143733    0.21907     0.437169     -0.140383     0.344273     0.577601     0.256609    -0.503037    0.0147437   0.368942     0.231086     0.881071      0.0288647    -0.625875     0.253539     0.361288    0.922156     0.472905    0.96284
  0.00362473  -0.313701    0.00443909   0.115231    -0.00927264   0.0803697   -0.756879     -0.208549    0.358209   -0.242092      0.161394     0.114574    -0.307852     0.507       -0.184897   -0.0121995  -0.0701387    0.323615     0.385193     -0.113542      0.158349     0.247161     0.641461   -0.0014695   -0.0710546  -0.150717
  0.420118     0.205523    0.0438825    0.242828     0.198849     0.221378     0.191417      0.419017   -0.214729   -0.0587625     0.0650972   -0.382751     0.416235    -0.199114     0.496453    0.606696   -0.30243     -0.185253    -0.0846433     0.417123     -0.0822567    0.689968    -0.719074   -0.0412787    0.376008    0.323959
 -0.0870212    0.156431    0.00143451   0.265727    -0.214198    -0.323285     0.368362     -0.529131    0.53732     0.151236     -0.257892     0.0325047    0.453972     0.211782    -0.0441244  -0.733751   -0.0640529    0.254106    -0.179195      0.461121      0.0459175    0.0663981    0.174695   -0.209613     0.614715   -0.447329
  0.334197    -0.112299   -0.193318     0.0638465    0.354162     0.0786825   -0.0163146     0.240126   -0.682606   -0.503543     -0.532803     0.12271      0.244811     0.131561     0.164928   -0.0759294  -0.379226    -0.657446    -0.0608188    -0.0528801    -0.0940662   -0.271238     0.0287968  -0.215839    -0.611665    0.481914
 -0.151215    -0.616406   -0.395577    -0.564507    -0.684152    -0.712418    -0.505216      0.47874    -0.249176    0.264833     -0.696218     0.327784    -0.0794703   -0.00566721  -0.549986   -0.249307   -0.116713    -0.76488     -0.158567     -0.589167     -0.619663     0.714361    -0.193646    0.129009     0.252973   -0.327655[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.399325
[ Info: iteration 2, average log likelihood -1.399312
[ Info: iteration 3, average log likelihood -1.399299
[ Info: iteration 4, average log likelihood -1.399287
[ Info: iteration 5, average log likelihood -1.399274
[ Info: iteration 6, average log likelihood -1.399263
[ Info: iteration 7, average log likelihood -1.399251
[ Info: iteration 8, average log likelihood -1.399240
[ Info: iteration 9, average log likelihood -1.399229
[ Info: iteration 10, average log likelihood -1.399219
┌ Info: EM with 100000 data points 10 iterations avll -1.399219
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
