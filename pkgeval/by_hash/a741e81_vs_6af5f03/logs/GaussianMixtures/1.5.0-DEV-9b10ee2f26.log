Julia Version 1.5.0-DEV.162
Commit 9b10ee2f26 (2020-01-27 13:16 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed PDMats ───────────── v0.9.11
 Installed StatsFuns ────────── v0.9.3
 Installed URIParser ────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed FillArrays ───────── v0.8.4
 Installed LegacyStrings ────── v0.4.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed NearestNeighbors ─── v0.4.4
 Installed ScikitLearnBase ──── v0.5.0
 Installed Clustering ───────── v0.13.3
 Installed DataAPI ──────────── v1.1.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed Missings ─────────── v0.4.3
 Installed BinaryProvider ───── v0.5.8
 Installed JLD ──────────────── v0.9.1
 Installed CMake ────────────── v1.1.2
 Installed SpecialFunctions ─── v0.9.0
 Installed Rmath ────────────── v0.6.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataStructures ───── v0.17.9
 Installed Compat ───────────── v2.2.0
 Installed SortingAlgorithms ── v0.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed Distributions ────── v0.22.3
 Installed Blosc ────────────── v0.5.1
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_DVZyqh/Project.toml`
 [no changes]
  Updating `/tmp/jl_DVZyqh/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_PpkqNs/Project.toml`
 [no changes]
  Updating `/tmp/jl_PpkqNs/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_jHY8DI/Project.toml`
 [no changes]
  Updating `/tmp/jl_jHY8DI/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_hKELrk/Project.toml`
 [no changes]
  Updating `/tmp/jl_hKELrk/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_nzHkwg/Project.toml`
 [no changes]
  Updating `/tmp/jl_nzHkwg/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_nzHkwg/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.660554185445777e6, [3480.0411704307053, 96519.95882956931], [-3857.7723748064514 3505.3247954165035 5504.93630903673; 3641.116739192386 -3160.9817995989824 -5403.756297420667], [[6297.442217536123 -3780.3385089854896 -5158.23108534476; -3780.338508985489 6109.494706799372 4230.183263540078; -5158.23108534476 4230.183263540078 10647.444019904678], [93458.54172031699 3630.268369973498 4913.624061120414; 3630.268369973498 93791.35885923251 -4061.0407344532564; 4913.624061120414 -4061.0407344532564 88885.26555504673]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.872345e+03
      1       1.231531e+03      -6.408133e+02 |        8
      2       1.079455e+03      -1.520758e+02 |        5
      3       1.051215e+03      -2.824042e+01 |        0
      4       1.051215e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1051.2150334963544)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.067255
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.697171
[ Info: iteration 2, lowerbound -3.540924
[ Info: iteration 3, lowerbound -3.392876
[ Info: iteration 4, lowerbound -3.233910
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.060584
[ Info: iteration 6, lowerbound -2.901871
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.779649
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.678619
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.595764
[ Info: iteration 10, lowerbound -2.531806
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.479698
[ Info: iteration 12, lowerbound -2.432701
[ Info: iteration 13, lowerbound -2.395086
[ Info: iteration 14, lowerbound -2.362210
[ Info: iteration 15, lowerbound -2.334157
[ Info: iteration 16, lowerbound -2.314328
[ Info: iteration 17, lowerbound -2.307409
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302938
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Jan 27 18:45:06 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Jan 27 18:45:14 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Jan 27 18:45:17 2020: EM with 272 data points 0 iterations avll -2.067255
5.8 data points per parameter
, Mon Jan 27 18:45:19 2020: GMM converted to Variational GMM
, Mon Jan 27 18:45:27 2020: iteration 1, lowerbound -3.697171
, Mon Jan 27 18:45:27 2020: iteration 2, lowerbound -3.540924
, Mon Jan 27 18:45:27 2020: iteration 3, lowerbound -3.392876
, Mon Jan 27 18:45:27 2020: iteration 4, lowerbound -3.233910
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 7
, Mon Jan 27 18:45:27 2020: iteration 5, lowerbound -3.060584
, Mon Jan 27 18:45:27 2020: iteration 6, lowerbound -2.901871
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 6
, Mon Jan 27 18:45:27 2020: iteration 7, lowerbound -2.779649
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 5
, Mon Jan 27 18:45:27 2020: iteration 8, lowerbound -2.678619
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 4
, Mon Jan 27 18:45:27 2020: iteration 9, lowerbound -2.595764
, Mon Jan 27 18:45:27 2020: iteration 10, lowerbound -2.531806
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 3
, Mon Jan 27 18:45:27 2020: iteration 11, lowerbound -2.479698
, Mon Jan 27 18:45:27 2020: iteration 12, lowerbound -2.432701
, Mon Jan 27 18:45:27 2020: iteration 13, lowerbound -2.395086
, Mon Jan 27 18:45:27 2020: iteration 14, lowerbound -2.362210
, Mon Jan 27 18:45:27 2020: iteration 15, lowerbound -2.334157
, Mon Jan 27 18:45:27 2020: iteration 16, lowerbound -2.314328
, Mon Jan 27 18:45:27 2020: iteration 17, lowerbound -2.307409
, Mon Jan 27 18:45:27 2020: dropping number of Gaussions to 2
, Mon Jan 27 18:45:27 2020: iteration 18, lowerbound -2.302938
, Mon Jan 27 18:45:27 2020: iteration 19, lowerbound -2.299260
, Mon Jan 27 18:45:27 2020: iteration 20, lowerbound -2.299256
, Mon Jan 27 18:45:27 2020: iteration 21, lowerbound -2.299255
, Mon Jan 27 18:45:27 2020: iteration 22, lowerbound -2.299254
, Mon Jan 27 18:45:27 2020: iteration 23, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 24, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 25, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 26, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 27, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 28, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 29, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 30, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 31, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 32, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 33, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 34, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 35, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 36, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 37, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 38, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 39, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 40, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 41, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 42, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 43, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 44, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 45, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 46, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 47, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 48, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 49, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: iteration 50, lowerbound -2.299253
, Mon Jan 27 18:45:28 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601388, 95.95490777398614]
β = [178.04509222601388, 95.95490777398614]
m = [4.25030073326991 79.28686694436183; 2.0002292577753704 53.85198717246131]
ν = [180.04509222601388, 97.95490777398614]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484644 -0.00764404904232731; 0.0 0.008581705166333409], [0.3758763611948406 -0.008953123827346065; 0.0 0.012748664777409515]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9785819208001233
avll from llpg:  -0.9785819208001229
avll direct:     -0.978581920800123
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9943548331049599
avll from llpg:  -0.9943548331049601
avll direct:     -0.99435483310496
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0877682    0.115117    0.0445666   -0.0738273    0.0331555    0.223056    -0.118788    -0.0859347    0.172673    -0.00667781   0.025411    -0.0642449   -0.0696057  -0.0464148    0.00123647   0.0645075  -0.00671739  -0.0463422   -0.0546037   -0.193099    -0.0555736   -0.094933     -0.107276     -0.0669205    -0.104673     0.0127791
 -0.0622649   -0.0544623   0.0919549    0.158249     0.0228837   -0.0554921   -0.0193654   -0.00257369  -0.151712     0.0640717   -0.0685362    0.104014     0.0834732   0.0416698    0.129596    -0.0195579   0.0464582    0.161458    -0.0188641    0.0917826    0.0592909    0.0599628    -0.101539     -0.0791033     0.0234883   -0.150516
  0.0165255    0.0133217   0.00828594   0.0426038    0.217794     0.0118677    0.0477578    0.0849183    0.233715     0.0805596    0.137835     0.203311     0.0863551  -0.0878741    0.188285     0.076229   -0.172282    -0.128795     0.101947     0.0582671    0.0487481    0.152368      0.0884619    -0.0313401    -0.0127259   -0.229881
 -0.0310044   -0.0788412  -0.175986     0.0369977   -0.0236527    0.100738    -0.00369512  -0.0383396   -0.0663418   -0.0146978   -0.0788607   -0.125263    -0.0225142  -0.149683     0.122559     0.0432852  -0.0351342   -0.0808159    0.286152     0.001288     0.0824084    0.0633427    -0.0383384    -0.0311698     0.00908595  -0.207259
  0.0296569   -0.214074   -0.041197    -0.0179772   -0.0761778    0.0752892   -0.0440904    0.0165091   -0.0255634   -0.0853132    0.0409548   -0.0382055   -0.114054   -0.00875033  -0.0791188    0.0250586  -0.132999    -0.0791574   -0.00455185  -0.0995348    0.0922169   -0.0152776    -0.110136      0.0580676    -0.182734     0.0643694
 -0.0286687    0.0234566  -0.126308     0.160227     0.11435     -0.00631939  -0.147874    -0.047634    -0.00628087  -0.12273     -0.0412861   -0.0391902   -0.093285   -0.0651009    0.225682     0.0625051  -0.0354053   -0.0352787   -0.00769255   0.0712702   -0.0309856    0.181494      0.09571      -0.0971775    -0.0671175    0.132639
  0.123179    -0.0161435   0.0481762    0.00754366  -0.0742751   -0.178723     0.0721605    0.0305581   -0.00526149  -0.228454    -0.0424432    0.257436    -0.148424   -0.0377259    0.113793    -0.125305   -0.0816138    0.138298     0.108125     0.199225     0.00912797  -0.0973408     0.0431117     0.0271727     0.0736075    0.0355839
  0.0926508    0.0773271   0.0565227    0.0363934   -0.0308699   -0.13441     -0.0417598   -0.198421    -0.0809156    0.00798682  -0.0134999   -0.212715    -0.1108     -0.00946149   0.0421531    0.0578533   0.036339     0.14346     -0.0695954    0.0701973    0.069275    -0.157868     -0.000565868  -0.0317288     0.024408     0.03799
  0.0937224   -0.048529    0.0746876   -0.0431967    0.0832717    0.0636014   -0.0142946   -0.0737806   -0.0191314   -0.0984279   -0.134548     0.243256     0.0266885   0.00559229   0.0338534   -0.0205065   0.0446024   -0.105259     0.00161493  -0.0745861    0.0567665    0.0170778     0.110835     -0.147859      0.0237933    0.156783
 -0.125652     0.0330873   0.146023    -0.00555091  -0.0363108   -0.0807459   -0.159947    -0.202922    -0.19387     -0.058364    -0.091383     0.044829    -0.121774   -0.0043973   -0.0205332    0.0770766  -0.16843     -0.0140163    0.0616601   -0.00308811   0.0704163    0.0199551     0.114571     -0.17282       0.0869394   -0.0292564
  0.0590608   -0.223172    0.039602    -0.0475702   -0.00197435   0.0631871   -0.102492    -0.0700755    0.0261091   -0.0975742   -0.0982843   -0.115128    -0.0386009   0.0308866   -0.119436    -0.0651746  -0.134882     0.0980444   -0.0857221    0.126099     0.0725469    0.0760052     0.202192      0.0441136     0.331796    -0.021975
  0.151793     0.0680684  -0.132916     0.11636     -0.0629164    0.00601362   0.140179     0.0501743   -0.106695    -0.0518702   -0.00032486  -0.12277     -0.147279    0.0238772   -0.031003    -0.06885     0.225172     0.0381158    0.0328206    0.270112    -0.104827     0.00555254   -0.0308009    -0.0913559     0.0864951   -0.00330518
  0.0598535    0.0857654   0.0162178    0.00679909   0.0709237    0.125811     0.033329    -0.0676241    0.104366    -0.0332288   -0.109057    -0.0580868    0.0843543   0.0508708   -0.0333779   -0.187664   -0.0187449   -0.00946294   0.0467819    0.108206     0.110803    -0.048223     -0.0410356     0.0973521    -0.0331903    0.14955
  0.0531937   -0.0215038  -0.0129132    0.0358773   -0.0490339    0.105473    -0.0472682   -0.0598385    0.0619713   -0.162054     0.0798491   -0.00778379   0.0418625  -0.135956     0.172037    -0.0877833  -0.049118     0.0723674    0.0981319    0.0410013   -0.151749    -0.0142334     0.118092     -0.108318     -0.236181     0.143612
 -0.0712968    0.0535607   0.148239     0.0463261    0.121548    -0.186519    -0.0541561   -0.00191359   0.13761     -0.0977897    0.00592266  -0.0404459   -0.0939043   0.119691     0.170057     0.0129145  -0.0941078   -0.0483248    0.0162308    0.123063     0.0535504   -0.0135321     0.105802     -0.0807808    -0.0271164   -0.0262276
  0.0993567   -0.0230305   0.0224431   -0.0748153   -0.0243756   -0.089602     0.076629    -0.044256    -0.173776     0.169076    -0.107988    -0.0844378    0.0132211  -0.0229197   -0.0144109    0.0753876  -0.0298686   -0.0229382   -0.119021     0.17362     -0.051435     0.00838541   -0.0482909     0.108639      0.114315     0.018325
  0.0268728    0.0336903   0.0862029   -0.0187131    0.0466631    0.0342935    0.180725    -0.111118    -0.0468105    0.0710794    0.0132251    0.0549114   -0.045906   -0.0407711   -0.030678     0.0941246  -0.0188541    0.0492054   -0.080889    -0.0775994    0.18917      0.0364425    -0.0942294     0.0887171     0.010565    -0.117596
 -0.0591375    0.0357622   0.0414417    0.234028     0.0816411   -0.0203829    0.0347865   -0.116124    -0.272592     0.0699584   -0.0989645   -0.049115    -0.063996   -0.0563308   -0.0104839    0.0022951   0.0759103    0.204199     0.0515269    0.0834234   -0.147172    -0.0310911     0.0344571     0.000590581  -0.0498554    0.0392787
 -0.113356    -0.0505594   0.0365795   -0.170836     0.01076      0.00856883   0.133114     0.0874359   -0.00178694  -0.128261     0.0352365    0.0231453   -0.0772671  -0.0696287    0.197845    -0.067663   -0.0580891   -0.0465145   -0.0432191   -0.0224075   -0.130417     0.104508     -0.121307      0.00370609   -0.0383417    0.0374357
  0.0502746   -0.033551    0.00464221  -0.0539493   -0.0777937   -0.0482844   -0.0567463    0.0536333   -0.041346     0.143734    -0.00701559   0.156621     0.0178794   0.0439564    0.120506     0.0776886   0.0369856    0.0217366   -0.159755    -0.0426323    0.0391559   -0.0276155    -0.00713774   -0.0908848     0.0389234    0.149148
  0.103561    -0.0355563   0.064113    -0.0652934   -0.0881437    0.054492    -0.123023    -0.00180556  -0.0312115   -0.0928442   -0.0829469   -0.0403215   -0.15875     0.126089    -0.184335    -0.18769     0.0897956   -0.00459798  -0.0208036    0.095599    -0.0163061   -0.207075     -0.0503425    -0.130883     -0.160489     0.033186
  0.0627607   -0.0569056   0.0139584   -0.142343    -0.0546885   -0.102985     0.209932     0.065017     0.0236405   -0.0797942    0.0716434   -0.043176    -0.0475232  -0.0770327    0.0567094    0.0684776  -0.142645     0.0325427    0.0209443    0.0226878    0.0471737   -0.000161351   0.0103453    -0.0501202    -0.123934     0.0126612
  0.012464     0.0834418  -0.0100833   -0.168218     0.0658997    0.011767     0.0248625   -0.0549767    0.0276414   -0.0214643   -0.0146404   -0.177721    -0.0306514   0.264491    -0.00373641   0.0364909   0.0541792    0.0426305    0.0552537   -0.0960066   -0.171389     0.0657708     0.133248      0.111848      0.04126     -0.00182457
  0.0986864    0.0404684  -0.102184    -0.0687616    0.125853     0.115675    -0.0692605    0.0973907   -0.159926     0.00289584  -0.0233336    0.213593    -0.0603974   0.235993     0.016808    -0.0711981  -0.102967    -0.0121498   -0.00914199  -0.0122428   -0.0367707   -0.185714      0.0454608     0.0457487    -0.0509448    0.00341258
 -0.103548     0.123245    0.17176     -0.10089      0.13734      0.155045    -0.105661    -0.0186718   -0.117007     0.10231     -0.0758135   -0.103444     0.149264    0.169399     0.0894598    0.0618805  -0.210042    -0.0383684    0.0227485    0.0180179    0.00129871   0.133821     -0.0271087     0.163201     -0.0321629    0.0432543
  0.11418      0.0191148  -0.0334255   -0.259956    -0.0953561   -0.0355498   -0.130796     0.0936111   -0.192215     0.132546     0.110589     0.00754983  -0.0717036  -0.00811462  -0.0909692   -0.0799427  -0.00285446  -0.129514     0.0556704   -0.0807667   -0.13192      0.266336      0.116891      0.0197172     0.00716099   0.00134855
  0.0782608   -0.0590449  -0.142132    -0.0885634    0.158667     0.0455049    0.0485831    0.0265898    0.0403086    0.0210398   -0.0442801    0.0268981   -0.148598   -0.0991895    0.165495    -0.0789433  -0.00881895   0.0718165   -0.0629472    0.0980893   -0.139829     0.0265973    -0.0648293     0.104881     -0.0064593   -0.0472036
  0.071704     0.192228    0.107329    -0.192727     0.0154672    0.0940286   -0.102745    -0.0254       0.0270535   -0.0756602    0.080123    -0.0696605    0.0726586   0.0488479    0.085835     0.108336    0.0366609   -0.0119346    0.051676     0.0940178   -0.0365697    0.0235873    -0.0819762     0.0114873    -0.0508496    0.0531442
 -0.00467074   0.323218   -0.0535721   -0.0325662    0.00146073   0.157409    -0.0152349   -0.0276551   -0.125241     0.131878    -0.125247     0.0978917   -0.106791   -0.164035    -0.18039      0.132702   -0.0424051    0.0770904   -0.0533769    0.0626104   -0.0270221    0.279129     -0.0758345    -0.00163566    0.0459551   -0.120601
  0.048912    -0.119395    0.0273472   -0.00223336  -0.0690594   -0.0699466    0.192884     0.0527553   -0.147939    -0.13861      0.0603724    0.133988     0.0378732   0.122051     0.0209138    0.0829704   0.199985     0.312871     0.025861    -0.0660587    0.0714476    0.0301429     0.00521857    0.0201045     0.0360142   -0.00514395
  0.0816458    0.0254312  -0.0624651   -0.0181356    0.0992555   -0.115508     0.111591    -0.106958    -0.0629164   -0.0756186    0.0810267   -0.150697    -0.208061   -0.0650955    0.262761    -0.0123498   0.00335213   0.119963     0.0594949    0.138608     0.00998384  -0.0897008     0.0080214    -0.0450165    -0.16637     -0.0439301
  0.0375018   -0.0420225  -0.00387951   0.150372    -0.0700688    0.047743    -0.0863815    0.0893665   -0.0168722    0.206218    -0.00470598   0.0307421   -0.208978    0.0472537    0.0542588    0.130032   -0.0170437    0.144288    -0.0634276   -0.291064     0.0477562    0.0840528     0.092197      0.180065      0.0220649    0.0286369kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4409131132448687
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.440987
[ Info: iteration 2, average log likelihood -1.440916
[ Info: iteration 3, average log likelihood -1.440289
[ Info: iteration 4, average log likelihood -1.433212
[ Info: iteration 5, average log likelihood -1.416774
[ Info: iteration 6, average log likelihood -1.409914
[ Info: iteration 7, average log likelihood -1.408414
[ Info: iteration 8, average log likelihood -1.407786
[ Info: iteration 9, average log likelihood -1.407386
[ Info: iteration 10, average log likelihood -1.406973
[ Info: iteration 11, average log likelihood -1.406510
[ Info: iteration 12, average log likelihood -1.406010
[ Info: iteration 13, average log likelihood -1.405434
[ Info: iteration 14, average log likelihood -1.404862
[ Info: iteration 15, average log likelihood -1.404305
[ Info: iteration 16, average log likelihood -1.403845
[ Info: iteration 17, average log likelihood -1.403481
[ Info: iteration 18, average log likelihood -1.403202
[ Info: iteration 19, average log likelihood -1.403001
[ Info: iteration 20, average log likelihood -1.402860
[ Info: iteration 21, average log likelihood -1.402762
[ Info: iteration 22, average log likelihood -1.402695
[ Info: iteration 23, average log likelihood -1.402647
[ Info: iteration 24, average log likelihood -1.402612
[ Info: iteration 25, average log likelihood -1.402585
[ Info: iteration 26, average log likelihood -1.402563
[ Info: iteration 27, average log likelihood -1.402545
[ Info: iteration 28, average log likelihood -1.402530
[ Info: iteration 29, average log likelihood -1.402518
[ Info: iteration 30, average log likelihood -1.402507
[ Info: iteration 31, average log likelihood -1.402498
[ Info: iteration 32, average log likelihood -1.402490
[ Info: iteration 33, average log likelihood -1.402484
[ Info: iteration 34, average log likelihood -1.402478
[ Info: iteration 35, average log likelihood -1.402473
[ Info: iteration 36, average log likelihood -1.402469
[ Info: iteration 37, average log likelihood -1.402465
[ Info: iteration 38, average log likelihood -1.402462
[ Info: iteration 39, average log likelihood -1.402459
[ Info: iteration 40, average log likelihood -1.402457
[ Info: iteration 41, average log likelihood -1.402455
[ Info: iteration 42, average log likelihood -1.402453
[ Info: iteration 43, average log likelihood -1.402451
[ Info: iteration 44, average log likelihood -1.402450
[ Info: iteration 45, average log likelihood -1.402449
[ Info: iteration 46, average log likelihood -1.402447
[ Info: iteration 47, average log likelihood -1.402446
[ Info: iteration 48, average log likelihood -1.402446
[ Info: iteration 49, average log likelihood -1.402445
[ Info: iteration 50, average log likelihood -1.402444
┌ Info: EM with 100000 data points 50 iterations avll -1.402444
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4409872757992006
│     -1.4409158302561962
│      ⋮
└     -1.4024440003081975
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402584
[ Info: iteration 2, average log likelihood -1.402441
[ Info: iteration 3, average log likelihood -1.401466
[ Info: iteration 4, average log likelihood -1.392129
[ Info: iteration 5, average log likelihood -1.372795
[ Info: iteration 6, average log likelihood -1.361708
[ Info: iteration 7, average log likelihood -1.357360
[ Info: iteration 8, average log likelihood -1.354782
[ Info: iteration 9, average log likelihood -1.352772
[ Info: iteration 10, average log likelihood -1.351316
[ Info: iteration 11, average log likelihood -1.350392
[ Info: iteration 12, average log likelihood -1.349816
[ Info: iteration 13, average log likelihood -1.349424
[ Info: iteration 14, average log likelihood -1.349133
[ Info: iteration 15, average log likelihood -1.348889
[ Info: iteration 16, average log likelihood -1.348672
[ Info: iteration 17, average log likelihood -1.348477
[ Info: iteration 18, average log likelihood -1.348305
[ Info: iteration 19, average log likelihood -1.348152
[ Info: iteration 20, average log likelihood -1.348019
[ Info: iteration 21, average log likelihood -1.347902
[ Info: iteration 22, average log likelihood -1.347798
[ Info: iteration 23, average log likelihood -1.347703
[ Info: iteration 24, average log likelihood -1.347611
[ Info: iteration 25, average log likelihood -1.347516
[ Info: iteration 26, average log likelihood -1.347416
[ Info: iteration 27, average log likelihood -1.347310
[ Info: iteration 28, average log likelihood -1.347204
[ Info: iteration 29, average log likelihood -1.347104
[ Info: iteration 30, average log likelihood -1.347017
[ Info: iteration 31, average log likelihood -1.346942
[ Info: iteration 32, average log likelihood -1.346879
[ Info: iteration 33, average log likelihood -1.346824
[ Info: iteration 34, average log likelihood -1.346775
[ Info: iteration 35, average log likelihood -1.346731
[ Info: iteration 36, average log likelihood -1.346689
[ Info: iteration 37, average log likelihood -1.346649
[ Info: iteration 38, average log likelihood -1.346613
[ Info: iteration 39, average log likelihood -1.346581
[ Info: iteration 40, average log likelihood -1.346553
[ Info: iteration 41, average log likelihood -1.346530
[ Info: iteration 42, average log likelihood -1.346510
[ Info: iteration 43, average log likelihood -1.346495
[ Info: iteration 44, average log likelihood -1.346482
[ Info: iteration 45, average log likelihood -1.346472
[ Info: iteration 46, average log likelihood -1.346465
[ Info: iteration 47, average log likelihood -1.346458
[ Info: iteration 48, average log likelihood -1.346453
[ Info: iteration 49, average log likelihood -1.346448
[ Info: iteration 50, average log likelihood -1.346444
┌ Info: EM with 100000 data points 50 iterations avll -1.346444
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4025842383034826
│     -1.4024413887334526
│      ⋮
└     -1.3464444104331157
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346612
[ Info: iteration 2, average log likelihood -1.346438
[ Info: iteration 3, average log likelihood -1.345541
[ Info: iteration 4, average log likelihood -1.336285
[ Info: iteration 5, average log likelihood -1.311183
[ Info: iteration 6, average log likelihood -1.297576
[ Info: iteration 7, average log likelihood -1.293434
[ Info: iteration 8, average log likelihood -1.291320
[ Info: iteration 9, average log likelihood -1.289779
[ Info: iteration 10, average log likelihood -1.288495
[ Info: iteration 11, average log likelihood -1.287308
[ Info: iteration 12, average log likelihood -1.286078
[ Info: iteration 13, average log likelihood -1.284778
[ Info: iteration 14, average log likelihood -1.283591
[ Info: iteration 15, average log likelihood -1.282767
[ Info: iteration 16, average log likelihood -1.282212
[ Info: iteration 17, average log likelihood -1.281744
[ Info: iteration 18, average log likelihood -1.281279
[ Info: iteration 19, average log likelihood -1.280752
[ Info: iteration 20, average log likelihood -1.280076
[ Info: iteration 21, average log likelihood -1.279284
[ Info: iteration 22, average log likelihood -1.278535
[ Info: iteration 23, average log likelihood -1.278084
[ Info: iteration 24, average log likelihood -1.277837
[ Info: iteration 25, average log likelihood -1.277656
[ Info: iteration 26, average log likelihood -1.277489
[ Info: iteration 27, average log likelihood -1.277310
[ Info: iteration 28, average log likelihood -1.277086
[ Info: iteration 29, average log likelihood -1.276766
[ Info: iteration 30, average log likelihood -1.276274
[ Info: iteration 31, average log likelihood -1.275484
[ Info: iteration 32, average log likelihood -1.274185
[ Info: iteration 33, average log likelihood -1.272666
[ Info: iteration 34, average log likelihood -1.271724
[ Info: iteration 35, average log likelihood -1.271361
[ Info: iteration 36, average log likelihood -1.271187
[ Info: iteration 37, average log likelihood -1.271092
[ Info: iteration 38, average log likelihood -1.271041
[ Info: iteration 39, average log likelihood -1.271014
[ Info: iteration 40, average log likelihood -1.270998
[ Info: iteration 41, average log likelihood -1.270988
[ Info: iteration 42, average log likelihood -1.270981
[ Info: iteration 43, average log likelihood -1.270976
[ Info: iteration 44, average log likelihood -1.270973
[ Info: iteration 45, average log likelihood -1.270971
[ Info: iteration 46, average log likelihood -1.270970
[ Info: iteration 47, average log likelihood -1.270968
[ Info: iteration 48, average log likelihood -1.270968
[ Info: iteration 49, average log likelihood -1.270967
[ Info: iteration 50, average log likelihood -1.270967
┌ Info: EM with 100000 data points 50 iterations avll -1.270967
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3466118487845031
│     -1.3464379847650259
│      ⋮
└     -1.2709669617609727
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.271246
[ Info: iteration 2, average log likelihood -1.270962
[ Info: iteration 3, average log likelihood -1.270089
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.259577
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.235244
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.204022
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.207384
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.191320
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.210349
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.194671
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.203064
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.190120
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.199351
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.197473
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.203224
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.188959
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.196873
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.183949
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.204019
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.188621
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.197069
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.184009
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.193818
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.192082
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.198945
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.185378
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.194806
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.182430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.202973
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.187429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.196007
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.182718
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.192659
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.190640
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.197560
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.183962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.193512
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.181260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.201841
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.186412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.195215
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.182250
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.192494
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.190604
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.197550
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.183956
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.193507
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.181252
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.201839
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.186412
┌ Info: EM with 100000 data points 50 iterations avll -1.186412
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2712462305442598
│     -1.2709620507206152
│      ⋮
└     -1.1864122302035829
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.195569
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.182090
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.189765
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.160804
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.130777
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.108444
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110550
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084590
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│     13
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089817
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072370
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081619
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.094016
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.097194
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.082743
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.089516
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074902
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.100286
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.090383
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.088653
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.083085
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.081202
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.093768
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.096691
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.082016
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.089402
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.074794
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.100029
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.089494
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.098238
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.077260
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.079095
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.093687
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.096503
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.082489
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.089147
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.074755
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.100098
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.089719
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.098203
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.077211
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.079138
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.093890
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.097178
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.084334
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081068
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.071133
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.107753
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.092658
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.090638
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.074652
┌ Info: EM with 100000 data points 50 iterations avll -1.074652
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1955692343328106
│     -1.182090309932543
│      ⋮
└     -1.074652384719477
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4409131132448687
│     -1.4409872757992006
│     -1.4409158302561962
│     -1.4402893174321678
│      ⋮
│     -1.092657653621788
│     -1.090637706679593
└     -1.074652384719477
32×26 Array{Float64,2}:
  0.0628553     0.0535479     0.0254635    0.00451119    0.0726704    0.123049     0.068939     -0.00745809   0.100706      0.0120243   -0.0884587   -0.0672894    0.0809609   0.0463646   -0.0337766   -0.136028   -0.0144676    -0.0459522    0.0288928    0.13529      0.108399    -0.0424199    -0.0487622    0.0616985    -0.0261784    0.17652
 -0.123042     -0.0490524     0.0276856   -0.172308      0.0137777    0.00259054   0.152314      0.154925     0.00143662   -0.121947     0.0551127    0.0300123   -0.096341    0.0173824    0.196949    -0.0606927  -0.0387038    -0.0271185   -0.0369648   -0.00548521  -0.129616     0.102042     -0.114972     0.00590824   -0.0341       0.0396591
 -0.00168762    0.31925      -0.0723991   -0.0305708    -0.020385     0.156685    -0.0267089    -0.0258739   -0.101839     -0.156904    -0.0398084    0.05382      0.0381172  -0.146788    -0.179241     0.164415   -0.0388502    -0.667746     0.00885103   0.114316    -0.0422278    0.415306     -0.0407567   -0.0570308     0.0543986   -0.12531
  0.000217932   0.318897      0.0268249   -0.0363354     0.0585487    0.159507    -0.013156     -0.0263274   -0.227128      0.500433    -0.209061     0.114151    -0.328783   -0.156937    -0.172466     0.163375   -0.0464956     1.153       -0.130941    -0.108248    -0.00639432   0.0683195    -0.121643     0.116585      0.0382507   -0.0514511
  0.0797877    -0.0599541    -0.16167     -0.111147      0.147785     0.0444843    0.0344666     0.0283897    0.0376376     0.0345851   -0.0688654    0.0302301   -0.136335   -0.102694     0.13122     -0.0739899   0.00668391    0.0783185   -0.0993655    0.11195     -0.138922     0.056668     -0.0997092    0.105481     -0.00215969  -0.0479068
  0.0847926    -0.0217761     0.0221205   -0.0752075    -0.0317051   -0.082787     0.137744     -0.0380125   -0.167701      0.171796    -0.107656    -0.0654541    0.0167929  -0.0207085   -0.0389663    0.0725656   0.0137615    -0.0167272   -0.159508     0.141313    -0.0571601   -0.000989316  -0.0388625    0.110164      0.12453      0.0216745
  0.100901      0.0270251    -0.0689634   -0.0169108     0.0989371   -0.136043     0.105413     -0.0986943   -0.0507981    -0.0787772    0.0600239   -0.149314    -0.203821   -0.0645553    0.25925     -0.0371357   0.022481      0.112435     0.0605848    0.142663     0.00346371  -0.0844658     0.00972497  -0.0559759    -0.166167    -0.0266961
  0.0575065    -0.0554843     0.0533078   -0.10008      -0.0528613   -0.0990593    0.209394      0.0654586    0.0222829    -0.00739988   0.0742535   -0.0377288   -0.0446257  -0.0901546    0.0571131    0.0577178  -0.157415      0.0427824    0.0125298    0.0340479    0.0422528    0.00012395    0.018772    -0.0723016    -0.123921     0.0104701
 -0.196082      0.10122       0.209891     0.000415636  -0.0436743   -0.0602597   -0.128048     -0.182329    -0.262518     -0.0211679   -0.754521     0.0866196   -0.0685392  -0.0588287   -0.0781885    0.094894   -0.201936      0.0785127    0.0657133   -0.0355599    0.0831014    0.0413585     0.133768    -0.168533      0.0891408    0.0062937
 -0.0834767    -0.0414462     0.0286405   -0.00422497   -0.0275937   -0.0782598   -0.172405     -0.202628    -0.131129     -0.0485202    0.580942     0.0112626   -0.182679    0.134922    -0.0306952    0.0533529  -0.142593     -0.0981354    0.0860525    0.0265203    0.0768634   -0.0114117     0.095835    -0.174848      0.0865696   -0.0613821
 -0.0260944    -0.0970297    -0.173734    -0.988927     -0.0122848    0.0946086    0.000306303  -0.0406478   -0.239313     -0.024984    -0.0859679   -0.168133     0.0729939  -0.150657     0.125378     0.045517   -0.0373071    -0.0446298    0.285682    -0.0250506    0.106308     0.0697872    -0.0378322   -0.030555      0.00767657  -0.154496
 -0.0291269    -0.063701     -0.17156      0.496328     -0.0216067    0.0948537    0.0122861    -0.0385425   -0.0605068    -0.0222113   -0.0543553   -0.0867499   -0.0877991  -0.149238     0.134546     0.0454857  -0.0339623    -0.0839057    0.285887     0.00851744   0.0503367    0.0677076    -0.0388136   -0.0307499     0.0102537   -0.217914
 -0.0499085     0.0590516     0.0422531    0.22668       0.0821673   -0.0268269    0.423011     -0.115619    -0.270776     -0.212025    -0.103515    -0.0546166    0.199282   -0.0587087   -0.00726873  -0.115772    0.0752647     0.20638     -0.00772391   0.0824086   -0.145176    -0.0494412     0.0347698   -0.000399582  -0.0674091    0.0228386
 -0.0724205     0.0203339     0.0480362    0.275561      0.0795055   -0.0237629   -0.431082     -0.114759    -0.271104      0.352604    -0.0555731   -0.0522371   -0.378554   -0.0575387   -0.00880259   0.129074    0.072389      0.190175     0.0641868    0.071969    -0.147898    -0.0250672     0.0380624   -0.000277655  -0.0330617    0.0513137
  0.153041     -0.1472        0.012265     0.116606     -0.0601716   -0.0463697    0.134731      0.0480801   -0.105069     -0.0576089    0.0354056    0.0857631   -0.147018   -0.240074     0.152933    -0.0767905   0.246119      0.0868775    0.041481     0.317394     0.766069    -0.00247197    0.0713114   -0.0907226     0.0791135   -0.558967
  0.161719      0.394353     -0.2526       0.115823     -0.0615808    0.0508711    0.146737      0.0519243   -0.105389     -0.0565739    0.0618311   -0.448506    -0.146755    0.377877    -0.218735    -0.0696023   0.218445     -0.0270874    0.0243604    0.212568    -0.893258     0.0384493    -0.135309    -0.0910044     0.0989455    0.646232
  0.108373     -0.0361583     0.0635561   -0.0720724    -0.088725     0.0365951   -0.0921142    -0.0136659   -0.0350978    -0.0920865   -0.0935193   -0.0599041   -0.164465    0.120222    -0.170885    -0.173488    0.0835368    -0.00319194  -0.015178     0.0991709   -0.0204301   -0.192404     -0.0503489   -0.13783      -0.16107      0.0321906
 -0.00119457   -0.0334286     0.0239797    0.0823007    -0.0110396    0.0265139   -0.0481468    -0.021589    -0.0441583    -0.0321615    0.00711673   0.0596471    0.0582437  -0.0339763    0.144801    -0.0646755   0.00592738    0.125728     0.0132377    0.0506132   -0.0466142    0.0222783     0.01142     -0.0886407    -0.0706967    0.0131277
  0.081555     -0.0563212     0.0369185   -0.0426933    -0.0263948   -0.0240105    0.00541298    0.0201402   -0.0668787    -0.0305381   -0.0287907    0.136657     0.0389698   0.057401     0.0504849    0.0297491   0.0911713     0.0527371   -0.0179501   -0.0646477    0.0616693    0.0523996     0.036702    -0.0850434     0.033324     0.100421
  0.0998516     0.0471742    -0.018226    -0.0900419     0.00612749  -0.0156594   -0.0577945    -0.0105343   -0.141859      0.0644207    0.0224399    0.031516    -0.0898306   0.0739432   -0.0118445   -0.0142113  -0.0292422    -0.00651749  -0.0118164   -0.00107386  -0.0524364   -0.0548132     0.0538319    0.00279473   -0.00769652   0.00968397
  0.0976363     0.026986     -0.0597319    0.0984283     0.151291    -0.0203399   -0.120315     -0.136342     0.000111337  -0.0778321   -0.0643183   -0.0546      -0.109892   -0.171022     0.222007     0.110612   -0.0673159    -0.0442901    0.0614149    0.101552    -0.0301752    0.145808      0.0904692   -0.580074     -0.0496046    0.128889
 -0.130193     -0.027339     -0.18752      0.29793       0.12719      0.0115615   -0.164263      0.0498927   -0.0571686    -0.11706     -0.0408114    0.0110066   -0.0851301   0.0961617    0.227196     0.118136    0.000592256  -0.00689775  -0.206396     0.0273414   -0.0263638    0.201199      0.106256     0.498846     -0.0840024    0.1443
  0.0373334    -0.138159     -0.0569818    0.0207416    -0.0718139    0.0633248   -0.063993      0.0425001    0.0529606     0.0354275    0.039493    -0.0238272   -0.153629   -0.00238966  -0.0323011    0.0798987  -0.0829365     0.00532996  -0.0471823   -0.190663     0.0593224    0.0407284    -0.0515013    0.193026     -0.0977125    0.0368934
  0.1126       -0.00749624    0.0571173    0.0376119    -0.0928791   -0.13736      0.0659471     0.0278238   -0.0162949    -0.156032    -0.0269572    0.249804    -0.155115   -0.030391     0.113932    -0.0695066  -0.0712307     0.141595     0.0875573    0.123501     0.0104298   -0.0880197     0.032251     0.0420106     0.0834329    0.0205655
  0.0166222     0.000811468   0.0374465    0.0333692     0.200054     0.0299314    0.0430797     0.077784     0.219475      0.0790654    0.147437     0.207563     0.0758924  -0.104731     0.193605     0.0588491  -0.188915     -0.158467     0.103354     0.0575727    0.0494205    0.153164      0.0824081   -0.0485504    -0.013167    -0.204101
  0.0484285     0.102175      0.0938383   -0.0822408     0.045112     0.0595746    0.0360395    -0.0682767   -0.0570712     0.0141991    0.0532759   -0.00402748   0.011721   -0.00785971   0.0150182    0.0967541   0.00734287    0.0269628   -0.0122078   -0.00275956   0.0589422    0.00123558   -0.0886387    0.042416     -0.0294132   -0.0294306
  0.0595709    -0.205106      0.0398648   -0.0824691    -0.0026573    0.0673907   -0.101505     -0.0773087    0.0395013    -0.0981184   -0.0932978   -0.11157     -0.0334378   0.00459813  -0.146646    -0.0605811  -0.134578      0.095774    -0.0683708    0.121072     0.109006     0.075722      0.214878     0.0691446     0.3502      -0.035558
  0.090166      0.109748      0.0439778   -0.0899227     0.0347302    0.235969    -0.125573     -0.117529     0.162982     -0.0199425   -0.00464604  -0.0666593   -0.0715203  -0.0448948   -0.0147031    0.056879    0.00456564   -0.0477808   -0.072272    -0.203934    -0.0522599   -0.102189     -0.0835838   -0.0282722    -0.12289      0.0145458
  0.0127045     0.0832092    -0.00810875  -0.174676      0.0633682    0.00621237   0.0254582    -0.0711646    0.0237269    -0.0352184   -0.0199134   -0.179204    -0.0429171   0.259206    -0.00919868   0.0389351   0.0531509     0.0257393    0.0536233   -0.0964683   -0.160019     0.0734495     0.1116       0.10794       0.0424344   -0.00345042
 -0.101963      0.125297      0.174287    -0.105942      0.141952     0.171929    -0.0966199    -0.0209247   -0.105598      0.107786    -0.0778948   -0.108516     0.147445    0.159187     0.071246     0.0629288  -0.192192     -0.0324755    0.0219921    0.0132656    0.0255658    0.125033     -0.0235836    0.158593     -0.0327213    0.00156595
 -0.0621866     0.0621411     0.140584     0.0350408     0.113244    -0.192504    -0.0963031    -0.41188      0.174765     -0.0927088    0.0449275   -0.00153203  -0.0921396   0.122446     0.159243     0.0309168  -0.0587363    -0.0851489    0.102674     0.132138    -0.0989677   -0.071216      0.160025    -0.117007     -0.00412544  -0.0667167
 -0.0772021     0.0432988     0.153799     0.0581271     0.124043    -0.20046      0.0343246     0.499071     0.0517102    -0.100564    -0.0263998   -0.0619119   -0.116765    0.11139      0.177514     0.0215208  -0.123506      0.0228675   -0.100594     0.116172     0.252725     0.12348       0.0472151    0.003248     -0.0808812    0.0309201[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077322
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.065206
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.077204
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.065163
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.077202
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.065162
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.077201
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.065162
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077201
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     16
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.065162
┌ Info: EM with 100000 data points 10 iterations avll -1.065162
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.781568e+05
      1       7.267244e+05      -2.514324e+05 |       32
      2       6.890994e+05      -3.762500e+04 |       32
      3       6.712150e+05      -1.788439e+04 |       32
      4       6.602876e+05      -1.092743e+04 |       32
      5       6.536152e+05      -6.672412e+03 |       32
      6       6.497029e+05      -3.912225e+03 |       32
      7       6.476420e+05      -2.060914e+03 |       32
      8       6.464508e+05      -1.191190e+03 |       32
      9       6.456858e+05      -7.650192e+02 |       32
     10       6.452125e+05      -4.733153e+02 |       32
     11       6.448242e+05      -3.882946e+02 |       32
     12       6.444954e+05      -3.287634e+02 |       32
     13       6.440841e+05      -4.113493e+02 |       32
     14       6.434882e+05      -5.958607e+02 |       32
     15       6.428163e+05      -6.718722e+02 |       32
     16       6.421985e+05      -6.177986e+02 |       32
     17       6.417902e+05      -4.083660e+02 |       32
     18       6.415092e+05      -2.810305e+02 |       32
     19       6.413369e+05      -1.722141e+02 |       32
     20       6.412287e+05      -1.082242e+02 |       32
     21       6.411633e+05      -6.545318e+01 |       32
     22       6.411183e+05      -4.496152e+01 |       32
     23       6.410744e+05      -4.391453e+01 |       32
     24       6.410181e+05      -5.632005e+01 |       32
     25       6.409182e+05      -9.987492e+01 |       32
     26       6.406972e+05      -2.209607e+02 |       31
     27       6.403061e+05      -3.911619e+02 |       32
     28       6.394961e+05      -8.099211e+02 |       32
     29       6.387027e+05      -7.934171e+02 |       32
     30       6.385100e+05      -1.927398e+02 |       30
     31       6.384680e+05      -4.202829e+01 |       32
     32       6.384453e+05      -2.264746e+01 |       30
     33       6.384351e+05      -1.018455e+01 |       29
     34       6.384292e+05      -5.949904e+00 |       29
     35       6.384242e+05      -4.963615e+00 |       26
     36       6.384140e+05      -1.017339e+01 |       24
     37       6.383896e+05      -2.440727e+01 |       28
     38       6.383354e+05      -5.422275e+01 |       28
     39       6.381925e+05      -1.428705e+02 |       32
     40       6.377399e+05      -4.525929e+02 |       32
     41       6.368894e+05      -8.505158e+02 |       32
     42       6.360810e+05      -8.083853e+02 |       32
     43       6.357081e+05      -3.729781e+02 |       32
     44       6.356283e+05      -7.973454e+01 |       31
     45       6.356059e+05      -2.239619e+01 |       29
     46       6.355958e+05      -1.013803e+01 |       28
     47       6.355904e+05      -5.440240e+00 |       27
     48       6.355867e+05      -3.665840e+00 |       29
     49       6.355831e+05      -3.592776e+00 |       25
     50       6.355813e+05      -1.807031e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 635581.293925288)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339022
[ Info: iteration 2, average log likelihood -1.302621
[ Info: iteration 3, average log likelihood -1.265406
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.223344
[ Info: iteration 5, average log likelihood -1.186083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.115447
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     13
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.100308
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.130453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.100152
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059438
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     11
│     13
│     14
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.049141
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.124673
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.070114
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.091032
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.048394
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     14
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.064195
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.138308
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.084374
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     13
│     14
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.049202
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.108115
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.082604
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     21
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.066506
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.102718
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069423
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     13
│     14
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.051017
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.092229
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     18
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.055248
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.059456
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.069603
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     18
│     21
│     22
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.018498
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.089241
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.110294
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.060941
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     13
│     21
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.028505
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.101416
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     18
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.046232
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.070740
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.079156
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     11
│     14
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047859
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085056
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.087637
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     14
│     18
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.035433
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.071253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.100123
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     11
│     18
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.039476
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.051746
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.087747
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.039204
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      8
│     11
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.004698
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.122015
┌ Info: EM with 100000 data points 50 iterations avll -1.122015
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.10321     -0.036536     0.0635006   -0.0678649   -0.0865325    0.0381281   -0.0902542   -0.0141321    -0.0392358    -0.0935718   -0.0938936   -0.0567531   -0.163087    0.117084    -0.169569    -0.16551      0.0842926   -0.00215372   -0.0145331   0.100043    -0.0220962   -0.186985     -0.0492021   -0.137654    -0.158442     0.0332021
  0.0174801    0.0492384    0.0616548   -0.016609     0.052436     0.073696     0.201122    -0.12426      -0.100054      0.0660967    0.016042     0.0324378   -0.0259928  -0.0519613   -0.0122632    0.0249864   -0.0420386    0.00901284   -0.0217118  -0.186397     0.113707     0.0194387    -0.0871895    0.0534456    0.00850341  -0.11488
  0.0175165    0.00350935   0.0353291    0.0306245    0.194409     0.0327923    0.0438879    0.0768873     0.218025      0.0779449    0.144967     0.20471      0.0758439  -0.100933     0.194013     0.0588884   -0.181638    -0.153774      0.103603    0.0580015    0.0508518    0.153173      0.0800224   -0.050638    -0.0123002   -0.202536
  0.0978416    0.0706152    0.0960368    0.0328524   -0.0354632   -0.128491    -0.038472    -0.197808     -0.0859045     0.0520953   -0.013355    -0.192457    -0.108494   -0.0107884    0.0451618    0.0581209    0.0413844    0.152488     -0.020746    0.0542173    0.0546539   -0.156417     -0.0202311   -0.0826104    0.0186675    0.0390414
 -0.0862523    0.0903386    0.158524    -0.0256273    0.12688     -0.00177006  -0.0766918   -0.0117589     0.0112669     0.00715313  -0.0369325   -0.0756316    0.0322068   0.134578     0.121662     0.0430031   -0.149178    -0.0380723     0.0161674   0.0692364    0.0453037    0.0730174     0.0395471    0.0522963   -0.0360341   -0.0159084
  0.0773913   -0.059032    -0.179096    -0.108419     0.146359     0.0464178    0.0345495    0.0312771     0.0428986     0.0216767   -0.069027     0.0290356   -0.137845   -0.0994841    0.136951    -0.0815291    0.00605195   0.0818315    -0.092813    0.126238    -0.138195     0.0531213    -0.097679     0.109276    -0.00250926  -0.0522483
  0.0587022   -0.0483221   -0.0200693    0.146557    -0.0408865    0.0457936   -0.0711571    0.0856959    -0.000498912   0.203729     0.00609445   0.0267775   -0.207595    0.0322479    0.0497084    0.123593    -0.0165049    0.138742     -0.0317006  -0.295764     0.0309204    0.0959727     0.0472282    0.159939     0.0433353    0.0104205
  0.0631387    0.186617     0.0970432   -0.163512     0.0440636    0.0941105   -0.15881     -0.0413761     0.0447497    -0.101578     0.0768029   -0.057515     0.0812647   0.0168163    0.0759157    0.141514     0.0232448   -0.000877995   0.068357    0.0960845   -0.0526872    0.00583923   -0.075717     0.0301819   -0.0680835    0.0436718
 -0.00671224   0.0193403   -0.11083      0.20096      0.131327    -0.00189154  -0.133964    -0.0459418    -0.0298365    -0.0989005   -0.0594497   -0.0274141   -0.0963012  -0.0501476    0.216046     0.120052    -0.0308428   -0.0246056    -0.0752048   0.0782153   -0.0347696    0.165819      0.0948239   -0.060622    -0.0705577    0.135065
  0.131139     0.00732479  -0.0975046   -0.255169    -0.0917299   -0.0232591   -0.0953504    0.0745584    -0.160603      0.0921863    0.103364     0.0128011   -0.0651396  -0.0268429   -0.0850099   -0.0686576   -0.0210379   -0.140138      0.0812118  -0.018236    -0.161705     0.254317      0.0775474    0.00606018   0.00749375  -0.0332634
  0.050634     0.00849113   0.0341076   -0.0124866    0.0818744    0.119513     0.0884563   -0.0426969     0.091815     -0.018181    -0.0840076   -0.0556372    0.0432479   0.0605527   -0.0105852   -0.204251    -0.0405318   -0.0410573     0.0199895   0.191086     0.104172    -0.11027      -0.0550763    0.0669023   -0.0232405    0.247447
  0.0893828    0.109787     0.0434765   -0.0894038    0.0342836    0.234555    -0.127722    -0.122635      0.162702     -0.0196213   -0.0058004   -0.0665187   -0.0728291  -0.0452124   -0.0191496    0.0598797    0.00212748  -0.048193     -0.0727664  -0.204717    -0.0530659   -0.0986422    -0.0815248   -0.0265133   -0.123572     0.0120613
 -0.0241363   -0.0911703   -0.14038      0.0588657    0.0134934    0.0623104    0.0105089   -0.0502703    -0.170595     -0.0273498   -0.0796859   -0.110258    -0.041184   -0.129429     0.119358     0.0508206   -0.00519595  -0.0115644     0.249237   -0.017427     0.022247     0.0344985    -0.013687    -0.0235583   -0.00152613  -0.204487
  0.0128568    0.280167     0.00906149  -0.0105956    0.0129222    0.150109    -8.70529e-6  -0.0228899    -0.0284271     0.0974241   -0.179584     0.0917433    0.141744   -0.118452    -0.076711     0.118603    -0.0707386    0.131396     -0.0415803   0.006592     0.0297534    0.184643     -0.0818119    0.110459     0.0392372   -0.0466454
  0.0125286    0.0831978   -0.00940183  -0.176895     0.0632282    0.00513167   0.0264856   -0.0715287     0.0241011    -0.0342396   -0.0201957   -0.179347    -0.0441777   0.258664    -0.00941821   0.03877      0.0531161    0.0262923     0.0540602  -0.0966536   -0.160714     0.0742673     0.110089     0.107173     0.0423986   -0.00388031
  0.0729787   -0.0756763    0.0331245    0.00179316  -0.0860616   -0.0835827    0.127599     0.0615407    -0.13092      -0.1241       0.0508622    0.0441322    0.03762     0.122875     0.0326657    0.0479711    0.193629     0.31196       0.0414536  -0.0632768    0.0546094    0.00645667    0.00122553   0.0152631    0.0416509    0.00210622
  0.0587545   -0.204039     0.0398744   -0.0776151   -0.00240907   0.0664511   -0.101106    -0.0775605     0.0365713    -0.0983268   -0.0928439   -0.111027    -0.0335655   0.00171804  -0.144151    -0.0606606   -0.133984     0.095491     -0.0650486   0.122682     0.109674     0.074874      0.212444     0.0678685    0.348107    -0.035342
  0.0366576   -0.187652    -0.0643895   -0.0652503   -0.0888997    0.0731088   -0.0413521    0.0150824     0.0685743    -0.0845263    0.0453608   -0.0592786   -0.111887   -0.0308376   -0.0685098    0.0475487   -0.125825    -0.0743264    -0.0149417  -0.0920799    0.0857715   -0.0201363    -0.116672     0.197263    -0.17201      0.0514581
 -0.0156523   -0.00880416  -0.0166029   -0.0944347    0.0597744   -0.0626011    0.132243     0.0345516    -0.0242914    -0.0981062    0.0584707   -0.0626894   -0.146328   -0.0250845    0.22089     -0.0529217   -0.00585877   0.0385339     0.0152304   0.0721111   -0.0620974    0.00703245   -0.049737    -0.0245442   -0.0986252    0.00346973
  0.0568087   -0.0540117    0.0533939   -0.0982747   -0.0517318   -0.095295     0.207953     0.065298      0.0205937    -0.0103881    0.0730363   -0.0385263   -0.0446695  -0.0853445    0.0579696    0.0555531   -0.159342     0.0410322     0.0139478   0.0370963    0.0413927   -8.46395e-5    0.0195753   -0.0708771   -0.124677     0.009352
  0.0851131   -0.0345547    0.0378509    0.0178358   -0.0907356   -0.217564     0.0929949    0.0226675    -0.0129946    -0.271296    -0.00490286   0.292225    -0.121988   -0.018529     0.0758774   -0.151454    -0.0676289    0.132759      0.110297    0.254227    -0.0109589   -0.106802      0.0337422    0.0361444    0.0536622    0.029736
  0.00763351   0.0191465    0.0844032    0.0810068    0.0591274    0.0234891    0.142738    -0.0865847    -0.167825      0.0699175    0.00340164   0.0452723   -0.0143207  -0.0359645    0.00438356   0.094608    -0.00670928   0.0659825    -0.0399805  -0.0596878    0.184139    -0.0301953    -0.128375     0.0722286   -0.00438187  -0.122237
  0.124608     0.0978045   -0.0801803    0.093089    -0.0316773    0.0057207    0.155333     0.0557834    -0.0749354    -0.0600036    0.0362953   -0.155279    -0.111831    0.101846    -0.0289948   -0.113445     0.173957     0.0416555     0.0351334   0.311128    -0.0825471   -0.0183524    -0.04153     -0.0746391    0.0639189    0.137469
  0.0158432   -0.0281398   -0.00764945   0.0427      -0.0138808    0.0809903   -0.0643983   -0.0292223     0.0136803    -0.144829     0.0376988    0.0322947    0.0552779  -0.0768732    0.150264    -0.123117    -0.051925     0.103234      0.0528621   0.0463072   -0.117248     0.00663256    0.129027    -0.108054    -0.136289     0.0903858
 -0.0521766   -0.046144     0.0818039    0.221748     0.0354828   -0.0823134   -0.0367329    0.000227122  -0.192987      0.217199    -0.0682011    0.1751       0.0644014   0.0399871    0.116817    -0.0966003    0.235428     0.1672       -0.0115372   0.112888     0.0737044    0.0737546    -0.229933    -0.0792425    0.0317363   -0.202697
  0.0730623   -0.0352235    0.0752986   -0.0347503    0.0850119    0.0641793   -0.0493859   -0.0823633     0.00271895   -0.102074    -0.13148      0.214966     0.0472884   0.00678733   0.0460422   -0.00574995   0.0405266   -0.105187      0.0104331  -0.065521     0.0909332    0.0746776     0.147965    -0.184436     0.0213269    0.1749
 -0.0512472    0.133923     0.0326209    0.171237     0.056194     0.0304082    0.0024215   -0.0692628    -0.226956      0.115204    -0.0999912   -0.00734843  -0.0849253  -0.0710695   -0.0513689    0.0156939    0.0384053    0.215831      0.0171363   0.0882337   -0.102203    -0.0437538     0.018307    -0.0105111   -0.0103679    0.0271163
  0.123611     0.0469902   -0.106017    -0.0630916    0.153212     0.137586    -0.0480754    0.0918469    -0.187042     -0.0156109   -0.0217944    0.273141    -0.0769657   0.259041     0.0030811   -0.0510375   -0.20257     -0.095644     -0.0804648  -0.0835854   -0.0316944   -0.182162      0.0837608    0.0886685   -0.0389742   -0.000987065
  0.0829231   -0.0219997    0.0218355   -0.0748136   -0.0325897   -0.0838062    0.136616    -0.0364472    -0.168866      0.172688    -0.107747    -0.0631788    0.0190016  -0.0209638   -0.0398944    0.0728557    0.0138044   -0.017265     -0.162896    0.142263    -0.057502    -0.000750693  -0.0381324    0.111162     0.125308     0.0215377
  0.0155313    0.275636    -0.0181946   -0.0162684    0.00194891   0.156164    -0.0254695   -0.0282034    -0.125028      0.209288    -0.14442      0.0523811   -0.49487    -0.29172     -0.141138     0.217056    -0.0535956   -0.235668     -0.0224467  -0.0592299   -0.00102566   0.56214      -0.0782078   -0.0545477    0.0234704   -0.116176
  0.0443481   -0.0357864    0.00870815  -0.0812213   -0.0736492   -0.0497586   -0.0580025    0.0659939    -0.044793      0.168569    -0.0113722    0.154731     0.0238062   0.0429013    0.12308      0.0916699    0.0478238    0.00267178   -0.144546   -0.0401731    0.0251584   -0.0241878    -0.0194741   -0.0873261    0.0402963    0.115049
 -0.124982     0.020802     0.104551     0.0015882   -0.0358453   -0.0636842   -0.136816    -0.180151     -0.194648     -0.0430316   -0.0906861    0.0467127   -0.12604     0.0385187   -0.0535277    0.0665842   -0.153338    -0.00998248    0.0798847  -0.00564592   0.0824183    0.0160125     0.110047    -0.163833     0.0860586   -0.0280396[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.075213
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     13
│     14
│     18
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.017528
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     18
│     21
│     22
│     25
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.010085
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     13
│     18
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.018377
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     18
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.040890
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     13
│     18
│     21
│     22
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.988985
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     14
│     18
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.035482
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      8
│     13
│     18
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.002336
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     18
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.054506
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     13
│     18
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.022171
┌ Info: EM with 100000 data points 10 iterations avll -1.022171
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0188499    0.144531     0.0707244    0.0281686   -0.0531897   -0.107359      0.027999     0.0569175   -0.0416008   -0.0942803   -0.153425    -0.105443     0.0247015   -0.108366    -0.110986   -0.0449854   -0.0133131   -0.128637     0.0229379   -0.0647661   -0.0303476    0.0751155   -0.027721     0.300652     0.134042    -0.0270518
  0.112436     0.0308539   -0.155262     0.028828     0.0786697    0.0742175    -0.137975    -0.163343     0.200865     0.00997051   0.113271    -0.0222872    0.0879568   -0.0597231   -0.155409    0.177747     0.108206    -0.11138      0.0378699    0.0883197   -0.0299716   -0.0308253    0.00505795  -0.00659365   0.0136161    0.00852106
 -0.0755799   -0.0323146    0.0502844    0.00126302   0.072803    -0.0436461     0.10992     -0.0210891    0.125197    -0.0714245   -0.0325482    0.0323358   -0.139455    -0.10137      0.0826717   0.124676    -0.0615665   -0.196718    -0.0707982   -0.158967     0.0639895   -0.0879806   -0.0071296   -0.0143584    0.0358104    0.0280215
 -0.105132     0.0185852   -0.212491     0.0478204    0.172137    -0.0205491     0.125898     0.204584    -0.108787     0.017175     0.056123     0.102388     0.140338     0.127818     0.15087     0.0450837   -0.00437478   0.00428849   0.0208042    0.0162939    0.00652002  -0.00564803   0.00116225  -0.169995     0.0912667   -0.0864066
  0.128717    -0.09722      0.082116     0.147577     0.0341111    0.0439148    -0.0214719   -0.21824     -0.011788    -0.109228     0.101412    -0.0243315   -0.0118164   -0.127083     0.151554    0.104431    -0.13126     -0.0111721    0.139734    -0.0596288    0.122239     0.00458608   0.0722819   -0.0553422    0.129516     0.0119232
  0.125466     0.0903544    0.113896     0.187571     0.154003     0.0763882     0.0836815    0.10616     -0.0433886   -0.171225    -0.131547     0.201678     0.0716174   -0.168499     0.0498611  -0.0667055    0.159331     0.179688    -0.0181223   -0.245726    -0.0631564   -0.0745992    0.0308014   -0.0311443   -0.055928     0.00681771
  0.0703457    0.150389    -0.0135789    0.0977029    0.0596994   -0.024074     -0.154696    -0.0935686   -0.0267286   -0.219647     0.0753464    0.170979     0.150871     0.0123578    0.0565136   0.0918763   -0.109201     0.0578326    0.11506      0.0206522    0.086586     0.0780243    0.0482411   -0.074691    -0.121779    -0.0916458
 -0.126513    -0.154244    -0.0173302    0.0957722    0.00398103   0.0104282     0.0899321    0.0545381    0.0674829   -0.111253    -0.1042       0.0374498    0.124553     0.0915453    0.0316337   0.10636     -0.0977029    0.0374216    0.0324452    0.0107921   -0.0340122   -0.0696085   -0.0787492   -0.106592    -0.0811235    0.0386442
 -0.107757    -0.00521377   0.0565168   -0.0332212   -0.0507073   -0.0525451     0.0539074   -0.0661931   -0.218714    -0.0898434    0.12103      0.0394935   -0.208888     0.0438703   -0.0563553   0.0506167    0.0393767    0.0815979   -0.166438    -0.0684261    0.0403863   -0.0144859    0.0130761    0.0246981    0.0415102    0.0810241
  0.00802207   0.0628034    0.2461       0.0383159   -0.0953491   -0.064082      0.0920933   -0.0426707    0.0476476   -0.17102     -0.0281408   -0.0905415   -0.00259122  -0.0306107   -0.0603563   0.103006    -0.00279027   0.0188674   -0.00155084  -0.00847131   0.00715901  -0.189425    -0.209484    -0.0135603    0.0760136   -0.109228
  0.0504072   -0.0296651   -0.0886953    0.0366295    0.164583    -0.0772523     0.220549     0.0554412   -0.0319812   -0.124164     0.0194823   -0.193725     0.0538355    0.0260815   -0.172109    0.144264    -0.0106402    0.00622827   0.00468038  -0.0798706   -0.094202     0.0960567   -0.0257433    0.0954964    0.0657794   -0.0966244
 -0.0206717   -0.184607     0.0518313    0.0994051   -0.0843057   -0.0240552    -0.139193     0.228438     0.173533     0.0366101   -0.0601325    0.0525811   -0.0306715   -0.0139286    0.0672753  -0.0520489   -0.0611433    0.0337096    0.17432      0.0271056    0.120334     0.0053291    0.118922    -0.171829    -0.0371315   -0.0655519
 -0.160238    -0.0184126   -0.0255874   -0.10086     -0.00537995  -0.0736114    -0.0371571   -0.0940228    0.115392    -0.0315579   -0.0202551   -0.12662     -0.205719    -0.142075    -0.11398     0.229164    -0.0534119    0.140994    -0.118084    -0.133385    -0.0852269    0.127853     0.0927251   -0.0517508    0.164921    -0.00239945
  0.0990057   -0.0131453   -0.0361084    0.0329538    0.120522    -0.0184075     0.00754268  -0.185825    -0.00543111  -0.092255    -0.122431    -0.139507    -0.0686672   -0.0675443    0.057665    0.0810734   -0.170407    -0.0499537    0.153115    -0.0336556   -0.0994998    0.0106905   -0.0124153   -0.0908591   -0.0698758   -0.0891817
 -0.0809236    0.131695    -0.0727444    0.0943105    0.0809397   -0.0226367     0.079644    -0.0568027    0.114757    -0.0138492    0.296064    -0.0929621    0.0105282   -0.145869    -0.0616033   0.0221442    0.0361241    0.166668     0.0926284    0.0119026   -0.0605782    0.039507     0.246767     0.0334452    0.00110718  -0.0608809
  0.0259457    0.206398    -0.0436862   -0.18608     -0.115857    -0.0484386     0.0225832   -0.0410111    0.0248858   -0.213418     0.00438563  -0.194055    -0.255509     0.0580551    0.149364   -0.10569      0.00146089  -0.0291257   -0.0857926   -0.0198636    0.146633    -0.0619362    0.099474     0.0652526   -0.0587599   -0.215472
 -0.177264     0.0172812    0.242728    -0.0545984   -0.074248    -0.0742925    -0.158828     0.0173481   -0.154149     0.0115295    0.0778379    0.0332074   -0.104337     0.0997485    0.0881968  -0.0815352   -0.115514     0.148909    -0.0337858    0.0595664    0.0307775    0.0254903    0.106817    -0.00775473   0.0845951   -0.00726756
  0.0797057    0.0207313    0.00500092   0.0129499    0.0528841    0.0494521     0.0716736   -0.153167     0.0624394   -0.00247933  -0.0417503   -0.0679403    0.204411     0.0311868    0.164538    0.0261379   -0.0650829    0.0124205   -0.113943    -0.00480218   0.0862255   -0.109907    -0.144621    -0.100991     0.0858178    0.103792
  0.0020594    0.0582176   -0.0138805   -0.00983079  -0.0237765    0.0276723    -0.199477     0.139212    -0.0307749   -0.0386174    0.00876734  -0.0247135   -0.108306     0.0717472    0.0646585  -0.0130914   -0.00650741   0.0244407    0.0543581    0.114658     0.0556412    0.168087    -0.0912893    0.109847     0.0641591   -0.0101898
 -0.101685     0.161584     0.120576     0.0347852   -0.0718671    0.110661      0.0120688   -0.0473956    0.0424497   -0.0105896   -0.174669    -0.135367    -0.0900337    0.00568673   0.0927945  -0.00512296  -0.151145     0.064755     0.0315354   -0.0517459    0.16694      0.100417     0.0929187   -0.0448818   -0.0949241   -0.0962007
 -0.0562419   -0.0372464    0.0197152    0.0892176    0.0437579    0.184632      0.102344     0.0397769   -0.161186    -0.0553162   -0.0114727   -0.136203    -0.105715    -0.0584896   -0.0575502   0.0321902   -0.133923    -0.00515225  -0.0585758   -0.0368932   -0.0306444    0.0488157    0.0614784    0.0729918   -0.0159945   -0.0169789
  0.0325788    0.208197    -0.0642228   -0.0490773    0.00741225   0.0104622    -0.0421913    0.117786     0.131431    -0.242393     0.0631682   -0.184617     0.0346545    0.129078     0.0358813   0.180677     0.164589    -0.157309     0.0843789   -0.0269278   -0.0144502   -0.110403     0.140118     0.074504     0.109988     0.0953335
  0.0272035   -0.0546619    0.113998     0.105048     0.050531    -0.0754789    -0.0188638   -0.0718961    0.00882523   0.0608314    0.157056     0.0686411    0.0227839   -0.0301083   -0.0513715   0.0126964   -0.0285843    0.0568394    0.101513     0.0482548    0.0915176    0.156182    -0.0974345   -0.0706288    0.110427     0.0127334
 -0.0616383    0.0574148    0.0719089    0.124906     0.0265735    0.062333      0.128907    -0.0150803    0.101904     0.0294718   -0.078997    -0.109861     0.115837    -0.0447271    0.0786264   0.103151     0.0715929    0.00784711   0.0656053   -0.121589    -0.105716    -0.10885     -0.0316397   -0.138833    -0.0579965    0.0627185
  0.0875822    0.170638     0.0858179   -0.0611166    0.0727205   -0.0766014    -0.048681     0.0729985   -0.0995278   -0.0496375    0.0337888    0.156634    -0.065167    -0.0134119    0.0731215  -0.0921919   -0.229783    -0.140883     0.0323921    0.182237    -0.139877    -0.14853     -0.0912304   -0.0661436   -0.170926     0.0644767
 -0.170059    -0.0436806    0.0999194    0.0501834    0.0580968   -0.176616     -0.131934    -0.148011     0.128952     0.0284578   -0.222687     0.0440496    0.371701    -0.0227107    0.0529914   0.0216629   -0.0357137    0.175359    -0.078954     0.062748     0.00824321  -0.203785     0.189931    -0.0244342    0.0687352   -0.056703
 -0.193978     0.170759     0.151147     0.0658429   -0.0786441    0.0918614    -0.0829581    0.229873     0.089739     0.099205    -0.024355    -0.0698793    0.00156769   0.0535243   -0.0371136  -0.0757544    0.0709974   -0.126167     0.0455449    0.0612413   -0.101294     0.061533    -0.101747    -0.0192222   -0.0852242    0.0258359
 -0.0214539   -0.117677     0.0055162    0.0277767    0.0237058   -0.17776       0.0185923    0.00881764   0.132425    -0.037953     0.0504954    0.00201008   0.018444     0.0909437    0.0660504   0.0560363   -0.057588     0.127965     0.0839329   -0.0617903   -0.0679909   -0.0532315   -0.0158387   -0.170486    -0.160804    -0.0916741
 -0.0246025    0.106826    -0.0950593    0.00107333   0.0382756    0.0193604     0.0196176    0.0809769   -0.0567956    0.0177577   -0.0733689    0.137034     0.138095     0.00890499   0.160252   -0.106248    -0.051118    -0.00427757  -0.0416799    0.0375286    0.012863    -0.0925264    0.0531269    0.0188277   -0.0881386   -0.0995436
  0.108328     0.0532372   -0.00811849  -0.0276388    0.0406882   -0.179497     -0.0560482   -0.153734     0.0925388    0.0920017   -0.0477998    0.044429    -0.117277    -0.037137    -0.224588   -0.0886603   -0.0645418    0.0065417   -0.00907693   0.116825     0.0260861    0.01718     -0.131797    -0.0778454   -0.145289    -0.0350073
  0.0917113   -0.0125775   -0.0310429   -0.168862    -0.118612    -0.000150513   0.00500045  -0.0828149    0.0151668   -0.0359941    0.054372     0.0292439   -0.0679818    0.0568273    0.0298341   0.0709858    0.108481     0.00351078   0.0659753   -0.0431826   -0.00476571  -0.0260678   -0.0240943   -0.275214    -0.0300543    0.0841299
 -0.0503911   -0.0664475    0.0522107    0.229906    -0.0999171    0.0155046    -0.0976324   -0.0843042   -0.140105    -0.00113451   0.115655    -0.0240139    0.0937689    0.0940172   -0.10901     0.191975     0.112418    -0.103177     0.0865233    0.0756952    0.0656883    0.00110252  -0.0206668   -0.126276    -0.136864     0.0617581kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4258558526365686
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425875
[ Info: iteration 2, average log likelihood -1.425791
[ Info: iteration 3, average log likelihood -1.425726
[ Info: iteration 4, average log likelihood -1.425652
[ Info: iteration 5, average log likelihood -1.425566
[ Info: iteration 6, average log likelihood -1.425469
[ Info: iteration 7, average log likelihood -1.425371
[ Info: iteration 8, average log likelihood -1.425281
[ Info: iteration 9, average log likelihood -1.425208
[ Info: iteration 10, average log likelihood -1.425152
[ Info: iteration 11, average log likelihood -1.425113
[ Info: iteration 12, average log likelihood -1.425083
[ Info: iteration 13, average log likelihood -1.425058
[ Info: iteration 14, average log likelihood -1.425032
[ Info: iteration 15, average log likelihood -1.425002
[ Info: iteration 16, average log likelihood -1.424957
[ Info: iteration 17, average log likelihood -1.424883
[ Info: iteration 18, average log likelihood -1.424751
[ Info: iteration 19, average log likelihood -1.424511
[ Info: iteration 20, average log likelihood -1.424084
[ Info: iteration 21, average log likelihood -1.423399
[ Info: iteration 22, average log likelihood -1.422497
[ Info: iteration 23, average log likelihood -1.421605
[ Info: iteration 24, average log likelihood -1.420962
[ Info: iteration 25, average log likelihood -1.420603
[ Info: iteration 26, average log likelihood -1.420430
[ Info: iteration 27, average log likelihood -1.420351
[ Info: iteration 28, average log likelihood -1.420315
[ Info: iteration 29, average log likelihood -1.420299
[ Info: iteration 30, average log likelihood -1.420292
[ Info: iteration 31, average log likelihood -1.420288
[ Info: iteration 32, average log likelihood -1.420287
[ Info: iteration 33, average log likelihood -1.420286
[ Info: iteration 34, average log likelihood -1.420285
[ Info: iteration 35, average log likelihood -1.420285
[ Info: iteration 36, average log likelihood -1.420284
[ Info: iteration 37, average log likelihood -1.420284
[ Info: iteration 38, average log likelihood -1.420284
[ Info: iteration 39, average log likelihood -1.420284
[ Info: iteration 40, average log likelihood -1.420284
[ Info: iteration 41, average log likelihood -1.420283
[ Info: iteration 42, average log likelihood -1.420283
[ Info: iteration 43, average log likelihood -1.420283
[ Info: iteration 44, average log likelihood -1.420283
[ Info: iteration 45, average log likelihood -1.420283
[ Info: iteration 46, average log likelihood -1.420283
[ Info: iteration 47, average log likelihood -1.420283
[ Info: iteration 48, average log likelihood -1.420283
[ Info: iteration 49, average log likelihood -1.420283
[ Info: iteration 50, average log likelihood -1.420283
┌ Info: EM with 100000 data points 50 iterations avll -1.420283
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4258751231533897
│     -1.4257905059508227
│      ⋮
└     -1.4202826331795726
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420302
[ Info: iteration 2, average log likelihood -1.420215
[ Info: iteration 3, average log likelihood -1.420147
[ Info: iteration 4, average log likelihood -1.420068
[ Info: iteration 5, average log likelihood -1.419974
[ Info: iteration 6, average log likelihood -1.419869
[ Info: iteration 7, average log likelihood -1.419762
[ Info: iteration 8, average log likelihood -1.419665
[ Info: iteration 9, average log likelihood -1.419584
[ Info: iteration 10, average log likelihood -1.419518
[ Info: iteration 11, average log likelihood -1.419465
[ Info: iteration 12, average log likelihood -1.419417
[ Info: iteration 13, average log likelihood -1.419370
[ Info: iteration 14, average log likelihood -1.419324
[ Info: iteration 15, average log likelihood -1.419275
[ Info: iteration 16, average log likelihood -1.419226
[ Info: iteration 17, average log likelihood -1.419178
[ Info: iteration 18, average log likelihood -1.419132
[ Info: iteration 19, average log likelihood -1.419091
[ Info: iteration 20, average log likelihood -1.419055
[ Info: iteration 21, average log likelihood -1.419026
[ Info: iteration 22, average log likelihood -1.419002
[ Info: iteration 23, average log likelihood -1.418983
[ Info: iteration 24, average log likelihood -1.418968
[ Info: iteration 25, average log likelihood -1.418956
[ Info: iteration 26, average log likelihood -1.418947
[ Info: iteration 27, average log likelihood -1.418939
[ Info: iteration 28, average log likelihood -1.418932
[ Info: iteration 29, average log likelihood -1.418926
[ Info: iteration 30, average log likelihood -1.418921
[ Info: iteration 31, average log likelihood -1.418916
[ Info: iteration 32, average log likelihood -1.418913
[ Info: iteration 33, average log likelihood -1.418909
[ Info: iteration 34, average log likelihood -1.418906
[ Info: iteration 35, average log likelihood -1.418903
[ Info: iteration 36, average log likelihood -1.418900
[ Info: iteration 37, average log likelihood -1.418897
[ Info: iteration 38, average log likelihood -1.418895
[ Info: iteration 39, average log likelihood -1.418893
[ Info: iteration 40, average log likelihood -1.418891
[ Info: iteration 41, average log likelihood -1.418889
[ Info: iteration 42, average log likelihood -1.418887
[ Info: iteration 43, average log likelihood -1.418885
[ Info: iteration 44, average log likelihood -1.418883
[ Info: iteration 45, average log likelihood -1.418881
[ Info: iteration 46, average log likelihood -1.418879
[ Info: iteration 47, average log likelihood -1.418878
[ Info: iteration 48, average log likelihood -1.418876
[ Info: iteration 49, average log likelihood -1.418875
[ Info: iteration 50, average log likelihood -1.418873
┌ Info: EM with 100000 data points 50 iterations avll -1.418873
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420301705017211
│     -1.420214596077536
│      ⋮
└     -1.4188729445166839
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418885
[ Info: iteration 2, average log likelihood -1.418822
[ Info: iteration 3, average log likelihood -1.418774
[ Info: iteration 4, average log likelihood -1.418720
[ Info: iteration 5, average log likelihood -1.418658
[ Info: iteration 6, average log likelihood -1.418586
[ Info: iteration 7, average log likelihood -1.418506
[ Info: iteration 8, average log likelihood -1.418423
[ Info: iteration 9, average log likelihood -1.418340
[ Info: iteration 10, average log likelihood -1.418262
[ Info: iteration 11, average log likelihood -1.418191
[ Info: iteration 12, average log likelihood -1.418126
[ Info: iteration 13, average log likelihood -1.418066
[ Info: iteration 14, average log likelihood -1.418011
[ Info: iteration 15, average log likelihood -1.417960
[ Info: iteration 16, average log likelihood -1.417912
[ Info: iteration 17, average log likelihood -1.417867
[ Info: iteration 18, average log likelihood -1.417826
[ Info: iteration 19, average log likelihood -1.417788
[ Info: iteration 20, average log likelihood -1.417753
[ Info: iteration 21, average log likelihood -1.417721
[ Info: iteration 22, average log likelihood -1.417693
[ Info: iteration 23, average log likelihood -1.417667
[ Info: iteration 24, average log likelihood -1.417643
[ Info: iteration 25, average log likelihood -1.417622
[ Info: iteration 26, average log likelihood -1.417602
[ Info: iteration 27, average log likelihood -1.417583
[ Info: iteration 28, average log likelihood -1.417566
[ Info: iteration 29, average log likelihood -1.417549
[ Info: iteration 30, average log likelihood -1.417533
[ Info: iteration 31, average log likelihood -1.417518
[ Info: iteration 32, average log likelihood -1.417503
[ Info: iteration 33, average log likelihood -1.417489
[ Info: iteration 34, average log likelihood -1.417475
[ Info: iteration 35, average log likelihood -1.417462
[ Info: iteration 36, average log likelihood -1.417448
[ Info: iteration 37, average log likelihood -1.417435
[ Info: iteration 38, average log likelihood -1.417421
[ Info: iteration 39, average log likelihood -1.417408
[ Info: iteration 40, average log likelihood -1.417395
[ Info: iteration 41, average log likelihood -1.417381
[ Info: iteration 42, average log likelihood -1.417368
[ Info: iteration 43, average log likelihood -1.417354
[ Info: iteration 44, average log likelihood -1.417341
[ Info: iteration 45, average log likelihood -1.417327
[ Info: iteration 46, average log likelihood -1.417313
[ Info: iteration 47, average log likelihood -1.417299
[ Info: iteration 48, average log likelihood -1.417285
[ Info: iteration 49, average log likelihood -1.417270
[ Info: iteration 50, average log likelihood -1.417256
┌ Info: EM with 100000 data points 50 iterations avll -1.417256
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188849904305907
│     -1.4188220673292553
│      ⋮
└     -1.4172561965119175
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417251
[ Info: iteration 2, average log likelihood -1.417175
[ Info: iteration 3, average log likelihood -1.417103
[ Info: iteration 4, average log likelihood -1.417021
[ Info: iteration 5, average log likelihood -1.416922
[ Info: iteration 6, average log likelihood -1.416804
[ Info: iteration 7, average log likelihood -1.416670
[ Info: iteration 8, average log likelihood -1.416528
[ Info: iteration 9, average log likelihood -1.416388
[ Info: iteration 10, average log likelihood -1.416255
[ Info: iteration 11, average log likelihood -1.416133
[ Info: iteration 12, average log likelihood -1.416023
[ Info: iteration 13, average log likelihood -1.415925
[ Info: iteration 14, average log likelihood -1.415839
[ Info: iteration 15, average log likelihood -1.415763
[ Info: iteration 16, average log likelihood -1.415697
[ Info: iteration 17, average log likelihood -1.415640
[ Info: iteration 18, average log likelihood -1.415590
[ Info: iteration 19, average log likelihood -1.415546
[ Info: iteration 20, average log likelihood -1.415507
[ Info: iteration 21, average log likelihood -1.415472
[ Info: iteration 22, average log likelihood -1.415440
[ Info: iteration 23, average log likelihood -1.415412
[ Info: iteration 24, average log likelihood -1.415386
[ Info: iteration 25, average log likelihood -1.415362
[ Info: iteration 26, average log likelihood -1.415339
[ Info: iteration 27, average log likelihood -1.415319
[ Info: iteration 28, average log likelihood -1.415299
[ Info: iteration 29, average log likelihood -1.415281
[ Info: iteration 30, average log likelihood -1.415264
[ Info: iteration 31, average log likelihood -1.415248
[ Info: iteration 32, average log likelihood -1.415233
[ Info: iteration 33, average log likelihood -1.415218
[ Info: iteration 34, average log likelihood -1.415205
[ Info: iteration 35, average log likelihood -1.415192
[ Info: iteration 36, average log likelihood -1.415180
[ Info: iteration 37, average log likelihood -1.415169
[ Info: iteration 38, average log likelihood -1.415158
[ Info: iteration 39, average log likelihood -1.415148
[ Info: iteration 40, average log likelihood -1.415139
[ Info: iteration 41, average log likelihood -1.415130
[ Info: iteration 42, average log likelihood -1.415121
[ Info: iteration 43, average log likelihood -1.415114
[ Info: iteration 44, average log likelihood -1.415106
[ Info: iteration 45, average log likelihood -1.415099
[ Info: iteration 46, average log likelihood -1.415093
[ Info: iteration 47, average log likelihood -1.415087
[ Info: iteration 48, average log likelihood -1.415081
[ Info: iteration 49, average log likelihood -1.415075
[ Info: iteration 50, average log likelihood -1.415070
┌ Info: EM with 100000 data points 50 iterations avll -1.415070
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172510845003217
│     -1.4171748994523203
│      ⋮
└     -1.4150702894977538
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415073
[ Info: iteration 2, average log likelihood -1.415004
[ Info: iteration 3, average log likelihood -1.414937
[ Info: iteration 4, average log likelihood -1.414856
[ Info: iteration 5, average log likelihood -1.414755
[ Info: iteration 6, average log likelihood -1.414627
[ Info: iteration 7, average log likelihood -1.414474
[ Info: iteration 8, average log likelihood -1.414302
[ Info: iteration 9, average log likelihood -1.414119
[ Info: iteration 10, average log likelihood -1.413937
[ Info: iteration 11, average log likelihood -1.413764
[ Info: iteration 12, average log likelihood -1.413603
[ Info: iteration 13, average log likelihood -1.413458
[ Info: iteration 14, average log likelihood -1.413331
[ Info: iteration 15, average log likelihood -1.413220
[ Info: iteration 16, average log likelihood -1.413124
[ Info: iteration 17, average log likelihood -1.413042
[ Info: iteration 18, average log likelihood -1.412972
[ Info: iteration 19, average log likelihood -1.412911
[ Info: iteration 20, average log likelihood -1.412859
[ Info: iteration 21, average log likelihood -1.412813
[ Info: iteration 22, average log likelihood -1.412772
[ Info: iteration 23, average log likelihood -1.412736
[ Info: iteration 24, average log likelihood -1.412704
[ Info: iteration 25, average log likelihood -1.412675
[ Info: iteration 26, average log likelihood -1.412649
[ Info: iteration 27, average log likelihood -1.412625
[ Info: iteration 28, average log likelihood -1.412602
[ Info: iteration 29, average log likelihood -1.412582
[ Info: iteration 30, average log likelihood -1.412562
[ Info: iteration 31, average log likelihood -1.412544
[ Info: iteration 32, average log likelihood -1.412527
[ Info: iteration 33, average log likelihood -1.412511
[ Info: iteration 34, average log likelihood -1.412496
[ Info: iteration 35, average log likelihood -1.412482
[ Info: iteration 36, average log likelihood -1.412468
[ Info: iteration 37, average log likelihood -1.412455
[ Info: iteration 38, average log likelihood -1.412443
[ Info: iteration 39, average log likelihood -1.412431
[ Info: iteration 40, average log likelihood -1.412420
[ Info: iteration 41, average log likelihood -1.412409
[ Info: iteration 42, average log likelihood -1.412399
[ Info: iteration 43, average log likelihood -1.412389
[ Info: iteration 44, average log likelihood -1.412380
[ Info: iteration 45, average log likelihood -1.412371
[ Info: iteration 46, average log likelihood -1.412362
[ Info: iteration 47, average log likelihood -1.412354
[ Info: iteration 48, average log likelihood -1.412346
[ Info: iteration 49, average log likelihood -1.412339
[ Info: iteration 50, average log likelihood -1.412331
┌ Info: EM with 100000 data points 50 iterations avll -1.412331
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.415073455011368
│     -1.4150039449483987
│      ⋮
└     -1.4123312137871786
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4258558526365686
│     -1.4258751231533897
│     -1.4257905059508227
│     -1.4257255029747038
│      ⋮
│     -1.412346188506483
│     -1.4123385590822166
└     -1.4123312137871786
32×26 Array{Float64,2}:
 -0.28072     -0.0542917   0.0321474   -0.208328   -0.0698014  -0.0600244    0.582272   -0.852685    0.182137   -0.112037     0.318947    0.591417   -0.109       -0.388       -0.252747    -0.264256     0.0220011   0.316228   -0.701119   -0.149752   -0.397161      0.0658383    0.334645   -0.298258   -0.121638    0.0279716
 -0.144999     0.28174     0.369506    -0.400048    0.258021   -0.311128     0.0964379  -0.506007   -0.0806181  -0.445721    -0.312965    0.855215   -0.00234796  -0.148589     0.410553    -0.168197    -0.141091   -0.287226    0.436356   -0.105702    0.205588     -0.388451     0.273342   -0.720866   -0.132801    0.317621
  0.356627    -0.0578346   0.0534855    1.06647     0.820656   -0.221881     0.401228   -0.928242   -0.180172    0.351366    -0.278257    0.517623    0.706304    -0.0743731   -0.185718    -0.686796    -0.0132822   0.908284   -0.286656    0.428647   -0.135891     -0.527621    -0.464418   -1.21614    -0.157109   -0.226423
  0.655352     0.158678   -0.346893     0.402286    0.393359   -0.0713628   -0.0858597  -0.232492    0.127593    0.22233     -0.02191     0.167343    0.425108    -0.359998    -0.329582    -0.354754    -0.0463104  -0.0860384   0.261883   -0.159983   -0.167399      0.545322    -0.323076   -0.727404   -0.296505    0.0565772
 -0.338597    -0.828923    0.0485452    0.221602    0.243398   -0.0383626    0.245004   -0.411095   -0.0105881   0.0965939    0.0403712   0.281635   -0.315094    -0.184824    -0.155396     0.0281891    0.244397    0.438618   -0.30176    -0.280873   -0.00382168   -0.181682     0.406536   -0.0417866  -0.260261   -0.114434
  0.214782     0.597819    0.360209     0.128487    0.0948806   0.00536585  -0.224985    0.0950988   0.151425   -0.14237     -0.213124   -0.116811    0.235161     0.0664077    0.174503     0.0581789   -0.0162918  -0.0805466   0.231411    0.429063   -0.0903899     0.0841795   -0.367591    0.116242   -0.0401649  -0.106495
 -0.441081     0.300031   -0.50745     -0.845024   -0.396596   -0.0224984   -0.549871    0.29751     0.0842624  -0.0601252    0.0307617  -0.327184    0.0941818    0.111737    -0.0676191    0.0870474   -0.445824   -0.309663   -0.0871141  -0.429457   -0.0259112     0.11029      0.0200052  -0.270903    0.381871    0.560006
  0.0145131   -0.0181007  -1.01288      0.896444   -0.513777   -0.190523    -0.0360557   0.43215     0.2519      0.306039     0.2231     -0.270223   -0.223274     0.253236    -0.262242    -0.085755    -0.432354    0.634902   -0.178333   -0.250362    0.0357807     0.245388     0.009922   -0.175272    0.270912   -0.304401
  0.129799     0.44821    -0.0276416   -0.161134    0.0360204   0.423436    -0.861575   -0.0278598  -0.405942    0.143953    -0.142468   -0.0642467   0.00145356   0.406061     0.217087    -0.216005    -0.172067   -0.244923   -0.467884    0.297313   -0.110995     -0.367036    -0.437055    0.26279    -0.478351    0.292777
  0.179349     0.104254   -0.435105    -0.160803   -0.1986      0.346162    -0.399445    0.388488   -0.155524   -0.263383    -0.141599    0.273506    0.857493     0.80187      0.352505    -0.0709271   -0.0305628  -0.809826    0.62435     0.0285035   0.351495     -0.0498765    0.192733   -0.13363    -0.178933    0.270228
  0.246911    -0.216306    0.223186    -0.23418     0.276408    0.583257     0.6517      0.283173   -0.376383   -0.0559635    0.0782499  -0.189112    0.180747    -0.127235    -0.0611857   -0.49552      0.358989   -0.826485    0.452681   -0.306948   -0.323657      0.0472414   -0.133899    0.561439   -0.64757    -0.0470527
  0.375647     0.324455   -0.00894671  -0.478601    0.498397   -0.0469079    0.646088    0.155821    0.202966    0.0427829    0.59141     0.122033    0.200741    -0.439397    -0.364584    -0.380704    -0.062209   -0.778908    0.40965    -0.0589729  -0.244585      0.312441     0.11657     0.263265    0.632528    0.172336
  0.0157041   -0.0389181   0.718904    -0.511975    0.307964   -0.339372    -0.128411   -0.61775    -0.0100262  -0.637579     0.0107044   0.296765    0.111773    -0.0596542    0.238837     1.1294      -0.0387895  -0.544814   -0.133284    0.599725    0.212492      0.00456234  -0.383719    0.372267    0.235055    0.327916
 -0.388955     0.252999    0.231372    -0.820953   -0.614499   -0.162867    -0.23606     0.288806   -0.0754293  -0.88733      0.121498   -0.213138   -0.225356     0.15663      0.365138     0.692192    -0.0901516  -0.348519   -0.0501916   0.11944     0.455275      0.666949     0.254762    0.793233    0.382985   -0.509062
  0.00543189   0.0365141   0.624276     0.0311634  -0.449119    0.165607    -0.142909   -0.192772   -0.726061    0.351197    -0.144307   -0.503201   -0.524608    -0.689089     0.585141     0.872459     0.144908   -0.096486    0.343246   -0.37512     0.203774     -0.153207    -0.500525   -0.216959    0.851634    0.262767
  0.620497     0.700991    0.0258869    0.340345   -0.207294    0.150917    -0.487866    0.258058    0.179012    0.00552573  -0.490054   -0.38496    -0.468731     0.577411     0.733389     0.432395    -0.458148   -0.194203    0.811438    0.105549    0.484354     -0.0760062   -0.114272   -0.12864     0.292935   -0.368804
 -0.365153     0.037629    0.344623     0.0395487   0.144627   -0.100288     0.388898    0.51592     0.425326    0.0110813   -0.525302   -0.187131    0.215655    -0.248809    -0.00612428  -0.401277     0.0534909   0.125007    0.163729   -0.725959    0.278744     -0.235114     0.282033   -0.409419   -0.531077    0.300643
 -0.15701     -0.224546   -0.37406     -0.55213     0.0908114  -0.111287    -0.0388493   0.261605   -0.0906409   0.0394769    0.506985   -0.028089   -0.0487717    0.227244    -0.217451    -0.272299    -0.204191   -0.204476   -0.274445   -0.758441    0.0626644    -0.00260359   0.184175   -0.17849     0.0694358   0.0812209
  0.030321    -0.821615   -0.113287     0.415318   -0.342838    0.296648     0.360484   -0.254394    0.192034   -0.171129     0.0689065   0.142442   -0.365557     0.242593     0.189438     0.516597    -0.0615286   0.210679    0.468684   -0.38615     0.248345     -0.221837     0.517571    0.0726096  -0.172356    0.364515
 -0.511741    -0.163869    0.214895     0.305502    0.0524254  -0.535064     0.343586    0.562354    0.106188    0.00730756   0.337083   -0.0990845  -0.0886475   -0.126458    -0.398433     0.898469     0.0686698   0.0813798   0.333709   -0.475636   -0.0728189    -0.0718105    0.339978   -0.38419     0.941107   -0.038958
 -0.022111    -0.0636658  -0.215779     0.230419   -0.191742    0.0208258    0.0775554   0.0360723   0.0637081   0.0332345   -0.0429809  -0.0413566  -0.0854553   -0.0593671   -0.00814593  -0.0126274   -0.179299    0.273141   -0.039773   -0.133781   -0.082937     -0.0468693    0.145092   -0.108218    0.0301161  -0.0474456
  0.118338    -0.053986    0.23165      0.0338871   0.384479   -0.0768405   -0.138138   -0.163296   -0.11382    -0.0443569   -0.0428651   0.137959    0.0191018   -0.00447499  -0.0267786   -0.00222891   0.312271   -0.078845    0.0184711   0.167178    0.147019     -0.0440462   -0.0690116  -0.158821   -0.16512    -0.160267
 -0.173021     0.320266    0.268356    -0.131351   -0.26481     0.231912     0.377962    0.30585     0.151434   -0.183176    -0.0226543  -0.0984106  -0.183676    -0.0336848    0.256628     0.00155535  -0.181524   -0.302812    0.286172    0.149217   -0.0757854    -0.042684    -0.111229    0.742743   -0.179375    0.212822
 -0.0355563    0.443761    0.112252    -0.212123    0.0779836  -0.21607     -0.205689    0.237954    0.129644   -0.238301     0.0809552  -0.168367    0.31701      0.136353    -0.02449      0.303645    -0.201986   -0.281428    0.39459     0.0974699   0.0846481     0.134654    -0.201295   -0.038576    0.441279    0.151365
  0.0202426    0.114716    0.280948     0.85963    -0.186802    0.140169     0.0617441  -0.561483    0.256994    0.0888483   -0.367423   -0.0398722  -0.201667    -0.254083     0.289965     0.318212     0.125554    0.595206    0.179693    0.664052   -0.368926      0.0269752   -0.291306    0.0261175  -0.147434   -0.233642
  0.038794    -0.192836   -0.0586716    0.440056    0.196529    0.0271895    0.322888    0.444259    0.0353199   0.643225     0.0424694  -0.659975   -0.413727    -0.200273    -0.671303     0.0286129   -0.0431485   0.1169     -0.235721   -0.0189124  -0.399614      0.11972     -0.475431    0.537866   -0.0247142  -0.285664
  0.0633669   -0.698681    0.472279     0.28287     0.309007   -0.0413855    0.0155546   0.478258   -0.028661    0.0525456   -0.021311   -1.05227    -0.0958101    0.236868     0.561443     0.0516182    0.443655    0.188442    0.224328    0.37499     0.552684     -0.286784    -0.411421    0.452296   -0.474989   -0.504212
 -0.0333696   -0.365074    0.234502     0.291282    0.0234383   0.00901198   0.169313    0.256094    0.517815    0.0249372    0.0773023   0.298726    0.554829     0.180059    -0.19334     -0.224599     0.44652     0.469748    0.0646248   0.798536    0.0679884     0.0109386    0.981403    0.376397   -0.359332   -0.442972
 -0.429121    -0.467534   -0.128534     0.411616    0.117519   -0.464341    -0.571946   -0.371706   -0.287706   -0.0980107   -0.315327   -0.0903087   0.00777007   0.110537     0.102104     0.564107    -0.0171914   0.700726   -0.449156    0.0410858   0.19614       0.066622     0.180147   -0.430621   -0.178915   -0.373377
  0.0412214    0.4156      0.302045    -0.113442    0.166317   -0.432848    -0.190022   -0.0330284  -0.0938359  -0.402693     0.212941   -0.197414    0.00641072  -0.328062    -0.100354    -0.248394     0.0688082   0.511313   -0.832906    0.282067   -0.256146      0.0555109   -0.241094   -0.116496    0.130555   -0.433426
  0.489966    -0.0179707  -0.555744    -0.362425   -0.431035    0.500771    -0.33588    -0.167029   -0.487349   -0.151708     0.400723   -0.0182617  -0.312668     0.193857     0.257383    -0.435863     0.171764    0.299175   -0.406442    0.330459   -0.000907891  -0.201509     0.256284   -0.120471    0.804574   -0.374718
 -0.194452     0.413131   -0.988173    -0.0652348  -0.562548    0.385022     0.050575   -0.838614   -0.221303   -0.0379032    0.44045    -0.105217    0.33198      0.364411    -0.896245     0.582683    -0.280038   -0.544655   -0.130564    0.230221   -0.329906     -0.0967036   -0.0518862   0.432311    0.549933   -0.0275278[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412324
[ Info: iteration 2, average log likelihood -1.412317
[ Info: iteration 3, average log likelihood -1.412311
[ Info: iteration 4, average log likelihood -1.412304
[ Info: iteration 5, average log likelihood -1.412298
[ Info: iteration 6, average log likelihood -1.412292
[ Info: iteration 7, average log likelihood -1.412286
[ Info: iteration 8, average log likelihood -1.412281
[ Info: iteration 9, average log likelihood -1.412275
[ Info: iteration 10, average log likelihood -1.412270
┌ Info: EM with 100000 data points 10 iterations avll -1.412270
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.739742e+05
      1       7.109909e+05      -1.629833e+05 |       32
      2       6.958915e+05      -1.509942e+04 |       32
      3       6.897069e+05      -6.184579e+03 |       32
      4       6.864596e+05      -3.247237e+03 |       32
      5       6.844063e+05      -2.053395e+03 |       32
      6       6.830884e+05      -1.317857e+03 |       32
      7       6.821137e+05      -9.747341e+02 |       32
      8       6.813082e+05      -8.055122e+02 |       32
      9       6.806685e+05      -6.396754e+02 |       32
     10       6.801090e+05      -5.594329e+02 |       32
     11       6.796472e+05      -4.618041e+02 |       32
     12       6.792569e+05      -3.903562e+02 |       32
     13       6.788815e+05      -3.753417e+02 |       32
     14       6.785428e+05      -3.387488e+02 |       32
     15       6.782189e+05      -3.239102e+02 |       32
     16       6.779155e+05      -3.033778e+02 |       32
     17       6.776575e+05      -2.580243e+02 |       32
     18       6.774508e+05      -2.067059e+02 |       32
     19       6.772506e+05      -2.002076e+02 |       32
     20       6.770682e+05      -1.823447e+02 |       32
     21       6.769127e+05      -1.555440e+02 |       32
     22       6.767743e+05      -1.383413e+02 |       32
     23       6.766309e+05      -1.434318e+02 |       32
     24       6.764990e+05      -1.319186e+02 |       32
     25       6.763772e+05      -1.218264e+02 |       32
     26       6.762666e+05      -1.105103e+02 |       32
     27       6.761672e+05      -9.947775e+01 |       32
     28       6.760760e+05      -9.119957e+01 |       32
     29       6.759951e+05      -8.088597e+01 |       32
     30       6.759311e+05      -6.403460e+01 |       32
     31       6.758696e+05      -6.144858e+01 |       32
     32       6.758086e+05      -6.096415e+01 |       32
     33       6.757497e+05      -5.894653e+01 |       32
     34       6.756865e+05      -6.321385e+01 |       32
     35       6.756195e+05      -6.700942e+01 |       32
     36       6.755504e+05      -6.906314e+01 |       32
     37       6.754836e+05      -6.675896e+01 |       32
     38       6.754227e+05      -6.092953e+01 |       32
     39       6.753591e+05      -6.360890e+01 |       32
     40       6.753021e+05      -5.697431e+01 |       32
     41       6.752429e+05      -5.918830e+01 |       32
     42       6.751895e+05      -5.340665e+01 |       32
     43       6.751444e+05      -4.516935e+01 |       32
     44       6.751055e+05      -3.891290e+01 |       32
     45       6.750675e+05      -3.796456e+01 |       32
     46       6.750274e+05      -4.012620e+01 |       32
     47       6.749900e+05      -3.737145e+01 |       32
     48       6.749477e+05      -4.227803e+01 |       32
     49       6.748987e+05      -4.901685e+01 |       32
     50       6.748486e+05      -5.007399e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674848.6259408896)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424575
[ Info: iteration 2, average log likelihood -1.419447
[ Info: iteration 3, average log likelihood -1.418022
[ Info: iteration 4, average log likelihood -1.416895
[ Info: iteration 5, average log likelihood -1.415722
[ Info: iteration 6, average log likelihood -1.414738
[ Info: iteration 7, average log likelihood -1.414137
[ Info: iteration 8, average log likelihood -1.413825
[ Info: iteration 9, average log likelihood -1.413652
[ Info: iteration 10, average log likelihood -1.413539
[ Info: iteration 11, average log likelihood -1.413455
[ Info: iteration 12, average log likelihood -1.413388
[ Info: iteration 13, average log likelihood -1.413332
[ Info: iteration 14, average log likelihood -1.413283
[ Info: iteration 15, average log likelihood -1.413239
[ Info: iteration 16, average log likelihood -1.413200
[ Info: iteration 17, average log likelihood -1.413164
[ Info: iteration 18, average log likelihood -1.413132
[ Info: iteration 19, average log likelihood -1.413101
[ Info: iteration 20, average log likelihood -1.413073
[ Info: iteration 21, average log likelihood -1.413046
[ Info: iteration 22, average log likelihood -1.413020
[ Info: iteration 23, average log likelihood -1.412996
[ Info: iteration 24, average log likelihood -1.412973
[ Info: iteration 25, average log likelihood -1.412950
[ Info: iteration 26, average log likelihood -1.412929
[ Info: iteration 27, average log likelihood -1.412908
[ Info: iteration 28, average log likelihood -1.412887
[ Info: iteration 29, average log likelihood -1.412867
[ Info: iteration 30, average log likelihood -1.412848
[ Info: iteration 31, average log likelihood -1.412829
[ Info: iteration 32, average log likelihood -1.412811
[ Info: iteration 33, average log likelihood -1.412793
[ Info: iteration 34, average log likelihood -1.412775
[ Info: iteration 35, average log likelihood -1.412758
[ Info: iteration 36, average log likelihood -1.412741
[ Info: iteration 37, average log likelihood -1.412724
[ Info: iteration 38, average log likelihood -1.412708
[ Info: iteration 39, average log likelihood -1.412692
[ Info: iteration 40, average log likelihood -1.412676
[ Info: iteration 41, average log likelihood -1.412661
[ Info: iteration 42, average log likelihood -1.412646
[ Info: iteration 43, average log likelihood -1.412632
[ Info: iteration 44, average log likelihood -1.412617
[ Info: iteration 45, average log likelihood -1.412603
[ Info: iteration 46, average log likelihood -1.412590
[ Info: iteration 47, average log likelihood -1.412577
[ Info: iteration 48, average log likelihood -1.412564
[ Info: iteration 49, average log likelihood -1.412551
[ Info: iteration 50, average log likelihood -1.412539
┌ Info: EM with 100000 data points 50 iterations avll -1.412539
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.298855      0.63411     -0.426608   -0.790758     -0.323869    -0.00502255  -0.430708     0.227255      0.157905    -0.0979019   -0.143906    -0.0982893    0.162249   -0.119079    -0.16034    -0.127601     -0.401463    -0.544257     0.0227917  -0.51313      -0.0270939     0.172845    -0.0595248  -0.294792    0.206334     0.857497
 -0.194283     -0.13868     -0.676604    0.747019     -0.294007    -0.128203     0.624411     0.673351      0.195649     0.328978     0.294844    -0.0476302   -0.357847   -0.0906815   -0.182635   -0.0584907    -0.230257     0.591137     0.32154    -0.893923     -0.150314      0.361459     0.261291   -0.568101    0.266121    -0.275227
 -0.0601206     0.16746      0.153484    0.532445     -0.228039     0.210923    -0.51021     -0.305125     -0.0687031   -0.0523988   -0.577225    -0.438331    -0.244318   -0.0540206    0.492558   -0.0132436     0.0962966    0.683194    -0.335893    0.403505      0.0132371    -0.231214    -0.272525    0.246541   -0.656065    -0.232569
  0.109202      0.172861    -0.0622232  -0.261798      0.31604     -0.25221      0.536879     0.103386      0.182472    -0.127617     0.759595     0.188124     0.333141   -0.0886859   -0.587326    0.193302     -0.133558    -0.671994     0.314273   -0.219904     -0.0788833     0.264466     0.215779    0.12272     0.636225     0.152568
  0.328296      0.175411    -0.0653146  -0.442676     -0.218515     0.667707     0.0215351   -0.445486     -0.812493     0.158454    -0.122839     0.157629    -0.359422   -0.197684    -0.0647267  -0.000455438  -0.00314486  -0.340985    -0.0332096   0.0174355    -0.307931     -0.0639065   -0.140226    0.171862    0.58814     -0.00871122
 -0.680018     -0.186111     0.0983226  -0.321782     -0.0508391   -0.00154799   0.253713     0.379599      0.427062    -0.111137    -0.1452      -0.0612304    0.137213   -0.0527321   -0.143744   -0.284101      0.196466     0.11353     -0.0172405  -0.787915      0.234474     -0.241435     0.699002   -0.480099   -0.199348     0.306675
 -0.0124154     0.137854     0.573567   -0.5366        0.281128    -0.01658     -0.0925782   -0.107876     -0.112953    -0.556588     0.0899896    0.0698749    0.297748   -0.0848823    0.386867    0.343392      0.0386098   -0.685187     0.272615    0.4733        0.0223321     0.0927585   -0.169946    0.371978    0.0634537    0.267719
 -0.84153      -1.0495      -0.438445   -0.0701177     0.246798    -0.740261    -0.698275    -0.183875     -0.204412    -0.0493729   -0.0744958   -0.47168      0.198218    0.20386      0.0796225   0.531408     -0.190306     0.181031    -0.173148   -0.175725      0.429882     -0.126536     0.725021   -0.0606583   0.236816    -0.139871
  0.1657       -0.148346    -0.144065    0.795478      0.138575    -0.121573    -0.0784212   -0.351663     -0.11024      0.386431    -0.309386    -0.20116      0.0160135  -0.221404    -0.17922     0.200191      0.0338427    0.593369    -0.184981   -0.067048      0.00655493    0.237829    -0.355507   -0.497003   -0.20799     -0.1945
 -0.129941     -0.220227     0.305421    0.0405626     0.244698     0.140097     0.039081     0.509147     -0.229317     0.0589311    0.147157    -0.884762    -0.097457    0.366038    -0.0852685   0.256643      0.128403    -0.104993     0.0487662   0.292213      0.0996792     0.1028      -0.524534    0.672525   -0.0589732   -0.758691
 -0.00780645   -0.0575853   -0.100944   -0.000509571   0.0738422   -0.0655851   -0.0390627   -0.000652007   0.00399778   0.0269992    0.084909    -0.0107925   -0.062517   -0.0322009   -0.0935577  -0.0970579    -0.0599486    0.1144      -0.128977   -0.142724     -0.0201364     0.00647461   0.0857054  -0.107546   -0.00998748  -0.110328
 -0.0540624     0.185235     0.0264221   0.134626     -0.402436     0.210828     0.539137     0.200245      0.268803    -0.101165     0.0298934   -0.209531    -0.263939   -0.140867     0.159048   -0.096098     -0.358668    -0.039596     0.239146    0.0416492    -0.249374     -0.0780583   -0.101912    0.690788   -0.203676     0.232213
 -0.294297      0.480256     0.358784   -0.611106     -0.523521    -0.294539    -0.158618    -0.00562894    0.105507    -0.982211     0.179891    -0.0260004   -0.157995    0.0505531    0.473465    0.63621      -0.185936    -0.218848    -0.211787    0.261404      0.382215      0.692734     0.309502    0.533459    0.392427    -0.419312
 -0.0144764     0.220596     0.722754   -0.0967237     0.291606    -0.0726616   -0.0122388   -0.253823      0.199612    -0.432434    -0.474399     0.518061     0.0147805  -0.311989     0.286174   -0.0758996     0.682604     0.0525393    0.453692    0.595232      0.120663     -0.312747     0.347583    0.0115915  -0.235436     0.026863
  0.500963      0.208925    -0.0707377   0.0158422     0.266094     0.150628    -0.534336    -0.113341     -0.0650911   -0.155163     0.177554     0.102672     0.474802    0.186728    -0.417361   -0.510717      0.412337    -0.165797    -0.14371     0.455721     -0.0321557     0.397613    -0.135239   -0.133415   -0.149079    -0.342757
 -0.485064     -0.491207     0.300268    0.0909106     0.292333    -0.412375     0.494127    -0.65264       0.0473693   -0.116903    -0.195365     0.720807    -0.448451    0.00541492   0.0999081   0.609817     -0.122001    -0.0822651    0.0816895  -0.385362      0.18066      -0.2978       0.161628   -0.309502   -0.469819     0.382609
  0.579921      0.680241    -0.147973    0.0915105    -0.370041     0.266125    -0.420229     0.336081      0.00163357  -0.0863445   -0.41578     -0.275089    -0.0827386   0.611878     0.680275    0.27171      -0.290514    -0.340191     0.840603    0.160603      0.536324     -0.139614    -0.117989   -0.0701156   0.355434    -0.373183
 -0.185913     -0.376012     0.494894    0.297777     -0.428146     0.0957396   -0.133872    -0.00085167   -0.255145     0.182541     0.0304222   -0.526758    -0.587752   -0.363865     0.410538    1.16692       0.205487     0.158399     0.605131   -0.239018      0.0860612    -0.0815271   -0.0599241  -0.180132    0.871924     0.214626
  0.0470538     0.603248    -0.0436607   0.0413149    -0.124429    -0.381419    -0.241172    -0.489543     -0.0798266   -0.521648    -0.179513     0.459566     0.41126     0.0741924    0.146954    0.0975534    -0.708883     0.186868     0.180519    0.0636109    -0.0398703    -0.143934    -0.0615504  -0.992233    0.413177    -0.103049
  0.390461     -0.00421879   0.176667   -0.125835      1.02735     -0.304453    -0.0307322    0.232656      0.0642386   -0.00289988  -0.00524826   0.0211231    0.123929   -0.377779     0.362324   -0.548307     -0.0938684   -0.277389     0.434817   -0.525696     -0.000752623   0.0813375   -0.0800205  -0.517089   -0.471041    -0.0976893
  0.143816     -0.386129    -0.817879   -0.123527     -0.539514     0.298168     0.00505028  -0.71537      -0.00660127  -0.268457     0.527222     0.944577    -0.0422772   0.284292     0.0754976  -0.314292      0.0779093    0.248851    -0.149546    0.0221057     0.238769     -0.0640241    0.614821   -0.40223    -0.165422     0.395824
  0.234096      0.17662     -0.146115   -0.154461     -0.0150739    0.511797    -0.482257     0.36482      -0.353404     0.180406     0.0402924    0.0796688    0.303707    0.650451     0.297934   -0.226621     -0.254905    -0.623893     0.100624   -0.109998     -0.0326576    -0.327557    -0.21889     0.0614219  -0.459594     0.525639
 -0.0377647    -0.494144     0.144105   -0.00515486    0.37771      0.364115     0.789924     0.235236     -0.202259     0.39967      0.200319    -0.254826    -0.108025   -0.62362     -0.517574   -0.608563      0.437718    -0.332612    -0.0360683  -0.299819     -0.416839     -0.0734487   -0.112646    0.653367   -0.457951     0.0361027
 -0.0352369     0.101143     0.0946513   0.00633203   -0.140663     0.0994545    0.0772174    0.14616       0.0779674   -0.157325    -0.174399    -0.0219578    0.177115    0.0897899    0.206049    0.288682     -0.0593608   -0.286317     0.585593   -0.0159569     0.219482      0.0118121    0.0774684  -0.0257072   0.110239     0.221626
  0.175303     -0.156039     0.0320658   0.756577      0.504433    -0.0988532    0.349356    -0.940055      0.278539     0.598605     0.0572007    0.773517     0.427423   -0.316236    -0.0228363  -0.195735      0.0128883    0.679111     0.141955    0.910587     -0.554595      0.312223    -0.253944   -0.469231   -0.173012    -0.393175
  0.192468     -0.959927     0.10103     0.593906     -0.244373     0.210661     0.178533    -0.056369     -0.0194542   -0.0931995    0.173437    -0.00474159  -0.105205    0.277122     0.259523    0.153954      0.311183     0.619671    -0.247132    0.216995      0.140754     -0.477693     0.518681    0.245687   -0.177723    -0.642189
 -0.185431      0.189251     0.0716914  -0.0734487     0.00249514  -0.236179    -0.47292     -0.0649826    -0.139485    -0.108156     0.115778    -0.11169     -0.147444    0.362021     0.147714    0.537186     -0.0120442   -0.00671995  -0.349021    0.450818      0.0439931    -0.282681    -0.316101    0.229701    0.218901     0.118017
 -0.106912     -0.0658203    0.356174    0.30322       0.296819    -0.194543     0.489713    -0.228346      0.152135    -0.0565277   -0.385283     0.333731     0.23404    -0.173422    -0.164583   -0.447893      0.115835     0.510406    -0.266839   -0.382826      0.137055     -0.511884     0.179214   -0.844931   -0.265958     0.14063
 -0.000977041   0.0987825   -0.588941    0.155795     -0.403323    -0.0283355   -0.435337     0.24948       0.0800652    0.227457     0.342632    -0.479025    -0.217179    0.283282    -0.562876    0.0733249    -0.259836     0.350103    -0.60981    -0.0648408    -0.289128      0.0823255   -0.132815    0.07903     0.602235    -0.351766
  0.0140473     0.929131     0.692795    0.180659      0.539074    -0.421992    -0.111792     0.368921      0.213343     0.197133    -0.446502    -0.623332     0.209388   -0.382986    -0.117983    0.293143     -0.317789    -0.214093     0.373735    0.108354     -0.154417      0.0110928   -0.840538   -0.0353293   0.0413907    0.0835089
 -0.0977558     0.114947     0.17364    -0.211971      0.11063     -0.342929     0.262919    -0.381404     -0.054138    -0.217752     0.302862     0.134248    -0.197996   -0.561875    -0.251513   -0.323498      0.0952911    0.459663    -1.0169      0.000509902  -0.38071      -0.0120551    0.0865483  -0.185124    0.141328    -0.288952
  0.0637094    -0.334833    -0.181414    0.317642      0.050724     0.036974     0.518077     0.818973      0.943112     0.0678822   -0.210378    -0.274958     0.271878    0.425932    -0.222477    0.0169575     0.269111     0.0502424    0.615076    0.170681      0.363481      0.486471     0.394931    0.404935   -0.443435    -0.123656[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412526
[ Info: iteration 2, average log likelihood -1.412515
[ Info: iteration 3, average log likelihood -1.412503
[ Info: iteration 4, average log likelihood -1.412492
[ Info: iteration 5, average log likelihood -1.412481
[ Info: iteration 6, average log likelihood -1.412470
[ Info: iteration 7, average log likelihood -1.412460
[ Info: iteration 8, average log likelihood -1.412450
[ Info: iteration 9, average log likelihood -1.412440
[ Info: iteration 10, average log likelihood -1.412430
┌ Info: EM with 100000 data points 10 iterations avll -1.412430
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
