Julia Version 1.5.0-DEV.162
Commit fba188c5ea (2020-01-28 03:57 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed Compat ───────────── v2.2.0
 Installed PDMats ───────────── v0.9.11
 Installed DataAPI ──────────── v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
 Installed BinDeps ──────────── v1.0.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed Distances ────────── v0.8.2
 Installed DataStructures ───── v0.17.9
 Installed Arpack ───────────── v0.4.0
 Installed FileIO ───────────── v1.2.1
 Installed HDF5 ─────────────── v0.12.5
 Installed CMakeWrapper ─────── v0.2.3
 Installed FillArrays ───────── v0.8.4
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed OrderedCollections ─ v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed StatsFuns ────────── v0.9.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Distributions ────── v0.22.3
 Installed ScikitLearnBase ──── v0.5.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_7XsGRA/Project.toml`
 [no changes]
  Updating `/tmp/jl_7XsGRA/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_eKoeeR/Project.toml`
 [no changes]
  Updating `/tmp/jl_eKoeeR/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_RmbcuH/Project.toml`
 [no changes]
  Updating `/tmp/jl_RmbcuH/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_E8K29e/Project.toml`
 [no changes]
  Updating `/tmp/jl_E8K29e/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_3KsSoc/Project.toml`
 [no changes]
  Updating `/tmp/jl_3KsSoc/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_3KsSoc/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.8681282109576722e6, [30.83543179900846, 99969.16456820098], [-24.75463310802858 22.842718114612353 -97.96917813968513; 24.61321021793779 -174.00853384930366 300.4299430506613], [[34.72666864549106 -21.16306849770629 73.78618634218246; -21.163068497706288 24.392959423465513 -72.31096401383344; 73.78618634218246 -72.31096401383344 313.3006665403948], [100316.40209205082 -507.7767669007582 383.1414118915096; -507.7767669007582 99786.34037855807 195.7121138770317; 383.1414118915096 195.7121138770317 99717.0987308937]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.359271e+03
      1       1.096920e+03      -2.623509e+02 |        8
      2       1.016187e+03      -8.073351e+01 |        5
      3       9.532131e+02      -6.297357e+01 |        0
      4       9.532131e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 953.2130741154938)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.067106
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.737191
[ Info: iteration 2, lowerbound -3.583489
[ Info: iteration 3, lowerbound -3.435446
[ Info: iteration 4, lowerbound -3.290869
[ Info: iteration 5, lowerbound -3.166994
[ Info: iteration 6, lowerbound -3.077544
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -3.009673
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.944790
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.868233
[ Info: iteration 10, lowerbound -2.784556
[ Info: iteration 11, lowerbound -2.706775
[ Info: iteration 12, lowerbound -2.641315
[ Info: iteration 13, lowerbound -2.590670
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.541345
[ Info: iteration 15, lowerbound -2.493087
[ Info: iteration 16, lowerbound -2.451589
[ Info: iteration 17, lowerbound -2.414108
[ Info: iteration 18, lowerbound -2.380256
[ Info: iteration 19, lowerbound -2.349725
[ Info: iteration 20, lowerbound -2.324559
[ Info: iteration 21, lowerbound -2.309694
[ Info: iteration 22, lowerbound -2.308514
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.302914
[ Info: iteration 24, lowerbound -2.299258
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 28 18:42:28 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 28 18:42:36 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Tue Jan 28 18:42:38 2020: EM with 272 data points 0 iterations avll -2.067106
5.8 data points per parameter
, Tue Jan 28 18:42:40 2020: GMM converted to Variational GMM
, Tue Jan 28 18:42:49 2020: iteration 1, lowerbound -3.737191
, Tue Jan 28 18:42:49 2020: iteration 2, lowerbound -3.583489
, Tue Jan 28 18:42:49 2020: iteration 3, lowerbound -3.435446
, Tue Jan 28 18:42:49 2020: iteration 4, lowerbound -3.290869
, Tue Jan 28 18:42:49 2020: iteration 5, lowerbound -3.166994
, Tue Jan 28 18:42:49 2020: iteration 6, lowerbound -3.077544
, Tue Jan 28 18:42:49 2020: dropping number of Gaussions to 6
, Tue Jan 28 18:42:49 2020: iteration 7, lowerbound -3.009673
, Tue Jan 28 18:42:49 2020: dropping number of Gaussions to 5
, Tue Jan 28 18:42:49 2020: iteration 8, lowerbound -2.944790
, Tue Jan 28 18:42:49 2020: dropping number of Gaussions to 4
, Tue Jan 28 18:42:49 2020: iteration 9, lowerbound -2.868233
, Tue Jan 28 18:42:49 2020: iteration 10, lowerbound -2.784556
, Tue Jan 28 18:42:49 2020: iteration 11, lowerbound -2.706775
, Tue Jan 28 18:42:49 2020: iteration 12, lowerbound -2.641315
, Tue Jan 28 18:42:49 2020: iteration 13, lowerbound -2.590670
, Tue Jan 28 18:42:49 2020: dropping number of Gaussions to 3
, Tue Jan 28 18:42:50 2020: iteration 14, lowerbound -2.541345
, Tue Jan 28 18:42:50 2020: iteration 15, lowerbound -2.493087
, Tue Jan 28 18:42:50 2020: iteration 16, lowerbound -2.451589
, Tue Jan 28 18:42:50 2020: iteration 17, lowerbound -2.414108
, Tue Jan 28 18:42:50 2020: iteration 18, lowerbound -2.380256
, Tue Jan 28 18:42:50 2020: iteration 19, lowerbound -2.349725
, Tue Jan 28 18:42:50 2020: iteration 20, lowerbound -2.324559
, Tue Jan 28 18:42:50 2020: iteration 21, lowerbound -2.309694
, Tue Jan 28 18:42:50 2020: iteration 22, lowerbound -2.308514
, Tue Jan 28 18:42:50 2020: dropping number of Gaussions to 2
, Tue Jan 28 18:42:50 2020: iteration 23, lowerbound -2.302914
, Tue Jan 28 18:42:50 2020: iteration 24, lowerbound -2.299258
, Tue Jan 28 18:42:50 2020: iteration 25, lowerbound -2.299255
, Tue Jan 28 18:42:50 2020: iteration 26, lowerbound -2.299254
, Tue Jan 28 18:42:50 2020: iteration 27, lowerbound -2.299254
, Tue Jan 28 18:42:50 2020: iteration 28, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 29, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 30, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 31, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 32, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 33, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 34, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 35, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 36, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 37, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 38, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 39, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 40, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 41, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 42, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 43, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 44, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 45, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 46, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 47, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 48, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 49, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: iteration 50, lowerbound -2.299253
, Tue Jan 28 18:42:50 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398155, 178.04509222601837]
β = [95.95490777398155, 178.04509222601837]
m = [2.0002292577753322 53.851987172461094; 4.250300733269874 79.28686694436132]
ν = [97.95490777398155, 180.04509222601837]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119490253 -0.008953123827346877; 0.0 0.012748664777409699], [0.18404155547483894 -0.007644049042327545; 0.0 0.00858170516633287]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9959218691994518
avll from llpg:  -0.9959218691994504
avll direct:     -0.9959218691994505
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9768084020769459
avll from llpg:  -0.9768084020769459
avll direct:     -0.9768084020769459
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.132438    -0.0549657    -0.123097    -0.0462324   -0.135663     0.0134167     0.0194007    0.0343176   -0.10667     -0.0826456   -0.0623361    0.115331     -0.0668158    0.113044      0.143871    -0.0946917   0.0161767     0.0529492    0.112143    -0.000632725  -0.0272759     0.036716    -0.238513      0.0386941   -0.186101    -0.0937739
 -0.131824    -0.0180132     0.143696    -0.0501634   -0.137506     0.0846072     0.119897     0.0766406    0.00298575  -0.0167901    0.00794942   0.104188     -5.90824e-5   0.00428259   -0.121258    -0.088663    0.0778284     0.154421    -0.0918565   -0.204695      0.108964      0.0110353   -0.138694     -0.100838     0.082615    -0.0268492
  0.108035    -0.00805956   -0.0719657    0.0588528   -0.0847775   -0.0320072     0.150257    -0.0493429    0.130262     0.145296    -0.0106206   -0.018645      0.037164    -0.0767283    -0.137462     0.266454    0.00870712    0.0248121    0.144352    -0.0616841    -0.119844      0.0833319   -0.108781     -0.0859855   -0.0465147   -0.0289156
  0.0376856   -0.0332113     0.0338051    0.0527481    0.0062693    0.124304      0.018585     0.135515    -0.167653     0.0875893    0.0900099    0.0730421     0.1975      -0.268997     -0.0148321    0.0336671  -0.0826327     0.0909648    0.0778301    0.0262137     0.0480783    -0.0936829    0.0615271    -0.00320294  -0.0120359   -0.104914
  0.0905649    0.189182     -0.0849136    0.0274088    0.0443476   -0.00999524   -0.150288     0.050278     0.0669996    0.0435816    0.0125091    0.024107     -0.00823985  -0.0367535     0.107141    -0.0819869   0.0329711    -0.337152     0.0902853    0.0157451    -0.0919854     0.225273     0.132344     -0.0689998    0.107453     0.173413
  0.0306212   -0.171221     -0.109338     0.0576045    0.0230482    0.122029     -0.0961843   -0.188533     0.0376078    0.10345     -0.0248546   -0.0454645    -0.164047    -0.0249341    -0.121398    -0.0322407   0.146933     -0.00288313  -0.0920092    0.00795066   -0.207922      0.166191    -0.12661      -0.0178952    0.161086    -0.0579968
 -0.00796718   0.0875242     0.132396     0.00848863  -0.041075     0.0340401    -0.106051     0.0342836    0.21754     -0.00277124  -0.105019     0.0623437    -0.113602     0.0742643    -0.0113436    0.17577    -0.0271208    -0.0273796    0.048117     0.13591       0.000784384  -0.0600373    0.12011      -0.0220678    0.232601     0.0601858
  0.0767558    0.00899946    0.0217083   -0.0643613   -0.00278949   0.0745826    -0.035848    -0.0253646   -0.179655    -0.0136276   -0.229574     0.0355884     0.0718338   -0.0562196     0.137731     0.350383    0.000404483   0.0439682    0.102984    -0.0126364     0.052437      0.0236296    0.110381     -0.0822626   -0.0402422   -0.0485312
 -0.060981    -0.171956     -0.00267899  -0.126719    -0.110691     0.0534655     0.0945877   -0.204994    -0.0131537   -0.0650203   -0.077934    -0.0325455     0.0393371   -0.106849     -0.112317    -0.0209901   0.00334527    0.00372035  -0.108292    -0.202229     -0.0563972     0.065736     0.0406008     0.0720994    0.136158     0.015856
  0.062346     0.0157678    -0.0166142   -0.151346     0.0167462    0.132512     -0.0618998   -0.153547    -0.00952356   0.00848749   0.0483476    0.16473      -0.0994648    0.0933866    -0.0145359   -0.0196314   0.0409928     0.0453396    0.0499504   -0.0439699     0.256987     -0.118811     0.0513628    -0.0796446    0.0235304   -0.0357863
 -0.095051     0.0356273     0.0875194   -0.175361     0.0225877    0.109546      0.0832006    0.00204884  -0.111863    -0.086398    -0.00127064  -0.0277326     0.129368     0.016496     -0.0395953   -0.0842965   0.219252      0.0668184    0.199206     0.0795999     0.132389      0.167491     0.0554175     0.0802238    0.0223259    0.0358265
 -0.0448054    0.0956948     0.0115519    0.0267774    0.119748     0.0408312    -0.107486     0.0761907   -0.0684052    0.0500081   -0.237394    -0.0228943    -0.067229    -0.0960348    -0.0395711   -0.152715    0.25821      -0.154534    -0.00567356  -0.0999422     0.00792012   -0.11423     -0.0321578     0.0630311    0.0549966   -0.00169625
  0.0011278    0.0210838    -0.0126985    0.0213019    0.00620825  -0.0600141     0.0610156   -0.0566812   -0.00616585   0.157463     0.00872005  -0.0071526    -0.020944     0.0723531     0.113224     0.191965    0.134939     -0.00345283  -0.0237896   -0.174715     -0.0333955     0.0702615    0.0541638    -0.0122001    0.104886    -0.0467695
 -0.0218818   -0.0424123    -0.0471991   -0.0676827    0.0917203    0.0629297    -0.112043    -0.0224166    0.0667164    0.0754635   -0.00315901  -0.0282266     0.0676462    0.0798228     0.0179594   -0.124943   -0.0702214     0.134788    -0.129691    -0.0681346     0.148892     -0.0370806   -0.109711      0.148507    -0.14708      0.0863972
 -0.0533566    0.085842     -0.00327908  -0.011587     0.0972509   -0.0730932    -0.0221802    0.0558217    0.131437    -0.0544113    0.0330687    0.191403      0.166622    -0.175198      0.184155    -0.167239    0.00932717    0.00414421  -0.19879     -0.000971016  -0.079142     -0.111409    -0.139964     -0.00492296   0.074152     0.0179281
 -0.12071     -0.0209795     0.0142175    0.0254603    0.0461464    0.0499761    -0.082421    -0.0799781   -0.0167309   -0.140065    -0.185396     0.000520523  -0.11779      0.0170693    -0.0134982   -0.0826322   0.0669698    -0.253117     0.0116274    0.0478682    -0.0650155     0.0667424    0.00444466   -0.108282     0.0629732   -0.0214233
 -0.0747901   -0.0325635    -0.042312    -0.082091    -0.00157805   0.000432829  -0.0251117   -0.0774484    0.00273896  -0.0981268    0.0226712    0.208476     -0.041727     0.00827231   -0.0675542    0.143238    0.129868     -0.0465314   -0.0622848   -0.0881776     0.0975346    -0.0947667    0.0389711    -0.0498563    0.0491958   -0.137022
  0.164588     0.000630953   0.144154    -0.0334669    0.00342232  -0.0870511     0.0656343   -0.100477    -0.141653    -0.0441016    0.0794777    0.00450446   -0.124574    -0.0146734     0.0428856    0.125518    0.0302843     0.0248935    0.032171    -0.0617761    -0.0961529    -0.0109224   -0.113545      0.0764178   -0.107587    -0.0700047
  0.0995303   -0.0425241     0.0832615   -0.01587      0.0850439   -0.193488     -0.10431      0.125617    -0.0267153    0.120054    -0.0440608   -0.010368      0.060833     0.147307     -0.217888     0.0817292  -0.142723     -0.0702391   -0.00385153   0.109388     -0.0158757    -0.0336454    0.237094     -0.161513    -0.198019     0.019683
  0.00696057  -0.0318001    -0.00865644  -0.096833     0.0729639    0.00517791   -0.167648     0.100556     0.0696762   -0.105606    -0.203797    -0.248286      0.0168632   -0.0135227     0.0606711    0.066691    0.00344623    0.0912341   -0.0574928   -0.125948     -0.0330203     0.075879    -0.0589222    -0.137201     0.0959247   -0.0233892
 -0.0534621   -0.0441347    -0.022153    -0.164921     0.0125811   -0.030533      0.0655937    0.0812976    0.102581     0.0661084    0.145651    -0.143833      0.0566254   -0.0739023     0.0177408   -0.175564   -0.0489027     0.0374004   -0.0784403   -0.0419854    -0.121336     -0.0344613    0.106537     -0.104042     0.0669386    0.0546717
 -0.0336418    0.0674158     0.140047     0.0817865   -0.030957     0.0232681     0.164754     0.0867636    0.0172517   -0.0434536   -0.0703564   -0.0147616     0.0293442    0.125299     -0.0471432   -0.109667    0.113531      0.24406      0.115324    -0.0474493     0.00934783    0.102852     0.00500819   -0.0424677   -0.0169783    0.0844506
  0.0315666    0.0566877     0.00914227  -0.068429    -0.0549826    0.0740372    -0.0206199   -0.00946549  -0.167472    -0.11911      0.157736    -0.0689234     0.05839      0.000434173  -0.00744563  -0.124358   -0.013634     -0.221739    -0.0234251   -0.0610312     0.0117854     0.124614     0.0251835    -0.0295467   -0.0140834    0.0869536
 -0.00786645   0.0701634     0.100538    -0.0386021   -0.104909    -0.148852     -0.00571308  -0.0394693    0.0938289   -0.0975882    0.027864    -0.00393131    0.0518041   -0.0837501    -0.184756    -0.107145    0.0552659    -0.0584238   -0.086208    -0.112975      0.116956      0.0855574    0.00494375   -0.0308745   -0.00888302  -0.12356
 -0.0345845   -0.0516822     0.100884    -0.0382128    0.0190099    0.116108     -0.0502652   -0.0855852    0.0699383    0.120239    -0.0245033    0.0508714     0.0989729   -0.138729     -0.0899602   -0.0399202   0.0758472    -0.0328686    0.00791397   0.0508148     0.218802     -0.158272     0.000437756  -0.0803182    0.0400657   -0.0449196
 -0.0642751   -0.103863     -0.105623    -0.0144504    0.194225     0.0359459    -0.117842     0.123778    -0.110893     0.0185378   -0.139093    -0.0445328    -0.0278825    0.0205703     0.0226476    0.0561408  -0.136154     -0.0443903   -0.0245015    0.0802982     0.0210243    -0.0479465    0.0586157     0.00597542  -0.110878     0.0191016
  0.0942383   -0.0685305    -0.0878995    0.0633064    0.0194098    0.206975      0.0498113    0.019918     0.00997416  -0.040335    -0.263852     0.11306       0.0961102    0.117962      0.0625442    0.0396506  -0.119548      0.072708     0.0191382    0.0337979    -0.0196917     0.00556685   0.0641668     0.112723     0.00135649  -0.120239
 -0.150198     0.0346217     0.112545    -0.0350184   -0.0180349   -0.0335172    -0.15287      0.00283272   0.0355904    0.0873051    0.0454122    0.0289461    -0.116275     0.0220786     0.0390207    0.0715984  -0.0563273     0.0170961   -0.0701482   -0.0358768     0.0173654     0.0376073   -0.155454      0.0213686   -0.0623115   -0.048547
  0.0428468   -0.0517309     0.0220598   -0.0471458   -0.102159    -0.134173     -0.0600782    0.0828884   -0.00712347  -0.00720528  -0.120164    -0.0462498     0.133687    -0.0214071    -0.0187394   -0.0150885   0.141995      0.0912408    0.196955     0.186856      0.0756523    -0.1846      -0.0455513    -0.161267    -0.142048     0.0901638
  0.169247     0.0776824     0.105736    -0.130806     0.166911    -0.129784      0.0359735    0.0392656   -0.0218503   -0.156555    -0.0629442   -0.0287753    -0.0132752    0.0731358     0.177169    -0.0106728  -0.0449332    -0.113797    -0.00846151  -0.0830153     0.0107207     0.00379597   0.118746     -0.0620373   -0.0774473    0.100839
  0.0768269   -0.0983085     0.0394998    0.00268882  -0.0140954    0.0103721    -0.192178    -0.0497584   -0.0535925    0.0082319    0.0808613    0.167783     -0.148723    -0.156694     -0.160337    -0.147352    0.0449489     0.0370583   -0.00979931   0.103965      0.00310413   -0.0348148    0.104033      0.0321625   -0.0696493    0.024584
  0.0273117   -0.00955089   -0.0454897    0.007511     0.0235847   -0.0484464    -0.201441     0.141616     0.0643376   -0.204364     0.00678642  -0.0742857     0.17617     -0.0718256     0.0162702   -0.0297114  -0.0936221     0.0653473    0.0522418   -0.137513     -0.0019078    -0.0446491    0.0360314     0.177461     0.144526     0.0636623kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3819887372378308
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382079
[ Info: iteration 2, average log likelihood -1.381989
[ Info: iteration 3, average log likelihood -1.381092
[ Info: iteration 4, average log likelihood -1.371763
[ Info: iteration 5, average log likelihood -1.352316
[ Info: iteration 6, average log likelihood -1.344711
[ Info: iteration 7, average log likelihood -1.342913
[ Info: iteration 8, average log likelihood -1.342135
[ Info: iteration 9, average log likelihood -1.341728
[ Info: iteration 10, average log likelihood -1.341513
[ Info: iteration 11, average log likelihood -1.341396
[ Info: iteration 12, average log likelihood -1.341331
[ Info: iteration 13, average log likelihood -1.341294
[ Info: iteration 14, average log likelihood -1.341272
[ Info: iteration 15, average log likelihood -1.341259
[ Info: iteration 16, average log likelihood -1.341250
[ Info: iteration 17, average log likelihood -1.341245
[ Info: iteration 18, average log likelihood -1.341242
[ Info: iteration 19, average log likelihood -1.341239
[ Info: iteration 20, average log likelihood -1.341238
[ Info: iteration 21, average log likelihood -1.341237
[ Info: iteration 22, average log likelihood -1.341236
[ Info: iteration 23, average log likelihood -1.341236
[ Info: iteration 24, average log likelihood -1.341236
[ Info: iteration 25, average log likelihood -1.341235
[ Info: iteration 26, average log likelihood -1.341235
[ Info: iteration 27, average log likelihood -1.341235
[ Info: iteration 28, average log likelihood -1.341235
[ Info: iteration 29, average log likelihood -1.341235
[ Info: iteration 30, average log likelihood -1.341235
[ Info: iteration 31, average log likelihood -1.341235
[ Info: iteration 32, average log likelihood -1.341235
[ Info: iteration 33, average log likelihood -1.341235
[ Info: iteration 34, average log likelihood -1.341235
[ Info: iteration 35, average log likelihood -1.341235
[ Info: iteration 36, average log likelihood -1.341235
[ Info: iteration 37, average log likelihood -1.341235
[ Info: iteration 38, average log likelihood -1.341235
[ Info: iteration 39, average log likelihood -1.341235
[ Info: iteration 40, average log likelihood -1.341235
[ Info: iteration 41, average log likelihood -1.341235
[ Info: iteration 42, average log likelihood -1.341235
[ Info: iteration 43, average log likelihood -1.341235
[ Info: iteration 44, average log likelihood -1.341235
[ Info: iteration 45, average log likelihood -1.341235
[ Info: iteration 46, average log likelihood -1.341235
[ Info: iteration 47, average log likelihood -1.341235
[ Info: iteration 48, average log likelihood -1.341235
[ Info: iteration 49, average log likelihood -1.341235
[ Info: iteration 50, average log likelihood -1.341235
┌ Info: EM with 100000 data points 50 iterations avll -1.341235
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.382079111540555
│     -1.3819891600029102
│      ⋮
└     -1.3412351618805711
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341364
[ Info: iteration 2, average log likelihood -1.341258
[ Info: iteration 3, average log likelihood -1.340721
[ Info: iteration 4, average log likelihood -1.335835
[ Info: iteration 5, average log likelihood -1.322805
[ Info: iteration 6, average log likelihood -1.312170
[ Info: iteration 7, average log likelihood -1.309022
[ Info: iteration 8, average log likelihood -1.307750
[ Info: iteration 9, average log likelihood -1.306970
[ Info: iteration 10, average log likelihood -1.306433
[ Info: iteration 11, average log likelihood -1.306007
[ Info: iteration 12, average log likelihood -1.305620
[ Info: iteration 13, average log likelihood -1.305259
[ Info: iteration 14, average log likelihood -1.304948
[ Info: iteration 15, average log likelihood -1.304692
[ Info: iteration 16, average log likelihood -1.304479
[ Info: iteration 17, average log likelihood -1.304300
[ Info: iteration 18, average log likelihood -1.304153
[ Info: iteration 19, average log likelihood -1.304034
[ Info: iteration 20, average log likelihood -1.303939
[ Info: iteration 21, average log likelihood -1.303862
[ Info: iteration 22, average log likelihood -1.303800
[ Info: iteration 23, average log likelihood -1.303751
[ Info: iteration 24, average log likelihood -1.303711
[ Info: iteration 25, average log likelihood -1.303678
[ Info: iteration 26, average log likelihood -1.303650
[ Info: iteration 27, average log likelihood -1.303625
[ Info: iteration 28, average log likelihood -1.303602
[ Info: iteration 29, average log likelihood -1.303581
[ Info: iteration 30, average log likelihood -1.303561
[ Info: iteration 31, average log likelihood -1.303541
[ Info: iteration 32, average log likelihood -1.303522
[ Info: iteration 33, average log likelihood -1.303503
[ Info: iteration 34, average log likelihood -1.303483
[ Info: iteration 35, average log likelihood -1.303463
[ Info: iteration 36, average log likelihood -1.303443
[ Info: iteration 37, average log likelihood -1.303422
[ Info: iteration 38, average log likelihood -1.303401
[ Info: iteration 39, average log likelihood -1.303378
[ Info: iteration 40, average log likelihood -1.303355
[ Info: iteration 41, average log likelihood -1.303332
[ Info: iteration 42, average log likelihood -1.303309
[ Info: iteration 43, average log likelihood -1.303286
[ Info: iteration 44, average log likelihood -1.303264
[ Info: iteration 45, average log likelihood -1.303243
[ Info: iteration 46, average log likelihood -1.303222
[ Info: iteration 47, average log likelihood -1.303203
[ Info: iteration 48, average log likelihood -1.303185
[ Info: iteration 49, average log likelihood -1.303168
[ Info: iteration 50, average log likelihood -1.303151
┌ Info: EM with 100000 data points 50 iterations avll -1.303151
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3413641272777215
│     -1.341257542574166
│      ⋮
└     -1.3031513882883223
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303341
[ Info: iteration 2, average log likelihood -1.303149
[ Info: iteration 3, average log likelihood -1.302689
[ Info: iteration 4, average log likelihood -1.298236
[ Info: iteration 5, average log likelihood -1.280923
[ Info: iteration 6, average log likelihood -1.264304
[ Info: iteration 7, average log likelihood -1.258628
[ Info: iteration 8, average log likelihood -1.256489
[ Info: iteration 9, average log likelihood -1.255319
[ Info: iteration 10, average log likelihood -1.254533
[ Info: iteration 11, average log likelihood -1.253935
[ Info: iteration 12, average log likelihood -1.253450
[ Info: iteration 13, average log likelihood -1.253059
[ Info: iteration 14, average log likelihood -1.252750
[ Info: iteration 15, average log likelihood -1.252495
[ Info: iteration 16, average log likelihood -1.252262
[ Info: iteration 17, average log likelihood -1.252014
[ Info: iteration 18, average log likelihood -1.251694
[ Info: iteration 19, average log likelihood -1.251185
[ Info: iteration 20, average log likelihood -1.250203
[ Info: iteration 21, average log likelihood -1.248284
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.245870
[ Info: iteration 23, average log likelihood -1.259613
[ Info: iteration 24, average log likelihood -1.254913
[ Info: iteration 25, average log likelihood -1.252588
[ Info: iteration 26, average log likelihood -1.251334
[ Info: iteration 27, average log likelihood -1.250329
[ Info: iteration 28, average log likelihood -1.249335
[ Info: iteration 29, average log likelihood -1.248186
[ Info: iteration 30, average log likelihood -1.246568
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.244493
[ Info: iteration 32, average log likelihood -1.257272
[ Info: iteration 33, average log likelihood -1.252868
[ Info: iteration 34, average log likelihood -1.250313
[ Info: iteration 35, average log likelihood -1.248621
[ Info: iteration 36, average log likelihood -1.247095
[ Info: iteration 37, average log likelihood -1.245450
[ Info: iteration 38, average log likelihood -1.243707
[ Info: iteration 39, average log likelihood -1.242028
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.240413
[ Info: iteration 41, average log likelihood -1.253765
[ Info: iteration 42, average log likelihood -1.249831
[ Info: iteration 43, average log likelihood -1.247510
[ Info: iteration 44, average log likelihood -1.246183
[ Info: iteration 45, average log likelihood -1.245067
[ Info: iteration 46, average log likelihood -1.243890
[ Info: iteration 47, average log likelihood -1.242710
[ Info: iteration 48, average log likelihood -1.241484
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.240014
[ Info: iteration 50, average log likelihood -1.253787
┌ Info: EM with 100000 data points 50 iterations avll -1.253787
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3033410059949007
│     -1.3031487516699676
│      ⋮
└     -1.2537871904634228
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.250078
[ Info: iteration 2, average log likelihood -1.247436
[ Info: iteration 3, average log likelihood -1.245371
[ Info: iteration 4, average log likelihood -1.236606
[ Info: iteration 5, average log likelihood -1.206063
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.179880
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.185046
[ Info: iteration 8, average log likelihood -1.181702
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.168880
[ Info: iteration 10, average log likelihood -1.177700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.155737
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.172795
[ Info: iteration 13, average log likelihood -1.170850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.157317
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.158018
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.164083
[ Info: iteration 17, average log likelihood -1.166705
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.155756
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.159580
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.158392
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.159102
[ Info: iteration 22, average log likelihood -1.163184
[ Info: iteration 23, average log likelihood -1.154138
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.148286
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.153492
[ Info: iteration 26, average log likelihood -1.165785
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.153790
[ Info: iteration 28, average log likelihood -1.157890
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.144604
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.150315
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.152005
[ Info: iteration 32, average log likelihood -1.166203
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.153777
[ Info: iteration 34, average log likelihood -1.159023
[ Info: iteration 35, average log likelihood -1.149663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.142838
[ Info: iteration 37, average log likelihood -1.171220
[ Info: iteration 38, average log likelihood -1.155488
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.148683
[ Info: iteration 40, average log likelihood -1.153888
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.142349
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.153122
[ Info: iteration 43, average log likelihood -1.166140
[ Info: iteration 44, average log likelihood -1.152579
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.146089
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.151734
[ Info: iteration 47, average log likelihood -1.164257
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.152090
[ Info: iteration 49, average log likelihood -1.157524
[ Info: iteration 50, average log likelihood -1.148409
┌ Info: EM with 100000 data points 50 iterations avll -1.148409
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.25007760746609
│     -1.2474363866225922
│      ⋮
└     -1.1484092685424512
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.142242
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.141822
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.139707
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.118560
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.077906
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.080392
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.069906
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.076689
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058228
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.072888
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.062757
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.059822
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.061222
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.073426
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.048373
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.065827
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.064388
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.061267
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.055329
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069772
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.052448
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.068675
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.059819
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.058060
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.059863
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.073042
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.047874
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065319
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.064296
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.061197
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.055104
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.069667
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.052377
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.068548
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.059755
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.057940
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.059662
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.072898
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.047395
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063668
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.058909
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051971
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     10
│     13
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.059618
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.054181
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.049913
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.066167
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.051102
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.062782
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055741
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     17
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.066139
┌ Info: EM with 100000 data points 50 iterations avll -1.066139
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1422417966071257
│     -1.1418223448785543
│      ⋮
└     -1.0661392391775204
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3819887372378308
│     -1.382079111540555
│     -1.3819891600029102
│     -1.3810915250794933
│      ⋮
│     -1.0627821275469933
│     -1.0557413281455723
└     -1.0661392391775204
32×26 Array{Float64,2}:
 -0.120819    -0.0210527    0.0072555    0.0346239    0.0441844    0.0396796    -0.0741303   -0.0759329  -0.0157601    -0.138093    -0.189944     0.0038972   -0.115434     0.024113    -0.0361604    -0.100789     0.0767043   -0.25399      0.025606     0.04739      -0.0984754    0.0122986   -0.00214985  -0.110093     0.0502668   -0.00555372
 -0.0346101    0.066323     0.153727     0.0836982   -0.0377498    0.0205212     0.148419     0.118977    0.0230196    -0.0436846   -0.0627973   -0.018014     0.0319894    0.110711    -0.0619537    -0.0826659    0.13099      0.259776     0.119892    -0.0437131     0.00863112   0.123211     0.0136272   -0.0274706   -0.0173346    0.0731032
 -0.0294278   -0.0751282   -0.10117      0.0984529   -0.0302222    0.0309831    -0.581986     0.0513605   0.0458131    -0.201427     0.0577628   -0.0744452    0.184305    -0.0686592    0.000416027  -0.0312031   -0.0776943   -0.259033     0.349832    -0.108556     -0.0256106   -0.0537398    0.274643     0.172276     0.145438     0.0631102
  0.0146674    0.0379081   -0.0423308   -0.0420475    0.0579157   -0.174291      0.321606     0.290016    0.088592     -0.202772    -0.0734017   -0.0746853    0.174233    -0.0679696   -0.00979837   -0.0215436   -0.00930384   0.43856     -0.303441    -0.171234      0.0194697   -0.0611335   -0.288323     0.179629     0.144888     0.0631578
  0.0868978   -0.0422571   -0.0870885    0.139508    -0.00580504  -0.0238562    -1.11777      0.11923     0.0423607    -0.0136402   -0.0405062    0.0240826   -0.00596347  -0.0361762    0.106557     -0.0667398    0.0319649   -0.324402     0.0737771    0.0516991    -0.0303514    0.229763     0.0788017   -0.0359925   -0.040261     0.200394
  0.0834809    0.195631    -0.0862671   -0.073023     0.00937316   0.00735483    0.810619     0.0168441   0.0390327     0.135973     0.0678597    0.0211635   -0.00912491  -0.0370704    0.0987525    -0.0749621    0.0321143   -0.336246     0.100151     0.000379721  -0.117918     0.213242     0.161012    -0.0315301    0.156304     0.142422
 -0.0880745   -0.103126    -0.0546524   -0.111697     0.0308219    0.0295575     0.0828764   -0.238092    0.00968076   -0.0944508    0.0101198    0.284254     0.00382479   0.00733579  -0.0819533     0.138105     0.173376    -0.0967647   -0.0687366   -0.0850216     0.0982228   -0.0695253    0.0930065    0.00215043   0.126244    -0.134027
 -0.0534185   -0.120987    -0.0253837   -0.0659154   -0.0843747   -0.0379182    -0.206406     0.136857    0.0118037    -0.110057     0.0322821    0.141295    -0.115504     0.00356916  -0.0862496     0.0557106    0.114943     0.0169611   -0.0567759   -0.0913154     0.0886442   -0.0915458   -0.0252371   -0.0996167   -0.0689878   -0.131735
 -0.0368853   -0.00888862   0.128756    -0.0316709    0.0580538    0.121766     -0.0762882   -0.0844509   0.0556728     0.129652    -0.0241535    0.0487938    0.0261523   -0.0657924   -0.102076     -0.201966    -0.15805     -0.0174527    0.00834851  -0.15456      -0.266449    -0.157774     0.0114354   -0.0685392    0.0927306    0.019421
 -0.109233    -0.0933458    0.187504    -0.0439957   -0.0253648    0.0998748    -0.00896636  -0.0860818   0.0997122     0.134204    -0.0195914    0.0528175    0.142942    -0.189342    -0.0668888     0.0607893    0.370798    -0.0519567    0.00793156   0.202644      0.607988    -0.157406     0.00195996  -0.0953482    0.0103242   -0.0923477
  0.0450423    0.172333    -0.0489737   -0.152775     0.00205115   0.136818     -0.0504283   -0.160318   -0.114983      0.00880144   0.118092     0.167056    -0.0943868    0.1095      -0.0155306    -0.708279    -0.0223293    0.0418332    0.0694871   -0.037312      0.290912    -0.148461     0.0167858   -0.0784465   -0.204749    -0.00662397
  0.133405    -0.0826579    0.014034    -0.141369     0.0745632    0.130871     -0.064066    -0.118506    0.105565      0.00442895  -0.0488274    0.161785    -0.107956     0.128835    -0.0120434     0.683921     0.089708     0.0506522    0.0349231    0.00863462    0.297259    -0.0921938    0.0939649   -0.0803393    0.181446    -0.0547354
  0.0926055    0.00774763  -0.0712295    0.0515725   -0.0838752   -0.0239143     0.120104    -0.0459069   0.112951      0.141772    -0.0216907   -0.0101314    0.0230819   -0.0677022   -0.129405      0.237113     0.0144432    0.0654593    0.110389    -0.0862958    -0.116231     0.0832299   -0.105771    -0.109183    -0.0278445   -0.0375323
 -0.0477868    0.0101886    0.151037    -0.0230953   -0.0834005    0.0630053    -0.00637176   0.0459834   0.118131     -0.0100384   -0.0569335    0.0750548   -0.0528044    0.0312015   -0.0620137     0.0324046    0.0260906    0.106619    -0.0279908   -0.0209698     0.0475761   -0.0297875   -0.00560947  -0.0490925    0.168028     0.0155314
  0.065283    -0.00627096  -0.0538794    0.0651997    0.00946384   0.177224      0.0514651    0.0257293   0.0223531    -0.0386882   -0.268515     0.102538     0.0913747    0.122348     0.0776836     0.044966    -0.129418     0.0844789    0.0820159    0.0288875    -0.0164171    0.00474951   0.0857882    0.108464    -0.0105686   -0.120572
  0.0929189   -0.00367488  -0.0104288   -0.0804448   -0.0127883    0.0539294    -0.0424725   -0.0186455  -0.181823     -0.0248697   -0.234524     0.0305856    0.0781276   -0.058588     0.135804      0.328538    -0.00390054   0.0395379    0.118219    -0.0164441     0.0534747    0.0187125    0.109547    -0.0870228   -0.0818689   -0.0445449
 -0.00713947   0.0651926    0.10409     -0.0551408   -0.102204    -0.141411     -0.00776181  -0.0347841   0.127174     -0.115207    -0.00988475   0.00464057   0.051155    -0.0681035   -0.179895     -0.10214      0.0525161   -0.0598005   -0.0934486   -0.110433      0.108362     0.0850986    0.0134988   -0.035104    -0.0182462   -0.121251
  0.105901    -0.0549347    0.0784457   -0.0194873    0.0888796   -0.190325     -0.102946     0.116225   -0.0177707     0.0938035   -0.0268624   -0.0318903    0.0654297    0.155008    -0.190769      0.0775964   -0.123908    -0.0604303   -0.00635258   0.116797     -0.0187606   -0.036829     0.255836    -0.161161    -0.183815     0.0206692
 -0.0873304    0.0985935   -0.0598518    0.00124417   0.120919     0.0410356    -0.170873     0.186886    0.007638      0.114579    -0.211541    -0.00340597  -0.0286503   -0.0894366   -0.0889067    -0.153054    -0.0944806   -0.140417    -0.0175256   -0.0940017     0.00952624  -0.111945    -0.0459887    0.0720258    0.0651915   -0.00493179
  0.0173699    0.121327     0.114263     0.0275911    0.12237      0.0429538    -0.0659775   -0.099031   -0.117735     -0.0731679   -0.27814     -0.0588718   -0.0867149   -0.104719     0.0075419    -0.153504     0.502959    -0.169922     0.00338765  -0.11525      -1.16842e-6  -0.10707     -0.0767935    0.056194     0.0582679   -0.00679006
  0.154891    -0.00477165   0.132012    -0.00925871   0.00609389  -0.0638138     0.0661171   -0.103759   -0.158509     -0.0434946    0.0717925    0.00953155  -0.116154    -0.00447634  -0.0137386     0.124918     0.0386706    0.0292174    0.0120352   -0.0619112    -0.0966174   -0.0130259   -0.110288     0.0738857   -0.101552    -0.0698123
 -0.0306525   -0.0377677   -0.0241711   -0.0660176    0.0665078    0.0685601    -0.119139    -0.0158137  -0.000480615   0.0643065   -0.0214656   -0.0363889    0.0693767    0.107658     0.0347528    -0.128961    -0.0815666    0.143377    -0.146135    -0.0673668     0.1529      -0.0372504   -0.108581     0.131519    -0.165627     0.0813048
  0.00413488   0.0215779   -0.0079138   -0.12429     -0.00918819  -0.0655813     0.00197661  -0.0581377   0.0106496    -0.13706      0.0634714    0.0276522   -0.0191781    0.0340069    0.101006      0.173542     0.134838    -0.0450076   -0.107221    -0.0657992    -0.036717     0.0462247    0.100965    -0.0102674    0.107224    -0.55092
 -0.00646348   0.0212835   -0.00898033   0.210143     0.0318176   -0.0425514     0.106294    -0.0717352  -0.0163041     0.478593    -0.0243699    0.00742144  -0.0233627    0.0854998    0.133067      0.197235     0.134766     0.0526854    0.154483    -0.281363     -0.0340045    0.0993147   -0.0266374   -0.0108961    0.0969471    0.399863
  0.0357617   -0.0697217    0.0403624   -0.0844629   -0.048991    -0.0445644     0.0379209   -0.0551722   0.0108625    -0.0881874   -0.0998375   -0.0307527    0.0600434   -0.0424698   -0.0213505    -0.00986138   0.0510518   -0.00439708   0.0364743   -0.0328865     0.012786    -0.0380085    0.0242228   -0.0394965   -0.0013157    0.0529394
 -0.0662571    0.086247    -0.0180239   -0.0104086    0.0954485   -0.0756137    -0.0290583    0.0697277   0.142054     -0.0518381   -0.00546321   0.204619     0.166405    -0.185748     0.164247     -0.166149     0.0130481    0.0284284   -0.205366     0.0207716    -0.0498083   -0.107019    -0.136249    -0.0123927    0.0695706    0.0182178
  0.0347772    0.0609632    0.0147764   -0.0651487   -0.0475546    0.120012     -0.0193067   -0.0141672  -0.170381     -0.145269     0.154772    -0.0619784    0.0514949   -0.00448263  -0.00480631   -0.11449     -0.0143588   -0.234635    -0.0230381   -0.0625533     0.00683387   0.111854    -0.0211296    0.0088057   -0.00762342   0.0848653
  0.101458    -0.167532    -0.0821959    0.0640841   -0.0151637    0.132949     -0.0985325   -0.14511     0.0383226     0.094444    -0.0210195   -0.0483693   -0.155383    -0.024807    -0.100946     -0.0307451    0.149664     0.049114    -0.0946697    0.0119367    -0.202761     0.149469    -0.113565    -0.0334827    0.154846    -0.0268897
 -0.0460993   -0.0778294   -0.0793868   -0.0730712    0.111072    -0.0021109    -0.0165297    0.119127   -0.0280169     0.0240581    0.010797    -0.109159     0.00956386  -0.0335066    0.0421566    -0.0683894   -0.0904392   -0.00490153  -0.049946     0.0204962    -0.0661401   -0.0300741    0.11447     -0.0523225   -0.026671     0.0503706
 -0.123732     0.0322884    0.10418     -0.0652994    0.0469024   -0.0272472    -0.120761     0.0137767   0.0607615     0.0825085    0.0404869    0.0309119   -0.0888851   -0.00350956   0.035437      0.0647185   -0.0653265    0.00803552  -0.0713      -0.0387578    -0.00421763   0.0359047   -0.122157     0.0179213   -0.0597308   -0.0325937
 -0.00985461  -0.0427157   -0.0193735   -0.0223181   -0.0210136   -0.000449865  -0.0863368    0.0438085  -0.041394     -0.0716805   -0.0790897    0.00610916  -0.0693523    0.0109728    0.0354445    -0.0728336    0.0202788    0.0625406    0.0297069    0.0200984    -0.0287563    0.0206051   -0.0737831   -0.0237128   -0.0619461   -0.0337631
 -0.0213911    0.00745424   0.0557583   -0.0604658    0.0121952    0.118769      0.0469799    0.0666291  -0.132515      0.0369456    0.0486015    0.0270353    0.15579     -0.118833    -0.0271695    -0.0273774    0.0541967    0.0219589    0.123267     0.0508778     0.0923909    0.0278049    0.0605586    0.0334827    0.00190704  -0.0378747[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.051126
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.042174
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.051047
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.041802
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.051049
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041764
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051047
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041756
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051044
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.041751
┌ Info: EM with 100000 data points 10 iterations avll -1.041751
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.578975e+05
      1       6.561612e+05      -2.017362e+05 |       32
      2       6.284276e+05      -2.773365e+04 |       32
      3       6.121473e+05      -1.628032e+04 |       32
      4       5.989134e+05      -1.323388e+04 |       32
      5       5.888263e+05      -1.008704e+04 |       32
      6       5.833501e+05      -5.476201e+03 |       32
      7       5.806527e+05      -2.697462e+03 |       32
      8       5.793699e+05      -1.282740e+03 |       32
      9       5.786482e+05      -7.217313e+02 |       32
     10       5.781153e+05      -5.328698e+02 |       32
     11       5.777459e+05      -3.694133e+02 |       32
     12       5.775134e+05      -2.324952e+02 |       32
     13       5.773293e+05      -1.841686e+02 |       32
     14       5.771975e+05      -1.317533e+02 |       32
     15       5.771052e+05      -9.235282e+01 |       31
     16       5.770367e+05      -6.848618e+01 |       31
     17       5.769911e+05      -4.556701e+01 |       32
     18       5.769547e+05      -3.644482e+01 |       32
     19       5.769016e+05      -5.310900e+01 |       30
     20       5.768120e+05      -8.958090e+01 |       32
     21       5.766790e+05      -1.329270e+02 |       31
     22       5.764887e+05      -1.903118e+02 |       32
     23       5.762654e+05      -2.233046e+02 |       32
     24       5.760127e+05      -2.527048e+02 |       32
     25       5.758167e+05      -1.960632e+02 |       31
     26       5.757169e+05      -9.978467e+01 |       31
     27       5.756645e+05      -5.237433e+01 |       32
     28       5.756364e+05      -2.806497e+01 |       30
     29       5.756231e+05      -1.335100e+01 |       26
     30       5.756166e+05      -6.493925e+00 |       26
     31       5.756111e+05      -5.456457e+00 |       21
     32       5.756089e+05      -2.281103e+00 |       17
     33       5.756079e+05      -9.636332e-01 |       13
     34       5.756074e+05      -5.251563e-01 |       12
     35       5.756069e+05      -5.094593e-01 |        6
     36       5.756061e+05      -7.977292e-01 |       10
     37       5.756055e+05      -5.244116e-01 |        5
     38       5.756052e+05      -3.712313e-01 |        5
     39       5.756047e+05      -4.213202e-01 |        5
     40       5.756044e+05      -3.061123e-01 |        3
     41       5.756039e+05      -5.147531e-01 |        7
     42       5.756035e+05      -4.281206e-01 |        2
     43       5.756035e+05      -1.685908e-02 |        2
     44       5.756034e+05      -5.937019e-02 |        2
     45       5.756033e+05      -6.759458e-02 |        2
     46       5.756033e+05      -6.304508e-02 |        0
     47       5.756033e+05       0.000000e+00 |        0
K-means converged with 47 iterations (objv = 575603.284593482)
┌ Info: K-means with 32000 data points using 47 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.293745
[ Info: iteration 2, average log likelihood -1.262898
[ Info: iteration 3, average log likelihood -1.233836
[ Info: iteration 4, average log likelihood -1.202243
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.171750
[ Info: iteration 6, average log likelihood -1.160899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.128686
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.092836
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     22
│     26
│     27
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.037496
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.097699
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.060908
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.032264
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     19
│     22
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.038711
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.074975
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.064832
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.048941
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.062346
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      8
│     13
│     19
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.030783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.080400
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.072044
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.073273
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.033071
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     19
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.063159
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060632
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.066067
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.032547
[ Info: iteration 28, average log likelihood -1.068494
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     13
│     19
│     22
│     23
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.010131
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057221
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.064088
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     13
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.023044
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.065010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.089693
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.051903
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     22
│     26
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.005277
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     23
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.063661
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.088010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.047432
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.001794
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     22
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.066435
[ Info: iteration 43, average log likelihood -1.087105
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.031839
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     26
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.027313
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.069764
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.063887
[ Info: iteration 48, average log likelihood -1.043064
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     19
│     23
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.998461
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.086070
┌ Info: EM with 100000 data points 50 iterations avll -1.086070
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.173808     0.0856641    0.112642    -0.111037      0.162504    -0.129815     0.0505575    0.0391666    0.0243547   -0.148978    -0.0499579   -0.0600865   -0.0131561    0.0663463    0.167995    -0.00543822  -0.0398371   -0.147213     -0.0206031    -0.0937987    0.00565573  -0.00124884   0.114008    -0.0588912    -0.0570564     0.098529
 -0.00779567   0.0668261    0.10429     -0.0520033    -0.104896    -0.142599    -0.00775182  -0.0364234    0.131934    -0.117772    -0.00770219   0.0034988    0.0518696   -0.0691362   -0.184866    -0.102602     0.0535564   -0.0587555    -0.0949313    -0.109984     0.109502     0.0855664    0.0114451   -0.0323705    -0.0198629    -0.124562
 -0.0665612    0.0862491   -0.0180821   -0.00972379    0.094916    -0.0751991   -0.0292744    0.0699274    0.1428      -0.0496957   -0.00428706   0.206618     0.166691    -0.188296     0.163265    -0.166675     0.0132517    0.0268239    -0.205655      0.0219743   -0.0502032   -0.107551    -0.136136    -0.0124817     0.0693701     0.0169962
  0.0323037    0.0549232    0.01081     -0.065331     -0.0459519    0.113664    -0.0194925   -0.0137965   -0.162195    -0.129786     0.148666    -0.0604086    0.0505962   -0.00358549   0.0102735   -0.107002    -0.0065491   -0.21916      -0.0225812    -0.0532073    0.00920402   0.101678    -0.0256354    0.000313959  -0.0051689     0.0808636
 -0.0433416   -0.0262565   -0.0646546    0.0348744     0.028191    -0.0386805   -0.280425     0.153113     0.0499326   -0.169943    -0.0441935   -0.0556846    0.0840382   -0.0465844   -0.00161382  -0.0659587   -0.0253578    0.00648155   -0.000653898  -0.0885875   -0.0320438   -0.0390489    0.00686507   0.136466      0.125069      0.0649311
  0.0826215    0.0740819   -0.0863507    0.0387239     0.00376893  -0.00779223  -0.179278     0.0710756    0.0402133    0.0644103    0.0139431    0.0235278   -0.00808525  -0.0364922    0.103233    -0.0691805    0.0325547   -0.33463       0.0878229     0.0291964   -0.0761766    0.222629     0.12005     -0.0336009     0.0610768     0.17204
  0.101129    -0.0552228    0.0763929   -0.0182925     0.0847813   -0.189847    -0.100309     0.118721    -0.0190452    0.0893343   -0.0268062   -0.0324372    0.0665247    0.15458     -0.196414     0.0744706   -0.119484    -0.0600509    -0.00540678    0.116394    -0.0177378   -0.0383987    0.251405    -0.157425     -0.182887      0.0218601
  0.0757403   -0.0759985    0.00632072  -0.0145022    -0.121075    -0.196689    -0.046547     0.111842     0.0529389   -0.0413065   -0.158242    -0.0464551    0.0728251   -0.0278807   -0.00435996   0.0078422    0.11774      0.208579      0.238564      0.16133      0.0354529   -0.189274    -0.10605     -0.213298     -0.134794      0.0914811
  0.155644    -0.00539673   0.132537    -0.0117142     0.00561578  -0.0654967    0.0672423   -0.102959    -0.155887    -0.043879     0.0674455    0.00887125  -0.115928    -0.00420802  -0.0196939    0.124369     0.0381501    0.0286842     0.00885904   -0.0619484   -0.0974755   -0.0132415   -0.112121     0.073373     -0.100914     -0.0691856
  0.0239351    0.0527734    0.160429    -0.00350285   -0.0335023    0.0397051   -0.102403     0.0266812    0.217149    -0.0028724   -0.105981     0.0540948   -0.110741     0.0269351   -0.0160308    0.171257    -0.0197555    0.0488053     0.0380863     0.134045     0.0208964   -0.0608156    0.12635      0.0265015     0.232331      0.0293598
 -0.0800908   -0.110505    -0.0420499   -0.0880348    -0.00117756   0.00857386  -0.0284892   -0.10346      0.0107799   -0.0979087    0.0169376    0.214149    -0.0441033    0.00709327  -0.0803804    0.104364     0.155447    -0.0481174    -0.0644222    -0.0842982    0.077864    -0.0695118    0.0329348   -0.0423884     0.0445502    -0.136693
  0.0869719   -0.0199605   -0.0153195   -0.0730361    -0.0141313    0.0613858   -0.0455208   -0.02122     -0.178923    -0.0167887   -0.237499     0.027923     0.0766517   -0.0643722    0.130986     0.332134    -0.0040819    0.0417941     0.143283     -0.0245492    0.0550211    0.0195714    0.103007    -0.0822078    -0.0816472    -0.0447448
 -0.0458031   -0.158313     0.00793702  -0.121791     -0.108883     0.0601067    0.128709    -0.192044    -0.00342778  -0.0910575   -0.0917709   -0.0192536    0.0373151   -0.109132    -0.115566    -0.0350832    0.00982872  -0.000852283  -0.105648     -0.204235    -0.0417379    0.0700086    0.0338527    0.0719155     0.136175     -0.001209
 -0.0378634    0.0611354    0.147174     0.0799499    -0.0361       0.0202919    0.153843     0.109431     0.0185453   -0.0474321   -0.0678252   -0.0177506    0.0225396    0.107823    -0.0656228   -0.0861074    0.127695     0.245451      0.119197     -0.0386015    0.00543722   0.121116     0.0160188   -0.0286908    -0.0168667     0.0745546
 -0.0293132   -0.0413486   -0.00114488  -0.137991      0.0476029   -0.0192461   -0.0142622    0.099566     0.0732399    0.00212131  -0.00890016  -0.18427      0.0526682   -0.0502279    0.0330293   -0.0866731   -0.0297862    0.062248     -0.0681356    -0.075194    -0.0845193    0.00862788   0.0470683   -0.114353      0.0891923    -0.00119954
  0.0535162    0.13726     -0.0450648   -0.153785      0.00933964   0.136834    -0.0568938   -0.158348    -0.0889016    0.0191686    0.104921     0.166676    -0.0960781    0.123611    -0.0137288   -0.710468    -0.0293453    0.0426721     0.0729302    -0.0434184    0.294922    -0.138342     0.0376675   -0.0783047    -0.170178     -0.0169563
 -0.0306141   -0.0364927   -0.0238846   -0.0661515     0.0671907    0.0710502   -0.122793    -0.0171166    0.00283958   0.0625182   -0.0274005   -0.0359531    0.0692081    0.105309     0.0336152   -0.128197    -0.0798669    0.145308     -0.142373     -0.0675617    0.153383    -0.0370619   -0.108866     0.133325     -0.163982      0.0791864
 -0.131474    -0.0507839   -0.125646     0.0303867    -0.134063     0.00508187   0.0350226    0.0352535   -0.114881    -0.0864134   -0.0729       0.11402     -0.0667338    0.119581     0.152066    -0.0981853    0.0189774    0.0514505     0.0988375     0.0300656   -0.0538981    0.0119766   -0.241892     0.0316789    -0.174631     -0.102004
 -0.0898734   -0.0240084    0.0078454    0.024038      0.0578912    0.04578     -0.0852416   -0.0493656   -0.00381865  -0.148468    -0.22986     -0.0154757   -0.0429531    0.011517    -0.04067     -0.076638     0.0585382   -0.301173      0.0148216     0.0555006   -0.126462     0.0137425   -0.0168173   -0.0973769     0.0680734    -0.0283779
  0.0788149   -0.0834748    0.029412     0.0359014    -0.0144992    0.00853303  -0.188339    -0.0418265   -0.0712368    0.00585051   0.0723772    0.161552    -0.145438    -0.151649    -0.166594    -0.119366     0.0397223    0.0416625    -0.0235592     0.168181    -0.00646693  -0.0350478    0.108282     0.0384287    -0.0708483     0.0319736
 -0.0327478    0.11117      0.0298767    0.014886      0.121858     0.0423695   -0.116451     0.0401993   -0.0569062    0.0169074   -0.246097    -0.0302644   -0.0583972   -0.0972852   -0.0401354   -0.153186     0.214717    -0.155677     -0.00696817   -0.104588     0.00486138  -0.108965    -0.0631234    0.0638175     0.0626556    -0.00561553
 -0.142124     0.0509587    0.154865    -0.0442443     0.0292012   -0.0255999   -0.152787     2.70231e-5   0.0817285    0.104397     0.0407147    0.0330314   -0.0952186   -0.0109707    0.0403373    0.0807386   -0.0600617    0.0488133    -0.0663411    -0.0474864    0.0511197    0.0437394   -0.151338     0.0105159    -0.0722928    -0.0441304
 -0.0871128    0.0261644    0.073097    -0.142044      0.00090585   0.0987871    0.0522383    0.0361919   -0.116928    -0.0879512   -0.00743716  -0.0103806    0.13954      0.0146523    0.00288144  -0.10062      0.15371      0.0770008     0.234235      0.106584     0.151785     0.108182     0.0417155    0.0397592     0.000521947   0.0317361
  0.114513    -0.0618951    0.0150326   -0.13455       0.0690625    0.130102    -0.0558877   -0.117733     0.0933829    0.00259442  -0.0457556    0.154986    -0.10509      0.103076    -0.0152133    0.783467     0.12873      0.048952      0.0288741    -0.0026042    0.280162    -0.103789     0.0762039   -0.0809564     0.172988     -0.0485396
  0.0590721   -0.00930088  -0.0564714    0.0528001     0.00611436   0.163549     0.0458469    0.0242156    0.0230591   -0.0389594   -0.266657     0.0968165    0.0924038    0.119571     0.0800836    0.0474968   -0.123037     0.0798534     0.0828328     0.0297516   -0.0282044    0.00411083   0.0805953    0.107999     -0.0113001    -0.118691
 -0.00325408   0.0211591   -0.0089323    0.0414272     0.0108661   -0.0524138    0.0573931   -0.0667674   -0.00181573   0.169559     0.0158865    0.0170685   -0.0207129    0.0594257    0.117994     0.186404     0.134914     0.00401287    0.0281159    -0.172007    -0.0369442    0.071941     0.0393909   -0.0102555     0.102962     -0.0777282
  0.0865923   -0.0523635    0.0168464    0.0593449     0.00900107   0.169177    -0.00258936   0.221172    -0.114795     0.145281     0.0623521    0.0531526    0.137692    -0.324786    -0.0159517    0.0426902   -0.0107577   -0.0209381     0.0461009     0.00415532   0.0189486   -0.109692     0.0927432    0.00513047   -0.0222615    -0.0816412
  0.0962578    0.00234293  -0.0911685    0.0564841    -0.0810913    0.00133903   0.186531    -0.0539126    0.0877303    0.13784     -0.00988581  -0.0158059    0.0478381   -0.0707859   -0.127376     0.272161     0.00917623   0.0257446     0.118238     -0.092012    -0.145463     0.0668351   -0.096523    -0.103942     -0.0121016    -0.0558757
 -0.101854    -0.0413707    0.24716     -0.0273264     0.0154506    0.102981    -0.0498463   -0.081137     0.0784928    0.137255    -0.0228485    0.0428767    0.0920751   -0.130925    -0.0855959   -0.13601      0.110095    -0.0397997     0.0120186     0.0695073    0.302784    -0.166981     0.00817593  -0.0840471     0.0652959    -0.0354341
  0.151573    -0.143575    -0.0990387    0.0483219    -0.0236133    0.0991869   -0.0780207   -0.319294     0.0460757    0.0993505   -0.0346639   -0.0381554   -0.111589    -0.0269228   -0.139806    -0.0173758    0.145729     0.0567297    -0.0672174     0.0298218   -0.253392     0.13059     -0.147308    -0.0512492     0.16919      -0.0149472
 -0.0727341   -0.104782    -0.0955861    0.000596451   0.129992     0.0517679   -0.113368     0.114755    -0.112491     0.0199513   -0.0777005   -0.0461494   -0.0565016    0.0160064    0.0187163    0.0429429   -0.0962451   -0.0413721    -0.0289949     0.0731941   -0.0271422   -0.0173099    0.0403715    0.00595968   -0.109006      0.0171872
 -0.125626    -0.0386767    0.0988593   -0.0440687    -0.133658     0.0852807    0.0852567    0.0683115    0.0123132   -0.0165179   -0.00161259   0.0874293    0.00682296   0.0352241   -0.118221    -0.113774     0.0791049    0.16122      -0.105418     -0.195524     0.0687545    0.0107861   -0.13642     -0.142032      0.0828533    -0.014476[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.084659
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.042013
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.007807
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     13
│     22
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.028144
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.047455
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     22
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007733
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.025171
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.015238
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.026962
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     22
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.021659
┌ Info: EM with 100000 data points 10 iterations avll -1.021659
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0155726   0.0318848   -0.134029    -0.127042    -0.0365601   -0.0374418    0.00505334  -0.0590776    0.143392    -0.103862     0.0694006    0.112534    -0.141314   -0.167462     0.0933845  -0.119465    -0.0241485    -0.0224183    0.0442336    0.111838     0.122336    -0.0480555   -0.0825234   -0.121577     -0.0657063     0.0855562
 -0.191189   -0.200824    -0.0469985   -0.153836     0.109847    -0.0490134   -0.0243211   -0.0872111   -0.0243728   -0.0218739   -0.0124017    0.0633955    0.104657   -0.169468    -0.0342793   0.159797     0.135003      0.00664471  -0.107737    -0.0792589    0.0413297   -0.0343732   -0.0407321    0.075358     -0.116475      0.0887518
  0.0197931   0.00939346   0.136771    -0.12957     -0.0639237   -0.0959887    0.120315     0.125257    -0.0309793    0.0583044    0.0197402   -0.0102009   -0.126379   -0.161105     0.110225   -0.143384    -0.180776      0.0859789   -0.026949     0.185545     0.0337726    0.072395     0.0440002    0.163871      0.0672192    -0.192568
  0.0257814  -0.0104648   -0.0318171   -0.0755912   -0.0165378   -0.152589     0.164553     0.00605366   0.152695    -0.0301171    0.0507952    0.0354327   -0.146052   -0.0373381    0.0617983   0.022439     0.0669478     0.0620447   -0.187961     0.0366407    0.064215    -0.0342128    0.0471245   -0.0196043    -0.102872     -0.0418015
 -0.215309   -0.0202743    0.189059    -0.1715      -0.0726514    0.0900011   -0.0157055   -0.0960453    0.0328574    0.0987648   -0.0561738    0.0575485   -0.0918103  -0.0744016   -0.0813885  -0.00865621   0.0391308    -0.0589993    0.121723     0.110144    -0.00888288  -0.0562705    0.106483    -0.0652879     0.00643611    0.144981
  0.0499131   0.0267945    0.0999136   -0.135227     0.17742     -2.22668e-5   0.0396921    0.0295398    0.00167857   0.0311411   -0.152649    -0.109224    -0.16957    -0.053181     0.114658   -0.127598    -0.0672034    -0.145743     0.0936442   -0.0136172    0.078997     0.0489637    0.0224763   -0.196218     -0.0498453     0.106261
 -0.0637385   0.0897548    0.0211855   -0.164197    -0.0830084   -0.0737988   -0.0742692   -0.1063       0.31253      0.0509186   -0.0921848    0.0615596   -0.0924218   0.242362    -0.0283776   0.140229     0.0583382     0.197628    -0.117596    -0.0408178    0.131811     0.00611799  -0.0150523    0.0618191     0.0325369     0.00716243
 -0.0433665  -0.0979772   -0.108212     0.00344852   0.0852748   -0.0211244    0.0489908    0.104714     0.00305389  -0.0884622    0.057805     0.108756    -0.0951961  -0.0844872    0.141006   -0.132263    -0.195533     -0.0817502   -0.0960186   -0.137892    -0.0836434    0.115602    -0.0977056    0.0322552    -0.000863165   0.00740918
 -0.0522892  -0.0298159    0.0238774    0.0173764    0.0156061   -0.0142956   -0.151579    -0.0129606   -0.0671121    0.0527478   -0.0916253    0.150477     0.115554   -0.104791    -0.0499882  -0.00646592   0.0221112    -0.0208748    0.0742952   -0.0674655    0.0703687   -0.00432148   0.00489151   0.0782555    -0.0542124    -0.00994513
 -0.0903717   0.054061     0.252757     0.0297927   -0.0649419   -0.183794     0.0808067    0.00541774  -0.0107135    0.104754     0.0477941    0.0242007   -0.0756239   0.0871557   -0.0176751   0.0637117    0.0622515    -0.00284174   0.0341955    0.0442587    0.100604    -0.00992744  -0.132692     0.0877569    -0.0487021    -0.0259076
  0.21384     0.0337486    0.00130529  -0.161834    -0.0540295   -0.139012    -0.078368    -0.01085      0.0597611    0.0178525    0.120789    -0.0365075    0.0915668   0.0903831   -0.165206   -0.015776    -0.11441      -0.040695     0.0104712    0.0243857   -0.0294515   -0.0956354   -0.0563233   -0.103654     -0.0593759    -0.193001
  0.0800862  -0.00743339  -0.0955741   -0.0453069   -0.0540689   -0.0210886    0.0462625   -0.0238222   -0.0369793    0.0413408   -0.197407     0.149495     0.0337906   0.0539216   -0.0430263  -0.0426372   -0.0425044    -0.116396     0.0547336    0.0826792    0.059905    -0.294749    -0.101845     0.172395     -0.0733486    -0.099075
  0.0710728  -0.0406563   -0.0206461    0.0196703   -0.102004    -0.0012427   -0.157241     0.0850425   -0.0214791    0.0632863    0.0903956    0.178176     0.073621   -0.278691    -0.0160408   0.134811     0.0661446     0.0974384   -0.0453978    0.059864     0.0483939   -0.120254    -0.130672    -0.000359823   0.0111995     0.144737
  0.0653179  -0.120984     0.0858966    0.111551     0.102547     0.0318269   -0.0626026    0.0456659   -0.103817     0.0388275    0.0440395    0.0434332    0.190843   -0.00771677   0.0117486  -0.0724812   -0.000673181  -0.0856857    0.100538     0.151564     0.0155288   -0.168358     0.0195799    0.0723151     0.0231018    -0.0598423
 -0.0338918  -0.178401    -0.0375243    0.0562675    0.107665    -0.0464108    0.0166465   -0.0914305    0.066264     0.212488    -0.116391     0.0781764   -0.0327793   0.0139321   -0.125194    0.0480303   -0.158969     -0.155727     0.159122    -0.0441478    0.0228985    0.0161331    0.0932459   -0.046977      0.082992      0.0209758
  0.0436791  -0.0239001   -0.0446742   -0.0924896    0.157064    -0.110193    -0.103279    -0.197267     0.0434649    0.0805143   -0.113431     0.201687     0.107283   -0.0320547   -0.114733   -0.0421782    0.0468207    -0.0107478    0.0615697    0.0708055    0.157442    -0.130959    -0.138463     0.0120864    -0.0612586    -0.0414265
  0.0928207   0.0797779    0.0699816    0.0564938   -0.072302    -0.255681     0.0610627    0.00713131   0.0127456   -0.0601311    0.0298294   -0.191824     0.0456129   0.141549     0.111546   -0.038216    -0.0761814     0.127743     0.160869     0.0102425    0.00870464  -0.0514086   -0.0444663   -0.154565      0.0313125    -0.0695996
 -0.0592513   0.104883     0.0138053    0.113698     0.00365375  -0.10595      0.0182318   -0.0554263   -0.055234     0.118995     0.0629942    0.121933     0.0740577  -0.0156972    0.121794    0.0356784    0.0796656    -0.0919896    0.00429017   0.0897168   -0.013516    -0.0353687    0.0203841    0.142784      0.0967624    -0.18355
 -0.0484899   0.0746335    0.0532839    0.11489      0.104677     0.210932     0.164481    -0.0956819    0.0475979    0.236786    -0.0186797    0.0132507   -0.128091    0.113306     0.0829451   0.0516226    0.0985461     0.00262482   0.10768      0.0885182    0.0923222   -0.0822381   -0.109451    -0.00768276    0.0183955     0.118052
 -0.0826393  -0.0602349   -0.00722918   0.0220219   -0.0976732   -0.0102004   -0.0493512   -0.0599519   -0.0240708    0.214847     0.196691     0.0373478    0.108604   -0.178335    -0.105688    0.0325298   -0.113316      0.12279     -0.162861    -0.00473614  -0.0750397    0.180038    -0.0666418   -0.00359397   -0.0679971     0.0554881
 -0.113902    0.02218     -0.0447254   -0.188626    -0.00303515   0.0443167   -0.225617     0.0980349   -0.102862     0.0407762    0.0163536    0.0124411    0.0436308  -0.0829444    0.107677   -0.0198873   -0.106478     -0.126355     0.0261409    0.284412     0.157873     0.0528233    0.0461108    0.153493     -0.012425     -0.00508886
  0.0194274  -0.0716555   -0.234586    -0.0705996   -0.053948     0.0157829    0.0269782    0.0577615   -0.0634355   -0.0596882   -0.0653405   -0.0205323   -0.204808    0.0654131   -0.0488471  -0.121476    -0.0133022    -0.00959192  -0.0384417   -0.118275    -0.0179383   -0.00309163  -0.0448419    0.0325033     0.223842     -0.215494
 -0.0510638   0.150804    -0.0970194    0.0183589   -0.0875729   -0.0185419    0.00658777   0.168243    -0.226902     0.00831326  -0.0460265   -0.0875722    0.0461695  -0.0426389   -0.0768399   0.062317    -0.100605      0.0871507    0.0563085   -0.182778     0.116354    -0.116921     0.143608     0.159827      0.0362599     0.0575289
 -0.0346404   0.0921629    0.11883      0.203966    -0.0136635   -0.0607966   -0.015098    -0.0108481   -0.176858    -0.186324     0.0880051   -0.192727     0.0429628  -0.0197886   -0.0433853   0.0656269    0.16868      -0.0701943   -0.0745025    0.0481748    0.134979    -0.125481     0.0915661   -0.132567      0.105236      0.05006
  0.0531453   0.0412666   -0.0419641    0.064383    -0.146215    -0.0760364   -0.164757    -0.0647537    0.0635233   -0.0372711    0.141472    -0.0054198    0.0666702   0.0996184   -0.161106    0.0620036    0.0935702    -0.0497864    0.113994     0.0297392   -0.0698275    0.0684137   -0.0439358   -0.136154      0.124099     -0.0782954
 -0.182513   -0.0637766   -0.0141251   -0.107945    -0.0937558    0.0934222    0.0645815    0.155129    -0.0355524   -0.0340349    0.132801    -0.0656949    0.0459217   0.0798461   -0.0998692  -0.116893     0.0133377    -0.14898      0.168679    -0.0406405    0.0185174    0.119774    -0.0954545    0.032452     -0.0222291    -0.0227826
 -0.0139873   0.069518     0.011296     0.023412     0.02149      0.0072157    0.0806369    0.0670822    0.092899    -0.0854102    0.028815     0.0558436   -0.033972   -0.042932     0.104079    0.00510895   0.0461913    -0.0199412    0.0276409    0.00619065  -0.00839547  -0.0224745    0.0237156   -0.168339      0.0593713     0.0144897
  0.0898067   0.00142063  -0.169437     0.0400694    0.0629638   -0.103284     0.197252    -0.117813     0.0820602    0.045163    -0.00914814  -0.172954    -0.0575899  -0.0983977    0.120514   -0.280367     0.0396402    -0.15385     -0.0602983   -0.072585     0.0500599    0.0619963   -0.0484      -0.0587533     0.0202031    -0.0854209
 -0.236265    0.0355651   -0.0164346    0.0698064    0.0928183    0.0588678    0.0748197   -0.00363918  -0.0914919    0.131331     0.0747189   -0.0251276   -0.0533563  -0.0126797    0.0228703  -0.0477756   -0.0919731    -5.11518e-5  -0.0495828   -0.0249143   -0.0208365   -0.123063    -0.137921     0.0108138     0.0341084     0.11106
  0.0618439   0.0704062    0.136223     0.144081    -0.0972132   -0.168892     0.157669    -0.166634    -0.0612473    0.113342    -0.0670626   -0.109125     0.108844    0.0211882   -0.0968795   0.107018     0.265071     -0.0675137    0.0462681    0.113351    -0.0237019   -0.030294     0.140364    -0.0796062     0.10141      -0.0381753
  0.179961    0.0779956   -0.0364842   -0.0100192    0.173937     0.0783314   -0.0498842    0.124491    -0.00975352  -0.034603    -0.130041    -0.00377398  -0.0591128  -0.0309804    0.133581   -0.0540034    0.0153102    -0.085847    -0.169495     0.0808563   -0.145226     0.0831071    0.0919035   -0.170902     -0.0674173    -0.130888
 -0.0061783   0.149176    -0.0501086    0.0311752   -0.0873383    0.111537    -0.0645341    0.0529755    0.106378     0.033226     0.147025    -0.0997811    0.0174646   0.0387188    0.108257   -0.0303417   -0.0979752    -0.197057     0.0976583    0.0128021   -0.0572402   -0.0536954   -0.167983    -0.000475892   0.106667      0.110638kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4085183447613558
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408537
[ Info: iteration 2, average log likelihood -1.408484
[ Info: iteration 3, average log likelihood -1.408449
[ Info: iteration 4, average log likelihood -1.408408
[ Info: iteration 5, average log likelihood -1.408353
[ Info: iteration 6, average log likelihood -1.408266
[ Info: iteration 7, average log likelihood -1.408102
[ Info: iteration 8, average log likelihood -1.407751
[ Info: iteration 9, average log likelihood -1.407018
[ Info: iteration 10, average log likelihood -1.405806
[ Info: iteration 11, average log likelihood -1.404482
[ Info: iteration 12, average log likelihood -1.403614
[ Info: iteration 13, average log likelihood -1.403239
[ Info: iteration 14, average log likelihood -1.403105
[ Info: iteration 15, average log likelihood -1.403058
[ Info: iteration 16, average log likelihood -1.403040
[ Info: iteration 17, average log likelihood -1.403034
[ Info: iteration 18, average log likelihood -1.403031
[ Info: iteration 19, average log likelihood -1.403030
[ Info: iteration 20, average log likelihood -1.403029
[ Info: iteration 21, average log likelihood -1.403029
[ Info: iteration 22, average log likelihood -1.403029
[ Info: iteration 23, average log likelihood -1.403028
[ Info: iteration 24, average log likelihood -1.403028
[ Info: iteration 25, average log likelihood -1.403028
[ Info: iteration 26, average log likelihood -1.403028
[ Info: iteration 27, average log likelihood -1.403028
[ Info: iteration 28, average log likelihood -1.403028
[ Info: iteration 29, average log likelihood -1.403028
[ Info: iteration 30, average log likelihood -1.403028
[ Info: iteration 31, average log likelihood -1.403028
[ Info: iteration 32, average log likelihood -1.403028
[ Info: iteration 33, average log likelihood -1.403028
[ Info: iteration 34, average log likelihood -1.403027
[ Info: iteration 35, average log likelihood -1.403027
[ Info: iteration 36, average log likelihood -1.403027
[ Info: iteration 37, average log likelihood -1.403027
[ Info: iteration 38, average log likelihood -1.403027
[ Info: iteration 39, average log likelihood -1.403027
[ Info: iteration 40, average log likelihood -1.403027
[ Info: iteration 41, average log likelihood -1.403027
[ Info: iteration 42, average log likelihood -1.403027
[ Info: iteration 43, average log likelihood -1.403027
[ Info: iteration 44, average log likelihood -1.403027
[ Info: iteration 45, average log likelihood -1.403027
[ Info: iteration 46, average log likelihood -1.403027
[ Info: iteration 47, average log likelihood -1.403027
[ Info: iteration 48, average log likelihood -1.403027
[ Info: iteration 49, average log likelihood -1.403027
[ Info: iteration 50, average log likelihood -1.403027
┌ Info: EM with 100000 data points 50 iterations avll -1.403027
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.408537311771715
│     -1.4084839158800324
│      ⋮
└     -1.4030272007649163
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403046
[ Info: iteration 2, average log likelihood -1.402991
[ Info: iteration 3, average log likelihood -1.402955
[ Info: iteration 4, average log likelihood -1.402915
[ Info: iteration 5, average log likelihood -1.402867
[ Info: iteration 6, average log likelihood -1.402811
[ Info: iteration 7, average log likelihood -1.402748
[ Info: iteration 8, average log likelihood -1.402682
[ Info: iteration 9, average log likelihood -1.402616
[ Info: iteration 10, average log likelihood -1.402554
[ Info: iteration 11, average log likelihood -1.402499
[ Info: iteration 12, average log likelihood -1.402447
[ Info: iteration 13, average log likelihood -1.402399
[ Info: iteration 14, average log likelihood -1.402351
[ Info: iteration 15, average log likelihood -1.402302
[ Info: iteration 16, average log likelihood -1.402250
[ Info: iteration 17, average log likelihood -1.402196
[ Info: iteration 18, average log likelihood -1.402138
[ Info: iteration 19, average log likelihood -1.402079
[ Info: iteration 20, average log likelihood -1.402021
[ Info: iteration 21, average log likelihood -1.401965
[ Info: iteration 22, average log likelihood -1.401915
[ Info: iteration 23, average log likelihood -1.401870
[ Info: iteration 24, average log likelihood -1.401833
[ Info: iteration 25, average log likelihood -1.401802
[ Info: iteration 26, average log likelihood -1.401777
[ Info: iteration 27, average log likelihood -1.401756
[ Info: iteration 28, average log likelihood -1.401740
[ Info: iteration 29, average log likelihood -1.401726
[ Info: iteration 30, average log likelihood -1.401714
[ Info: iteration 31, average log likelihood -1.401704
[ Info: iteration 32, average log likelihood -1.401695
[ Info: iteration 33, average log likelihood -1.401686
[ Info: iteration 34, average log likelihood -1.401678
[ Info: iteration 35, average log likelihood -1.401670
[ Info: iteration 36, average log likelihood -1.401662
[ Info: iteration 37, average log likelihood -1.401654
[ Info: iteration 38, average log likelihood -1.401646
[ Info: iteration 39, average log likelihood -1.401637
[ Info: iteration 40, average log likelihood -1.401629
[ Info: iteration 41, average log likelihood -1.401620
[ Info: iteration 42, average log likelihood -1.401611
[ Info: iteration 43, average log likelihood -1.401601
[ Info: iteration 44, average log likelihood -1.401592
[ Info: iteration 45, average log likelihood -1.401582
[ Info: iteration 46, average log likelihood -1.401573
[ Info: iteration 47, average log likelihood -1.401563
[ Info: iteration 48, average log likelihood -1.401553
[ Info: iteration 49, average log likelihood -1.401544
[ Info: iteration 50, average log likelihood -1.401534
┌ Info: EM with 100000 data points 50 iterations avll -1.401534
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.403045878423504
│     -1.4029908192473948
│      ⋮
└     -1.4015341883818173
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.401539
[ Info: iteration 2, average log likelihood -1.401476
[ Info: iteration 3, average log likelihood -1.401424
[ Info: iteration 4, average log likelihood -1.401365
[ Info: iteration 5, average log likelihood -1.401292
[ Info: iteration 6, average log likelihood -1.401207
[ Info: iteration 7, average log likelihood -1.401112
[ Info: iteration 8, average log likelihood -1.401015
[ Info: iteration 9, average log likelihood -1.400924
[ Info: iteration 10, average log likelihood -1.400843
[ Info: iteration 11, average log likelihood -1.400774
[ Info: iteration 12, average log likelihood -1.400714
[ Info: iteration 13, average log likelihood -1.400664
[ Info: iteration 14, average log likelihood -1.400621
[ Info: iteration 15, average log likelihood -1.400585
[ Info: iteration 16, average log likelihood -1.400554
[ Info: iteration 17, average log likelihood -1.400528
[ Info: iteration 18, average log likelihood -1.400507
[ Info: iteration 19, average log likelihood -1.400488
[ Info: iteration 20, average log likelihood -1.400472
[ Info: iteration 21, average log likelihood -1.400457
[ Info: iteration 22, average log likelihood -1.400443
[ Info: iteration 23, average log likelihood -1.400429
[ Info: iteration 24, average log likelihood -1.400417
[ Info: iteration 25, average log likelihood -1.400404
[ Info: iteration 26, average log likelihood -1.400392
[ Info: iteration 27, average log likelihood -1.400380
[ Info: iteration 28, average log likelihood -1.400368
[ Info: iteration 29, average log likelihood -1.400356
[ Info: iteration 30, average log likelihood -1.400344
[ Info: iteration 31, average log likelihood -1.400333
[ Info: iteration 32, average log likelihood -1.400322
[ Info: iteration 33, average log likelihood -1.400311
[ Info: iteration 34, average log likelihood -1.400300
[ Info: iteration 35, average log likelihood -1.400289
[ Info: iteration 36, average log likelihood -1.400278
[ Info: iteration 37, average log likelihood -1.400268
[ Info: iteration 38, average log likelihood -1.400257
[ Info: iteration 39, average log likelihood -1.400247
[ Info: iteration 40, average log likelihood -1.400237
[ Info: iteration 41, average log likelihood -1.400226
[ Info: iteration 42, average log likelihood -1.400216
[ Info: iteration 43, average log likelihood -1.400206
[ Info: iteration 44, average log likelihood -1.400195
[ Info: iteration 45, average log likelihood -1.400185
[ Info: iteration 46, average log likelihood -1.400175
[ Info: iteration 47, average log likelihood -1.400164
[ Info: iteration 48, average log likelihood -1.400154
[ Info: iteration 49, average log likelihood -1.400143
[ Info: iteration 50, average log likelihood -1.400132
┌ Info: EM with 100000 data points 50 iterations avll -1.400132
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4015385252341461
│     -1.4014761823257016
│      ⋮
└     -1.4001322906600304
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.400132
[ Info: iteration 2, average log likelihood -1.400074
[ Info: iteration 3, average log likelihood -1.400024
[ Info: iteration 4, average log likelihood -1.399969
[ Info: iteration 5, average log likelihood -1.399905
[ Info: iteration 6, average log likelihood -1.399830
[ Info: iteration 7, average log likelihood -1.399741
[ Info: iteration 8, average log likelihood -1.399640
[ Info: iteration 9, average log likelihood -1.399530
[ Info: iteration 10, average log likelihood -1.399417
[ Info: iteration 11, average log likelihood -1.399306
[ Info: iteration 12, average log likelihood -1.399201
[ Info: iteration 13, average log likelihood -1.399104
[ Info: iteration 14, average log likelihood -1.399018
[ Info: iteration 15, average log likelihood -1.398941
[ Info: iteration 16, average log likelihood -1.398873
[ Info: iteration 17, average log likelihood -1.398812
[ Info: iteration 18, average log likelihood -1.398758
[ Info: iteration 19, average log likelihood -1.398709
[ Info: iteration 20, average log likelihood -1.398664
[ Info: iteration 21, average log likelihood -1.398621
[ Info: iteration 22, average log likelihood -1.398581
[ Info: iteration 23, average log likelihood -1.398542
[ Info: iteration 24, average log likelihood -1.398505
[ Info: iteration 25, average log likelihood -1.398468
[ Info: iteration 26, average log likelihood -1.398433
[ Info: iteration 27, average log likelihood -1.398399
[ Info: iteration 28, average log likelihood -1.398366
[ Info: iteration 29, average log likelihood -1.398334
[ Info: iteration 30, average log likelihood -1.398304
[ Info: iteration 31, average log likelihood -1.398276
[ Info: iteration 32, average log likelihood -1.398250
[ Info: iteration 33, average log likelihood -1.398226
[ Info: iteration 34, average log likelihood -1.398204
[ Info: iteration 35, average log likelihood -1.398184
[ Info: iteration 36, average log likelihood -1.398165
[ Info: iteration 37, average log likelihood -1.398148
[ Info: iteration 38, average log likelihood -1.398132
[ Info: iteration 39, average log likelihood -1.398118
[ Info: iteration 40, average log likelihood -1.398104
[ Info: iteration 41, average log likelihood -1.398091
[ Info: iteration 42, average log likelihood -1.398079
[ Info: iteration 43, average log likelihood -1.398068
[ Info: iteration 44, average log likelihood -1.398057
[ Info: iteration 45, average log likelihood -1.398047
[ Info: iteration 46, average log likelihood -1.398038
[ Info: iteration 47, average log likelihood -1.398029
[ Info: iteration 48, average log likelihood -1.398020
[ Info: iteration 49, average log likelihood -1.398012
[ Info: iteration 50, average log likelihood -1.398004
┌ Info: EM with 100000 data points 50 iterations avll -1.398004
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4001321969788985
│     -1.4000742341256185
│      ⋮
└     -1.398003725869502
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.398005
[ Info: iteration 2, average log likelihood -1.397938
[ Info: iteration 3, average log likelihood -1.397874
[ Info: iteration 4, average log likelihood -1.397799
[ Info: iteration 5, average log likelihood -1.397704
[ Info: iteration 6, average log likelihood -1.397584
[ Info: iteration 7, average log likelihood -1.397440
[ Info: iteration 8, average log likelihood -1.397278
[ Info: iteration 9, average log likelihood -1.397107
[ Info: iteration 10, average log likelihood -1.396938
[ Info: iteration 11, average log likelihood -1.396777
[ Info: iteration 12, average log likelihood -1.396630
[ Info: iteration 13, average log likelihood -1.396496
[ Info: iteration 14, average log likelihood -1.396377
[ Info: iteration 15, average log likelihood -1.396271
[ Info: iteration 16, average log likelihood -1.396178
[ Info: iteration 17, average log likelihood -1.396095
[ Info: iteration 18, average log likelihood -1.396021
[ Info: iteration 19, average log likelihood -1.395955
[ Info: iteration 20, average log likelihood -1.395896
[ Info: iteration 21, average log likelihood -1.395842
[ Info: iteration 22, average log likelihood -1.395792
[ Info: iteration 23, average log likelihood -1.395747
[ Info: iteration 24, average log likelihood -1.395706
[ Info: iteration 25, average log likelihood -1.395667
[ Info: iteration 26, average log likelihood -1.395632
[ Info: iteration 27, average log likelihood -1.395599
[ Info: iteration 28, average log likelihood -1.395567
[ Info: iteration 29, average log likelihood -1.395538
[ Info: iteration 30, average log likelihood -1.395511
[ Info: iteration 31, average log likelihood -1.395485
[ Info: iteration 32, average log likelihood -1.395460
[ Info: iteration 33, average log likelihood -1.395437
[ Info: iteration 34, average log likelihood -1.395415
[ Info: iteration 35, average log likelihood -1.395394
[ Info: iteration 36, average log likelihood -1.395374
[ Info: iteration 37, average log likelihood -1.395356
[ Info: iteration 38, average log likelihood -1.395338
[ Info: iteration 39, average log likelihood -1.395321
[ Info: iteration 40, average log likelihood -1.395305
[ Info: iteration 41, average log likelihood -1.395290
[ Info: iteration 42, average log likelihood -1.395275
[ Info: iteration 43, average log likelihood -1.395261
[ Info: iteration 44, average log likelihood -1.395248
[ Info: iteration 45, average log likelihood -1.395236
[ Info: iteration 46, average log likelihood -1.395224
[ Info: iteration 47, average log likelihood -1.395212
[ Info: iteration 48, average log likelihood -1.395201
[ Info: iteration 49, average log likelihood -1.395191
[ Info: iteration 50, average log likelihood -1.395180
┌ Info: EM with 100000 data points 50 iterations avll -1.395180
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3980049488799828
│     -1.3979376880430254
│      ⋮
└     -1.3951803667011589
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4085183447613558
│     -1.408537311771715
│     -1.4084839158800324
│     -1.4084487365381624
│      ⋮
│     -1.39520117237378
│     -1.3951905769094997
└     -1.3951803667011589
32×26 Array{Float64,2}:
 -0.549235     0.355073   -0.425894   -0.221507      0.251345   -0.173223    -0.0510194   0.165371   -0.569808    0.331723     0.364425    0.0262215    0.354452   -0.204944    0.079265   -0.200469   -0.15512     -0.579481   -0.272177    0.153193      0.301695    0.145467     0.0481184   -0.118614   -0.288349   -0.965323
 -0.434223     0.472875    0.0780334   0.00621383    0.18415     0.206748    -0.0150648  -0.417199   -0.519915    0.232409     0.494778   -0.646282     0.409093   -0.133648   -0.0720685   0.0477924   0.227103    -0.254514   -0.65949    -0.292157     -0.379051   -0.408635     0.354359    -0.220436    0.117339    0.362777
  0.858984     0.20252    -0.344632   -0.423603     -0.159844   -0.174071     0.15963    -0.244057    0.287728    0.124431     0.426738    0.0107174    0.087538   -0.152155   -0.0306176  -0.58246    -0.0365519   -0.381694   -0.905836   -0.0332789     0.328872    0.300896    -0.193137    -0.709362   -0.584508   -0.308045
  0.376374    -0.131734   -0.247228    0.201291     -0.183957   -0.0451015    0.0627746  -0.079775   -0.0551123  -0.144329     0.0303066   0.138404     0.163531   -0.308055    0.0359839  -0.530899   -0.72574     -0.611335    0.576264    0.035134      0.463147    0.0242177   -0.00063532  -0.276166   -0.230532   -0.0113193
 -0.567386    -0.301333   -0.615264    0.145352      0.326741   -0.716056    -0.0160549   0.113426   -0.372819   -0.426648     0.240627   -0.23035     -0.155458    0.0129376   0.248051   -0.372721   -0.479878    -0.277992   -0.334067   -0.274439      0.255056    0.439626    -0.159899     0.249757   -0.21323     0.0359608
 -0.267328    -0.150608   -0.262221    0.203163      0.530696    0.669312     0.115751    0.52652    -0.160505   -0.259907    -0.102363   -0.0874308    0.155026   -0.471411    0.25548     0.0170011  -0.4792       0.151759   -0.319997   -0.280643      0.0452227   0.0384465   -0.27016      0.424451    0.116453    0.392964
 -0.344776    -0.0987431  -0.0186094   0.19642      -0.580837    0.18033     -0.441018   -0.198407   -0.100902   -0.140402    -0.164284    0.016571    -0.546496    0.323723   -0.0741772  -0.310379   -0.0206805    0.025802   -0.107312   -0.691245      0.279899    0.00086417  -0.128567    -0.418247    0.433555   -0.0499498
  0.484275    -0.33642     0.209359    0.144308      0.354575    0.548111     0.0212347   0.331128   -0.0324678  -0.00724711  -0.217238   -0.202034    -0.0691321  -0.179042   -0.366165   -0.0600029   0.214727     0.243666   -0.0300023  -0.159846      0.439464   -0.290586     0.685355    -0.598423    0.31438     0.0553782
 -0.0862892   -0.0172214   0.203437    0.12666      -0.048874   -0.101045    -0.0486808   0.186895    0.235011   -0.0353414   -0.2036      0.0832626   -0.0891676   0.0209135  -0.0246066   0.0761642  -0.127122     0.186385    0.172613   -0.000214141  -0.0665027  -0.12509     -0.0498813    0.246659    0.0946294   0.151474
 -0.149549     0.18137    -0.116288   -0.133829      0.0855458  -0.0873377   -0.14733     0.0612537  -0.222965    0.0793643    0.337615    0.0609091    0.0105288  -0.0830847   0.0221923  -0.0741884  -0.119255     0.0185846  -0.346312    0.0381039     0.0537564  -0.157085    -0.0633969    0.0892929  -0.202006   -0.0550373
 -0.117255     0.256515   -0.100685   -0.202279     -0.23162    -0.13895     -0.299338   -0.286973   -0.0434882   0.0924082   -0.199497   -0.152119     0.339814    0.0241019  -0.118516   -0.17843     0.354021    -0.455431    0.37383     0.285442      0.0167026   0.00986104   0.151572    -0.466918   -0.0718105  -0.183034
  0.288958    -0.259848    0.0505618  -0.067802     -0.110447    0.0952928    0.435913   -0.249118    0.0216593   0.128351    -0.0270698  -0.0305243    0.0352478   0.0226505   0.0492591   0.172458    0.31932     -0.181418    0.0128483  -0.012033      0.152799    0.170862     0.0571764   -0.203677    0.204438    0.00516341
 -0.278404    -0.494352    0.0657672   0.445609     -0.118052   -0.317283     0.195858   -0.0091224   0.25133    -0.10499     -0.584182    0.0964697   -0.157706    0.0256913   0.202927    0.435792    0.0272204    0.387126    0.601193    0.288582      0.227668   -0.285065     0.122274     0.33386    -0.028477    0.259115
 -0.107079     0.516267    0.58614    -0.00673712   -0.0433703  -0.020084     0.0241427   0.127396    0.423276   -0.298118    -0.415323    0.0928978   -0.0167416   0.403299    0.185029   -0.010647    0.226763     0.712249    0.0884445   0.554131     -0.137566   -0.0556162    0.33303     -0.114054   -0.0119124   0.046534
 -0.122444    -0.268291    0.0733878   0.225274      0.671309   -0.0972118   -0.190802   -0.28412    -0.0713061   0.528696     0.978224    0.264239    -0.461888    0.167226   -0.422883    0.206496   -0.386803     0.477658    0.0558238   0.090291     -0.0940001  -0.404774     0.103901     0.146106    0.0663985   0.0878664
  0.243143    -0.116149   -0.307415   -0.558368      0.494874   -0.124264     0.374473    0.0172143   0.194119    0.107233     0.0897739   0.196984     0.116892    0.122273   -0.460483    0.694406    0.138981     0.0775083  -0.0244464   0.688273     -0.0544994  -0.195673     0.0241803    0.585472   -0.0849342   0.181915
 -0.620511     0.185853   -0.0344634  -0.0427949     0.261832   -0.216625    -0.101292    0.121691   -0.238441    0.0260307    0.222728    0.225866    -0.224908    0.0836985   0.0846388   0.252911    0.0518864    0.587181   -0.114872   -0.0234607    -0.277504   -0.332772     0.0988554    0.529886    0.118895   -0.0434543
  0.329342    -0.21182    -0.178778    0.475066      0.237744    0.0707732    0.0338644   0.2372      0.64378     0.0424055   -0.300443   -0.0838412   -0.0119405  -0.356206   -0.0621199  -0.0298262  -0.31653      0.0530931  -0.0214775  -0.065315     -0.0385209   0.235731    -0.34204      0.174109    0.291381    0.0855978
  0.00355972   0.156221   -0.454588   -0.0484522     0.168325   -0.764902    -0.274582   -0.0729753   0.0788655   0.130786     0.0195291   0.157976    -0.434857   -0.429753    0.423851   -0.601433   -0.497548    -0.291442   -0.239958   -0.301832     -0.790767   -0.746556     0.142012     0.492541   -0.277748   -0.115471
 -0.0128804   -0.119526   -0.104084   -0.000727987   0.369758   -0.518309    -0.14893     0.151539   -0.0204898   0.228798    -0.0575146   0.192881    -0.925559   -0.173458    0.187032   -0.315889   -0.321585     0.108001   -0.358201   -0.547383      0.775139   -0.150181     0.440588     0.0624522  -0.600804   -0.124492
  0.885406     0.350593    0.0382058  -0.105251      0.808141   -0.368034     0.450691    0.242069    0.0580823   0.528524     0.491728   -0.808799    -0.130076   -0.446862    0.53079    -0.114011    0.385797     0.0591815  -0.255608   -0.0658545    -0.549084    0.456436    -0.29669      0.389843    0.273091   -0.441101
  0.493114    -0.211954   -0.445395   -0.0220311     1.01501    -0.329588     0.5555     -0.240952    0.660426   -0.368573    -0.100185   -0.94718      0.0655926  -0.260576    0.109004   -0.52453    -0.0544737    0.0881482   0.431333    0.180564      0.433849   -0.422855     0.224093     0.174678   -0.190115   -0.315821
 -0.00229839   0.782481    0.263514   -0.316128     -0.817564    0.119308     0.0393266   0.0324684  -0.354335    0.116202     0.246592    0.0473669    0.0778548   0.578301    0.787822    0.125281   -0.639642    -0.764073   -0.0880632  -0.416509     -0.837453    0.13795     -1.12476      0.499562   -0.122629    0.341323
  0.0301512    0.0961573   0.0527467  -0.0536626     0.0732882  -0.0959663    0.240416    0.278815    0.0699967  -0.328083     0.475572    0.185978    -0.219429    0.180364    0.633724   -0.119252   -0.00828492   0.226777    0.0359483   0.459126     -0.158747   -0.0106788   -1.01663      0.664736    0.138237   -0.517632
 -0.273354     0.113301    0.376731   -0.569011     -0.570749   -0.00204747  -0.354159    0.370814   -0.464613    0.64915     -0.170956    0.731991    -0.37607     0.130159   -0.323275    0.45708     0.485368     0.0329498  -0.265169   -0.183266     -0.369431    0.122438     0.19746     -0.0385822   0.0442519  -0.16815
 -0.338682    -0.0563108   0.571605   -0.557767     -0.478259   -0.179837    -0.322933   -0.599782   -0.963809    0.309812     1.01418     0.675948     0.470202    0.126663   -0.138272   -0.0941053   0.668181     0.414081    0.352322    0.677436      0.25408    -0.175518     0.169827    -0.313979   -1.01807     0.0555826
  0.0143256    0.0752022  -0.158366    0.477723     -0.225341    0.0661809    0.376826    0.443471    0.718493    0.279649    -1.00059    -0.113901     0.101825   -0.233733   -0.0529116   0.361883   -0.038643    -0.296311   -0.22475    -0.239469     -0.217862    0.601352    -0.297106     0.125881    0.421205   -0.0722358
  0.0959369    0.172334    0.739385   -0.03797      -0.498465    0.376798    -0.231615   -0.186031    0.17184     0.155817     0.312213    0.298427     0.296745   -0.124706   -0.443162    0.161694    0.202957     0.117317    0.227462   -0.112655     -0.297318    0.141285    -0.708504    -0.166044    0.428939    0.192316
 -0.25644     -0.269668   -0.135455    0.028114     -0.558035    0.00804966  -0.467978   -0.374363   -0.120585   -0.335942    -0.68295     0.0244798   -0.0160838   0.142239   -0.300984   -0.278008    0.0570439   -0.167986    0.628679   -0.144255      0.199109    0.0231203    0.64489     -0.957082   -0.177953    0.295087
  0.548926    -0.110732    0.225927   -0.628338     -0.342323    0.191706     0.359967   -0.343899   -0.170897   -0.184574     0.12015    -0.221394     0.352208    0.457553    0.272016   -0.16751     0.284451    -0.867469    0.0225264   0.0503404     0.162095    0.133829     0.0025118   -0.523556    0.204114    0.0457622
  0.630804     0.054273    0.293771   -0.25282      -0.876761   -0.0433925    0.0395751  -0.468663    0.134584    0.456093    -0.229428   -0.0918024    0.0739821  -0.49454    -0.201181    0.23425     0.382711    -0.637703    0.728096    0.202468     -0.0465963  -0.61941     -0.346839     0.0487135   0.0137109  -0.0862292
 -0.361648    -0.238568    0.0139491   0.395305     -0.304792    0.404321     0.265407    0.128242   -0.156961   -0.064449     0.118401    0.00768836   0.888835    0.332768   -0.452083    0.38335     0.480447    -0.0800289   0.180877    0.62845       0.412702    1.06727     -0.124913    -0.411342    0.264089    0.109658[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395171
[ Info: iteration 2, average log likelihood -1.395161
[ Info: iteration 3, average log likelihood -1.395152
[ Info: iteration 4, average log likelihood -1.395143
[ Info: iteration 5, average log likelihood -1.395134
[ Info: iteration 6, average log likelihood -1.395125
[ Info: iteration 7, average log likelihood -1.395117
[ Info: iteration 8, average log likelihood -1.395109
[ Info: iteration 9, average log likelihood -1.395101
[ Info: iteration 10, average log likelihood -1.395093
┌ Info: EM with 100000 data points 10 iterations avll -1.395093
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.385578e+05
      1       6.828729e+05      -2.556849e+05 |       32
      2       6.714599e+05      -1.141306e+04 |       32
      3       6.669981e+05      -4.461754e+03 |       32
      4       6.648242e+05      -2.173877e+03 |       32
      5       6.634584e+05      -1.365838e+03 |       32
      6       6.624320e+05      -1.026342e+03 |       32
      7       6.615974e+05      -8.345942e+02 |       32
      8       6.609065e+05      -6.909447e+02 |       32
      9       6.603232e+05      -5.833473e+02 |       32
     10       6.598108e+05      -5.123121e+02 |       32
     11       6.593588e+05      -4.520612e+02 |       32
     12       6.589685e+05      -3.903104e+02 |       32
     13       6.586342e+05      -3.343057e+02 |       32
     14       6.582925e+05      -3.416774e+02 |       32
     15       6.579830e+05      -3.094875e+02 |       32
     16       6.577091e+05      -2.738646e+02 |       32
     17       6.574424e+05      -2.667113e+02 |       32
     18       6.571971e+05      -2.453440e+02 |       32
     19       6.569725e+05      -2.245371e+02 |       32
     20       6.567636e+05      -2.089439e+02 |       32
     21       6.565760e+05      -1.875496e+02 |       32
     22       6.564035e+05      -1.725374e+02 |       32
     23       6.562344e+05      -1.691034e+02 |       32
     24       6.560857e+05      -1.486812e+02 |       32
     25       6.559405e+05      -1.452185e+02 |       32
     26       6.558076e+05      -1.329164e+02 |       32
     27       6.556823e+05      -1.252974e+02 |       32
     28       6.555765e+05      -1.057853e+02 |       32
     29       6.554892e+05      -8.734809e+01 |       32
     30       6.554000e+05      -8.917600e+01 |       32
     31       6.553212e+05      -7.878035e+01 |       32
     32       6.552503e+05      -7.090914e+01 |       32
     33       6.551768e+05      -7.344872e+01 |       32
     34       6.551163e+05      -6.054688e+01 |       32
     35       6.550622e+05      -5.414394e+01 |       32
     36       6.550129e+05      -4.920690e+01 |       32
     37       6.549629e+05      -5.000223e+01 |       32
     38       6.549106e+05      -5.231097e+01 |       32
     39       6.548528e+05      -5.780055e+01 |       32
     40       6.548002e+05      -5.261274e+01 |       32
     41       6.547456e+05      -5.462986e+01 |       32
     42       6.546963e+05      -4.930477e+01 |       32
     43       6.546479e+05      -4.835243e+01 |       32
     44       6.545909e+05      -5.706800e+01 |       32
     45       6.545385e+05      -5.231921e+01 |       32
     46       6.544896e+05      -4.899419e+01 |       32
     47       6.544368e+05      -5.280078e+01 |       32
     48       6.543850e+05      -5.172659e+01 |       32
     49       6.543339e+05      -5.112818e+01 |       32
     50       6.542823e+05      -5.158725e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 654282.3114238762)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407199
[ Info: iteration 2, average log likelihood -1.402225
[ Info: iteration 3, average log likelihood -1.400854
[ Info: iteration 4, average log likelihood -1.399835
[ Info: iteration 5, average log likelihood -1.398773
[ Info: iteration 6, average log likelihood -1.397795
[ Info: iteration 7, average log likelihood -1.397113
[ Info: iteration 8, average log likelihood -1.396718
[ Info: iteration 9, average log likelihood -1.396488
[ Info: iteration 10, average log likelihood -1.396335
[ Info: iteration 11, average log likelihood -1.396220
[ Info: iteration 12, average log likelihood -1.396127
[ Info: iteration 13, average log likelihood -1.396047
[ Info: iteration 14, average log likelihood -1.395977
[ Info: iteration 15, average log likelihood -1.395914
[ Info: iteration 16, average log likelihood -1.395857
[ Info: iteration 17, average log likelihood -1.395804
[ Info: iteration 18, average log likelihood -1.395756
[ Info: iteration 19, average log likelihood -1.395710
[ Info: iteration 20, average log likelihood -1.395667
[ Info: iteration 21, average log likelihood -1.395626
[ Info: iteration 22, average log likelihood -1.395587
[ Info: iteration 23, average log likelihood -1.395549
[ Info: iteration 24, average log likelihood -1.395512
[ Info: iteration 25, average log likelihood -1.395477
[ Info: iteration 26, average log likelihood -1.395444
[ Info: iteration 27, average log likelihood -1.395411
[ Info: iteration 28, average log likelihood -1.395379
[ Info: iteration 29, average log likelihood -1.395349
[ Info: iteration 30, average log likelihood -1.395320
[ Info: iteration 31, average log likelihood -1.395292
[ Info: iteration 32, average log likelihood -1.395265
[ Info: iteration 33, average log likelihood -1.395240
[ Info: iteration 34, average log likelihood -1.395215
[ Info: iteration 35, average log likelihood -1.395192
[ Info: iteration 36, average log likelihood -1.395170
[ Info: iteration 37, average log likelihood -1.395150
[ Info: iteration 38, average log likelihood -1.395130
[ Info: iteration 39, average log likelihood -1.395112
[ Info: iteration 40, average log likelihood -1.395095
[ Info: iteration 41, average log likelihood -1.395078
[ Info: iteration 42, average log likelihood -1.395063
[ Info: iteration 43, average log likelihood -1.395048
[ Info: iteration 44, average log likelihood -1.395034
[ Info: iteration 45, average log likelihood -1.395021
[ Info: iteration 46, average log likelihood -1.395009
[ Info: iteration 47, average log likelihood -1.394997
[ Info: iteration 48, average log likelihood -1.394985
[ Info: iteration 49, average log likelihood -1.394974
[ Info: iteration 50, average log likelihood -1.394963
┌ Info: EM with 100000 data points 50 iterations avll -1.394963
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.911958    0.369458    0.174875   -0.00368515   0.753706     -0.35885      0.424098    0.289075    0.0425476     0.560673    0.515487   -1.09825    -0.237713    -0.441977     0.576591    -0.13035      0.456143    0.0672379  -0.250533   -0.141504   -0.491323     0.550209    -0.393713     0.341314    0.280309   -0.437301
 -0.461887   -0.392733   -0.551254    0.122092     0.448844     -0.515812     0.119779    0.139256   -0.164336     -0.440635    0.154108   -0.345567   -0.44304     -0.018231     0.37156     -0.53168     -0.461638   -0.157983   -0.33984    -0.498036    0.357877     0.28859     -0.122585     0.260401   -0.273757   -0.0188541
 -0.0463056   0.417177   -0.272146   -0.705448    -0.0341326    -0.703147    -0.0875156   0.121676    0.000611802   0.0308637  -0.436159   -0.0719642  -0.0795521    0.0294307    0.268293     0.0234541   -0.103451    0.0270722   0.0433398   0.241114   -0.102811    -0.508812     0.36766      0.131433   -0.673214    0.0347599
  0.571479   -0.256855   -0.361977    0.0154507    0.848317     -0.176588     0.621214   -0.171843    0.603321     -0.341906   -0.186444   -0.979733    0.114918    -0.278531     0.137755    -0.365561    -0.0228104   0.073313    0.413976    0.250881    0.401431    -0.467857     0.253776     0.237341   -0.165136   -0.350805
 -0.105498   -0.0955671  -0.201272    0.00851849  -0.272963      0.0387494   -0.415425   -0.358247   -0.198742      0.0969684  -0.452359   -0.12977     0.00644771   0.0934446   -0.510577    -0.18615      0.150129   -0.280165    0.272807   -0.310154    0.106894    -0.0821409    0.924042    -1.02863     0.0359809   0.110548
  0.0193903   0.733898    0.272321   -0.310671    -0.806876      0.069043     0.0402966  -0.0394683  -0.309998      0.0787021   0.29316     0.0330429   0.100248     0.507897     0.765899     0.12345     -0.610909   -0.740373   -0.0232743  -0.376797   -0.826565     0.114952    -1.1386       0.491415   -0.0870331   0.363395
 -0.0526175  -0.0700851  -0.252932   -0.112582    -0.125824      0.00241273   0.075965   -0.105009   -0.217321      0.0513058   0.0755244  -0.0756325   0.122825    -0.325664     0.134629    -0.507596    -0.228454   -0.648523    0.22442    -0.0776498   0.15417     -0.148273    -0.0261193   -0.198934   -0.139471   -0.358541
 -0.442017    0.0474713   0.515747   -0.554139    -0.493655     -0.19018     -0.309213   -0.375478   -0.804204      0.355338    0.722993    0.581795    0.373534     0.153796    -0.153782    -0.0323634    0.727745    0.278009    0.353113    0.737929    0.203033    -0.0337114    0.166438    -0.255772   -1.05526    -0.122223
 -0.614773    0.595915   -0.605369    0.13296      0.471523      0.0382251   -0.25083     0.176689   -0.725724     -0.0298493   0.646869   -0.090158    0.448129    -0.259091     0.243565    -0.211723    -0.07818    -0.341885   -0.58581     0.150608   -0.00940055  -0.0852966   -0.0637106   -0.0051826   0.102069   -0.394727
 -1.06627     0.204076    0.401784    0.259783     0.110808     -0.169249    -0.0254983  -0.239566    0.185289      0.130592   -0.302358   -0.262655   -0.191524     0.23853      0.0834954    0.564673     0.0318932   0.561465    0.304387   -0.103433   -0.604488    -0.689259     0.342929     0.564097    0.518219    0.0277025
  0.668196    0.27385    -0.257493   -0.452796    -0.0812752    -0.121383     0.116248   -0.247236    0.0794551     0.184566    0.502274   -0.0299357   0.186619    -0.0315722   -0.00647336  -0.626236    -0.174167   -0.734988   -0.578223   -0.0356613   0.408593     0.403593    -0.171923    -0.721496   -0.576797   -0.388105
 -0.0637978   0.217529   -0.0638406  -0.194745     0.188886     -0.00963269  -0.104581   -0.107531   -0.160544      0.25948     0.493317   -0.0284774   0.161488    -0.0137071   -0.209191     0.10838      0.0637287  -0.0406826  -0.421798    0.137811   -0.0854286   -0.074031    -0.00897516  -0.0243468  -0.102427    0.00237159
 -0.092776    0.876306    0.357983    0.200039    -0.492144      0.237566    -0.130748   -0.0652309   0.309101     -0.34556    -0.953935   -0.124543    0.375685     0.132223     0.412438    -0.200689     0.362523   -0.25981    -0.0845694   0.117002   -0.235887     0.29766      0.130846    -0.372506    0.0043067  -0.0944575
  0.280595    0.0295306  -0.0167321  -0.88906      0.229721      0.0669157    0.462909    0.309223   -0.131573     -0.143048    0.458061    0.286035   -0.0478642    0.094857     0.137965     0.47824      0.615208    0.201425   -0.217042    0.0901831  -0.209507    -0.297489    -0.441013     0.893674    0.544924   -0.635151
  0.187874    0.124469    0.0456432  -0.0333103    0.000423918  -0.146449     0.0410434  -0.350467    0.295912     -0.0606268  -0.0957186  -0.142385    0.0204926   -0.013005     0.0783323   -0.0325678    0.222455   -0.0635393   0.328299    0.206722    0.131845    -0.0821645    0.0266254   -0.120895    0.139568   -0.0335735
  0.11624    -0.399281   -0.152418   -0.00340624   0.609428     -0.0757207    0.0738763  -0.324562   -0.590309      0.727708    1.4273      0.10345    -0.286541     0.218824    -0.450957     0.397433    -0.274427    0.142673    0.184715    0.134519    0.0929603   -0.582224     0.0792635    0.165553    0.107088    0.324294
 -0.182236    0.0422302   0.363319    0.176333     0.244139     -0.112414    -0.014971    0.330829    0.22199       0.0179357  -0.290854    0.240214   -0.383144     0.367783    -0.173854     0.206369     0.270536    1.14587    -0.215743    0.402457    0.180724     0.226487     0.670901    -0.152629    0.0936105   0.0409375
  0.439896   -0.25449     0.490041   -0.468961    -0.355811      0.461222     0.195471   -0.37192    -0.196599     -0.492348    0.121376   -0.309849    0.115649     0.471345     0.155979    -0.0315512    0.525664   -0.3331      0.169512    0.150171    0.234273    -0.00732889   0.0424238   -0.683158    0.394075    0.225314
  0.407897   -0.38663    -0.267172   -0.109974     0.365663     -0.24377      0.450907   -0.207756    0.50796       0.0485654  -0.0914062   0.224178    0.0453772   -0.0407018   -0.299404     0.499023     0.0653828   0.191226    0.137294    0.660366   -0.0892596   -0.141224    -0.0316231    0.353747   -0.273982    0.643064
 -0.167402   -0.218166   -0.0852881   0.301426     0.353727      0.691038     0.200695    0.432839   -0.142085     -0.0813445  -0.163034   -0.204581    0.253296    -0.442082     0.073086     0.134631    -0.271608    0.177419   -0.237309   -0.392391    0.065566    -0.0156175   -0.207773     0.221021    0.136214    0.702971
 -0.0467997  -0.124196    0.138348    0.147731    -0.185896      0.307599     0.0911547   0.0983877   0.17348      -0.0818174  -0.175367    0.0102496   0.389309     0.00727875  -0.224383     0.186084     0.139611    0.0193779   0.211273    0.194956    0.0552282    0.33998     -0.321284    -0.0307038   0.268603    0.120578
 -0.250107   -0.339674   -0.667492   -0.0906039   -0.666782     -0.164359     0.76716    -0.202719   -0.308576      0.577863   -0.30922    -0.441683    0.787082     0.0498519   -0.0433304    0.358402     0.791531   -0.869561    0.212497    0.315495    0.334994     0.870695     0.155982    -0.180635    0.228364    0.0571963
 -0.374431    0.0568372   0.335313    0.0224419   -0.0506563     0.159118     0.0187134   0.312879    0.168241     -0.193581   -0.105774    0.193668    0.147426     0.169858     0.141211     0.194514     0.243403    0.483807    0.229531    0.484642   -0.213073     0.0992077   -0.414201     0.387482    0.189835    0.051331
 -0.0321124  -0.168595    0.0574317   0.153837    -0.177354     -0.0306328   -0.0226437   0.158596    0.0320012    -0.0111948  -0.217385    0.0636984  -0.217377     0.104333    -0.061074     0.0938682   -0.124252    0.0707297  -0.0435213  -0.276793    0.139494    -0.0276457    0.0873425   -0.0368399   0.135189    0.123761
 -0.0640207  -0.3892     -0.156753    0.716148    -0.121401     -0.192838    -0.27427     0.0799262   0.0802411    -0.544715   -0.306742    0.154657    0.295832    -0.00324599  -0.0225793   -0.269697    -0.406634   -0.154599    0.752578    0.551189    0.6842       0.213067     0.0825991   -0.481329   -0.157878    0.324772
 -0.0700338  -0.0521515  -0.349813   -0.0204509    0.161657     -0.548831    -0.26212    -0.0779055   0.0368869     0.184566   -0.021448    0.190904   -0.578475    -0.369934     0.296472    -0.362796    -0.347112   -0.175204   -0.153133   -0.452457   -0.161417    -0.542871     0.133399     0.370021   -0.352275   -0.0984608
  0.45714     0.256091    0.628315   -0.0904281   -0.681507      0.162056    -0.077201   -0.281153    0.311985      0.576802   -0.0886643   0.113628    0.21627     -0.283462    -0.499497     0.268799     0.328598   -0.336882    0.527156    0.269595   -0.23573     -0.33584     -0.292851    -0.165276    0.1564     -0.0809628
  0.373602    0.208022    0.652697    0.275056     0.649554      0.181382    -0.451933    0.249856    0.146011     -0.403864    0.232578    0.189441   -0.48012     -0.373378    -0.322486    -0.424282    -0.350265    0.805515   -0.0552964  -0.217151    0.162341    -0.838747     0.450064    -0.153001   -0.0950524  -0.202366
 -0.499117    0.0215165   0.230903   -0.175314    -0.604505      0.0936491   -0.566538    0.040074   -0.523874      0.28677     0.112832    0.569175   -0.280935     0.118954    -0.251194     0.00331453   0.140752   -0.0538628  -0.242587   -0.454044   -0.018052     0.216618    -0.266738    -0.211288    0.345897   -0.0788051
  0.362418   -0.645064    0.260913    0.24829     -0.135079     -0.00938794   0.548714    0.040149    0.210688      0.312963   -0.501787    0.514726   -0.0568451   -0.142088    -0.00246827   0.243428     0.20052    -0.0274998   0.0624862  -0.219134    0.253381     0.718537    -0.0836019    0.0379997   0.0608768  -0.239668
  0.0095123   0.180671   -0.0695454   0.297727     0.224423     -0.339197     0.0440082   0.183946    0.200733      0.0411113   0.392787    0.5032     -0.397548     0.0675352    0.384636    -0.245728    -0.763535    0.14427     0.0433652   0.345315   -0.0523385    0.00197606  -0.49885      0.67161    -0.15041    -0.524278
  0.343178    0.0363692  -0.625543    0.512727     0.0705777    -0.0704599    0.172087    0.423001    1.19781       0.139475   -0.629113   -0.431252   -0.248655    -0.333496    -0.236759     0.0936687   -0.68015    -0.37182    -0.425981   -0.540466   -0.324092     0.243289    -0.336724     0.102621    0.82959    -0.234468[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.394953
[ Info: iteration 2, average log likelihood -1.394943
[ Info: iteration 3, average log likelihood -1.394933
[ Info: iteration 4, average log likelihood -1.394923
[ Info: iteration 5, average log likelihood -1.394914
[ Info: iteration 6, average log likelihood -1.394905
[ Info: iteration 7, average log likelihood -1.394896
[ Info: iteration 8, average log likelihood -1.394887
[ Info: iteration 9, average log likelihood -1.394878
[ Info: iteration 10, average log likelihood -1.394870
┌ Info: EM with 100000 data points 10 iterations avll -1.394870
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
