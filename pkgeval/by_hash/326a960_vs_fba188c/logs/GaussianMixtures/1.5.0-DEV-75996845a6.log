Julia Version 1.5.0-DEV.164
Commit 75996845a6 (2020-01-28 14:07 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed DataAPI ──────────── v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Distances ────────── v0.8.2
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed Clustering ───────── v0.13.3
 Installed CMake ────────────── v1.1.2
 Installed Rmath ────────────── v0.6.0
 Installed FillArrays ───────── v0.8.4
 Installed URIParser ────────── v0.4.0
 Installed Missings ─────────── v0.4.3
 Installed HDF5 ─────────────── v0.12.5
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed Compat ───────────── v2.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed SpecialFunctions ─── v0.9.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed OrderedCollections ─ v1.1.0
 Installed StaticArrays ─────── v0.12.1
 Installed JLD ──────────────── v0.9.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack ───────────── v0.4.0
 Installed DataStructures ───── v0.17.9
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Distributions ────── v0.22.3
 Installed NearestNeighbors ─── v0.4.4
 Installed SortingAlgorithms ── v0.3.1
 Installed PDMats ───────────── v0.9.11
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_aMGGMt/Project.toml`
 [no changes]
  Updating `/tmp/jl_aMGGMt/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_RVCuEs/Project.toml`
 [no changes]
  Updating `/tmp/jl_RVCuEs/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_OKjTgs/Project.toml`
 [no changes]
  Updating `/tmp/jl_OKjTgs/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_hJr5uG/Project.toml`
 [no changes]
  Updating `/tmp/jl_hJr5uG/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_4fkmLl/Project.toml`
 [no changes]
  Updating `/tmp/jl_4fkmLl/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_4fkmLl/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -648755.2029422477, [1274.2947449521002, 98725.70525504791], [238.9244992701465 1808.231495797188 -177.2642197035773; -503.37707626202683 -1215.5635178210728 92.38454967895139], [[824.4548818721054 401.37029747492056 607.1684983976879; 401.3702974749207 2669.053700019858 -448.7786883005099; 607.1684983976878 -448.7786883005099 1201.091025368627], [98725.83488741665 -313.4097707888058 -554.1498521118685; -313.4097707888059 96846.09869138218 761.2100078448935; -554.1498521118683 761.2100078448935 98600.92887520269]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.712879e+03
      1       1.271772e+03      -4.411066e+02 |        8
      2       1.200316e+03      -7.145601e+01 |        5
      3       1.093736e+03      -1.065798e+02 |        4
      4       1.005217e+03      -8.851938e+01 |        2
      5       9.622206e+02      -4.299641e+01 |        2
      6       9.304452e+02      -3.177543e+01 |        2
      7       9.277076e+02      -2.737565e+00 |        0
      8       9.277076e+02       0.000000e+00 |        0
K-means converged with 8 iterations (objv = 927.7076243003548)
┌ Info: K-means with 272 data points using 8 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082536
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.861606
[ Info: iteration 2, lowerbound -3.751812
[ Info: iteration 3, lowerbound -3.617307
[ Info: iteration 4, lowerbound -3.435680
[ Info: iteration 5, lowerbound -3.222619
[ Info: iteration 6, lowerbound -3.012931
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.829244
[ Info: iteration 8, lowerbound -2.697070
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.605401
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.525890
[ Info: iteration 11, lowerbound -2.473383
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.426685
[ Info: iteration 13, lowerbound -2.386601
[ Info: iteration 14, lowerbound -2.354769
[ Info: iteration 15, lowerbound -2.328292
[ Info: iteration 16, lowerbound -2.311298
[ Info: iteration 17, lowerbound -2.307832
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302917
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Jan 28 18:13:58 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Jan 28 18:14:06 2020: K-means with 272 data points using 8 iterations
11.3 data points per parameter
, Tue Jan 28 18:14:09 2020: EM with 272 data points 0 iterations avll -2.082536
5.8 data points per parameter
, Tue Jan 28 18:14:11 2020: GMM converted to Variational GMM
, Tue Jan 28 18:14:20 2020: iteration 1, lowerbound -3.861606
, Tue Jan 28 18:14:20 2020: iteration 2, lowerbound -3.751812
, Tue Jan 28 18:14:20 2020: iteration 3, lowerbound -3.617307
, Tue Jan 28 18:14:20 2020: iteration 4, lowerbound -3.435680
, Tue Jan 28 18:14:20 2020: iteration 5, lowerbound -3.222619
, Tue Jan 28 18:14:20 2020: iteration 6, lowerbound -3.012931
, Tue Jan 28 18:14:20 2020: dropping number of Gaussions to 7
, Tue Jan 28 18:14:20 2020: iteration 7, lowerbound -2.829244
, Tue Jan 28 18:14:20 2020: iteration 8, lowerbound -2.697070
, Tue Jan 28 18:14:20 2020: dropping number of Gaussions to 5
, Tue Jan 28 18:14:20 2020: iteration 9, lowerbound -2.605401
, Tue Jan 28 18:14:20 2020: dropping number of Gaussions to 4
, Tue Jan 28 18:14:20 2020: iteration 10, lowerbound -2.525890
, Tue Jan 28 18:14:20 2020: iteration 11, lowerbound -2.473383
, Tue Jan 28 18:14:20 2020: dropping number of Gaussions to 3
, Tue Jan 28 18:14:20 2020: iteration 12, lowerbound -2.426685
, Tue Jan 28 18:14:20 2020: iteration 13, lowerbound -2.386601
, Tue Jan 28 18:14:20 2020: iteration 14, lowerbound -2.354769
, Tue Jan 28 18:14:20 2020: iteration 15, lowerbound -2.328292
, Tue Jan 28 18:14:20 2020: iteration 16, lowerbound -2.311298
, Tue Jan 28 18:14:20 2020: iteration 17, lowerbound -2.307832
, Tue Jan 28 18:14:20 2020: dropping number of Gaussions to 2
, Tue Jan 28 18:14:20 2020: iteration 18, lowerbound -2.302917
, Tue Jan 28 18:14:20 2020: iteration 19, lowerbound -2.299259
, Tue Jan 28 18:14:20 2020: iteration 20, lowerbound -2.299256
, Tue Jan 28 18:14:20 2020: iteration 21, lowerbound -2.299254
, Tue Jan 28 18:14:20 2020: iteration 22, lowerbound -2.299254
, Tue Jan 28 18:14:20 2020: iteration 23, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 24, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 25, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 26, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 27, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 28, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 29, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 30, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 31, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 32, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 33, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 34, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 35, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 36, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 37, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 38, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 39, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 40, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 41, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 42, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 43, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 44, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 45, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 46, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 47, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 48, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 49, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: iteration 50, lowerbound -2.299253
, Tue Jan 28 18:14:20 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398619]
β = [178.04509222601382, 95.95490777398619]
m = [4.25030073326991 79.28686694436185; 2.0002292577753704 53.85198717246129]
ν = [180.04509222601382, 97.95490777398619]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748454 -0.007644049042327357; 0.0 0.00858170516633346], [0.37587636119483825 -0.008953123827346048; 0.0 0.012748664777409427]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.020639618703781
avll from llpg:  -1.0206396187037825
avll direct:     -1.0206396187037827
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0055905156406806
avll from llpg:  -1.0055905156406806
avll direct:     -1.0055905156406806
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0100219    0.17781    -0.00771333  -0.0117257    0.187233     0.07174      -0.208745    -0.0961508   -0.0414329    0.00405319   0.119604     0.0336635    0.103986    0.0675925   -0.0727907   -0.0564277    0.0284684    0.0968124   -0.130799    -0.190142     0.145407     0.0538529     0.0355212    0.152151    -0.0466864     0.0534442
 -0.0608265   -0.0299971   0.0323095    0.180038     0.115458    -0.0185452    -0.18622     -0.0604556   -0.0812513    0.138733     0.0781801   -0.0283762    0.0551348  -0.0446089    0.0423989   -0.0605899   -0.0560982    0.0288392   -0.0270099    0.00572267  -0.0354958    0.109249     -0.0692429    0.0239809   -0.104501     -0.0773634
  0.0412494   -0.128307   -0.0157733    0.061348     0.075513    -0.0229816    -0.0832405    0.00282497   0.113089     0.142314     0.0608333    0.101315    -0.0302985   0.0734319    0.0200093   -0.0525771    0.0177784   -0.00344797   0.133372     0.00618406  -0.071815     0.169407      0.0350384    0.054943    -0.111301     -0.0915196
 -0.0884564   -0.139109   -0.0449088    0.0792665    0.0290764    0.0104188     0.178336     0.141856     0.00790089   0.0280319   -0.109106    -0.184905    -0.0946639  -0.0425409   -0.0329432    0.0276701   -0.105556    -0.22233      0.0838912    0.153073     0.148879    -0.0990289    -0.0121057    0.0442319    0.156562     -0.0378437
  0.0242131   -0.132205   -0.0793623    0.0699187    0.0313001   -0.179366     -0.260894     0.116867    -0.0898222   -0.00454012  -0.015018    -0.0541173    0.0680795  -0.00333245  -0.234589    -0.140233     0.0551497   -0.0150948   -0.189425    -0.0640873    0.0798877   -0.145342     -0.0947084   -0.108435     0.0902785     0.0796173
  0.0274503    0.0670984  -0.106699    -0.0459253    0.00210747   0.0799204     0.0239427    0.0644963   -0.0225586    0.0417174   -0.168369     0.0473904   -0.0302603   0.015688    -0.219586     0.0949412   -0.109387    -0.0263517   -0.101539     0.0541967   -0.0421802    0.0974623     0.0965964   -0.100121    -0.12371      -0.107547
 -0.0201571    0.10289    -0.0133687    0.0578466    0.0231523   -0.137886      0.0907192   -0.287774     0.0226267   -0.0310598   -0.0619799    0.119789     0.0446012   0.0449544   -0.00465904  -0.0447709   -0.0321913   -0.0950597   -0.041315     0.00756351  -0.00994258   0.0737992    -0.0646978   -0.0506192    0.0359387    -0.00877711
  0.128367    -0.0235205  -0.131349    -0.173535    -0.0660524   -0.000312896   0.101835    -0.272343    -0.0692423   -0.107911    -0.0304856   -0.0261091   -0.0693111   0.0378772   -0.202795     0.00681006   0.0880712   -0.0494852    0.156671     0.151146     0.0896235   -0.0515791    -0.0266965   -0.0555039   -0.0967141    -0.0389279
  0.0530624   -0.0299306  -0.00740623   0.00715833   0.0494433   -0.20512      -0.0163755    0.165181     0.0110572    0.0518082    0.11739     -0.0338589    0.0800874   0.0395584   -0.129513     0.0478062   -0.0908091   -0.135438    -0.181813    -0.150675     0.143106    -0.120258     -0.151643    -0.117553    -0.10884      -0.00920115
  0.029108     0.0600982   0.0042561   -0.0664531    0.135798    -0.0525876    -0.144694     0.0280034   -0.0742646   -0.0940654    0.119961    -0.10082     -0.0943046   0.0976433    0.0121488   -0.133452    -0.0895193    0.213073    -0.0785832    0.104296    -0.256718    -0.0714469     0.0865313    0.0721928   -0.15123      -0.0177937
  0.122154    -0.0805575   0.17986     -0.204212    -0.125378    -0.054181     -0.0252496   -0.0309266    0.084639    -0.109494     0.10872     -0.0883078    0.155685    0.202365    -0.281406    -0.184873    -0.0734608   -0.206464     0.00193794  -0.129118    -0.0333893    0.0202952     0.0200494    0.127435    -0.0671654    -0.0745243
  0.13869      0.069793   -0.096558    -0.0747593    0.114824     0.0501731     0.00681087   0.0618677    0.140019     0.0244556   -0.0401265    0.0537286   -0.072204   -0.0428365    0.0619917   -0.00402735  -0.0226582    0.261161     0.116921     0.0840558   -0.0519074    0.0447263    -0.0814804    0.0150421    0.143099      0.0705839
 -0.0111484   -0.0914761   0.06909      0.101146     0.0100097    0.0764389    -0.0605828    0.22042     -0.0177349    0.108676    -0.0145519    0.140119    -0.0510271  -0.12903      0.0260684    0.120904     0.126186    -0.169479     0.0990358   -0.0951834    0.0507292    2.04881e-5    0.074288    -0.114847    -0.118047     -0.0169669
  0.0944388    0.0407043  -0.154995     0.115668    -0.0478468    0.13472       0.00250543  -0.0376274   -0.0520229    0.173558     0.126128    -0.0294964   -0.031853    0.100167    -0.143264    -0.111058    -0.176658     0.101449     0.0337668   -0.00348636   0.0421323    0.0617167     0.00180243   0.058605    -0.106687      0.206709
 -0.0232898    0.0437774   0.0392062    0.0300221    0.194899     0.125902      0.126127     0.0248658    0.155822    -0.0260012   -0.126525     0.0121419   -0.172075   -0.162072    -0.0413876   -0.0502128   -0.0548776   -0.0547875   -0.024387    -0.0457593   -0.0630754   -0.0350845    -0.0025142    0.00480743  -0.111211      0.0377697
 -0.036903     0.159604    0.082724    -0.20578      0.170645    -0.0380237    -0.00634211  -0.0836075   -0.132498     0.0990709    0.148909     0.198212     0.117929    0.00127524   0.00499554   0.154575    -0.092724    -0.106807    -0.120002    -0.0388581   -0.0122143    0.0602038    -0.0316436   -0.224874     0.179378     -0.0259174
 -0.267284    -0.0342208   0.0426954   -0.0378903   -0.0744225    0.0617999     0.230597    -0.0462454    0.00991517  -0.00444947  -0.00892087  -0.0366141    0.134072    0.0540632    0.199368     0.0322037   -0.00686203  -0.19742     -0.13187      0.215362    -0.0502849   -0.0339916     0.0185473   -0.132182     0.129648     -0.00708323
 -0.123411    -0.0562725  -0.0653374   -0.0928541   -0.127563     0.0863947     0.0800162    0.0514941   -0.0112955   -0.0994026   -0.254147     0.0886655   -0.15962    -0.0518749    0.0798067    0.00485771   0.0205378    0.137967     0.0294569   -0.0430514    0.00916855   0.0427247    -0.0125761   -0.0843722    0.107136     -0.203746
  0.0559515    0.119779   -0.00199943  -0.069919    -0.21909      0.0534961    -0.223747    -0.00963766  -0.0819561   -0.00211889   0.0110803   -0.00214657   0.0461529  -0.126773    -0.0238287   -0.0826651    0.162068     0.106461     0.211814    -0.097605    -0.0340697    0.0286313     0.00995965   0.0555661    0.131689     -0.0235695
  0.209264     0.161937    0.0457328   -0.032985     0.0623572   -0.0265987     0.111912    -0.022903    -0.0252707    0.0998635    0.00848095  -0.126286    -0.125608   -0.0307879    0.178488     0.171954     0.0919123    0.0940275    0.032934    -0.138035     0.0963758   -0.0950691     0.0195955    0.0892303   -0.0652979    -0.0648609
  0.0275712    0.102374    0.162977     0.0724019   -0.0439158   -0.0148727    -0.0303079    0.0552609   -0.0520294    0.102143    -0.107316     0.0587316   -0.0202067   0.0310205   -0.0285716    0.148732     0.0916242   -0.0648496   -0.156957    -0.0772453   -0.0185386   -0.0601769     0.0581635   -0.0107728   -0.000567745   0.0752236
 -0.010551    -0.16615     0.0481263   -0.146326     0.0466597   -0.0729739    -0.0870166   -0.163252     0.0926677    0.00626957  -0.219266     0.0842122   -0.0693015   0.1208       0.072199     0.0135794    3.92638e-5   0.0896665    0.110013    -0.029401     0.0505498    0.0473574     0.0292697   -0.0687216    0.0123136     0.0321121
 -0.0290488   -0.0879646  -0.133706    -0.0212659    0.135847     0.0941605    -0.175888     0.0883418   -0.0908138   -0.194341     0.0809147    0.0535013   -0.020181    0.18692      0.0832498   -0.153279    -0.0827031   -0.0840428   -0.187508    -0.0940142    0.0576947    0.185108      0.051368    -0.0292622    0.158461      0.133044
  0.0454339   -0.0964994  -0.0098762   -0.0363934    0.0829518   -0.0860477    -0.0637272    0.0386758    0.00393163   0.102792     0.217052    -0.0713127    0.125627   -0.00770603   0.0436625    0.151734     0.0683101    0.0223194    0.140075    -0.00584503  -0.0228018    0.0988208     0.0111208    0.00476004   0.0333292     0.0673012
  0.0746435   -0.061908   -0.0478722    0.034106    -0.0107082   -0.112242     -0.0939306    0.0736549    0.169593     0.126943    -0.0697659   -0.0172073    0.022039    0.12442     -0.112631     0.0439273    0.0636225    0.0678346    0.153487     0.140333    -0.0536404   -0.110975      0.017262    -0.061525     0.0521541    -0.0611551
  0.0537375    0.0766264   0.0425334    0.0658032   -0.144693    -0.026991      0.0330955    0.109357    -0.0227777    0.0851844   -0.0613718   -0.163601     0.134832   -0.150255    -0.0757467   -0.0102218    0.0440364    0.101798     0.112361    -0.103159     0.0443266    0.0109908    -0.0643139   -0.111795     0.0221238     0.0253406
 -0.00999995  -0.0270195   0.122916    -0.0305246    0.0778564   -0.181834     -0.0434332    0.219383     0.0488775   -0.0999036   -0.0926182   -0.128934    -0.0991285   0.0526125    0.195612     0.24034     -0.162062     0.108824     0.0664835   -0.0950316    0.0673916    0.0944752    -0.0481199   -0.202071    -0.155389      0.0545678
  0.0134257   -0.132266   -0.0840898    0.0414847    0.0223853   -0.0125596    -0.0545477    0.0148096   -0.0456772    0.0134945   -0.0766127    0.115251     0.0401426   0.0175064    0.00608902   0.0109728    0.0219247    0.0624428    0.0184094    0.0533046    0.018326     0.0945763     0.133363     0.072798    -0.0435661     0.131727
 -0.105269     0.150959   -0.0423119    0.0151882    0.112393     0.0857476    -0.132727    -0.0111309    0.0577085   -0.0656755   -0.0080568    0.0374837   -0.0404578   0.0240836   -0.189929    -0.0223427    0.0528461    0.105562    -0.112966    -0.0870097    0.0235212   -0.0888655     0.0145388    0.147681     0.0085783    -0.0718545
 -0.0353704    0.0859726   0.06712     -0.0144728    0.00022647  -0.00941344    0.0165579   -0.014498     0.00786702  -0.185825     0.202479    -0.144994     0.0122757  -0.0535855    0.0318058    0.0458466    0.0154017   -0.186943    -0.0266919   -0.0446409   -0.105313    -0.000394564   0.0198219   -0.0130042    0.169963      0.0878118
 -0.107623     0.0150196  -0.133198    -0.161557    -0.0351137    0.00400321   -0.131766    -0.0742365   -0.00361096  -0.167467     0.0424269   -0.0057663   -0.114833   -0.0622373   -0.122776    -0.0194749    0.0549238    0.0781668    0.0705133    0.0274762    0.0928974    0.112037      0.0963386   -0.0627516    0.0109398     0.0235452
 -0.0908403    0.0336584  -0.039695    -0.0786392    0.056988    -0.000704929  -0.022537    -0.0643188   -0.00130332   0.188935    -0.168826    -0.0300146   -0.134506    0.153346     0.0144465    0.090651    -0.0378422   -0.0224053   -0.0138633    0.0495128   -0.0819367    0.0203551    -0.100058     0.0166029    0.0415189    -0.00335245kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3813182582966235
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.381374
[ Info: iteration 2, average log likelihood -1.381296
[ Info: iteration 3, average log likelihood -1.380751
[ Info: iteration 4, average log likelihood -1.375531
[ Info: iteration 5, average log likelihood -1.361541
[ Info: iteration 6, average log likelihood -1.354399
[ Info: iteration 7, average log likelihood -1.351398
[ Info: iteration 8, average log likelihood -1.348908
[ Info: iteration 9, average log likelihood -1.347101
[ Info: iteration 10, average log likelihood -1.345653
[ Info: iteration 11, average log likelihood -1.344572
[ Info: iteration 12, average log likelihood -1.343828
[ Info: iteration 13, average log likelihood -1.343329
[ Info: iteration 14, average log likelihood -1.343000
[ Info: iteration 15, average log likelihood -1.342795
[ Info: iteration 16, average log likelihood -1.342672
[ Info: iteration 17, average log likelihood -1.342599
[ Info: iteration 18, average log likelihood -1.342558
[ Info: iteration 19, average log likelihood -1.342534
[ Info: iteration 20, average log likelihood -1.342519
[ Info: iteration 21, average log likelihood -1.342511
[ Info: iteration 22, average log likelihood -1.342506
[ Info: iteration 23, average log likelihood -1.342503
[ Info: iteration 24, average log likelihood -1.342501
[ Info: iteration 25, average log likelihood -1.342500
[ Info: iteration 26, average log likelihood -1.342499
[ Info: iteration 27, average log likelihood -1.342499
[ Info: iteration 28, average log likelihood -1.342499
[ Info: iteration 29, average log likelihood -1.342498
[ Info: iteration 30, average log likelihood -1.342498
[ Info: iteration 31, average log likelihood -1.342498
[ Info: iteration 32, average log likelihood -1.342498
[ Info: iteration 33, average log likelihood -1.342498
[ Info: iteration 34, average log likelihood -1.342498
[ Info: iteration 35, average log likelihood -1.342498
[ Info: iteration 36, average log likelihood -1.342498
[ Info: iteration 37, average log likelihood -1.342498
[ Info: iteration 38, average log likelihood -1.342498
[ Info: iteration 39, average log likelihood -1.342498
[ Info: iteration 40, average log likelihood -1.342498
[ Info: iteration 41, average log likelihood -1.342498
[ Info: iteration 42, average log likelihood -1.342498
[ Info: iteration 43, average log likelihood -1.342498
[ Info: iteration 44, average log likelihood -1.342498
[ Info: iteration 45, average log likelihood -1.342498
[ Info: iteration 46, average log likelihood -1.342498
[ Info: iteration 47, average log likelihood -1.342498
[ Info: iteration 48, average log likelihood -1.342498
[ Info: iteration 49, average log likelihood -1.342498
[ Info: iteration 50, average log likelihood -1.342498
┌ Info: EM with 100000 data points 50 iterations avll -1.342498
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.381373681982301
│     -1.3812964553776472
│      ⋮
└     -1.3424981205206765
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342570
[ Info: iteration 2, average log likelihood -1.342439
[ Info: iteration 3, average log likelihood -1.341299
[ Info: iteration 4, average log likelihood -1.333293
[ Info: iteration 5, average log likelihood -1.319286
[ Info: iteration 6, average log likelihood -1.311336
[ Info: iteration 7, average log likelihood -1.307906
[ Info: iteration 8, average log likelihood -1.306379
[ Info: iteration 9, average log likelihood -1.305574
[ Info: iteration 10, average log likelihood -1.305053
[ Info: iteration 11, average log likelihood -1.304651
[ Info: iteration 12, average log likelihood -1.304315
[ Info: iteration 13, average log likelihood -1.304035
[ Info: iteration 14, average log likelihood -1.303793
[ Info: iteration 15, average log likelihood -1.303566
[ Info: iteration 16, average log likelihood -1.303361
[ Info: iteration 17, average log likelihood -1.303186
[ Info: iteration 18, average log likelihood -1.303028
[ Info: iteration 19, average log likelihood -1.302884
[ Info: iteration 20, average log likelihood -1.302757
[ Info: iteration 21, average log likelihood -1.302646
[ Info: iteration 22, average log likelihood -1.302545
[ Info: iteration 23, average log likelihood -1.302459
[ Info: iteration 24, average log likelihood -1.302390
[ Info: iteration 25, average log likelihood -1.302338
[ Info: iteration 26, average log likelihood -1.302297
[ Info: iteration 27, average log likelihood -1.302265
[ Info: iteration 28, average log likelihood -1.302239
[ Info: iteration 29, average log likelihood -1.302218
[ Info: iteration 30, average log likelihood -1.302199
[ Info: iteration 31, average log likelihood -1.302181
[ Info: iteration 32, average log likelihood -1.302164
[ Info: iteration 33, average log likelihood -1.302148
[ Info: iteration 34, average log likelihood -1.302133
[ Info: iteration 35, average log likelihood -1.302117
[ Info: iteration 36, average log likelihood -1.302103
[ Info: iteration 37, average log likelihood -1.302089
[ Info: iteration 38, average log likelihood -1.302076
[ Info: iteration 39, average log likelihood -1.302063
[ Info: iteration 40, average log likelihood -1.302051
[ Info: iteration 41, average log likelihood -1.302041
[ Info: iteration 42, average log likelihood -1.302031
[ Info: iteration 43, average log likelihood -1.302024
[ Info: iteration 44, average log likelihood -1.302017
[ Info: iteration 45, average log likelihood -1.302012
[ Info: iteration 46, average log likelihood -1.302007
[ Info: iteration 47, average log likelihood -1.302004
[ Info: iteration 48, average log likelihood -1.302001
[ Info: iteration 49, average log likelihood -1.301998
[ Info: iteration 50, average log likelihood -1.301996
┌ Info: EM with 100000 data points 50 iterations avll -1.301996
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.342570311899316
│     -1.3424387203693686
│      ⋮
└     -1.3019958769736202
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.302097
[ Info: iteration 2, average log likelihood -1.301971
[ Info: iteration 3, average log likelihood -1.301473
[ Info: iteration 4, average log likelihood -1.297159
[ Info: iteration 5, average log likelihood -1.282735
[ Info: iteration 6, average log likelihood -1.269497
[ Info: iteration 7, average log likelihood -1.263582
[ Info: iteration 8, average log likelihood -1.260839
[ Info: iteration 9, average log likelihood -1.258620
[ Info: iteration 10, average log likelihood -1.256422
[ Info: iteration 11, average log likelihood -1.254555
[ Info: iteration 12, average log likelihood -1.253263
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.252043
[ Info: iteration 14, average log likelihood -1.262158
[ Info: iteration 15, average log likelihood -1.256350
[ Info: iteration 16, average log likelihood -1.253812
[ Info: iteration 17, average log likelihood -1.251478
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.249445
[ Info: iteration 19, average log likelihood -1.259997
[ Info: iteration 20, average log likelihood -1.254126
[ Info: iteration 21, average log likelihood -1.251687
[ Info: iteration 22, average log likelihood -1.249520
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.247665
[ Info: iteration 24, average log likelihood -1.258342
[ Info: iteration 25, average log likelihood -1.252696
[ Info: iteration 26, average log likelihood -1.250597
[ Info: iteration 27, average log likelihood -1.248741
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.247024
[ Info: iteration 29, average log likelihood -1.257662
[ Info: iteration 30, average log likelihood -1.252143
[ Info: iteration 31, average log likelihood -1.250185
[ Info: iteration 32, average log likelihood -1.248444
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.246778
[ Info: iteration 34, average log likelihood -1.257379
[ Info: iteration 35, average log likelihood -1.251890
[ Info: iteration 36, average log likelihood -1.249973
[ Info: iteration 37, average log likelihood -1.248273
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.246644
[ Info: iteration 39, average log likelihood -1.257252
[ Info: iteration 40, average log likelihood -1.251767
[ Info: iteration 41, average log likelihood -1.249865
[ Info: iteration 42, average log likelihood -1.248185
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.246582
[ Info: iteration 44, average log likelihood -1.257205
[ Info: iteration 45, average log likelihood -1.251710
[ Info: iteration 46, average log likelihood -1.249814
[ Info: iteration 47, average log likelihood -1.248141
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.246553
[ Info: iteration 49, average log likelihood -1.257191
[ Info: iteration 50, average log likelihood -1.251684
┌ Info: EM with 100000 data points 50 iterations avll -1.251684
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3020969212747375
│     -1.3019706691745263
│      ⋮
└     -1.2516841508081198
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.249923
[ Info: iteration 2, average log likelihood -1.248068
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.245527
[ Info: iteration 4, average log likelihood -1.239112
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.205316
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.177896
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.172553
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.182600
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.177385
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.165347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.161336
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.169843
[ Info: iteration 13, average log likelihood -1.185097
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.161953
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.155215
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.179402
[ Info: iteration 17, average log likelihood -1.181788
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.153168
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.164214
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.177441
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.175971
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.163474
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.161028
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.168224
[ Info: iteration 25, average log likelihood -1.184687
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.162134
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.156140
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.179049
[ Info: iteration 29, average log likelihood -1.181523
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.153432
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.165752
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.176916
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.175490
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.163809
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.162264
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.166877
[ Info: iteration 37, average log likelihood -1.183299
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.160893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.155564
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.162468
[ Info: iteration 41, average log likelihood -1.182800
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.151059
[ Info: iteration 43, average log likelihood -1.178430
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.157001
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.172228
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.172241
[ Info: iteration 47, average log likelihood -1.168034
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     11
│     12
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.142731
[ Info: iteration 49, average log likelihood -1.191140
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.163240
┌ Info: EM with 100000 data points 50 iterations avll -1.163240
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2499230922761202
│     -1.2480682650732295
│      ⋮
└     -1.163240403622315
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.156983
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.141705
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.153290
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.111529
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     16
│     21
│     22
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.074544
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│      5
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.060371
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     16
│     21
│     22
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.088622
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.057614
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│     15
│     16
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.061754
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.077096
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     16
│     21
│     22
│     27
│     28
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.071892
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      5
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.054817
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     16
│     21
│     22
│     27
│     28
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.081255
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071043
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.046442
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.087952
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.068319
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.043732
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.085909
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.064128
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.051930
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.080657
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.062772
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.054449
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080452
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.060278
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.051971
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.080519
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.062870
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.054336
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.080574
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.060168
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.052093
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.080408
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.062992
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.054222
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.080688
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.060056
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.052202
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.080300
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063091
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.054122
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.080779
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.059961
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.052282
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.080216
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.063157
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.054051
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     16
│     21
│     22
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.080838
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│     17
│     18
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.059896
┌ Info: EM with 100000 data points 50 iterations avll -1.059896
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1569829582951434
│     -1.1417052004389432
│      ⋮
└     -1.0598959368494425
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3813182582966235
│     -1.381373681982301
│     -1.3812964553776472
│     -1.3807513175284323
│      ⋮
│     -1.0540509740936606
│     -1.080837849332997
└     -1.0598959368494425
32×26 Array{Float64,2}:
  0.111169    -0.00305207  -0.0763922   -0.0319514    0.0234832   -0.0228344   -0.0465663    0.0855116    0.147648     0.0800466   -0.0674762     0.0149669   -0.0177132    0.0324951   -0.0225249   0.0104488    0.0225143     0.16071      0.125534     0.0944667   -0.0227236  -0.0245726    -0.00622601  -0.0259676    0.0989676    0.00203287
  0.0543538   -0.0445878   -0.0576713    0.0885582    0.0173183    0.0188847   -0.032721     0.0194604   -0.0449851    0.0752598    0.0119827     0.0248316    0.00222016   0.0585518   -0.0362442  -0.00962688  -0.082643      0.0862205    0.062625     0.0434043    0.0431051   0.0631605     0.0616989    0.0307988   -0.0804528    0.177846
  0.190983     0.16338      0.00271886  -0.0353353    0.0623473   -0.0318669    0.140374    -0.055318    -0.0333152    0.0906226   -0.00397365   -0.127168    -0.144945    -0.0181375    0.1788      0.131994     0.117326      0.103553     0.0302992   -0.13205      0.0960328  -0.0561591     0.0165432    0.0581568   -0.0882536   -0.0640164
  0.041031    -0.122608    -0.0131639    0.0631167    0.0751163   -0.0304123   -0.0724464    0.00561682   0.137746     0.132232     0.0600245     0.0756849   -0.0500177    0.072228     0.0153971  -0.0737007    0.0105579     0.00973275   0.131625     0.00465574  -0.0727809   0.173976      0.0336917    0.099493    -0.114358    -0.0723547
 -0.124027    -0.0539446   -0.0817626   -0.138901    -0.12787      0.0841809    0.0654725    0.0636763   -0.056412    -0.0914164   -0.278145      0.0949841   -0.143728    -0.0564984    0.074277    0.0232656    0.0207687     0.145532     0.0297546   -0.0285594   -0.0181152   0.0420209    -0.0088282   -0.0844694    0.0936458   -0.216567
  0.112581    -0.0582106   -0.14776     -0.166551    -0.0650214   -0.0430677    0.109687    -0.265748    -0.0627081   -0.112814    -0.0382735    -0.0327761   -0.0720536   -0.0176295   -0.212947    0.00851625   0.0759416    -0.041452     0.157334     0.138868     0.0967783  -0.0463615    -0.02714     -0.0517691   -0.10183     -0.0402669
  0.056191     0.123547    -0.0233247   -0.0821796   -0.225712     0.0896406   -0.201103    -0.0258338   -0.112116    -0.00563501   0.0104673     0.0205691    0.0502227   -0.127232    -0.0404688  -0.0677104    0.149844      0.0795151    0.179813    -0.0924489   -0.0443442   0.0496381     0.010102     0.056331     0.122344    -0.0894193
  0.0460213    0.0930953    0.0601362   -0.268269    -0.0732739   -0.485575     0.0889888    0.140556     0.881933     0.00518456   0.0368764    -0.259521     0.0252199   -0.419813    -0.0304491   0.0891139    0.0240769     0.692783     0.368545    -0.274186    -0.0694442  -0.0943294     0.00694366   0.0553295    0.0693103    0.0706691
  0.00533209   0.0600945    0.00527356   0.0557749    0.0120773   -0.130237     0.0942208   -0.287861     0.0211223   -0.0344235   -0.0714655     0.119031     0.0720842    0.0673112    0.0219028  -0.0710059   -0.0297486    -0.100819    -0.0421936    0.00627708  -0.0408563   0.0820812    -0.0559193   -0.0526026    0.0229705   -0.00536329
  0.0261786   -0.133679    -0.0811505    0.0625738    0.0497774   -0.212443    -0.280075     0.116295    -0.0880514    0.00345437  -0.0123204    -0.0551418    0.0698704   -0.0101428   -0.236823   -0.151515     0.0696077    -0.00794902  -0.168149    -0.0890754    0.0635664  -0.146861     -0.111949    -0.109659     0.116567     0.0832422
 -0.00362408  -0.0997286    0.0331409   -0.0795154    0.0714688   -0.10419     -0.047224     0.00225072   0.0452885    0.0278063    0.000372592  -0.0286737   -0.00514815   0.0558447    0.0899931   0.153392    -0.0313312     0.0863584    0.0991509   -0.0274432    0.0212524   0.075331      0.00372796  -0.0714383   -0.0199559    0.0475401
 -0.00499401   0.0702381    0.0929678    0.0891908    0.105682     0.0635133    0.0412237    0.0304592    0.052173     0.0228173   -0.0981909     0.0270762   -0.107295    -0.0667492   -0.0305989   0.0466977    0.0287766    -0.0353424   -0.0646516   -0.0679544   -0.0620734  -0.0682622     0.021414    -0.0181286   -0.0658028    0.0476321
  0.090928    -0.00516865   0.0979247   -0.0845272   -0.155088    -0.0408215    0.0344322    0.0235311    0.0384297   -0.0165691    0.0386143    -0.119258     0.138192     0.0634936   -0.190033   -0.0904647   -0.0298597    -0.0565269    0.0476889   -0.0931048    0.0126627   0.0143072    -0.03343     -0.00343658  -0.0331526   -0.0230794
 -0.0675244    0.162866     0.0170796   -0.0729233    0.169473     0.0200766   -0.0755418   -0.0473058   -0.0425651    0.0158884    0.0560139     0.11416      0.0454398    0.032951    -0.126621    0.0841645   -0.0232066     0.00753258  -0.145953    -0.0628689    0.0158846  -0.0134158    -0.0106793   -0.0131233    0.0853148   -0.0524896
 -0.0620742   -0.0414562    0.0386849    0.139075     0.113666    -0.0173987   -0.140021    -0.0490157   -0.0853434    0.157527     0.075568     -0.0294487    0.0541756   -0.00650956   0.0510781  -0.0549875   -0.0696344     0.0535275   -0.0305833    0.0170976   -0.0253107   0.121963     -0.0756784    0.0271681   -0.0564109   -0.0698875
  0.00870114   0.198516     0.0391035   -0.00430553   0.195621     0.0699942   -0.199291    -0.106293    -0.0399496    0.00769814   0.121973      0.0378697    0.112193     0.102023    -0.0753083  -0.0539762    0.0351783     0.105666    -0.124469    -0.159282     0.143523    0.0535366     0.0393162    0.158067    -0.0408395    0.0395311
 -0.0291102   -0.502528    -0.123997    -0.0245322    0.151567     0.0938662   -0.215613     0.0847644   -0.107288    -0.176797     0.080864      0.0497967   -0.0389542    0.188691     0.0807543  -0.124599    -0.0885775    -0.108193    -0.190732    -0.0929773    0.0483653   0.155871      0.0561076    0.0185039    0.147985     0.125323
 -0.0745669    0.420458    -0.118204    -0.0186085    0.0998065    0.0939973   -0.144823     0.0922546   -0.0683336   -0.153092     0.0815068     0.0534285   -0.0311579    0.178431     0.0922032  -0.0525944   -0.0919812    -0.0700985   -0.175977    -0.0959805    0.036833    0.192941      0.0480451   -0.091356     0.19463      0.128786
  0.199173     0.0645475   -0.032211    -0.0947699    0.149731    -0.0533329   -0.469897    -0.0292636   -0.0717436   -0.124258     0.103581     -0.0932459   -0.301248     0.0483211    0.0116923  -0.0110286   -0.0169994     0.218426    -0.0754458    0.0970668   -0.238305   -0.065191      0.0665505    0.0677005   -0.152559     0.00193133
 -0.186806     0.0636484    0.0376773   -0.0366677    0.128933    -0.0463262    0.18783      0.0965901   -0.0696747   -0.0586622    0.116107     -0.153509     0.210828     0.178193     0.0179873  -0.230721    -0.237976      0.209521    -0.0797494    0.102343    -0.265583   -0.0753605     0.100228     0.0423097   -0.152479    -0.0375996
 -0.0349692   -0.0787777    0.0608291    0.135206     0.00480296  -0.964796    -0.0540318    0.227559    -0.0219236    0.130102    -0.0129775     0.127796    -0.0523107   -0.116228     0.0415352   0.151808     0.111188     -0.169491     0.142059    -0.0857061    0.0656667  -0.000914659   0.0743408   -0.122701    -0.140934    -0.0188626
 -0.00943672  -0.0143592    0.0715962    0.131925     0.0192005    1.06531     -0.0672438    0.237694    -0.0433064    0.112993    -0.00974201    0.136382    -0.0507036   -0.119279     0.0324716   0.124763     0.181271     -0.16966      0.110211    -0.0868751    0.0456345   0.00218845    0.0721469   -0.111843    -0.118709    -0.0139725
  0.0505327    0.0293482   -0.0105215   -0.718361     0.0268928   -0.203941    -0.0455936    0.183539    -0.0167963   -0.0668919    0.119245     -0.0481712    0.123987     0.0407207   -0.171455    0.0601029   -0.0865325    -0.135103    -0.18616     -0.151589     0.142997   -0.121375     -0.172028    -0.0794993   -0.0924016   -0.00910601
  0.0415711    0.0449688    0.00998419   1.13767      0.0590312   -0.203939    -0.00935118   0.141069     0.0476383    0.283647     0.133906     -0.0337856    0.0827907    0.0454478   -0.0395692   0.0541761   -0.0803554    -0.134465    -0.205943    -0.158811     0.156035   -0.119983     -0.138712    -0.135689    -0.116513    -0.0091287
  0.0325412    0.0524047   -0.121268    -0.0489698    0.00360103   0.0693509    0.0279509    0.042681    -0.0174144    0.0446048   -0.180445      0.0508586   -0.0437167    0.0138124   -0.217105    0.0803898   -0.0808342    -0.00697304  -0.110873     0.08309     -0.0404808   0.0897354     0.0956035   -0.105549    -0.136738    -0.118742
 -0.0901696    0.0479495   -0.0453551   -0.0819873    0.0597855   -0.00108755  -0.0129443   -0.0611649   -0.00293032   0.174003    -0.168396     -0.0387785   -0.139419     0.171007     0.0164532   0.0834914   -0.0228014    -0.00217289  -0.00786551   0.0499033   -0.0878172   0.0170009    -0.0990579    0.0120456    0.0344264   -0.0135397
 -0.107491     0.00444679  -0.133282    -0.148013    -0.0265246    0.0717113   -0.16254     -0.0225006    0.00454872  -0.782447     0.0237233    -0.0104841   -0.118185     0.0666767   -0.277177   -0.089341     0.0547416     0.078265     0.055204     0.0547307    0.0962394   0.207931      0.0722886   -0.0542822   -0.00908364   0.02394
 -0.106998     0.050145    -0.135334    -0.143262    -0.03738     -0.00761704  -0.144878    -0.154653    -0.0266037    0.571539     0.128851      0.00321365  -0.118543    -0.193016    -0.0245234  -0.0053035    0.0547835     0.0750443    0.0837966   -0.0168284    0.0938396  -0.00972962    0.155467    -0.0429552    0.0146883    0.0235919
 -0.0894206   -0.101622    -0.0433303    0.0877589    0.0277422    0.0189379    0.196102     0.171729     0.0137614    0.00294997  -0.110775     -0.189486    -0.147873    -0.033349    -0.0133545  -0.00495812  -0.111039     -0.222545     0.0832922    0.15009      0.15441    -0.0974633     0.00559727   0.0515317    0.190716    -0.0426692
 -0.0351555    0.105472     0.0695743   -0.00974527   0.0206745   -0.0246308    0.018198     0.0335911    0.00811821  -0.184654     0.180325     -0.171915     0.0120448   -0.0521155    0.0406471   0.0449392    0.0140252    -0.192973    -0.0246502   -0.0499275   -0.147777   -0.0518828     0.00929255   0.00396092   0.169719     0.0853755
 -0.32164      0.152103     0.0419878   -0.0208477   -0.0148622    0.0533163    0.199088    -0.0303888    0.011885    -0.255803    -0.0577074     0.026751     0.13875     -0.0871185   -0.073798    0.0377365   -0.0193733    -0.266561    -1.09698      0.217124    -0.0492602   0.0476378     0.0111088   -0.13801      0.323552     0.188787
 -0.265378    -0.137591     0.041963    -0.0528024   -0.0838138    0.0563138    0.352893    -0.0323825    0.0132806    0.144479    -0.0259859     0.0061103    0.136294     0.1607       0.25369     0.0374345   -0.000941932  -0.141794     0.275684     0.215991    -0.049292   -0.0743385    -0.00909969  -0.139405     0.0561703   -0.113783[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.052329
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.032404
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.052223
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.032385
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.052153
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.032422
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.052059
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032482
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      8
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051932
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032567
┌ Info: EM with 100000 data points 10 iterations avll -1.032567
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.361333e+05
      1       6.344878e+05      -2.016454e+05 |       32
      2       6.097928e+05      -2.469505e+04 |       32
      3       5.960757e+05      -1.371710e+04 |       32
      4       5.884740e+05      -7.601666e+03 |       32
      5       5.839479e+05      -4.526164e+03 |       32
      6       5.810402e+05      -2.907721e+03 |       32
      7       5.784751e+05      -2.565065e+03 |       32
      8       5.760026e+05      -2.472475e+03 |       32
      9       5.741577e+05      -1.844952e+03 |       32
     10       5.729406e+05      -1.217079e+03 |       32
     11       5.723425e+05      -5.980646e+02 |       32
     12       5.721315e+05      -2.110206e+02 |       32
     13       5.720424e+05      -8.908927e+01 |       32
     14       5.720059e+05      -3.648474e+01 |       32
     15       5.719800e+05      -2.592463e+01 |       32
     16       5.719619e+05      -1.812314e+01 |       31
     17       5.719476e+05      -1.430667e+01 |       31
     18       5.719379e+05      -9.710938e+00 |       27
     19       5.719319e+05      -5.933383e+00 |       31
     20       5.719281e+05      -3.868357e+00 |       27
     21       5.719254e+05      -2.650452e+00 |       24
     22       5.719238e+05      -1.582741e+00 |       18
     23       5.719229e+05      -9.534557e-01 |       14
     24       5.719222e+05      -6.787681e-01 |       18
     25       5.719214e+05      -7.622760e-01 |       14
     26       5.719211e+05      -3.661987e-01 |        9
     27       5.719208e+05      -2.956467e-01 |        4
     28       5.719207e+05      -6.776145e-02 |        2
     29       5.719206e+05      -4.624547e-02 |        2
     30       5.719206e+05      -2.969946e-02 |        0
     31       5.719206e+05       0.000000e+00 |        0
K-means converged with 31 iterations (objv = 571920.6194736231)
┌ Info: K-means with 32000 data points using 31 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.304044
[ Info: iteration 2, average log likelihood -1.274017
[ Info: iteration 3, average log likelihood -1.239913
[ Info: iteration 4, average log likelihood -1.200026
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.156495
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.118784
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.059923
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.097290
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     17
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.039384
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059573
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.061902
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.064803
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.004445
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.116760
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.068979
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.018220
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     10
│     17
│     18
│     24
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.023190
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.107363
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.053778
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      7
│     12
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.021059
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     10
│     18
│     24
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.045854
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.087306
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.063145
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     10
│     12
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.018342
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     18
│     24
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039354
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.073401
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│     12
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.054284
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.050981
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.028463
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073449
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     10
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.046932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.052153
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.033796
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.067376
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.064986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.040843
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     12
│     16
│     17
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.018671
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.106329
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.089253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052453
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     12
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.988100
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.100772
[ Info: iteration 44, average log likelihood -1.103857
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.036501
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     17
│     18
│     20
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.008518
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.081076
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.030174
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     12
│     17
│     18
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.033595
┌ Info: EM with 100000 data points 50 iterations avll -1.033595
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0143366   -0.165214     0.0477039    -0.254889    0.0599606   -0.111317     -0.236371     -0.14948      0.0909885    0.0418996   -0.211995     0.092886    -0.118545     0.14682      0.0647358    0.0349801     0.0020443   0.0955116   0.362868    -0.0405282    0.0253       0.0416264    0.0869802   -0.00298587   0.00633298   0.0755669
 -0.0850586    0.047691    -0.0517659    -0.0804877   0.0593375    0.000548294  -0.0115172    -0.0631737   -0.00534419   0.168468    -0.168217    -0.0331752   -0.134451     0.169637     0.00477001   0.0818596    -0.0228827  -0.0110431  -0.0207489    0.0547627   -0.0862617    0.02493     -0.0910438    0.0106731    0.0448796   -0.0194576
  0.0303321    0.0777549    0.161984      0.0721634  -0.012845    -0.00388019   -0.0298293     0.0484183   -0.0476192    0.0991498   -0.0914473    0.0719018   -0.0325318    0.0277685   -0.0620114    0.137172      0.0839337  -0.0335848  -0.138333    -0.0509386   -0.0292667   -0.0571094    0.0452693   -0.0469386    0.0199068    0.0156609
  0.05708      0.0301985   -0.128411      0.154424   -0.0453488    0.10548       0.00505484   -0.0771135   -0.0819657    0.170811     0.118912    -0.0231434   -0.023542     0.0911587   -0.143354    -0.103444     -0.164542    0.100266    0.100797     0.0052333    0.0379298    0.033705     0.0222637    0.0494368   -0.102781     0.219982
  0.0944937   -0.05889     -0.151805     -0.171842   -0.0706717   -0.0321276     0.105642     -0.243283    -0.0596362   -0.107749    -0.062947    -0.0222004   -0.0734458   -0.0237791   -0.194127     0.00545641    0.0750059  -0.0330939   0.151141     0.136899     0.0913067   -0.0401418   -0.0273478   -0.0540322   -0.0931676   -0.0512189
  0.0256712   -0.135653    -0.0817016     0.0628314   0.0493491   -0.210689     -0.278245      0.11592     -0.0888981    0.00407446  -0.0134093   -0.0523014    0.0698916   -0.0109877   -0.236519    -0.15029       0.0668877  -0.0096743  -0.170601    -0.0856848    0.0619771   -0.146317    -0.109641    -0.109982     0.116509     0.0810229
 -0.036932    -0.121083     0.0544235    -0.0621735  -0.00969355  -0.0403396     0.00145673   -0.122309     0.0850948   -0.0163212   -0.157886     0.0332525   -0.00713696   0.0788826    0.0486084    0.0390018    -0.027074    0.0286198  -0.213322     0.145093     0.0349868    0.0299925   -0.011529    -0.0846222    0.0173364    0.0115819
  0.0870011   -0.0588901   -0.0500056     0.0273475  -0.00673069  -0.0994453    -0.0943489     0.0763161    0.170077     0.131977    -0.0705664   -0.0156009    0.0461325    0.120063    -0.112469     0.0460929     0.0646726   0.0623351   0.124771     0.139664    -0.0263294   -0.115062     0.0405864   -0.0865719    0.0563911   -0.0640843
  0.146508     0.0598262   -0.0995728    -0.0759248   0.042486     0.0445329    -0.00422698    0.0851569    0.127519     0.0265086   -0.0644922    0.0481784   -0.0707761   -0.0427637    0.0634325   -0.0308854    -0.022285    0.264682    0.12819      0.0590852   -0.0254156    0.0502974   -0.066196     0.0222365    0.143302     0.0683766
  0.030096     0.0603704   -0.167398     -0.0613252   0.00201012   0.0719092     0.0151341     0.0344817   -0.00868822   0.0304795   -0.200588     0.0419704   -0.036968    -0.00120877  -0.21568      0.0792972    -0.0833971  -0.0391326  -0.0916628    0.100834    -0.0502067    0.0801724    0.0942601   -0.10388     -0.256689    -0.114835
 -0.089065    -0.102512    -0.0432971     0.0867266   0.0277533    0.0192018     0.197906      0.172432     0.0127611    0.00230837  -0.110649    -0.18851     -0.148062    -0.0325061   -0.0125234   -0.00482435   -0.112273   -0.22218     0.0833977    0.150112     0.153743    -0.0964284    0.00489942   0.0528307    0.193308    -0.0425748
 -0.0352623    0.106273     0.0695308    -0.0091363   0.0210821   -0.0232083     0.0197687     0.035014     0.00770417  -0.185221     0.180778    -0.172258     0.0136811   -0.0533524    0.0382423    0.0446883     0.0146925  -0.194455   -0.02474     -0.0497017   -0.150339    -0.0508868    0.00890836   0.00302444   0.172292     0.0842109
  0.0139759   -0.118087    -0.0217494    -0.0412271   0.101941    -0.0572892     0.0194681     0.0340882   -0.00203302   0.114427     0.219022    -0.0723751    0.126537    -0.00165115   0.042996     0.186227      0.0638869   0.0745011   0.134879     0.00282712  -0.0318116    0.0982691    0.0190727    0.0261779    0.0348394    0.0181542
 -0.0137858   -0.0325321    0.0815685    -0.0290573   0.0828464   -0.17797      -0.0658386     0.225113     0.0457282   -0.0761792   -0.100509    -0.120067    -0.105482     0.0477538    0.197395     0.236656     -0.165085    0.125314    0.0374794   -0.0890641    0.0649542    0.0891677   -0.0459672   -0.199762    -0.157269     0.0552965
 -0.102998     0.142875    -0.0468848     0.0474599   0.153749     0.0847327    -0.132614     -0.0119029    0.0480383   -0.0658957   -0.0214473    0.0343397   -0.0214705    0.0419233   -0.229428     0.0203771     0.0610551   0.117646   -0.155392    -0.0875251    0.0256516   -0.0779194    0.0123184    0.162437     0.0101384   -0.0736786
  0.0432782    0.0332647   -0.00239635   -0.0597688   0.0404496   -0.199329     -0.0255074     0.160725     0.00806039   0.0533473    0.122575    -0.0533058    0.110206     0.0418513   -0.128529     0.0588782    -0.0822618  -0.132771   -0.192125    -0.151037     0.149631    -0.120017    -0.168888    -0.0929673   -0.0970411   -0.00941158
 -0.107196     0.0296704   -0.134502     -0.14746    -0.0321576    0.035037     -0.153587     -0.0880017   -0.0105674   -0.110291     0.0783839   -0.00410537  -0.118119    -0.061317    -0.154719    -0.0502459     0.0546754   0.0764092   0.0693609    0.0201809    0.0953857    0.102051     0.112591    -0.0489007    0.00381282   0.0236984
 -0.0456323   -0.117116    -0.120429     -0.0226276   0.130394     0.0934797    -0.185262      0.0884762   -0.090252    -0.168476     0.0808791    0.0514394   -0.0366548    0.184165     0.0861683   -0.0968092    -0.0902238  -0.0928722  -0.184618    -0.094598     0.0438062    0.171462     0.0530726   -0.0281296    0.167864     0.126538
  0.189654     0.160817     0.00360496   -0.035349    0.0619211   -0.0305247     0.138017     -0.0561726   -0.0320851    0.0923285   -0.00659826  -0.126621    -0.145575    -0.0167702    0.176997     0.128134      0.122236    0.103876    0.0300418   -0.131387     0.0946519   -0.0553506    0.0153956    0.0604941   -0.0915207   -0.0650598
  0.00754733   0.204775     0.0330147    -0.0100663   0.190057     0.0725095    -0.204555     -0.112118    -0.0363366    0.0077769    0.119767     0.0404782    0.110368     0.105973    -0.0744403   -0.0568587     0.0339359   0.0968833  -0.129973    -0.163386     0.144999     0.0541869    0.0378861    0.160263    -0.0506849    0.0445222
  0.00532085   0.0592449    0.00631997    0.0560844   0.0109318   -0.131316      0.0944572    -0.288256     0.020969    -0.0335704   -0.0714624    0.119671     0.071673     0.0654292    0.0228475   -0.0725236    -0.0282244  -0.101303   -0.0422755    0.00570814  -0.0405342    0.0812249   -0.0563772   -0.052751     0.0223693   -0.005825
  0.0128603    0.0637693    0.000206328  -0.0661938   0.140515    -0.0495133    -0.155016      0.0298498   -0.071349    -0.0936147    0.109949    -0.120642    -0.0540516    0.110488     0.0164271   -0.117039     -0.121534    0.213425   -0.0780811    0.0988946   -0.2513      -0.0701753    0.0834201    0.0553476   -0.154177    -0.0179437
  0.0481327   -0.00349702  -0.0191888    -0.0140325  -0.0706715    0.0150301    -0.133641     -0.00363442   0.0451456    0.0653279    0.0381809    0.0466812   -0.00310396  -0.0356624   -0.0117141   -0.079228      0.0783077   0.058697    0.164228    -0.0470941   -0.0666114    0.11328      0.0221566    0.0900798   -0.00187873  -0.0756516
 -0.0334708    0.185836     0.0861141    -0.201372    0.187815    -0.0429863    -0.000265452  -0.0909107   -0.131444     0.0978283    0.146338     0.198987     0.101932     0.0229091   -0.021706     0.153798     -0.107509   -0.115516   -0.120958    -0.033206     0.00368795   0.0591853   -0.0342662   -0.194575     0.171637    -0.0295272
 -0.360187    -0.0479747    0.041137     -0.0646509  -0.0772023    0.0874637     0.406609     -0.0216216    0.0390605   -0.00036208   0.0293592    0.0255702    0.0644143    0.0433738    0.188755     0.030721     -0.0065669  -0.21579    -0.181122     0.175239    -0.0438315   -0.0426807    0.00185939  -0.136432     0.254956    -0.00745529
  0.0521473    0.0863782    0.0389835     0.166465    0.26256      0.134994      0.0870488     0.0104541    0.163566    -0.0671708   -0.175358     0.00341016  -0.172281    -0.152271    -0.0338391   -0.047317     -0.0463161   0.0490719   0.0498173   -0.110051    -0.107204    -0.0452301   -0.0225752    0.00769384  -0.240167     0.0908223
 -0.11177     -0.061815    -0.117491     -0.199388   -0.118317     0.0871315     0.0356272     0.0689808   -0.10901     -0.104599    -0.270993     0.0908218   -0.133332    -0.047828     0.0498848    0.0425985     0.0230941   0.167404    0.0342175   -0.0654648   -0.0206783    0.0369751    0.0134399   -0.0794211    0.129001    -0.373343
 -0.0630287   -0.0338054    0.0393974     0.127639    0.112827    -0.0155473    -0.142336     -0.051006    -0.0873074    0.15407      0.075424    -0.0274705    0.0541644   -0.005346     0.0514295   -0.0545533    -0.0663294   0.0574001  -0.0342538    0.0114727   -0.0279591    0.120259    -0.0744148    0.0252094   -0.0502588   -0.077097
  0.123392    -0.0669472    0.157277     -0.207341   -0.154512    -0.0517809    -0.00360221   -0.0468034    0.0843423   -0.111273     0.128244    -0.0884819    0.153495     0.222908    -0.286051    -0.188334     -0.0955162  -0.2058      0.00288973  -0.11293      0.00473053   0.00987722   0.0151416    0.111193    -0.092313    -0.078165
 -0.0196536   -0.0457038    0.0603899     0.132386    0.0103777    0.0493067    -0.0699149     0.231851    -0.0319394    0.122988    -0.00474653   0.132698    -0.0470134   -0.110414     0.0338837    0.13313       0.130247   -0.167922    0.114019    -0.0923568    0.0580379   -0.00581625   0.0692756   -0.12322     -0.131904    -0.0163268
  0.0525614    0.073753     0.0427689     0.075632   -0.143245    -0.0246395     0.0991138     0.10237     -0.0083244    0.0830799   -0.0508019   -0.165248     0.12233     -0.124692    -0.0932796   -0.000776671   0.0244669   0.136732    0.109354    -0.0773003    0.0428376    0.0154828   -0.0888075   -0.110047     0.026285     0.0308785
  0.0366145   -0.122622    -0.0385962     0.0433289   0.0448479    0.000390402  -0.0686469     0.0362599   -0.044069    -0.00741552  -0.0933308    0.105786     0.0359392    0.0111349    0.0141874    0.0137392     0.0112607   0.0665463   0.0182325    0.0726107    0.0325164    0.105205     0.135596     0.0512995   -0.0303976    0.193574[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.068722
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     16
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.010224
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      8
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.970061
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     10
│     16
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.054986
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│     16
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.019678
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.974128
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      8
│     16
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.052816
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│      9
│     16
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.018241
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.963835
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     16
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062201
┌ Info: EM with 100000 data points 10 iterations avll -1.062201
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.178156    -0.0549087   -0.171287    -0.0979138    0.102059     0.0367071    -0.0413318    0.205092    -0.0780909   -0.030085     0.095248     0.118077     0.156232     0.0675809    0.0556421    0.174327    -0.0893546     0.220399     0.0218608     0.109878     0.159556      0.186158     0.0453822  -0.00250945   0.0682645     0.0704586
 -0.0883813    0.0712146    0.138879     0.0462562   -0.0415673    0.105773      0.115591    -0.0675343   -0.121435    -0.116625     0.0336675    0.0458468   -0.0606933    0.042107    -0.00251489   0.0310759    0.0566499     0.0778944    0.208107     -0.175801    -0.199016     -0.0821908   -0.0430196  -0.0652654   -0.0617844     0.0119827
 -0.00128921   0.0180606   -0.00415315   0.0997115   -0.0215354    0.00802683    0.0332973    0.130672     0.177443     0.201003     0.0572981    0.0277953    0.0917111    0.0283138   -0.0883       0.0468549    0.116288     -0.117186    -0.105361     -0.124564    -0.050726      0.0740048    0.10063     0.00671367  -0.0770734    -0.22386
  0.12738      0.107288     0.00446154  -0.00944496  -0.0364215    0.199569      0.170368    -0.0180399    0.0538031   -0.010112     0.0336434   -0.0338819   -0.106626    -0.0416321    0.0961885   -0.15751     -0.00976635   -0.0522326   -0.125046     -0.10886     -0.0814433    -0.038235     0.0901743  -0.0857593   -0.0165394     0.115739
  0.0912181   -0.0762176    0.0186252    0.0775971    0.0479485    0.0440733    -0.0536847   -0.136183    -0.0853247    0.0811738    0.0105587    0.178638     0.0546389    0.112616    -0.112311     0.00836116  -0.0104525    -0.175019     0.0453449    -0.108446     0.165348      0.130611    -0.0204762  -0.291228     0.0540093     0.0256794
  0.108111    -0.100456    -0.231346    -0.200172     0.0852477    0.161012      0.0688829    0.101471    -0.0859209    0.115201    -0.0274608    0.0655847    0.13827      0.070387    -0.0255692   -0.103829     0.00367374    0.0649012    0.112561      0.0896837    0.0362635     0.0251029    0.113942   -0.0736955   -0.0573499    -0.131933
 -0.0619695   -0.0195956   -0.100474     0.0887615   -0.031578    -8.17354e-5    0.219011    -0.0955395   -0.0650386   -0.0546667   -0.0418465   -0.00956578  -0.152563     0.00223094  -0.0980265    0.0363364   -0.00318514   -0.052822     0.00303199   -0.187606     0.0257649    -0.0108725    0.043746    0.207653    -0.0206759     0.0638979
 -0.0847114    0.00664185   0.0613135   -0.073115    -0.0319739   -0.00597937    0.00296974  -0.120596    -0.0939927    0.0833886    0.0170109   -0.0379201    0.0861593   -0.0960576   -0.0882895    0.00371593  -0.00880402    0.109548    -0.118073     -0.0413971   -0.0824207    -0.0198901   -0.0482233  -0.161627     0.0243439    -0.0750031
 -0.0316775   -0.138884     0.10598     -0.0521569   -0.106843     0.0569015     0.114592    -0.0104156   -0.107962    -0.311491     0.0762724   -0.0359534   -0.252782    -0.015949     0.0821944    0.17948     -0.0880319    -0.0187018   -0.00297515   -0.0965315   -0.165759     -0.0139453    0.0795592   0.0286937   -0.037721     -0.0325218
 -0.0942951   -0.00529166   0.0262086   -0.0103966   -0.0846289   -0.0998736     0.016115    -0.0704525    0.0337457    0.11715      0.103116    -0.0243267   -0.0651983   -0.0941294    0.081792     0.00649278   0.205414      0.0419442    0.100814     -0.0635096   -0.0486664    -0.0207048   -0.0798246   0.0718344   -0.0189334     0.191977
  0.130065    -0.0246317    0.132084     0.0855756    0.0715613    0.0907502    -0.0289077    0.0949657    0.0299823    0.0218159   -0.0495121    0.0644772    0.0844598   -0.0253075   -0.00467788  -0.0363866   -0.0514225    -0.0484401    0.0678144     0.0238952   -0.000513802  -0.00291723   0.0210849   0.146239    -0.0634225     0.0458823
 -0.134215    -0.0696723    0.0586149    0.10284     -0.0620249    0.0565024     0.0451639   -0.032941    -0.0519135   -0.227305     0.167126     0.123271     0.100033    -0.0664223    0.0854715    0.144226     0.0421778     0.128969     0.0309038    -0.00466527   0.0812851    -0.179861    -0.0105539   0.01346     -0.000626337   0.0381723
  0.15583      0.0437142   -0.00437791   0.0615294    0.0754474    0.0361141     0.0915075   -0.0595698   -0.0109057   -0.170385    -0.0484319    0.00128923   0.019278     0.146375     0.117125    -0.00241378   0.0903801    -0.0258685    0.0274862     0.0542913   -0.0666115    -0.0541818   -0.0416569  -0.22348      0.134751     -0.0417146
  0.0691318   -0.00269238  -0.120599    -0.0050465   -0.0590342    0.127901     -0.0317999   -0.103763    -0.120479    -0.0878554   -0.123026     0.0206575    0.0591995   -0.0667125   -0.0708892   -0.116893     0.0452374    -0.00169082  -0.111052     -0.121203     0.0922613     0.0769234   -0.0671935  -0.0548875    0.0884686     0.023013
 -0.0881141    0.0840693    0.111509     0.0507486    0.0767825    0.105838     -0.143709     0.086776    -0.12267     -0.0285552   -0.086005    -0.0109821   -0.194217    -0.0184723   -0.0366855   -0.09471      0.163755     -0.0281063   -0.0159514    -0.0542266   -0.0462563     0.0980708   -0.137383    0.00497881  -0.197126     -0.0713023
 -0.0657985   -0.0336868   -0.0690827   -0.0854091    0.094391    -0.101339     -0.147271    -0.116019     0.0404759    0.049278    -0.124826     0.0616104   -0.21304     -0.147749     0.0668289    0.186351     0.0602171    -0.0258025    0.0444804     0.0622995    0.0189205     0.0523335   -0.0679588   0.0695143   -0.0882817     0.0271694
  0.0187525   -0.0636014   -0.182623     0.0407287    0.0403615   -0.0775239    -0.0882666    0.0644606    0.17964      0.093665     0.161289     0.200228     0.0185478    0.10042      0.00906774  -0.115137     0.0598541    -0.0469778    0.00807677    0.118433    -0.116788     -0.0568208   -0.0423866  -0.0838067    0.0223064    -0.0457872
  0.0598627   -0.0860268   -0.0632216    0.157122    -0.034379     0.000993546  -0.0195091   -0.0752421    0.0917035    0.121758    -0.0426454   -0.032352    -0.12145      0.162148    -0.100114     0.103499    -0.0974631     0.105404    -0.000540341   0.0149918   -0.0596668     0.202456    -0.151859    0.0189685    0.0427853    -0.0304404
 -0.0489059   -0.0546351   -0.0837576   -0.133681    -0.0198173   -0.00359412    0.0581936   -0.159121     0.0422516   -0.108112     0.0696568   -0.117637     0.0580453   -0.154004    -0.101443     0.0109269    0.0741879     0.0640089   -0.0588156    -0.00153302  -0.0254788    -0.170212    -0.0285966   0.0404055   -0.0936493    -0.126171
 -0.0617363    0.138104     0.0309956    0.156069    -0.034684    -0.137789     -0.114726    -0.183411     0.0199027    0.0091455   -0.126154     0.0511846   -0.0104589    0.100257    -0.025344     0.170342    -0.279525      0.0972718   -0.129378      0.0706368    0.0140577     0.0331962   -0.100481   -0.00565416   0.070957      0.0150291
  0.164701    -0.207521     0.0089349   -0.0356666   -0.00229798   0.0634999    -0.175994    -0.0602158    0.0377881    0.0932951    0.025934    -0.0415637    0.134776    -0.0138428   -0.0903692    0.0594157   -0.160508     -0.14248     -0.219857     -0.0346066   -0.0263099     0.0412874   -0.143752    0.00791935  -0.0814253    -0.00193852
  0.0285851    0.219312     0.0641865    0.0160257   -0.0187502   -0.0201563     0.0139785    0.144896    -0.0535214    0.170319    -0.0332849    0.0610826   -0.101495    -0.0539832   -0.138933    -0.11072      0.0546101    -0.325005    -0.0331666    -0.0633429    0.00877532    0.0156512    0.0358815   0.0972204   -0.110318      0.0375321
  0.0709441   -0.17221     -0.169528    -0.257115    -0.0923311   -0.0293192     0.00677986   0.122739    -0.0969652    0.0847315   -0.00724125  -0.0773624    0.178973     0.012834     0.0675291    0.151501     0.000950293  -0.0527209    0.0744856     0.0758587    0.0468422    -0.0485349   -0.199783    0.0492027    0.00434294    0.125843
 -0.0744539    0.023813    -0.0357899    0.00102877  -0.0861332    0.202074     -0.220846     0.173315    -0.00620302   0.00592621   0.0886317    0.0735772    0.251461     0.0348526   -0.0782557   -0.370507     0.0121675     0.152784     0.0442477    -0.0812594    0.261359     -0.00455085   0.189933   -0.139912     0.0693649     0.0381311
 -0.0764649   -0.23993      0.190714     0.0428018   -0.174329     0.26941       0.123247    -0.0880183   -0.195966    -0.0812444   -0.208227     0.161528     0.130063    -0.0238376   -0.0727903   -0.0285506    0.085378      0.0523943    0.0728087     0.00212258   0.0593056     0.00333224   0.174751   -0.204896     0.00362407   -0.0933836
  0.00382999  -0.0419328   -0.0642641    0.0846675    0.0264051   -0.0935009    -0.00172463   0.0968034    0.0434647   -0.0689656    0.0256482   -0.130097    -0.0889805    0.0891644    0.11232     -0.0579989   -0.0782267    -0.0183424   -0.12587      -0.124455     0.0338806    -0.104905    -0.19654     0.00872505  -0.109963      0.0849838
  0.0843077   -0.0842099   -0.0454931   -0.0443256    0.0249762   -0.0987251     0.0155372    0.252291     0.0441652   -0.125523    -0.0154595    0.0264245    0.125377     0.0108737    0.110818    -0.0625645   -0.0785972     0.0264328   -0.0392539     0.215159     0.0272065     0.107838     0.0600751   0.104137    -0.0728542     0.0894088
  0.0726495   -0.286966    -0.291349    -0.0427458   -0.0413067   -0.122625      0.0288526   -0.0255191   -0.0492786   -0.0955322    0.0303311    0.0692912    0.00149203  -0.0608556    0.179093     0.0733208   -0.145262      0.124809     0.00680529   -0.174287    -0.071529     -0.0568318   -0.201054   -0.0376675    0.00280609   -0.10853
 -0.0673025    0.196693     0.0493035    0.00215052   0.0346716   -0.0777674    -0.136181    -0.0223422    0.00735083  -0.00189017   0.167606    -0.0325157    0.0836539    0.167495     0.0524491   -0.12588     -0.0862283    -0.113118    -0.0424094    -0.201076     0.0889769    -0.139145     0.182947   -0.0879026   -0.103655      0.0800425
  0.0638954   -0.053122     0.013646    -0.0113043   -0.120872     0.0331554     0.259487    -0.0627198   -0.221181     0.114052    -0.0453391    0.0944097   -0.124271    -0.040678    -0.106933     0.0994824   -0.028323     -0.145324     0.00183201    0.00729713   0.241408     -0.0148432    0.09279     0.0561986    0.120993     -0.0978774
 -0.0494349   -0.0393215   -0.151329    -0.0071838   -0.0998916    0.133068      0.065419     0.0657964    0.118552     0.0321057   -0.0716793    0.0265248   -0.0549108   -0.107039     0.0828629    0.294882    -0.123303     -0.00569402   0.0981586     0.115331     0.0332991    -0.180703     0.0433277   0.0467479   -0.0168871    -0.0994404
  0.0240268    0.00560013  -0.178639    -0.0369564    0.0876761    0.165798      0.00885391   0.00519622  -0.00383563  -0.182052    -0.0407684   -0.211076     0.0773577   -0.0751144    0.096099     0.147007     0.067799      0.0567806   -0.0366427     0.0237019    0.242817      0.178258     0.0405161   0.0829397    0.0447687    -0.0299668kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4282820226500141
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428302
[ Info: iteration 2, average log likelihood -1.428229
[ Info: iteration 3, average log likelihood -1.428172
[ Info: iteration 4, average log likelihood -1.428106
[ Info: iteration 5, average log likelihood -1.428025
[ Info: iteration 6, average log likelihood -1.427930
[ Info: iteration 7, average log likelihood -1.427826
[ Info: iteration 8, average log likelihood -1.427722
[ Info: iteration 9, average log likelihood -1.427623
[ Info: iteration 10, average log likelihood -1.427525
[ Info: iteration 11, average log likelihood -1.427406
[ Info: iteration 12, average log likelihood -1.427225
[ Info: iteration 13, average log likelihood -1.426914
[ Info: iteration 14, average log likelihood -1.426386
[ Info: iteration 15, average log likelihood -1.425596
[ Info: iteration 16, average log likelihood -1.424667
[ Info: iteration 17, average log likelihood -1.423868
[ Info: iteration 18, average log likelihood -1.423362
[ Info: iteration 19, average log likelihood -1.423105
[ Info: iteration 20, average log likelihood -1.422988
[ Info: iteration 21, average log likelihood -1.422936
[ Info: iteration 22, average log likelihood -1.422914
[ Info: iteration 23, average log likelihood -1.422903
[ Info: iteration 24, average log likelihood -1.422898
[ Info: iteration 25, average log likelihood -1.422896
[ Info: iteration 26, average log likelihood -1.422894
[ Info: iteration 27, average log likelihood -1.422893
[ Info: iteration 28, average log likelihood -1.422892
[ Info: iteration 29, average log likelihood -1.422891
[ Info: iteration 30, average log likelihood -1.422891
[ Info: iteration 31, average log likelihood -1.422890
[ Info: iteration 32, average log likelihood -1.422890
[ Info: iteration 33, average log likelihood -1.422889
[ Info: iteration 34, average log likelihood -1.422889
[ Info: iteration 35, average log likelihood -1.422889
[ Info: iteration 36, average log likelihood -1.422888
[ Info: iteration 37, average log likelihood -1.422888
[ Info: iteration 38, average log likelihood -1.422888
[ Info: iteration 39, average log likelihood -1.422888
[ Info: iteration 40, average log likelihood -1.422888
[ Info: iteration 41, average log likelihood -1.422887
[ Info: iteration 42, average log likelihood -1.422887
[ Info: iteration 43, average log likelihood -1.422887
[ Info: iteration 44, average log likelihood -1.422887
[ Info: iteration 45, average log likelihood -1.422887
[ Info: iteration 46, average log likelihood -1.422887
[ Info: iteration 47, average log likelihood -1.422887
[ Info: iteration 48, average log likelihood -1.422887
[ Info: iteration 49, average log likelihood -1.422887
[ Info: iteration 50, average log likelihood -1.422886
┌ Info: EM with 100000 data points 50 iterations avll -1.422886
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4283018974027002
│     -1.4282286713866728
│      ⋮
└     -1.422886485895482
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422906
[ Info: iteration 2, average log likelihood -1.422831
[ Info: iteration 3, average log likelihood -1.422772
[ Info: iteration 4, average log likelihood -1.422701
[ Info: iteration 5, average log likelihood -1.422613
[ Info: iteration 6, average log likelihood -1.422512
[ Info: iteration 7, average log likelihood -1.422406
[ Info: iteration 8, average log likelihood -1.422309
[ Info: iteration 9, average log likelihood -1.422230
[ Info: iteration 10, average log likelihood -1.422170
[ Info: iteration 11, average log likelihood -1.422127
[ Info: iteration 12, average log likelihood -1.422093
[ Info: iteration 13, average log likelihood -1.422064
[ Info: iteration 14, average log likelihood -1.422039
[ Info: iteration 15, average log likelihood -1.422016
[ Info: iteration 16, average log likelihood -1.421994
[ Info: iteration 17, average log likelihood -1.421974
[ Info: iteration 18, average log likelihood -1.421955
[ Info: iteration 19, average log likelihood -1.421936
[ Info: iteration 20, average log likelihood -1.421919
[ Info: iteration 21, average log likelihood -1.421903
[ Info: iteration 22, average log likelihood -1.421888
[ Info: iteration 23, average log likelihood -1.421873
[ Info: iteration 24, average log likelihood -1.421859
[ Info: iteration 25, average log likelihood -1.421844
[ Info: iteration 26, average log likelihood -1.421830
[ Info: iteration 27, average log likelihood -1.421816
[ Info: iteration 28, average log likelihood -1.421801
[ Info: iteration 29, average log likelihood -1.421785
[ Info: iteration 30, average log likelihood -1.421769
[ Info: iteration 31, average log likelihood -1.421753
[ Info: iteration 32, average log likelihood -1.421735
[ Info: iteration 33, average log likelihood -1.421718
[ Info: iteration 34, average log likelihood -1.421700
[ Info: iteration 35, average log likelihood -1.421683
[ Info: iteration 36, average log likelihood -1.421666
[ Info: iteration 37, average log likelihood -1.421650
[ Info: iteration 38, average log likelihood -1.421636
[ Info: iteration 39, average log likelihood -1.421623
[ Info: iteration 40, average log likelihood -1.421611
[ Info: iteration 41, average log likelihood -1.421602
[ Info: iteration 42, average log likelihood -1.421593
[ Info: iteration 43, average log likelihood -1.421587
[ Info: iteration 44, average log likelihood -1.421581
[ Info: iteration 45, average log likelihood -1.421576
[ Info: iteration 46, average log likelihood -1.421573
[ Info: iteration 47, average log likelihood -1.421570
[ Info: iteration 48, average log likelihood -1.421568
[ Info: iteration 49, average log likelihood -1.421566
[ Info: iteration 50, average log likelihood -1.421564
┌ Info: EM with 100000 data points 50 iterations avll -1.421564
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4229061912848728
│     -1.422830860065508
│      ⋮
└     -1.4215642084753242
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421575
[ Info: iteration 2, average log likelihood -1.421511
[ Info: iteration 3, average log likelihood -1.421456
[ Info: iteration 4, average log likelihood -1.421392
[ Info: iteration 5, average log likelihood -1.421315
[ Info: iteration 6, average log likelihood -1.421225
[ Info: iteration 7, average log likelihood -1.421124
[ Info: iteration 8, average log likelihood -1.421020
[ Info: iteration 9, average log likelihood -1.420918
[ Info: iteration 10, average log likelihood -1.420826
[ Info: iteration 11, average log likelihood -1.420746
[ Info: iteration 12, average log likelihood -1.420677
[ Info: iteration 13, average log likelihood -1.420619
[ Info: iteration 14, average log likelihood -1.420570
[ Info: iteration 15, average log likelihood -1.420528
[ Info: iteration 16, average log likelihood -1.420493
[ Info: iteration 17, average log likelihood -1.420463
[ Info: iteration 18, average log likelihood -1.420438
[ Info: iteration 19, average log likelihood -1.420415
[ Info: iteration 20, average log likelihood -1.420396
[ Info: iteration 21, average log likelihood -1.420378
[ Info: iteration 22, average log likelihood -1.420362
[ Info: iteration 23, average log likelihood -1.420347
[ Info: iteration 24, average log likelihood -1.420334
[ Info: iteration 25, average log likelihood -1.420321
[ Info: iteration 26, average log likelihood -1.420309
[ Info: iteration 27, average log likelihood -1.420298
[ Info: iteration 28, average log likelihood -1.420288
[ Info: iteration 29, average log likelihood -1.420278
[ Info: iteration 30, average log likelihood -1.420268
[ Info: iteration 31, average log likelihood -1.420259
[ Info: iteration 32, average log likelihood -1.420250
[ Info: iteration 33, average log likelihood -1.420242
[ Info: iteration 34, average log likelihood -1.420234
[ Info: iteration 35, average log likelihood -1.420226
[ Info: iteration 36, average log likelihood -1.420218
[ Info: iteration 37, average log likelihood -1.420211
[ Info: iteration 38, average log likelihood -1.420203
[ Info: iteration 39, average log likelihood -1.420196
[ Info: iteration 40, average log likelihood -1.420189
[ Info: iteration 41, average log likelihood -1.420182
[ Info: iteration 42, average log likelihood -1.420175
[ Info: iteration 43, average log likelihood -1.420168
[ Info: iteration 44, average log likelihood -1.420161
[ Info: iteration 45, average log likelihood -1.420155
[ Info: iteration 46, average log likelihood -1.420148
[ Info: iteration 47, average log likelihood -1.420141
[ Info: iteration 48, average log likelihood -1.420135
[ Info: iteration 49, average log likelihood -1.420128
[ Info: iteration 50, average log likelihood -1.420121
┌ Info: EM with 100000 data points 50 iterations avll -1.420121
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4215746462675325
│     -1.421511466265471
│      ⋮
└     -1.4201214408952019
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420124
[ Info: iteration 2, average log likelihood -1.420059
[ Info: iteration 3, average log likelihood -1.420000
[ Info: iteration 4, average log likelihood -1.419933
[ Info: iteration 5, average log likelihood -1.419850
[ Info: iteration 6, average log likelihood -1.419751
[ Info: iteration 7, average log likelihood -1.419634
[ Info: iteration 8, average log likelihood -1.419506
[ Info: iteration 9, average log likelihood -1.419375
[ Info: iteration 10, average log likelihood -1.419248
[ Info: iteration 11, average log likelihood -1.419132
[ Info: iteration 12, average log likelihood -1.419030
[ Info: iteration 13, average log likelihood -1.418942
[ Info: iteration 14, average log likelihood -1.418866
[ Info: iteration 15, average log likelihood -1.418801
[ Info: iteration 16, average log likelihood -1.418744
[ Info: iteration 17, average log likelihood -1.418695
[ Info: iteration 18, average log likelihood -1.418652
[ Info: iteration 19, average log likelihood -1.418613
[ Info: iteration 20, average log likelihood -1.418579
[ Info: iteration 21, average log likelihood -1.418547
[ Info: iteration 22, average log likelihood -1.418518
[ Info: iteration 23, average log likelihood -1.418491
[ Info: iteration 24, average log likelihood -1.418466
[ Info: iteration 25, average log likelihood -1.418442
[ Info: iteration 26, average log likelihood -1.418419
[ Info: iteration 27, average log likelihood -1.418397
[ Info: iteration 28, average log likelihood -1.418376
[ Info: iteration 29, average log likelihood -1.418355
[ Info: iteration 30, average log likelihood -1.418335
[ Info: iteration 31, average log likelihood -1.418316
[ Info: iteration 32, average log likelihood -1.418296
[ Info: iteration 33, average log likelihood -1.418278
[ Info: iteration 34, average log likelihood -1.418259
[ Info: iteration 35, average log likelihood -1.418242
[ Info: iteration 36, average log likelihood -1.418224
[ Info: iteration 37, average log likelihood -1.418207
[ Info: iteration 38, average log likelihood -1.418191
[ Info: iteration 39, average log likelihood -1.418175
[ Info: iteration 40, average log likelihood -1.418159
[ Info: iteration 41, average log likelihood -1.418144
[ Info: iteration 42, average log likelihood -1.418129
[ Info: iteration 43, average log likelihood -1.418114
[ Info: iteration 44, average log likelihood -1.418100
[ Info: iteration 45, average log likelihood -1.418087
[ Info: iteration 46, average log likelihood -1.418073
[ Info: iteration 47, average log likelihood -1.418061
[ Info: iteration 48, average log likelihood -1.418048
[ Info: iteration 49, average log likelihood -1.418036
[ Info: iteration 50, average log likelihood -1.418024
┌ Info: EM with 100000 data points 50 iterations avll -1.418024
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420124104522282
│     -1.4200593649221536
│      ⋮
└     -1.4180239319621912
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418020
[ Info: iteration 2, average log likelihood -1.417947
[ Info: iteration 3, average log likelihood -1.417875
[ Info: iteration 4, average log likelihood -1.417791
[ Info: iteration 5, average log likelihood -1.417687
[ Info: iteration 6, average log likelihood -1.417559
[ Info: iteration 7, average log likelihood -1.417408
[ Info: iteration 8, average log likelihood -1.417241
[ Info: iteration 9, average log likelihood -1.417068
[ Info: iteration 10, average log likelihood -1.416899
[ Info: iteration 11, average log likelihood -1.416739
[ Info: iteration 12, average log likelihood -1.416594
[ Info: iteration 13, average log likelihood -1.416463
[ Info: iteration 14, average log likelihood -1.416347
[ Info: iteration 15, average log likelihood -1.416245
[ Info: iteration 16, average log likelihood -1.416155
[ Info: iteration 17, average log likelihood -1.416075
[ Info: iteration 18, average log likelihood -1.416006
[ Info: iteration 19, average log likelihood -1.415944
[ Info: iteration 20, average log likelihood -1.415889
[ Info: iteration 21, average log likelihood -1.415840
[ Info: iteration 22, average log likelihood -1.415796
[ Info: iteration 23, average log likelihood -1.415756
[ Info: iteration 24, average log likelihood -1.415719
[ Info: iteration 25, average log likelihood -1.415686
[ Info: iteration 26, average log likelihood -1.415655
[ Info: iteration 27, average log likelihood -1.415626
[ Info: iteration 28, average log likelihood -1.415598
[ Info: iteration 29, average log likelihood -1.415573
[ Info: iteration 30, average log likelihood -1.415549
[ Info: iteration 31, average log likelihood -1.415526
[ Info: iteration 32, average log likelihood -1.415504
[ Info: iteration 33, average log likelihood -1.415483
[ Info: iteration 34, average log likelihood -1.415463
[ Info: iteration 35, average log likelihood -1.415444
[ Info: iteration 36, average log likelihood -1.415426
[ Info: iteration 37, average log likelihood -1.415408
[ Info: iteration 38, average log likelihood -1.415390
[ Info: iteration 39, average log likelihood -1.415374
[ Info: iteration 40, average log likelihood -1.415357
[ Info: iteration 41, average log likelihood -1.415341
[ Info: iteration 42, average log likelihood -1.415326
[ Info: iteration 43, average log likelihood -1.415311
[ Info: iteration 44, average log likelihood -1.415296
[ Info: iteration 45, average log likelihood -1.415281
[ Info: iteration 46, average log likelihood -1.415268
[ Info: iteration 47, average log likelihood -1.415254
[ Info: iteration 48, average log likelihood -1.415241
[ Info: iteration 49, average log likelihood -1.415228
[ Info: iteration 50, average log likelihood -1.415216
┌ Info: EM with 100000 data points 50 iterations avll -1.415216
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180202549331693
│     -1.417946595906292
│      ⋮
└     -1.4152156382845862
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4282820226500141
│     -1.4283018974027002
│     -1.4282286713866728
│     -1.4281722951602465
│      ⋮
│     -1.4152408206198526
│     -1.4152280360812541
└     -1.4152156382845862
32×26 Array{Float64,2}:
  0.164726    -0.28864      -0.290342    -0.0927214    0.126448    0.588645    0.438277   -0.00841089  -0.527927   -0.498518   -0.26812    -0.164517   -0.0862977    0.141182     0.00936077  -0.981334     0.125582     0.0787315     0.282049    -0.204665    0.199041    -0.145814   -0.626734    -0.184299    0.315788    0.0702493
 -0.0617319    0.261844     -0.00607755   0.12205      0.255194    0.393057   -0.0493835  -0.0811761   -0.619292    0.892353   -0.717758   -0.171413   -0.0582958   -0.480595    -0.1891      -0.503914    -0.531036     0.173546     -0.106364     0.0416828  -0.187871     0.0688833   0.124287    -0.150903    0.326919   -0.600499
  0.0984951    0.000807627  -0.254876    -0.841054     0.164971    0.236497   -0.075476   -0.11386      0.745453   -0.233177    0.121594   -0.217461    0.490478    -0.422159    -0.313057     0.0261903   -0.129602     0.277403     -0.205444    -0.0724133  -0.0121062    0.68121    -0.66181     -0.554173    0.22468    -0.0617128
 -0.266567    -0.982329     -0.198144    -0.329698    -0.414729    0.712935   -0.315066    0.723121     0.40116    -0.089017   -0.0902896   0.200661    0.266547     0.116154    -0.0582771    0.314054    -0.608555    -0.0150424     0.325567     0.433255    0.00223461   1.01808     0.438226    -0.566377   -0.0668693   0.324699
 -0.247927     0.206193      0.266699    -0.326542     0.384485    0.398306    0.171142    0.567595    -0.113713   -0.0353918  -0.383486   -0.621377   -0.510432     0.0757401    0.752467     0.146726     0.165823    -0.0466478    -0.357751    -0.829974    0.49546     -0.0816524   0.357674     0.049381   -0.412902    0.116673
  0.470703    -0.362032     -0.992499    -0.9134      -0.10786    -0.113183   -0.0773238   0.149111    -0.346534    0.243298   -0.532283   -0.419227   -0.396397    -0.558624     0.39949      0.812676    -0.379522    -0.305768     -0.054283    -0.0153874   0.24122     -0.133336   -0.276561     0.0625253  -0.174174    0.531788
 -0.250567     0.0638505    -0.130353     0.313738     0.317214    0.23042    -0.999497    0.339257     0.04899    -0.301361   -0.72868     0.198068   -0.128556    -0.0654615    0.436087    -0.114587    -0.29656      0.303811     -0.132605    -0.323549    0.595989     0.0698417  -0.397984     1.01815     0.168666    0.0636641
 -0.00835433  -0.112084     -1.12066      0.451121     0.120017   -0.121498   -0.197676   -0.167001    -0.400181    0.494018   -0.805203    0.531341    0.00771342   0.0454149   -0.293612    -0.104656     0.759958     0.580461     -0.143861     0.205495    0.0443243   -0.587718   -0.223342     0.57742     0.206531    0.136608
 -0.472011    -0.00517541    0.543608    -0.463789     0.385789    0.343481    0.176891    0.229635     0.214248   -0.608511    0.102558    0.0300274  -0.645115    -0.667474    -0.40167      0.34094      0.0884593    0.185293     -0.203131     0.149637    0.145569    -0.0859268   0.571188    -0.0636182  -0.0558934  -0.73427
 -0.955662     0.39972       0.710091     0.515344     0.296743   -0.150878    0.236805   -0.214361     0.193846   -0.405609    0.56001     0.387071    0.238163     0.0388648   -0.39389     -0.473624     0.682562     0.0368461     0.0254125    0.266449    0.00692881  -0.224149    0.28465      0.0803322  -0.276321    0.216648
  0.400649     0.159717     -0.00624972   0.355636    -0.310377   -0.342691   -0.245847   -0.316718    -0.344449    0.0468834   0.225518    0.406371    0.0377739    0.0479943    0.207156     0.391279     0.189502    -0.148947      0.0671646    0.25243    -0.0409274   -0.178357    0.211665     0.277683   -0.0143342   0.0238423
 -0.624201    -0.328936      0.243479     0.24291     -0.453346   -0.0658558  -0.204812    0.212364     0.836786    0.0139952   0.044664    0.126742    0.197917    -0.0411084   -0.287831     0.807874    -0.286403     0.083535      0.149122    -0.367274   -0.308428     0.167358    0.254633    -0.138484   -0.112712   -0.369597
  0.982293     0.399221      0.147338    -0.237395     0.414165   -0.215146    0.257905    0.0327801    0.318568   -0.425962    0.958013    0.102808    0.284297     0.224732     0.434948    -0.117252    -0.329602     0.15884       0.152867     0.15362    -0.404224     0.461059   -0.0600193    0.41897    -0.154209    0.244699
  0.342345    -0.129449     -0.248362    -0.279602    -0.348924   -0.0529314   0.236159    0.0360166    0.575531   -0.979079    0.809852   -0.219748   -0.184497     0.578868     0.500031     0.58435      0.749153    -0.0671581     0.0235274   -0.235935    0.0406946   -0.403991   -0.239958     0.0931125  -0.450394    0.663744
 -0.0197012   -0.111032      0.437241    -0.28324      0.640436   -0.604157   -0.417651   -0.541714    -0.159744    0.267918    0.513969    0.463052   -0.24149      0.0970872   -0.57274      0.207252    -0.20049     -0.684025      0.00324332  -0.132533   -0.192686     0.172607   -0.184074     0.5558     -0.497411    0.0923608
  0.255152    -0.312789      0.091496    -0.00310545  -0.205813   -0.850614    0.394225   -0.235148     0.17376     0.501927    0.394239    0.258388    0.418268     0.094264    -0.620167     0.516808     0.152157    -0.285609      0.086121     0.371038   -0.00105923  -0.0181065   0.711215    -0.27743    -0.348899    0.435939
  0.0958256    0.329102      0.185819    -0.540395    -0.164506    0.127967    0.490979   -0.171846    -0.366634    0.0794781   0.23188    -0.444187   -0.0572938    0.309852    -0.368734    -0.27017      0.0600219   -0.0784114    -0.498271    -0.167829    0.0360859   -0.193458    0.296405    -1.0569     -0.230845   -0.0762246
  0.214002     0.277085     -0.383614    -0.761252     0.610794    0.016234    0.156853   -0.329835    -0.261503   -0.0120006   0.145488   -0.132018   -0.0570042   -0.097959    -0.363682    -0.500423    -0.0274691    0.367762     -0.223893     0.0526473   0.0154974    0.101425   -0.225061    -0.15882    -0.129648    0.18276
 -0.634794    -0.139199      0.0644049    0.518657     0.0132954  -0.235213    0.179231    0.0554786   -0.264964   -0.0705385  -0.62149     0.0767884  -0.144568     0.20695     -0.298693    -0.17736      0.0635288   -0.231594      0.208179    -0.378297    0.132294    -0.364623   -0.00771591  -0.165328   -0.362835    0.120594
 -0.181986    -0.01297      -0.215162    -0.399121     0.710533   -0.382001    0.23322     0.335818     0.851993   -0.0301527  -0.290386   -0.226849    0.209152    -0.0288705   -0.0256469   -0.0593721   -0.063402    -0.384878      0.169221    -0.372513    0.217854    -0.23371    -0.291248    -0.158531   -0.175172   -0.0817407
  0.044521    -0.253931     -0.655819    -0.315313    -0.0750155   0.235635   -0.0245777   0.268211    -0.173105   -0.0260993  -0.259485   -0.264605   -0.289998    -0.00647634   0.221538     0.0240589   -0.268709     0.0630861    -0.0959671   -0.0533607  -0.00621427  -0.513218   -0.291213     0.129677    0.247841    0.0626471
  0.072522    -0.0421589     0.00666835  -0.0127388   -0.0507682   0.572329    0.083851    0.14312     -0.110132    0.155073   -0.291845   -0.375594   -0.00879376  -0.174497     0.307025     0.0492537    0.07922     -0.0337403     0.24545     -0.705942    0.174591     0.408388   -0.248962    -0.0050248   0.137869   -0.0188838
  0.331138     0.499033      0.0158633    0.0208423   -0.210441   -0.117658   -0.573552   -0.0261566    0.0854536   0.176529    0.20068     0.0763615  -0.0377656   -0.147788     0.381897     0.626415    -0.206675    -0.000886033  -0.506017     0.375691   -0.334631     0.162469    0.233056     0.134006    0.034953   -0.0830847
  0.193583     0.171868     -0.00593688  -0.336003     0.24015    -0.111706   -0.28213     0.38101     -0.0145982  -0.111015   -0.312076    0.0299653   0.0143981   -0.356996     0.478852     0.108892     0.386528     0.0997471    -0.483478     0.401499    1.06167     -0.257556    0.295682    -0.203088   -0.0803159   0.164794
 -0.143215     0.154318      0.14844      0.410446    -0.238263    0.428487   -0.18745    -0.379803     0.0324337  -0.410557    0.298817   -0.100611   -0.273224     0.25756     -0.14071     -0.475971    -0.227373     0.207924     -0.0229238   -0.0298814  -0.562884     0.0358241  -0.484902    -0.115524    0.572143   -0.854253
  0.0570885   -0.431004      0.0571138    0.282262    -0.660892    0.170518   -0.180933   -0.682522    -0.0973443  -0.187842    0.208811    0.420064    0.0931324   -0.352465    -0.118921     0.634445    -0.0665154   -0.225703      0.264297     0.0231597   0.0411578    0.153883   -0.292996     0.0211341   0.1442     -0.480106
  0.0215364   -0.000582378  -0.00667626   0.0485278   -0.14332    -0.151514    0.109655   -0.124459    -0.0627543   0.163176   -0.024932    0.0258786   0.131075     0.108669    -0.134063     0.0221553    0.021183    -0.0662997    -0.113999     0.0208169   0.0428403   -0.014244    0.0690829   -0.237084   -0.103512    0.0154925
 -0.0576458   -0.125412      0.179629     0.0575048    0.229248    0.0284327  -0.0835684   0.021349     0.153382   -0.237342    0.230407    0.261016    0.0623687   -0.0967699   -0.052766     0.138261     0.00910477   0.0681995     0.183743     0.0792692   0.00280413   0.203964   -0.0119848    0.291777   -0.0166461   0.0291204
  0.134738     0.155335     -0.416135     0.729373    -0.976262    0.219139    0.33753     0.512591     0.0676379  -0.18504    -0.427563   -0.428935   -0.001719     0.492705     0.661601     0.00251708  -0.100012     0.0037625    -0.198556     0.519563   -0.567389    -0.0403326   0.0834473   -0.427162    0.275842    0.332157
 -0.0452055   -0.0186992     0.244982     0.927623    -0.469114   -0.296427    0.152309    0.524351     0.0298858   0.0485543   0.057452    0.357861   -0.0165998    0.372773     0.299815    -0.01715     -0.0500322    0.110525      0.0352563    0.0643735  -0.213737    -0.65683     0.604017     0.697209    0.423559   -0.248227
  0.321948    -0.535212     -0.0621532    0.437584    -0.452484    0.720453    0.18881     0.00753313  -0.312603    0.163714    0.661169    0.477897    0.433618     0.12177     -0.138799    -0.535251     0.223214     0.162873      0.416987     0.282991   -0.187285     0.366742    0.441762    -0.22561     0.0656439   0.101003
  0.348177    -0.258895     -0.229004     0.473789    -0.51306    -0.151539    0.164596   -0.339822    -0.398709    0.704233   -0.113027   -0.145257    0.564672     0.582085     0.338067    -0.245371     0.00128807  -0.247776      0.528769    -0.387636   -0.0283164    0.157019   -0.380699    -0.0558321  -0.103745    0.421955[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415204
[ Info: iteration 2, average log likelihood -1.415192
[ Info: iteration 3, average log likelihood -1.415181
[ Info: iteration 4, average log likelihood -1.415170
[ Info: iteration 5, average log likelihood -1.415159
[ Info: iteration 6, average log likelihood -1.415149
[ Info: iteration 7, average log likelihood -1.415139
[ Info: iteration 8, average log likelihood -1.415130
[ Info: iteration 9, average log likelihood -1.415121
[ Info: iteration 10, average log likelihood -1.415112
┌ Info: EM with 100000 data points 10 iterations avll -1.415112
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.243121e+05
      1       7.133411e+05      -2.109710e+05 |       32
      2       6.991846e+05      -1.415652e+04 |       32
      3       6.936245e+05      -5.560123e+03 |       32
      4       6.907066e+05      -2.917896e+03 |       32
      5       6.888592e+05      -1.847426e+03 |       32
      6       6.875229e+05      -1.336229e+03 |       32
      7       6.865020e+05      -1.020946e+03 |       32
      8       6.856682e+05      -8.337633e+02 |       32
      9       6.849630e+05      -7.051749e+02 |       32
     10       6.843691e+05      -5.939116e+02 |       32
     11       6.838693e+05      -4.998109e+02 |       32
     12       6.834634e+05      -4.059541e+02 |       32
     13       6.831065e+05      -3.568670e+02 |       32
     14       6.828109e+05      -2.956067e+02 |       32
     15       6.825310e+05      -2.799064e+02 |       32
     16       6.822427e+05      -2.882931e+02 |       32
     17       6.819741e+05      -2.686357e+02 |       32
     18       6.817354e+05      -2.386672e+02 |       32
     19       6.815129e+05      -2.225045e+02 |       32
     20       6.813169e+05      -1.960110e+02 |       32
     21       6.811289e+05      -1.879551e+02 |       32
     22       6.809638e+05      -1.651431e+02 |       32
     23       6.808217e+05      -1.420972e+02 |       32
     24       6.806892e+05      -1.324849e+02 |       32
     25       6.805651e+05      -1.241167e+02 |       32
     26       6.804366e+05      -1.285158e+02 |       32
     27       6.803119e+05      -1.246715e+02 |       32
     28       6.802040e+05      -1.078826e+02 |       32
     29       6.801002e+05      -1.038139e+02 |       32
     30       6.800140e+05      -8.621285e+01 |       32
     31       6.799343e+05      -7.964565e+01 |       32
     32       6.798688e+05      -6.550461e+01 |       32
     33       6.798107e+05      -5.816579e+01 |       32
     34       6.797516e+05      -5.906575e+01 |       32
     35       6.796887e+05      -6.287619e+01 |       32
     36       6.796266e+05      -6.213231e+01 |       32
     37       6.795680e+05      -5.856037e+01 |       32
     38       6.795113e+05      -5.671430e+01 |       32
     39       6.794544e+05      -5.695170e+01 |       32
     40       6.793988e+05      -5.553046e+01 |       32
     41       6.793459e+05      -5.289499e+01 |       32
     42       6.792866e+05      -5.929565e+01 |       32
     43       6.792243e+05      -6.229945e+01 |       32
     44       6.791688e+05      -5.552523e+01 |       32
     45       6.791179e+05      -5.096289e+01 |       32
     46       6.790688e+05      -4.904425e+01 |       32
     47       6.790240e+05      -4.482935e+01 |       32
     48       6.789778e+05      -4.616799e+01 |       32
     49       6.789309e+05      -4.688581e+01 |       32
     50       6.788835e+05      -4.743278e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678883.4966674612)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426867
[ Info: iteration 2, average log likelihood -1.421888
[ Info: iteration 3, average log likelihood -1.420575
[ Info: iteration 4, average log likelihood -1.419630
[ Info: iteration 5, average log likelihood -1.418653
[ Info: iteration 6, average log likelihood -1.417740
[ Info: iteration 7, average log likelihood -1.417085
[ Info: iteration 8, average log likelihood -1.416704
[ Info: iteration 9, average log likelihood -1.416492
[ Info: iteration 10, average log likelihood -1.416362
[ Info: iteration 11, average log likelihood -1.416271
[ Info: iteration 12, average log likelihood -1.416199
[ Info: iteration 13, average log likelihood -1.416140
[ Info: iteration 14, average log likelihood -1.416089
[ Info: iteration 15, average log likelihood -1.416043
[ Info: iteration 16, average log likelihood -1.416001
[ Info: iteration 17, average log likelihood -1.415962
[ Info: iteration 18, average log likelihood -1.415926
[ Info: iteration 19, average log likelihood -1.415892
[ Info: iteration 20, average log likelihood -1.415860
[ Info: iteration 21, average log likelihood -1.415829
[ Info: iteration 22, average log likelihood -1.415799
[ Info: iteration 23, average log likelihood -1.415771
[ Info: iteration 24, average log likelihood -1.415743
[ Info: iteration 25, average log likelihood -1.415716
[ Info: iteration 26, average log likelihood -1.415690
[ Info: iteration 27, average log likelihood -1.415664
[ Info: iteration 28, average log likelihood -1.415640
[ Info: iteration 29, average log likelihood -1.415616
[ Info: iteration 30, average log likelihood -1.415593
[ Info: iteration 31, average log likelihood -1.415570
[ Info: iteration 32, average log likelihood -1.415549
[ Info: iteration 33, average log likelihood -1.415528
[ Info: iteration 34, average log likelihood -1.415508
[ Info: iteration 35, average log likelihood -1.415489
[ Info: iteration 36, average log likelihood -1.415470
[ Info: iteration 37, average log likelihood -1.415452
[ Info: iteration 38, average log likelihood -1.415435
[ Info: iteration 39, average log likelihood -1.415418
[ Info: iteration 40, average log likelihood -1.415402
[ Info: iteration 41, average log likelihood -1.415386
[ Info: iteration 42, average log likelihood -1.415371
[ Info: iteration 43, average log likelihood -1.415357
[ Info: iteration 44, average log likelihood -1.415342
[ Info: iteration 45, average log likelihood -1.415329
[ Info: iteration 46, average log likelihood -1.415315
[ Info: iteration 47, average log likelihood -1.415302
[ Info: iteration 48, average log likelihood -1.415289
[ Info: iteration 49, average log likelihood -1.415277
[ Info: iteration 50, average log likelihood -1.415265
┌ Info: EM with 100000 data points 50 iterations avll -1.415265
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0595328   0.0421988   -0.0360762  -0.2955       0.501711    0.234384     0.179744     0.969126    -0.0573908    0.259875    -0.64717    -0.43835     -0.388795    -0.0529483    0.874134    0.134976     0.0409984   0.0868536   -0.233554    -0.66808      0.398909    -0.181839     0.305723    0.247812   -0.280195     0.119437
  0.358542    0.184075    -0.10384    -0.42778     -0.201999    0.344721    -0.0883534   -0.611536    -0.228791     0.255811     0.666073    0.0681053    0.448919    -0.316104    -0.195038    0.0247314    0.116072    0.077429     0.269704     0.321972     0.116842     0.751741     0.135594   -0.561911   -0.298989    -0.0302257
  0.701419    0.0199635   -0.358821   -0.352408     0.689362    0.0578932   -0.17858      0.0759839    0.515913    -0.457071     0.543955    0.112751     0.0912267    0.106305     0.285057   -0.0249709   -0.234659    0.501298     0.427327    -0.193175    -0.169801     0.233529    -0.270992    0.761372    0.361435     0.0803732
 -0.360783    0.00919779   0.0909333   0.207781    -0.387529    0.113543     0.170254    -0.113447    -0.682521     0.216437    -0.439963   -0.349247    -0.347256     0.274223    -0.156193   -0.180098     0.0467565  -0.105357    -0.399888    -0.235441     0.118822    -0.206588     0.0473788  -0.743948   -0.228569     0.0331266
 -0.0484047  -0.252821     0.226653    1.02827     -0.505546   -0.0714752    0.26329      0.838142     0.0146196    0.184282     0.0316888  -0.0549385    0.0332435    0.466798     0.0851346  -0.365334     0.0703722   0.0643924    0.0879052    0.276173    -0.0942469   -0.612607     0.920816    0.106393    0.262837     0.00379642
 -1.0711      0.187548     0.563716    0.479678     0.29632     0.00420484   0.0611822    0.0962472    0.273916    -0.789274     0.246878    0.327732    -0.171678    -0.141312    -0.258716   -0.210047     0.366764    0.210952    -0.00248561   0.252912    -0.0134446   -0.237059     0.179401    0.0750623  -0.132726    -0.0121878
  0.110887    0.25755      0.2705     -0.00917507  -0.0416283   0.151555    -0.289214     0.0129943    0.0938701   -0.309383     0.404183   -0.043295    -0.389243    -0.0185544    0.426366    0.468315     0.0859829  -0.00768755  -0.178941     0.0608126   -0.085889     0.149464     0.0640605   0.299121    0.00650755  -0.279029
 -0.498495    0.0294787   -0.0690629   0.376882     0.296974   -0.20759     -0.552701     0.429716    -0.134444    -0.238632    -0.901458    0.182121    -0.347023     0.190686     0.161779   -0.24326     -0.229913   -0.0700108   -0.00710991  -0.680706     0.567773    -0.379267    -0.359876    0.760709   -0.177869     0.152565
  0.526706   -0.375139    -0.957249   -0.909222    -0.236182    0.179728     0.0180745    0.0383578   -0.302329     0.0462141   -0.428634   -0.533142    -0.377496    -0.449917     0.452082    0.420394    -0.54048    -0.0572916   -5.04516e-5   0.00100014   0.0287261   -0.00857254  -0.549085   -0.108365    0.217006     0.231939
 -0.142355   -0.0521153   -0.140782   -0.138091     0.229504    0.178802     0.0821591    0.0221371   -0.0527575   -0.0802514   -0.11344    -0.0566929   -0.0469002    0.0090942   -0.210776   -0.186231    -0.0122951   0.177571    -0.00505349  -0.0885324    0.0139014   -0.0600501   -0.0585781  -0.0379556   0.0289984    0.00418933
  0.427366    0.0192743   -0.32234     0.0306357   -0.276696    0.1785       0.338625    -0.343708    -0.514792     0.365434    -0.0876264  -0.837102     0.41297      0.667628     0.375802   -0.46404     -0.203652   -0.0423697    0.67402     -0.863497    -0.00693396   0.378387    -0.461582   -0.174486   -0.239184     0.463852
 -0.284       0.397598     0.216567   -0.0195088    0.680469    0.197552     0.188152    -0.177581    -0.415977     0.829393    -0.911551   -0.161387     0.167196    -0.417516    -0.484864   -0.611033    -0.501121    0.139633    -0.078221    -0.127396    -0.0577631    0.0511396    0.106206   -0.299487    0.281758    -0.546815
  0.0805225   0.0602016   -0.013444    0.805798    -0.724688    0.00336819  -0.100344    -0.648513    -0.149001    -0.140037     0.18959     0.110744    -0.0679385    0.292136    -0.22105    -0.0186311   -0.244338   -0.0607326    0.207318    -0.0908553   -0.540683    -0.121604    -0.517511   -0.0581021   0.457873    -0.769862
  0.0896884   0.0950796   -0.120727   -0.419887     0.439382   -0.514656    -0.119471    -0.149085     0.31287      0.00673525  -0.237363    0.0769789    0.0292157   -0.158253    -0.120331    0.0435804   -0.137777   -0.328339    -0.0217768   -0.344477     0.307592     0.0314738   -0.534085   -0.152045   -0.274821    -0.0993184
  0.230994   -0.224213    -0.30716    -0.677207     0.378842   -0.159994    -0.358161     0.364397    -0.0589707    0.156613    -0.404018    0.0755576    0.095609    -0.522962     0.0768636   0.480576     0.0323104  -0.176346    -0.280449     0.456994     0.896952     0.0594258    0.296484    0.0485553  -0.399057     0.562071
  0.570073    0.623037    -0.0280576  -0.292132    -0.169587    0.0351755   -0.134762    -0.0135728   -0.25575      0.0636453    0.488278   -0.145358    -0.00102386   0.156268     0.189998   -0.189994    -0.25579     0.277512    -0.993678     0.447236    -0.363251    -0.118617     0.280532   -0.157251    0.056626    -0.0491591
  0.330969   -0.343532    -0.47964     0.324389    -0.894404   -0.154099    -0.0166022    0.175559     0.121985    -0.514022     0.433042    0.152609     0.0689013    0.691686     0.588928    0.405522     0.190786   -0.0235212    0.177321     0.240281    -0.0641744   -0.021349    -0.101884   -0.0623024  -0.224167     0.832127
 -0.158267    0.0641821   -0.138936   -0.41435      0.61684    -0.438457    -0.456583    -0.428094     0.123621     0.204896     0.122817   -0.182779    -0.737537     0.407912    -0.599447    0.27904     -0.369779   -0.588771    -0.491624    -0.0500836   -0.79553      0.087202    -0.367513    0.347513   -0.571381     0.237306
  0.0309121  -0.40822      0.166055   -0.661884     0.0933827   0.0552321    0.177604    -0.510223    -0.163909    -0.30103      0.214061    0.246033    -0.702177    -0.945267    -0.546633    0.484409    -0.0662245  -0.0241075   -0.0913262    0.194637     0.139057    -0.111801     0.293563   -0.0248254   0.269865    -0.784291
  0.218367    0.0887431   -0.297593   -0.200605     0.114758   -0.198914     0.452472     0.33663      1.32201     -0.0478048    0.181635   -0.284969     0.829778    -0.169061     0.122189    0.172878     0.164655   -0.188172     0.0722989    0.0718325   -0.271269     0.107646    -0.250978   -0.569657   -0.0949809    0.0252389
 -0.243426    0.190385     0.253817   -0.86748      0.414105    0.183719     0.422381     0.319244     0.439531    -0.550539     0.168694   -0.725065    -0.291536    -0.0510946   -0.107004    0.0276505    0.15127    -0.0130474   -0.370248    -0.326685     0.377934    -0.022017     0.295175   -0.598979   -0.272385    -0.00686476
  0.0968727   0.252756     0.509148    0.0511732    0.240065   -0.295856    -0.0202377   -0.310384     0.00430499  -0.0548447    0.568314    0.368972     0.113842    -0.00293883  -0.200848    0.00861788   0.229862   -0.102159    -0.00049114   0.178857    -0.0166106    0.0552145    0.20973     0.129941   -0.186447     0.0040061
  0.0960587  -0.15943     -0.300019    0.249001    -0.525618    0.1959      -0.00834006   0.264259    -0.00404009   0.188116    -0.188755   -0.0892787    0.115431    -0.00680514   0.380703    0.245995    -0.124826   -0.0828047    0.0486563   -0.0236497   -0.0385646    0.00490248  -0.0222791  -0.0544628   0.218604     0.0660206
 -0.0619772  -0.47243     -1.27407     0.437598    -0.122633    0.213839    -0.0932914   -0.0423786   -0.322497     0.316622    -0.861532    0.325143     0.253231     0.0318148   -0.390752   -0.269332     0.393958    0.44971      0.0744624    0.138342     0.0797529   -0.315872    -0.341205    0.156099    0.332676     0.0733591
 -0.474845   -0.563955     0.383661    0.167114    -0.561512    0.119155    -0.402616     0.301632     0.523989     0.0132552   -0.171315    0.30894      0.199031    -0.253213    -0.0123852   1.00587     -0.385633   -0.0317003    0.108407    -0.168135     0.0625064    0.301866     0.430409   -0.144963   -0.136459    -0.340515
 -0.146013    0.158503    -0.218336   -0.00415143  -0.250106   -0.492807     0.762766    -0.218734    -0.305542     0.267171    -0.0069313   0.151654     0.277738     0.230283    -0.135757    0.241734     0.550653   -0.454253     0.162544    -0.384326     0.147255    -0.682846     0.371458   -0.0102398  -0.606497     0.369339
  0.143428   -0.128742     0.167034    0.0865093   -0.0772918  -0.580448     0.180928    -0.299106     0.0435966    0.195813     0.338244    0.350554     0.332539     0.259257    -0.452281    0.196141     0.0419829  -0.0786381   -0.0816594    0.231495    -0.074149     0.00664251   0.370209   -0.0979365  -0.22922      0.21533
  0.283115   -0.25391     -0.126439   -0.246079     0.38496     0.484144     0.503818    -0.00685625  -0.592731    -0.486252    -0.0212374  -0.00328288  -0.089961     0.0966715    0.0185022  -1.12185      0.310319   -0.0331885    0.0869008    0.0134974    0.326983    -0.242975    -0.508563   -0.213906    0.191525     0.23666
  0.293627    0.448263    -0.102121    0.455252    -0.117297   -0.358832    -0.850441    -0.308801    -0.173324     0.352361    -0.372645    0.442885     0.0891764   -0.164728     0.643577    0.346378     0.0531125   0.0749232   -0.464679     0.447809     0.103295    -0.185868     0.128979    0.610055    0.20381      0.0820195
  0.0581543  -0.505312     0.427631    0.498738    -0.0580703  -0.044676    -0.0139649   -0.207308    -0.188272     0.20342      0.269284    0.529056     0.343769    -0.00673673  -0.0568308   0.0430066    0.0793252  -0.290255     0.711722    -0.01151     -0.019689     0.2799      -0.156651    0.297805    0.00245392   0.0693378
 -0.213169    0.117386    -0.0605118   0.0753246   -0.129778    1.05664     -0.272922     0.263269    -0.142212    -0.355957    -0.464581   -0.400056    -0.224861    -0.364321     0.402464   -0.332869    -0.0776839   0.403131    -0.080777    -0.332701     0.213085     0.164628    -0.57328    -0.0180192   0.685558    -0.502492
 -0.180687   -0.601116     0.0230594   0.0985461   -0.29921     1.26         0.283812     0.116399     0.20231      0.149538     0.401722    0.361279     0.135043     0.134147    -0.552423   -0.490076    -0.142139    0.180162     0.385271     0.105195    -0.949013     0.943886     0.320328   -0.221869    0.17876     -0.229742[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415253
[ Info: iteration 2, average log likelihood -1.415241
[ Info: iteration 3, average log likelihood -1.415230
[ Info: iteration 4, average log likelihood -1.415219
[ Info: iteration 5, average log likelihood -1.415209
[ Info: iteration 6, average log likelihood -1.415198
[ Info: iteration 7, average log likelihood -1.415188
[ Info: iteration 8, average log likelihood -1.415178
[ Info: iteration 9, average log likelihood -1.415169
[ Info: iteration 10, average log likelihood -1.415160
┌ Info: EM with 100000 data points 10 iterations avll -1.415160
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
