Julia Version 1.6.0-DEV.142
Commit 6f059bf1ae (2020-06-01 16:19 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Reexport ───────────────────── v0.2.0
  Installed TimerOutputs ───────────────── v0.5.5
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed Adapt ──────────────────────── v1.1.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed BinaryProvider ─────────────── v0.5.10
  Installed CUDAdrv ────────────────────── v6.3.0
  Installed CUDAnative ─────────────────── v3.1.0
  Installed Knet ───────────────────────── v1.3.5
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Zlib_jll ───────────────────── v1.2.11+10
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed TranscodingStreams ─────────── v0.9.5
  Installed JLD2 ───────────────────────── v0.1.13
  Installed CUDAapi ────────────────────── v4.0.0
  Installed AutoGrad ───────────────────── v1.2.2
  Installed GPUArrays ──────────────────── v3.4.1
  Installed Cthulhu ────────────────────── v1.1.1
  Installed ExprTools ──────────────────── v0.1.1
  Installed GPUCompiler ────────────────── v0.2.0
  Installed OrderedCollections ─────────── v1.2.0
  Installed CEnum ──────────────────────── v0.3.0
  Installed CodecZlib ──────────────────── v0.7.0
  Installed CodeTracking ───────────────── v0.5.11
  Installed SpecialFunctions ───────────── v0.10.3
  Installed LLVM ───────────────────────── v1.5.1
  Installed DataStructures ─────────────── v0.17.17
  Installed Requires ───────────────────── v1.0.1
  Installed NNlib ──────────────────────── v0.6.6
  Installed FileIO ─────────────────────── v1.3.0
  Installed CuArrays ───────────────────── v2.2.0
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.3.5
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v1.1.0
  [6710c13c] + AutoGrad v1.2.2
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.3.0
  [3895d2a7] + CUDAapi v4.0.0
  [c5f51814] + CUDAdrv v6.3.0
  [be33ccc6] + CUDAnative v3.1.0
  [da1fd8a2] + CodeTracking v0.5.11
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [f68482b8] + Cthulhu v1.1.1
  [3a865a2d] + CuArrays v2.2.0
  [864edb3b] + DataStructures v0.17.17
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.3.0
  [0c68f7d7] + GPUArrays v3.4.1
  [61eb1bfa] + GPUCompiler v0.2.0
  [033835bb] + JLD2 v0.1.13
  [1902f260] + Knet v1.3.5
  [929cbde3] + LLVM v1.5.1
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.6.6
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.2.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.5
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+10
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building NNlib → `~/.julia/packages/NNlib/FAI3o/deps/build.log`
   Building Knet ─→ `~/.julia/packages/Knet/bTNMd/deps/build.log`
    Testing Knet
Status `/tmp/jl_lKx2FB/Project.toml`
  [6710c13c] AutoGrad v1.2.2
  [3895d2a7] CUDAapi v4.0.0
  [3a865a2d] CuArrays v2.2.0
  [864edb3b] DataStructures v0.17.17
  [5789e2e9] FileIO v1.3.0
  [033835bb] JLD2 v0.1.13
  [1902f260] Knet v1.3.5
  [872c559c] NNlib v0.6.6
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.5
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_lKx2FB/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v1.1.0
  [6710c13c] AutoGrad v1.2.2
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.3.0
  [3895d2a7] CUDAapi v4.0.0
  [c5f51814] CUDAdrv v6.3.0
  [be33ccc6] CUDAnative v3.1.0
  [da1fd8a2] CodeTracking v0.5.11
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [f68482b8] Cthulhu v1.1.1
  [3a865a2d] CuArrays v2.2.0
  [864edb3b] DataStructures v0.17.17
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.3.0
  [0c68f7d7] GPUArrays v3.4.1
  [61eb1bfa] GPUCompiler v0.2.0
  [033835bb] JLD2 v0.1.13
  [1902f260] Knet v1.3.5
  [929cbde3] LLVM v1.5.1
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.6.6
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.2.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.5
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+10
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
  0.948321 seconds (400.18 k allocations: 21.417 MiB, 25.00% gc time)
Knet.gpuCount() = 1
Knet.gpu() = 0
Knet.tk = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
Knet.libknet8 = ""
Knet.cudartfound = true
Knet.cudaRuntimeVersion = 10020
Knet.cudaDriverVersion = 10020
Knet.cudaGetDeviceCount() = 1
Knet.cudaGetDevice() = 0
Knet.cudaMemGetInfo() = (15684009984, 15843721216)
Knet.cudaDeviceSynchronize() = nothing
Knet.nvmlfound = false
Knet.cublashandle() = Ptr{Nothing} @0x0000000008907800
Knet.cublasVersion = 10202
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gpu.jl:3
  Got exception outside of a @test
  Cannot find cudnn
  Stacktrace:
   [1] error(::String) at ./error.jl:33
   [2] cudnnCreate() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:306
   [3] cudnnhandle(::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:213
   [4] cudnnhandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:206
   [5] top-level scope at show.jl:636
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gpu.jl:28
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gpu.jl:5
   [9] include(::String) at ./client.jl:444
   [10] macro expansion at ./timing.jl:174 [inlined]
   [11] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:7 [inlined]
   [12] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
   [14] include(::String) at ./client.jl:444
   [15] top-level scope at none:6
   [16] eval(::Module, ::Any) at ./boot.jl:331
   [17] exec_options(::Base.JLOptions) at ./client.jl:260
   [18] _start() at ./client.jl:485
  
  8.029373 seconds (5.22 M allocations: 267.057 MiB, 1.69% gc time)
  3.163813 seconds (4.57 M allocations: 231.492 MiB, 2.54% gc time)

Stacktrace:
 [1] dropout!(::Float64, ::KnetArray{Float64,2}, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:62
 [2] dropout(::KnetArray{Float64,2}, ::Float64; seed::Int64, drop::Bool) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:25
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Symbol,Integer,Tuple{Symbol,Symbol},NamedTuple{(:seed, :drop),Tuple{Int64,Bool}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #dropout#777 at ./none:0 [inlined]
 [5] (::var"#dropout1#7")(::Param{KnetArray{Float64,2}}, ::Float64) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
 [6] gcsum(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] (::AutoGrad.var"#217#219"{Tuple{},var"#dropout1#7",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gradcheck(::var"#dropout1#7", ::KnetArray{Float64,2}, ::Vararg{Any,N} where N; kw::Tuple{}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [12] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:9
 [13] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
 [15] include(::String) at ./client.jl:444
 [16] macro expansion at ./timing.jl:174 [inlined]
 [17] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:9 [inlined]
 [18] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [20] include(::String) at ./client.jl:444
 [21] top-level scope at none:6
 [22] eval(::Module, ::Any) at ./boot.jl:331
 [23] exec_options(::Base.JLOptions) at ./client.jl:260
 [24] _start() at ./client.jl:485
dropout: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:9
  Test threw exception
  Expression: gradcheck(dropout1, k, 0.5; args = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#dropout1#7", ::KnetArray{Float64,2}, ::Vararg{Any,N} where N; kw::Tuple{}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:9
   [5] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] dropout!(::Float64, ::KnetArray{Float64,2}, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:62
   [2] dropout(::KnetArray{Float64,2}, ::Float64; seed::Int64, drop::Bool) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:25
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Symbol,Integer,Tuple{Symbol,Symbol},NamedTuple{(:seed, :drop),Tuple{Int64,Bool}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #dropout#777 at ./none:0 [inlined]
   [5] (::var"#dropout1#7")(::Param{KnetArray{Float64,2}}, ::Float64) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
   [6] gcsum(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] (::AutoGrad.var"#217#219"{Tuple{},var"#dropout1#7",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gradcheck(::var"#dropout1#7", ::KnetArray{Float64,2}, ::Vararg{Any,N} where N; kw::Tuple{}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [12] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:9
   [13] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
  
dropout: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:12
  Test threw exception
  Expression: isapprox(sum(abs2, dropout1(k, 0.5)), sum(abs2, dropout1(a, 0.5)), rtol = 0.1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] dropout!(::Float64, ::KnetArray{Float64,2}, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:62
   [2] dropout(::KnetArray{Float64,2}, ::Float64; seed::Int64, drop::Bool) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/dropout.jl:25
   [3] (::var"#dropout1#7")(::KnetArray{Float64,2}, ::Float64) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
   [4] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:12
   [5] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/dropout.jl:4
  
 15.774073 seconds (15.02 M allocations: 766.986 MiB, 4.05% gc time)
serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/serialize.jl:5
  Got exception outside of a @test
  Cannot find cudnn
  Stacktrace:
   [1] error(::String) at ./error.jl:33
   [2] cudnnCreate() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:306
   [3] cudnnhandle(::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:213
   [4] cudnnhandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:206
   [5] gethandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:384
   [6] RNN(::Int64, ::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:147
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/serialize.jl:6
   [8] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [9] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/serialize.jl:6
   [10] include(::String) at ./client.jl:444
   [11] macro expansion at ./timing.jl:174 [inlined]
   [12] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:10 [inlined]
   [13] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
   [15] include(::String) at ./client.jl:444
   [16] top-level scope at none:6
   [17] eval(::Module, ::Any) at ./boot.jl:331
   [18] exec_options(::Base.JLOptions) at ./client.jl:260
   [19] _start() at ./client.jl:485
  
  0.985674 seconds (1.04 M allocations: 56.184 MiB, 5.58% gc time)
JLD: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/jld.jl:3
  Got exception outside of a @test
  Cannot find cudnn
  Stacktrace:
   [1] error(::String) at ./error.jl:33
   [2] cudnnCreate() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:306
   [3] cudnnhandle(::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:213
   [4] cudnnhandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:206
   [5] gethandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:384
   [6] RNN(::Int64, ::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:147
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/jld.jl:7
   [8] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [9] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/jld.jl:6
   [10] include(::String) at ./client.jl:444
   [11] macro expansion at ./timing.jl:174 [inlined]
   [12] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:11 [inlined]
   [13] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
   [15] include(::String) at ./client.jl:444
   [16] top-level scope at none:6
   [17] eval(::Module, ::Any) at ./boot.jl:331
   [18] exec_options(::Base.JLOptions) at ./client.jl:260
   [19] _start() at ./client.jl:485
  
  0.261524 seconds (6.36 k allocations: 402.469 KiB)
gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gcnode.jl:3
  Got exception outside of a @test
  Cannot find cudnn
  Stacktrace:
   [1] error(::String) at ./error.jl:33
   [2] cudnnCreate() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:306
   [3] cudnnhandle(::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:213
   [4] cudnnhandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/gpu.jl:206
   [5] gethandle() at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:384
   [6] RNN(::Int64, ::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/rnn.jl:147
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gcnode.jl:8
   [8] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [9] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/gcnode.jl:6
   [10] include(::String) at ./client.jl:444
   [11] macro expansion at ./timing.jl:174 [inlined]
   [12] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:12 [inlined]
   [13] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
   [15] include(::String) at ./client.jl:444
   [16] top-level scope at none:6
   [17] eval(::Module, ::Any) at ./boot.jl:331
   [18] exec_options(::Base.JLOptions) at ./client.jl:260
   [19] _start() at ./client.jl:485
  
  0.213589 seconds (5.79 k allocations: 365.729 KiB)
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:13
  Test threw exception
  Expression: mean(a) ≈ mean(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:13
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#25#42"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#25#42"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14 =# @gcheck mean(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#25#42"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#25#42"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:15
  Test threw exception
  Expression: mean(a, dims = 1) ≈ mean(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:15
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#26#43"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#26#43"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16 =# @gcheck mean(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#26#43"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#26#43"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:17
  Test threw exception
  Expression: mean(a, dims = 2) ≈ mean(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:17
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#27#44"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#27#44"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18 =# @gcheck mean(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#27#44"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#27#44"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:19
  Test threw exception
  Expression: mean(abs, a) ≈ mean(abs, k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [3] sum(::typeof(abs), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:19
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sumabs(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::typeof(abs), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
 [3] sum(::typeof(abs), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
 [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
 [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#163 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#28#45"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#28#45"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20 =# @gcheck mean(abs, p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [3] sum(::typeof(abs), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#163 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#28#45"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#28#45"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:21
  Test threw exception
  Expression: mean(abs2, a) ≈ mean(abs2, k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs2(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs2), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [3] sum(::typeof(abs2), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:21
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sumabs2(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::typeof(abs2), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
 [3] sum(::typeof(abs2), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
 [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
 [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#181 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#29#46"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#29#46"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22 =# @gcheck mean(abs2, p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs2(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs2), ::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [3] sum(::typeof(abs2), ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [4] mean(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#181 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#29#46"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#29#46"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:23
  Test threw exception
  Expression: std(a) ≈ std(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] var(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [6] std(::KnetArray{Float32,2}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [7] std(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:23
   [9] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [10] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [8] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [9] std at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24 [inlined]
 [10] (::var"#30#47"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [11] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [12] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [13] (::AutoGrad.var"#234#239"{Tuple{},var"#30#47"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [14] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [15] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [16] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
 [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [21] include(::String) at ./client.jl:444
 [22] macro expansion at ./timing.jl:174 [inlined]
 [23] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [24] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [25] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [26] include(::String) at ./client.jl:444
 [27] top-level scope at none:6
 [28] eval(::Module, ::Any) at ./boot.jl:331
 [29] exec_options(::Base.JLOptions) at ./client.jl:260
 [30] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24 =# @gcheck std(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [8] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [9] std at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24 [inlined]
   [10] (::var"#30#47"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [11] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [12] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [13] (::AutoGrad.var"#234#239"{Tuple{},var"#30#47"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [14] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [15] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [16] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:25
  Test threw exception
  Expression: std(a, dims = 1) ≈ std(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] std(::KnetArray{Float32,2}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:25
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [8] (::var"#31#48"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#31#48"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26 =# @gcheck std(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [8] (::var"#31#48"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#31#48"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:27
  Test threw exception
  Expression: std(a, dims = 2) ≈ std(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] std(::KnetArray{Float32,2}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:27
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [8] (::var"#32#49"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#32#49"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28 =# @gcheck std(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] std(::Param{KnetArray{Float32,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [8] (::var"#32#49"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#32#49"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:29
  Test threw exception
  Expression: stdm(a, mean(a)) ≈ stdm(k, mean(k))
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:29
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#33#50"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#33#50"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30 =# @gcheck stdm(p, mean(p))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#33#50"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#33#50"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:31
  Test threw exception
  Expression: stdm(a, mean(a, dims = 1), dims = 1) ≈ stdm(k, mean(k, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:31
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#34#51"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#34#51"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32 =# @gcheck stdm(p, mean(p, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#34#51"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#34#51"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:33
  Test threw exception
  Expression: stdm(a, mean(a, dims = 2), dims = 2) ≈ stdm(k, mean(k, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:33
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#35#52"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#35#52"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34 =# @gcheck stdm(p, mean(p, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#35#52"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#35#52"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:35
  Test threw exception
  Expression: var(a) ≈ var(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] var(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:35
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [8] (::var"#36#53"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#36#53"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36 =# @gcheck var(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [8] (::var"#36#53"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#36#53"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:37
  Test threw exception
  Expression: var(a, dims = 1) ≈ var(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:37
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] (::var"#37#54"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [10] (::AutoGrad.var"#234#239"{Tuple{},var"#37#54"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
 [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [18] include(::String) at ./client.jl:444
 [19] macro expansion at ./timing.jl:174 [inlined]
 [20] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [22] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [23] include(::String) at ./client.jl:444
 [24] top-level scope at none:6
 [25] eval(::Module, ::Any) at ./boot.jl:331
 [26] exec_options(::Base.JLOptions) at ./client.jl:260
 [27] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38 =# @gcheck var(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] (::var"#37#54"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [10] (::AutoGrad.var"#234#239"{Tuple{},var"#37#54"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
   [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:39
  Test threw exception
  Expression: var(a, dims = 2) ≈ var(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float32,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float32,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:39
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] (::var"#38#55"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [10] (::AutoGrad.var"#234#239"{Tuple{},var"#38#55"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
 [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [18] include(::String) at ./client.jl:444
 [19] macro expansion at ./timing.jl:174 [inlined]
 [20] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [22] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [23] include(::String) at ./client.jl:444
 [24] top-level scope at none:6
 [25] eval(::Module, ::Any) at ./boot.jl:331
 [26] exec_options(::Base.JLOptions) at ./client.jl:260
 [27] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40 =# @gcheck var(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float32,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] (::var"#38#55"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [10] (::AutoGrad.var"#234#239"{Tuple{},var"#38#55"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
   [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:41
  Test threw exception
  Expression: varm(a, mean(a)) ≈ varm(k, mean(k))
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:41
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#39#56"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#39#56"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42 =# @gcheck varm(p, mean(p))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#39#56"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#39#56"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:43
  Test threw exception
  Expression: varm(a, mean(a, dims = 1), dims = 1) ≈ varm(k, mean(k, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:43
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#40#57"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#40#57"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44 =# @gcheck varm(p, mean(p, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#40#57"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#40#57"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:45
  Test threw exception
  Expression: varm(a, mean(a, dims = 2), dims = 2) ≈ varm(k, mean(k, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:45
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#41#58"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#41#58"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46 =# @gcheck varm(p, mean(p, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float32,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#41#58"{Param{KnetArray{Float32,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#41#58"{Param{KnetArray{Float32,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:13
  Test threw exception
  Expression: mean(a) ≈ mean(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:13
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#25#42"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#25#42"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14 =# @gcheck mean(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#25#42"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#25#42"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:14
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:15
  Test threw exception
  Expression: mean(a, dims = 1) ≈ mean(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:15
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#26#43"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#26#43"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16 =# @gcheck mean(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#26#43"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#26#43"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:16
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:17
  Test threw exception
  Expression: mean(a, dims = 2) ≈ mean(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:17
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#27#44"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#27#44"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18 =# @gcheck mean(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#27#44"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#27#44"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:18
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:19
  Test threw exception
  Expression: mean(abs, a) ≈ mean(abs, k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [3] sum(::typeof(abs), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:19
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sumabs(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::typeof(abs), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
 [3] sum(::typeof(abs), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
 [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
 [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#163 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#28#45"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#28#45"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20 =# @gcheck mean(abs, p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [3] sum(::typeof(abs), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:6
   [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#163 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#28#45"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#28#45"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:20
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:21
  Test threw exception
  Expression: mean(abs2, a) ≈ mean(abs2, k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs2(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs2), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [3] sum(::typeof(abs2), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:21
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sumabs2(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::typeof(abs2), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
 [3] sum(::typeof(abs2), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
 [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
 [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#181 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#29#46"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#29#46"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22 =# @gcheck mean(abs2, p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sumabs2(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::typeof(abs2), ::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [3] sum(::typeof(abs2), ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:7
   [4] mean(::Function, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:4
   [5] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#181 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#29#46"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#29#46"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:22
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:23
  Test threw exception
  Expression: std(a) ≈ std(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] var(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [6] std(::KnetArray{Float64,2}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [7] std(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:23
   [9] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [10] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [8] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [9] std at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24 [inlined]
 [10] (::var"#30#47"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [11] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [12] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [13] (::AutoGrad.var"#234#239"{Tuple{},var"#30#47"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [14] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [15] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [16] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
 [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [21] include(::String) at ./client.jl:444
 [22] macro expansion at ./timing.jl:174 [inlined]
 [23] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [24] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [25] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [26] include(::String) at ./client.jl:444
 [27] top-level scope at none:6
 [28] eval(::Module, ::Any) at ./boot.jl:331
 [29] exec_options(::Base.JLOptions) at ./client.jl:260
 [30] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24 =# @gcheck std(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [8] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [9] std at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24 [inlined]
   [10] (::var"#30#47"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [11] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [12] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [13] (::AutoGrad.var"#234#239"{Tuple{},var"#30#47"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [14] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [15] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [16] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:24
   [19] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:25
  Test threw exception
  Expression: std(a, dims = 1) ≈ std(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] std(::KnetArray{Float64,2}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:25
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [8] (::var"#31#48"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#31#48"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26 =# @gcheck std(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [8] (::var"#31#48"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#31#48"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:26
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:27
  Test threw exception
  Expression: std(a, dims = 2) ≈ std(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] std(::KnetArray{Float64,2}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:5
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:27
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
 [8] (::var"#32#49"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#32#49"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28 =# @gcheck std(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] std(::Param{KnetArray{Float64,2}}; kws::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:24
   [8] (::var"#32#49"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#32#49"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:28
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:29
  Test threw exception
  Expression: stdm(a, mean(a)) ≈ stdm(k, mean(k))
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:29
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#33#50"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#33#50"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30 =# @gcheck stdm(p, mean(p))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#33#50"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#33#50"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:30
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:31
  Test threw exception
  Expression: stdm(a, mean(a, dims = 1), dims = 1) ≈ stdm(k, mean(k, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:31
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#34#51"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#34#51"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32 =# @gcheck stdm(p, mean(p, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#34#51"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#34#51"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:32
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:33
  Test threw exception
  Expression: stdm(a, mean(a, dims = 2), dims = 2) ≈ stdm(k, mean(k, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:33
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#35#52"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#35#52"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34 =# @gcheck stdm(p, mean(p, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#35#52"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#35#52"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:34
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:35
  Test threw exception
  Expression: var(a) ≈ var(k)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] var(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:35
   [7] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [8] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [8] (::var"#36#53"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [11] (::AutoGrad.var"#234#239"{Tuple{},var"#36#53"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
 [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [19] include(::String) at ./client.jl:444
 [20] macro expansion at ./timing.jl:174 [inlined]
 [21] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [22] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [23] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [24] include(::String) at ./client.jl:444
 [25] top-level scope at none:6
 [26] eval(::Module, ::Any) at ./boot.jl:331
 [27] exec_options(::Base.JLOptions) at ./client.jl:260
 [28] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36 =# @gcheck var(p)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Colon,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Colon}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] var at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [8] (::var"#36#53"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [9] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [10] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [11] (::AutoGrad.var"#234#239"{Tuple{},var"#36#53"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [12] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [13] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [14] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:36
   [17] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [18] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:37
  Test threw exception
  Expression: var(a, dims = 1) ≈ var(k, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:37
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] (::var"#37#54"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [10] (::AutoGrad.var"#234#239"{Tuple{},var"#37#54"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
 [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [18] include(::String) at ./client.jl:444
 [19] macro expansion at ./timing.jl:174 [inlined]
 [20] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [22] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [23] include(::String) at ./client.jl:444
 [24] top-level scope at none:6
 [25] eval(::Module, ::Any) at ./boot.jl:331
 [26] exec_options(::Base.JLOptions) at ./client.jl:260
 [27] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38 =# @gcheck var(p, dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] (::var"#37#54"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [10] (::AutoGrad.var"#234#239"{Tuple{},var"#37#54"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:38
   [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:39
  Test threw exception
  Expression: var(a, dims = 2) ≈ var(k, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] _varm(::KnetArray{Float64,2}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:11
   [4] var(::KnetArray{Float64,2}; corrected::Bool, mean::Nothing, dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:7
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:39
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
 [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
 [7] (::var"#38#55"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [10] (::AutoGrad.var"#234#239"{Tuple{},var"#38#55"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
 [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [18] include(::String) at ./client.jl:444
 [19] macro expansion at ./timing.jl:174 [inlined]
 [20] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [21] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [22] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [23] include(::String) at ./client.jl:444
 [24] top-level scope at none:6
 [25] eval(::Module, ::Any) at ./boot.jl:331
 [26] exec_options(::Base.JLOptions) at ./client.jl:260
 [27] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40 =# @gcheck var(p, dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] _varm(::Param{KnetArray{Float64,2}}, ::Nothing; corrected::Bool, dims::Int64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:31
   [6] #var#195 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/statistics.jl:27 [inlined]
   [7] (::var"#38#55"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [8] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [10] (::AutoGrad.var"#234#239"{Tuple{},var"#38#55"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [11] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [12] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [13] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:40
   [16] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:41
  Test threw exception
  Expression: varm(a, mean(a)) ≈ varm(k, mean(k))
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:41
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [7] #mean#153 at ./none:0 [inlined]
 [8] mean at ./none:0 [inlined]
 [9] (::var"#39#56"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [12] (::AutoGrad.var"#234#239"{Tuple{},var"#39#56"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
 [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [20] include(::String) at ./client.jl:444
 [21] macro expansion at ./timing.jl:174 [inlined]
 [22] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [23] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [24] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [25] include(::String) at ./client.jl:444
 [26] top-level scope at none:6
 [27] eval(::Module, ::Any) at ./boot.jl:331
 [28] exec_options(::Base.JLOptions) at ./client.jl:260
 [29] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42 =# @gcheck varm(p, mean(p))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [4] mean(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [5] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [6] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [7] #mean#153 at ./none:0 [inlined]
   [8] mean at ./none:0 [inlined]
   [9] (::var"#39#56"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [10] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [11] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [12] (::AutoGrad.var"#234#239"{Tuple{},var"#39#56"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [13] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [14] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [15] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [16] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [17] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:42
   [18] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [19] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:43
  Test threw exception
  Expression: varm(a, mean(a, dims = 1), dims = 1) ≈ varm(k, mean(k, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:43
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#40#57"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#40#57"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44 =# @gcheck varm(p, mean(p, dims = 1), dims = 1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#40#57"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#40#57"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:44
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:45
  Test threw exception
  Expression: varm(a, mean(a, dims = 2), dims = 2) ≈ varm(k, mean(k, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:45
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
 [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] #mean#153 at ./none:0 [inlined]
 [5] (::var"#41#58"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [8] (::AutoGrad.var"#234#239"{Tuple{},var"#41#58"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
 [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
 [16] include(::String) at ./client.jl:444
 [17] macro expansion at ./timing.jl:174 [inlined]
 [18] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:13 [inlined]
 [19] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [20] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [21] include(::String) at ./client.jl:444
 [22] top-level scope at none:6
 [23] eval(::Module, ::Any) at ./boot.jl:331
 [24] exec_options(::Base.JLOptions) at ./client.jl:260
 [25] _start() at ./client.jl:485
statistics: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46 =# @gcheck varm(p, mean(p, dims = 2), dims = 2)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:54
   [2] mean(::KnetArray{Float64,2}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/statistics.jl:3
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] #mean#153 at ./none:0 [inlined]
   [5] (::var"#41#58"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [6] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [7] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [8] (::AutoGrad.var"#234#239"{Tuple{},var"#41#58"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [9] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [10] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [11] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [12] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:46
   [14] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [15] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/statistics.jl:9
  
 32.780800 seconds (9.81 M allocations: 521.311 MiB, 1.16% gc time)

Stacktrace:
 [1] sum(::KnetArray{Float64,1}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,1}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,1}}) at ./none:0
 [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [9] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,1}},Tuple{UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13 =# @gcheck getindex(a3, idx...)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,1}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,1}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,1}}) at ./none:0
   [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [9] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,1}},Tuple{UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,2}}) at ./none:0
 [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [9] (::AutoGrad.var"#234#239"{Tuple{},var"#64#84"{Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:17
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:17
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:17 =# @gcheck permutedims(a3)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:17
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,2}}) at ./none:0
   [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [9] (::AutoGrad.var"#234#239"{Tuple{},var"#64#84"{Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:17
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
 [40] (::var"#75#95"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37 =# @gcheck hcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
   [40] (::var"#75#95"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,1,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,1,Nothing}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
 [40] (::var"#76#96"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38 =# @gcheck vcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,1,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,1,Nothing}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
   [40] (::var"#76#96"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,1,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,1,Nothing}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,1,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,1,Nothing}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,1,Nothing},CuArrays.CuArray{Float64,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,1,Nothing}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,1,Nothing}, ::Vararg{CuArrays.CuArray{Float64,1,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,1}, ::Vararg{KnetArray{Float64,1},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,1}}, ::Vararg{Param{KnetArray{Float64,1}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,1}},Param{KnetArray{Float64,1}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:11
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: lib not defined
  Stacktrace:
   [1] getindex2(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:984
   [2] getindex(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:938
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:11
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] getindex2(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:984
 [2] getindex(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:938
 [3] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] getindex at ./none:0 [inlined]
 [6] (::var"#62#82"{Param{KnetArray{Float64,2}},Tuple{UnitRange{Int64},UnitRange{Int64}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [9] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,2}},Tuple{UnitRange{Int64},UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13 =# @gcheck getindex(a3, idx...)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] getindex2(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:984
   [2] getindex(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:938
   [3] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] getindex at ./none:0 [inlined]
   [6] (::var"#62#82"{Param{KnetArray{Float64,2}},Tuple{UnitRange{Int64},UnitRange{Int64}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [9] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,2}},Tuple{UnitRange{Int64},UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:20
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:20
   [37] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [38] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:21
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:21
   [37] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [38] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,2}}) at ./none:0
 [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [9] (::AutoGrad.var"#234#239"{Tuple{},var"#68#88"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:25
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:25
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:25 =# @gcheck permutedims(a3)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:25
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,2}}) at ./none:0
   [7] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [9] (::AutoGrad.var"#234#239"{Tuple{},var"#68#88"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [13] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:25
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#69#89"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#69#89"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:26
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:26
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:26 =# @gcheck permutedims(a3, (2, 1))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:26
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#69#89"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#69#89"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:26
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#70#90"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#70#90"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:27
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:27
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:27 =# @gcheck permutedims(a3, (1, 2))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:27
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,2,Nothing}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,2}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#70#90"{Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#70#90"{Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:27
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:34
  Test threw exception
  Expression: vcat(a0, b0) == vcat(a1, b1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] setindex2!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::UnitRange{Int64}, ::Colon) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:1024
   [2] setindex! at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:949 [inlined]
   [3] vcat(::KnetArray{Float64,2}, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:268
   [4] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:34
   [5] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [6] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
 [40] (::var"#75#95"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37 =# @gcheck hcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
   [40] (::var"#75#95"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
 [40] (::var"#76#96"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38 =# @gcheck vcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
   [40] (::var"#76#96"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,2,Nothing},CuArrays.CuArray{Float64,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,2,Nothing}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,2,Nothing}, ::Vararg{CuArrays.CuArray{Float64,2,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,2}, ::Vararg{KnetArray{Float64,2},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,2}}, ::Vararg{Param{KnetArray{Float64,2}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,2}},Param{KnetArray{Float64,2}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:44
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: lib not defined
  Stacktrace:
   [1] getindex2(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:984
   [2] getindex(::KnetArray{Float64,2}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:938
   [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:44
   [4] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{2}[CartesianIndex(2, 1) CartesianIndex(2, 2) … CartesianIndex(5, 7) CartesianIndex(4, 8)] == CartesianIndex{2}[CartesianIndex(2, 1) CartesianIndex(8, 2) … CartesianIndex(5, 7) CartesianIndex(4, 8)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.011978536247788218 0.06522619017049802 … 0.05599259930811473 0.17545313606622703], CartesianIndex{2}[CartesianIndex(2, 1) CartesianIndex(2, 2) … CartesianIndex(5, 7) CartesianIndex(4, 8)]) == ([0.011978536247788218 0.09099377886343163 … 0.05599259930811473 0.17545313606622703], CartesianIndex{2}[CartesianIndex(2, 1) CartesianIndex(8, 2) … CartesianIndex(5, 7) CartesianIndex(4, 8)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{2}[CartesianIndex(1, 3); CartesianIndex(2, 1); … ; CartesianIndex(7, 8); CartesianIndex(8, 4)] == CartesianIndex{2}[CartesianIndex(1, 3); CartesianIndex(2, 1); … ; CartesianIndex(7, 8); CartesianIndex(8, 4)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.15756748810868815; 0.011978536247788218; … ; 0.27417276359728815; 0.024152127937150603], CartesianIndex{2}[CartesianIndex(1, 3); CartesianIndex(2, 1); … ; CartesianIndex(7, 8); CartesianIndex(8, 4)]) == ([0.15756748810868815; 0.011978536247788218; … ; 0.27417276359728815; 0.024152127937150603], CartesianIndex{2}[CartesianIndex(1, 3); CartesianIndex(2, 1); … ; CartesianIndex(7, 8); CartesianIndex(8, 4)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:11
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] _unsafe_getindex!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::Vararg{UnitRange{Int64},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:135
   [34] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:28
   [35] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:11
   [36] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] _unsafe_getindex!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::Vararg{UnitRange{Int64},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:135
 [34] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:28
 [35] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [36] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [37] getindex at ./none:0 [inlined]
 [38] (::var"#62#82"{Param{KnetArray{Float64,3}},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [39] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [40] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [41] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,3}},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [42] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [43] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [44] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [45] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
 [47] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [49] include(::String) at ./client.jl:444
 [50] macro expansion at ./timing.jl:174 [inlined]
 [51] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [52] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [53] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [54] include(::String) at ./client.jl:444
 [55] top-level scope at none:6
 [56] eval(::Module, ::Any) at ./boot.jl:331
 [57] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13 =# @gcheck getindex(a3, idx...)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] _unsafe_getindex!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::Vararg{UnitRange{Int64},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:135
   [34] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:28
   [35] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [36] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [37] getindex at ./none:0 [inlined]
   [38] (::var"#62#82"{Param{KnetArray{Float64,3}},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [39] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [40] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [41] (::AutoGrad.var"#234#239"{Tuple{},var"#62#82"{Param{KnetArray{Float64,3}},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [42] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [43] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [44] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [45] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:13
   [47] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:29
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:29
   [37] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [38] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#72#92"{Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#72#92"{Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:31
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:31
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:31 =# @gcheck permutedims(a3, (1, 3, 2))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:31
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#72#92"{Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#72#92"{Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:31
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:33
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:59
   [38] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:33
   [39] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [40] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:34
  Test threw exception
  Expression: vcat(a0, b0) == vcat(a1, b1)
  UndefVarError: lib not defined
  Stacktrace:
   [1] setindex2!(::KnetArray{Float64,2}, ::KnetArray{Float64,2}, ::UnitRange{Int64}, ::Colon) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:1024
   [2] setindex! at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:949 [inlined]
   [3] vcat(::KnetArray{Float64,2}, ::KnetArray{Float64,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:268
   [4] vcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/karray.jl:283
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:34
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
 [40] (::var"#75#95"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37 =# @gcheck hcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] hcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:119 [inlined]
   [40] (::var"#75#95"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#75#95"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:37
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
 [40] (::var"#76#96"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
 [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [50] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [51] include(::String) at ./client.jl:444
 [52] macro expansion at ./timing.jl:174 [inlined]
 [53] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [54] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [55] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [56] include(::String) at ./client.jl:444
 [57] top-level scope at none:6
 [58] eval(::Module, ::Any) at ./boot.jl:331
 [59] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38 =# @gcheck vcat(a3, b3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] vcat at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:118 [inlined]
   [40] (::var"#76#96"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [41] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [43] (::AutoGrad.var"#234#239"{Tuple{},var"#76#96"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [44] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [45] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [46] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [48] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:38
   [49] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:40
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
 [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
 [33] _setindex! at ./multidimensional.jl:785 [inlined]
 [34] setindex! at ./abstractarray.jl:1142 [inlined]
 [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
 [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
 [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
 [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
 [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
 [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:14 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42 =# @gcheck cat(a3, b3, dims = i)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [4] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:162 [inlined]
   [33] _setindex! at ./multidimensional.jl:785 [inlined]
   [34] setindex! at ./abstractarray.jl:1142 [inlined]
   [35] __cat(::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{CuArrays.CuArray{Float64,3,Nothing},N} where N) at ./abstractarray.jl:1533
   [36] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:71
   [37] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [38] #cat#199 at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/cat.jl:30 [inlined]
   [39] (::var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:172
   [40] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50 [inlined]
   [42] (::AutoGrad.var"#234#239"{Tuple{},var"#78#98"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [46] gcheck(::Function) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:158
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:42
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:44
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] _unsafe_getindex!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::Vararg{UnitRange{Int64},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/indexing.jl:135
   [34] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:28
   [35] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:44
   [36] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(5, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(6, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(6, 8, 2)]

CartesianIndex{3}[CartesianIndex(2, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(1, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(8, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(3, 1, 7) CartesianIndex(4, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(2, 7, 8) CartesianIndex(4, 8, 8)] == CartesianIndex{3}[CartesianIndex(5, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(6, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(7, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(6, 8, 2)]

CartesianIndex{3}[CartesianIndex(2, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(1, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(8, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(3, 1, 7) CartesianIndex(4, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(2, 7, 8) CartesianIndex(4, 8, 8)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(4, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(1, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(6, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(1, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(6, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)] == CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(4, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(1, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(3, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(1, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(6, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.727586592833992 0.9671755036450553 … 0.9401862327770283 0.9827823792376333]

[0.8377293204663485 0.5546194742054924 … 0.9417789568118808 0.9434288198169076]

[0.8869740712193446 0.9802253651995854 … 0.9963910048571323 0.8451588185336074]

[0.838971362543782 0.9742081547117187 … 0.8466147534415893 0.958327255522984]

[0.8630544135674918 0.8945977142656028 … 0.7417341129895101 0.8446416512892818]

[0.9751157790421963 0.981918898123064 … 0.8535927914838313 0.7179836048650645]

[0.9584517589850021 0.8174233175740566 … 0.9910216988605751 0.7495183029598291]

[0.9904786649251711 0.8726937832930126 … 0.9013306936542429 0.7859714462719325], CartesianIndex{3}[CartesianIndex(5, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(6, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(6, 8, 2)]

CartesianIndex{3}[CartesianIndex(2, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(1, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(8, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(3, 1, 7) CartesianIndex(4, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(2, 7, 8) CartesianIndex(4, 8, 8)]) == ([0.727586592833992 0.9671755036450553 … 0.9401862327770283 0.9827823792376333]

[0.8377293204663485 0.7700876338585008 … 0.9417789568118808 0.9434288198169076]

[0.8869740712193446 0.9802253651995854 … 0.9963910048571323 0.8451588185336074]

[0.838971362543782 0.9742081547117187 … 0.8466147534415893 0.958327255522984]

[0.8630544135674918 0.8945977142656028 … 0.7417341129895101 0.8446416512892818]

[0.9751157790421963 0.981918898123064 … 0.8535927914838313 0.7179836048650645]

[0.9584517589850021 0.8174233175740566 … 0.9910216988605751 0.7495183029598291]

[0.9904786649251711 0.8726937832930126 … 0.9013306936542429 0.7859714462719325], CartesianIndex{3}[CartesianIndex(5, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(6, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(7, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(4, 7, 2) CartesianIndex(6, 8, 2)]

CartesianIndex{3}[CartesianIndex(2, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(1, 7, 3) CartesianIndex(2, 8, 3)]

CartesianIndex{3}[CartesianIndex(5, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(1, 7, 4) CartesianIndex(6, 8, 4)]

CartesianIndex{3}[CartesianIndex(3, 1, 5) CartesianIndex(8, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(4, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(5, 2, 6) … CartesianIndex(1, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(3, 1, 7) CartesianIndex(4, 2, 7) … CartesianIndex(1, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(2, 7, 8) CartesianIndex(4, 8, 8)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.20634341544778478 0.14287603651602288 … 0.05368136663405365 0.4023852431485908]

[0.03452908521415465 0.14346357816810418 … 0.13684374002421618 0.4185368132390723]

[0.04795271921162958 0.03271982709435961 … 0.025172527473980244 0.021990843101291846]

[0.030213026871790616 0.262496466469041 … 0.07315600492166974 0.2787263223479137]

[0.13345933552756573 0.06608586982188713 … 0.15115560573525877 0.03625875001840906]

[0.13730028739232747 0.09866833320669888 … 0.2570105389028263 0.05475731910551862]

[0.12217826579289581 0.0686169187887069 … 0.22370966702515238 0.03499732545462231]

[0.1363023038710922 0.11668425759029777 … 0.010753423801240336 0.0511293610535315], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(4, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(1, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(6, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(1, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(6, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)]) == ([0.20634341544778478 0.14287603651602288 … 0.05368136663405365 0.4023852431485908]

[0.03452908521415465 0.14346357816810418 … 0.13684374002421618 0.4185368132390723]

[0.04795271921162958 0.3378772175731146 … 0.025172527473980244 0.021990843101291846]

[0.030213026871790616 0.17477441028334595 … 0.07315600492166974 0.2787263223479137]

[0.13345933552756573 0.06608586982188713 … 0.15115560573525877 0.03625875001840906]

[0.13730028739232747 0.09866833320669888 … 0.2570105389028263 0.05475731910551862]

[0.12217826579289581 0.0686169187887069 … 0.22370966702515238 0.03499732545462231]

[0.1363023038710922 0.11668425759029777 … 0.010753423801240336 0.0511293610535315], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(4, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(5, 8, 2)]

CartesianIndex{3}[CartesianIndex(4, 1, 3) CartesianIndex(1, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(1, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(3, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(4, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(4, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(1, 2, 6) … CartesianIndex(7, 7, 6) CartesianIndex(5, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(6, 7, 7) CartesianIndex(4, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(5, 8, 8)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 8, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 1, 1); CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 6, 2)]

CartesianIndex{3}[CartesianIndex(1, 7, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 1, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 6, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 6, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 4, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)] == CartesianIndex{3}[CartesianIndex(1, 8, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 1, 1); CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 6, 2)]

CartesianIndex{3}[CartesianIndex(1, 7, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 1, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 6, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 6, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 4, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 4, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 5, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 5, 4)]

CartesianIndex{3}[CartesianIndex(1, 6, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 6, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 8, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 4, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 6, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 4, 8); CartesianIndex(8, 6, 8)] == CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 4, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 5, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 5, 4)]

CartesianIndex{3}[CartesianIndex(1, 6, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 6, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 8, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 4, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 6, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 4, 8); CartesianIndex(8, 6, 8)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.7816038569991239; 0.8586865852257355; … ; 0.6776139655839566; 0.9827823792376333]

[0.8006812549046782; 0.8500620162715649; … ; 0.996024589201796; 0.9847236987325565]

[0.9963910048571323; 0.8869740712193446; … ; 0.8876421209959995; 0.8435192338902457]

[0.8466147534415893; 0.954963573556006; … ; 0.7519982178614304; 0.9742081547117187]

[0.7609736364179487; 0.7810278403357642; … ; 0.8681388495622862; 0.8945977142656028]

[0.9381361127565242; 0.8149060316784615; … ; 0.8167173503433771; 0.8357216892701411]

[0.9910216988605751; 0.9988199289527331; … ; 0.8291930717123188; 0.9710429565941592]

[0.6996465489674464; 0.9772160135957104; … ; 0.9904786649251711; 0.7493878830593854], CartesianIndex{3}[CartesianIndex(1, 8, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 1, 1); CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 6, 2)]

CartesianIndex{3}[CartesianIndex(1, 7, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 1, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 6, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 6, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 4, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)]) == ([0.7816038569991239; 0.8586865852257355; … ; 0.6776139655839566; 0.9827823792376333]

[0.8006812549046782; 0.8500620162715649; … ; 0.996024589201796; 0.9847236987325565]

[0.9963910048571323; 0.8869740712193446; … ; 0.8876421209959995; 0.8435192338902457]

[0.8466147534415893; 0.6653652721273571; … ; 0.7519982178614304; 0.9742081547117187]

[0.7609736364179487; 0.7810278403357642; … ; 0.8681388495622862; 0.8945977142656028]

[0.9381361127565242; 0.8149060316784615; … ; 0.8167173503433771; 0.8357216892701411]

[0.9910216988605751; 0.9988199289527331; … ; 0.8291930717123188; 0.9710429565941592]

[0.6996465489674464; 0.9772160135957104; … ; 0.9904786649251711; 0.7493878830593854], CartesianIndex{3}[CartesianIndex(1, 8, 1); CartesianIndex(2, 6, 1); … ; CartesianIndex(7, 1, 1); CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 3, 2); CartesianIndex(8, 6, 2)]

CartesianIndex{3}[CartesianIndex(1, 7, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 2, 3); CartesianIndex(8, 2, 3)]

CartesianIndex{3}[CartesianIndex(1, 7, 4); CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 2, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 4, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 1, 6); CartesianIndex(2, 6, 6); … ; CartesianIndex(7, 6, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 7, 7); CartesianIndex(2, 6, 7); … ; CartesianIndex(7, 4, 7); CartesianIndex(8, 4, 7)]

CartesianIndex{3}[CartesianIndex(1, 3, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.07988410387499334; 0.24244602161615236; … ; 0.021909035554606326; 0.14237523601021573]

[0.20145267671769207; 0.16169393340226756; … ; 0.028461171596630308; 0.08949548585180533]

[0.021990843101291846; 0.026875178939471667; … ; 0.0778699863791954; 0.05431405649709009]

[0.008813163171450755; 0.09205858981927317; … ; 0.030213026871790616; 0.0799275376101769]

[0.06293116796741627; 0.16504354230358032; … ; 0.055444971836610124; 0.13054163089537174]

[0.07736866301343448; 0.08568429598786675; … ; 0.05367761416752059; 0.07023060439729156]

[0.011911552641358458; 0.22733708103631267; … ; 0.06783558683696889; 0.06981766525126076]

[0.06094258198886093; 0.09299716289813187; … ; 0.0021586147758663188; 0.31413195855363774], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 4, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 5, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 5, 4)]

CartesianIndex{3}[CartesianIndex(1, 6, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 6, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 8, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 4, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 6, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 4, 8); CartesianIndex(8, 6, 8)]) == ([0.07988410387499334; 0.24244602161615236; … ; 0.021909035554606326; 0.14237523601021573]

[0.20145267671769207; 0.16169393340226756; … ; 0.028461171596630308; 0.08949548585180533]

[0.021990843101291846; 0.026875178939471667; … ; 0.0778699863791954; 0.05431405649709009]

[0.008813163171450755; 0.09205858981927317; … ; 0.030213026871790616; 0.0799275376101769]

[0.06293116796741627; 0.16504354230358032; … ; 0.055444971836610124; 0.13054163089537174]

[0.07736866301343448; 0.08568429598786675; … ; 0.05367761416752059; 0.07023060439729156]

[0.011911552641358458; 0.22733708103631267; … ; 0.06783558683696889; 0.06981766525126076]

[0.06094258198886093; 0.09299716289813187; … ; 0.0021586147758663188; 0.31413195855363774], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 4, 1)]

CartesianIndex{3}[CartesianIndex(1, 7, 2); CartesianIndex(2, 1, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 5, 2)]

CartesianIndex{3}[CartesianIndex(1, 8, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 5, 4); CartesianIndex(2, 7, 4); … ; CartesianIndex(7, 1, 4); CartesianIndex(8, 5, 4)]

CartesianIndex{3}[CartesianIndex(1, 6, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 6, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 8, 6); CartesianIndex(2, 4, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 4, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 6, 7); CartesianIndex(8, 3, 7)]

CartesianIndex{3}[CartesianIndex(1, 6, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 4, 8); CartesianIndex(8, 6, 8)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 3) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 4) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 1)] == CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 3) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 1)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:52
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 3); CartesianIndex(2, 1, 4) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 1) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 5)] == CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 3); CartesianIndex(2, 1, 4) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 1) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 5)]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:53
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9381361127565242 0.6682627279346713 … 0.9963910048571323 0.8006812549046782; 0.8869740712193446 0.954963573556006 … 0.9013306936542429 0.8451588185336074; … ; 0.9904786649251711 0.8876421209959995 … 0.7024641665554321 0.6765420474669772; 0.7071709803128796 0.9742081547117187 … 0.8513749968989226 0.9827823792376333], CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 3) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 4) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 1)]) == ([0.9381361127565242 0.6682627279346713 … 0.9963910048571323 0.8006812549046782; 0.8869740712193446 0.704862145963528 … 0.9013306936542429 0.8451588185336074; … ; 0.9904786649251711 0.8876421209959995 … 0.7024641665554321 0.6765420474669772; 0.7071709803128796 0.9742081547117187 … 0.8513749968989226 0.9827823792376333], CartesianIndex{3}[CartesianIndex(1, 1, 6) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 3) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 3) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 8) CartesianIndex(2, 8, 3); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 3) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 7) CartesianIndex(8, 8, 1)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:54
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.1363023038710922 0.09866833320669888 … 0.20145267671769207 0.021990843101291846; 0.12948527985365543 0.16504354230358032 … 0.026875178939471667 0.360958338298756; … ; 0.030213026871790616 0.3131731250484806 … 0.010753423801240336 0.3458376915379855; 0.13593336262316935 0.14346357816810418 … 0.32034087195251115 0.42823427325232144], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 3); CartesianIndex(2, 1, 4) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 1) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 5)]) == ([0.1363023038710922 0.09866833320669888 … 0.20145267671769207 0.021990843101291846; 0.12948527985365543 0.16504354230358032 … 0.026875178939471667 0.360958338298756; … ; 0.030213026871790616 0.3131731250484806 … 0.010753423801240336 0.3458376915379855; 0.13593336262316935 0.14346357816810418 … 0.32034087195251115 0.42823427325232144], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 6) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 3); CartesianIndex(2, 1, 4) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 3) CartesianIndex(2, 8, 6); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 1) … CartesianIndex(7, 7, 8) CartesianIndex(7, 8, 4); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 5)])
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:55
 [2] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/cuarray.jl:4
 64.190282 seconds (45.27 M allocations: 2.318 GiB, 3.02% gc time)

Stacktrace:
 [1] sum(::KnetArray{Float32,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,3}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,3}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  

Stacktrace:
 [1] sum(::KnetArray{Float32,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,3}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,3}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float32,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  

Stacktrace:
 [1] sum(::KnetArray{Float32,4}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,4}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,4}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,4}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,4},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,4},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float32,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float32,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,4}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,4}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,4}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,4}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float32,4},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float32,4},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float32,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float32,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  

Stacktrace:
 [1] sum(::KnetArray{Float64,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,3}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,3}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  

Stacktrace:
 [1] sum(::KnetArray{Float64,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,3}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,3}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,3}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,3}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,3},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,3},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float64,3},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  

Stacktrace:
 [1] sum(::KnetArray{Float64,4}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float64,4}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float64,4}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,4},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,4},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{KnetArray{Float64,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
  Test threw exception
  Expression: gradcheck(bmmul1, w)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{KnetArray{Float64,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float64,4}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float64,4}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float64,4}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{KnetArray{Float64,4},1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{KnetArray{Float64,4},1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#bmmul1#99",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#bmmul1#99", ::Array{KnetArray{Float64,4},1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{KnetArray{Float64,4},1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:30
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
  
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:5
  Got exception outside of a @test
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61 [inlined]
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Tuple{Int64,Int64,Int64}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:38
   [37] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [38] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/bmm.jl:6
   [39] include(::String) at ./client.jl:444
   [40] macro expansion at ./timing.jl:174 [inlined]
   [41] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:15 [inlined]
   [42] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [43] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
   [44] include(::String) at ./client.jl:444
   [45] top-level scope at none:6
   [46] eval(::Module, ::Any) at ./boot.jl:331
   [47] exec_options(::Base.JLOptions) at ./client.jl:260
   [48] _start() at ./client.jl:485
  
 27.777257 seconds (21.48 M allocations: 1.099 GiB, 2.16% gc time)

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul#108",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul#108", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:19
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:19
  Test threw exception
  Expression: gradcheck(mmul, (ka, kb))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul#108", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:19
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul#108",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul#108", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:19
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulABt#109",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmulABt#109", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:24
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:24
  Test threw exception
  Expression: gradcheck(mmulABt, (ka, kb'))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmulABt#109", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:24
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulABt#109",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmulABt#109", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:24
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulAtB#110",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmulAtB#110", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:25
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:25
  Test threw exception
  Expression: gradcheck(mmulAtB, (ka', kb))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmulAtB#110", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:25
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulAtB#110",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmulAtB#110", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:25
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulAtBt#111",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmulAtBt#111", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:26
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:26
  Test threw exception
  Expression: gradcheck(mmulAtBt, (ka', kb'))
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmulAtBt#111", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:26
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmulAtBt#111",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmulAtBt#111", ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Tuple{KnetArray{Float32,2},KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:26
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},typeof(transpose),Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::typeof(transpose), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:59
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:59
  Test threw exception
  Expression: gradcheck(transpose, ka)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(transpose), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:59
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},typeof(transpose),Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::typeof(transpose), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:59
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:63
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:63
  Test threw exception
  Expression: gradcheck(mmul1, Any[kat, kb])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:63
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:63
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:64
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:64
  Test threw exception
  Expression: gradcheck(mmul2, Any[ka, kbt])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:64
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:64
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:65
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:65
  Test threw exception
  Expression: gradcheck(mmul3, Any[kat, kbt])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:65
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:65
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
 [6] (::var"#mmul1#112")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:43
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:66
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:66
  Test threw exception
  Expression: gradcheck(mmul1, Any[ka, s])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:66
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
   [6] (::var"#mmul1#112")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:43
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:66
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
 [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [6] (::var"#mmul1#112")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:43
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:67
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:67
  Test threw exception
  Expression: gradcheck(mmul1, Any[s, kb])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:67
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
   [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [6] (::var"#mmul1#112")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:43
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul1#112",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul1#112", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:67
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
 [6] (::var"#mmul2#113")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:44
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:68
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:68
  Test threw exception
  Expression: gradcheck(mmul2, Any[ka, s])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:68
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
   [6] (::var"#mmul2#113")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:44
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:68
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
 [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [6] (::var"#mmul2#113")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:44
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:69
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:69
  Test threw exception
  Expression: gradcheck(mmul2, Any[s, kb])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:69
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
   [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [6] (::var"#mmul2#113")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:44
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul2#113",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul2#113", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:69
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
 [6] (::var"#mmul3#114")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:45
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:70
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:70
  Test threw exception
  Expression: gradcheck(mmul3, Any[ka, s])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:70
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::KnetArray{Float32,2}, ::Float32) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:305
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{KnetArray{Float32,2}}, ::AutoGrad.Result{Float32}) at ./none:0
   [6] (::var"#mmul3#114")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:45
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:70
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
 [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
 [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [6] (::var"#mmul3#114")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:45
 [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:71
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:71
  Test threw exception
  Expression: gradcheck(mmul3, Any[s, kb])
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:71
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] broadcasted(::typeof(*), ::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:31
   [2] *(::Float32, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/binary.jl:306
   [3] forw(::Function, ::AutoGrad.Result{Float32}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] *(::AutoGrad.Result{Float32}, ::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [6] (::var"#mmul3#114")(::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:45
   [7] gcsum(::Function, ::Param{Array{Any,1}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [8] gcsum(::Function, ::Param{Array{Any,1}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},var"#mmul3#114",Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::var"#mmul3#114", ::Array{Any,1}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::Array{Any,1}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:71
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
 [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
 [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [5] #sum#75 at ./none:0 [inlined]
 [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
 [7] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
 [8] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [9] (::AutoGrad.var"#217#219"{Tuple{},typeof(mat),Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [12] gradcheck(::typeof(mat), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [13] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:77
 [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [17] include(::String) at ./client.jl:444
 [18] macro expansion at ./timing.jl:174 [inlined]
 [19] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [20] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [21] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [22] include(::String) at ./client.jl:444
 [23] top-level scope at none:6
 [24] eval(::Module, ::Any) at ./boot.jl:331
 [25] exec_options(::Base.JLOptions) at ./client.jl:260
 [26] _start() at ./client.jl:485
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:77
  Test threw exception
  Expression: gradcheck(mat, ka)
  UndefVarError: lib not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(mat), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:77
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  UndefVarError: lib not defined
  Stacktrace:
   [1] sum(::KnetArray{Float32,2}; dims::Function) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:30
   [2] sum(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/reduction.jl:29
   [3] forw(::Function, ::AutoGrad.Result{KnetArray{Float32,2}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [4] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [5] #sum#75 at ./none:0 [inlined]
   [6] sum(::AutoGrad.Result{KnetArray{Float32,2}}) at ./none:0
   [7] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:57
   [8] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [9] (::AutoGrad.var"#217#219"{Tuple{},typeof(mat),Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [10] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [11] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [12] gradcheck(::typeof(mat), ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [13] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [14] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:77
   [15] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [16] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:84
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p2#115"{Array{Int64,1}})(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:84
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p2#115"{Array{Int64,1}})(::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
 [40] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p2#115"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
  Test threw exception
  Expression: gradcheck(p2, ka)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p2#115"{Array{Int64,1}})(::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
   [40] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p2#115"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:84
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p2#115"{Array{Int64,1}})(::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:84
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p2#115"{Array{Int64,1}})(::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
 [40] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p2#115"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
  Test threw exception
  Expression: gradcheck(p2, ka)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float32,2,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float32,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float32,2,Nothing}, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float32,2}, ::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float32,2}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float32,2}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p2#115"{Array{Int64,1}})(::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:81
   [40] gcsum(::Function, ::Param{KnetArray{Float32,2}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float32,2}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p2#115"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p2#115"{Array{Int64,1}}, ::KnetArray{Float32,2}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float32,2}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:85
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49 [inlined]
   [36] (::var"#p3#116"{Array{Int64,1}})(::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [37] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:95
   [38] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [39] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  

Stacktrace:
 [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
 [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
 [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
 [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
 [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
 [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
 [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
 [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
 [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
 [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
 [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
 [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
 [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
 [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
 [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
 [18] get! at ./dict.jl:450 [inlined]
 [19] macro expansion at ./lock.jl:183 [inlined]
 [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
 [21] + at ./int.jl:87 [inlined]
 [22] hash_64_64 at ./hashing.jl:35 [inlined]
 [23] hash_uint64 at ./hashing.jl:62 [inlined]
 [24] hx at ./float.jl:568 [inlined]
 [25] hash at ./float.jl:571 [inlined]
 [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
 [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
 [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
 [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
 [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
 [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
 [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
 [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
 [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
 [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
 [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
 [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
 [38] permutedims at ./none:0 [inlined]
 [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
 [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
 [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
 [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
 [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
 [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
 [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
 [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
 [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
 [50] include(::String) at ./client.jl:444
 [51] macro expansion at ./timing.jl:174 [inlined]
 [52] macro expansion at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:16 [inlined]
 [53] macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
 [54] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/runtests.jl:6
 [55] include(::String) at ./client.jl:444
 [56] top-level scope at none:6
 [57] eval(::Module, ::Any) at ./boot.jl:331
 [58] exec_options(::Base.JLOptions) at ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
  Test threw exception
  Expression: gradcheck(p3, k3)
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:148
   [2] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [3] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [4] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [5] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [6] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [7] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  caused by [exception 1]
  MethodError: no method matching inf_for_methodinstance(::Core.MethodInstance, ::UInt64, ::UInt64)
  Closest candidates are:
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64) at compiler/utilities.jl:121
    inf_for_methodinstance(!Matched::Core.Compiler.AbstractInterpreter, !Matched::Core.MethodInstance, ::UInt64, !Matched::UInt64) at compiler/utilities.jl:121
  Stacktrace:
   [1] compile_method_instance(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:138
   [2] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [3] irgen(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/irgen.jl:326
   [4] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [5] macro expansion at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:98 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/NvIUx/src/TimerOutput.jl:245 [inlined]
   [7] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:97
   [8] emit_function!(::LLVM.Module, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:100
   [9] build_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:135
   [10] (::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:175
   [11] get!(::GPUCompiler.var"#52#55"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams},String,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [12] load_runtime(::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/rtlib.jl:167
   [13] codegen(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:93
   [14] compile(::Symbol, ::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDAnative.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/driver.jl:36
   [15] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:308
   [16] _cufunction(::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:302
   [17] (::GPUCompiler.var"#77#78"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CUDAnative._cufunction),GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}})() at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:21
   [18] get! at ./dict.jl:450 [inlined]
   [19] macro expansion at ./lock.jl:183 [inlined]
   [20] check_cache(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:19
   [21] + at ./int.jl:87 [inlined]
   [22] hash_64_64 at ./hashing.jl:35 [inlined]
   [23] hash_uint64 at ./hashing.jl:62 [inlined]
   [24] hx at ./float.jl:568 [inlined]
   [25] hash at ./float.jl:571 [inlined]
   [26] cached_compilation(::typeof(CUDAnative._cufunction), ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:0
   [27] cached_compilation(::Function, ::GPUCompiler.FunctionSpec{GPUArrays.var"#50#51",Tuple{CuArrays.CuKernelContext,CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},CUDAnative.CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64}}}, ::UInt64) at /home/pkgeval/.julia/packages/GPUCompiler/bwcs0/src/cache.jl:33
   [28] cufunction(::Function, ::Type{T} where T; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:296
   [29] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/e0IdN/src/execution.jl:108 [inlined]
   [30] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArrays.CuArray{Float64,3,Nothing},CuArrays.CuArray{Float64,3,Nothing},Tuple{Int64,Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/l0gXB/src/gpuarrays.jl:32
   [31] gpu_call(::Function, ::CuArrays.CuArray{Float64,3,Nothing}, ::Vararg{Any,N} where N; target::CuArrays.CuArray{Float64,3,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:61
   [32] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/device/execution.jl:46 [inlined]
   [33] permutedims!(::CuArrays.CuArray{Float64,3,Nothing}, ::CuArrays.CuArray{Float64,3,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/JqOUg/src/host/linalg.jl:196
   [34] permutedims!(::KnetArray{Float64,3}, ::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:40
   [35] permutedims(::KnetArray{Float64,3}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/Knet/bTNMd/src/cuarray.jl:49
   [36] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:66
   [37] forw at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:65 [inlined]
   [38] permutedims at ./none:0 [inlined]
   [39] (::var"#p3#116"{Array{Int64,1}})(::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:92
   [40] gcsum(::Function, ::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [41] gcsum(::Function, ::Param{KnetArray{Float64,3}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:50
   [42] (::AutoGrad.var"#217#219"{Tuple{},var"#p3#116"{Array{Int64,1}},Array{Any,1}})() at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:205
   [43] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:144
   [44] differentiate at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]
   [45] gradcheck(::var"#p3#116"{Array{Int64,1}}, ::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:39
   [46] gradcheck(::Function, ::KnetArray{Float64,3}) at /home/pkgeval/.julia/packages/AutoGrad/6QsMu/test/gradcheck.jl:36
   [47] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:96
   [48] top-level scope at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
   [49] top-level scope at /home/pkgeval/.julia/packages/Knet/bTNMd/test/linalg.jl:8
  
