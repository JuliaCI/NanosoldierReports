Julia Version 1.5.2-pre.0
Commit c4acbf93fb (2020-08-26 10:58 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed Requires ───────────────────── v1.0.1
  Installed UnPack ─────────────────────── v1.0.2
  Installed Distances ──────────────────── v0.9.0
  Installed DiffEqFlux ─────────────────── v1.21.0
  Installed ChainRulesCore ─────────────── v0.9.6
  Installed IterativeSolvers ───────────── v0.8.4
  Installed Zygote ─────────────────────── v0.5.5
  Installed CpuId ──────────────────────── v0.2.2
  Installed FunctionWrappers ───────────── v1.1.1
  Installed RecursiveArrayTools ────────── v2.6.0
  Installed OrderedCollections ─────────── v1.3.0
  Installed CommonSubexpressions ───────── v0.3.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed ReverseDiff ────────────────── v1.4.2
  Installed ZipFile ────────────────────── v0.9.2
  Installed Flux ───────────────────────── v0.11.1
  Installed Missings ───────────────────── v0.4.3
  Installed ExponentialUtilities ───────── v1.8.0
  Installed SIMDPirates ────────────────── v0.8.24
  Installed GPUArrays ──────────────────── v5.1.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed CEnum ──────────────────────── v0.4.1
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed Compat ─────────────────────── v3.14.0
  Installed ArrayInterface ─────────────── v2.12.0
  Installed SpatialIndexing ────────────── v0.1.2
  Installed FixedPointNumbers ──────────── v0.8.4
  Installed LoopVectorization ──────────── v0.8.24
  Installed ChainRules ─────────────────── v0.7.14
  Installed ArrayLayouts ───────────────── v0.3.8
  Installed Rmath ──────────────────────── v0.6.1
  Installed RecursiveFactorization ─────── v0.1.4
  Installed TranscodingStreams ─────────── v0.9.5
  Installed RecipesBase ────────────────── v1.0.2
  Installed DiffEqSensitivity ──────────── v6.31.1
  Installed LLVM ───────────────────────── v2.0.0
  Installed CUDA ───────────────────────── v1.3.3
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed LeftChildRightSiblingTrees ─── v0.1.2
  Installed ProgressMeter ──────────────── v1.3.2
  Installed StatsFuns ──────────────────── v0.9.5
  Installed DiffEqNoiseProcess ─────────── v5.3.0
  Installed VectorizationBase ──────────── v0.12.32
  Installed LineSearches ───────────────── v7.1.0
  Installed ColorTypes ─────────────────── v0.10.8
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Reexport ───────────────────── v0.2.0
  Installed LoggingExtras ──────────────── v0.4.2
  Installed LabelledArrays ─────────────── v1.3.0
  Installed QuadGK ─────────────────────── v2.4.1
  Installed IRTools ────────────────────── v0.4.0
  Installed NNlib ──────────────────────── v0.7.4
  Installed VertexSafeGraphs ───────────── v0.1.2
  Installed GenericSVD ─────────────────── v0.3.0
  Installed SortingAlgorithms ──────────── v0.3.1
  Installed CPUTime ────────────────────── v1.0.0
  Installed ConsoleProgressMonitor ─────── v0.1.2
  Installed IteratorInterfaceExtensions ── v1.0.0
  Installed DiffEqJump ─────────────────── v6.10.1
  Installed Tracker ────────────────────── v0.2.11
  Installed Parameters ─────────────────── v0.12.1
  Installed FFTW ───────────────────────── v1.2.4
  Installed RandomNumbers ──────────────── v1.4.0
  Installed Media ──────────────────────── v0.5.0
  Installed ResettableStacks ───────────── v1.0.0
  Installed Roots ──────────────────────── v1.0.5
  Installed DataStructures ─────────────── v0.17.20
  Installed StaticArrays ───────────────── v0.12.4
  Installed StochasticDiffEq ───────────── v6.25.0
  Installed Sobol ──────────────────────── v1.4.0
  Installed NaNMath ────────────────────── v0.3.4
  Installed GPUCompiler ────────────────── v0.6.0
  Installed AbstractTrees ──────────────── v0.3.3
  Installed BlackBoxOptim ──────────────── v0.5.0
  Installed ForwardDiff ────────────────── v0.10.12
  Installed PoissonRandom ──────────────── v0.4.0
  Installed PDMats ─────────────────────── v0.10.0
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed Rmath_jll ──────────────────── v0.2.2+1
  Installed MuladdMacro ────────────────── v0.2.2
  Installed FiniteDiff ─────────────────── v2.6.0
  Installed DiffRules ──────────────────── v1.0.1
  Installed SparseDiffTools ────────────── v1.10.0
  Installed SLEEFPirates ───────────────── v0.5.5
  Installed LightGraphs ────────────────── v1.3.3
  Installed ZygoteRules ────────────────── v0.2.0
  Installed Adapt ──────────────────────── v2.0.2
  Installed Functors ───────────────────── v0.1.0
  Installed DataAPI ────────────────────── v1.3.0
  Installed FillArrays ─────────────────── v0.8.14
  Installed ProgressLogging ────────────── v0.1.3
  Installed OffsetArrays ───────────────── v1.1.2
  Installed TerminalLoggers ────────────── v0.1.2
  Installed FastClosures ───────────────── v0.3.2
  Installed ExprTools ──────────────────── v0.1.1
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed TreeViews ──────────────────── v0.3.0
  Installed TimerOutputs ───────────────── v0.5.6
  Installed Juno ───────────────────────── v0.8.3
  Installed ArnoldiMethod ──────────────── v0.0.4
  Installed SimpleTraits ───────────────── v0.9.3
  Installed DiffResults ────────────────── v1.0.2
  Installed DistributionsAD ────────────── v0.6.4
  Installed SpecialFunctions ───────────── v0.10.3
  Installed StatsBase ──────────────────── v0.33.0
  Installed DocStringExtensions ────────── v0.8.2
  Installed OrdinaryDiffEq ─────────────── v5.42.3
  Installed Optim ──────────────────────── v0.22.0
  Installed PositiveFactorizations ─────── v0.2.3
  Installed NLSolversBase ──────────────── v7.7.0
  Installed DiffEqCallbacks ────────────── v2.13.5
  Installed TableTraits ────────────────── v1.0.0
  Installed QuasiMonteCarlo ────────────── v0.2.0
  Installed DiffEqBase ─────────────────── v6.45.1
  Installed Distributions ──────────────── v0.23.8
  Installed Inflate ────────────────────── v0.1.2
  Installed NLsolve ────────────────────── v4.4.1
  Installed Colors ─────────────────────── v0.12.4
  Installed LatinHypercubeSampling ─────── v1.6.4
Updating `~/.julia/environments/v1.5/Project.toml`
  [aae7a2af] + DiffEqFlux v1.21.0
Updating `~/.julia/environments/v1.5/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [1520ce14] + AbstractTrees v0.3.3
  [79e6a3ab] + Adapt v2.0.2
  [ec485272] + ArnoldiMethod v0.0.4
  [4fba245c] + ArrayInterface v2.12.0
  [4c555306] + ArrayLayouts v0.3.8
  [b99e7846] + BinaryProvider v0.5.10
  [a134a8b2] + BlackBoxOptim v0.5.0
  [fa961155] + CEnum v0.4.1
  [a9c8d775] + CPUTime v1.0.0
  [052768ef] + CUDA v1.3.3
  [082447d4] + ChainRules v0.7.14
  [d360d2e6] + ChainRulesCore v0.9.6
  [944b1d66] + CodecZlib v0.7.0
  [3da002f7] + ColorTypes v0.10.8
  [5ae59095] + Colors v0.12.4
  [bbf7d656] + CommonSubexpressions v0.3.0
  [34da2185] + Compat v3.14.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [88cd18e8] + ConsoleProgressMonitor v0.1.2
  [adafc99b] + CpuId v0.2.2
  [9a962f9c] + DataAPI v1.3.0
  [864edb3b] + DataStructures v0.17.20
  [2b5f629d] + DiffEqBase v6.45.1
  [459566f4] + DiffEqCallbacks v2.13.5
  [aae7a2af] + DiffEqFlux v1.21.0
  [c894b116] + DiffEqJump v6.10.1
  [77a26b50] + DiffEqNoiseProcess v5.3.0
  [41bf760c] + DiffEqSensitivity v6.31.1
  [163ba53b] + DiffResults v1.0.2
  [b552c78f] + DiffRules v1.0.1
  [b4f34e82] + Distances v0.9.0
  [31c24e10] + Distributions v0.23.8
  [ced4e74d] + DistributionsAD v0.6.4
  [ffbed154] + DocStringExtensions v0.8.2
  [d4d017d3] + ExponentialUtilities v1.8.0
  [e2ba6199] + ExprTools v0.1.1
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+5
  [9aa1b823] + FastClosures v0.3.2
  [1a297f60] + FillArrays v0.8.14
  [6a86dc24] + FiniteDiff v2.6.0
  [53c48c17] + FixedPointNumbers v0.8.4
  [587475ba] + Flux v0.11.1
  [f6369f11] + ForwardDiff v0.10.12
  [069b7b12] + FunctionWrappers v1.1.1
  [d9f16b24] + Functors v0.1.0
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [01680d73] + GenericSVD v0.3.0
  [7869d1d1] + IRTools v0.4.0
  [d25df0c9] + Inflate v0.1.2
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [42fd0dbc] + IterativeSolvers v0.8.4
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [e5e0dc1b] + Juno v0.8.3
  [929cbde3] + LLVM v2.0.0
  [2ee39098] + LabelledArrays v1.3.0
  [a5e1c1ea] + LatinHypercubeSampling v1.6.4
  [1d6d02ad] + LeftChildRightSiblingTrees v0.1.2
  [093fc24a] + LightGraphs v1.3.3
  [d3d80556] + LineSearches v7.1.0
  [e6f89c97] + LoggingExtras v0.4.2
  [bdcacae8] + LoopVectorization v0.8.24
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.5
  [e89f7d12] + Media v0.5.0
  [e1d29d7a] + Missings v0.4.3
  [46d2c3a1] + MuladdMacro v0.2.2
  [d41bc354] + NLSolversBase v7.7.0
  [2774e3e8] + NLsolve v4.4.1
  [872c559c] + NNlib v0.7.4
  [77ba4419] + NaNMath v0.3.4
  [6fe1bfb0] + OffsetArrays v1.1.2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [429524aa] + Optim v0.22.0
  [bac558e1] + OrderedCollections v1.3.0
  [1dea7af3] + OrdinaryDiffEq v5.42.3
  [90014a1f] + PDMats v0.10.0
  [d96e819e] + Parameters v0.12.1
  [e409e4f3] + PoissonRandom v0.4.0
  [85a6dd25] + PositiveFactorizations v0.2.3
  [33c8b6b6] + ProgressLogging v0.1.3
  [92933f4c] + ProgressMeter v1.3.2
  [1fd47b50] + QuadGK v2.4.1
  [8a4e6c94] + QuasiMonteCarlo v0.2.0
  [e6cf234a] + RandomNumbers v1.4.0
  [3cdcf5f2] + RecipesBase v1.0.2
  [731186ca] + RecursiveArrayTools v2.6.0
  [f2c3362d] + RecursiveFactorization v0.1.4
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [ae5879a3] + ResettableStacks v1.0.0
  [37e2e3b7] + ReverseDiff v1.4.2
  [79098fc4] + Rmath v0.6.1
  [f50d1b31] + Rmath_jll v0.2.2+1
  [f2b01f46] + Roots v1.0.5
  [21efa798] + SIMDPirates v0.8.24
  [476501e8] + SLEEFPirates v0.5.5
  [699a6c99] + SimpleTraits v0.9.3
  [ed01d8cd] + Sobol v1.4.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [47a9eef4] + SparseDiffTools v1.10.0
  [d4ead438] + SpatialIndexing v0.1.2
  [276daf66] + SpecialFunctions v0.10.3
  [90137ffa] + StaticArrays v0.12.4
  [2913bbd2] + StatsBase v0.33.0
  [4c63d2b9] + StatsFuns v0.9.5
  [789caeaf] + StochasticDiffEq v6.25.0
  [3783bdb8] + TableTraits v1.0.0
  [5d786b92] + TerminalLoggers v0.1.2
  [a759f4b9] + TimerOutputs v0.5.6
  [9f7883ad] + Tracker v0.2.11
  [3bb67fe8] + TranscodingStreams v0.9.5
  [a2a6695c] + TreeViews v0.3.0
  [3a884ed6] + UnPack v1.0.2
  [3d5dd08c] + VectorizationBase v0.12.32
  [19fa3120] + VertexSafeGraphs v0.1.2
  [a5390f91] + ZipFile v0.9.2
  [83775a58] + Zlib_jll v1.2.11+15
  [e88e6eb3] + Zygote v0.5.5
  [700de1a5] + ZygoteRules v0.2.0
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [9fa8497b] + Future
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [9abbd945] + Profile
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [4607b0f0] + SuiteSparse
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building FFTW ────────→ `~/.julia/packages/FFTW/DMUbN/deps/build.log`
   Building SLEEFPirates → `~/.julia/packages/SLEEFPirates/jGsib/deps/build.log`
    Testing DiffEqFlux
Status `/tmp/jl_WfbWLE/Project.toml`
  [79e6a3ab] Adapt v2.0.2
  [a134a8b2] BlackBoxOptim v0.5.0
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [82cc6244] DataInterpolations v3.1.3
  [bcd4f6db] DelayDiffEq v5.24.1
  [2b5f629d] DiffEqBase v6.45.1
  [aae7a2af] DiffEqFlux v1.21.0
  [41bf760c] DiffEqSensitivity v6.31.1
  [163ba53b] DiffResults v1.0.2
  [b4f34e82] Distances v0.9.0
  [31c24e10] Distributions v0.23.8
  [ced4e74d] DistributionsAD v0.6.4
  [587475ba] Flux v0.11.1
  [f6369f11] ForwardDiff v0.10.12
  [7e08b658] GeometricFlux v0.6.2
  [e6f89c97] LoggingExtras v0.4.2
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v0.22.0
  [1dea7af3] OrdinaryDiffEq v5.42.3
  [33c8b6b6] ProgressLogging v0.1.3
  [731186ca] RecursiveArrayTools v2.6.0
  [ae029012] Requires v1.0.1
  [37e2e3b7] ReverseDiff v1.4.2
  [1bc83da4] SafeTestsets v0.0.1
  [90137ffa] StaticArrays v0.12.4
  [789caeaf] StochasticDiffEq v6.25.0
  [5d786b92] TerminalLoggers v0.1.2
  [9f7883ad] Tracker v0.2.11
  [e88e6eb3] Zygote v0.5.5
  [700de1a5] ZygoteRules v0.2.0
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_WfbWLE/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [1520ce14] AbstractTrees v0.3.3
  [79e6a3ab] Adapt v2.0.2
  [ec485272] ArnoldiMethod v0.0.4
  [4fba245c] ArrayInterface v2.12.0
  [4c555306] ArrayLayouts v0.3.8
  [b99e7846] BinaryProvider v0.5.10
  [a134a8b2] BlackBoxOptim v0.5.0
  [fa961155] CEnum v0.4.1
  [a9c8d775] CPUTime v1.0.0
  [052768ef] CUDA v1.3.3
  [082447d4] ChainRules v0.7.14
  [d360d2e6] ChainRulesCore v0.9.6
  [944b1d66] CodecZlib v0.7.0
  [3da002f7] ColorTypes v0.10.8
  [5ae59095] Colors v0.12.4
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.14.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [adafc99b] CpuId v0.2.2
  [9a962f9c] DataAPI v1.3.0
  [82cc6244] DataInterpolations v3.1.3
  [864edb3b] DataStructures v0.17.20
  [bcd4f6db] DelayDiffEq v5.24.1
  [2b5f629d] DiffEqBase v6.45.1
  [459566f4] DiffEqCallbacks v2.13.5
  [aae7a2af] DiffEqFlux v1.21.0
  [c894b116] DiffEqJump v6.10.1
  [77a26b50] DiffEqNoiseProcess v5.3.0
  [41bf760c] DiffEqSensitivity v6.31.1
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [b4f34e82] Distances v0.9.0
  [31c24e10] Distributions v0.23.8
  [ced4e74d] DistributionsAD v0.6.4
  [ffbed154] DocStringExtensions v0.8.2
  [d4d017d3] ExponentialUtilities v1.8.0
  [e2ba6199] ExprTools v0.1.1
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+5
  [9aa1b823] FastClosures v0.3.2
  [5789e2e9] FileIO v1.4.1
  [1a297f60] FillArrays v0.8.14
  [6a86dc24] FiniteDiff v2.6.0
  [53c48c17] FixedPointNumbers v0.8.4
  [587475ba] Flux v0.11.1
  [f6369f11] ForwardDiff v0.10.12
  [069b7b12] FunctionWrappers v1.1.1
  [d9f16b24] Functors v0.1.0
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [01680d73] GenericSVD v0.3.0
  [7e08b658] GeometricFlux v0.6.2
  [a1251efa] GraphLaplacians v0.1.0
  [3ebe565e] GraphSignals v0.1.1
  [7869d1d1] IRTools v0.4.0
  [d25df0c9] Inflate v0.1.2
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [42fd0dbc] IterativeSolvers v0.8.4
  [82899510] IteratorInterfaceExtensions v1.0.0
  [033835bb] JLD2 v0.1.14
  [e5e0dc1b] Juno v0.8.3
  [929cbde3] LLVM v2.0.0
  [2ee39098] LabelledArrays v1.3.0
  [a5e1c1ea] LatinHypercubeSampling v1.6.4
  [1d6d02ad] LeftChildRightSiblingTrees v0.1.2
  [093fc24a] LightGraphs v1.3.3
  [d3d80556] LineSearches v7.1.0
  [e6f89c97] LoggingExtras v0.4.2
  [bdcacae8] LoopVectorization v0.8.24
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e89f7d12] Media v0.5.0
  [626554b9] MetaGraphs v0.6.5
  [e1d29d7a] Missings v0.4.3
  [46d2c3a1] MuladdMacro v0.2.2
  [d41bc354] NLSolversBase v7.7.0
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [2774e3e8] NLsolve v4.4.1
  [872c559c] NNlib v0.7.4
  [77ba4419] NaNMath v0.3.4
  [6fe1bfb0] OffsetArrays v1.1.2
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.22.0
  [bac558e1] OrderedCollections v1.3.0
  [1dea7af3] OrdinaryDiffEq v5.42.3
  [90014a1f] PDMats v0.10.0
  [d96e819e] Parameters v0.12.1
  [e409e4f3] PoissonRandom v0.4.0
  [85a6dd25] PositiveFactorizations v0.2.3
  [33c8b6b6] ProgressLogging v0.1.3
  [92933f4c] ProgressMeter v1.3.2
  [1fd47b50] QuadGK v2.4.1
  [8a4e6c94] QuasiMonteCarlo v0.2.0
  [e6cf234a] RandomNumbers v1.4.0
  [3cdcf5f2] RecipesBase v1.0.2
  [731186ca] RecursiveArrayTools v2.6.0
  [f2c3362d] RecursiveFactorization v0.1.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [ae5879a3] ResettableStacks v1.0.0
  [37e2e3b7] ReverseDiff v1.4.2
  [79098fc4] Rmath v0.6.1
  [f50d1b31] Rmath_jll v0.2.2+1
  [f2b01f46] Roots v1.0.5
  [21efa798] SIMDPirates v0.8.24
  [476501e8] SLEEFPirates v0.5.5
  [1bc83da4] SafeTestsets v0.0.1
  [b1168b60] ScatterNNlib v0.1.1
  [699a6c99] SimpleTraits v0.9.3
  [47aef6b3] SimpleWeightedGraphs v1.1.1
  [ed01d8cd] Sobol v1.4.0
  [a2af1166] SortingAlgorithms v0.3.1
  [47a9eef4] SparseDiffTools v1.10.0
  [d4ead438] SpatialIndexing v0.1.2
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.0
  [4c63d2b9] StatsFuns v0.9.5
  [789caeaf] StochasticDiffEq v6.25.0
  [3783bdb8] TableTraits v1.0.0
  [5d786b92] TerminalLoggers v0.1.2
  [a759f4b9] TimerOutputs v0.5.6
  [9f7883ad] Tracker v0.2.11
  [3bb67fe8] TranscodingStreams v0.9.5
  [a2a6695c] TreeViews v0.3.0
  [3a884ed6] UnPack v1.0.2
  [3d5dd08c] VectorizationBase v0.12.32
  [19fa3120] VertexSafeGraphs v0.1.2
  [a5390f91] ZipFile v0.9.2
  [83775a58] Zlib_jll v1.2.11+15
  [e88e6eb3] Zygote v0.5.5
  [700de1a5] ZygoteRules v0.2.0
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [9abbd945] Profile
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [4607b0f0] SuiteSparse
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
┌ Warning: CUDA.jl found cuda, but did not find libcudnn. Some functionality will not be available.
└ @ Flux ~/.julia/packages/Flux/05b38/src/Flux.jl:56
┌ Warning: CUDA.jl found cuda, but did not find libcudnn. Some functionality will not be available.
└ @ Flux ~/.julia/packages/Flux/05b38/src/Flux.jl:56
Starting tests
416.7086995514811301.86465432569827213.21697213391016149.3929796071194115.2247517913104296.3438136311290279.3936123278511765.5625775751988754.73408970504229446.2626159904189439.55562467607837434.29338639796445430.54262397471921328.93102825992030330.78230280655101637.5616921386252547.3899178101139352.31771747076819448.8559023431533241.1409918445188933.4998573173513127.7136171838481823.8213532431337521.2574969683678819.43364473086034417.9080234863235616.40169427585258414.75827680393393112.9155083938401710.8813206837866058.7182734287630626.5317427624672214.45717155975515762.6440088213855261.23592071815229730.34657206429314730.032376452495214510.26367482940779230.905567097641851.72975726545156162.4738072183786732.93352765725007243.03618679634409672.84498125290393672.49864919108605132.1348949032518721.84171784634708581.64735382952383951.53548374223780541.46787860302471571.40348733006078131.31057624087927451.1723646987133380.98792068128521930.77000396330597080.54099857867771020.327773302321376360.156017818275280080.0445653704883056740.00091322139101779030.0190239786206280320.080410475436539270.159197271761418070.229589835455646730.27324885152407110.28364198270243850.26573545746272670.231707259387955280.195075966066423880.16585180213779310.148215404734272720.140797690163480650.13867239213660060.135911948945067140.127791420961522520.112133203758811030.089657382441687130.063454110359997350.037871264121909730.017167018654110830.0042911560636956050.000132331621225468740.0034254726393664930.0112719546828020260.020185633126746330.027176635651557520.0305475552150724330.0301433293399415230.027042574606087690.0228944748810245740.0192068480124802340.0168492892211720180.0158974341901012840.0157962049318957630.0157121461393411320.0149121397453862370.013034469259305310.0101844853779321530.0068527418229991870.00371107376408517140.41651472333630622.0574979950004412.0370170061059436.5135123950745713.44931932189921181.7559468701164440.84093619554414190.37442507954085170.168532382317527320.113993033837653730.146123430878245250.226085903016524930.330334854476624140.44453607046360510.55999043965512660.67148965890465460.77600896170330960.87189794211576280.95837284804221071.03519453504103541.102462468119151.1604809403635251.2096740246675781.2505296827649941.28356389938792611.3092977792750041.3282432671420641.3408945567685451.3477231917904121.34917568299961181.34567275651153921.33760965969436761.32535713923978181.30926283119076661.28965288718113881.26683371815545651.24109377565182391.21270532363075211.18192615543916561.14900120277133591.11416408494757111.0776385384441541.03963972907575551.00037545475925030.96004716055324730.91885085925083050.87697796780162950.83461578453768470.79194791465576250.7491546092974780.70641292726443780.66389667527127090.62177597710401310.58021695098207630.53938109283327550.49942448098243830.46049683701543230.422740446135237870.386288958824478560.351266106102598450.31778436152719740.28594358960323430.25582972628403930.227513541949103480.20104954040439650.17647504822376870.153809547487706370.133054301003206670.11419231258130050.097188655030507010.081991185732421780.068531653945972460.056727195199598220.0464821741737222950.037690330900355420.0302371660240337120.024002485214972780.018863008126808380.0146949697216094770.011376587915764770.008790320506736630.0068248311695943480.0053766232540579290.0043512582546466540.0036641684658992570.003241059631909680.00301792543950275570.00294072194226196620.0029647594934878470.00305388071927276130.00317949724857487840.0033195565264025470.0034575035527390830.00358129205678411840.0036824867525255790.0037554842797734490.00379686650199046730.0038048872648166380.00377908325254354550.003719992014970818416.70869955148316301.87186997430365213.22801705361297149.40648614478837115.2240412249364696.3454391345538679.3977976779125865.5678714713974554.73969630607274446.2681431647925939.5608383606454234.2980229596167530.54633410011867428.9332381463373130.78208250143966437.5587566610162847.3870414634704752.3184906512701248.8589544323429841.14383255919601433.5012140860317727.71329342894746323.81952936942857221.2543767187669819.4294856183711817.90303100693667616.39608500849614714.75230897079328312.90945584534311610.8754625577971288.712882525457966.5270686024001344.4534149599774862.6412962392444671.2342795663056390.3459158046638280.032506748634095760.264310414146053160.90639787468961761.7305156642179892.4743407762289472.9338239544033673.0363286740031682.84506488225275162.49872238818174442.13494430274363721.8416920826943291.6471951659831451.53515198186780831.46736343542057451.40280885504569251.30977827422533061.1715059590677530.98706641658549010.76921762520158130.54033333964074280.32726603243509670.155685347538229820.044402053227207340.00089265358725995560.0191039242369983630.080534769824929170.159307303717266780.229641600525029880.273224851436197740.283552996888048250.26561206968046450.23158584804701470.194985613398158870.165806707487119760.14821387238102470.140826097601411540.13871147379454670.135943057155115480.12780127946737040.112116466759106760.089616889144780110.063399129505176940.037814459743258160.017120978004210560.00426522788223897450.00013060182132885350.00344585479851722280.011306698777051870.0202248123961467770.02721155913652230.0305730930624841660.030158440940405340.027049241017987240.022895782224433470.0192051454721658860.016845112348903880.0158894783750984330.015782221974403340.015690315650227170.0148822708785586060.0129985681020147110.0101464819170533940.0068175358724189420.003683289147449469Test Summary: | Pass  Total
Layers Tests  |    6      6
Test Summary: | Pass  Total
Fast Layers   |    9      9
Training   0%|                                          |  ETA: N/A
494.2089032199091loss: 494   1%|▍                                        |  ETA: 0:10:50
416.7086995514831loss: 417   2%|▉                                        |  ETA: 0:05:29
301.87186997430365loss: 302   3%|█▎                                       |  ETA: 0:03:38
213.22801705361297loss: 213   4%|█▋                                       |  ETA: 0:02:43
149.40648614478843loss: 149   5%|██                                       |  ETA: 0:02:10
115.22404122493646loss: 115   6%|██▌                                      |  ETA: 0:01:47
96.34543913455384loss: 96.3   7%|██▊                                     |  ETA: 0:01:31
79.39779767791259loss: 79.4   8%|███▎                                    |  ETA: 0:01:19
65.56787147139745loss: 65.6   9%|███▋                                    |  ETA: 0:01:11
54.739696306072744loss: 54.7  10%|████                                    |  ETA: 0:01:03
46.26814316479258loss: 46.3  11%|████▍                                   |  ETA: 0:00:57
39.560838360645405loss: 39.6  12%|████▊                                   |  ETA: 0:00:52
34.298022959616745loss: 34.3  13%|█████▎                                  |  ETA: 0:00:47
30.54633410011867loss: 30.5  14%|█████▋                                  |  ETA: 0:00:44
28.933238146337313loss: 28.9  15%|██████                                  |  ETA: 0:00:40
30.78208250143967loss: 30.8  16%|██████▍                                 |  ETA: 0:00:38
37.55875666101628loss: 37.6  17%|██████▊                                 |  ETA: 0:00:35
47.38704146347047loss: 47.4  18%|███████▎                                |  ETA: 0:00:33
52.318490651270146loss: 52.3  19%|███████▋                                |  ETA: 0:00:31
48.85895443234298loss: 48.9  20%|████████                                |  ETA: 0:00:29
41.143832559196loss: 41.1  21%|████████▍                               |  ETA: 0:00:27
33.50121408603177loss: 33.5  22%|████████▊                               |  ETA: 0:00:26
27.713293428947466loss: 27.7  23%|█████████▎                              |  ETA: 0:00:24
23.819529369428558loss: 23.8  24%|█████████▋                              |  ETA: 0:00:23
21.254376718766984loss: 21.3  25%|██████████                              |  ETA: 0:00:22
19.42948561837119loss: 19.4  26%|██████████▍                             |  ETA: 0:00:21
17.90303100693668loss: 17.9  27%|██████████▊                             |  ETA: 0:00:20
16.396085008496147loss: 16.4  28%|███████████▎                            |  ETA: 0:00:19
14.752308970793283loss: 14.8  29%|███████████▋                            |  ETA: 0:00:18
12.909455845343116loss: 12.9  30%|████████████                            |  ETA: 0:00:17
10.875462557797128loss: 10.9  31%|████████████▍                           |  ETA: 0:00:17
8.71288252545796loss: 8.71  32%|████████████▊                           |  ETA: 0:00:16
6.527068602400136loss: 6.53  33%|█████████████▎                          |  ETA: 0:00:15
4.4534149599774855loss: 4.45  34%|█████████████▋                          |  ETA: 0:00:15
2.6412962392444665loss: 2.64  35%|██████████████                          |  ETA: 0:00:14
1.2342795663056394loss: 1.23  36%|██████████████▍                         |  ETA: 0:00:14
0.34591580466382804loss: 0.346  37%|██████████████▍                        |  ETA: 0:00:13
0.03250674863409575loss: 0.0325  38%|██████████████▌                       |  ETA: 0:00:12
0.2643104141460533loss: 0.264  39%|███████████████▎                       |  ETA: 0:00:12
0.9063978746896175loss: 0.906  40%|███████████████▋                       |  ETA: 0:00:12
1.7305156642179889loss: 1.73  41%|████████████████▍                       |  ETA: 0:00:11
2.474340776228947loss: 2.47  42%|████████████████▊                       |  ETA: 0:00:11
2.933823954403367loss: 2.93  43%|█████████████████▎                      |  ETA: 0:00:10
3.036328674003168loss: 3.04  44%|█████████████████▋                      |  ETA: 0:00:10
2.845064882252751loss: 2.85  45%|██████████████████                      |  ETA: 0:00:10
2.498722388181745loss: 2.5  46%|██████████████████▉                      |  ETA: 0:00:09
2.1349443027436377loss: 2.13  47%|██████████████████▊                     |  ETA: 0:00:09
1.8416920826943293loss: 1.84  48%|███████████████████▎                    |  ETA: 0:00:09
1.647195165983145loss: 1.65  49%|███████████████████▋                    |  ETA: 0:00:08
1.5351519818678083loss: 1.54  50%|████████████████████                    |  ETA: 0:00:08
1.467363435420574loss: 1.47  51%|████████████████████▍                   |  ETA: 0:00:08
1.402808855045693loss: 1.4  52%|█████████████████████▍                   |  ETA: 0:00:07
1.3097782742253306loss: 1.31  53%|█████████████████████▎                  |  ETA: 0:00:07
1.171505959067753loss: 1.17  54%|█████████████████████▋                  |  ETA: 0:00:07
0.9870664165854897loss: 0.987  55%|█████████████████████▌                 |  ETA: 0:00:07
0.7692176252015813loss: 0.769  56%|█████████████████████▉                 |  ETA: 0:00:06
0.5403333396407428loss: 0.54  57%|██████████████████████▊                 |  ETA: 0:00:06
0.3272660324350968loss: 0.327  58%|██████████████████████▋                |  ETA: 0:00:06
0.1556853475382298loss: 0.156  59%|███████████████████████                |  ETA: 0:00:06
0.04440205322720733loss: 0.0444  60%|██████████████████████▊               |  ETA: 0:00:05
0.0008926535872599556loss: 0.000893  61%|██████████████████████              |  ETA: 0:00:05
0.019103924236998377loss: 0.0191  62%|███████████████████████▌              |  ETA: 0:00:05
0.08053476982492919loss: 0.0805  63%|████████████████████████              |  ETA: 0:00:05
0.15930730371726676loss: 0.159  64%|█████████████████████████              |  ETA: 0:00:05
0.22964160052502988loss: 0.23  65%|██████████████████████████              |  ETA: 0:00:04
0.2732248514361978loss: 0.273  66%|█████████████████████████▊             |  ETA: 0:00:04
0.2835529968880482loss: 0.284  67%|██████████████████████████▏            |  ETA: 0:00:04
0.2656120696804645loss: 0.266  68%|██████████████████████████▌            |  ETA: 0:00:04
0.23158584804701468loss: 0.232  69%|██████████████████████████▉            |  ETA: 0:00:04
0.19498561339815892loss: 0.195  70%|███████████████████████████▎           |  ETA: 0:00:04
0.1658067074871198loss: 0.166  71%|███████████████████████████▊           |  ETA: 0:00:03
0.14821387238102476loss: 0.148  72%|████████████████████████████▏          |  ETA: 0:00:03
0.14082609760141152loss: 0.141  73%|████████████████████████████▌          |  ETA: 0:00:03
0.13871147379454676loss: 0.139  74%|████████████████████████████▉          |  ETA: 0:00:03
0.13594305715511545loss: 0.136  75%|█████████████████████████████▎         |  ETA: 0:00:03
0.1278012794673704loss: 0.128  76%|█████████████████████████████▋         |  ETA: 0:00:03
0.11211646675910676loss: 0.112  77%|██████████████████████████████         |  ETA: 0:00:03
0.0896168891447801loss: 0.0896  78%|█████████████████████████████▋        |  ETA: 0:00:02
0.06339912950517693loss: 0.0634  79%|██████████████████████████████        |  ETA: 0:00:02
0.03781445974325816loss: 0.0378  80%|██████████████████████████████▍       |  ETA: 0:00:02
0.017120978004210557loss: 0.0171  81%|██████████████████████████████▊       |  ETA: 0:00:02
0.004265227882238975loss: 0.00427  82%|██████████████████████████████▍      |  ETA: 0:00:02
0.00013060182132885353loss: 0.000131  83%|█████████████████████████████▉      |  ETA: 0:00:02
0.0034458547985172228loss: 0.00345  84%|███████████████████████████████▏     |  ETA: 0:00:02
0.01130669877705187loss: 0.0113  85%|████████████████████████████████▎     |  ETA: 0:00:02
0.020224812396146763loss: 0.0202  86%|████████████████████████████████▋     |  ETA: 0:00:01
0.0272115591365223loss: 0.0272  87%|█████████████████████████████████     |  ETA: 0:00:01
0.030573093062484166loss: 0.0306  88%|█████████████████████████████████▌    |  ETA: 0:00:01
0.03015844094040534loss: 0.0302  89%|█████████████████████████████████▉    |  ETA: 0:00:01
0.027049241017987252loss: 0.027  90%|███████████████████████████████████▏   |  ETA: 0:00:01
0.02289578222443347loss: 0.0229  91%|██████████████████████████████████▋   |  ETA: 0:00:01
0.019205145472165897loss: 0.0192  92%|███████████████████████████████████   |  ETA: 0:00:01
0.01684511234890388loss: 0.0168  93%|███████████████████████████████████▍  |  ETA: 0:00:01
0.01588947837509843loss: 0.0159  94%|███████████████████████████████████▊  |  ETA: 0:00:01
0.015782221974403335loss: 0.0158  95%|████████████████████████████████████▏ |  ETA: 0:00:00
0.01569031565022717loss: 0.0157  96%|████████████████████████████████████▌ |  ETA: 0:00:00
0.014882270878558595loss: 0.0149  97%|████████████████████████████████████▉ |  ETA: 0:00:00
0.01299856810201471loss: 0.013  98%|██████████████████████████████████████▎|  ETA: 0:00:00
0.010146481917053394loss: 0.0101  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.0068175358724189405loss: 0.00682 100%|█████████████████████████████████████| Time: 0:00:09
0.00013060182132885353Training 100%|██████████████████████████████████████████| Time: 0:00:10
494.2089032199091473.8759825703607567.1074818633421318.3855315564830028.9648899689183876.117368644930780.16955330167694750.00127452976279778434.4571905150957083e-72.8044413366351072e-82.7293451721924503e-82.729347900600587e-8494.2089032199091473.8237904460742767.225842645127621.36751439899320811.4350691360731788.0109706995672490.32915359623862510.0036303407653235878.934029714091469e-56.246060306129264e-50.00031047251577495510.0058696171661135780.000109832425486265727.733918863503838e-64.2537266437804656e-78.726103760581099e-74.2537266437804656e-72.72458808565546e-72.766701471525958e-72.72458808565546e-72.6483736867625894e-72.648412606822959e-72.6483736867625894e-72.5881397656192965e-72.588142311285918e-72.5881397656192965e-72.508740247077843e-72.508742514801445e-72.508740247077843e-72.508742104639958e-7Starting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},BlackBoxOptim.SimpleSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}
0.00 secs, 0 evals, 0 steps
179.689269947290484750.09315332379742.5946368451790963562.897687624222741.22276719308078601.6964431842247243.807251841729187.4065867503353583.11445474711107353.72753611521864248.032365106219178.7531584079847842.5946368451790967.95189723519634624587.43735728781425.54516732840544270.6775631111618118.18343219508202150.571567975023134079.761017838422914.5249474767747143.66906694803924110.5546676505077511244.9401249846276.006135191907387e61481.502248845912213452.8487065571262396.59777183776621.08987230406058475.32793994086751255.8848049337809255.884804933780942.59463684517909634079.7610178384293.6311109338300934.2759098115473523.36570612784810375.32793994086751110.6757446311229219597.52155261835338.8142016107607789.15935274031544175.0075396046107789.1593527403154449.7071278216383118.1834321950820221.08987230406058441.2227671930807823.36570612784810355.5446212986050939.1438309072664551521.812997405568256208.57252866666175.007539604610776530.62172400848323.36570612784810355.544621298605091.100329514022360621.0898723040605843562.897687624222720759.615071634587515.9067144808291147.69727281793303223.1194394229993341.22276719308078243.80725184172911902.647853446121425.309084351079312707.509962088520378.75315840798478125.622730472860916.5045250290900294750.09315332379738.81420161076077175.007539604610771.3462510551948601e71394.5342097942778168.18321469345878121.36801695558597.95189723519634623.3657061278481037.951897235196346105.73711390728315105.7371139072831525.309084351079311.300847921145814634.2759098115473534.27590981154735127.0584400624288939.0030687596423.365706127848103458.927588092909161168.1762110756467178.6283007201703620096.8659386843231.15432324279567339.00306875964143.669066948039246.6321938304809565e6245.787732487453352143.953044298202
Optimization stopped after 101 steps and 0.30 seconds
Termination reason: Max number of steps (100) reached
Steps per second = 332.56
Function evals per second = 579.51
Improvements/step = 0.38000
Total function evaluations = 176


Best candidate found: [2.77351, 2.72284, 4.50713, 4.20875]

Fitness: 1.100329514

Training   0%|                                          |  ETA: N/A
74.23325824778604loss: 74.2   1%|▍                                       |  ETA: 0:00:31
40.4164194498653loss: 40.4   2%|▊                                       |  ETA: 0:00:15
22.057491209158513loss: 22.1   3%|█▎                                      |  ETA: 0:00:10
12.037002416237797loss: 12   4%|█▋                                        |  ETA: 0:00:08
6.513514176038034loss: 6.51   5%|██                                      |  ETA: 0:00:06
3.449315856483889loss: 3.45   6%|██▍                                     |  ETA: 0:00:05
1.7559405779241133loss: 1.76   7%|██▊                                     |  ETA: 0:00:04
0.8409318703400847loss: 0.841   8%|███▏                                   |  ETA: 0:00:04
0.37442386292913404loss: 0.374   9%|███▌                                   |  ETA: 0:00:03
0.16853186673666665loss: 0.169  10%|███▉                                   |  ETA: 0:00:03
0.11399290140978496loss: 0.114  11%|████▎                                  |  ETA: 0:00:03
0.14612335704642926loss: 0.146  12%|████▋                                  |  ETA: 0:00:02
0.2260857703754901loss: 0.226  13%|█████▏                                 |  ETA: 0:00:02
0.3303346615355988loss: 0.33  14%|█████▋                                  |  ETA: 0:00:02
0.4445359230978686loss: 0.445  15%|█████▉                                 |  ETA: 0:00:02
0.5599902753192113loss: 0.56  16%|██████▍                                 |  ETA: 0:00:02
0.6714894127392135loss: 0.671  17%|██████▋                                |  ETA: 0:00:02
0.7760086714524222loss: 0.776  18%|███████                                |  ETA: 0:00:02
0.8718976552638854loss: 0.872  19%|███████▍                               |  ETA: 0:00:01
0.9583726548559248loss: 0.958  20%|███████▊                               |  ETA: 0:00:01
1.0351944772621668loss: 1.04  21%|████████▍                               |  ETA: 0:00:01
1.1024622728294085loss: 1.1  22%|█████████                                |  ETA: 0:00:01
1.1604806407794377loss: 1.16  23%|█████████▎                              |  ETA: 0:00:01
1.2096736667176855loss: 1.21  24%|█████████▋                              |  ETA: 0:00:01
1.2505292974467475loss: 1.25  25%|██████████                              |  ETA: 0:00:01
1.283563492652668loss: 1.28  26%|██████████▍                             |  ETA: 0:00:01
1.3092973590051766loss: 1.31  27%|██████████▊                             |  ETA: 0:00:01
1.3282428527895576loss: 1.33  28%|███████████▎                            |  ETA: 0:00:01
1.3408941543284723loss: 1.34  29%|███████████▋                            |  ETA: 0:00:01
1.347722799827034loss: 1.35  30%|████████████                            |  ETA: 0:00:01
1.3491752967037178loss: 1.35  31%|████████████▍                           |  ETA: 0:00:01
1.3456723700693698loss: 1.35  32%|████████████▊                           |  ETA: 0:00:01
1.3376092677219953loss: 1.34  33%|█████████████▎                          |  ETA: 0:00:01
1.325356737798009loss: 1.33  34%|█████████████▋                          |  ETA: 0:00:01
1.3092624186822712loss: 1.31  35%|██████████████                          |  ETA: 0:00:01
1.2896524652827968loss: 1.29  36%|██████████████▍                         |  ETA: 0:00:01
1.2668332928708992loss: 1.27  37%|██████████████▊                         |  ETA: 0:00:01
1.2410933585100037loss: 1.24  38%|███████████████▎                        |  ETA: 0:00:01
1.2127049259187612loss: 1.21  39%|███████████████▋                        |  ETA: 0:00:01
1.1819257771614318loss: 1.18  40%|████████████████                        |  ETA: 0:00:01
1.149000846100309loss: 1.15  41%|████████████████▍                       |  ETA: 0:00:01
1.114163756065005loss: 1.11  42%|████████████████▊                       |  ETA: 0:00:01
1.0776382490548937loss: 1.08  43%|█████████████████▎                      |  ETA: 0:00:00
1.0396394962407705loss: 1.04  44%|█████████████████▋                      |  ETA: 0:00:00
1.0003752816538773loss: 1  45%|███████████████████▍                       |  ETA: 0:00:00
0.9600470518264401loss: 0.96  46%|██████████████████▍                     |  ETA: 0:00:00
0.9188508239173396loss: 0.919  47%|██████████████████▍                    |  ETA: 0:00:00
0.8769779454263259loss: 0.877  48%|██████████████████▊                    |  ETA: 0:00:00
0.8346156986981961loss: 0.835  49%|███████████████████▏                   |  ETA: 0:00:00
0.7919477468877152loss: 0.792  50%|███████████████████▌                   |  ETA: 0:00:00
0.7491544012715825loss: 0.749  51%|███████████████████▉                   |  ETA: 0:00:00
0.7064127220919338loss: 0.706  52%|████████████████████▎                  |  ETA: 0:00:00
0.6638964439341639loss: 0.664  53%|████████████████████▋                  |  ETA: 0:00:00
0.621775717268065loss: 0.622  54%|█████████████████████                  |  ETA: 0:00:00
0.5802166741263294loss: 0.58  55%|██████████████████████                  |  ETA: 0:00:00
0.5393808160869739loss: 0.539  56%|█████████████████████▉                 |  ETA: 0:00:00
0.4994242148273938loss: 0.499  57%|██████████████████████▎                |  ETA: 0:00:00
0.46049658508887287loss: 0.46  58%|███████████████████████▎                |  ETA: 0:00:00
0.422740206254793loss: 0.423  59%|███████████████████████                |  ETA: 0:00:00
0.3862887259190619loss: 0.386  60%|███████████████████████▍               |  ETA: 0:00:00
0.3512658747724826loss: 0.351  61%|███████████████████████▊               |  ETA: 0:00:00
0.31778412752220664loss: 0.318  62%|████████████████████████▏              |  ETA: 0:00:00
0.28594335040894087loss: 0.286  63%|████████████████████████▋              |  ETA: 0:00:00
0.2558294812693047loss: 0.256  64%|█████████████████████████              |  ETA: 0:00:00
0.2275132922770024loss: 0.228  65%|█████████████████████████▍             |  ETA: 0:00:00
0.2010492888596346loss: 0.201  66%|█████████████████████████▊             |  ETA: 0:00:00
0.17647479886217407loss: 0.176  67%|██████████████████████████▏            |  ETA: 0:00:00
0.15380930463603779loss: 0.154  68%|██████████████████████████▌            |  ETA: 0:00:00
0.13305406858608437loss: 0.133  69%|██████████████████████████▉            |  ETA: 0:00:00
0.1141920936172176loss: 0.114  70%|███████████████████████████▎           |  ETA: 0:00:00
0.09718845122621063loss: 0.0972  71%|███████████████████████████           |  ETA: 0:00:00
0.08199099776286106loss: 0.082  72%|████████████████████████████▏          |  ETA: 0:00:00
0.06853148399898737loss: 0.0685  73%|███████████████████████████▊          |  ETA: 0:00:00
0.05672704615215089loss: 0.0567  74%|████████████████████████████▏         |  ETA: 0:00:00
0.0464820484633796loss: 0.0465  75%|████████████████████████████▌         |  ETA: 0:00:00
0.037690229420949496loss: 0.0377  76%|████████████████████████████▉         |  ETA: 0:00:00
0.030237086932483195loss: 0.0302  77%|█████████████████████████████▎        |  ETA: 0:00:00
0.024002423470514525loss: 0.024  78%|██████████████████████████████▍        |  ETA: 0:00:00
0.018862961694512584loss: 0.0189  79%|██████████████████████████████        |  ETA: 0:00:00
0.014694935290963164loss: 0.0147  80%|██████████████████████████████▍       |  ETA: 0:00:00
0.01137655951206971loss: 0.0114  81%|██████████████████████████████▊       |  ETA: 0:00:00
0.00879029145714628loss: 0.00879  82%|██████████████████████████████▍      |  ETA: 0:00:00
0.0068248013697039984loss: 0.00682  83%|██████████████████████████████▊      |  ETA: 0:00:00
0.005376592448207337loss: 0.00538  84%|███████████████████████████████▏     |  ETA: 0:00:00
0.004351226758845359loss: 0.00435  85%|███████████████████████████████▌     |  ETA: 0:00:00
0.003664137311381933loss: 0.00366  86%|███████████████████████████████▉     |  ETA: 0:00:00
0.0032410294485036894loss: 0.00324  87%|████████████████████████████████▎    |  ETA: 0:00:00
0.0030178966227528115loss: 0.00302  88%|████████████████████████████████▌    |  ETA: 0:00:00
0.0029406947081914757loss: 0.00294  89%|████████████████████████████████▉    |  ETA: 0:00:00
0.002964733832868185loss: 0.00296  90%|█████████████████████████████████▎   |  ETA: 0:00:00
0.0030538563717949383loss: 0.00305  91%|█████████████████████████████████▋   |  ETA: 0:00:00
0.003179473774834676loss: 0.00318  92%|██████████████████████████████████   |  ETA: 0:00:00
0.003319533428035687loss: 0.00332  93%|██████████████████████████████████▍  |  ETA: 0:00:00
0.003457480368934461loss: 0.00346  94%|██████████████████████████████████▊  |  ETA: 0:00:00
0.0035812684112175508loss: 0.00358  95%|███████████████████████████████████▏ |  ETA: 0:00:00
0.0036824623647110978loss: 0.00368  96%|███████████████████████████████████▌ |  ETA: 0:00:00
0.0037554589589010225loss: 0.00376  97%|███████████████████████████████████▉ |  ETA: 0:00:00
0.003796840145991127loss: 0.0038  98%|█████████████████████████████████████▎|  ETA: 0:00:00
0.003804859847567066loss: 0.0038  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.003779054814435765loss: 0.00378 100%|█████████████████████████████████████| Time: 0:00:00
0.0029406947081914757Training 100%|██████████████████████████████████████████| Time: 0:00:00
74.233258247786041.56137402969470581.5194493086335571.51474703458556980.68245072980120280.19137607162820030.00019285585891125411.7885924618516596e-61.0538953816834905e-105.1109844738397894e-172.1447155860696258e-29Training   0%|                                          |  ETA: N/A
494.2089032199091loss: 494   1%|▍                                        |  ETA: 0:00:35
416.7086995514831loss: 417   2%|▉                                        |  ETA: 0:00:19
301.87186997430365loss: 302   3%|█▎                                       |  ETA: 0:00:13
213.22801705361297loss: 213   4%|█▋                                       |  ETA: 0:00:11
149.40648614478843loss: 149   5%|██                                       |  ETA: 0:00:09
115.22404122493646loss: 115   6%|██▌                                      |  ETA: 0:00:08
96.34543913455384loss: 96.3   7%|██▊                                     |  ETA: 0:00:07
79.39779767791259loss: 79.4   8%|███▎                                    |  ETA: 0:00:06
65.56787147139745loss: 65.6   9%|███▋                                    |  ETA: 0:00:06
54.739696306072744loss: 54.7  10%|████                                    |  ETA: 0:00:05
46.26814316479258loss: 46.3  11%|████▍                                   |  ETA: 0:00:05
39.560838360645405loss: 39.6  12%|████▊                                   |  ETA: 0:00:05
34.298022959616745loss: 34.3  13%|█████▎                                  |  ETA: 0:00:05
30.54633410011867loss: 30.5  14%|█████▋                                  |  ETA: 0:00:04
28.933238146337313loss: 28.9  15%|██████                                  |  ETA: 0:00:04
30.78208250143967loss: 30.8  16%|██████▍                                 |  ETA: 0:00:04
37.55875666101628loss: 37.6  17%|██████▊                                 |  ETA: 0:00:04
47.38704146347047loss: 47.4  18%|███████▎                                |  ETA: 0:00:04
52.318490651270146loss: 52.3  19%|███████▋                                |  ETA: 0:00:04
48.85895443234298loss: 48.9  20%|████████                                |  ETA: 0:00:03
41.143832559196loss: 41.1  21%|████████▍                               |  ETA: 0:00:03
33.50121408603177loss: 33.5  22%|████████▊                               |  ETA: 0:00:03
27.713293428947466loss: 27.7  23%|█████████▎                              |  ETA: 0:00:03
23.819529369428558loss: 23.8  24%|█████████▋                              |  ETA: 0:00:03
21.254376718766984loss: 21.3  25%|██████████                              |  ETA: 0:00:03
19.42948561837119loss: 19.4  26%|██████████▍                             |  ETA: 0:00:03
17.90303100693668loss: 17.9  27%|██████████▊                             |  ETA: 0:00:03
16.396085008496147loss: 16.4  28%|███████████▎                            |  ETA: 0:00:03
14.752308970793283loss: 14.8  29%|███████████▋                            |  ETA: 0:00:03
12.909455845343116loss: 12.9  30%|████████████                            |  ETA: 0:00:03
10.875462557797128loss: 10.9  31%|████████████▍                           |  ETA: 0:00:03
8.71288252545796loss: 8.71  32%|████████████▊                           |  ETA: 0:00:03
6.527068602400136loss: 6.53  33%|█████████████▎                          |  ETA: 0:00:03
4.4534149599774855loss: 4.45  34%|█████████████▋                          |  ETA: 0:00:03
2.6412962392444665loss: 2.64  35%|██████████████                          |  ETA: 0:00:02
1.2342795663056394loss: 1.23  36%|██████████████▍                         |  ETA: 0:00:02
0.34591580466382804loss: 0.346  37%|██████████████▍                        |  ETA: 0:00:02
0.03250674863409575loss: 0.0325  38%|██████████████▌                       |  ETA: 0:00:02
0.2643104141460533loss: 0.264  39%|███████████████▎                       |  ETA: 0:00:02
0.9063978746896175loss: 0.906  40%|███████████████▋                       |  ETA: 0:00:02
1.7305156642179889loss: 1.73  41%|████████████████▍                       |  ETA: 0:00:02
2.474340776228947loss: 2.47  42%|████████████████▊                       |  ETA: 0:00:02
2.933823954403367loss: 2.93  43%|█████████████████▎                      |  ETA: 0:00:02
3.036328674003168loss: 3.04  44%|█████████████████▋                      |  ETA: 0:00:02
2.845064882252751loss: 2.85  45%|██████████████████                      |  ETA: 0:00:02
2.498722388181745loss: 2.5  46%|██████████████████▉                      |  ETA: 0:00:02
2.1349443027436377loss: 2.13  47%|██████████████████▊                     |  ETA: 0:00:02
1.8416920826943293loss: 1.84  48%|███████████████████▎                    |  ETA: 0:00:02
1.647195165983145loss: 1.65  49%|███████████████████▋                    |  ETA: 0:00:02
1.5351519818678083loss: 1.54  50%|████████████████████                    |  ETA: 0:00:02
1.467363435420574loss: 1.47  51%|████████████████████▍                   |  ETA: 0:00:02
1.402808855045693loss: 1.4  52%|█████████████████████▍                   |  ETA: 0:00:02
1.3097782742253306loss: 1.31  53%|█████████████████████▎                  |  ETA: 0:00:02
1.171505959067753loss: 1.17  54%|█████████████████████▋                  |  ETA: 0:00:02
0.9870664165854897loss: 0.987  55%|█████████████████████▌                 |  ETA: 0:00:01
0.7692176252015813loss: 0.769  56%|█████████████████████▉                 |  ETA: 0:00:01
0.5403333396407428loss: 0.54  57%|██████████████████████▊                 |  ETA: 0:00:01
0.3272660324350968loss: 0.327  58%|██████████████████████▋                |  ETA: 0:00:01
0.1556853475382298loss: 0.156  59%|███████████████████████                |  ETA: 0:00:01
0.04440205322720733loss: 0.0444  60%|██████████████████████▊               |  ETA: 0:00:01
0.0008926535872599556loss: 0.000893  61%|██████████████████████              |  ETA: 0:00:01
0.019103924236998377loss: 0.0191  62%|███████████████████████▌              |  ETA: 0:00:01
0.08053476982492919loss: 0.0805  63%|████████████████████████              |  ETA: 0:00:01
0.15930730371726676loss: 0.159  64%|█████████████████████████              |  ETA: 0:00:01
0.22964160052502988loss: 0.23  65%|██████████████████████████              |  ETA: 0:00:01
0.2732248514361978loss: 0.273  66%|█████████████████████████▊             |  ETA: 0:00:01
0.2835529968880482loss: 0.284  67%|██████████████████████████▏            |  ETA: 0:00:01
0.2656120696804645loss: 0.266  68%|██████████████████████████▌            |  ETA: 0:00:01
0.23158584804701468loss: 0.232  69%|██████████████████████████▉            |  ETA: 0:00:01
0.19498561339815892loss: 0.195  70%|███████████████████████████▎           |  ETA: 0:00:01
0.1658067074871198loss: 0.166  71%|███████████████████████████▊           |  ETA: 0:00:01
0.14821387238102476loss: 0.148  72%|████████████████████████████▏          |  ETA: 0:00:01
0.14082609760141152loss: 0.141  73%|████████████████████████████▌          |  ETA: 0:00:01
0.13871147379454676loss: 0.139  74%|████████████████████████████▉          |  ETA: 0:00:01
0.13594305715511545loss: 0.136  75%|█████████████████████████████▎         |  ETA: 0:00:01
0.1278012794673704loss: 0.128  76%|█████████████████████████████▋         |  ETA: 0:00:01
0.11211646675910676loss: 0.112  77%|██████████████████████████████         |  ETA: 0:00:01
0.0896168891447801loss: 0.0896  78%|█████████████████████████████▋        |  ETA: 0:00:01
0.06339912950517693loss: 0.0634  79%|██████████████████████████████        |  ETA: 0:00:01
0.03781445974325816loss: 0.0378  80%|██████████████████████████████▍       |  ETA: 0:00:01
0.017120978004210557loss: 0.0171  81%|██████████████████████████████▊       |  ETA: 0:00:01
0.004265227882238975loss: 0.00427  82%|██████████████████████████████▍      |  ETA: 0:00:01
0.00013060182132885353loss: 0.000131  83%|█████████████████████████████▉      |  ETA: 0:00:01
0.0034458547985172228loss: 0.00345  84%|███████████████████████████████▏     |  ETA: 0:00:01
0.01130669877705187loss: 0.0113  85%|████████████████████████████████▎     |  ETA: 0:00:01
0.020224812396146763loss: 0.0202  86%|████████████████████████████████▋     |  ETA: 0:00:00
0.0272115591365223loss: 0.0272  87%|█████████████████████████████████     |  ETA: 0:00:00
0.030573093062484166loss: 0.0306  88%|█████████████████████████████████▌    |  ETA: 0:00:00
0.03015844094040534loss: 0.0302  89%|█████████████████████████████████▉    |  ETA: 0:00:00
0.027049241017987252loss: 0.027  90%|███████████████████████████████████▏   |  ETA: 0:00:00
0.02289578222443347loss: 0.0229  91%|██████████████████████████████████▋   |  ETA: 0:00:00
0.019205145472165897loss: 0.0192  92%|███████████████████████████████████   |  ETA: 0:00:00
0.01684511234890388loss: 0.0168  93%|███████████████████████████████████▍  |  ETA: 0:00:00
0.01588947837509843loss: 0.0159  94%|███████████████████████████████████▊  |  ETA: 0:00:00
0.015782221974403335loss: 0.0158  95%|████████████████████████████████████▏ |  ETA: 0:00:00
0.01569031565022717loss: 0.0157  96%|████████████████████████████████████▌ |  ETA: 0:00:00
0.014882270878558595loss: 0.0149  97%|████████████████████████████████████▉ |  ETA: 0:00:00
0.01299856810201471loss: 0.013  98%|██████████████████████████████████████▎|  ETA: 0:00:00
0.010146481917053394loss: 0.0101  99%|█████████████████████████████████████▋|  ETA: 0:00:00
0.0068175358724189405loss: 0.00682 100%|█████████████████████████████████████| Time: 0:00:03
0.00013060182132885353Training 100%|██████████████████████████████████████████| Time: 0:00:03
494.2089032199091473.8759825703607567.1074818633421318.3855315564830028.9648899689183876.117368644930780.16955330167694750.00127452976279778434.4571905150957083e-72.8044413366351072e-82.7293451721924503e-82.729347900600587e-8494.2089032199091473.8237904460742767.225842645127621.36751439899320811.4350691360731788.0109706995672490.32915359623862510.0036303407653235878.934029714091469e-56.246060306129264e-50.00031047251577495510.0058696171661135780.000109832425486265727.733918863503838e-64.2537266437804656e-78.726103760581099e-74.2537266437804656e-72.72458808565546e-72.766701471525958e-72.72458808565546e-72.6483736867625894e-72.648412606822959e-72.6483736867625894e-72.5881397656192965e-72.588142311285918e-72.5881397656192965e-72.508740247077843e-72.508742514801445e-72.508740247077843e-72.508742104639958e-7fval:4.94e+02  norm:3.16e+00
fval:7.43e+05  norm:2.61e+00
fval:8.79e+05  norm:2.73e+00
fval:1.51e+05  norm:2.92e+00
fval:2.24e+03  norm:3.07e+00
fval:4.87e+02  norm:3.14e+00
fval:3.70e+02  norm:3.14e+00
fval:1.96e+02  norm:3.16e+00
fval:1.41e+02  norm:3.16e+00
fval:5.00e+01  norm:3.11e+00
fval:2.77e+01  norm:3.09e+00
fval:1.16e+02  norm:3.14e+00
fval:6.74e+00  norm:3.06e+00
fval:6.17e+02  norm:3.00e+00
fval:3.01e-01  norm:3.01e+00
fval:2.34e-01  norm:3.03e+00
fval:1.19e-02  norm:3.02e+00
fval:1.28e+00  norm:3.00e+00
fval:1.76e-03  norm:3.02e+00
fval:6.35e-04  norm:3.02e+00
fval:4.33e-03  norm:3.02e+00
fval:7.05e-06  norm:3.02e+00
fval:1.18e-03  norm:3.02e+00
fval:1.40e-06  norm:3.02e+00
fval:4.46e-08  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:5.45e-09  norm:3.02e+00
fval:1.42e-09  norm:3.02e+00
fval:1.04e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
fval:1.02e-09  norm:3.02e+00
Layers SciML Tests: Error During Test at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:25
  Got exception outside of a @test
  LoadError: MethodError: no method matching iterate(::DataStructures.BinaryHeap{Float64,DataStructures.LessThan})
  Closest candidates are:
    iterate(!Matched::DataStructures.TrieIterator) at /home/pkgeval/.julia/packages/DataStructures/DLSxi/src/trie.jl:112
    iterate(!Matched::DataStructures.TrieIterator, !Matched::Any) at /home/pkgeval/.julia/packages/DataStructures/DLSxi/src/trie.jl:112
    iterate(!Matched::LoopVectorization.LoopOrders) at /home/pkgeval/.julia/packages/LoopVectorization/OZUlx/src/determinestrategy.jl:921
    ...
  Stacktrace:
   [1] first(::DataStructures.BinaryHeap{Float64,DataStructures.LessThan}) at ./abstractarray.jl:341
   [2] check_error(::OrdinaryDiffEq.ODEIntegrator{OrdinaryDiffEq.Tsit5,false,Array{Float64,1},Nothing,Float64,Array{Float64,1},Float64,Float64,Float64,Array{Array{Float64,1},1},DiffEqBase.ODESolution{Float64,2,Array{Array{Float64,1},1},Nothing,Nothing,Array{Float64,1},Array{Array{Array{Float64,1},1},1},DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem},OrdinaryDiffEq.Tsit5,OrdinaryDiffEq.InterpolationData{DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Array{Array{Float64,1},1},Array{Float64,1},Array{Array{Array{Float64,1},1},1},OrdinaryDiffEq.Tsit5ConstantCache{Float64,Float64}},DiffEqBase.DEStats},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},OrdinaryDiffEq.Tsit5ConstantCache{Float64,Float64},OrdinaryDiffEq.DEOptions{Float64,Float64,Float64,Float64,typeof(DiffEqBase.ODE_DEFAULT_NORM),typeof(LinearAlgebra.opnorm),DiffEqBase.CallbackSet{Tuple{},Tuple{}},typeof(DiffEqBase.ODE_DEFAULT_ISOUTOFDOMAIN),typeof(DiffEqBase.ODE_DEFAULT_PROG_MESSAGE),typeof(DiffEqBase.ODE_DEFAULT_UNSTABLE_CHECK),DataStructures.BinaryHeap{Float64,DataStructures.LessThan},DataStructures.BinaryHeap{Float64,DataStructures.LessThan},Nothing,Nothing,Int64,Tuple{},Tuple{},Tuple{}},Array{Float64,1},Float64,Nothing,OrdinaryDiffEq.DefaultInit}) at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/integrator_interface.jl:337
   [3] check_error! at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/integrator_interface.jl:371 [inlined]
   [4] solve!(::OrdinaryDiffEq.ODEIntegrator{OrdinaryDiffEq.Tsit5,false,Array{Float64,1},Nothing,Float64,Array{Float64,1},Float64,Float64,Float64,Array{Array{Float64,1},1},DiffEqBase.ODESolution{Float64,2,Array{Array{Float64,1},1},Nothing,Nothing,Array{Float64,1},Array{Array{Array{Float64,1},1},1},DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem},OrdinaryDiffEq.Tsit5,OrdinaryDiffEq.InterpolationData{DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Array{Array{Float64,1},1},Array{Float64,1},Array{Array{Array{Float64,1},1},1},OrdinaryDiffEq.Tsit5ConstantCache{Float64,Float64}},DiffEqBase.DEStats},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},OrdinaryDiffEq.Tsit5ConstantCache{Float64,Float64},OrdinaryDiffEq.DEOptions{Float64,Float64,Float64,Float64,typeof(DiffEqBase.ODE_DEFAULT_NORM),typeof(LinearAlgebra.opnorm),DiffEqBase.CallbackSet{Tuple{},Tuple{}},typeof(DiffEqBase.ODE_DEFAULT_ISOUTOFDOMAIN),typeof(DiffEqBase.ODE_DEFAULT_PROG_MESSAGE),typeof(DiffEqBase.ODE_DEFAULT_UNSTABLE_CHECK),DataStructures.BinaryHeap{Float64,DataStructures.LessThan},DataStructures.BinaryHeap{Float64,DataStructures.LessThan},Nothing,Nothing,Int64,Tuple{},Tuple{},Tuple{}},Array{Float64,1},Float64,Nothing,OrdinaryDiffEq.DefaultInit}) at /home/pkgeval/.julia/packages/OrdinaryDiffEq/VPJBD/src/solve.jl:425
   [5] #__solve#391 at /home/pkgeval/.julia/packages/OrdinaryDiffEq/VPJBD/src/solve.jl:5 [inlined]
   [6] #solve_call#455 at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:65 [inlined]
   [7] solve_up(::DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem}, ::Nothing, ::Array{Float64,1}, ::Array{Float64,1}, ::OrdinaryDiffEq.Tsit5; kwargs::Base.Iterators.Pairs{Symbol,Real,NTuple{4,Symbol},NamedTuple{(:save_noise, :save_start, :save_end, :reltol),Tuple{Bool,Bool,Bool,Float64}}}) at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:86
   [8] #solve#456 at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:74 [inlined]
   [9] _concrete_solve_adjoint(::DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem}, ::OrdinaryDiffEq.Tsit5, ::DiffEqSensitivity.InterpolatingAdjoint{0,true,Val{:central},Bool,Bool}, ::Array{Float64,1}, ::Array{Float64,1}; save_start::Bool, save_end::Bool, saveat::Float64, save_idxs::Nothing, kwargs::Base.Iterators.Pairs{Symbol,Float64,Tuple{Symbol},NamedTuple{(:reltol,),Tuple{Float64}}}) at /home/pkgeval/.julia/packages/DiffEqSensitivity/gBrQz/src/local_sensitivity/concrete_solve.jl:55
   [10] #_concrete_solve_adjoint#123 at /home/pkgeval/.julia/packages/DiffEqSensitivity/gBrQz/src/local_sensitivity/concrete_solve.jl:25 [inlined]
   [11] #_solve_adjoint#477 at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:277 [inlined]
   [12] #adjoint#468 at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:241 [inlined]
   [13] _pullback at /home/pkgeval/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:53 [inlined]
   [14] adjoint at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/lib/lib.jl:175 [inlined]
   [15] _pullback at /home/pkgeval/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:47 [inlined]
   [16] #solve#456 at /home/pkgeval/.julia/packages/DiffEqBase/AMw6H/src/solve.jl:74 [inlined]
   [17] _pullback(::Zygote.Context, ::DiffEqBase.var"##solve#456", ::Nothing, ::Nothing, ::Array{Float64,1}, ::Base.Iterators.Pairs{Symbol,Float64,Tuple{Symbol,Symbol},NamedTuple{(:saveat, :reltol),Tuple{Float64,Float64}}}, ::typeof(DiffEqBase.solve), ::DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem}, ::OrdinaryDiffEq.Tsit5) at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface2.jl:0
   [18] adjoint at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/lib/lib.jl:175 [inlined]
   [19] _pullback at /home/pkgeval/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:47 [inlined]
   [20] _pullback(::Zygote.Context, ::DiffEqBase.var"#solve##kw", ::NamedTuple{(:p, :saveat, :reltol),Tuple{Array{Float64,1},Float64,Float64}}, ::typeof(DiffEqBase.solve), ::DiffEqBase.ODEProblem{Array{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.ODEFunction{false,typeof(Main.##431.lotka_volterra2),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem}, ::OrdinaryDiffEq.Tsit5) at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface2.jl:0
   [21] predict_adjoint at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/layers_sciml.jl:138 [inlined]
   [22] _pullback(::Zygote.Context, ::typeof(Main.##431.predict_adjoint), ::Array{Float64,1}) at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface2.jl:0
   [23] loss_adjoint at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/layers_sciml.jl:141 [inlined]
   [24] _pullback(::Zygote.Context, ::typeof(Main.##431.loss_adjoint), ::Array{Float64,1}) at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface2.jl:0
   [25] adjoint at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/lib/lib.jl:175 [inlined]
   [26] adjoint(::Zygote.Context, ::typeof(Core._apply_iterate), ::typeof(iterate), ::Function, ::Tuple{Array{Float64,1}}, ::DiffEqFlux.NullData) at ./none:0
   [27] _pullback at /home/pkgeval/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:47 [inlined]
   [28] #69 at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/src/train.jl:197 [inlined]
   [29] _pullback(::Zygote.Context, ::DiffEqFlux.var"#69#82"{typeof(Main.##431.loss_adjoint)}, ::Array{Float64,1}) at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface2.jl:0
   [30] _pullback at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface.jl:38 [inlined]
   [31] pullback at /home/pkgeval/.julia/packages/Zygote/rqvFi/src/compiler/interface.jl:44 [inlined]
   [32] (::DiffEqFlux.var"#72#85"{DiffEqFlux.var"#69#82"{typeof(Main.##431.loss_adjoint)}})(::Array{Float64,1}, ::Array{Float64,1}) at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/src/train.jl:218
   [33] value_gradient!!(::NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}}, ::Array{Float64,1}) at /home/pkgeval/.julia/packages/NLSolversBase/5oIMo/src/interface.jl:82
   [34] value_gradient! at /home/pkgeval/.julia/packages/NLSolversBase/5oIMo/src/interface.jl:69 [inlined]
   [35] (::LineSearches.var"#ϕdϕ#6"{NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}},Array{Float64,1},Array{Float64,1},Array{Float64,1}})(::Float64) at /home/pkgeval/.julia/packages/LineSearches/pJuyA/src/LineSearches.jl:84
   [36] (::LineSearches.HagerZhang{Float64,Base.RefValue{Bool}})(::Function, ::LineSearches.var"#ϕdϕ#6"{NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}},Array{Float64,1},Array{Float64,1},Array{Float64,1}}, ::Float64, ::Float64, ::Float64) at /home/pkgeval/.julia/packages/LineSearches/pJuyA/src/hagerzhang.jl:139
   [37] HagerZhang at /home/pkgeval/.julia/packages/LineSearches/pJuyA/src/hagerzhang.jl:101 [inlined]
   [38] perform_linesearch!(::Optim.NewtonState{Array{Float64,1},Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}, ::Optim.Newton{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}}) at /home/pkgeval/.julia/packages/Optim/TNmSw/src/utilities/perform_linesearch.jl:56
   [39] update_state!(::NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}}, ::Optim.NewtonState{Array{Float64,1},Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}, ::Optim.Newton{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}) at /home/pkgeval/.julia/packages/Optim/TNmSw/src/multivariate/solvers/second_order/newton.jl:79
   [40] optimize(::NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}}, ::Array{Float64,1}, ::Optim.Newton{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Optim.Options{Float64,DiffEqFlux.var"#_cb#81"{DiffEqFlux.var"#79#92",Base.Iterators.Cycle{Tuple{DiffEqFlux.NullData}}}}, ::Optim.NewtonState{Array{Float64,1},Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}) at /home/pkgeval/.julia/packages/Optim/TNmSw/src/multivariate/optimize/optimize.jl:57
   [41] optimize(::NLSolversBase.TwiceDifferentiable{Float64,Array{Float64,1},Array{Float64,2},Array{Float64,1}}, ::Array{Float64,1}, ::Optim.Newton{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Optim.Options{Float64,DiffEqFlux.var"#_cb#81"{DiffEqFlux.var"#79#92",Base.Iterators.Cycle{Tuple{DiffEqFlux.NullData}}}}) at /home/pkgeval/.julia/packages/Optim/TNmSw/src/multivariate/optimize/optimize.jl:33
   [42] sciml_train(::Function, ::Array{Float64,1}, ::Optim.Newton{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Base.Iterators.Cycle{Tuple{DiffEqFlux.NullData}}; cb::Function, maxiters::Int64, diffmode::DiffEqFlux.ZygoteDiffMode, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/src/train.jl:290
   [43] sciml_train at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/src/train.jl:184 [inlined] (repeats 2 times)
   [44] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/layers_sciml.jl:143
   [45] include(::Function, ::Module, ::String) at ./Base.jl:380
   [46] include at ./Base.jl:368 [inlined]
   [47] include(::String) at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:23
   [48] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/runtests.jl:20
   [49] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1115
   [50] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/runtests.jl:20
   [51] eval(::Module, ::Any) at ./boot.jl:331
   [52] top-level scope at /home/pkgeval/.julia/packages/SafeTestsets/A83XK/src/SafeTestsets.jl:23
   [53] top-level scope at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/runtests.jl:20
   [54] top-level scope at timing.jl:174
   [55] include(::String) at ./client.jl:457
   [56] top-level scope at none:6
   [57] eval(::Module, ::Any) at ./boot.jl:331
   [58] exec_options(::Base.JLOptions) at ./client.jl:272
  in expression starting at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/layers_sciml.jl:143
  
Test Summary:      | Pass  Error  Total
Layers SciML Tests |   13      1     14
ERROR: LoadError: Some tests did not pass: 13 passed, 0 failed, 1 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/DiffEqFlux/1xTu3/test/runtests.jl:16
ERROR: Package DiffEqFlux errored during testing
Stacktrace:
 [1] pkgerror(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1578
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:328
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:315
 [5] #test#61 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]
 [7] #test#60 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65
 [11] top-level scope at none:16
